id,updated,published,title,summary,database
http://arxiv.org/abs/1807.11805v2,2018-08-08T09:29:37Z,2018-07-31T13:24:31Z,Disaster Monitoring using Unmanned Aerial Vehicles and Deep Learning,"Monitoring of disasters is crucial for mitigating their effects on the
environment and human population, and can be facilitated by the use of unmanned
aerial vehicles (UAV), equipped with camera sensors that produce aerial photos
of the areas of interest. A modern technique for recognition of events based on
aerial photos is deep learning. In this paper, we present the state of the art
work related to the use of deep learning techniques for disaster
identification. We demonstrate the potential of this technique in identifying
disasters with high accuracy, by means of a relatively simple deep learning
model. Based on a dataset of 544 images (containing disaster images such as
fires, earthquakes, collapsed buildings, tsunami and flooding, as well as
non-disaster scenes), our results show an accuracy of 91% achieved, indicating
that deep learning, combined with UAV equipped with camera sensors, have the
potential to predict disasters with high accuracy.",arxiv
http://arxiv.org/abs/1906.05015v10,2020-03-04T02:18:20Z,2019-06-12T09:12:50Z,"Deep Reinforcement Learning for Unmanned Aerial Vehicle-Assisted
  Vehicular Networks","Unmanned aerial vehicles (UAVs) are envisioned to complement the 5G
communication infrastructure in future smart cities. Hot spots easily appear in
road intersections, where effective communication among vehicles is
challenging. UAVs may serve as relays with the advantages of low price, easy
deployment, line-of-sight links, and flexible mobility. In this paper, we study
a UAV-assisted vehicular network where the UAV jointly adjusts its transmission
control (power and channel) and 3D flight to maximize the total throughput.
First, we formulate a Markov decision process (MDP) problem by modeling the
mobility of the UAV/vehicles and the state transitions. Secondly, we solve the
target problem using a deep reinforcement learning method under unknown or
unmeasurable environment variables especially in 5G, namely, the deep
deterministic policy gradient (DDPG), and propose three solutions with
different control objectives. Environment variables are unknown and
unmeasurable, therefore, we use a deep reinforcement learning method. Moreover,
considering the energy consumption of 3D flight, we extend the proposed
solutions to maximize the total throughput per energy unit by encouraging or
discouraging the UAV's mobility. To achieve this goal, the DDPG framework is
modified. Thirdly, in a simplified model with small state space and action
space, we verify the optimality of proposed algorithms. Comparing with two
baseline schemes, we demonstrate the effectiveness of proposed algorithms in a
realistic model.",arxiv
http://arxiv.org/abs/1706.01384v1,2017-06-05T15:49:12Z,2017-06-05T15:49:12Z,"Time-Varying Formation Controllers for Unmanned Aerial Vehicles Using
  Deep Reinforcement Learning","We consider the problem of designing scalable and portable controllers for
unmanned aerial vehicles (UAVs) to reach time-varying formations as quickly as
possible. This brief confirms that deep reinforcement learning can be used in a
multi-agent fashion to drive UAVs to reach any formation while taking into
account optimality and portability. We use a deep neural network to estimate
how good a state is, so the agent can choose actions accordingly. The system is
tested with different non-high-dimensional sensory inputs without any change in
the neural network architecture, algorithm or hyperparameters, just with
additional training.",arxiv
http://arxiv.org/abs/2008.06189v1,2020-08-14T04:35:10Z,2020-08-14T04:35:10Z,"An Improved Deep Convolutional Neural Network-Based Autonomous Road
  Inspection Scheme Using Unmanned Aerial Vehicles","Advancements in artificial intelligence (AI) gives a great opportunity to
develop an autonomous devices. The contribution of this work is an improved
convolutional neural network (CNN) model and its implementation for the
detection of road cracks, potholes, and yellow lane in the road. The purpose of
yellow lane detection and tracking is to realize autonomous navigation of
unmanned aerial vehicle (UAV) by following yellow lane while detecting and
reporting the road cracks and potholes to the server through WIFI or 5G medium.
The fabrication of own data set is a hectic and time-consuming task. The data
set is created, labeled and trained using default and an improved model. The
performance of both these models is benchmarked with respect to accuracy, mean
average precision (mAP) and detection time. In the testing phase, it was
observed that the performance of the improved model is better in respect of
accuracy and mAP. The improved model is implemented in UAV using the robot
operating system for the autonomous detection of potholes and cracks in roads
via UAV front camera vision in real-time.",arxiv
http://arxiv.org/abs/1908.06472v1,2019-08-18T16:25:14Z,2019-08-18T16:25:14Z,"Training Deep Learning Models via Synthetic Data: Application in
  Unmanned Aerial Vehicles","This paper describes preliminary work in the recent promising approach of
generating synthetic training data for facilitating the learning procedure of
deep learning (DL) models, with a focus on aerial photos produced by unmanned
aerial vehicles (UAV). The general concept and methodology are described, and
preliminary results are presented, based on a classification problem of fire
identification in forests as well as a counting problem of estimating number of
houses in urban areas. The proposed technique constitutes a new possibility for
the DL community, especially related to UAV-based imagery analysis, with much
potential, promising results, and unexplored ground for further research.",arxiv
http://arxiv.org/abs/2001.04944v1,2020-01-14T17:59:09Z,2020-01-14T17:59:09Z,"Testbed for Connected Artificial Intelligence using Unmanned Aerial
  Vehicles and Convolutional Pose Machines","Unmanned Aerial Vehicles (UAVs) became very popular in a vast number of
applications in recent years, especially drones with computer vision functions
enabled by on-board cameras and embedded systems. Many of them apply object
detection using data collected by the integrated camera. However, several
applications of real-time object detection rely on Convolutional Neural
Networks (CNNs) which are computationally expensive and processing CNNs on a
UAV platform is challenging (due to its limited battery life and limited
processing power). To understand the effects of these issues, in this paper we
evaluate the constraints and benefits of processing the whole data in the UAV
versus in an edge computing device. We apply Convolutional Pose Machines (CPMs)
known as OpenPose for the task of articulated pose estimation. We used this
information to detect human gestures that are used as input to send commands to
control the UAV. The experimental results using a real UAV indicate that the
edge processing is more efficient and faster (w.r.t battery consumption and the
delay in recognizing the human pose and the command given to the drone) than
UAV processing and then could be more suitable for CNNs based applications.",arxiv
http://arxiv.org/abs/2012.15472v1,2020-12-31T07:00:44Z,2020-12-31T07:00:44Z,"Multi-Agent Reinforcement Learning for Unmanned Aerial Vehicle
  Coordination by Multi-Critic Policy Gradient Optimization","Recent technological progress in the development of Unmanned Aerial Vehicles
(UAVs) together with decreasing acquisition costs make the application of drone
fleets attractive for a wide variety of tasks. In agriculture, disaster
management, search and rescue operations, commercial and military applications,
the advantage of applying a fleet of drones originates from their ability to
cooperate autonomously. Multi-Agent Reinforcement Learning approaches that aim
to optimize a neural network based control policy, such as the best performing
actor-critic policy gradient algorithms, struggle to effectively back-propagate
errors of distinct rewards signal sources and tend to favor lucrative signals
while neglecting coordination and exploitation of previously learned
similarities. We propose a Multi-Critic Policy Optimization architecture with
multiple value estimating networks and a novel advantage function that
optimizes a stochastic actor policy network to achieve optimal coordination of
agents. Consequently, we apply the algorithm to several tasks that require the
collaboration of multiple drones in a physics-based reinforcement learning
environment. Our approach achieves a stable policy network update and
similarity in reward signal development for an increasing number of agents. The
resulting policy achieves optimal coordination and compliance with constraints
such as collision avoidance.",arxiv
http://arxiv.org/abs/2004.08603v2,2020-04-21T10:35:16Z,2020-04-18T12:17:18Z,"Real-time System Identification Using Deep Learning for Linear Processes
  with Application to Unmanned Aerial Vehicles","This paper proposes a novel parametric identification approach for linear
systems using Deep Learning (DL) and the Modified Relay Feedback Test (MRFT).
The proposed methodology utilizes MRFT to reveal distinguishing frequencies
about an unknown process; which are then passed to a trained DL model to
identify the underlying process parameters. The presented approach guarantees
stability and performance in the identification and control phases
respectively, and requires few seconds of observation data to infer the dynamic
system parameters. Quadrotor Unmanned Aerial Vehicle (UAV) attitude and
altitude dynamics were used in simulation and experimentation to verify the
presented methodology. Results show the effectiveness and real-time
capabilities of the proposed approach, which outperforms the conventional
Prediction Error Method in terms of accuracy, robustness to biases,
computational efficiency and data requirements.",arxiv
http://arxiv.org/abs/1905.10796v1,2019-05-26T12:36:26Z,2019-05-26T12:36:26Z,"Online Deep Learning for Improved Trajectory Tracking of Unmanned Aerial
  Vehicles Using Expert Knowledge","This work presents an online learning-based control method for improved
trajectory tracking of unmanned aerial vehicles using both deep learning and
expert knowledge. The proposed method does not require the exact model of the
system to be controlled, and it is robust against variations in system dynamics
as well as operational uncertainties. The learning is divided into two phases:
offline (pre-)training and online (post-)training. In the former, a
conventional controller performs a set of trajectories and, based on the
input-output dataset, the deep neural network (DNN)-based controller is
trained. In the latter, the trained DNN, which mimics the conventional
controller, controls the system. Unlike the existing papers in the literature,
the network is still being trained for different sets of trajectories which are
not used in the training phase of DNN. Thanks to the rule-base, which contains
the expert knowledge, the proposed framework learns the system dynamics and
operational uncertainties in real-time. The experimental results show that the
proposed online learning-based approach gives better trajectory tracking
performance when compared to the only offline trained network.",arxiv
http://arxiv.org/abs/1906.08716v1,2019-06-20T16:03:32Z,2019-06-20T16:03:32Z,"Deep-Learning-Based Aerial Image Classification for Emergency Response
  Applications Using Unmanned Aerial Vehicles","Unmanned Aerial Vehicles (UAVs), equipped with camera sensors can facilitate
enhanced situational awareness for many emergency response and disaster
management applications since they are capable of operating in remote and
difficult to access areas. In addition, by utilizing an embedded platform and
deep learning UAVs can autonomously monitor a disaster stricken area, analyze
the image in real-time and alert in the presence of various calamities such as
collapsed buildings, flood, or fire in order to faster mitigate their effects
on the environment and on human population. To this end, this paper focuses on
the automated aerial scene classification of disaster events from on-board a
UAV. Specifically, a dedicated Aerial Image Database for Emergency Response
(AIDER) applications is introduced and a comparative analysis of existing
approaches is performed. Through this analysis a lightweight convolutional
neural network (CNN) architecture is developed, capable of running efficiently
on an embedded platform achieving ~3x higher performance compared to existing
models with minimal memory requirements with less than 2% accuracy drop
compared to the state-of-the-art. These preliminary results provide a solid
basis for further experimentation towards real-time aerial image classification
for emergency response applications using UAVs.",arxiv
http://arxiv.org/abs/2005.00336v2,2020-05-06T18:55:28Z,2020-04-03T22:46:34Z,"On-board Deep-learning-based Unmanned Aerial Vehicle Fault Cause
  Detection and Identification","With the increase in use of Unmanned Aerial Vehicles (UAVs)/drones, it is
important to detect and identify causes of failure in real time for proper
recovery from a potential crash-like scenario or post incident forensics
analysis. The cause of crash could be either a fault in the sensor/actuator
system, a physical damage/attack, or a cyber attack on the drone's software. In
this paper, we propose novel architectures based on deep Convolutional and Long
Short-Term Memory Neural Networks (CNNs and LSTMs) to detect (via Autoencoder)
and classify drone mis-operations based on sensor data. The proposed
architectures are able to learn high-level features automatically from the raw
sensor data and learn the spatial and temporal dynamics in the sensor data. We
validate the proposed deep-learning architectures via simulations and
experiments on a real drone. Empirical results show that our solution is able
to detect with over 90% accuracy and classify various types of drone
mis-operations (with about 99% accuracy (simulation data) and upto 88% accuracy
(experimental data)).",arxiv
http://arxiv.org/abs/2103.13933v3,2021-08-18T14:58:41Z,2021-03-25T15:51:53Z,"Unmanned Aerial Vehicle Visual Detection and Tracking using Deep Neural
  Networks: A Performance Benchmark","Unmanned Aerial Vehicles (UAV) can pose a major risk for aviation safety, due
to both negligent and malicious use. For this reason, the automated detection
and tracking of UAV is a fundamental task in aerial security systems. Common
technologies for UAV detection include visible-band and thermal infrared
imaging, radio frequency and radar. Recent advances in deep neural networks
(DNNs) for image-based object detection open the possibility to use visual
information for this detection and tracking task. Furthermore, these detection
architectures can be implemented as backbones for visual tracking systems,
thereby enabling persistent tracking of UAV incursions. To date, no
comprehensive performance benchmark exists that applies DNNs to visible-band
imagery for UAV detection and tracking. To this end, three datasets with varied
environmental conditions for UAV detection and tracking, comprising a total of
241 videos (331,486 images), are assessed using four detection architectures
and three tracking frameworks. The best performing detector architecture
obtains an mAP of 98.6% and the best performing tracking framework obtains a
MOTA of 96.3%. Cross-modality evaluation is carried out between visible and
infrared spectrums, achieving a maximal 82.8% mAP on visible images when
training in the infrared modality. These results provide the first public
multi-approach benchmark for state-of-the-art deep learning-based methods and
give insight into which detection and tracking architectures are effective in
the UAV domain.",arxiv
http://arxiv.org/abs/2004.09864v1,2020-04-21T09:42:03Z,2020-04-21T09:42:03Z,"Reinforcement Learning to Optimize the Logistics Distribution Routes of
  Unmanned Aerial Vehicle","Path planning methods for the unmanned aerial vehicle (UAV) in goods delivery
have drawn great attention from industry and academics because of its
flexibility which is suitable for many situations in the ""Last Kilometer""
between customer and delivery nodes. However, the complicated situation is
still a problem for traditional combinatorial optimization methods. Based on
the state-of-the-art Reinforcement Learning (RL), this paper proposed an
improved method to achieve path planning for UAVs in complex surroundings:
multiple no-fly zones. The improved approach leverages the attention mechanism
and includes the embedding mechanism as the encoder and three different widths
of beam search (i.e.,~1, 5, and 10) as the decoders. Policy gradients are
utilized to train the RL model for obtaining the optimal strategies during
inference. The results show the feasibility and efficiency of the model
applying in this kind of complicated situation. Comparing the model with the
results obtained by the optimization solver OR-tools, it improves the
reliability of the distribution system and has a guiding significance for the
broad application of UAVs.",arxiv
http://arxiv.org/abs/2011.13744v1,2020-11-27T14:16:55Z,2020-11-27T14:16:55Z,"Reinforcement Learning-based Joint Path and Energy Optimization of
  Cellular-Connected Unmanned Aerial Vehicles","Unmanned Aerial Vehicles (UAVs) have attracted considerable research interest
recently. Especially when it comes to the realm of Internet of Things, the UAVs
with Internet connectivity are one of the main demands. Furthermore, the energy
constraint i.e. battery limit is a bottle-neck of the UAVs that can limit their
applications. We try to address and solve the energy problem. Therefore, a path
planning method for a cellular-connected UAV is proposed that will enable the
UAV to plan its path in an area much larger than its battery range by getting
recharged in certain positions equipped with power stations (PSs). In addition
to the energy constraint, there are also no-fly zones; for example, due to Air
to Air (A2A) and Air to Ground (A2G) interference or for lack of necessary
connectivity that impose extra constraints in the trajectory optimization of
the UAV. No-fly zones determine the infeasible areas that should be avoided. We
have used a reinforcement learning (RL) hierarchically to extend typical
short-range path planners to consider battery recharge and solve the problem of
UAVs in long missions. The problem is simulated for the UAV that flies over a
large area, and Q-learning algorithm could enable the UAV to find the optimal
path and recharge policy.",arxiv
http://arxiv.org/abs/1801.09339v1,2018-01-29T01:41:55Z,2018-01-29T01:41:55Z,"Liquid State Machine Learning for Resource and Cache Management in LTE-U
  Unmanned Aerial Vehicle (UAV) Networks","In this paper, the problem of joint caching and resource allocation is
investigated for a network of cache-enabled unmanned aerial vehicles (UAVs)
that service wireless ground users over the LTE licensed and unlicensed (LTE-U)
bands. The considered model focuses on users that can access both licensed and
unlicensed bands while receiving contents from either the cache units at the
UAVs directly or via content server-UAV-user links. This problem is formulated
as an optimization problem which jointly incorporates user association,
spectrum allocation, and content caching. To solve this problem, a distributed
algorithm based on the machine learning framework of liquid state machine (LSM)
is proposed. Using the proposed LSM algorithm, the cloud can predict the users'
content request distribution while having only limited information on the
network's and users' states. The proposed algorithm also enables the UAVs to
autonomously choose the optimal resource allocation strategies that maximize
the number of users with stable queues depending on the network states. Based
on the users' association and content request distributions, the optimal
contents that need to be cached at UAVs as well as the optimal resource
allocation are derived. Simulation results using real datasets show that the
proposed approach yields up to 33.3% and 50.3% gains, respectively, in terms of
the number of users that have stable queues compared to two baseline
algorithms: Q-learning with cache and Q-learning without cache. The results
also show that LSM significantly improves the convergence time of up to 33.3%
compared to conventional learning algorithms such as Q-learning.",arxiv
http://arxiv.org/abs/2009.11799v1,2020-09-24T16:42:56Z,2020-09-24T16:42:56Z,"Motion Planning by Reinforcement Learning for an Unmanned Aerial Vehicle
  in Virtual Open Space with Static Obstacles","In this study, we applied reinforcement learning based on the proximal policy
optimization algorithm to perform motion planning for an unmanned aerial
vehicle (UAV) in an open space with static obstacles. The application of
reinforcement learning through a real UAV has several limitations such as time
and cost; thus, we used the Gazebo simulator to train a virtual quadrotor UAV
in a virtual environment. As the reinforcement learning progressed, the mean
reward and goal rate of the model were increased. Furthermore, the test of the
trained model shows that the UAV reaches the goal with an 81% goal rate using
the simple reward function suggested in this work.",arxiv
http://arxiv.org/abs/1903.09021v1,2019-03-21T14:21:11Z,2019-03-21T14:21:11Z,"Localization of Unmanned Aerial Vehicles in Corridor Environments using
  Deep Learning","Vision-based pose estimation of Unmanned Aerial Vehicles (UAV) in unknown
environments is a rapidly growing research area in the field of robot vision.
The task becomes more complex when the only available sensor is a static single
camera (monocular vision). In this regard, we propose a monocular vision
assisted localization algorithm, that will help a UAV to navigate safely in
indoor corridor environments. Always, the aim is to navigate the UAV through a
corridor in the forward direction by keeping it at the center with no
orientation either to the left or right side. The algorithm makes use of the
RGB image, captured from the UAV front camera, and passes it through a trained
deep neural network (DNN) to predict the position of the UAV as either on the
left or center or right side of the corridor. Depending upon the divergence of
the UAV with respect to the central bisector line (CBL) of the corridor, a
suitable command is generated to bring the UAV to the center. When the UAV is
at the center of the corridor, a new image is passed through another trained
DNN to predict the orientation of the UAV with respect to the CBL of the
corridor. If the UAV is either left or right tilted, an appropriate command is
generated to rectify the orientation. We also propose a new corridor dataset,
named NITRCorrV1, which contains images as captured by the UAV front camera
when the UAV is at all possible locations of a variety of corridors. An
exhaustive set of experiments in different corridors reveal the efficacy of the
proposed algorithm.",arxiv
http://arxiv.org/abs/2109.04865v1,2021-09-10T13:22:21Z,2021-09-10T13:22:21Z,Emerging AI Security Threats for Autonomous Cars -- Case Studies,"Artificial Intelligence has made a significant contribution to autonomous
vehicles, from object detection to path planning. However, AI models require a
large amount of sensitive training data and are usually computationally
intensive to build. The commercial value of such models motivates attackers to
mount various attacks. Adversaries can launch model extraction attacks for
monetization purposes or step-ping-stone towards other attacks like model
evasion. In specific cases, it even results in destroying brand reputation,
differentiation, and value proposition. In addition, IP laws and AI-related
legalities are still evolving and are not uniform across countries. We discuss
model extraction attacks in detail with two use-cases and a generic kill-chain
that can compromise autonomous cars. It is essential to investigate strategies
to manage and mitigate the risk of model theft.",arxiv
http://arxiv.org/abs/1712.08644v4,2018-07-30T02:29:01Z,2017-12-19T22:24:08Z,DeepPicar: A Low-cost Deep Neural Network-based Autonomous Car,"We present DeepPicar, a low-cost deep neural network based autonomous car
platform. DeepPicar is a small scale replication of a real self-driving car
called DAVE-2 by NVIDIA. DAVE-2 uses a deep convolutional neural network (CNN),
which takes images from a front-facing camera as input and produces car
steering angles as output. DeepPicar uses the same network architecture---9
layers, 27 million connections and 250K parameters---and can drive itself in
real-time using a web camera and a Raspberry Pi 3 quad-core platform. Using
DeepPicar, we analyze the Pi 3's computing capabilities to support end-to-end
deep learning based real-time control of autonomous vehicles. We also
systematically compare other contemporary embedded computing platforms using
the DeepPicar's CNN-based real-time control workload. We find that all tested
platforms, including the Pi 3, are capable of supporting the CNN-based
real-time control, from 20 Hz up to 100 Hz, depending on hardware platform.
However, we find that shared resource contention remains an important issue
that must be considered in applying CNN models on shared memory based embedded
computing platforms; we observe up to 11.6X execution time increase in the CNN
based control loop due to shared resource contention. To protect the CNN
workload, we also evaluate state-of-the-art cache partitioning and memory
bandwidth throttling techniques on the Pi 3. We find that cache partitioning is
ineffective, while memory bandwidth throttling is an effective solution.",arxiv
http://arxiv.org/abs/1708.08559v2,2018-03-20T06:10:24Z,2017-08-28T23:26:14Z,"DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous
  Cars","Recent advances in Deep Neural Networks (DNNs) have led to the development of
DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can
drive without any human intervention. Most major manufacturers including Tesla,
GM, Ford, BMW, and Waymo/Google are working on building and testing different
types of autonomous vehicles. The lawmakers of several US states including
California, Texas, and New York have passed new legislation to fast-track the
process of testing and deployment of autonomous vehicles on their roads.
  However, despite their spectacular progress, DNNs, just like traditional
software, often demonstrate incorrect or unexpected corner case behaviors that
can lead to potentially fatal collisions. Several such real-world accidents
involving autonomous cars have already happened including one which resulted in
a fatality. Most existing testing techniques for DNN-driven vehicles are
heavily dependent on the manual collection of test data under different driving
conditions which become prohibitively expensive as the number of test
conditions increases.
  In this paper, we design, implement and evaluate DeepTest, a systematic
testing tool for automatically detecting erroneous behaviors of DNN-driven
vehicles that can potentially lead to fatal crashes. First, our tool is
designed to automatically generated test cases leveraging real-world changes in
driving conditions like rain, fog, lighting conditions, etc. DeepTest
systematically explores different parts of the DNN logic by generating test
inputs that maximize the numbers of activated neurons. DeepTest found thousands
of erroneous behaviors under different realistic driving conditions (e.g.,
blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in
three top performing DNNs in the Udacity self-driving car challenge.",arxiv
http://arxiv.org/abs/2107.08325v1,2021-07-18T00:00:48Z,2021-07-18T00:00:48Z,"Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement
  Learning","Autonomous car racing is a challenging task in the robotic control area.
Traditional modular methods require accurate mapping, localization and
planning, which makes them computationally inefficient and sensitive to
environmental changes. Recently, deep-learning-based end-to-end systems have
shown promising results for autonomous driving/racing. However, they are
commonly implemented by supervised imitation learning (IL), which suffers from
the distribution mismatch problem, or by reinforcement learning (RL), which
requires a huge amount of risky interaction data. In this work, we present a
general deep imitative reinforcement learning approach (DIRL), which
successfully achieves agile autonomous racing using visual inputs. The driving
knowledge is acquired from both IL and model-based RL, where the agent can
learn from human teachers as well as perform self-improvement by safely
interacting with an offline world model. We validate our algorithm both in a
high-fidelity driving simulation and on a real-world 1/20-scale RC-car with
limited onboard computation. The evaluation results demonstrate that our method
outperforms previous IL and RL methods in terms of sample efficiency and task
performance. Demonstration videos are available at
https://caipeide.github.io/autorace-dirl/",arxiv
http://arxiv.org/abs/1901.00569v1,2019-01-03T01:05:29Z,2019-01-03T01:05:29Z,"Human-Like Autonomous Car-Following Model with Deep Reinforcement
  Learning","This study proposes a framework for human-like autonomous car-following
planning based on deep reinforcement learning (deep RL). Historical driving
data are fed into a simulation environment where an RL agent learns from trial
and error interactions based on a reward function that signals how much the
agent deviates from the empirical data. Through these interactions, an optimal
policy, or car-following model that maps in a human-like way from speed,
relative speed between a lead and following vehicle, and inter-vehicle spacing
to acceleration of a following vehicle is finally obtained. The model can be
continuously updated when more data are fed in. Two thousand car-following
periods extracted from the 2015 Shanghai Naturalistic Driving Study were used
to train the model and compare its performance with that of traditional and
recent data-driven car-following models. As shown by this study results, a deep
deterministic policy gradient car-following model that uses disparity between
simulated and observed speed as the reward function and considers a reaction
delay of 1s, denoted as DDPGvRT, can reproduce human-like car-following
behavior with higher accuracy than traditional and recent data-driven
car-following models. Specifically, the DDPGvRT model has a spacing validation
error of 18% and speed validation error of 5%, which are less than those of
other models, including the intelligent driver model, models based on locally
weighted regression, and conventional neural network-based models. Moreover,
the DDPGvRT demonstrates good capability of generalization to various driving
situations and can adapt to different drivers by continuously learning. This
study demonstrates that reinforcement learning methodology can offer insight
into driver behavior and can contribute to the development of human-like
autonomous driving algorithms and traffic-flow models.",arxiv
http://arxiv.org/abs/1803.07015v2,2018-03-22T17:57:00Z,2018-03-19T16:15:22Z,"Live Target Detection with Deep Learning Neural Network and Unmanned
  Aerial Vehicle on Android Mobile Device","This paper describes the stages faced during the development of an Android
program which obtains and decodes live images from DJI Phantom 3 Professional
Drone and implements certain features of the TensorFlow Android Camera Demo
application. Test runs were made and outputs of the application were noted. A
lake was classified as seashore, breakwater and pier with the proximities of
24.44%, 21.16% and 12.96% respectfully. The joystick of the UAV controller and
laptop keyboard was classified with the proximities of 19.10% and 13.96%
respectfully. The laptop monitor was classified as screen, monitor and
television with the proximities of 18.77%, 14.76% and 14.00% respectfully. The
computer used during the development of this study was classified as notebook
and laptop with the proximities of 20.04% and 11.68% respectfully. A tractor
parked at a parking lot was classified with the proximity of 12.88%. A group of
cars in the same parking lot were classified as sports car, racer and
convertible with the proximities of 31.75%, 18.64% and 13.45% respectfully at
an inference time of 851ms.",arxiv
http://arxiv.org/abs/1804.05111v2,2020-06-28T06:36:07Z,2018-04-13T20:37:46Z,"Multi-Sound-Source Localization Using Machine Learning for Small
  Autonomous Unmanned Vehicles with a Self-Rotating Bi-Microphone Array","Abstract While vision-based localization techniques have been widely studied
for small autonomous unmanned vehicles (SAUVs), sound-source localization
capabilities have not been fully enabled for SAUVs. This paper presents two
novel approaches for SAUVs to perform three-dimensional (3D)
multi-sound-sources localization (MSSL) using only the inter-channel time
difference (ICTD) signal generated by a self-rotating bi-microphone array. The
proposed two approaches are based on two machine learning techniques viz.,
Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Random
Sample Consensus (RANSAC) algorithms, respectively, whose performances are
tested and compared in both simulations and experiments. The results show that
both approaches are capable of correctly identifying the number of sound
sources along with their 3D orientations in a reverberant environment.",arxiv
http://arxiv.org/abs/1906.11886v1,2019-06-04T18:05:25Z,2019-06-04T18:05:25Z,"Traffic Light Recognition Using Deep Learning and Prior Maps for
  Autonomous Cars","Autonomous terrestrial vehicles must be capable of perceiving traffic lights
and recognizing their current states to share the streets with human drivers.
Most of the time, human drivers can easily identify the relevant traffic
lights. To deal with this issue, a common solution for autonomous cars is to
integrate recognition with prior maps. However, additional solution is required
for the detection and recognition of the traffic light. Deep learning
techniques have showed great performance and power of generalization including
traffic related problems. Motivated by the advances in deep learning, some
recent works leveraged some state-of-the-art deep detectors to locate (and
further recognize) traffic lights from 2D camera images. However, none of them
combine the power of the deep learning-based detectors with prior maps to
recognize the state of the relevant traffic lights. Based on that, this work
proposes to integrate the power of deep learning-based detection with the prior
maps used by our car platform IARA (acronym for Intelligent Autonomous Robotic
Automobile) to recognize the relevant traffic lights of predefined routes. The
process is divided in two phases: an offline phase for map construction and
traffic lights annotation; and an online phase for traffic light recognition
and identification of the relevant ones. The proposed system was evaluated on
five test cases (routes) in the city of Vit\'oria, each case being composed of
a video sequence and a prior map with the relevant traffic lights for the
route. Results showed that the proposed technique is able to correctly identify
the relevant traffic light along the trajectory.",arxiv
http://arxiv.org/abs/2009.09647v1,2020-09-21T07:12:07Z,2020-09-21T07:12:07Z,"Reinforced Edge Selection using Deep Learning for Robust Surveillance in
  Unmanned Aerial Vehicles","In this paper, we propose a novel deep Q-network (DQN)-based edge selection
algorithm designed specifically for real-time surveillance in unmanned aerial
vehicle (UAV) networks. The proposed algorithm is designed under the
consideration of delay, energy, and overflow as optimizations to ensure
real-time properties while striking a balance for other environment-related
parameters. The merit of the proposed algorithm is verified via
simulation-based performance evaluation.",arxiv
http://arxiv.org/abs/2105.04430v1,2021-05-10T14:41:03Z,2021-05-10T14:41:03Z,"An Enhanced Randomly Initialized Convolutional Neural Network for
  Columnar Cactus Recognition in Unmanned Aerial Vehicle Imagery","Recently, Convolutional Neural Networks (CNNs) have made a great performance
for remote sensing image classification. Plant recognition using CNNs is one of
the active deep learning research topics due to its added-value in different
related fields, especially environmental conservation and natural areas
preservation. Automatic recognition of plants in protected areas helps in the
surveillance process of these zones and ensures the sustainability of their
ecosystems. In this work, we propose an Enhanced Randomly Initialized
Convolutional Neural Network (ERI-CNN) for the recognition of columnar cactus,
which is an endemic plant that exists in the Tehuac\'an-Cuicatl\'an Valley in
southeastern Mexico. We used a public dataset created by a group of researchers
that consists of more than 20000 remote sensing images. The experimental
results confirm the effectiveness of the proposed model compared to other
models reported in the literature like InceptionV3 and the modified LeNet-5
CNN. Our ERI-CNN provides 98% of accuracy, 97% of precision, 97% of recall,
97.5% as f1-score, and 0.056 loss.",arxiv
http://arxiv.org/abs/2001.11231v1,2020-01-30T09:47:22Z,2020-01-30T09:47:22Z,"Survey of Deep Reinforcement Learning for Motion Planning of Autonomous
  Vehicles","Academic research in the field of autonomous vehicles has reached high
popularity in recent years related to several topics as sensor technologies,
V2X communications, safety, security, decision making, control, and even legal
and standardization rules. Besides classic control design approaches,
Artificial Intelligence and Machine Learning methods are present in almost all
of these fields. Another part of research focuses on different layers of Motion
Planning, such as strategic decisions, trajectory planning, and control. A wide
range of techniques in Machine Learning itself have been developed, and this
article describes one of these fields, Deep Reinforcement Learning (DRL). The
paper provides insight into the hierarchical motion planning problem and
describes the basics of DRL. The main elements of designing such a system are
the modeling of the environment, the modeling abstractions, the description of
the state and the perception models, the appropriate rewarding, and the
realization of the underlying neural network. The paper describes vehicle
models, simulation possibilities and computational requirements. Strategic
decisions on different layers and the observation models, e.g., continuous and
discrete state representations, grid-based, and camera-based solutions are
presented. The paper surveys the state-of-art solutions systematized by the
different tasks and levels of autonomous driving, such as car-following,
lane-keeping, trajectory following, merging, or driving in dense traffic.
Finally, open questions and future challenges are discussed.",arxiv
http://arxiv.org/abs/2102.02315v4,2021-09-15T05:11:29Z,2021-02-03T22:34:22Z,"Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap
  Time Simulation Using Machine Learning","Widespread development of driverless vehicles has led to the formation of
autonomous racing, where technological development is accelerated by the high
speeds and competitive environment of motorsport. A particular challenge for an
autonomous vehicle is that of identifying a target trajectory - or, in the case
of a competition vehicle, the racing line. Many existing approaches to finding
the racing line are either not time-optimal solutions, or are computationally
expensive - rendering them unsuitable for real-time application using on-board
processing hardware. This study describes a machine learning approach to
generating an accurate prediction of the racing line in real-time on desktop
processing hardware. The proposed algorithm is a feed-forward neural network,
trained using a dataset comprising racing lines for a large number of circuits
calculated via traditional optimal control lap time simulation. The network
predicts the racing line with a mean absolute error of +/-0.27m, and just
+/-0.11m at corner apex - comparable to human drivers, and autonomous vehicle
control subsystems. The approach generates predictions within 33ms, making it
over 9,000 times faster than traditional methods of finding the optimal
trajectory. Results suggest that for certain applications data-driven
approaches to find near-optimal racing lines may be favourable to traditional
computational methods.",arxiv
http://arxiv.org/abs/2007.05156v1,2020-07-10T04:27:39Z,2020-07-10T04:27:39Z,"A Survey on Autonomous Vehicle Control in the Era of Mixed-Autonomy:
  From Physics-Based to AI-Guided Driving Policy Learning","This paper serves as an introduction and overview of the potentially useful
models and methodologies from artificial intelligence (AI) into the field of
transportation engineering for autonomous vehicle (AV) control in the era of
mixed autonomy. We will discuss state-of-the-art applications of AI-guided
methods, identify opportunities and obstacles, raise open questions, and help
suggest the building blocks and areas where AI could play a role in mixed
autonomy. We divide the stage of autonomous vehicle (AV) deployment into four
phases: the pure HVs, the HV-dominated, the AVdominated, and the pure AVs. This
paper is primarily focused on the latter three phases. It is the
first-of-its-kind survey paper to comprehensively review literature in both
transportation engineering and AI for mixed traffic modeling. Models used for
each phase are summarized, encompassing game theory, deep (reinforcement)
learning, and imitation learning. While reviewing the methodologies, we
primarily focus on the following research questions: (1) What scalable driving
policies are to control a large number of AVs in mixed traffic comprised of
human drivers and uncontrollable AVs? (2) How do we estimate human driver
behaviors? (3) How should the driving behavior of uncontrollable AVs be modeled
in the environment? (4) How are the interactions between human drivers and
autonomous vehicles characterized? Hopefully this paper will not only inspire
our transportation community to rethink the conventional models that are
developed in the data-shortage era, but also reach out to other disciplines, in
particular robotics and machine learning, to join forces towards creating a
safe and efficient mixed traffic ecosystem.",arxiv
http://arxiv.org/abs/2102.01740v1,2021-02-02T20:25:23Z,2021-02-02T20:25:23Z,"Reliability Analysis of Artificial Intelligence Systems Using Recurrent
  Events Data from Autonomous Vehicles","Artificial intelligence (AI) systems have become increasingly common and the
trend will continue. Examples of AI systems include autonomous vehicles (AV),
computer vision, natural language processing, and AI medical experts. To allow
for safe and effective deployment of AI systems, the reliability of such
systems needs to be assessed. Traditionally, reliability assessment is based on
reliability test data and the subsequent statistical modeling and analysis. The
availability of reliability data for AI systems, however, is limited because
such data are typically sensitive and proprietary. The California Department of
Motor Vehicles (DMV) oversees and regulates an AV testing program, in which
many AV manufacturers are conducting AV road tests. Manufacturers participating
in the program are required to report recurrent disengagement events to
California DMV. This information is being made available to the public. In this
paper, we use recurrent disengagement events as a representation of the
reliability of the AI system in AV, and propose a statistical framework for
modeling and analyzing the recurrent events data from AV driving tests. We use
traditional parametric models in software reliability and propose a new
nonparametric model based on monotonic splines to describe the event process.
We develop inference procedures for selecting the best models, quantifying
uncertainty, and testing heterogeneity in the event process. We then analyze
the recurrent events data from four AV manufacturers, and make inferences on
the reliability of the AI systems in AV. We also describe how the proposed
analysis can be applied to assess the reliability of other AI systems.",arxiv
http://arxiv.org/abs/1904.02697v1,2019-04-04T17:55:36Z,2019-04-04T17:55:36Z,"A Systematic Literature Review about the impact of Artificial
  Intelligence on Autonomous Vehicle Safety","Autonomous Vehicles (AV) are expected to bring considerable benefits to
society, such as traffic optimization and accidents reduction. They rely
heavily on advances in many Artificial Intelligence (AI) approaches and
techniques. However, while some researchers in this field believe AI is the
core element to enhance safety, others believe AI imposes new challenges to
assure the safety of these new AI-based systems and applications. In this
non-convergent context, this paper presents a systematic literature review to
paint a clear picture of the state of the art of the literature in AI on AV
safety. Based on an initial sample of 4870 retrieved papers, 59 studies were
selected as the result of the selection criteria detailed in the paper. The
shortlisted studies were then mapped into six categories to answer the proposed
research questions. An AV system model was proposed and applied to orient the
discussions about the SLR findings. As a main result, we have reinforced our
preliminary observation about the necessity of considering a serious safety
agenda for the future studies on AI-based AV systems.",arxiv
http://arxiv.org/abs/2009.11722v1,2020-09-23T09:23:29Z,2020-09-23T09:23:29Z,"Cloud2Edge Elastic AI Framework for Prototyping and Deployment of AI
  Inference Engines in Autonomous Vehicles","Self-driving cars and autonomous vehicles are revolutionizing the automotive
sector, shaping the future of mobility altogether. Although the integration of
novel technologies such as Artificial Intelligence (AI) and Cloud/Edge
computing provides golden opportunities to improve autonomous driving
applications, there is the need to modernize accordingly the whole prototyping
and deployment cycle of AI components. This paper proposes a novel framework
for developing so-called AI Inference Engines for autonomous driving
applications based on deep learning modules, where training tasks are deployed
elastically over both Cloud and Edge resources, with the purpose of reducing
the required network bandwidth, as well as mitigating privacy issues. Based on
our proposed data driven V-Model, we introduce a simple yet elegant solution
for the AI components development cycle, where prototyping takes place in the
cloud according to the Software-in-the-Loop (SiL) paradigm, while deployment
and evaluation on the target ECUs (Electronic Control Units) is performed as
Hardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework
is demonstrated using two real-world use-cases of AI inference engines for
autonomous vehicles, that is environment perception and most probable path
prediction.",arxiv
http://arxiv.org/abs/2107.14573v1,2021-07-30T12:11:31Z,2021-07-30T12:11:31Z,Neural Network Based Model Predictive Control for an Autonomous Vehicle,"We study learning based controllers as a replacement for model predictive
controllers (MPC) for the control of autonomous vehicles. We concentrate for
the experiments on the simple yet representative bicycle model. We compare
training by supervised learning and by reinforcement learning. We also discuss
the neural net architectures so as to obtain small nets with the best
performances. This work aims at producing controllers that can both be embedded
on real-time platforms and amenable to verification by formal methods
techniques.",arxiv
http://arxiv.org/abs/2012.01872v2,2021-05-06T02:52:49Z,2020-12-03T12:31:07Z,Towards Repairing Neural Networks Correctly,"Neural networks are increasingly applied to support decision making in
safety-critical applications (like autonomous cars, unmanned aerial vehicles
and face recognition based authentication). While many impressive static
verification techniques have been proposed to tackle the correctness problem of
neural networks, it is possible that static verification may never be
sufficiently scalable to handle real-world neural networks. In this work, we
propose a runtime verification method to ensure the correctness of neural
networks. Given a neural network and a desirable safety property, we adopt
state-of-the-art static verification techniques to identify strategically
locations to introduce additional gates which ""correct"" neural network
behaviors at runtime. Experiment results show that our approach effectively
generates neural networks which are guaranteed to satisfy the properties,
whilst being consistent with the original neural network most of the time.",arxiv
http://arxiv.org/abs/1909.12153v2,2020-03-13T08:55:20Z,2019-09-24T06:24:23Z,Controlling an Autonomous Vehicle with Deep Reinforcement Learning,"We present a control approach for autonomous vehicles based on deep
reinforcement learning. A neural network agent is trained to map its estimated
state to acceleration and steering commands given the objective of reaching a
specific target state while considering detected obstacles. Learning is
performed using state-of-the-art proximal policy optimization in combination
with a simulated environment. Training from scratch takes five to nine hours.
The resulting agent is evaluated within simulation and subsequently applied to
control a full-size research vehicle. For this, the autonomous exploration of a
parking lot is considered, including turning maneuvers and obstacle avoidance.
Altogether, this work is among the first examples to successfully apply deep
reinforcement learning to a real vehicle.",arxiv
http://arxiv.org/abs/1910.00399v1,2019-09-27T20:36:28Z,2019-09-27T20:36:28Z,Safe Reinforcement Learning on Autonomous Vehicles,"There have been numerous advances in reinforcement learning, but the
typically unconstrained exploration of the learning process prevents the
adoption of these methods in many safety critical applications. Recent work in
safe reinforcement learning uses idealized models to achieve their guarantees,
but these models do not easily accommodate the stochasticity or
high-dimensionality of real world systems. We investigate how prediction
provides a general and intuitive framework to constraint exploration, and show
how it can be used to safely learn intersection handling behaviors on an
autonomous vehicle.",arxiv
http://arxiv.org/abs/2011.04752v1,2020-11-09T20:49:54Z,2020-11-09T20:49:54Z,"Trajectory Planning for Autonomous Vehicles Using Hierarchical
  Reinforcement Learning","Planning safe trajectories under uncertain and dynamic conditions makes the
autonomous driving problem significantly complex. Current sampling-based
methods such as Rapidly Exploring Random Trees (RRTs) are not ideal for this
problem because of the high computational cost. Supervised learning methods
such as Imitation Learning lack generalization and safety guarantees. To
address these problems and in order to ensure a robust framework, we propose a
Hierarchical Reinforcement Learning (HRL) structure combined with a
Proportional-Integral-Derivative (PID) controller for trajectory planning. HRL
helps divide the task of autonomous vehicle driving into sub-goals and supports
the network to learn policies for both high-level options and low-level
trajectory planner choices. The introduction of sub-goals decreases convergence
time and enables the policies learned to be reused for other scenarios. In
addition, the proposed planner is made robust by guaranteeing smooth
trajectories and by handling the noisy perception system of the ego-car. The
PID controller is used for tracking the waypoints, which ensures smooth
trajectories and reduces jerk. The problem of incomplete observations is
handled by using a Long-Short-Term-Memory (LSTM) layer in the network. Results
from the high-fidelity CARLA simulator indicate that the proposed method
reduces convergence time, generates smoother trajectories, and is able to
handle dynamic surroundings and noisy observations.",arxiv
http://arxiv.org/abs/1912.09630v1,2019-12-20T03:47:28Z,2019-12-20T03:47:28Z,Practical Solutions for Machine Learning Safety in Autonomous Vehicles,"Autonomous vehicles rely on machine learning to solve challenging tasks in
perception and motion planning. However, automotive software safety standards
have not fully evolved to address the challenges of machine learning safety
such as interpretability, verification, and performance limitations. In this
paper, we review and organize practical machine learning safety techniques that
can complement engineering safety for machine learning based software in
autonomous vehicles. Our organization maps safety strategies to
state-of-the-art machine learning techniques in order to enhance dependability
and safety of machine learning algorithms. We also discuss security limitations
and user experience aspects of machine learning components in autonomous
vehicles.",arxiv
http://arxiv.org/abs/1908.01094v1,2019-08-02T23:59:26Z,2019-08-02T23:59:26Z,"Requirements-driven Test Generation for Autonomous Vehicles with Machine
  Learning Components","Autonomous vehicles are complex systems that are challenging to test and
debug. A requirements-driven approach to the development process can decrease
the resources required to design and test these systems, while simultaneously
increasing the reliability. We present a testing framework that uses signal
temporal logic (STL), which is a precise and unambiguous requirements language.
Our framework evaluates test cases against the STL formulae and additionally
uses the requirements to automatically identify test cases that fail to satisfy
the requirements. One of the key features of our tool is the support for
machine learning (ML) components in the system design, such as deep neural
networks. The framework allows evaluation of the control algorithms, including
the ML components, and it also includes models of CCD camera, lidar, and radar
sensors, as well as the vehicle environment. We use multiple methods to
generate test cases, including covering arrays, which is an efficient method to
search discrete variable spaces. The resulting test cases can be used to debug
the controller design by identifying controller behaviors that do not satisfy
requirements. The test cases can also enhance the testing phase of development
by identifying critical corner cases that correspond to the limits of the
system's allowed behaviors. We present STL requirements for an autonomous
vehicle system, which capture both component-level and system-level behaviors.
Additionally, we present three driving scenarios and demonstrate how our
requirements-driven testing framework can be used to identify critical system
behaviors, which can be used to support the development process.",arxiv
http://arxiv.org/abs/2007.02219v2,2021-08-17T01:20:46Z,2020-07-05T00:59:24Z,"Deep Neural Networks with Koopman Operators for Modeling and Control of
  Autonomous Vehicles","Autonomous driving technologies have received notable attention in the past
decades. In autonomous driving systems, identifying a precise dynamical model
for motion control is nontrivial due to the strong nonlinearity and uncertainty
in vehicle dynamics. Recent efforts have resorted to machine learning
techniques for building vehicle dynamical models, but the generalization
ability and interpretability of existing methods still need to be improved. In
this paper, we propose a data-driven vehicle modeling approach based on deep
neural networks with an interpretable Koopman operator. The main advantage of
using the Koopman operator is to represent the nonlinear dynamics in a linear
lifted feature space. In the proposed approach, a deep learning-based extended
dynamic mode decomposition algorithm is presented to learn a finite-dimensional
approximation of the Koopman operator. Furthermore, a data-driven model
predictive controller with the learned Koopman model is designed for path
tracking control of autonomous vehicles. Simulation results in a high-fidelity
CarSim environment show that our approach exhibit a high modeling precision at
a wide operating range and outperforms previously developed methods in terms of
modeling performance. Path tracking tests of the autonomous vehicle are also
performed in the CarSim environment and the results show the effectiveness of
the proposed approach.",arxiv
http://arxiv.org/abs/1910.01636v2,2020-06-07T21:03:21Z,2019-10-03T17:56:18Z,"Self-supervised learning for autonomous vehicles perception: A
  conciliation between analytical and learning methods","Nowadays, supervised deep learning techniques yield the best state-of-the-art
prediction performances for a wide variety of computer vision tasks. However,
such supervised techniques generally require a large amount of manually labeled
training data. In the context of autonomous vehicles perception, this
requirement is critical, as the distribution of sensor data can continuously
change and include several unexpected variations. It turns out that a category
of learning techniques, referred to as self-supervised learning (SSL), consists
of replacing the manual labeling effort by an automatic labeling process.
Thanks to their ability to learn on the application time and in varying
environments, state-of-the-art SSL techniques provide a valid alternative to
supervised learning for a variety of different tasks, including long-range
traversable area segmentation, moving obstacle instance segmentation, long-term
moving obstacle tracking, or depth map prediction. In this tutorial-style
article, we present an overview and a general formalization of the concept of
self-supervised learning (SSL) for autonomous vehicles perception. This
formalization provides helpful guidelines for developing novel frameworks based
on generic SSL principles. Moreover, it enables to point out significant
challenges in the design of future SSL systems.",arxiv
http://arxiv.org/abs/1911.03799v1,2019-11-09T23:19:59Z,2019-11-09T23:19:59Z,"Hierarchical Reinforcement Learning Method for Autonomous Vehicle
  Behavior Planning","In this work, we propose a hierarchical reinforcement learning (HRL)
structure which is capable of performing autonomous vehicle planning tasks in
simulated environments with multiple sub-goals. In this hierarchical structure,
the network is capable of 1) learning one task with multiple sub-goals
simultaneously; 2) extracting attentions of states according to changing
sub-goals during the learning process; 3) reusing the well-trained network of
sub-goals for other similar tasks with the same sub-goals. The states are
defined as processed observations which are transmitted from the perception
system of the autonomous vehicle. A hybrid reward mechanism is designed for
different hierarchical layers in the proposed HRL structure. Compared to
traditional RL methods, our algorithm is more sample-efficient since its
modular design allows reusing the policies of sub-goals across similar tasks.
The results show that the proposed method converges to an optimal policy faster
than traditional RL methods.",arxiv
http://arxiv.org/abs/2003.01303v1,2020-03-03T02:53:30Z,2020-03-03T02:53:30Z,"Safe Reinforcement Learning for Autonomous Vehicles through Parallel
  Constrained Policy Optimization","Reinforcement learning (RL) is attracting increasing interests in autonomous
driving due to its potential to solve complex classification and control
problems. However, existing RL algorithms are rarely applied to real vehicles
for two predominant problems: behaviours are unexplainable, and they cannot
guarantee safety under new scenarios. This paper presents a safe RL algorithm,
called Parallel Constrained Policy Optimization (PCPO), for two autonomous
driving tasks. PCPO extends today's common actor-critic architecture to a
three-component learning framework, in which three neural networks are used to
approximate the policy function, value function and a newly added risk
function, respectively. Meanwhile, a trust region constraint is added to allow
large update steps without breaking the monotonic improvement condition. To
ensure the feasibility of safety constrained problems, synchronized parallel
learners are employed to explore different state spaces, which accelerates
learning and policy-update. The simulations of two scenarios for autonomous
vehicles confirm we can ensure safety while achieving fast learning.",arxiv
http://arxiv.org/abs/2008.13474v1,2020-08-31T10:34:05Z,2020-08-31T10:34:05Z,"A Cost-Effective Person-Following System for Assistive Unmanned Vehicles
  with Deep Learning at the Edge","The vital statistics of the last century highlight a sharp increment of the
average age of the world population with a consequent growth of the number of
older people. Service robotics applications have the potentiality to provide
systems and tools to support the autonomous and self-sufficient older adults in
their houses in everyday life, thereby avoiding the task of monitoring them
with third parties. In this context, we propose a cost-effective modular
solution to detect and follow a person in an indoor, domestic environment. We
exploited the latest advancements in deep learning optimization techniques, and
we compared different neural network accelerators to provide a robust and
flexible person-following system at the edge. Our proposed cost-effective and
power-efficient solution is fully-integrable with pre-existing navigation
stacks and creates the foundations for the development of fully-autonomous and
self-contained service robotics applications.",arxiv
http://arxiv.org/abs/2107.03600v1,2021-07-08T04:39:35Z,2021-07-08T04:39:35Z,"Reinforcement Learning based Negotiation-aware Motion Planning of
  Autonomous Vehicles","For autonomous vehicles integrating onto roadways with human traffic
participants, it requires understanding and adapting to the participants'
intention and driving styles by responding in predictable ways without explicit
communication. This paper proposes a reinforcement learning based
negotiation-aware motion planning framework, which adopts RL to adjust the
driving style of the planner by dynamically modifying the prediction horizon
length of the motion planner in real time adaptively w.r.t the event of a
change in environment, typically triggered by traffic participants' switch of
intents with different driving styles. The framework models the interaction
between the autonomous vehicle and other traffic participants as a Markov
Decision Process. A temporal sequence of occupancy grid maps are taken as
inputs for RL module to embed an implicit intention reasoning. Curriculum
learning is employed to enhance the training efficiency and the robustness of
the algorithm. We applied our method to narrow lane navigation in both
simulation and real world to demonstrate that the proposed method outperforms
the common alternative due to its advantage in alleviating the social dilemma
problem with proper negotiation skills.",arxiv
http://arxiv.org/abs/1807.02187v2,2018-10-03T13:50:07Z,2018-07-05T21:44:39Z,"Encoding Motion Primitives for Autonomous Vehicles using Virtual
  Velocity Constraints and Neural Network Scheduling","Within the context of trajectory planning for autonomous vehicles this paper
proposes methods for efficient encoding of motion primitives in neural networks
on top of model-based and gradient-free reinforcement learning. It is
distinguished between 5 core aspects: system model, network architecture,
training algorithm, training tasks selection and hardware/software
implementation. For the system model, a kinematic (3-states-2-controls) and a
dynamic (16-states-2-controls) vehicle model are compared. For the network
architecture, 3 feedforward structures are compared including weighted skip
connections. For the training algorithm, virtual velocity constraints and
network scheduling are proposed. For the training tasks, different feature
vector selections are discussed. For the implementation, aspects of
gradient-free learning using 1 GPU and the handling of perturbation noise
therefore are discussed. The effects of proposed methods are illustrated in
experiments encoding up to 14625 motion primitives. The capabilities of tiny
neural networks with as few as 10 scalar parameters when scheduled on vehicle
velocity are emphasized.",arxiv
http://arxiv.org/abs/1905.12762v1,2019-05-29T22:44:17Z,2019-05-29T22:44:17Z,"Securing Connected & Autonomous Vehicles: Challenges Posed by
  Adversarial Machine Learning and The Way Forward","Connected and autonomous vehicles (CAVs) will form the backbone of future
next-generation intelligent transportation systems (ITS) providing travel
comfort, road safety, along with a number of value-added services. Such a
transformation---which will be fuelled by concomitant advances in technologies
for machine learning (ML) and wireless communications---will enable a future
vehicular ecosystem that is better featured and more efficient. However, there
are lurking security problems related to the use of ML in such a critical
setting where an incorrect ML decision may not only be a nuisance but can lead
to loss of precious lives. In this paper, we present an in-depth overview of
the various challenges associated with the application of ML in vehicular
networks. In addition, we formulate the ML pipeline of CAVs and present various
potential security issues associated with the adoption of ML methods. In
particular, we focus on the perspective of adversarial ML attacks on CAVs and
outline a solution to defend against adversarial attacks in multiple settings.",arxiv
http://arxiv.org/abs/2012.01010v1,2020-12-02T08:01:53Z,2020-12-02T08:01:53Z,"Driving-Policy Adaptive Safeguard for Autonomous Vehicles Using
  Reinforcement Learning","Safeguard functions such as those provided by advanced emergency braking
(AEB) can provide another layer of safety for autonomous vehicles (AV). A smart
safeguard function should adapt the activation conditions to the driving
policy, to avoid unnecessary interventions as well as improve vehicle safety.
This paper proposes a driving-policy adaptive safeguard (DPAS) design,
including a collision avoidance strategy and an activation function. The
collision avoidance strategy is designed in a reinforcement learning framework,
obtained by Monte-Carlo Tree Search (MCTS). It can learn from past collisions
and manipulate both braking and steering in stochastic traffics. The
driving-policy adaptive activation function should dynamically assess current
driving policy risk and kick in when an urgent threat is detected. To generate
this activation function, MCTS' exploration and rollout modules are designed to
fully evaluate the AV's current driving policy, and then explore other safer
actions. In this study, the DPAS is validated with two typical highway-driving
policies. The results are obtained through and 90,000 times in the stochastic
and aggressive simulated traffic. The results are calibrated by naturalistic
driving data and show that the proposed safeguard reduces the collision rate
significantly without introducing more interventions, compared with the
state-based benchmark safeguards. In summary, the proposed safeguard leverages
the learning-based method in stochastic and emergent scenarios and imposes
minimal influence on the driving policy.",arxiv
http://arxiv.org/abs/2108.01125v1,2021-08-02T19:00:20Z,2021-08-02T19:00:20Z,"Hybrid Classical-Quantum Deep Learning Models for Autonomous Vehicle
  Traffic Image Classification Under Adversarial Attack","Image classification must work for autonomous vehicles (AV) operating on
public roads, and actions performed based on image misclassification can have
serious consequences. Traffic sign images can be misclassified by an
adversarial attack on machine learning models used by AVs for traffic sign
recognition. To make classification models resilient against adversarial
attacks, we used a hybrid deep-learning model with both the quantum and
classical layers. Our goal is to study the hybrid deep-learning architecture
for classical-quantum transfer learning models to support the current era of
intermediate-scale quantum technology. We have evaluated the impacts of various
white box adversarial attacks on these hybrid models. The classical part of
hybrid models includes a convolution network from the pre-trained Resnet18
model, which extracts informative features from a high dimensional LISA traffic
sign image dataset. The output from the classical processor is processed
further through the quantum layer, which is composed of various quantum gates
and provides support to various quantum mechanical features like entanglement
and superposition. We have tested multiple combinations of quantum circuits to
provide better classification accuracy with decreasing training data and found
better resiliency for our hybrid classical-quantum deep learning model during
attacks compared to the classical-only machine learning models.",arxiv
http://arxiv.org/abs/1710.02913v2,2019-06-30T02:21:28Z,2017-10-09T02:33:43Z,"Artificial Neural Networks-Based Machine Learning for Wireless Networks:
  A Tutorial","Next-generation wireless networks must support ultra-reliable, low-latency
communication and intelligently manage a massive number of Internet of Things
(IoT) devices in real-time, within a highly dynamic environment. This need for
stringent communication quality-of-service (QoS) requirements as well as mobile
edge and core intelligence can only be realized by integrating fundamental
notions of artificial intelligence (AI) and machine learning across the
wireless infrastructure and end-user devices. In this context, this paper
provides a comprehensive tutorial that introduces the main concepts of machine
learning, in general, and artificial neural networks (ANNs), in particular, and
their potential applications in wireless communications. For this purpose, we
present a comprehensive overview on a number of key types of neural networks
that include feed-forward, recurrent, spiking, and deep neural networks. For
each type of neural network, we present the basic architecture and training
procedure, as well as the associated challenges and opportunities. Then, we
provide an in-depth overview on the variety of wireless communication problems
that can be addressed using ANNs, ranging from communication using unmanned
aerial vehicles to virtual reality and edge caching.For each individual
application, we present the main motivation for using ANNs along with the
associated challenges while also providing a detailed example for a use case
scenario and outlining future works that can be addressed using ANNs. In a
nutshell, this article constitutes one of the first holistic tutorials on the
development of machine learning techniques tailored to the needs of future
wireless networks.",arxiv
http://arxiv.org/abs/1809.00251v3,2019-09-14T21:40:42Z,2018-09-01T21:00:58Z,"Car Monitoring System in Apartment Garages by Small Autonomous Car using
  Deep Learning","Currently, there is an increase in the number of Peruvian families living in
apartments instead of houses for the lots of advantage; However, in some cases
there are troubles such as robberies of goods that are usually left at the
parking lots or the entrance of strangers that use the tenants parking lots
(this last trouble sometimes is related to kidnappings or robberies in building
apartments). Due to these problems, the use of a self-driving mini-car is
proposed to implement a monitoring system of license plates in an underground
garage inside a building using a deep learning model with the aim of recording
the vehicles and identifying their owners if they were tenants or not. In
addition, the small robot has its own location system using beacons that allow
us to identify the position of the parking lot corresponding to each tenant of
the building while the mini-car is on its way. Finally, one of the objectives
of this work is to build a low-cost mini-robot that would replace expensive
cameras or work together in order to keep safe the goods of tenants.",arxiv
http://arxiv.org/abs/1912.00805v1,2019-11-28T16:54:36Z,2019-11-28T16:54:36Z,"Comparing Offline and Online Testing of Deep Neural Networks: An
  Autonomous Car Case Study","There is a growing body of research on developing testing techniques for Deep
Neural Networks (DNN). We distinguish two general modes of testing for DNNs:
Offline testing where DNNs are tested as individual units based on test
datasets obtained independently from the DNNs under test, and online testing
where DNNs are embedded into a specific application and tested in a close-loop
mode in interaction with the application environment. In addition, we identify
two sources for generating test datasets for DNNs: Datasets obtained from
real-life and datasets generated by simulators. While offline testing can be
used with datasets obtained from either sources, online testing is largely
confined to using simulators since online testing within real-life applications
can be time-consuming, expensive and dangerous. In this paper, we study the
following two important questions aiming to compare test datasets and testing
modes for DNNs: First, can we use simulator-generated data as a reliable
substitute to real-world data for the purpose of DNN testing? Second, how do
online and offline testing results differ and complement each other? Though
these questions are generally relevant to all autonomous systems, we study them
in the context of automated driving systems where, as study subjects, we use
DNNs automating end-to-end control of cars' steering actuators. Our results
show that simulator-generated datasets are able to yield DNN prediction errors
that are similar to those obtained by testing DNNs with real-life datasets.
Further, offline testing is more optimistic than online testing as many safety
violations identified by online testing could not be identified by offline
testing, while large prediction errors generated by offline testing always led
to severe safety violations detectable by online testing.",arxiv
http://arxiv.org/abs/2011.07699v1,2020-11-16T02:56:13Z,2020-11-16T02:56:13Z,"Efficient falsification approach for autonomous vehicle validation using
  a parameter optimisation technique based on reinforcement learning","The widescale deployment of Autonomous Vehicles (AV) appears to be imminent
despite many safety challenges that are yet to be resolved. It is well-known
that there are no universally agreed Verification and Validation (VV)
methodologies guarantee absolute safety, which is crucial for the acceptance of
this technology. The uncertainties in the behaviour of the traffic participants
and the dynamic world cause stochastic reactions in advanced autonomous
systems. The addition of ML algorithms and probabilistic techniques adds
significant complexity to the process for real-world testing when compared to
traditional methods. Most research in this area focuses on generating
challenging concrete scenarios or test cases to evaluate the system performance
by looking at the frequency distribution of extracted parameters as collected
from the real-world data. These approaches generally employ Monte-Carlo
simulation and importance sampling to generate critical cases. This paper
presents an efficient falsification method to evaluate the System Under Test.
The approach is based on a parameter optimisation problem to search for
challenging scenarios. The optimisation process aims at finding the challenging
case that has maximum return. The method applies policy-gradient reinforcement
learning algorithm to enable the learning. The riskiness of the scenario is
measured by the well established RSS safety metric, euclidean distance, and
instance of a collision. We demonstrate that by using the proposed method, we
can more efficiently search for challenging scenarios which could cause the
system to fail in order to satisfy the safety requirements.",arxiv
http://arxiv.org/abs/1903.01712v1,2019-03-05T07:46:47Z,2019-03-05T07:46:47Z,"Deep Learning Based Motion Planning For Autonomous Vehicle Using
  Spatiotemporal LSTM Network","Motion Planning, as a fundamental technology of automatic navigation for the
autonomous vehicle, is still an open challenging issue in the real-life traffic
situation and is mostly applied by the model-based approaches. However, due to
the complexity of the traffic situations and the uncertainty of the edge cases,
it is hard to devise a general motion planning system for the autonomous
vehicle. In this paper, we proposed a motion planning model based on deep
learning (named as spatiotemporal LSTM network), which is able to generate a
real-time reflection based on spatiotemporal information extraction. To be
specific, the model based on spatiotemporal LSTM network has three main
structure. Firstly, the Convolutional Long-short Term Memory (Conv-LSTM) is
used to extract hidden features through sequential image data. Then, the 3D
Convolutional Neural Network(3D-CNN) is applied to extract the spatiotemporal
information from the multi-frame feature information. Finally, the fully
connected neural networks are used to construct a control model for autonomous
vehicle steering angle. The experiments demonstrated that the proposed method
can generate a robust and accurate visual motion planning results for the
autonomous vehicle.",arxiv
http://arxiv.org/abs/2012.01403v2,2020-12-08T16:02:00Z,2020-12-02T18:52:56Z,"Empirical Study on the Software Engineering Practices in Open Source ML
  Package Repositories","Recent advances in Artificial Intelligence (AI), especially in Machine
Learning (ML), have introduced various practical applications (e.g., virtual
personal assistants and autonomous cars) that enhance the experience of
everyday users. However, modern ML technologies like Deep Learning require
considerable technical expertise and resources to develop, train and deploy
such models, making effective reuse of the ML models a necessity. Such
discovery and reuse by practitioners and researchers are being addressed by
public ML package repositories, which bundle up pre-trained models into
packages for publication. Since such repositories are a recent phenomenon,
there is no empirical data on their current state and challenges. Hence, this
paper conducts an exploratory study that analyzes the structure and contents of
two popular ML package repositories, TFHub and PyTorch Hub, comparing their
information elements (features and policies), package organization, package
manager functionalities and usage contexts against popular software package
repositories (npm, PyPI, and CRAN). Through these studies, we have identified
unique SE practices and challenges for sharing ML packages. These findings and
implications would be useful for data scientists, researchers and software
developers who intend to use these shared ML packages.",arxiv
http://arxiv.org/abs/2008.06595v1,2020-08-14T22:44:26Z,2020-08-14T22:44:26Z,"Decision-making at Unsignalized Intersection for Autonomous Vehicles:
  Left-turn Maneuver with Deep Reinforcement Learning","Decision-making module enables autonomous vehicles to reach appropriate
maneuvers in the complex urban environments, especially the intersection
situations. This work proposes a deep reinforcement learning (DRL) based
left-turn decision-making framework at unsignalized intersection for autonomous
vehicles. The objective of the studied automated vehicle is to make an
efficient and safe left-turn maneuver at a four-way unsignalized intersection.
The exploited DRL methods include deep Q-learning (DQL) and double DQL.
Simulation results indicate that the presented decision-making strategy could
efficaciously reduce the collision rate and improve transport efficiency. This
work also reveals that the constructed left-turn control structure has a great
potential to be applied in real-time.",arxiv
http://arxiv.org/abs/1907.06795v1,2019-07-16T00:12:09Z,2019-07-16T00:12:09Z,Efficient Autonomy Validation in Simulation with Adaptive Stress Testing,"During the development of autonomous systems such as driverless cars, it is
important to characterize the scenarios that are most likely to result in
failure. Adaptive Stress Testing (AST) provides a way to search for the
most-likely failure scenario as a Markov decision process (MDP). Our previous
work used a deep reinforcement learning (DRL) solver to identify likely failure
scenarios. However, the solver's use of a feed-forward neural network with a
discretized space of possible initial conditions poses two major problems.
First, the system is not treated as a black box, in that it requires analyzing
the internal state of the system, which leads to considerable implementation
complexities. Second, in order to simulate realistic settings, a new instance
of the solver needs to be run for each initial condition. Running a new solver
for each initial condition not only significantly increases the computational
complexity, but also disregards the underlying relationship between similar
initial conditions. We provide a solution to both problems by employing a
recurrent neural network that takes a set of initial conditions from a
continuous space as input. This approach enables robust and efficient detection
of failures because the solution generalizes across the entire space of initial
conditions. By simulating an instance where an autonomous car drives while a
pedestrian is crossing a road, we demonstrate the solver is now capable of
finding solutions for problems that would have previously been intractable.",arxiv
http://arxiv.org/abs/1912.10773v1,2019-12-23T12:50:32Z,2019-12-23T12:50:32Z,A Survey of Deep Learning Applications to Autonomous Vehicle Control,"Designing a controller for autonomous vehicles capable of providing adequate
performance in all driving scenarios is challenging due to the highly complex
environment and inability to test the system in the wide variety of scenarios
which it may encounter after deployment. However, deep learning methods have
shown great promise in not only providing excellent performance for complex and
non-linear control problems, but also in generalising previously learned rules
to new scenarios. For these reasons, the use of deep learning for vehicle
control is becoming increasingly popular. Although important advancements have
been achieved in this field, these works have not been fully summarised. This
paper surveys a wide range of research works reported in the literature which
aim to control a vehicle through deep learning methods. Although there exists
overlap between control and perception, the focus of this paper is on vehicle
control, rather than the wider perception problem which includes tasks such as
semantic segmentation and object detection. The paper identifies the strengths
and limitations of available deep learning methods through comparative analysis
and discusses the research challenges in terms of computation, architecture
selection, goal specification, generalisation, verification and validation, as
well as safety. Overall, this survey brings timely and topical information to a
rapidly evolving field relevant to intelligent transportation systems.",arxiv
http://arxiv.org/abs/1903.03642v1,2019-03-08T19:44:29Z,2019-03-08T19:44:29Z,"Improved Robustness and Safety for Autonomous Vehicle Control with
  Adversarial Reinforcement Learning","To improve efficiency and reduce failures in autonomous vehicles, research
has focused on developing robust and safe learning methods that take into
account disturbances in the environment. Existing literature in robust
reinforcement learning poses the learning problem as a two player game between
the autonomous system and disturbances. This paper examines two different
algorithms to solve the game, Robust Adversarial Reinforcement Learning and
Neural Fictitious Self Play, and compares performance on an autonomous driving
scenario. We extend the game formulation to a semi-competitive setting and
demonstrate that the resulting adversary better captures meaningful
disturbances that lead to better overall performance. The resulting robust
policy exhibits improved driving efficiency while effectively reducing
collision rates compared to baseline control policies produced by traditional
reinforcement learning methods.",arxiv
http://arxiv.org/abs/2005.13976v1,2020-05-22T19:00:38Z,2020-05-22T19:00:38Z,"Towards Automated Safety Coverage and Testing for Autonomous Vehicles
  with Reinforcement Learning","The kind of closed-loop verification likely to be required for autonomous
vehicle (AV) safety testing is beyond the reach of traditional test
methodologies and discrete verification. Validation puts the autonomous vehicle
system to the test in scenarios or situations that the system would likely
encounter in everyday driving after its release. These scenarios can either be
controlled directly in a physical (closed-course proving ground) or virtual
(simulation of predefined scenarios) environment, or they can arise
spontaneously during operation in the real world (open-road testing or
simulation of randomly generated scenarios).
  In AV testing, simulation serves primarily two purposes: to assist the
development of a robust autonomous vehicle and to test and validate the AV
before release. A challenge arises from the sheer number of scenario variations
that can be constructed from each of the above sources due to the high number
of variables involved (most of which are continuous). Even with continuous
variables discretized, the possible number of combinations becomes practically
infeasible to test. To overcome this challenge we propose using reinforcement
learning (RL) to generate failure examples and unexpected traffic situations
for the AV software implementation. Although reinforcement learning algorithms
have achieved notable results in games and some robotic manipulations, this
technique has not been widely scaled up to the more challenging real world
applications like autonomous driving.",arxiv
http://arxiv.org/abs/2002.05020v3,2020-10-14T16:41:24Z,2020-02-11T15:51:29Z,"AI Driven Heterogeneous MEC System with UAV Assistance for Dynamic
  Environment -- Challenges and Solutions","By taking full advantage of Computing, Communication and Caching (3C)
resources at the network edge, Mobile Edge Computing (MEC) is envisioned as one
of the key enablers for the next generation networks. However, current
fixed-location MEC architecture may not be able to make real-time decision in
dynamic environment, especially in large-scale scenarios. To address this
issue, in this paper, a Heterogeneous MEC (H-MEC) architecture is proposed,
which is composed of fixed unit, i.e., Ground Stations (GSs) as well as moving
nodes, i.e., Ground Vehicles (GVs) and Unmanned Aerial Vehicles (UAVs), all
with 3C resource enabled. The key challenges in H-MEC, i.e., mobile edge node
management, real-time decision making, user association and resource allocation
along with the possible Artificial Intelligence (AI)-based solutions are
discussed. In addition, the AI-based joint Resource schEduling (ARE) framework
with two different AI-based mechanisms, i.e., Deep neural network (DNN)-based
and deep reinforcement learning (DRL)-based architectures are proposed.
DNN-based solution with online incremental learning applies the global
optimizer and therefore has better performance than the DRL-based architecture
with online policy updating, but requires longer training time. The simulation
results are given to verify the efficiency of our proposed ARE framework.",arxiv
http://arxiv.org/abs/2001.09610v1,2020-01-27T07:37:07Z,2020-01-27T07:37:07Z,"Practical Fast Gradient Sign Attack against Mammographic Image
  Classifier","Artificial intelligence (AI) has been a topic of major research for many
years. Especially, with the emergence of deep neural network (DNN), these
studies have been tremendously successful. Today machines are capable of making
faster, more accurate decision than human. Thanks to the great development of
machine learning (ML) techniques, ML have been used many different fields such
as education, medicine, malware detection, autonomous car etc. In spite of
having this degree of interest and much successful research, ML models are
still vulnerable to adversarial attacks. Attackers can manipulate clean data in
order to fool the ML classifiers to achieve their desire target. For instance;
a benign sample can be modified as a malicious sample or a malicious one can be
altered as benign while this modification can not be recognized by human
observer. This can lead to many financial losses, or serious injuries, even
deaths. The motivation behind this paper is that we emphasize this issue and
want to raise awareness. Therefore, the security gap of mammographic image
classifier against adversarial attack is demonstrated. We use mamographic
images to train our model then evaluate our model performance in terms of
accuracy. Later on, we poison original dataset and generate adversarial samples
that missclassified by the model. We then using structural similarity index
(SSIM) analyze similarity between clean images and adversarial images. Finally,
we show how successful we are to misuse by using different poisoning factors.",arxiv
http://arxiv.org/abs/2105.13670v1,2021-05-28T08:45:37Z,2021-05-28T08:45:37Z,"Transferable Deep Reinforcement Learning Framework for Autonomous
  Vehicles with Joint Radar-Data Communications","Autonomous Vehicles (AVs) are required to operate safely and efficiently in
dynamic environments. For this, the AVs equipped with Joint
Radar-Communications (JRC) functions can enhance the driving safety by
utilizing both radar detection and data communication functions. However,
optimizing the performance of the AV system with two different functions under
uncertainty and dynamic of surrounding environments is very challenging. In
this work, we first propose an intelligent optimization framework based on the
Markov Decision Process (MDP) to help the AV make optimal decisions in
selecting JRC operation functions under the dynamic and uncertainty of the
surrounding environment. We then develop an effective learning algorithm
leveraging recent advances of deep reinforcement learning techniques to find
the optimal policy for the AV without requiring any prior information about
surrounding environment. Furthermore, to make our proposed framework more
scalable, we develop a Transfer Learning (TL) mechanism that enables the AV to
leverage valuable experiences for accelerating the training process when it
moves to a new environment. Extensive simulations show that the proposed
transferable deep reinforcement learning framework reduces the obstacle miss
detection probability by the AV up to 67% compared to other conventional deep
reinforcement learning approaches.",arxiv
http://arxiv.org/abs/2104.07557v2,2021-08-19T02:55:45Z,2021-04-15T16:11:13Z,"Decentralized Federated Learning for UAV Networks: Architecture,
  Challenges, and Opportunities","Unmanned aerial vehicles (UAVs), or say drones, are envisioned to support
extensive applications in next-generation wireless networks in both civil and
military fields. Empowering UAVs networks intelligence by artificial
intelligence (AI) especially machine learning (ML) techniques is inevitable and
appealing to enable the aforementioned applications. To solve the problems of
traditional cloud-centric ML for UAV networks such as privacy concern,
unacceptable latency, and resource burden, a distributed ML technique,
\textit(i.e.), federated learning (FL), has been recently proposed to enable
multiple UAVs to collaboratively train ML model without letting out raw data.
However, almost all existing FL paradigms are still centralized, \textit{i.e.},
a central entity is in charge of ML model aggregation and fusion over the whole
network, which could result in the issue of a single point of failure and are
inappropriate to UAV networks with both unreliable nodes and links. Thus
motivated, in this article, we propose a novel architecture called DFL-UN
(\underline{D}ecentralized \underline{F}ederated \underline{L}earning for
\underline{U}AV \underline{N}etworks), which enables FL within UAV networks
without a central entity. We also conduct a preliminary simulation study to
validate the feasibility and effectiveness of the DFL-UN architecture. Finally,
we discuss the main challenges and potential research directions in the DFL-UN.",arxiv
http://arxiv.org/abs/1911.04096v1,2019-11-11T06:18:04Z,2019-11-11T06:18:04Z,"UW-MARL: Multi-Agent Reinforcement Learning for Underwater Adaptive
  Sampling using Autonomous Vehicles","Near-real-time water-quality monitoring in uncertain environments such as
rivers, lakes, and water reservoirs of different variables is critical to
protect the aquatic life and to prevent further propagation of the potential
pollution in the water. In order to measure the physical values in a region of
interest, adaptive sampling is helpful as an energy- and time-efficient
technique since an exhaustive search of an area is not feasible with a single
vehicle. We propose an adaptive sampling algorithm using multiple autonomous
vehicles, which are well-trained, as agents, in a Multi-Agent Reinforcement
Learning (MARL) framework to make efficient sequence of decisions on the
adaptive sampling procedure. The proposed solution is evaluated using
experimental data, which is fed into a simulation framework. Experiments were
conducted in the Raritan River, Somerset and in Carnegie Lake, Princeton, NJ
during July 2019.",arxiv
http://arxiv.org/abs/2008.11852v1,2020-08-26T22:49:27Z,2020-08-26T22:49:27Z,"Decision-making for Autonomous Vehicles on Highway: Deep Reinforcement
  Learning with Continuous Action Horizon","Decision-making strategy for autonomous vehicles de-scribes a sequence of
driving maneuvers to achieve a certain navigational mission. This paper
utilizes the deep reinforcement learning (DRL) method to address the
continuous-horizon decision-making problem on the highway. First, the vehicle
kinematics and driving scenario on the freeway are introduced. The running
objective of the ego automated vehicle is to execute an efficient and smooth
policy without collision. Then, the particular algorithm named proximal policy
optimization (PPO)-enhanced DRL is illustrated. To overcome the challenges in
tardy training efficiency and sample inefficiency, this applied algorithm could
realize high learning efficiency and excellent control performance. Finally,
the PPO-DRL-based decision-making strategy is estimated from multiple
perspectives, including the optimality, learning efficiency, and adaptability.
Its potential for online application is discussed by applying it to similar
driving scenarios.",arxiv
http://arxiv.org/abs/2009.03268v2,2020-10-10T14:16:31Z,2020-09-07T17:34:01Z,"Driving Tasks Transfer in Deep Reinforcement Learning for
  Decision-making of Autonomous Vehicles","Knowledge transfer is a promising concept to achieve real-time
decision-making for autonomous vehicles. This paper constructs a transfer deep
reinforcement learning framework to transform the driving tasks in
inter-section environments. The driving missions at the un-signalized
intersection are cast into a left turn, right turn, and running straight for
automated vehicles. The goal of the autonomous ego vehicle (AEV) is to drive
through the intersection situation efficiently and safely. This objective
promotes the studied vehicle to increase its speed and avoid crashing other
vehicles. The decision-making pol-icy learned from one driving task is
transferred and evaluated in another driving mission. Simulation results reveal
that the decision-making strategies related to similar tasks are transferable.
It indicates that the presented control framework could reduce the time
consumption and realize online implementation.",arxiv
http://arxiv.org/abs/2105.14218v2,2021-06-01T03:50:52Z,2021-05-29T05:27:07Z,"A Survey of Deep Reinforcement Learning Algorithms for Motion Planning
  and Control of Autonomous Vehicles","In this survey, we systematically summarize the current literature on studies
that apply reinforcement learning (RL) to the motion planning and control of
autonomous vehicles. Many existing contributions can be attributed to the
pipeline approach, which consists of many hand-crafted modules, each with a
functionality selected for the ease of human interpretation. However, this
approach does not automatically guarantee maximal performance due to the lack
of a system-level optimization. Therefore, this paper also presents a growing
trend of work that falls into the end-to-end approach, which typically offers
better performance and smaller system scales. However, their performance also
suffers from the lack of expert data and generalization issues. Finally, the
remaining challenges applying deep RL algorithms on autonomous driving are
summarized, and future research directions are also presented to tackle these
challenges.",arxiv
http://arxiv.org/abs/2109.15266v1,2021-09-30T17:06:39Z,2021-09-30T17:06:39Z,"Modeling Interactions of Autonomous Vehicles and Pedestrians with Deep
  Multi-Agent Reinforcement Learning for Collision Avoidance","Reliable pedestrian crash avoidance mitigation (PCAM) systems are crucial
components of safe autonomous vehicles (AVs). The sequential nature of the
vehicle-pedestrian interaction, i.e., where immediate decisions of one agent
directly influence the following decisions of the other agent, is an often
neglected but important aspect. In this work, we model the corresponding
interaction sequence as a Markov decision process (MDP) that is solved by deep
reinforcement learning (DRL) algorithms to define the PCAM system's policy. The
simulated driving scenario is based on an AV acting as a DRL agent driving
along an urban street, facing a pedestrian at an unmarked crosswalk who tries
to cross. Since modeling realistic crossing behavior of the pedestrian is
challenging, we introduce two levels of intelligent pedestrian behavior: While
the baseline model follows a predefined strategy, our advanced model captures
continuous learning and the inherent uncertainty in human behavior by defining
the pedestrian as a second DRL agent, i.e., we introduce a deep multi-agent
reinforcement learning (DMARL) problem. The presented PCAM system with
different levels of intelligent pedestrian behavior is benchmarked according to
the agents' collision rate and the resulting traffic flow efficiency. In this
analysis, our focus lies on evaluating the influence of observation noise on
the decision making of the agents. The results show that the AV is able to
completely mitigate collisions under the majority of the investigated
conditions and that the DRL-based pedestrian model indeed learns a more
human-like crossing behavior.",arxiv
http://arxiv.org/abs/2004.06154v1,2020-04-13T18:53:12Z,2020-04-13T18:53:12Z,"An Efficient UAV-based Artificial Intelligence Framework for Real-Time
  Visual Tasks","Modern Unmanned Aerial Vehicles equipped with state of the art artificial
intelligence (AI) technologies are opening to a wide plethora of novel and
interesting applications. While this field received a strong impact from the
recent AI breakthroughs, most of the provided solutions either entirely rely on
commercial software or provide a weak integration interface which denies the
development of additional techniques. This leads us to propose a novel and
efficient framework for the UAV-AI joint technology. Intelligent UAV systems
encounter complex challenges to be tackled without human control. One of these
complex challenges is to be able to carry out computer vision tasks in
real-time use cases. In this paper we focus on this challenge and introduce a
multi-layer AI (MLAI) framework to allow easy integration of ad-hoc
visual-based AI applications. To show its features and its advantages, we
implemented and evaluated different modern visual-based deep learning models
for object detection, target tracking and target handover.",arxiv
http://arxiv.org/abs/2003.04371v2,2020-10-01T13:01:05Z,2020-03-09T19:15:30Z,"Behavior Planning For Connected Autonomous Vehicles Using Feedback Deep
  Reinforcement Learning","With the development of communication technologies, connected autonomous
vehicles (CAVs) can share information with each other. We propose a novel
behavior planning method for CAVs to decide actions such as whether to change
lane or keep lane based on the observation and shared information from
neighbors, and to make sure that there exist corresponding control maneuvers
such as acceleration and steering angle to guarantee the safety of each
individual autonomous vehicle. We formulate this problem as a hybrid partially
observable Markov decision process (HPOMDP) to consider objectives such as
improving traffic flow efficiency and driving comfort and safety requirements.
The discrete state transition is determined by the proposed feedback deep
Q-learning algorithm using the feedback action from an underlying controller
based on control barrier functions. The feedback deep Q-learning algorithm we
design aims to solve the critical challenge of reinforcement learning (RL) in a
physical system: guaranteeing the safety of the system while the RL is
exploring the action space to increase the reward. We prove that our method
renders a forward invariant safe set for the continuous state physical dynamic
model of the system while the RL agent is learning. In experiments, our
behavior planning method can increase traffic flow and driving comfort compared
with the intelligent driving model (IDM). We also validate that our method
maintains safety during the learning process.",arxiv
http://arxiv.org/abs/2108.08628v1,2021-08-19T11:48:27Z,2021-08-19T11:48:27Z,"A Reinforcement Learning Approach for GNSS Spoofing Attack Detection of
  Autonomous Vehicles","A resilient and robust positioning, navigation, and timing (PNT) system is a
necessity for the navigation of autonomous vehicles (AVs). Global Navigation
Satelite System (GNSS) provides satellite-based PNT services. However, a
spoofer can temper an authentic GNSS signal and could transmit wrong position
information to an AV. Therefore, a GNSS must have the capability of real-time
detection and feedback-correction of spoofing attacks related to PNT receivers,
whereby it will help the end-user (autonomous vehicle in this case) to navigate
safely if it falls into any compromises. This paper aims to develop a deep
reinforcement learning (RL)-based turn-by-turn spoofing attack detection using
low-cost in-vehicle sensor data. We have utilized Honda Driving Dataset to
create attack and non-attack datasets, develop a deep RL model, and evaluate
the performance of the RL-based attack detection model. We find that the
accuracy of the RL model ranges from 99.99% to 100%, and the recall value is
100%. However, the precision ranges from 93.44% to 100%, and the f1 score
ranges from 96.61% to 100%. Overall, the analyses reveal that the RL model is
effective in turn-by-turn spoofing attack detection.",arxiv
http://arxiv.org/abs/2107.00401v1,2021-07-01T12:20:48Z,2021-07-01T12:20:48Z,"CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous
  Cars on the Loihi Neuromorphic Research Processor","Autonomous Driving (AD) related features provide new forms of mobility that
are also beneficial for other kind of intelligent and autonomous systems like
robots, smart transportation, and smart industries. For these applications, the
decisions need to be made fast and in real-time. Moreover, in the quest for
electric mobility, this task must follow low power policy, without affecting
much the autonomy of the mean of transport or the robot. These two challenges
can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed
on a specialized neuromorphic hardware, SNNs can achieve high performance with
low latency and low power consumption. In this paper, we use an SNN connected
to an event-based camera for facing one of the key problems for AD, i.e., the
classification between cars and other objects. To consume less power than
traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The
experiments are made following an offline supervised learning rule, followed by
mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our
best experiment achieves an accuracy on offline implementation of 86%, that
drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware
implementation has maximum 0.72 ms of latency for every sample, and consumes
only 310 mW. To the best of our knowledge, this work is the first
implementation of an event-based car classifier on a Neuromorphic Chip.",arxiv
http://arxiv.org/abs/2101.11681v1,2021-01-27T20:37:33Z,2021-01-27T20:37:33Z,"Artificial Intelligence Driven UAV-NOMA-MEC in Next Generation Wireless
  Networks","Driven by the unprecedented high throughput and low latency requirements in
next-generation wireless networks, this paper introduces an artificial
intelligence (AI) enabled framework in which unmanned aerial vehicles (UAVs)
use non-orthogonal multiple access (NOMA) and mobile edge computing (MEC)
techniques to service terrestrial mobile users (MUs). The proposed framework
enables the terrestrial MUs to offload their computational tasks
simultaneously, intelligently, and flexibly, thus enhancing their connectivity
as well as reducing their transmission latency and their energy consumption. To
this end, the fundamentals of this framework are first introduced. Then, a
number of communication and AI techniques are proposed to improve the quality
of experiences of terrestrial MUs. To this end, federated learning and
reinforcement learning are introduced for intelligent task offloading and
computing resource allocation. For each learning technique, motivations,
challenges, and representative results are introduced. Finally, several key
technical challenges and open research issues of the proposed framework are
summarized.",arxiv
http://arxiv.org/abs/2004.03877v1,2020-04-08T08:33:48Z,2020-04-08T08:33:48Z,"Towards Federated Learning in UAV-Enabled Internet of Vehicles: A
  Multi-Dimensional Contract-Matching Approach","Coupled with the rise of Deep Learning, the wealth of data and enhanced
computation capabilities of Internet of Vehicles (IoV) components enable
effective Artificial Intelligence (AI) based models to be built. Beyond ground
data sources, Unmanned Aerial Vehicles (UAVs) based service providers for data
collection and AI model training, i.e., Drones-as-a-Service, is increasingly
popular in recent years. However, the stringent regulations governing data
privacy potentially impedes data sharing across independently owned UAVs. To
this end, we propose the adoption of a Federated Learning (FL) based approach
to enable privacy-preserving collaborative Machine Learning across a federation
of independent DaaS providers for the development of IoV applications, e.g.,
for traffic prediction and car park occupancy management. Given the information
asymmetry and incentive mismatches between the UAVs and model owners, we
leverage on the self-revealing properties of a multi-dimensional contract to
ensure truthful reporting of the UAV types, while accounting for the multiple
sources of heterogeneity, e.g., in sensing, computation, and transmission
costs. Then, we adopt the Gale-Shapley algorithm to match the lowest cost UAV
to each subregion. The simulation results validate the incentive compatibility
of our contract design, and shows the efficiency of our matching, thus
guaranteeing profit maximization for the model owner amid information
asymmetry.",arxiv
http://arxiv.org/abs/2007.08691v1,2020-07-16T23:41:48Z,2020-07-16T23:41:48Z,"Decision-making Strategy on Highway for Autonomous Vehicles using Deep
  Reinforcement Learning","Autonomous driving is a promising technology to reduce traffic accidents and
improve driving efficiency. In this work, a deep reinforcement learning
(DRL)-enabled decision-making policy is constructed for autonomous vehicles to
address the overtaking behaviors on the highway. First, a highway driving
environment is founded, wherein the ego vehicle aims to pass through the
surrounding vehicles with an efficient and safe maneuver. A hierarchical
control framework is presented to control these vehicles, which indicates the
upper-level manages the driving decisions, and the lower-level cares about the
supervision of vehicle speed and acceleration. Then, the particular DRL method
named dueling deep Q-network (DDQN) algorithm is applied to derive the highway
decision-making strategy. The exhaustive calculative procedures of deep
Q-network and DDQN algorithms are discussed and compared. Finally, a series of
estimation simulation experiments are conducted to evaluate the effectiveness
of the proposed highway decision-making policy. The advantages of the proposed
framework in convergence rate and control performance are illuminated.
Simulation results reveal that the DDQN-based overtaking policy could
accomplish highway driving tasks efficiently and safely.",arxiv
http://arxiv.org/abs/1805.00983v2,2018-05-08T16:13:09Z,2018-05-02T19:03:37Z,"Robust Deep Reinforcement Learning for Security and Safety in Autonomous
  Vehicle Systems","To operate effectively in tomorrow's smart cities, autonomous vehicles (AVs)
must rely on intra-vehicle sensors such as camera and radar as well as
inter-vehicle communication. Such dependence on sensors and communication links
exposes AVs to cyber-physical (CP) attacks by adversaries that seek to take
control of the AVs by manipulating their data. Thus, to ensure safe and optimal
AV dynamics control, the data processing functions at AVs must be robust to
such CP attacks. To this end, in this paper, the state estimation process for
monitoring AV dynamics, in presence of CP attacks, is analyzed and a novel
adversarial deep reinforcement learning (RL) algorithm is proposed to maximize
the robustness of AV dynamics control to CP attacks. The attacker's action and
the AV's reaction to CP attacks are studied in a game-theoretic framework. In
the formulated game, the attacker seeks to inject faulty data to AV sensor
readings so as to manipulate the inter-vehicle optimal safe spacing and
potentially increase the risk of AV accidents or reduce the vehicle flow on the
roads. Meanwhile, the AV, acting as a defender, seeks to minimize the
deviations of spacing so as to ensure robustness to the attacker's actions.
Since the AV has no information about the attacker's action and due to the
infinite possibilities for data value manipulations, the outcome of the
players' past interactions are fed to long-short term memory (LSTM) blocks.
Each player's LSTM block learns the expected spacing deviation resulting from
its own action and feeds it to its RL algorithm. Then, the the attacker's RL
algorithm chooses the action which maximizes the spacing deviation, while the
AV's RL algorithm tries to find the optimal action that minimizes such
deviation.",arxiv
http://arxiv.org/abs/2009.14665v1,2020-09-30T13:38:32Z,2020-09-30T13:38:32Z,"Facilitating Connected Autonomous Vehicle Operations Using
  Space-weighted Information Fusion and Deep Reinforcement Learning Based
  Control","The connectivity aspect of connected autonomous vehicles (CAV) is beneficial
because it facilitates dissemination of traffic-related information to vehicles
through Vehicle-to-External (V2X) communication. Onboard sensing equipment
including LiDAR and camera can reasonably characterize the traffic environment
in the immediate locality of the CAV. However, their performance is limited by
their sensor range (SR). On the other hand, longer-range information is helpful
for characterizing imminent conditions downstream. By contemporaneously
coalescing the short- and long-range information, the CAV can construct
comprehensively its surrounding environment and thereby facilitate informed,
safe, and effective movement planning in the short-term (local decisions
including lane change) and long-term (route choice). In this paper, we describe
a Deep Reinforcement Learning based approach that integrates the data collected
through sensing and connectivity capabilities from other vehicles located in
the proximity of the CAV and from those located further downstream, and we use
the fused data to guide lane changing, a specific context of CAV operations. In
addition, recognizing the importance of the connectivity range (CR) to the
performance of not only the algorithm but also of the vehicle in the actual
driving environment, the paper carried out a case study. The case study
demonstrates the application of the proposed algorithm and duly identifies the
appropriate CR for each level of prevailing traffic density. It is expected
that implementation of the algorithm in CAVs can enhance the safety and
mobility associated with CAV driving operations. From a general perspective,
its implementation can provide guidance to connectivity equipment manufacturers
and CAV operators, regarding the default CR settings for CAVs or the
recommended CR setting in a given traffic environment.",arxiv
http://arxiv.org/abs/1910.06788v1,2019-10-14T14:22:01Z,2019-10-14T14:22:01Z,"Dynamic Graph Configuration with Reinforcement Learning for Connected
  Autonomous Vehicle Trajectories","Traditional traffic optimization solutions assume that the graph structure of
road networks is static, missing opportunities for further traffic flow
optimization. We are interested in optimizing traffic flows as a new type of
graph-based problem, where the graph structure of a road network can adapt to
traffic conditions in real time. In particular, we focus on the dynamic
configuration of traffic-lane directions, which can help balance the usage of
traffic lanes in opposite directions. The rise of connected autonomous vehicles
offers an opportunity to apply this type of dynamic traffic optimization at a
large scale. The existing techniques for optimizing lane-directions are however
not suitable for dynamic traffic environments due to their high computational
complexity and the static nature.
  In this paper, we propose an efficient traffic optimization solution, called
Coordinated Learning-based Lane Allocation (CLLA), which is suitable for
dynamic configuration of lane-directions. CLLA consists of a two-layer
multi-agent architecture, where the bottom-layer agents use a machine learning
technique to find a suitable configuration of lane-directions around individual
road intersections. The lane-direction changes proposed by the learning agents
are then coordinated at a higher level to reduce the negative impact of the
changes on other parts of the road network. Our experimental results show that
CLLA can reduce the average travel time significantly in congested road
networks. We believe our method is general enough to be applied to other types
of networks as well.",arxiv
http://arxiv.org/abs/2105.03905v3,2021-07-23T10:51:12Z,2021-05-09T10:38:53Z,"Security Concerns on Machine Learning Solutions for 6G Networks in
  mmWave Beam Prediction","6G -- sixth generation -- is the latest cellular technology currently under
development for wireless communication systems. In recent years, machine
learning algorithms have been applied widely in various fields, such as
healthcare, transportation, energy, autonomous car, and many more. Those
algorithms have been also using in communication technologies to improve the
system performance in terms of frequency spectrum usage, latency, and security.
With the rapid developments of machine learning techniques, especially deep
learning, it is critical to take the security concern into account when
applying the algorithms. While machine learning algorithms offer significant
advantages for 6G networks, security concerns on Artificial Intelligent (AI)
models is typically ignored by the scientific community so far. However,
security is also a vital part of the AI algorithms, this is because the AI
model itself can be poisoned by attackers. This paper proposes a mitigation
method for adversarial attacks against proposed 6G machine learning models for
the millimeter-wave (mmWave) beam prediction using adversarial learning. The
main idea behind adversarial attacks against machine learning models is to
produce faulty results by manipulating trained deep learning models for 6G
applications for mmWave beam prediction. We also present the adversarial
learning mitigation method's performance for 6G security in mmWave beam
prediction application with fast gradient sign method attack. The mean square
errors (MSE) of the defended model under attack are very close to the
undefended model without attack.",arxiv
http://arxiv.org/abs/1703.09744v1,2017-03-28T18:52:38Z,2017-03-28T18:52:38Z,"Feature Analysis and Selection for Training an End-to-End Autonomous
  Vehicle Controller Using the Deep Learning Approach","Deep learning-based approaches have been widely used for training controllers
for autonomous vehicles due to their powerful ability to approximate nonlinear
functions or policies. However, the training process usually requires large
labeled data sets and takes a lot of time. In this paper, we analyze the
influences of features on the performance of controllers trained using the
convolutional neural networks (CNNs), which gives a guideline of feature
selection to reduce computation cost. We collect a large set of data using The
Open Racing Car Simulator (TORCS) and classify the image features into three
categories (sky-related, roadside-related, and road-related features).We then
design two experimental frameworks to investigate the importance of each single
feature for training a CNN controller.The first framework uses the training
data with all three features included to train a controller, which is then
tested with data that has one feature removed to evaluate the feature's
effects. The second framework is trained with the data that has one feature
excluded, while all three features are included in the test data. Different
driving scenarios are selected to test and analyze the trained controllers
using the two experimental frameworks. The experiment results show that (1) the
road-related features are indispensable for training the controller, (2) the
roadside-related features are useful to improve the generalizability of the
controller to scenarios with complicated roadside information, and (3) the
sky-related features have limited contribution to train an end-to-end
autonomous vehicle controller.",arxiv
http://arxiv.org/abs/2103.10533v1,2021-03-18T21:28:28Z,2021-03-18T21:28:28Z,"Resilient Cooperative Adaptive Cruise Control for Autonomous Vehicles
  Using Machine Learning","Cooperative Adaptive Cruise Control (CACC) is a fundamental connected vehicle
application that extends Adaptive Cruise Control by exploiting
vehicle-to-vehicle (V2V) communication. CACC is a crucial ingredient for
numerous autonomous vehicle functionalities including platooning, distributed
route management, etc. Unfortunately, malicious V2V communications can subvert
CACC, leading to string instability and road accidents. In this paper, we
develop a novel resiliency infrastructure, RACCON, for detecting and mitigating
V2V attacks on CACC. RACCON uses machine learning to develop an on-board
prediction model that captures anomalous vehicular responses and performs
mitigation in real time. RACCON-enabled vehicles can exploit the high
efficiency of CACC without compromising safety, even under potentially
adversarial scenarios. We present extensive experimental evaluation to
demonstrate the efficacy of RACCON.",arxiv
http://arxiv.org/abs/2005.07872v2,2020-08-16T08:07:49Z,2020-05-16T04:54:37Z,"Gentlemen on the Road: Understanding How Pedestrians Interpret Yielding
  Behavior of Autonomous Vehicles using Machine Learning","Autonomous vehicles (AVs) can prevent collisions by understanding pedestrian
intention. We conducted a virtual reality experiment with 39 participants and
measured crossing times (seconds) and head orientation (yaw degrees). We
manipulated AV yielding behavior (no-yield, slow-yield, and fast-yield) and the
AV size (small, medium, and large). Using machine learning approach, we
classified head orientation change of pedestrians by time into 6 clusters of
patterns. Results indicate that pedestrian head orientation change was
influenced by AV yielding behavior as well as the size of the AV. Participants
fixated on the front most of the time even when the car approached near.
Participants changed head orientation most frequently when a large size AV did
not yield (no-yield). In post-experiment interviews, participants reported that
yielding behavior and size affected their decision to cross and perceived
safety. For autonomous vehicles to be perceived more safe and trustful,
vehicle-specific factors such as size and yielding behavior should be
considered in the designing process.",arxiv
http://arxiv.org/abs/2103.12166v2,2021-03-30T01:12:02Z,2021-03-22T20:24:45Z,Special Session: Reliability Analysis for ML/AI Hardware,"Artificial intelligence (AI) and Machine Learning (ML) are becoming pervasive
in today's applications, such as autonomous vehicles, healthcare, aerospace,
cybersecurity, and many critical applications. Ensuring the reliability and
robustness of the underlying AI/ML hardware becomes our paramount importance.
In this paper, we explore and evaluate the reliability of different AI/ML
hardware. The first section outlines the reliability issues in a commercial
systolic array-based ML accelerator in the presence of faults engendering from
device-level non-idealities in the DRAM. Next, we quantified the impact of
circuit-level faults in the MSB and LSB logic cones of the Multiply and
Accumulate (MAC) block of the AI accelerator on the AI/ML accuracy. Finally, we
present two key reliability issues -- circuit aging and endurance in emerging
neuromorphic hardware platforms and present our system-level approach to
mitigate them.",arxiv
http://arxiv.org/abs/1909.09418v2,2019-11-07T13:51:17Z,2019-09-20T10:40:14Z,AIBA: An AI Model for Behavior Arbitration in Autonomous Driving,"Driving in dynamically changing traffic is a highly challenging task for
autonomous vehicles, especially in crowded urban roadways. The Artificial
Intelligence (AI) system of a driverless car must be able to arbitrate between
different driving strategies in order to properly plan the car's path, based on
an understandable traffic scene model. In this paper, an AI behavior
arbitration algorithm for Autonomous Driving (AD) is proposed. The method,
coined AIBA (AI Behavior Arbitration), has been developed in two stages: (i)
human driving scene description and understanding and (ii) formal modelling.
The description of the scene is achieved by mimicking a human cognition model,
while the modelling part is based on a formal representation which approximates
the human driver understanding process. The advantage of the formal
representation is that the functional safety of the system can be analytically
inferred. The performance of the algorithm has been evaluated in Virtual Test
Drive (VTD), a comprehensive traffic simulator, and in GridSim, a vehicle
kinematics engine for prototypes.",arxiv
http://arxiv.org/abs/1911.01419v1,2019-11-02T21:55:19Z,2019-11-02T21:55:19Z,On Solving the 2-Dimensional Greedy Shooter Problem for UAVs,"Unmanned Aerial Vehicles (UAVs), autonomously-guided aircraft, are widely
used for tasks involving surveillance and reconnaissance. A version of the
pursuit-evasion problems centered around UAVs and its variants has been
extensively studied in recent years due to numerous breakthroughs in AI. We
present an approach to UAV pursuit-evasion in a 2D aerial-engagement
environment using reinforcement learning (RL), a machine learning paradigm
concerned with goal-oriented algorithms. In this work, a UAV wielding the
greedy shooter strategy engages with a UAV trained using deep Q-learning
techniques. Simulated results show that the latter UAV wins every engagement in
which the UAVs are suffciently separated during initialization. This approach
highlights an exhaustive and robust application of reinforcement learning to
pursuit-evasion that provides insight into effective strategies for UAV flight
and interaction.",arxiv
http://arxiv.org/abs/1709.05116v1,2017-09-15T09:03:42Z,2017-09-15T09:03:42Z,"A Streaming Accelerator for Deep Convolutional Neural Networks with
  Image and Feature Decomposition for Resource-limited System Applications","Deep convolutional neural networks (CNN) are widely used in modern artificial
intelligence (AI) and smart vision systems but also limited by computation
latency, throughput, and energy efficiency on a resource-limited scenario, such
as mobile devices, internet of things (IoT), unmanned aerial vehicles (UAV),
and so on. A hardware streaming architecture is proposed to accelerate
convolution and pooling computations for state-of-the-art deep CNNs. It is
optimized for energy efficiency by maximizing local data reuse to reduce
off-chip DRAM data access. In addition, image and feature decomposition
techniques are introduced to optimize memory access pattern for an arbitrary
size of image and number of features within limited on-chip SRAM capacity. A
prototype accelerator was implemented in TSMC 65 nm CMOS technology with 2.3 mm
x 0.8 mm core area, which achieves 144 GOPS peak throughput and 0.8 TOPS/W peak
energy efficiency.",arxiv
http://arxiv.org/abs/1907.01051v1,2019-07-01T20:16:26Z,2019-07-01T20:16:26Z,"ML-based Fault Injection for Autonomous Vehicles: A Case for Bayesian
  Fault Injection","The safety and resilience of fully autonomous vehicles (AVs) are of
significant concern, as exemplified by several headline-making accidents. While
AV development today involves verification, validation, and testing, end-to-end
assessment of AV systems under accidental faults in realistic driving scenarios
has been largely unexplored. This paper presents DriveFI, a machine
learning-based fault injection engine, which can mine situations and faults
that maximally impact AV safety, as demonstrated on two industry-grade AV
technology stacks (from NVIDIA and Baidu). For example, DriveFI found 561
safety-critical faults in less than 4 hours. In comparison, random injection
experiments executed over several weeks could not find any safety-critical
faults",arxiv
http://arxiv.org/abs/2101.09362v1,2021-01-21T16:18:42Z,2021-01-21T16:18:42Z,"Machine Learning Based Early Fire Detection System using a Low-Cost
  Drone","This paper proposes a new machine learning based system for forest fire
earlier detection in a low-cost and accurate manner. Accordingly, it is aimed
to bring a new and definite perspective to visual detection in forest fires. A
drone is constructed for this purpose. The microcontroller in the system has
been programmed by training with deep learning methods, and the unmanned aerial
vehicle has been given the ability to recognize the smoke, the earliest sign of
fire detection. The common problem in the prevalent algorithms used in fire
detection is the high false alarm and overlook rates. Confirming the result
obtained from the visualization with an additional supervision stage will
increase the reliability of the system as well as guarantee the accuracy of the
result. Due to the mobile vision ability of the unmanned aerial vehicle, the
data can be controlled from any point of view clearly and continuously. System
performance are validated by conducting experiments in both simulation and
physical environments.",arxiv
http://arxiv.org/abs/2006.15172v2,2020-07-02T15:11:31Z,2020-06-26T18:55:10Z,"A Comparison of Uncertainty Estimation Approaches in Deep Learning
  Components for Autonomous Vehicle Applications","A key factor for ensuring safety in Autonomous Vehicles (AVs) is to avoid any
abnormal behaviors under undesirable and unpredicted circumstances. As AVs
increasingly rely on Deep Neural Networks (DNNs) to perform safety-critical
tasks, different methods for uncertainty quantification have recently been
proposed to measure the inevitable source of errors in data and models.
However, uncertainty quantification in DNNs is still a challenging task. These
methods require a higher computational load, a higher memory footprint, and
introduce extra latency, which can be prohibitive in safety-critical
applications. In this paper, we provide a brief and comparative survey of
methods for uncertainty quantification in DNNs along with existing metrics to
evaluate uncertainty predictions. We are particularly interested in
understanding the advantages and downsides of each method for specific AV tasks
and types of uncertainty sources.",arxiv
http://arxiv.org/abs/1809.01011v1,2018-08-31T11:18:18Z,2018-08-31T11:18:18Z,"JuncNet: A Deep Neural Network for Road Junction Disambiguation for
  Autonomous Vehicles","With a great amount of research going on in the field of autonomous vehicles
or self-driving cars, there has been considerable progress in road detection
and tracking algorithms. Most of these algorithms use GPS to handle road
junctions and its subsequent decisions. However, there are places in the urban
environment where it becomes difficult to get GPS fixes which render the
junction decision handling erroneous or possibly risky. Vision-based junction
detection, however, does not have such problems. This paper proposes a novel
deep convolutional neural network architecture for disambiguation of junctions
from roads with a high degree of accuracy. This network is benchmarked against
other well known classifying network architectures like AlexNet and VGGnet.
Further, we discuss a potential road navigation methodology which uses the
proposed network model. We conclude by performing an experimental validation of
the trained network and the navigational method on the roads of the Indian
Institute of Science (IISc).",arxiv
http://arxiv.org/abs/2011.03615v1,2020-11-06T22:12:40Z,2020-11-06T22:12:40Z,"Single and Multi-Agent Deep Reinforcement Learning for AI-Enabled
  Wireless Networks: A Tutorial","Deep Reinforcement Learning (DRL) has recently witnessed significant advances
that have led to multiple successes in solving sequential decision-making
problems in various domains, particularly in wireless communications. The
future sixth-generation (6G) networks are expected to provide scalable,
low-latency, ultra-reliable services empowered by the application of
data-driven Artificial Intelligence (AI). The key enabling technologies of
future 6G networks, such as intelligent meta-surfaces, aerial networks, and AI
at the edge, involve more than one agent which motivates the importance of
multi-agent learning techniques. Furthermore, cooperation is central to
establishing self-organizing, self-sustaining, and decentralized networks. In
this context, this tutorial focuses on the role of DRL with an emphasis on deep
Multi-Agent Reinforcement Learning (MARL) for AI-enabled 6G networks. The first
part of this paper will present a clear overview of the mathematical frameworks
for single-agent RL and MARL. The main idea of this work is to motivate the
application of RL beyond the model-free perspective which was extensively
adopted in recent years. Thus, we provide a selective description of RL
algorithms such as Model-Based RL (MBRL) and cooperative MARL and we highlight
their potential applications in 6G wireless networks. Finally, we overview the
state-of-the-art of MARL in fields such as Mobile Edge Computing (MEC),
Unmanned Aerial Vehicles (UAV) networks, and cell-free massive MIMO, and
identify promising future research directions. We expect this tutorial to
stimulate more research endeavors to build scalable and decentralized systems
based on MARL.",arxiv
http://arxiv.org/abs/2010.05436v1,2020-10-12T03:52:10Z,2020-10-12T03:52:10Z,"Leveraging the Capabilities of Connected and Autonomous Vehicles and
  Multi-Agent Reinforcement Learning to Mitigate Highway Bottleneck Congestion","Active Traffic Management strategies are often adopted in real-time to
address such sudden flow breakdowns. When queuing is imminent, Speed
Harmonization (SH), which adjusts speeds in upstream traffic to mitigate
traffic showckwaves downstream, can be applied. However, because SH depends on
driver awareness and compliance, it may not always be effective in mitigating
congestion. The use of multiagent reinforcement learning for collaborative
learning, is a promising solution to this challenge. By incorporating this
technique in the control algorithms of connected and autonomous vehicle (CAV),
it may be possible to train the CAVs to make joint decisions that can mitigate
highway bottleneck congestion without human driver compliance to altered speed
limits. In this regard, we present an RL-based multi-agent CAV control model to
operate in mixed traffic (both CAVs and human-driven vehicles (HDVs)). The
results suggest that even at CAV percent share of corridor traffic as low as
10%, CAVs can significantly mitigate bottlenecks in highway traffic. Another
objective was to assess the efficacy of the RL-based controller vis-\`a-vis
that of the rule-based controller. In addressing this objective, we duly
recognize that one of the main challenges of RL-based CAV controllers is the
variety and complexity of inputs that exist in the real world, such as the
information provided to the CAV by other connected entities and sensed
information. These translate as dynamic length inputs which are difficult to
process and learn from. For this reason, we propose the use of Graphical
Convolution Networks (GCN), a specific RL technique, to preserve information
network topology and corresponding dynamic length inputs. We then use this,
combined with Deep Deterministic Policy Gradient (DDPG), to carry out
multi-agent training for congestion mitigation using the CAV controllers.",arxiv
http://arxiv.org/abs/1906.07077v1,2019-06-17T15:06:47Z,2019-06-17T15:06:47Z,"The Attack Generator: A Systematic Approach Towards Constructing
  Adversarial Attacks","Most state-of-the-art machine learning (ML) classification systems are
vulnerable to adversarial perturbations. As a consequence, adversarial
robustness poses a significant challenge for the deployment of ML-based systems
in safety- and security-critical environments like autonomous driving, disease
detection or unmanned aerial vehicles. In the past years we have seen an
impressive amount of publications presenting more and more new adversarial
attacks. However, the attack research seems to be rather unstructured and new
attacks often appear to be random selections from the unlimited set of possible
adversarial attacks. With this publication, we present a structured analysis of
the adversarial attack creation process. By detecting different building blocks
of adversarial attacks, we outline the road to new sets of adversarial attacks.
We call this the ""attack generator"". In the pursuit of this objective, we
summarize and extend existing adversarial perturbation taxonomies. The
resulting taxonomy is then linked to the application context of computer vision
systems for autonomous vehicles, i.e. semantic segmentation and object
detection. Finally, in order to prove the usefulness of the attack generator,
we investigate existing semantic segmentation attacks with respect to the
detected defining components of adversarial attacks.",arxiv
http://arxiv.org/abs/1903.07107v1,2019-03-17T15:34:11Z,2019-03-17T15:34:11Z,"Adaptive Genomic Evolution of Neural Network Topologies (AGENT) for
  State-to-Action Mapping in Autonomous Agents","Neuroevolution is a process of training neural networks (NN) through an
evolutionary algorithm, usually to serve as a state-to-action mapping model in
control or reinforcement learning-type problems. This paper builds on the Neuro
Evolution of Augmented Topologies (NEAT) formalism that allows designing
topology and weight evolving NNs. Fundamental advancements are made to the
neuroevolution process to address premature stagnation and convergence issues,
central among which is the incorporation of automated mechanisms to control the
population diversity and average fitness improvement within the neuroevolution
process. Insights into the performance and efficiency of the new algorithm is
obtained by evaluating it on three benchmark problems from the Open AI platform
and an Unmanned Aerial Vehicle (UAV) collision avoidance problem.",arxiv
http://arxiv.org/abs/2109.06126v1,2021-09-13T17:05:43Z,2021-09-13T17:05:43Z,"Neural Network Guided Evolutionary Fuzzing for Finding Traffic
  Violations of Autonomous Vehicles","Self-driving cars and trucks, autonomous vehicles (AVs), should not be
accepted by regulatory bodies and the public until they have much higher
confidence in their safety and reliability -- which can most practically and
convincingly be achieved by testing. But existing testing methods are
inadequate for checking the end-to-end behaviors of AV controllers against
complex, real-world corner cases involving interactions with multiple
independent agents such as pedestrians and human-driven vehicles. While
test-driving AVs on streets and highways fails to capture many rare events,
existing simulation-based testing methods mainly focus on simple scenarios and
do not scale well for complex driving situations that require sophisticated
awareness of the surroundings. To address these limitations, we propose a new
fuzz testing technique, called AutoFuzz, which can leverage widely-used AV
simulators' API grammars. to generate semantically and temporally valid complex
driving scenarios (sequences of scenes). AutoFuzz is guided by a constrained
Neural Network (NN) evolutionary search over the API grammar to generate
scenarios seeking to find unique traffic violations. Evaluation of our
prototype on one state-of-the-art learning-based controller and two rule-based
controllers shows that AutoFuzz efficiently finds hundreds of realistic traffic
violations resembling real-world crashes. Further, fine-tuning the
learning-based controller with the traffic violations found by AutoFuzz
successfully reduced the traffic violations found in the new version of the AV
controller software.",arxiv
http://arxiv.org/abs/1808.05756v2,2019-01-04T14:07:31Z,2018-08-16T13:22:00Z,"Fast and Accurate, Convolutional Neural Network Based Approach for
  Object Detection from UAV","Unmanned Aerial Vehicles (UAVs), have intrigued different people from all
walks of life, because of their pervasive computing capabilities. UAV equipped
with vision techniques, could be leveraged to establish navigation autonomous
control for UAV itself. Also, object detection from UAV could be used to
broaden the utilization of drone to provide ubiquitous surveillance and
monitoring services towards military operation, urban administration and
agriculture management. As the data-driven technologies evolved, machine
learning algorithm, especially the deep learning approach has been intensively
utilized to solve different traditional computer vision research problems.
Modern Convolutional Neural Networks based object detectors could be divided
into two major categories: one-stage object detector and two-stage object
detector. In this study, we utilize some representative CNN based object
detectors to execute the computer vision task over Stanford Drone Dataset
(SDD). State-of-the-art performance has been achieved in utilizing focal loss
dense detector RetinaNet based approach for object detection from UAV in a fast
and accurate manner.",arxiv
http://arxiv.org/abs/2106.11810v2,2021-07-12T06:35:54Z,2021-06-22T14:24:55Z,"NuPlan: A closed-loop ML-based planning benchmark for autonomous
  vehicles","In this work, we propose the world's first closed-loop ML-based planning
benchmark for autonomous driving. While there is a growing body of ML-based
motion planners, the lack of established datasets and metrics has limited the
progress in this area. Existing benchmarks for autonomous vehicle motion
prediction have focused on short-term motion forecasting, rather than long-term
planning. This has led previous works to use open-loop evaluation with L2-based
metrics, which are not suitable for fairly evaluating long-term planning. Our
benchmark overcomes these limitations by introducing a large-scale driving
dataset, lightweight closed-loop simulator, and motion-planning-specific
metrics. We provide a high-quality dataset with 1500h of human driving data
from 4 cities across the US and Asia with widely varying traffic patterns
(Boston, Pittsburgh, Las Vegas and Singapore). We will provide a closed-loop
simulation framework with reactive agents and provide a large set of both
general and scenario-specific planning metrics. We plan to release the dataset
at NeurIPS 2021 and organize benchmark challenges starting in early 2022.",arxiv
http://arxiv.org/abs/1709.08233v1,2017-09-24T18:28:47Z,2017-09-24T18:28:47Z,Learning Unmanned Aerial Vehicle Control for Autonomous Target Following,"While deep reinforcement learning (RL) methods have achieved unprecedented
successes in a range of challenging problems, their applicability has been
mainly limited to simulation or game domains due to the high sample complexity
of the trial-and-error learning process. However, real-world robotic
applications often need a data-efficient learning process with safety-critical
constraints. In this paper, we consider the challenging problem of learning
unmanned aerial vehicle (UAV) control for tracking a moving target. To acquire
a strategy that combines perception and control, we represent the policy by a
convolutional neural network. We develop a hierarchical approach that combines
a model-free policy gradient method with a conventional feedback
proportional-integral-derivative (PID) controller to enable stable learning
without catastrophic failure. The neural network is trained by a combination of
supervised learning from raw images and reinforcement learning from games of
self-play. We show that the proposed approach can learn a target following
policy in a simulator efficiently and the learned behavior can be successfully
transferred to the DJI quadrotor platform for real-world UAV control.",arxiv
http://arxiv.org/abs/1808.01053v1,2018-08-03T00:38:35Z,2018-08-03T00:38:35Z,"Optimizing Space-Air-Ground Integrated Networks by Artificial
  Intelligence","It is widely acknowledged that the development of traditional terrestrial
communication technologies cannot provide all users with fair and high quality
services due to the scarce network resource and limited coverage areas. To
complement the terrestrial connection, especially for users in rural,
disaster-stricken, or other difficult-to-serve areas, satellites, unmanned
aerial vehicles (UAVs), and balloons have been utilized to relay the
communication signals. On the basis, Space-Air-Ground Integrated Networks
(SAGINs) have been proposed to improve the users' Quality of Experience (QoE).
However, compared with existing networks such as ad hoc networks and cellular
networks, the SAGINs are much more complex due to the various characteristics
of three network segments. To improve the performance of SAGINs, researchers
are facing many unprecedented challenges. In this paper, we propose the
Artificial Intelligence (AI) technique to optimize the SAGINs, as the AI
technique has shown its predominant advantages in many applications. We first
analyze several main challenges of SAGINs and explain how these problems can be
solved by AI. Then, we consider the satellite traffic balance as an example and
propose a deep learning based method to improve the traffic control
performance. Simulation results evaluate that the deep learning technique can
be an efficient tool to improve the performance of SAGINs.",arxiv
http://arxiv.org/abs/2105.14190v1,2021-05-20T01:38:45Z,2021-05-20T01:38:45Z,RaspberryPI for mosquito neutralization by power laser,"In this article for the first time, comprehensive studies of mosquito
neutralization using machine vision and a 1 W power laser are considered.
Developed laser installation with Raspberry Pi that changing the direction of
the laser with a galvanometer. We developed a program for mosquito tracking in
real. The possibility of using deep neural networks, Haar cascades, machine
learning for mosquito recognition was considered. We considered in detail the
classification problems of mosquitoes in images. A recommendation is given for
the implementation of this device based on a microcontroller for subsequent use
as part of an unmanned aerial vehicle. Any harmful insects in the fields can be
used as objects for control.",arxiv
http://arxiv.org/abs/1908.11157v2,2019-12-16T12:30:48Z,2019-08-29T11:31:10Z,Active Learning for UAV-based Semantic Mapping,"Unmanned aerial vehicles combined with computer vision systems, such as
convolutional neural networks, offer a flexible and affordable solution for
terrain monitoring, mapping, and detection tasks. However, a key challenge
remains the collection and annotation of training data for the given sensors,
application, and mission. We introduce an informative path planning system that
incorporates novelty estimation into its objective function, based on research
for uncertainty estimation in deep learning. The system is designed for data
collection to reduce both the number of flights and of annotated images. We
evaluate the approach on real world terrain mapping data and show significantly
smaller collected training dataset compared to standard lawnmower data
collection techniques.",arxiv
http://arxiv.org/abs/1905.10677v3,2020-02-26T00:27:20Z,2019-05-25T21:22:02Z,An Exploratory Study on Machine Learning Model Stores,"Recent advances in Artificial Intelligence, especially in Machine Learning
(ML), have brought applications previously considered as science fiction (e.g.,
virtual personal assistants and autonomous cars) into the reach of millions of
everyday users. Since modern ML technologies like deep learning require
considerable technical expertise and resource to build custom models, reusing
existing models trained by experts has become essential. This is why in the
past year model stores have been introduced, which, similar to mobile app
stores, offer organizations and developers access to pre-trained models and/or
their code to train, evaluate, and predict samples. This paper conducts an
exploratory study on three popular model stores (AWS marketplace, Wolfram
neural net repository, and ModelDepot) that compares the information elements
(features and policies) provided by model stores to those used by the two
popular mobile app stores (Google Play and Apple's App Store). We have found
that the model information elements vary among the different model stores, with
65% elements shared by all three studied stores. Model stores share five
information elements with mobile app stores, while eight elements are unique to
model stores and four elements unique to app stores. Only few models were
available on multiple model stores. Our findings allow to better understand the
differences between ML models and ""regular"" source code components or
applications, and provide inspiration to identify software engineering
practices (e.g., in requirements and delivery) specific to ML applications.",arxiv
http://arxiv.org/abs/2107.02355v1,2021-07-06T02:37:30Z,2021-07-06T02:37:30Z,"Total Nitrogen Estimation in Agricultural Soils via Aerial Multispectral
  Imaging and LIBS","Measuring soil health indicators is an important and challenging task that
affects farmers' decisions on timing, placement, and quantity of fertilizers
applied in the farms. Most existing methods to measure soil health indicators
(SHIs) are in-lab wet chemistry or spectroscopy-based methods, which require
significant human input and effort, time-consuming, costly, and are
low-throughput in nature. To address this challenge, we develop an artificial
intelligence (AI)-driven near real-time unmanned aerial vehicle (UAV)-based
multispectral sensing (UMS) solution to estimate total nitrogen (TN) of the
soil, an important macro-nutrient or SHI that directly affects the crop health.
Accurate prediction of soil TN can significantly increase crop yield through
informed decision making on the timing of seed planting, and fertilizer
quantity and timing. We train two machine learning models including multi-layer
perceptron and support vector machine to predict the soil nitrogen using a
suite of data classes including multispectral characteristics of the soil and
crops in red, near-infrared, and green spectral bands, computed vegetation
indices, and environmental variables including air temperature and relative
humidity. To generate the ground-truth data or the training data for the
machine learning models, we measure the total nitrogen of the soil samples
(collected from a farm) using laser-induced breakdown spectroscopy (LIBS).",arxiv
http://arxiv.org/abs/2106.15734v3,2021-07-11T19:33:00Z,2021-06-29T21:40:28Z,"UAV-assisted Online Machine Learning over Multi-Tiered Networks: A
  Hierarchical Nested Personalized Federated Learning Approach","We consider distributed machine learning (ML) through unmanned aerial
vehicles (UAVs) for geo-distributed device clusters. We propose five new
technologies/techniques: (i) stratified UAV swarms with leader, worker, and
coordinator UAVs, (ii) hierarchical nested personalized federated learning
(HN-PFL): a holistic distributed ML framework for personalized model training
across the worker-leader-core network hierarchy, (iii) cooperative UAV resource
pooling for distributed ML using the UAVs' local computational capabilities,
(iv) aerial data caching and relaying for efficient data relaying to conduct
ML, and (v) concept/model drift, capturing online data variations at the
devices. We split the UAV-enabled model training problem as two parts. (a)
Network-aware HN-PFL, where we optimize a tradeoff between energy consumption
and ML model performance by configuring data offloading among devices-UAVs and
UAV-UAVs, UAVs' CPU frequencies, and mini-batch sizes subject to
communication/computation network heterogeneity. We tackle this optimization
problem via the method of posynomial condensation and propose a distributed
algorithm with a performance guarantee. (b) Macro-trajectory and learning
duration design, which we formulate as a sequential decision making problem,
tackled via deep reinforcement learning. Our simulations demonstrate the
superiority of our methodology with regards to the distributed ML performance,
the optimization of network resources, and the swarm trajectory efficiency.",arxiv
http://arxiv.org/abs/1904.06680v1,2019-04-14T11:30:58Z,2019-04-14T11:30:58Z,"Online Sampling in the Parameter Space of a Neural Network for
  GPU-accelerated Motion Planning of Autonomous Vehicles","This paper proposes online sampling in the parameter space of a neural
network for GPU-accelerated motion planning of autonomous vehicles. Neural
networks are used as controller parametrization since they can handle nonlinear
non-convex systems and their complexity does not scale with prediction horizon
length. Network parametrizations are sampled at each sampling time and then
held constant throughout the prediction horizon. Controls still vary over the
prediction horizon due to varying feature vectors fed to the network.
Full-dimensional vehicles are modeled by polytopes. Under the assumption of
obstacle point data, and their extrapolation over a prediction horizon under
constant velocity assumption, collision avoidance reduces to linear inequality
checks. Steering and longitudinal acceleration controls are determined
simultaneously. The proposed method is designed for parallelization and
therefore well-suited to benefit from continuing advancements in hardware such
as GPUs. Characteristics of proposed method are illustrated in 5 numerical
simulation experiments including dynamic obstacle avoidance, waypoint tracking
requiring alternating forward and reverse driving with maximal steering, and a
reverse parking scenario.",arxiv
http://arxiv.org/abs/2107.01004v3,2021-09-17T11:52:10Z,2021-06-08T11:15:30Z,AdaptSky: A DRL Based Resource Allocation Framework in NOMA-UAV Networks,"Unmanned aerial vehicle (UAV) has recently attracted a lot of attention as a
candidate to meet the 6G ubiquitousconnectivity demand and boost the resiliency
of terrestrialnetworks. Thanks to the high spectral efficiency and low latency,
non-orthogonal multiple access (NOMA) is a potential access technique for
future communication networks. In this paper, we propose to use the UAV as a
moving base station (BS) to serve multiple users using NOMA and jointly solve
for the 3D-UAV placement and resource allocation problem. Since the
corresponding optimization problem is non-convex, we rely on the recent
advances in artificial intelligence (AI) and propose AdaptSky, a deep
reinforcement learning (DRL)-based framework, to efficiently solve it. To the
best of our knowledge, AdaptSky is the first framework that optimizes NOMA
power allocation jointly with 3D-UAV placement using both sub-6GHz and
millimeter wave mmWave spectrum. Furthermore, for the first time in NOMA-UAV
networks, AdaptSky integrates the dueling network (DN) architecture to the DRL
technique to improve its learning capabilities. Our findings show that AdaptSky
does not only exhibit a fast-adapting learning and outperform the
state-of-the-art baseline approach in data rate and fairness, but also it
generalizes very well.",arxiv
http://arxiv.org/abs/2001.11958v1,2020-01-28T15:10:22Z,2020-01-28T15:10:22Z,Artificial Intelligence Aided Next-Generation Networks Relying on UAVs,"Artificial intelligence (AI) assisted unmanned aerial vehicle (UAV) aided
next-generation networking is proposed for dynamic environments. In the
AI-enabled UAV-aided wireless networks (UAWN), multiple UAVs are employed as
aerial base stations, which are capable of rapidly adapting to the dynamic
environment by collecting information about the users' position and
tele-traffic demands, learning from the environment and acting upon the
feedback received from the users. Moreover, AI enables the interaction amongst
a swarm of UAVs for cooperative optimization of the system. As a benefit of the
AI framework, several challenges of conventional UAWN may be circumvented,
leading to enhanced network performance, improved reliability and agile
adaptivity. As a further benefit, dynamic trajectory design and resource
allocation are demonstrated. Finally, potential research challenges and
opportunities are discussed.",arxiv
http://arxiv.org/abs/2009.11522v2,2021-01-28T12:39:29Z,2020-09-24T07:11:31Z,Artificial Intelligence for UAV-enabled Wireless Networks: A Survey,"Unmanned aerial vehicles (UAVs) are considered as one of the promising
technologies for the next-generation wireless communication networks. Their
mobility and their ability to establish line of sight (LOS) links with the
users made them key solutions for many potential applications. In the same
vein, artificial intelligence (AI) is growing rapidly nowadays and has been
very successful, particularly due to the massive amount of the available data.
As a result, a significant part of the research community has started to
integrate intelligence at the core of UAVs networks by applying AI algorithms
in solving several problems in relation to drones. In this article, we provide
a comprehensive overview of some potential applications of AI in UAV-based
networks. We also highlight the limits of the existing works and outline some
potential future applications of AI for UAV networks.",arxiv
http://arxiv.org/abs/1809.04790v4,2019-09-23T13:04:37Z,2018-09-13T06:09:32Z,Adversarial Examples: Opportunities and Challenges,"Deep neural networks (DNNs) have shown huge superiority over humans in image
recognition, speech processing, autonomous vehicles and medical diagnosis.
However, recent studies indicate that DNNs are vulnerable to adversarial
examples (AEs), which are designed by attackers to fool deep learning models.
Different from real examples, AEs can mislead the model to predict incorrect
outputs while hardly be distinguished by human eyes, therefore threaten
security-critical deep-learning applications. In recent years, the generation
and defense of AEs have become a research hotspot in the field of artificial
intelligence (AI) security. This article reviews the latest research progress
of AEs. First, we introduce the concept, cause, characteristics and evaluation
metrics of AEs, then give a survey on the state-of-the-art AE generation
methods with the discussion of advantages and disadvantages. After that, we
review the existing defenses and discuss their limitations. Finally, future
research opportunities and challenges on AEs are prospected.",arxiv
http://arxiv.org/abs/1811.06187v1,2018-11-15T05:26:38Z,2018-11-15T05:26:38Z,"Intervention Aided Reinforcement Learning for Safe and Practical Policy
  Optimization in Navigation","Combining deep neural networks with reinforcement learning has shown great
potential in the next-generation intelligent control. However, there are
challenges in terms of safety and cost in practical applications. In this
paper, we propose the Intervention Aided Reinforcement Learning (IARL)
framework, which utilizes human intervened robot-environment interaction to
improve the policy. We used the Unmanned Aerial Vehicle (UAV) as the test
platform. We built neural networks as our policy to map sensor readings to
control signals on the UAV. Our experiment scenarios cover both simulation and
reality. We show that our approach substantially reduces the human intervention
and improves the performance in autonomous navigation, at the same time it
ensures safety and keeps training cost acceptable.",arxiv
http://arxiv.org/abs/2103.04132v1,2021-03-06T15:05:14Z,2021-03-06T15:05:14Z,"A Real-time Low-cost Artificial Intelligence System for Autonomous
  Spraying in Palm Plantations","In precision crop protection, (target-orientated) object detection in image
processing can help navigate Unmanned Aerial Vehicles (UAV, crop protection
drones) to the right place to apply the pesticide. Unnecessary application of
non-target areas could be avoided. Deep learning algorithms dominantly use in
modern computer vision tasks which require high computing time, memory
footprint, and power consumption. Based on the Edge Artificial Intelligence, we
investigate the main three paths that lead to dealing with this problem,
including hardware accelerators, efficient algorithms, and model compression.
Finally, we integrate them and propose a solution based on a light deep neural
network (DNN), called Ag-YOLO, which can make the crop protection UAV have the
ability to target detection and autonomous operation. This solution is
restricted in size, cost, flexible, fast, and energy-effective. The hardware is
only 18 grams in weight and 1.5 watts in energy consumption, and the developed
DNN model needs only 838 kilobytes of disc space. We tested the developed
hardware and software in comparison to the tiny version of the state-of-art
YOLOv3 framework, known as YOLOv3-Tiny to detect individual palm in a
plantation. An average F1 score of 0.9205 at the speed of 36.5 frames per
second (in comparison to similar accuracy at 18 frames per second and 8.66
megabytes of the YOLOv3-Tiny algorithm) was reached. This developed detection
system is easily plugged into any machines already purchased as long as the
machines have USB ports and run Linux Operating System.",arxiv
http://arxiv.org/abs/1904.03861v1,2019-04-08T06:44:52Z,2019-04-08T06:44:52Z,"Ready Player One: UAV Clustering based Multi-Task Offloading for
  Vehicular VR/AR Gaming","With rapid development of unmanned aerial vehicle (UAV) technology,
application of the UAVs for task offloading has received increasing interest in
the academia. However, real-time interaction between one UAV and the mobile
edge computing (MEC) node is required for processing the tasks of mobile end
users, which significantly increases the system overhead and is unable to meet
the demands of large-scale artificial intelligence (AI) based applications. To
tackle this problem, in this article, we propose a new architecture for UAV
clustering to enable efficient multi-modal multi-task task offloading. By the
proposed architecture, the computing, caching and communication resources are
collaboratively optimized using AI based decision-making. This not only
increases the efficiency of UAV clusters, but also provides insight into the
fusion of computation and communication.",arxiv
http://arxiv.org/abs/1906.10327v2,2019-07-09T05:51:07Z,2019-06-25T05:41:01Z,SkyNet: A Champion Model for DAC-SDC on Low Power Object Detection,"Developing artificial intelligence (AI) at the edge is always challenging,
since edge devices have limited computation capability and memory resources but
need to meet demanding requirements, such as real-time processing, high
throughput performance, and high inference accuracy. To overcome these
challenges, we propose SkyNet, an extremely lightweight DNN with 12
convolutional (Conv) layers and only 1.82 megabyte (MB) of parameters following
a bottom-up DNN design approach. SkyNet is demonstrated in the 56th IEEE/ACM
Design Automation Conference System Design Contest (DAC-SDC), a low power
object detection challenge in images captured by unmanned aerial vehicles
(UAVs). SkyNet won the first place award for both the GPU and FPGA tracks of
the contest: we deliver 0.731 Intersection over Union (IoU) and 67.33 frames
per second (FPS) on a TX2 GPU and deliver 0.716 IoU and 25.05 FPS on an Ultra96
FPGA.",arxiv
http://arxiv.org/abs/2012.06381v1,2020-12-08T10:52:57Z,2020-12-08T10:52:57Z,6G Wireless Channel Measurements and Models: Trends and Challenges,"In this article, we first present our vision on the application scenarios,
performance metrics, and potential key technologies of the sixth generation
(6G) wireless communication networks. Then, 6G wireless channel measurements,
characteristics, and models are comprehensively surveyed for all frequency
bands and all scenarios, focusing on millimeter wave (mmWave), terahertz (THz),
and optical wireless communication channels under all spectrums, satellite,
unmanned aerial vehicle (UAV), maritime, and underwater acoustic communication
channels under global coverage scenarios, and high-speed train (HST),
vehicle-to-vehicle (V2V), ultra-massive multiple-input multiple-output (MIMO),
orbital angular momentum (OAM), and industry Internet of things (IoT)
communication channels under full application scenarios. Future research
challenges on 6G channel measurements, a general standard 6G channel model
framework, channel measurements and models for intelligent reflection surface
(IRS) based 6G technologies, and artificial intelligence (AI) enabled channel
measurements and models are also given.",arxiv
http://arxiv.org/abs/2109.03180v2,2021-09-19T12:43:57Z,2021-09-07T16:19:01Z,"First Responders Got Wings: UAVs to the Rescue of Localization
  Operations in Beyond 5G Systems","Natural and human-made disasters have dramatically increased during the last
decades. Given the strong relationship between first responders localization
time and the final number of deaths, the modernization of search-and-rescue
operations has become imperative. In this context, Unmanned Aerial Vehicles
(UAVs)-based solutions are the most promising candidates to take up on the
localization challenge by leveraging on emerging technologies such as:
Artificial Intelligence (AI), Reconfigurable Intelligent Surfaces (RIS) and
Orthogonal Time Frequency Space (OTFS) modulations. In this paper, we
capitalize on such recently available techniques by shedding light on the main
challenges and future opportunities to boost the localization performance of
state-of-the-art techniques to give birth to unprecedentedly effective missing
victims localization solutions.",arxiv
http://arxiv.org/abs/2104.01283v1,2021-04-03T00:15:34Z,2021-04-03T00:15:34Z,"A Review of AI-enabled Routing Protocols for UAV Networks: Trends,
  Challenges, and Future Outlook","Unmanned Aerial Vehicles (UAVs), as a recently emerging technology, enabled a
new breed of unprecedented applications in different domains. This technology's
ongoing trend is departing from large remotely-controlled drones to networks of
small autonomous drones to collectively complete intricate tasks time and
cost-effectively. An important challenge is developing efficient sensing,
communication, and control algorithms that can accommodate the requirements of
highly dynamic UAV networks with heterogeneous mobility levels. Recently, the
use of Artificial Intelligence (AI) in learning-based networking has gained
momentum to harness the learning power of cognizant nodes to make more
intelligent networking decisions. An important example of this trend is
developing learning-powered routing protocols, where machine learning methods
are used to model and predict topology evolution, channel status, traffic
mobility, and environmental factors for enhanced routing.
  This paper reviews AI-enabled routing protocols designed primarily for aerial
networks, with an emphasis on accommodating highly-dynamic network topology. To
this end, we review the basics of UAV technology, different approaches to swarm
formation, and commonly-used mobility models, along with their impact on
networking paradigms. We proceed with reviewing conventional and AI-enabled
routing protocols, including topology-predictive and self-adaptive
learning-based routing algorithms. We also discuss tools, simulation
environments, remote experimentation platforms, and public datasets that can be
used for developing and testing AI-enabled networking protocols for UAV
networks. We conclude by presenting future trends, and the remaining challenges
in AI-based UAV Networking, for different aspects of routing, connectivity,
topology control, security and privacy, energy efficiency, and spectrum
sharing.",arxiv
http://arxiv.org/abs/1810.07862v1,2018-10-18T01:47:19Z,2018-10-18T01:47:19Z,"Applications of Deep Reinforcement Learning in Communications and
  Networking: A Survey","This paper presents a comprehensive literature review on applications of deep
reinforcement learning in communications and networking. Modern networks, e.g.,
Internet of Things (IoT) and Unmanned Aerial Vehicle (UAV) networks, become
more decentralized and autonomous. In such networks, network entities need to
make decisions locally to maximize the network performance under uncertainty of
network environment. Reinforcement learning has been efficiently used to enable
the network entities to obtain the optimal policy including, e.g., decisions or
actions, given their states when the state and action spaces are small.
However, in complex and large-scale networks, the state and action spaces are
usually large, and the reinforcement learning may not be able to find the
optimal policy in reasonable time. Therefore, deep reinforcement learning, a
combination of reinforcement learning with deep learning, has been developed to
overcome the shortcomings. In this survey, we first give a tutorial of deep
reinforcement learning from fundamental concepts to advanced models. Then, we
review deep reinforcement learning approaches proposed to address emerging
issues in communications and networking. The issues include dynamic network
access, data rate control, wireless caching, data offloading, network security,
and connectivity preservation which are all important to next generation
networks such as 5G and beyond. Furthermore, we present applications of deep
reinforcement learning for traffic routing, resource sharing, and data
collection. Finally, we highlight important challenges, open issues, and future
research directions of applying deep reinforcement learning.",arxiv
http://arxiv.org/abs/1801.05086v1,2018-01-16T01:14:12Z,2018-01-16T01:14:12Z,Autonomous UAV Navigation Using Reinforcement Learning,"Unmanned aerial vehicles (UAV) are commonly used for missions in unknown
environments, where an exact mathematical model of the environment may not be
available. This paper provides a framework for using reinforcement learning to
allow the UAV to navigate successfully in such environments. We conducted our
simulation and real implementation to show how the UAVs can successfully learn
to navigate through an unknown environment. Technical aspects regarding to
applying reinforcement learning algorithm to a UAV system and UAV flight
control were also addressed. This will enable continuing research using a UAV
with learning capabilities in more important applications, such as wildfire
monitoring, or search and rescue missions.",arxiv
http://arxiv.org/abs/2108.09986v1,2021-08-23T07:41:10Z,2021-08-23T07:41:10Z,"Indoor Path Planning for an Unmanned Aerial Vehicle via Curriculum
  Learning","In this study, reinforcement learning was applied to learning two-dimensional
path planning including obstacle avoidance by unmanned aerial vehicle (UAV) in
an indoor environment. The task assigned to the UAV was to reach the goal
position in the shortest amount of time without colliding with any obstacles.
Reinforcement learning was performed in a virtual environment created using
Gazebo, a virtual environment simulator, to reduce the learning time and cost.
Curriculum learning, which consists of two stages was performed for more
efficient learning. As a result of learning with two reward models, the maximum
goal rates achieved were 71.2% and 88.0%.",arxiv
http://arxiv.org/abs/2012.10878v1,2020-12-20T09:51:23Z,2020-12-20T09:51:23Z,"Computer Vision based Animal Collision Avoidance Framework for
  Autonomous Vehicles","Animals have been a common sighting on roads in India which leads to several
accidents between them and vehicles every year. This makes it vital to develop
a support system for driverless vehicles that assists in preventing these forms
of accidents. In this paper, we propose a neoteric framework for avoiding
vehicle-to-animal collisions by developing an efficient approach for the
detection of animals on highways using deep learning and computer vision
techniques on dashcam video. Our approach leverages the Mask R-CNN model for
detecting and identifying various commonly found animals. Then, we perform lane
detection to deduce whether a detected animal is on the vehicle's lane or not
and track its location and direction of movement using a centroid based object
tracking algorithm. This approach ensures that the framework is effective at
determining whether an animal is obstructing the path or not of an autonomous
vehicle in addition to predicting its movement and giving feedback accordingly.
This system was tested under various lighting and weather conditions and was
observed to perform relatively well, which leads the way for prominent
driverless vehicle's support systems for avoiding vehicular collisions with
animals on Indian roads in real-time.",arxiv
http://arxiv.org/abs/2012.05490v1,2020-12-10T07:29:14Z,2020-12-10T07:29:14Z,"PARRoT: Predictive Ad-hoc Routing Fueled by Reinforcement Learning and
  Trajectory Knowledge","Swarms of collaborating Unmanned Aerial Vehicles (UAVs) that utilize ad-hoc
networking technologies for coordinating their actions offer the potential to
catalyze emerging research fields such as autonomous exploration of disaster
areas, demanddriven network provisioning, and near field packet delivery in
Intelligent Transportation Systems (ITSs). As these mobile robotic networks are
characterized by high grades of relative mobility, existing routing protocols
often fail to adopt their decision making to the implied network topology
dynamics. For addressing these challenges, we present Predictive Ad-hoc Routing
fueled by Reinforcement learning and Trajectory knowledge (PARRoT) as a novel
machine learning-enabled routing protocol which exploits mobility control
information for integrating knowledge about the future motion of the mobile
agents into the routing process. The performance of the proposed routing
approach is evaluated using comprehensive network simulation. In comparison to
established routing protocols, PARRoT achieves a massively higher robustness
and a significantly lower end-to-end latency.",arxiv
http://arxiv.org/abs/2110.08590v1,2021-10-16T15:24:12Z,2021-10-16T15:24:12Z,Automated Remote Sensing Forest Inventory Using Satelite Imagery,"For many countries like Russia, Canada, or the USA, a robust and detailed
tree species inventory is essential to manage their forests sustainably. Since
one can not apply unmanned aerial vehicle (UAV) imagery-based approaches to
large-scale forest inventory applications, the utilization of machine learning
algorithms on satellite imagery is a rising topic of research. Although
satellite imagery quality is relatively low, additional spectral channels
provide a sufficient amount of information for tree crown classification tasks.
Assuming that tree crowns are detected already, we use embeddings of tree
crowns generated by Autoencoders as a data set to train classical Machine
Learning algorithms. We compare our Autoencoder (AE) based approach to
traditional convolutional neural networks (CNN) end-to-end classifiers.",arxiv
http://arxiv.org/abs/1908.03271v2,2019-08-19T19:07:10Z,2019-08-08T21:44:26Z,"Reflections in the Sky: Millimeter Wave Communication with UAV-Carried
  Intelligent Reflectors","In this paper, a novel approach that uses an unmanned aerial vehicle
(UAV)-carried intelligent reflector (IR) is proposed to enhance the performance
of millimeter wave (mmW) networks. In particular, the UAV-IR is used to
intelligently reflect mmW beamforming signals from a base station towards a
mobile outdoor user, while harvesting energy from mmW signals to power the IR.
To maintain a line-of-sight (LOS) channel, a reinforcement learning (RL)
approach, based on Q-learning and neural networks, is proposed to model the
propagation environment, such that the location and reflection coefficient of
the UAV-IR can be optimized to maximize the downlink transmission capacity.
Simulation results show a significant advantage for using a UAV-IR over a
static IR, in terms of the average data rate and the achievable downlink LOS
probability. The results also show that the RL-based deployment of the UAV-IR
further improves the network performance, relative to a scheme without
learning.",arxiv
http://arxiv.org/abs/1807.08241v1,2018-07-22T06:10:04Z,2018-07-22T06:10:04Z,"NAVREN-RL: Learning to fly in real environment via end-to-end deep
  reinforcement learning using monocular images","We present NAVREN-RL, an approach to NAVigate an unmanned aerial vehicle in
an indoor Real ENvironment via end-to-end reinforcement learning RL. A suitable
reward function is designed keeping in mind the cost and weight constraints for
micro drone with minimum number of sensing modalities. Collection of small
number of expert data and knowledge based data aggregation is integrated into
the RL process to aid convergence. Experimentation is carried out on a Parrot
AR drone in different indoor arenas and the results are compared with other
baseline technologies. We demonstrate how the drone successfully avoids
obstacles and navigates across different arenas.",arxiv
http://arxiv.org/abs/2006.07301v2,2021-03-01T21:24:19Z,2020-06-12T16:32:42Z,Human and Multi-Agent collaboration in a human-MARL teaming framework,"Reinforcement learning provides effective results with agents learning from
their observations, received rewards, and internal interactions between agents.
This study proposes a new open-source MARL framework, called COGMENT, to
efficiently leverage human and agent interactions as a source of learning. We
demonstrate these innovations by using a designed real-time environment with
unmanned aerial vehicles driven by RL agents, collaborating with a human. The
results of this study show that the proposed collaborative paradigm and the
open-source framework leads to significant reductions in both human effort and
exploration costs.",arxiv
http://arxiv.org/abs/2004.05843v1,2020-04-13T09:48:04Z,2020-04-13T09:48:04Z,"Federated Machine Learning for Intelligent IoT via Reconfigurable
  Intelligent Surface","Intelligent Internet-of-Things (IoT) will be transformative with the
advancement of artificial intelligence and high-dimensional data analysis,
shifting from ""connected things"" to ""connected intelligence"". This shall
unleash the full potential of intelligent IoT in a plethora of exciting
applications, such as self-driving cars, unmanned aerial vehicles, healthcare,
robotics, and supply chain finance. These applications drive the need of
developing revolutionary computation, communication and artificial intelligence
technologies that can make low-latency decisions with massive real-time data.
To this end, federated machine learning, as a disruptive technology, is emerged
to distill intelligence from the data at network edge, while guaranteeing
device privacy and data security. However, the limited communication bandwidth
is a key bottleneck of model aggregation for federated machine learning over
radio channels. In this article, we shall develop an over-the-air computation
based communication-efficient federated machine learning framework for
intelligent IoT networks via exploiting the waveform superposition property of
a multi-access channel. Reconfigurable intelligent surface is further leveraged
to reduce the model aggregation error via enhancing the signal strength by
reconfiguring the wireless propagation environments.",arxiv
http://arxiv.org/abs/2008.12332v2,2021-04-16T19:45:35Z,2020-08-27T18:45:40Z,Certainty Equivalent Perception-Based Control,"In order to certify performance and safety, feedback control requires precise
characterization of sensor errors. In this paper, we provide guarantees on such
feedback systems when sensors are characterized by solving a supervised
learning problem. We show a uniform error bound on nonparametric kernel
regression under a dynamically-achievable dense sampling scheme. This allows
for a finite-time convergence rate on the sub-optimality of using the regressor
in closed-loop for waypoint tracking. We demonstrate our results in simulation
with simplified unmanned aerial vehicle and autonomous driving examples.",arxiv
http://arxiv.org/abs/1708.05869v2,2018-03-24T14:34:30Z,2017-08-19T16:09:06Z,Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications,"We present a photo-realistic training and evaluation simulator (Sim4CV) with
extensive applications across various fields of computer vision. Built on top
of the Unreal Engine, the simulator integrates full featured physics based
cars, unmanned aerial vehicles (UAVs), and animated human actors in diverse
urban and suburban 3D environments. We demonstrate the versatility of the
simulator with two case studies: autonomous UAV-based tracking of moving
objects and autonomous driving using supervised learning. The simulator fully
integrates both several state-of-the-art tracking algorithms with a benchmark
evaluation tool and a deep neural network (DNN) architecture for training
vehicles to drive autonomously. It generates synthetic photo-realistic datasets
with automatic ground truth annotations to easily extend existing real-world
datasets and provides extensive synthetic data variety through its ability to
reconfigure synthetic worlds on the fly using an automatic world generation
tool. The supplementary video can be viewed a https://youtu.be/SqAxzsQ7qUU",arxiv
http://arxiv.org/abs/2109.02104v1,2021-09-05T15:33:09Z,2021-09-05T15:33:09Z,Machine Learning-Based 3D Channel Modeling for U2V mmWave Communications,"Unmanned aerial vehicle (UAV) millimeter wave (mmWave) technologies can
provide flexible link and high data rate for future communication networks. By
considering the new features of three-dimensional (3D) scattering space, 3D
velocity, 3D antenna array, and especially 3D rotations, a machine learning
(ML) integrated UAV-to-Vehicle (U2V) mmWave channel model is proposed.
Meanwhile, a ML-based network for channel parameter calculation and generation
is developed. The deterministic parameters are calculated based on the
simplified geometry information, while the random ones are generated by the
back propagation based neural network (BPNN) and generative adversarial network
(GAN), where the training data set is obtained from massive ray-tracing (RT)
simulations. Moreover, theoretical expressions of channel statistical
properties, i.e., power delay profile (PDP), autocorrelation function (ACF),
Doppler power spectrum density (DPSD), and cross-correlation function (CCF) are
derived and analyzed. Finally, the U2V mmWave channel is generated under a
typical urban scenario at 28 GHz. The generated PDP and DPSD show good
agreement with RT-based results, which validates the effectiveness of proposed
method. Moreover, the impact of 3D rotations, which has rarely been reported in
previous works, can be observed in the generated CCF and ACF, which are also
consistent with the theoretical and measurement results.",arxiv
http://arxiv.org/abs/2110.14873v1,2021-10-28T04:14:46Z,2021-10-28T04:14:46Z,"Optimal Stochastic Coded Computation Offloading in Unmanned Aerial
  Vehicles Network","Today, modern unmanned aerial vehicles (UAVs) are equipped with increasingly
advanced capabilities that can run applications enabled by machine learning
techniques, which require computationally intensive operations such as matrix
multiplications. Due to computation constraints, the UAVs can offload their
computation tasks to edge servers. To mitigate stragglers, coded distributed
computing (CDC) based offloading can be adopted. In this paper, we propose an
Optimal Task Allocation Scheme (OTAS) based on Stochastic Integer Programming
with the objective to minimize energy consumption during computation
offloading. The simulation results show that amid uncertainty of task
completion, the energy consumption in the UAV network is minimized.",arxiv
http://arxiv.org/abs/1905.10920v1,2019-05-24T14:43:21Z,2019-05-24T14:43:21Z,"Semi-supervised GAN for Classification of Multispectral Imagery Acquired
  by UAVs","Unmanned aerial vehicles (UAV) are used in precision agriculture (PA) to
enable aerial monitoring of farmlands. Intelligent methods are required to
pinpoint weed infestations and make optimal choice of pesticide. UAV can fly a
multispectral camera and collect data. However, the classification of
multispectral images using supervised machine learning algorithms such as
convolutional neural networks (CNN) requires large amount of training data.
This is a common drawback in deep learning we try to circumvent making use of a
semi-supervised generative adversarial networks (GAN), providing a pixel-wise
classification for all the acquired multispectral images. Our algorithm
consists of a generator network that provides photo-realistic images as extra
training data to a multi-class classifier, acting as a discriminator and
trained on small amounts of labeled data. The performance of the proposed
method is evaluated on the weedNet dataset consisting of multispectral crop and
weed images collected by a micro aerial vehicle (MAV). The results by the
proposed semi-supervised GAN achieves high classification accuracy and
demonstrates the potential of GAN-based methods for the challenging task of
multispectral image classification.",arxiv
http://arxiv.org/abs/2004.08008v1,2020-04-17T00:41:35Z,2020-04-17T00:41:35Z,"DepthNet Nano: A Highly Compact Self-Normalizing Neural Network for
  Monocular Depth Estimation","Depth estimation is an active area of research in the field of computer
vision, and has garnered significant interest due to its rising demand in a
large number of applications ranging from robotics and unmanned aerial vehicles
to autonomous vehicles. A particularly challenging problem in this area is
monocular depth estimation, where the goal is to infer depth from a single
image. An effective strategy that has shown considerable promise in recent
years for tackling this problem is the utilization of deep convolutional neural
networks. Despite these successes, the memory and computational requirements of
such networks have made widespread deployment in embedded scenarios very
challenging. In this study, we introduce DepthNet Nano, a highly compact self
normalizing network for monocular depth estimation designed using a human
machine collaborative design strategy, where principled network design
prototyping based on encoder-decoder design principles are coupled with
machine-driven design exploration. The result is a compact deep neural network
with highly customized macroarchitecture and microarchitecture designs, as well
as self-normalizing characteristics, that are highly tailored for the task of
embedded depth estimation. The proposed DepthNet Nano possesses a highly
efficient network architecture (e.g., 24X smaller and 42X fewer MAC operations
than Alhashim et al. on KITTI), while still achieving comparable performance
with state-of-the-art networks on the NYU-Depth V2 and KITTI datasets.
Furthermore, experiments on inference speed and energy efficiency on a Jetson
AGX Xavier embedded module further illustrate the efficacy of DepthNet Nano at
different resolutions and power budgets (e.g., ~14 FPS and >0.46
images/sec/watt at 384 X 1280 at a 30W power budget on KITTI).",arxiv
http://arxiv.org/abs/2006.14544v1,2020-06-24T07:39:47Z,2020-06-24T07:39:47Z,"Machine Learning-Assisted UAV Operations with UTM: Requirements,
  Challenges, and Solutions","Unmanned aerial vehicles (UAVs) are emerging in commercial spaces and will
support many applications and services, such as smart agriculture, dynamic
network deployment, and network coverage extension, surveillance and security.
The unmanned aircraft system (UAS) traffic management (UTM) provides a
framework for safe UAV operation integrating UAV controllers and central data
bases via a communications network. This paper discusses the challenges and
opportunities for machine learning (ML) for effectively providing critical UTM
services. We introduce the four pillars of UTM---operation planning,
situational awareness, status and advisors and security---and discuss the main
services, specific opportunities for ML and the ongoing research. We conclude
that the multi-faceted operating environment and operational parameters will
benefit from collected data and data-driven algorithms, as well as online
learning to face new UAV operation situations.",arxiv
http://arxiv.org/abs/2110.06775v1,2021-10-11T19:38:24Z,2021-10-11T19:38:24Z,"Using UAVs for vehicle tracking and collision risk assessment at
  intersections","Assessing collision risk is a critical challenge to effective traffic safety
management. The deployment of unmanned aerial vehicles (UAVs) to address this
issue has shown much promise, given their wide visual field and movement
flexibility. This research demonstrates the application of UAVs and V2X
connectivity to track the movement of road users and assess potential
collisions at intersections. The study uses videos captured by UAVs. The
proposed method combines deep-learning based tracking algorithms and
time-to-collision tasks. The results not only provide beneficial information
for vehicle's recognition of potential crashes and motion planning but also
provided a valuable tool for urban road agencies and safety management
engineers.",arxiv
http://arxiv.org/abs/1808.05336v1,2018-08-16T03:39:25Z,2018-08-16T03:39:25Z,"Simultaneous Localization And Mapping with depth Prediction using
  Capsule Networks for UAVs","In this paper, we propose an novel implementation of a simultaneous
localization and mapping (SLAM) system based on a monocular camera from an
unmanned aerial vehicle (UAV) using Depth prediction performed with Capsule
Networks (CapsNet), which possess improvements over the drawbacks of the more
widely-used Convolutional Neural Networks (CNN). An Extended Kalman Filter will
assist in estimating the position of the UAV so that we are able to update the
belief for the environment. Results will be evaluated on a benchmark dataset to
portray the accuracy of our intended approach.",arxiv
http://arxiv.org/abs/1712.01154v4,2018-12-28T01:04:52Z,2017-12-01T05:55:30Z,RF-Based Direction Finding of UAVs Using DNN,"This paper presents a sparse denoising autoencoder (SDAE)-based deep neural
network (DNN) for the direction finding (DF) of small unmanned aerial vehicles
(UAVs). It is motivated by the practical challenges associated with classical
DF algorithms such as MUSIC and ESPRIT. The proposed DF scheme is practical and
low-complex in the sense that a phase synchronization mechanism, an antenna
calibration mechanism, and the analytical model of the antenna radiation
pattern are not essential. Also, the proposed DF method can be implemented
using a single-channel RF receiver. The paper validates the proposed method
experimentally as well.",arxiv
http://arxiv.org/abs/1803.06363v2,2018-05-17T16:07:41Z,2018-03-16T18:24:21Z,"Geometric Adaptive Control for a Quadrotor UAV with Wind Disturbance
  Rejection","This paper presents a geometric adaptive control scheme for a quadrotor
unmanned aerial vehicle, where the effects of unknown, unstructured
disturbances are mitigated by a multilayer neural network that is adjusted
online. The stability of the proposed controller is analyzed with Lyapunov
stability theory on the special Euclidean group, and it is shown that the
tracking errors are uniformly ultimately bounded with an ultimate bound that
can be abridged arbitrarily. A mathematical model of wind disturbance on the
quadrotor dynamics is presented, and it is shown that the proposed adaptive
controller is capable of rejecting the effects of wind disturbances
successfully. These are illustrated by numerical examples.",arxiv
http://arxiv.org/abs/2107.07308v1,2021-07-15T13:26:38Z,2021-07-15T13:26:38Z,Panicle Counting in UAV Images For Estimating Flowering Time in Sorghum,"Flowering time (time to flower after planting) is important for estimating
plant development and grain yield for many crops including sorghum. Flowering
time of sorghum can be approximated by counting the number of panicles
(clusters of grains on a branch) across multiple dates. Traditional manual
methods for panicle counting are time-consuming and tedious. In this paper, we
propose a method for estimating flowering time and rapidly counting panicles
using RGB images acquired by an Unmanned Aerial Vehicle (UAV). We evaluate
three different deep neural network structures for panicle counting and
location. Experimental results demonstrate that our method is able to
accurately detect panicles and estimate sorghum flowering time.",arxiv
http://arxiv.org/abs/1809.03609v1,2018-09-10T21:49:38Z,2018-09-10T21:49:38Z,"URBAN-i: From urban scenes to mapping slums, transport modes, and
  pedestrians in cities using deep learning and computer vision","Within the burgeoning expansion of deep learning and computer vision across
the different fields of science, when it comes to urban development, deep
learning and computer vision applications are still limited towards the notions
of smart cities and autonomous vehicles. Indeed, a wide gap of knowledge
appears when it comes to cities and urban regions in less developed countries
where the chaos of informality is the dominant scheme. How can deep learning
and Artificial Intelligence (AI) untangle the complexities of informality to
advance urban modelling and our understanding of cities? Various questions and
debates can be raised concerning the future of cities of the North and the
South in the paradigm of AI and computer vision. In this paper, we introduce a
new method for multipurpose realistic-dynamic urban modelling relying on deep
learning and computer vision, using deep Convolutional Neural Networks (CNN),
to sense and detect informality and slums in urban scenes from aerial and
street view images in addition to detection of pedestrian and transport modes.
The model has been trained on images of urban scenes in cities across the
globe. The model shows a good validation of understanding a wide spectrum of
nuances among the planned and the unplanned regions, including informal and
slum areas. We attempt to advance urban modelling for better understanding the
dynamics of city developments. We also aim to exemplify the significant impacts
of AI in cities beyond how smart cities are discussed and perceived in the
mainstream. The algorithms of the URBAN-i model are fully-coded in Python
programming with the pre-trained deep learning models to be used as a tool for
mapping and city modelling in the various corner of the globe, including
informal settlements and slum regions.",arxiv
http://arxiv.org/abs/1812.10968v1,2018-12-28T12:08:55Z,2018-12-28T12:08:55Z,"Car Detection using Unmanned Aerial Vehicles: Comparison between Faster
  R-CNN and YOLOv3","Unmanned Aerial Vehicles are increasingly being used in surveillance and
traffic monitoring thanks to their high mobility and ability to cover areas at
different altitudes and locations. One of the major challenges is to use aerial
images to accurately detect cars and count them in real-time for traffic
monitoring purposes. Several deep learning techniques were recently proposed
based on convolution neural network (CNN) for real-time classification and
recognition in computer vision. However, their performance depends on the
scenarios where they are used. In this paper, we investigate the performance of
two state-of-the-art CNN algorithms, namely Faster R-CNN and YOLOv3, in the
context of car detection from aerial images. We trained and tested these two
models on a large car dataset taken from UAVs. We demonstrated in this paper
that YOLOv3 outperforms Faster R-CNN in sensitivity and processing time,
although they are comparable in the precision metric.",arxiv
http://arxiv.org/abs/2004.01343v1,2020-04-03T02:37:21Z,2020-04-03T02:37:21Z,"Efficient UAV Physical Layer Security based on Deep Learning and
  Artificial Noise","Network-connected unmanned aerial vehicle (UAV) communications is a common
solution to achieve high-rate image transmission. The broadcast nature of these
wireless networks makes this communication vulnerable to eavesdropping. This
paper considers the problem of compressed secret image transmission between two
nodes, in the presence of a passive eavesdropper. In this paper, we use auto
encoder/decoder convolutional neural networks, which by using deep learning
algorithms, allow us to compress/decompress images. Also we use network
physical layer features to generate high rate artificial noise to secure the
data. Using features of the channel with applying artificial noises, reduce the
channel capacity of the unauthorized users and prevent eavesdropper from
detecting received data. Our simulation experiments show that for received data
with SNR fewer than 5 in the authorized node, the MSE is less than 0.05.",arxiv
http://arxiv.org/abs/1812.02542v1,2018-12-06T14:16:56Z,2018-12-06T14:16:56Z,Computer Vision for Autonomous Vehicles,"In this work, we try to implement Image Processing techniques in the area of
autonomous vehicles, both indoor and outdoor. The challenges for both are
different and the ways to tackle them vary too. We also showed deep learning
makes things easier and precise. We also made base models for all the problems
we tackle while building an autonomous car for Indian Institute of Space
science and Technology.",arxiv
http://arxiv.org/abs/2010.11106v1,2020-10-21T16:15:41Z,2020-10-21T16:15:41Z,"UAV LiDAR Point Cloud Segmentation of A Stack Interchange with Deep
  Neural Networks","Stack interchanges are essential components of transportation systems. Mobile
laser scanning (MLS) systems have been widely used in road infrastructure
mapping, but accurate mapping of complicated multi-layer stack interchanges are
still challenging. This study examined the point clouds collected by a new
Unmanned Aerial Vehicle (UAV) Light Detection and Ranging (LiDAR) system to
perform the semantic segmentation task of a stack interchange. An end-to-end
supervised 3D deep learning framework was proposed to classify the point
clouds. The proposed method has proven to capture 3D features in complicated
interchange scenarios with stacked convolution and the result achieved over 93%
classification accuracy. In addition, the new low-cost semi-solid-state LiDAR
sensor Livox Mid-40 featuring a incommensurable rosette scanning pattern has
demonstrated its potential in high-definition urban mapping.",arxiv
http://arxiv.org/abs/2101.01284v1,2021-01-04T23:40:45Z,2021-01-04T23:40:45Z,Advancing Computing's Foundation of US Industry & Society,"While past information technology (IT) advances have transformed society,
future advances hold even greater promise. For example, we have only just begun
to reap the changes from artificial intelligence (AI), especially machine
learning (ML). Underlying IT's impact are the dramatic improvements in computer
hardware, which deliver performance that unlock new capabilities. For example,
recent successes in AI/ML required the synergy of improved algorithms and
hardware architectures (e.g., general-purpose graphics processing units).
However, unlike in the 20th Century and early 2000s, tomorrow's performance
aspirations must be achieved without continued semiconductor scaling formerly
provided by Moore's Law and Dennard Scaling. How will one deliver the next 100x
improvement in capability at similar or less cost to enable great value? Can we
make the next AI leap without 100x better hardware?
  This whitepaper argues for a multipronged effort to develop new computing
approaches beyond Moore's Law to advance the foundation that computing provides
to US industry, education, medicine, science, and government. This impact
extends far beyond the IT industry itself, as IT is now central for providing
value across society, for example in semi-autonomous vehicles, tele-education,
health wearables, viral analysis, and efficient administration. Herein we draw
upon considerable visioning work by CRA's Computing Community Consortium (CCC)
and the IEEE Rebooting Computing Initiative (IEEE RCI), enabled by thought
leader input from industry, academia, and the US government.",arxiv
http://arxiv.org/abs/1704.04688v1,2017-04-15T20:49:09Z,2017-04-15T20:49:09Z,Machine Learning and the Future of Realism,"The preceding three decades have seen the emergence, rise, and proliferation
of machine learning (ML). From half-recognised beginnings in perceptrons,
neural nets, and decision trees, algorithms that extract correlations (that is,
patterns) from a set of data points have broken free from their origin in
computational cognition to embrace all forms of problem solving, from voice
recognition to medical diagnosis to automated scientific research and
driverless cars, and it is now widely opined that the real industrial
revolution lies less in mobile phone and similar than in the maturation and
universal application of ML. Among the consequences just might be the triumph
of anti-realism over realism.",arxiv
http://arxiv.org/abs/2012.05410v1,2020-12-10T02:08:47Z,2020-12-10T02:08:47Z,Artificial Intelligence at the Edge,"The Internet of Things (IoT) and edge computing applications aim to support a
variety of societal needs, including the global pandemic situation that the
entire world is currently experiencing and responses to natural disasters.
  The need for real-time interactive applications such as immersive video
conferencing, augmented/virtual reality, and autonomous vehicles, in education,
healthcare, disaster recovery and other domains, has never been higher. At the
same time, there have been recent technological breakthroughs in highly
relevant fields such as artificial intelligence (AI)/machine learning (ML),
advanced communication systems (5G and beyond), privacy-preserving
computations, and hardware accelerators. 5G mobile communication networks
increase communication capacity, reduce transmission latency and error, and
save energy -- capabilities that are essential for new applications. The
envisioned future 6G technology will integrate many more technologies,
including for example visible light communication, to support groundbreaking
applications, such as holographic communications and high precision
manufacturing. Many of these applications require computations and analytics
close to application end-points: that is, at the edge of the network, rather
than in a centralized cloud. AI techniques applied at the edge have tremendous
potential both to power new applications and to need more efficient operation
of edge infrastructure. However, it is critical to understand where to deploy
AI systems within complex ecosystems consisting of advanced applications and
the specific real-time requirements towards AI systems.",arxiv
http://arxiv.org/abs/1810.04344v1,2018-10-10T02:46:23Z,2018-10-10T02:46:23Z,"Apprenticeship Bootstrapping Via Deep Learning with a Safety Net for
  UAV-UGV Interaction","In apprenticeship learning (AL), agents learn by watching or acquiring human
demonstrations on some tasks of interest. However, the lack of human
demonstrations in novel tasks where they may not be a human expert yet, or when
it is too expensive and/or time consuming to acquire human demonstrations
motivated a new algorithm: Apprenticeship bootstrapping (ABS). The basic idea
is to learn from demonstrations on sub-tasks then autonomously bootstrap a
model on the main, more complex, task. The original ABS used inverse
reinforcement learning (ABS-IRL). However, the approach is not suitable for
continuous action spaces.
  In this paper, we propose ABS via Deep learning (ABS-DL). It is first
validated in a simulation environment on an aerial and ground coordination
scenario, where an Unmanned Aerial Vehicle (UAV) is required to maintain three
Unmanned Ground Vehicles (UGVs) within a field of view of the UAV 's camera
(FoV). Moving a machine learning algorithm from a simulation environment to an
actual physical platform is challenging because `mistakes' made by the
algorithm while learning could lead to the damage of the platform. We then take
this extra step to test the algorithm in a physical environment. We propose a
safety-net as a protection layer to ensure that the autonomy of the algorithm
in learning does not compromise the safety of the platform. The tests of ABS-DL
in the real environment can guarantee a damage-free, collision avoidance
behaviour of autonomous bodies. The results show that performance of the
proposed approach is comparable to that of a human, and competitive to the
traditional approach using expert demonstrations performed on the composite
task. The proposed safety-net approach demonstrates its advantages when it
enables the UAV to operate more safely under the control of the ABS-DL
algorithm.",arxiv
http://arxiv.org/abs/1912.09902v1,2019-12-20T16:03:10Z,2019-12-20T16:03:10Z,Dependable Neural Networks for Safety Critical Tasks,"Neural Networks are being integrated into safety critical systems, e.g.,
perception systems for autonomous vehicles, which require trained networks to
perform safely in novel scenarios. It is challenging to verify neural networks
because their decisions are not explainable, they cannot be exhaustively
tested, and finite test samples cannot capture the variation across all
operating conditions. Existing work seeks to train models robust to new
scenarios via domain adaptation, style transfer, or few-shot learning. But
these techniques fail to predict how a trained model will perform when the
operating conditions differ from the testing conditions. We propose a metric,
Machine Learning (ML) Dependability, that measures the network's probability of
success in specified operating conditions which need not be the testing
conditions. In addition, we propose the metrics Task Undependability and
Harmful Undependability to distinguish network failures by their consequences.
We evaluate the performance of a Neural Network agent trained using
Reinforcement Learning in a simulated robot manipulation task. Our results
demonstrate that we can accurately predict the ML Dependability, Task
Undependability, and Harmful Undependability for operating conditions that are
significantly different from the testing conditions. Finally, we design a
Safety Function, using harmful failures identified during testing, that reduces
harmful failures, in one example, by a factor of 700 while maintaining a high
probability of success.",arxiv
http://arxiv.org/abs/2104.07914v1,2021-04-16T06:32:15Z,2021-04-16T06:32:15Z,Federated Learning for Internet of Things: A Comprehensive Survey,"The Internet of Things (IoT) is penetrating many facets of our daily life
with the proliferation of intelligent services and applications empowered by
artificial intelligence (AI). Traditionally, AI techniques require centralized
data collection and processing that may not be feasible in realistic
application scenarios due to the high scalability of modern IoT networks and
growing data privacy concerns. Federated Learning (FL) has emerged as a
distributed collaborative AI approach that can enable many intelligent IoT
applications, by allowing for AI training at distributed IoT devices without
the need for data sharing. In this article, we provide a comprehensive survey
of the emerging applications of FL in IoT networks, beginning from an
introduction to the recent advances in FL and IoT to a discussion of their
integration. Particularly, we explore and analyze the potential of FL for
enabling a wide range of IoT services, including IoT data sharing, data
offloading and caching, attack detection, localization, mobile crowdsensing,
and IoT privacy and security. We then provide an extensive survey of the use of
FL in various key IoT applications such as smart healthcare, smart
transportation, Unmanned Aerial Vehicles (UAVs), smart cities, and smart
industry. The important lessons learned from this review of the FL-IoT services
and applications are also highlighted. We complete this survey by highlighting
the current challenges and possible directions for future research in this
booming area.",arxiv
http://arxiv.org/abs/2108.05457v1,2021-08-11T21:39:51Z,2021-08-11T21:39:51Z,"Low-level Pose Control of Tilting Multirotor for Wall Perching Tasks
  Using Reinforcement Learning","Recently, needs for unmanned aerial vehicles (UAVs) that are attachable to
the wall have been highlighted. As one of the ways to address the need,
researches on various tilting multirotors that can increase maneuverability has
been employed. Unfortunately, existing studies on the tilting multirotors
require considerable amounts of prior information on the complex dynamic model.
Meanwhile, reinforcement learning on quadrotors has been studied to mitigate
this issue. Yet, these are only been applied to standard quadrotors, whose
systems are less complex than those of tilting multirotors. In this paper, a
novel reinforcement learning-based method is proposed to control a tilting
multirotor on real-world applications, which is the first attempt to apply
reinforcement learning to a tilting multirotor. To do so, we propose a novel
reward function for a neural network model that takes power efficiency into
account. The model is initially trained over a simulated environment and then
fine-tuned using real-world data in order to overcome the sim-to-real gap
issue. Furthermore, a novel, efficient state representation with respect to the
goal frame that helps the network learn optimal policy better is proposed. As
verified on real-world experiments, our proposed method shows robust
controllability by overcoming the complex dynamics of tilting multirotors.",arxiv
http://arxiv.org/abs/2102.02078v3,2021-05-19T08:44:35Z,2021-02-03T14:22:36Z,"Multi-UAV Mobile Edge Computing and Path Planning Platform based on
  Reinforcement Learning","Unmanned Aerial vehicles (UAVs) are widely used as network processors in
mobile networks, but more recently, UAVs have been used in Mobile Edge
Computing as mobile servers. However, there are significant challenges to use
UAVs in complex environments with obstacles and cooperation between UAVs. We
introduce a new multi-UAV Mobile Edge Computing platform, which aims to provide
better Quality-of-Service and path planning based on reinforcement learning to
address these issues. The contributions of our work include: 1) optimizing the
quality of service for mobile edge computing and path planning in the same
reinforcement learning framework; 2) using a sigmoid-like function to depict
the terminal users' demand to ensure a higher quality of service; 3) applying
synthetic considerations of the terminal users' demand, risk and geometric
distance in reinforcement learning reward matrix to ensure the quality of
service, risk avoidance, and the cost-savings. Simulations have shown the
effectiveness and feasibility of our platform, which can help advance related
researches.",arxiv
http://arxiv.org/abs/2108.03495v1,2021-08-07T18:11:40Z,2021-08-07T18:11:40Z,"Game Theory and Machine Learning in UAVs-Assisted Wireless Communication
  Networks: A Survey","In recent years, Unmanned Aerial Vehicles (UAVs) have been used in fields
such as architecture, business delivery, military and civilian theaters, and
many others. With increased applications comes the increased demand for
advanced algorithms for resource allocation and energy management. As is well
known, game theory and machine learning are two powerful tools already widely
used in the wireless communication field and there are numerous surveys of game
theory and machine learning usage in wireless communication. Existing surveys
however focus either on game theory or machine learning and due to this fact,
the current article surveys both game-theoretic and machine learning algorithms
for use by UAVs in Wireless Communication Networks (U-WCNs). We also discuss
how to combine game theory and machine learning for solving problems in U-WCNs
and identify several future research directions.",arxiv
http://arxiv.org/abs/2110.07716v1,2021-10-13T09:06:16Z,2021-10-13T09:06:16Z,"Adversarial Scene Reconstruction and Object Detection System for
  Assisting Autonomous Vehicle","In the current computer vision era classifying scenes through video
surveillance systems is a crucial task. Artificial Intelligence (AI) Video
Surveillance technologies have been advanced remarkably while artificial
intelligence and deep learning ascended into the system. Adopting the superior
compounds of deep learning visual classification methods achieved enormous
accuracy in classifying visual scenes. However, the visual classifiers face
difficulties examining the scenes in dark visible areas, especially during the
nighttime. Also, the classifiers face difficulties in identifying the contexts
of the scenes. This paper proposed a deep learning model that reconstructs dark
visual scenes to clear scenes like daylight, and the method recognizes visual
actions for the autonomous vehicle. The proposed model achieved 87.3 percent
accuracy for scene reconstruction and 89.2 percent in scene understanding and
detection tasks.",arxiv
http://arxiv.org/abs/1910.06734v1,2019-10-10T19:03:37Z,2019-10-10T19:03:37Z,Self Driving RC Car using Behavioral Cloning,"Self Driving Car technology is a vehicle that guides itself without human
conduction. The first truly autonomous cars appeared in the 1980s with projects
funded by DARPA( Defense Advance Research Project Agency ). Since then a lot
has changed with the improvements in the fields of Computer Vision and Machine
Learning. We have used the concept of behavioral cloning to convert a normal RC
model car into an autonomous car using Deep Learning technology",arxiv
http://arxiv.org/abs/1804.07045v2,2018-05-18T18:14:19Z,2018-04-19T09:15:58Z,Semantic Adversarial Deep Learning,"Fueled by massive amounts of data, models produced by machine-learning (ML)
algorithms, especially deep neural networks, are being used in diverse domains
where trustworthiness is a concern, including automotive systems, finance,
health care, natural language processing, and malware detection. Of particular
concern is the use of ML algorithms in cyber-physical systems (CPS), such as
self-driving cars and aviation, where an adversary can cause serious
consequences. However, existing approaches to generating adversarial examples
and devising robust ML algorithms mostly ignore the semantics and context of
the overall system containing the ML component. For example, in an autonomous
vehicle using deep learning for perception, not every adversarial example for
the neural network might lead to a harmful consequence. Moreover, one may want
to prioritize the search for adversarial examples towards those that
significantly modify the desired semantics of the overall system. Along the
same lines, existing algorithms for constructing robust ML algorithms ignore
the specification of the overall system. In this paper, we argue that the
semantics and specification of the overall system has a crucial role to play in
this line of research. We present preliminary research results that support
this claim.",arxiv
http://arxiv.org/abs/2011.08779v1,2020-11-17T17:14:28Z,2020-11-17T17:14:28Z,Exploring Energy-Accuracy Tradeoffs in AI Hardware,"Artificial intelligence (AI) is playing an increasingly significant role in
our everyday lives. This trend is expected to continue, especially with recent
pushes to move more AI to the edge. However, one of the biggest challenges
associated with AI on edge devices (mobile phones, unmanned vehicles, sensors,
etc.) is their associated size, weight, and power constraints. In this work, we
consider the scenario where an AI system may need to operate at
less-than-maximum accuracy in order to meet application-dependent energy
requirements. We propose a simple function that divides the cost of using an AI
system into the cost of the decision making process and the cost of decision
execution. For simple binary decision problems with convolutional neural
networks, it is shown that minimizing the cost corresponds to using fewer than
the maximum number of resources (e.g. convolutional neural network layers and
filters). Finally, it is shown that the cost associated with energy can be
significantly reduced by leveraging high-confidence predictions made in
lower-level layers of the network.",arxiv
http://arxiv.org/abs/2108.13448v1,2021-08-30T18:03:34Z,2021-08-30T18:03:34Z,Machine Learning Methods for Management UAV Flocks -- a Survey,"The development of unmanned aerial vehicles (UAVs) has been gaining momentum
in recent years owing to technological advances and a significant reduction in
their cost. UAV technology can be used in a wide range of domains, including
communication, agriculture, security, and transportation. It may be useful to
group the UAVs into clusters/flocks in certain domains, and various challenges
associated with UAV usage can be alleviated by clustering. Several
computational challenges arise in UAV flock management, which can be solved by
using machine learning (ML) methods. In this survey, we describe the basic
terms relating to UAVS and modern ML methods, and we provide an overview of
related tutorials and surveys. We subsequently consider the different
challenges that appear in UAV flocks. For each issue, we survey several machine
learning-based methods that have been suggested in the literature to handle the
associated challenges. Thereafter, we describe various open issues in which ML
can be applied to solve the different challenges of flocks, and we suggest
means of using ML methods for this purpose. This comprehensive review may be
useful for both researchers and developers in providing a wide view of various
aspects of state-of-the-art ML technologies that are applicable to flock
management.",arxiv
http://arxiv.org/abs/2009.02280v1,2020-09-02T11:52:32Z,2020-09-02T11:52:32Z,Communication and networking technologies for UAVs: A survey,"With the advancement in drone technology, in just a few years, drones will be
assisting humans in every domain. But there are many challenges to be tackled,
communication being the chief one. This paper aims at providing insights into
the latest UAV (Unmanned Aerial Vehicle) communication technologies through
investigation of suitable task modules, antennas, resource handling platforms,
and network architectures. Additionally, we explore techniques such as machine
learning and path planning to enhance existing drone communication methods.
Encryption and optimization techniques for ensuring long lasting and secure
communications, as well as for power management, are discussed. Moreover,
applications of UAV networks for different contextual uses ranging from
navigation to surveillance, URLLC (Ultra reliable and low latency
communications), edge computing and work related to artificial intelligence are
examined. In particular, the intricate interplay between UAV, advanced cellular
communication, and internet of things constitutes one of the focal points of
this paper. The survey encompasses lessons learned, insights, challenges, open
issues, and future directions in UAV communications. Our literature review
reveals the need for more research work on drone to drone and drone to device
communications.",arxiv
http://arxiv.org/abs/1805.06628v2,2019-04-23T06:58:38Z,2018-05-17T07:21:37Z,"UAV-Aided Cellular Communications with Deep Reinforcement Learning
  Against Jamming","Cellular systems are vulnerable to jamming attacks, especially smart jammers
that choose their jamming policies such as the jamming channel frequencies and
power based on the ongoing communication policies and network states. In this
article, we present an unmanned aerial vehicle (UAV) aided cellular
communication framework against jamming. In this scheme, UAVs use reinforcement
learning methods to choose the relay policy for mobile users in cellular
systems, if the serving base station is heavily jammed. More specifically, we
propose a deep reinforcement learning based UAV relay scheme to help cellular
systems resist smart jamming without being aware of the jamming model and the
network model in the dynamic game based on the previous anti-jamming relay
experiences and the observed current network status. This scheme can achieve
the optimal performance after enough interactions with the jammer. Simulation
results show that this scheme can reduce the bit error rate of the messages and
save energy for the cellular system compared with the existing scheme.",arxiv
http://arxiv.org/abs/1911.08771v1,2019-11-20T08:48:07Z,2019-11-20T08:48:07Z,"Reinforcement Learning for a Cellular Internet of UAVs: Protocol Design,
  Trajectory Control, and Resource Management","Unmanned aerial vehicles (UAVs) can be powerful Internet-of-Things components
to execute sensing tasks over the next-generation cellular networks, which are
generally referred to as the cellular Internet of UAVs. However, due to the
high mobility of UAVs and the shadowing in the air-to-ground channels, UAVs
operate in an environment with dynamics and uncertainties. Therefore, UAVs need
to improve the quality of service (QoS) of sensing and communication without
complete information, which makes reinforcement learning suitable to be
employed in the cellular Internet of UAVs. In this article, we propose a
distributed sense-and-send protocol to coordinate the UAVs for sensing and
transmission. Then, we apply reinforcement learning in the cellular Internet of
UAVs to solve key problems such as trajectory control and resource management.
Finally, we point out several potential future research directions.",arxiv
http://arxiv.org/abs/2007.13418v2,2021-03-02T21:54:45Z,2020-07-27T10:43:31Z,"Intelligent Trajectory Planning in UAV-mounted Wireless Networks: A
  Quantum-Inspired Reinforcement Learning Perspective","In this paper, we consider a wireless uplink transmission scenario in which
an unmanned aerial vehicle (UAV) serves as an aerial base station collecting
data from ground users. To optimize the expected sum uplink transmit rate
without any prior knowledge of ground users (e.g., locations, channel state
information and transmit power), the trajectory planning problem is optimized
via the quantum-inspired reinforcement learning (QiRL) approach. Specifically,
the QiRL method adopts novel probabilistic action selection policy and new
reinforcement strategy, which are inspired by the collapse phenomenon and
amplitude amplification in quantum computation theory, respectively. Numerical
results demonstrate that the proposed QiRL solution can offer natural balancing
between exploration and exploitation via ranking collapse probabilities of
possible actions, compared to the traditional reinforcement learning approaches
which are highly dependent on tuned exploration parameters.",arxiv
http://arxiv.org/abs/2107.04648v1,2021-07-09T19:47:02Z,2021-07-09T19:47:02Z,"Efficient Real-Time Image Recognition Using Collaborative Swarm of UAVs
  and Convolutional Networks","Unmanned Aerial Vehicles (UAVs) have recently attracted significant attention
due to their outstanding ability to be used in different sectors and serve in
difficult and dangerous areas. Moreover, the advancements in computer vision
and artificial intelligence have increased the use of UAVs in various
applications and solutions, such as forest fires detection and borders
monitoring. However, using deep neural networks (DNNs) with UAVs introduces
several challenges of processing deeper networks and complex models, which
restricts their on-board computation. In this work, we present a strategy
aiming at distributing inference requests to a swarm of resource-constrained
UAVs that classifies captured images on-board and finds the minimum
decision-making latency. We formulate the model as an optimization problem that
minimizes the latency between acquiring images and making the final decisions.
The formulated optimization solution is an NP-hard problem. Hence it is not
adequate for online resource allocation. Therefore, we introduce an online
heuristic solution, namely DistInference, to find the layers placement strategy
that gives the best latency among the available UAVs. The proposed approach is
general enough to be used for different low decision-latency applications as
well as for all CNN types organized into the pipeline of layers (e.g., VGG) or
based on residual blocks (e.g., ResNet).",arxiv
http://arxiv.org/abs/1812.09724v1,2018-12-23T14:57:28Z,2018-12-23T14:57:28Z,Parallelized Interactive Machine Learning on Autonomous Vehicles,"Deep reinforcement learning (deep RL) has achieved superior performance in
complex sequential tasks by learning directly from image input. A deep neural
network is used as a function approximator and requires no specific state
information. However, one drawback of using only images as input is that this
approach requires a prohibitively large amount of training time and data for
the model to learn the state feature representation and approach reasonable
performance. This is not feasible in real-world applications, especially when
the data are expansive and training phase could introduce disasters that affect
human safety. In this work, we use a human demonstration approach to speed up
training for learning features and use the resulting pre-trained model to
replace the neural network in the deep RL Deep Q-Network (DQN), followed by
human interaction to further refine the model. We empirically evaluate our
approach by using only a human demonstration model and modified DQN with human
demonstration model included in the Microsoft AirSim car simulator. Our results
show that (1) pre-training with human demonstration in a supervised learning
approach is better and much faster at discovering features than DQN alone, (2)
initializing the DQN with a pre-trained model provides a significant
improvement in training time and performance even with limited human
demonstration, and (3) providing the ability for humans to supply suggestions
during DQN training can speed up the network's convergence on an optimal
policy, as well as allow it to learn more complex policies that are harder to
discover by random exploration.",arxiv
http://arxiv.org/abs/1707.02589v1,2017-07-09T14:50:02Z,2017-07-09T14:50:02Z,"Exploiting the Tradeoff between Program Accuracy and Soft-error
  Resiliency Overhead for Machine Learning Workloads","To protect multicores from soft-error perturbations, resiliency schemes have
been developed with high coverage but high power and performance overheads.
Emerging safety-critical machine learning applications are increasingly being
deployed on these platforms. Moreover, these systems are exposed to harsh
environments, such as unmanned aerial vehicles (UAVs) and self-driving cars.
Due to the unique structure and computational behavior of such applications,
research has been done on relaxing their accuracy for performance benefits. We
observe that not all transient errors affect program correctness, some errors
only affect program accuracy, i.e., the program completes with certain
acceptable deviations from error free outcome. This paper illustrates the idea
of cross-layer soft-error resilience using machine learning workloads, where
program accuracy is introduced as a tradeoff to deliver resilient yet efficient
execution on futuristic large-scale multicores.",arxiv
http://arxiv.org/abs/2009.14551v2,2021-02-02T08:09:12Z,2020-09-30T10:40:44Z,Explainable Deep Reinforcement Learning for UAV Autonomous Navigation,"Autonomous navigation in unknown complex environment is still a hard problem,
especially for small Unmanned Aerial Vehicles (UAVs) with limited computation
resources. In this paper, a neural network-based reactive controller is
proposed for a quadrotor to fly autonomously in unknown outdoor environment.
The navigation controller makes use of only current sensor data to generate the
control signal without any optimization or configuration space searching, which
reduces both memory and computation requirement. The navigation problem is
modelled as a Markov Decision Process (MDP) and solved using deep reinforcement
learning (DRL) method. Specifically, to get better understanding of the trained
network, some model explanation methods are proposed. Based on the feature
attribution, each decision making result during flight is explained using both
visual and texture explanation. Moreover, some global analysis are also
provided for experts to evaluate and improve the trained neural network. The
simulation results illustrated the proposed method can make useful and
reasonable explanation for the trained model, which is beneficial for both
non-expert users and controller designer. Finally, the real world tests shown
the proposed controller can navigate the quadrotor to goal position
successfully and the reactive controller performs much faster than some
conventional approach under the same computation resource.",arxiv
http://arxiv.org/abs/2007.15286v1,2020-07-30T08:00:32Z,2020-07-30T08:00:32Z,Design Guidelines for Blockchain-Assisted 5G-UAV Networks,"Fifth Generation (5G) wireless networks are designed to meet various end-user
Quality of Service (QoS) requirements through high data rates (typically of
Gbps order) and low latencies. Coupled with Fog and Mobile Edge Computing
(MEC), 5G can achieve high data rates, enabling complex autonomous smart city
services such as the large deployment of self-driving vehicles and large-scale
Artificial Intelligence (AI)-enabled industrial manufacturing. However, to meet
the exponentially growing number of connected IoT devices and irregular data
and service requests in both low and highly dense locations, the process of
enacting traditional cells supported through fixed and costly base stations
requires rethought to enable on-demand mobile access points in the form of
Unmanned Aerial Vehicles (UAV) for diversified smart city scenarios. This
article envisions a 5G network environment that is supported by
blockchain-enabled UAVs to meet dynamic user demands with network access
supply. The solution enables decentralized service delivery (Drones as a
Service) and routing to and from end-users in a reliable and secure manner.
Both public and private blockchains are deployed within the UAVs, supported by
fog and cloud computing devices and data centers to provide wide range of
complex authenticated service and data availability. Particular attention is
paid tocomparing data delivery success rates and message exchange in the
proposed solution against traditional UAV-supported cellular networks.
Challenges and future research are also discussed with highlights on emerging
technologies such as Federated Learning.",arxiv
http://arxiv.org/abs/2009.10267v1,2020-09-22T01:43:05Z,2020-09-22T01:43:05Z,Model-Driven Requirements for Humans-on-the-Loop Multi-UAV Missions,"The use of semi-autonomous Unmanned Aerial Vehicles (UAVs or drones) to
support emergency response scenarios, such as fire surveillance and
search-and-rescue, has the potential for huge societal benefits. Onboard
sensors and artificial intelligence (AI) allow these UAVs to operate
autonomously in the environment. However, human intelligence and domain
expertise are crucial in planning and guiding UAVs to accomplish the mission.
Therefore, humans and multiple UAVs need to collaborate as a team to conduct a
time-critical mission successfully. We propose a meta-model to describe
interactions among the human operators and the autonomous swarm of UAVs. The
meta-model also provides a language to describe the roles of UAVs and humans
and the autonomous decisions. We complement the meta-model with a template of
requirements elicitation questions to derive models for specific missions. We
also identify common scenarios where humans should collaborate with UAVs to
augment the autonomy of the UAVs. We introduce the meta-model and the
requirements elicitation process with examples drawn from a search-and-rescue
mission in which multiple UAVs collaborate with humans to respond to the
emergency. We then apply it to a second scenario in which UAVs support first
responders in fighting a structural fire. Our results show that the meta-model
and the template of questions support the modeling of the human-on-the-loop
human interactions for these complex missions, suggesting that it is a useful
tool for modeling the human-on-the-loop interactions for multi-UAVs missions.",arxiv
http://arxiv.org/abs/2011.14197v1,2020-11-28T18:58:34Z,2020-11-28T18:58:34Z,"Privacy-Preserving Federated Learning for UAV-Enabled Networks:
  Learning-Based Joint Scheduling and Resource Management","Unmanned aerial vehicles (UAVs) are capable of serving as flying base
stations (BSs) for supporting data collection, artificial intelligence (AI)
model training, and wireless communications. However, due to the privacy
concerns of devices and limited computation or communication resource of UAVs,
it is impractical to send raw data of devices to UAV servers for model
training. Moreover, due to the dynamic channel condition and heterogeneous
computing capacity of devices in UAV-enabled networks, the reliability and
efficiency of data sharing require to be further improved. In this paper, we
develop an asynchronous federated learning (AFL) framework for
multi-UAV-enabled networks, which can provide asynchronous distributed
computing by enabling model training locally without transmitting raw sensitive
data to UAV servers. The device selection strategy is also introduced into the
AFL framework to keep the low-quality devices from affecting the learning
efficiency and accuracy. Moreover, we propose an asynchronous advantage
actor-critic (A3C) based joint device selection, UAVs placement, and resource
management algorithm to enhance the federated convergence speed and accuracy.
Simulation results demonstrate that our proposed framework and algorithm
achieve higher learning accuracy and faster federated execution time compared
to other existing solutions.",arxiv
http://arxiv.org/abs/2101.03613v1,2021-01-10T19:49:12Z,2021-01-10T19:49:12Z,Explainable Artificial Intelligence (XAI): An Engineering Perspective,"The remarkable advancements in Deep Learning (DL) algorithms have fueled
enthusiasm for using Artificial Intelligence (AI) technologies in almost every
domain; however, the opaqueness of these algorithms put a question mark on
their applications in safety-critical systems. In this regard, the
`explainability' dimension is not only essential to both explain the inner
workings of black-box algorithms, but it also adds accountability and
transparency dimensions that are of prime importance for regulators, consumers,
and service providers. eXplainable Artificial Intelligence (XAI) is the set of
techniques and methods to convert the so-called black-box AI algorithms to
white-box algorithms, where the results achieved by these algorithms and the
variables, parameters, and steps taken by the algorithm to reach the obtained
results, are transparent and explainable. To complement the existing literature
on XAI, in this paper, we take an `engineering' approach to illustrate the
concepts of XAI. We discuss the stakeholders in XAI and describe the
mathematical contours of XAI from engineering perspective. Then we take the
autonomous car as a use-case and discuss the applications of XAI for its
different components such as object detection, perception, control, action
decision, and so on. This work is an exploratory study to identify new avenues
of research in the field of XAI.",arxiv
http://arxiv.org/abs/1803.07250v2,2018-09-16T05:27:12Z,2018-03-20T04:24:23Z,"Cooperative and Distributed Reinforcement Learning of Drones for Field
  Coverage","This paper proposes a distributed Multi-Agent Reinforcement Learning (MARL)
algorithm for a team of Unmanned Aerial Vehicles (UAVs). The proposed MARL
algorithm allows UAVs to learn cooperatively to provide a full coverage of an
unknown field of interest while minimizing the overlapping sections among their
field of views. Two challenges in MARL for such a system are discussed in the
paper: firstly, the complex dynamic of the joint-actions of the UAV team, that
will be solved using game-theoretic correlated equilibrium, and secondly, the
challenge in huge dimensional state space representation will be tackled with
efficient function approximation techniques. We also provide our experimental
results in detail with both simulation and physical implementation to show that
the UAV team can successfully learn to accomplish the task.",arxiv
http://arxiv.org/abs/1905.03440v1,2019-05-09T04:48:11Z,2019-05-09T04:48:11Z,Path Design for Cellular-Connected UAV with Reinforcement Learning,"This paper studies the path design problem for cellular-connected unmanned
aerial vehicle (UAV), which aims to minimize its mission completion time while
maintaining good connectivity with the cellular network. We first argue that
the conventional path design approach via formulating and solving optimization
problems faces several practical challenges, and then propose a new
reinforcement learning-based UAV path design algorithm by applying
\emph{temporal-difference} method to directly learn the \emph{state-value
function} of the corresponding Markov Decision Process. The proposed algorithm
is further extended by using linear function approximation with tile coding to
deal with large state space. The proposed algorithms only require the raw
measured or simulation-generated signal strength as the input and are suitable
for both online and offline implementations. Numerical results show that the
proposed path designs can successfully avoid the coverage holes of cellular
networks even in the complex urban environment.",arxiv
http://arxiv.org/abs/2003.00391v1,2020-03-01T03:42:26Z,2020-03-01T03:42:26Z,"Deep Reinforcement Learning for Fresh Data Collection in UAV-assisted
  IoT Networks","Due to the flexibility and low operational cost, dispatching unmanned aerial
vehicles (UAVs) to collect information from distributed sensors is expected to
be a promising solution in Internet of Things (IoT), especially for
time-critical applications. How to maintain the information freshness is a
challenging issue. In this paper, we investigate the fresh data collection
problem in UAV-assisted IoT networks. Particularly, the UAV flies towards the
sensors to collect status update packets within a given duration while
maintaining a non-negative residual energy. We formulate a Markov Decision
Process (MDP) to find the optimal flight trajectory of the UAV and transmission
scheduling of the sensors that minimizes the weighted sum of the age of
information (AoI). A UAV-assisted data collection algorithm based on deep
reinforcement learning (DRL) is further proposed to overcome the curse of
dimensionality. Extensive simulation results demonstrate that the proposed
DRL-based algorithm can significantly reduce the weighted sum of the AoI
compared to other baseline algorithms.",arxiv
http://arxiv.org/abs/2004.01920v1,2020-04-04T12:44:55Z,2020-04-04T12:44:55Z,Beyond D2D: Full Dimension UAV-to-Everything Communications in 6G,"In this paper, we consider an Internet of unmanned aerial vehicles (UAVs)
over cellular networks, where UAVs work as aerial users to collect various
sensory data, and send the collected data to their transmission destinations
over cellular links. Unlike the terrestrial users in the conventional cellular
networks, different UAVs have various communication requirements due to their
sensing applications, and a more flexible communication framework is in demand.
To tackle this problem, we propose a UAV-to-Everything (U2X) networking, which
enables the UAVs to adjust their communication modes full dimensionally
according to the requirements of their sensing applications. In this article,
we first introduce the concept of U2X communications, and elaborate on its
three communication modes. Afterwards, we discuss the key techniques of the U2X
communications, including joint sensing and transmission protocol, UAV
trajectory design, and radio resource management. A reinforcement
learning-based mathematical framework for U2X communications is then proposed.
Finally, the extensions of the U2X communications are presented.",arxiv
http://arxiv.org/abs/2005.05057v1,2020-05-05T20:39:18Z,2020-05-05T20:39:18Z,"Reinforcement Learning for UAV Autonomous Navigation, Mapping and Target
  Detection","In this paper, we study a joint detection, mapping and navigation problem for
a single unmanned aerial vehicle (UAV) equipped with a low complexity radar and
flying in an unknown environment. The goal is to optimize its trajectory with
the purpose of maximizing the mapping accuracy and, at the same time, to avoid
areas where measurements might not be sufficiently informative from the
perspective of a target detection. This problem is formulated as a Markov
decision process (MDP) where the UAV is an agent that runs either a state
estimator for target detection and for environment mapping, and a reinforcement
learning (RL) algorithm to infer its own policy of navigation (i.e., the
control law). Numerical results show the feasibility of the proposed idea,
highlighting the UAV's capability of autonomously exploring areas with high
probability of target detection while reconstructing the surrounding
environment.",arxiv
http://arxiv.org/abs/2005.12521v1,2020-05-26T05:39:27Z,2020-05-26T05:39:27Z,"Integrating LEO Satellite and UAV Relaying via Reinforcement Learning
  for Non-Terrestrial Networks","A mega-constellation of low-earth orbit (LEO) satellites has the potential to
enable long-range communication with low latency. Integrating this with
burgeoning unmanned aerial vehicle (UAV) assisted non-terrestrial networks will
be a disruptive solution for beyond 5G systems provisioning large scale
three-dimensional connectivity. In this article, we study the problem of
forwarding packets between two faraway ground terminals, through an LEO
satellite selected from an orbiting constellation and a mobile high-altitude
platform (HAP) such as a fixed-wing UAV. To maximize the end-to-end data rate,
the satellite association and HAP location should be optimized, which is
challenging due to a huge number of orbiting satellites and the resulting
time-varying network topology. We tackle this problem using deep reinforcement
learning (DRL) with a novel action dimension reduction technique. Simulation
results corroborate that our proposed method achieves up to 5.74x higher
average data rate compared to a direct communication baseline without SAT and
HAP.",arxiv
http://arxiv.org/abs/2009.03721v1,2020-08-19T21:41:34Z,2020-08-19T21:41:34Z,DDPG-based Resource Management for MEC/UAV-Assisted Vehicular Networks,"In this paper, we investigate joint vehicle association and multi-dimensional
resource management in a vehicular network assisted by multi-access edge
computing (MEC) and unmanned aerial vehicle (UAV). To efficiently manage the
available spectrum, computing, and caching resources for the MEC-mounted base
station and UAVs, a resource optimization problem is formulated and carried out
at a central controller. Considering the overlong solving time of the
formulated problem and the sensitive delay requirements of vehicular
applications, we transform the optimization problem using reinforcement
learning and then design a deep deterministic policy gradient (DDPG)-based
solution. Through training the DDPG-based resource management model offline,
optimal vehicle association and resource allocation decisions can be obtained
rapidly. Simulation results demonstrate that the DDPG-based resource management
scheme can converge within 200 episodes and achieve higher
delay/quality-of-service satisfaction ratios than the random scheme.",arxiv
http://arxiv.org/abs/2010.02293v1,2020-10-05T19:16:57Z,2020-10-05T19:16:57Z,Using Soft Actor-Critic for Low-Level UAV Control,"Unmanned Aerial Vehicles (UAVs), or drones, have recently been used in
several civil application domains from organ delivery to remote locations to
wireless network coverage. These platforms, however, are naturally unstable
systems for which many different control approaches have been proposed.
Generally based on classic and modern control, these algorithms require
knowledge of the robot's dynamics. However, recently, model-free reinforcement
learning has been successfully used for controlling drones without any prior
knowledge of the robot model. In this work, we present a framework to train the
Soft Actor-Critic (SAC) algorithm to low-level control of a quadrotor in a
go-to-target task. All experiments were conducted under simulation. With the
experiments, we show that SAC can not only learn a robust policy, but it can
also cope with unseen scenarios. Videos from the simulations are available in
https://www.youtube.com/watch?v=9z8vGs0Ri5g and the code in
https://github.com/larocs/SAC_uav.",arxiv
http://arxiv.org/abs/2010.02663v1,2020-10-06T12:23:05Z,2020-10-06T12:23:05Z,"Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment
  Mapping","Reinforcement learning in heterogeneous multi-agent scenarios is important
for real-world applications but presents challenges beyond those seen in
homogeneous settings and simple benchmarks. In this work, we present an
actor-critic algorithm that allows a team of heterogeneous agents to learn
decentralized control policies for covering an unknown environment. This task
is of interest to national security and emergency response organizations that
would like to enhance situational awareness in hazardous areas by deploying
teams of unmanned aerial vehicles. To solve this multi-agent coverage path
planning problem in unknown environments, we augment a multi-agent actor-critic
architecture with a new state encoding structure and triplet learning loss to
support heterogeneous agent learning. We developed a simulation environment
that includes real-world environmental factors such as turbulence, delayed
communication, and agent loss, to train teams of agents as well as probe their
robustness and flexibility to such disturbances.",arxiv
http://arxiv.org/abs/2105.10716v1,2021-05-22T12:43:25Z,2021-05-22T12:43:25Z,"Attention-based Reinforcement Learning for Real-Time UAV Semantic
  Communication","In this article, we study the problem of air-to-ground ultra-reliable and
low-latency communication (URLLC) for a moving ground user. This is done by
controlling multiple unmanned aerial vehicles (UAVs) in real time while
avoiding inter-UAV collisions. To this end, we propose a novel multi-agent deep
reinforcement learning (MADRL) framework, coined a graph attention exchange
network (GAXNet). In GAXNet, each UAV constructs an attention graph locally
measuring the level of attention to its neighboring UAVs, while exchanging the
attention weights with other UAVs so as to reduce the attention mismatch
between them. Simulation results corroborates that GAXNet achieves up to 4.5x
higher rewards during training. At execution, without incurring inter-UAV
collisions, GAXNet achieves 6.5x lower latency with the target 0.0000001 error
rate, compared to a state-of-the-art baseline framework.",arxiv
http://arxiv.org/abs/2105.14142v2,2021-08-05T23:49:12Z,2021-05-28T23:23:46Z,"Reconfigurable Intelligent Surface-assisted Multi-UAV Networks:
  Efficient Resource Allocation with Deep Reinforcement Learning","In this paper, we propose reconfigurable intelligent surface (RIS)-assisted
unmanned aerial vehicles (UAVs) networks that can utilise both advantages of
UAV's agility and RIS's reflection for enhancing the network's performance. To
aim at maximising the energy efficiency (EE) of the considered networks, we
jointly optimise the power allocation of the UAVs and the phase-shift matrix of
the RIS. A deep reinforcement learning (DRL) approach is proposed for solving
the continuous optimisation problem with time-varying channels in a centralised
fashion. Moreover, a parallel learning approach is also proposed for reducing
the information transmission requirement of the centralised approach. Numerical
results show a significant improvement of our proposed schemes compared with
the conventional approaches in terms of EE, flexibility, and processing time.
Our proposed DRL methods for RIS-assisted UAV networks can be used for
real-time applications due to their capability of instant decision-making and
handling the time-varying channel with the dynamic environmental setting.",arxiv
http://arxiv.org/abs/2108.13184v2,2021-09-16T23:02:12Z,2021-08-30T12:41:43Z,"Path Planning for Cellular-Connected UAV: A DRL Solution with
  Quantum-Inspired Experience Replay","In cellular-connected unmanned aerial vehicle (UAV) network, a minimization
problem on the weighted sum of time cost and expected outage duration is
considered. Taking advantage of UAV's adjustable mobility, an intelligent UAV
navigation approach is formulated to achieve the aforementioned optimization
goal. Specifically, after mapping the navigation task into a Markov decision
process (MDP), a deep reinforcement learning (DRL) solution with novel
quantum-inspired experience replay (QiER) framework is proposed to help the UAV
find the optimal flying direction within each time slot, and thus the designed
trajectory towards the destination can be generated. Via relating experienced
transition's importance to its associated quantum bit (qubit) and applying
Grover iteration based amplitude amplification technique, the proposed DRL-QiER
solution commits a better trade-off between sampling priority and diversity.
Compared to several representative baselines, the effectiveness and supremacy
of the proposed DRL-QiER solution are demonstrated and validated in numerical
results.",arxiv
http://arxiv.org/abs/2109.05767v1,2021-09-13T08:15:41Z,2021-09-13T08:15:41Z,"Computation Rate Maximum for Mobile Terminals in UAV-assisted Wireless
  Powered MEC Networks with Fairness Constraint","This paper investigates an unmanned aerial vehicle (UAV)-assisted wireless
powered mobile-edge computing (MEC) system, where the UAV powers the mobile
terminals by wireless power transfer (WPT) and provides computation service for
them. We aim to maximize the computation rate of terminals while ensuring
fairness among them. Considering the random trajectories of mobile terminals,
we propose a soft actor-critic (SAC)-based UAV trajectory planning and resource
allocation (SAC-TR) algorithm, which combines off-policy and maximum entropy
reinforcement learning to promote the convergence of the algorithm. We design
the reward as a heterogeneous function of computation rate, fairness, and
reaching of destination. Simulation results show that SAC-TR can quickly adapt
to varying network environments and outperform representative benchmarks in a
variety of situations.",arxiv
http://arxiv.org/abs/2104.14006v1,2021-04-28T20:24:10Z,2021-04-28T20:24:10Z,"EmergencyNet: Efficient Aerial Image Classification for Drone-Based
  Emergency Monitoring Using Atrous Convolutional Feature Fusion","Deep learning-based algorithms can provide state-of-the-art accuracy for
remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones,
potentially enhancing their remote sensing capabilities for many emergency
response and disaster management applications. In particular, UAVs equipped
with camera sensors can operating in remote and difficult to access
disaster-stricken areas, analyze the image and alert in the presence of various
calamities such as collapsed buildings, flood, or fire in order to faster
mitigate their effects on the environment and on human population. However, the
integration of deep learning introduces heavy computational requirements,
preventing the deployment of such deep neural networks in many scenarios that
impose low-latency constraints on inference, in order to make mission-critical
decisions in real time. To this end, this article focuses on the efficient
aerial image classification from on-board a UAV for emergency
response/monitoring applications. Specifically, a dedicated Aerial Image
Database for Emergency Response applications is introduced and a comparative
analysis of existing approaches is performed. Through this analysis a
lightweight convolutional neural network architecture is proposed, referred to
as EmergencyNet, based on atrous convolutions to process multiresolution
features and capable of running efficiently on low-power embedded platforms
achieving upto 20x higher performance compared to existing models with minimal
memory requirements with less than 1% accuracy drop compared to
state-of-the-art models.",arxiv
http://arxiv.org/abs/2009.01708v1,2020-09-03T14:37:57Z,2020-09-03T14:37:57Z,"VddNet: Vine Disease Detection Network Based on Multispectral Images and
  Depth Map","Early detection of vine disease is important to avoid spread of virus or
fungi. Disease propagation can lead to a huge loss of grape production and
disastrous economic consequences, therefore the problem represents a challenge
for the precision farming. In this paper, we present a new system for vine
disease detection. The article contains two contributions: the first one is an
automatic orthophotos registration method from multispectral images acquired
with an unmanned aerial vehicle (UAV). The second one is a new deep learning
architecture called VddNet (Vine Disease Detection Network). The proposed
architecture is assessed by comparing it with the most known architectures:
SegNet, U-Net, DeepLabv3+ and PSPNet. The deep learning architectures were
trained on multispectral data and depth map information. The results of the
proposed architecture show that the VddNet architecture achieves higher scores
than the base line methods. Moreover, this study demonstrates that the proposed
system has many advantages compared to methods that directly use the UAV
images.",arxiv
http://arxiv.org/abs/2010.12108v1,2020-10-22T23:25:43Z,2020-10-22T23:25:43Z,GPS-Denied Navigation Using SAR Images and Neural Networks,"Unmanned aerial vehicles (UAV) often rely on GPS for navigation. GPS signals,
however, are very low in power and easily jammed or otherwise disrupted. This
paper presents a method for determining the navigation errors present at the
beginning of a GPS-denied period utilizing data from a synthetic aperture radar
(SAR) system. This is accomplished by comparing an online-generated SAR image
with a reference image obtained a priori. The distortions relative to the
reference image are learned and exploited with a convolutional neural network
to recover the initial navigational errors, which can be used to recover the
true flight trajectory throughout the synthetic aperture. The proposed neural
network approach is able to learn to predict the initial errors on both
simulated and real SAR image data.",arxiv
http://arxiv.org/abs/2011.02853v1,2020-11-05T14:26:29Z,2020-11-05T14:26:29Z,"UAV-AdNet: Unsupervised Anomaly Detection using Deep Neural Networks for
  Aerial Surveillance","Anomaly detection is a key goal of autonomous surveillance systems that
should be able to alert unusual observations. In this paper, we propose a
holistic anomaly detection system using deep neural networks for surveillance
of critical infrastructures (e.g., airports, harbors, warehouses) using an
unmanned aerial vehicle (UAV). First, we present a heuristic method for the
explicit representation of spatial layouts of objects in bird-view images.
Then, we propose a deep neural network architecture for unsupervised anomaly
detection (UAV-AdNet), which is trained on environment representations and GPS
labels of bird-view images jointly. Unlike studies in the literature, we
combine GPS and image data to predict abnormal observations. We evaluate our
model against several baselines on our aerial surveillance dataset and show
that it performs better in scene reconstruction and several anomaly detection
tasks. The codes, trained models, dataset, and video will be available at
https://bozcani.github.io/uavadnet.",arxiv
http://arxiv.org/abs/2106.07003v1,2021-06-13T14:23:18Z,2021-06-13T14:23:18Z,"Experimental Analysis of Trajectory Control Using Computer Vision and
  Artificial Intelligence for Autonomous Vehicles","Perception of the lane boundaries is crucial for the tasks related to
autonomous trajectory control. In this paper, several methodologies for lane
detection are discussed with an experimental illustration: Hough
transformation, Blob analysis, and Bird's eye view. Following the abstraction
of lane marks from the boundary, the next approach is applying a control law
based on the perception to control steering and speed control. In the
following, a comparative analysis is made between an open-loop response, PID
control, and a neural network control law through graphical statistics. To get
the perception of the surrounding a wireless streaming camera connected to
Raspberry Pi is used. After pre-processing the signal received by the camera
the output is sent back to the Raspberry Pi that processes the input and
communicates the control to the motors through Arduino via serial
communication.",arxiv
http://arxiv.org/abs/1911.06073v1,2019-11-14T12:50:27Z,2019-11-14T12:50:27Z,"Efficient ConvNet-based Object Detection for Unmanned Aerial Vehicles by
  Selective Tile Processing","Many applications utilizing Unmanned Aerial Vehicles (UAVs) require the use
of computer vision algorithms to analyze the information captured from their
on-board camera. Recent advances in deep learning have made it possible to use
single-shot Convolutional Neural Network (CNN) detection algorithms that
process the input image to detect various objects of interest. To keep the
computational demands low these neural networks typically operate on small
image sizes which, however, makes it difficult to detect small objects. This is
further emphasized when considering UAVs equipped with cameras where due to the
viewing range, objects tend to appear relatively small. This paper therefore,
explores the trade-offs involved when maintaining the resolution of the objects
of interest by extracting smaller patches (tiles) from the larger input image
and processing them using a neural network. Specifically, we introduce an
attention mechanism to focus on detecting objects only in some of the tiles and
a memory mechanism to keep track of information for tiles that are not
processed. Through the analysis of different methods and experiments we show
that by carefully selecting which tiles to process we can considerably improve
the detection accuracy while maintaining comparable performance to CNNs that
resize and process a single image which makes the proposed approach suitable
for UAV applications.",arxiv
http://arxiv.org/abs/1805.00061v1,2018-04-30T19:08:53Z,2018-04-30T19:08:53Z,"Machine Learning for Predictive On-Demand Deployment of UAVs for
  Wireless Communications","In this paper, a novel machine learning (ML) framework is proposed for
enabling a predictive, efficient deployment of unmanned aerial vehicles (UAVs),
acting as aerial base stations (BSs), to provide on-demand wireless service to
cellular users. In order to have a comprehensive analysis of cellular traffic,
an ML framework based on a Gaussian mixture model (GMM) and a weighted
expectation maximization (WEM) algorithm is introduced to predict the potential
network congestion. Then, the optimal deployment of UAVs is studied to minimize
the transmit power needed to satisfy the communication demand of users in the
downlink, while also minimizing the power needed for UAV mobility, based on the
predicted cellular traffic. To this end, first, the optimal partition of
service areas of each UAV is derived, based on a fairness principle. Next, the
optimal location of each UAV that minimizes the total power consumption is
derived. Simulation results show that the proposed ML approach can reduce the
required downlink transmit power and improve the power efficiency by over 20%,
compared with an optimal deployment of UAVs with no ML prediction.",arxiv
http://arxiv.org/abs/1905.04152v1,2019-05-10T13:07:00Z,2019-05-10T13:07:00Z,"Massive Autonomous UAV Path Planning: A Neural Network Based Mean-Field
  Game Theoretic Approach","This paper investigates the autonomous control of massive unmanned aerial
vehicles (UAVs) for mission-critical applications (e.g., dispatching many UAVs
from a source to a destination for firefighting). Achieving their fast travel
and low motion energy without inter-UAV collision under wind perturbation is a
daunting control task, which incurs huge communication energy for exchanging
UAV states in real time. We tackle this problem by exploiting a mean-field game
(MFG) theoretic control method that requires the UAV state exchanges only once
at the initial source. Afterwards, each UAV can control its acceleration by
locally solving two partial differential equations (PDEs), known as the
Hamilton-Jacobi-Bellman (HJB) and Fokker-Planck-Kolmogorov (FPK) equations.
This approach, however, brings about huge computation energy for solving the
PDEs, particularly under multi-dimensional UAV states. We address this issue by
utilizing a machine learning (ML) method where two separate ML models
approximate the solutions of the HJB and FPK equations. These ML models are
trained and exploited using an online gradient descent method with low
computational complexity. Numerical evaluations validate that the proposed ML
aided MFG theoretic algorithm, referred to as MFG learning control, is
effective in collision avoidance with low communication energy and acceptable
computation energy.",arxiv
http://arxiv.org/abs/1411.6326v1,2014-11-24T02:09:59Z,2014-11-24T02:09:59Z,Vision and Learning for Deliberative Monocular Cluttered Flight,"Cameras provide a rich source of information while being passive, cheap and
lightweight for small and medium Unmanned Aerial Vehicles (UAVs). In this work
we present the first implementation of receding horizon control, which is
widely used in ground vehicles, with monocular vision as the only sensing mode
for autonomous UAV flight in dense clutter. We make it feasible on UAVs via a
number of contributions: novel coupling of perception and control via relevant
and diverse, multiple interpretations of the scene around the robot, leveraging
recent advances in machine learning to showcase anytime budgeted cost-sensitive
feature selection, and fast non-linear regression for monocular depth
prediction. We empirically demonstrate the efficacy of our novel pipeline via
real world experiments of more than 2 kms through dense trees with a quadrotor
built from off-the-shelf parts. Moreover our pipeline is designed to combine
information from other modalities like stereo and lidar as well if available.",arxiv
http://arxiv.org/abs/1709.01722v1,2017-09-06T08:45:09Z,2017-09-06T08:45:09Z,Detecting animals in African Savanna with UAVs and the crowds,"Unmanned aerial vehicles (UAVs) offer new opportunities for wildlife
monitoring, with several advantages over traditional field-based methods. They
have readily been used to count birds, marine mammals and large herbivores in
different environments, tasks which are routinely performed through manual
counting in large collections of images. In this paper, we propose a
semi-automatic system able to detect large mammals in semi-arid Savanna. It
relies on an animal-detection system based on machine learning, trained with
crowd-sourced annotations provided by volunteers who manually interpreted
sub-decimeter resolution color images. The system achieves a high recall rate
and a human operator can then eliminate false detections with limited effort.
Our system provides good perspectives for the development of data-driven
management practices in wildlife conservation. It shows that the detection of
large mammals in semi-arid Savanna can be approached by processing data
provided by standard RGB cameras mounted on affordable fixed wings UAVs.",arxiv
http://arxiv.org/abs/1809.05767v1,2018-09-15T20:45:20Z,2018-09-15T20:45:20Z,UAV Communications Based on Non-Orthogonal Multiple Access,"This article proposes a novel framework for unmaned aerial vehicle (UAV)
networks with massive access capability supported by non-orthogonal multiple
access (NOMA). In order to better understand NOMA enabled UAV networks, three
case studies are carried out. We first provide performance evaluation of NOMA
enabled UAV networks by adopting stochastic geometry to model the positions of
UAVs and ground users. Then we investigate the joint trajectory design and
power allocation for static NOMA users based on a simplified two-dimensional
(2D) model that UAV is flying around at fixed height. As a further advance, we
demonstrate the UAV placement issue with the aid of machine learning techniques
when the ground users are roaming and the UAVs are capable of adjusting their
positions in three-dimensions (3D) accordingly. With these case studies, we can
comprehensively understand the UAV systems from fundamental theory to practical
implementation.",arxiv
http://arxiv.org/abs/1903.03947v1,2019-03-10T07:59:01Z,2019-03-10T07:59:01Z,"Object recognition and tracking using Haar-like Features Cascade
  Classifiers: Application to a quad-rotor UAV","In this paper, we develop a functional Unmanned Aerial Vehicle (UAV), capable
of tracking an object using a Machine Learning-like vision system called Haar
feature-based cascade classifier. The image processing is made on-board with a
high processor single-board computer. Based on the detected object and its
position, the quadrotor must track it in order to be in a centered position and
in a safe distance to it. The object in question is a human face; the
experiments were conducted in a two-step detection, searching first for the
upper-body and then searching for the face inside of the human body detected
area. Once the human face is detected the quadrotor must follow it
automatically. Experiments were conducted which shows the effectiveness of our
mythology; these results are showing in a video.",arxiv
http://arxiv.org/abs/1905.03988v1,2019-05-10T07:49:54Z,2019-05-10T07:49:54Z,"Non-cooperative Aerial Base Station Placement via Stochastic
  Optimization","Autonomous unmanned aerial vehicles (UAVs) with on-board base station
equipment can potentially provide connectivity in areas where the terrestrial
infrastructure is overloaded, damaged, or absent. Use cases comprise emergency
response, wildfire suppression, surveillance, and cellular communications in
crowded events to name a few. A central problem to enable this technology is to
place such aerial base stations (AirBSs) in locations that approximately
optimize the relevant communication metrics. To alleviate the limitations of
existing algorithms, which require intensive and reliable communications among
AirBSs or between the AirBSs and a central controller, this paper leverages
stochastic optimization and machine learning techniques to put forth an
adaptive and decentralized algorithm for AirBS placement without inter-AirBS
cooperation or communication. The approach relies on a smart design of the
network utility function and on a stochastic gradient ascent iteration that can
be evaluated with information available in practical scenarios. To complement
the theoretical convergence properties, a simulation study corroborates the
effectiveness of the proposed scheme.",arxiv
http://arxiv.org/abs/2108.10748v1,2021-08-23T16:10:14Z,2021-08-23T16:10:14Z,"Federated Learning for UAV Swarms Under Class Imbalance and Power
  Consumption Constraints","The usage of unmanned aerial vehicles (UAVs) in civil and military
applications continues to increase due to the numerous advantages that they
provide over conventional approaches. Despite the abundance of such advantages,
it is imperative to investigate the performance of UAV utilization while
considering their design limitations. This paper investigates the deployment of
UAV swarms when each UAV carries a machine learning classification task. To
avoid data exchange with ground-based processing nodes, a federated learning
approach is adopted between a UAV leader and the swarm members to improve the
local learning model while avoiding excessive air-to-ground and ground-to-air
communications. Moreover, the proposed deployment framework considers the
stringent energy constraints of UAVs and the problem of class imbalance, where
we show that considering these design parameters significantly improves the
performances of the UAV swarm in terms of classification accuracy, energy
consumption and availability of UAVs when compared with several baseline
algorithms.",arxiv
http://arxiv.org/abs/2012.06058v1,2020-12-11T00:50:09Z,2020-12-11T00:50:09Z,"Next Wave Artificial Intelligence: Robust, Explainable, Adaptable,
  Ethical, and Accountable","The history of AI has included several ""waves"" of ideas. The first wave, from
the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded
representations of knowledge, the foundations of so-called ""expert systems"".
The second wave, starting in the 1990s, focused on statistics and machine
learning, in which, instead of hand-programming rules for behavior, programmers
constructed ""statistical learning algorithms"" that could be trained on large
datasets. In the most recent wave research in AI has largely focused on deep
(i.e., many-layered) neural networks, which are loosely inspired by the brain
and trained by ""deep learning"" methods. However, while deep neural networks
have led to many successes and new capabilities in computer vision, speech
recognition, language processing, game-playing, and robotics, their potential
for broad application remains limited by several factors.
  A concerning limitation is that even the most successful of today's AI
systems suffer from brittleness-they can fail in unexpected ways when faced
with situations that differ sufficiently from ones they have been trained on.
This lack of robustness also appears in the vulnerability of AI systems to
adversarial attacks, in which an adversary can subtly manipulate data in a way
to guarantee a specific wrong answer or action from an AI system. AI systems
also can absorb biases-based on gender, race, or other factors-from their
training data and further magnify these biases in their subsequent
decision-making. Taken together, these various limitations have prevented AI
systems such as automatic medical diagnosis or autonomous vehicles from being
sufficiently trustworthy for wide deployment. The massive proliferation of AI
across society will require radically new ideas to yield technology that will
not sacrifice our productivity, our quality of life, or our values.",arxiv
http://arxiv.org/abs/1906.10971v1,2019-06-26T11:05:18Z,2019-06-26T11:05:18Z,"NeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory
  Learning for Autonomous Vehicles","Autonomous vehicles are controlled today either based on sequences of
decoupled perception-planning-action operations, either based on End2End or
Deep Reinforcement Learning (DRL) systems. Current deep learning solutions for
autonomous driving are subject to several limitations (e.g. they estimate
driving actions through a direct mapping of sensors to actuators, or require
complex reward shaping methods). Although the cost function used for training
can aggregate multiple weighted objectives, the gradient descent step is
computed by the backpropagation algorithm using a single-objective loss. To
address these issues, we introduce NeuroTrajectory, which is a multi-objective
neuroevolutionary approach to local state trajectory learning for autonomous
driving, where the desired state trajectory of the ego-vehicle is estimated
over a finite prediction horizon by a perception-planning deep neural network.
In comparison to DRL methods, which predict optimal actions for the upcoming
sampling time, we estimate a sequence of optimal states that can be used for
motion control. We propose an approach which uses genetic algorithms for
training a population of deep neural networks, where each network individual is
evaluated based on a multi-objective fitness vector, with the purpose of
establishing a so-called Pareto front of optimal deep neural networks. The
performance of an individual is given by a fitness vector composed of three
elements. Each element describes the vehicle's travel path, lateral velocity
and longitudinal speed, respectively. The same network structure can be trained
on synthetic, as well as on real-world data sequences. We have benchmarked our
system against a baseline Dynamic Window Approach (DWA), as well as against an
End2End supervised learning method.",arxiv
http://arxiv.org/abs/1910.05309v1,2019-09-25T16:22:29Z,2019-09-25T16:22:29Z,"Communications and Networking Technologies for Intelligent Drone
  Cruisers","Future mobile communication networks require an Aerial Base Station (ABS)
with fast mobility and long-term hovering capabilities. At present, unmanned
aerial vehicles (UAV) or drones do not have long flight times and are mainly
used for monitoring, surveillance, and image post-processing. On the other
hand, the traditional airship is too large and not easy to take off and land.
Therefore, we propose to develop an ""Artificial Intelligence (AI)
Drone-Cruiser"" base station that can help 5G mobile communication systems and
beyond quickly recover the network after a disaster and handle the instant
communications by the flash crowd. The drone-cruiser base station can overcome
the communications problem for three types of flash crowds, such as in
stadiums, parades, and large plaza so that an appropriate number of aerial base
stations can be accurately deployed to meet large and dynamic traffic demands.
Artificial intelligence can solve these problems by analyzing the collected
data, and then adjust the system parameters in the framework of Self-Organizing
Network (SON) to achieve the goals of self-configuration, self-optimization,
and self-healing. With the help of AI technologies, 5G networks can become more
intelligent. This paper aims to provide a new type of service, On-Demand Aerial
Base Station as a Service. This work needs to overcome the following five
technical challenges: innovative design of drone-cruisers for the long-time
hovering, crowd estimation and prediction, rapid 3D wireless channel learning
and modeling, 3D placement of aerial base stations and the integration of WiFi
front-haul and millimeter wave/WiGig back-haul networks.",arxiv
http://arxiv.org/abs/2109.07601v1,2021-09-15T22:22:38Z,2021-09-15T22:22:38Z,"A Column Streaming-Based Convolution Engine and Mapping Algorithm for
  CNN-based Edge AI accelerators","Edge AI accelerators have been emerging as a solution for near customers'
applications in areas such as unmanned aerial vehicles (UAVs), image
recognition sensors, wearable devices, robotics, and remote sensing satellites.
These applications not only require meeting performance targets but also
meeting strict area and power constraints due to their portable mobility
feature and limited power sources. As a result, a column streaming-based
convolution engine has been proposed in this paper that includes column sets of
processing elements design for flexibility in terms of the applicability for
different CNN algorithms in edge AI accelerators. Comparing to a commercialized
CNN accelerator, the key results reveal that the column streaming-based
convolution engine requires similar execution cycles for processing a 227 x 227
feature map with avoiding zero-padding penalties.",arxiv
http://arxiv.org/abs/1903.03275v1,2019-03-08T04:09:54Z,2019-03-08T04:09:54Z,"Below Horizon Aircraft Detection Using Deep Learning for Vision-Based
  Sense and Avoid","Commercial operation of unmanned aerial vehicles (UAVs) would benefit from an
onboard ability to sense and avoid (SAA) potential mid-air collision threats.
In this paper we present a new approach for detection of aircraft below the
horizon. We address some of the challenges faced by existing vision-based SAA
methods such as detecting stationary aircraft (that have no relative motion to
the background), rejecting moving ground vehicles, and simultaneous detection
of multiple aircraft. We propose a multi-stage, vision-based aircraft detection
system which utilises deep learning to produce candidate aircraft that we track
over time. We evaluate the performance of our proposed system on real flight
data where we demonstrate detection ranges comparable to the state of the art
with the additional capability of detecting stationary aircraft, rejecting
moving ground vehicles, and tracking multiple aircraft.",arxiv
http://arxiv.org/abs/2002.03510v2,2020-03-02T09:09:03Z,2020-02-10T03:09:17Z,"Autonomous quadrotor obstacle avoidance based on dueling double deep
  recurrent Q-learning with monocular vision","The rapid development of unmanned aerial vehicles (UAV) puts forward a higher
requirement for autonomous obstacle avoidance. Due to the limited payload and
power supply, small UAVs such as quadrotors usually carry simple sensors and
computation units, which makes traditional methods more challenging to
implement. In this paper, a novel framework is demonstrated to control a
quadrotor flying through crowded environments autonomously with monocular
vision. The framework adopts a two-stage architecture, consisting of a sensing
module and a decision module. The sensing module is based on an unsupervised
deep learning method. And the decision module uses dueling double deep
recurrent Q-learning to eliminate the adverse effects of limited observation
capacity of an on-board monocular camera. The framework enables the quadrotor
to realize autonomous obstacle avoidance without any prior environment
information or labeled datasets for training. The trained model shows a high
success rate in the simulation and a good generalization ability for
transformed scenarios.",arxiv
http://arxiv.org/abs/2004.02758v1,2020-03-19T00:40:48Z,2020-03-19T00:40:48Z,Towards Detection of Sheep Onboard a UAV,"In this work we consider the task of detecting sheep onboard an unmanned
aerial vehicle (UAV) flying at an altitude of 80 m. At this height, the sheep
are relatively small, only about 15 pixels across. Although deep learning
strategies have gained enormous popularity in the last decade and are now
extensively used for object detection in many fields, state-of-the-art
detectors perform poorly in the case of smaller objects. We develop a novel
dataset of UAV imagery of sheep and consider a variety of object detectors to
determine which is the most suitable for our task in terms of both accuracy and
speed. Our findings indicate that a UNet detector using the weighted Hausdorff
distance as a loss function during training is an excellent option for
detection of sheep onboard a UAV.",arxiv
http://arxiv.org/abs/2008.04619v1,2020-08-11T10:54:36Z,2020-08-11T10:54:36Z,Deep UAV Localization with Reference View Rendering,"This paper presents a framework for the localization of Unmanned Aerial
Vehicles (UAVs) in unstructured environments with the help of deep learning. A
real-time rendering engine is introduced that generates optical and depth
images given a six Degrees-of-Freedom (DoF) camera pose, camera model,
geo-referenced orthoimage, and elevation map. The rendering engine is embedded
into a learning-based six-DoF Inverse Compositional Lucas-Kanade (ICLK)
algorithm that is able to robustly align the rendered and real-world image
taken by the UAV. To learn the alignment under environmental changes, the
architecture is trained using maps spanning multiple years at high resolution.
The evaluation shows that the deep 6DoF-ICLK algorithm outperforms its
non-trainable counterparts by a large margin. To further support the research
in this field, the real-time rendering engine and accompanying datasets are
released along with this publication.",arxiv
http://arxiv.org/abs/2012.04794v1,2020-12-08T23:59:48Z,2020-12-08T23:59:48Z,"Deep Learning based Multi-Modal Sensing for Tracking and State
  Extraction of Small Quadcopters","This paper proposes a multi-sensor based approach to detect, track, and
localize a quadcopter unmanned aerial vehicle (UAV). Specifically, a pipeline
is developed to process monocular RGB and thermal video (captured from a fixed
platform) to detect and track the UAV in our FoV. Subsequently, a 2D planar
lidar is used to allow conversion of pixel data to actual distance
measurements, and thereby enable localization of the UAV in global coordinates.
The monocular data is processed through a deep learning-based object detection
method that computes an initial bounding box for the UAV. The thermal data is
processed through a thresholding and Kalman filter approach to detect and track
the bounding box. Training and testing data are prepared by combining a set of
original experiments conducted in a motion capture environment and publicly
available UAV image data. The new pipeline compares favorably to existing
methods and demonstrates promising tracking and localization capacity of sample
experiments.",arxiv
http://arxiv.org/abs/2012.10706v4,2021-07-30T13:36:36Z,2020-12-19T14:53:56Z,Siamese Anchor Proposal Network for High-Speed Aerial Tracking,"In the domain of visual tracking, most deep learning-based trackers highlight
the accuracy but casting aside efficiency. Therefore, their real-world
deployment on mobile platforms like the unmanned aerial vehicle (UAV) is
impeded. In this work, a novel two-stage Siamese network-based method is
proposed for aerial tracking, \textit{i.e.}, stage-1 for high-quality anchor
proposal generation, stage-2 for refining the anchor proposal. Different from
anchor-based methods with numerous pre-defined fixed-sized anchors, our
no-prior method can 1) increase the robustness and generalization to different
objects with various sizes, especially to small, occluded, and fast-moving
objects, under complex scenarios in light of the adaptive anchor generation, 2)
make calculation feasible due to the substantial decrease of anchor numbers. In
addition, compared to anchor-free methods, our framework has better performance
owing to refinement at stage-2. Comprehensive experiments on three benchmarks
have proven the superior performance of our approach, with a speed of around
200 frames/s.",arxiv
http://arxiv.org/abs/2109.01800v1,2021-09-04T06:27:13Z,2021-09-04T06:27:13Z,"A Comprehensive Approach for UAV Small Object Detection with
  Simulation-based Transfer Learning and Adaptive Fusion","Precisely detection of Unmanned Aerial Vehicles(UAVs) plays a critical role
in UAV defense systems. Deep learning is widely adopted for UAV object
detection whereas researches on this topic are limited by the amount of dataset
and small scale of UAV. To tackle these problems, a novel comprehensive
approach that combines transfer learning based on simulation data and adaptive
fusion is proposed. Firstly, the open-source plugin AirSim proposed by
Microsoft is used to generate mass realistic simulation data. Secondly,
transfer learning is applied to obtain a pre-trained YOLOv5 model on the
simulated dataset and fine-tuned model on the real-world dataset. Finally, an
adaptive fusion mechanism is proposed to further improve small object detection
performance. Experiment results demonstrate the effectiveness of
simulation-based transfer learning which leads to a 2.7% performance increase
on UAV object detection. Furthermore, with transfer learning and adaptive
fusion mechanism, 7.1% improvement is achieved compared to the original YOLO v5
model.",arxiv
http://arxiv.org/abs/1708.05884v4,2018-11-22T15:12:02Z,2017-08-19T18:13:23Z,"Teaching UAVs to Race: End-to-End Regression of Agile Controls in
  Simulation","Automating the navigation of unmanned aerial vehicles (UAVs) in diverse
scenarios has gained much attention in recent years. However, teaching UAVs to
fly in challenging environments remains an unsolved problem, mainly due to the
lack of training data. In this paper, we train a deep neural network to predict
UAV controls from raw image data for the task of autonomous UAV racing in a
photo-realistic simulation. Training is done through imitation learning with
data augmentation to allow for the correction of navigation mistakes. Extensive
experiments demonstrate that our trained network (when sufficient data
augmentation is used) outperforms state-of-the-art methods and flies more
consistently than many human pilots. Additionally, we show that our optimized
network architecture can run in real-time on embedded hardware, allowing for
efficient on-board processing critical for real-world deployment. From a
broader perspective, our results underline the importance of extensive data
augmentation techniques to improve robustness in end-to-end learning setups.",arxiv
http://arxiv.org/abs/1804.05348v3,2018-11-29T22:06:32Z,2018-04-15T12:33:55Z,"Machine Learning for Wireless Connectivity and Security of
  Cellular-Connected UAVs","Cellular-connected unmanned aerial vehicles (UAVs) will inevitably be
integrated into future cellular networks as new aerial mobile users. Providing
cellular connectivity to UAVs will enable a myriad of applications ranging from
online video streaming to medical delivery. However, to enable a reliable
wireless connectivity for the UAVs as well as a secure operation, various
challenges need to be addressed such as interference management, mobility
management and handover, cyber-physical attacks, and authentication. In this
paper, the goal is to expose the wireless and security challenges that arise in
the context of UAV-based delivery systems, UAV-based real-time multimedia
streaming, and UAV-enabled intelligent transportation systems. To address such
challenges, artificial neural network (ANN) based solution schemes are
introduced. The introduced approaches enable the UAVs to adaptively exploit the
wireless system resources while guaranteeing a secure operation, in real-time.
Preliminary simulation results show the benefits of the introduced solutions
for each of the aforementioned cellular-connected UAV application use case.",arxiv
http://arxiv.org/abs/1711.02821v1,2017-11-08T04:11:08Z,2017-11-08T04:11:08Z,"Realtime Profiling of Fine-Grained Air Quality Index Distribution using
  UAV Sensing","Given significant air pollution problems, air quality index (AQI) monitoring
has recently received increasing attention. In this paper, we design a mobile
AQI monitoring system boarded on unmanned-aerial-vehicles (UAVs), called ARMS,
to efficiently build fine-grained AQI maps in realtime. Specifically, we first
propose the Gaussian plume model on basis of the neural network (GPM-NN), to
physically characterize the particle dispersion in the air. Based on GPM-NN, we
propose a battery efficient and adaptive monitoring algorithm to monitor AQI at
the selected locations and construct an accurate AQI map with the sensed data.
The proposed adaptive monitoring algorithm is evaluated in two typical
scenarios, a two-dimensional open space like a roadside park, and a
three-dimensional space like a courtyard inside a building. Experimental
results demonstrate that our system can provide higher prediction accuracy of
AQI with GPM-NN than other existing models, while greatly reducing the power
consumption with the adaptive monitoring algorithm.",arxiv
http://arxiv.org/abs/1811.01075v2,2019-03-11T13:14:04Z,2018-11-02T20:14:51Z,"Toward Verifiable Real-Time Obstacle Motion Prediction for Dynamic
  Collision Avoidance","Next generation Unmanned Aerial Vehicles (UAVs) must reliably avoid moving
obstacles. Existing dynamic collision avoidance methods are effective where
obstacle trajectories are linear or known, but such restrictions are not
accurate to many real-world UAV applications. We propose an efficient method of
predicting an obstacle's motion based only on recent observations, via online
training of an LSTM neural network. Given such predictions, we define a
Nonlinear Probabilistic Velocity Obstacle (NPVO), which can be used select a
velocity that is collision free with a given probability. We take a step
towards formal verification of our approach, using statistical model checking
to approximate the probability that our system will mispredict an obstacle's
motion. Given such a probability, we prove upper bounds on the probability of
collision in multi-agent and reciprocal collision avoidance scenarios.
Furthermore, we demonstrate in simulation that our method avoids collisions
where state-of-the-art methods fail.",arxiv
http://arxiv.org/abs/1910.04969v1,2019-10-11T04:40:57Z,2019-10-11T04:40:57Z,"Remote UAV Online Path Planning via Neural Network Based Opportunistic
  Control","This letter proposes a neural network (NN) aided remote unmanned aerial
vehicle (UAV) online control algorithm, coined oHJB. By downloading a UAV's
state, a base station (BS) trains an HJB NN that solves the
Hamilton-Jacobi-Bellman equation (HJB) in real time, yielding the optimal
control action. Initially, the BS uploads this control action to the UAV. If
the HJB NN is sufficiently trained and the UAV is far away, the BS uploads the
HJB NN model, enabling to locally carry out control decisions even when the
connection is lost. Simulations corroborate the effectiveness of oHJB in
reducing the UAV's travel time and energy by utilizing the trade-off between
uploading delays and control robustness in poor channel conditions.",arxiv
http://arxiv.org/abs/1912.12139v1,2019-12-13T12:35:00Z,2019-12-13T12:35:00Z,"Crack Detection Using Enhanced Hierarchical Convolutional Neural
  Networks","Unmanned aerial vehicles (UAV) are expected to replace human in hazardous
tasks of surface inspection due to their flexibility in operating space and
capability of collecting high quality visual data. In this study, we propose
enhanced hierarchical convolutional neural networks (HCNN) to detect cracks
from image data collected by UAVs. Unlike traditional HCNN, here a set of
branch networks is utilised to reduce the obscuration in the down-sampling
process. Moreover, the feature preserving blocks combine the current and
previous terms from the convolutional blocks to provide input to the loss
functions. As a result, the weights of resized images can be reduced to
minimise the information loss. Experiments on images of different crack
datasets have been carried out to demonstrate the effectiveness of proposed
HCNN.",arxiv
http://arxiv.org/abs/2002.12852v2,2020-11-10T02:38:21Z,2020-02-28T16:29:59Z,"Probably Approximately Correct Vision-Based Planning using Motion
  Primitives","This paper presents an approach for learning vision-based planners that
provably generalize to novel environments (i.e., environments unseen during
training). We leverage the Probably Approximately Correct (PAC)-Bayes framework
to obtain an upper bound on the expected cost of policies across all
environments. Minimizing the PAC-Bayes upper bound thus trains policies that
are accompanied by a certificate of performance on novel environments. The
training pipeline we propose provides strong generalization guarantees for deep
neural network policies by (a) obtaining a good prior distribution on the space
of policies using Evolutionary Strategies (ES) followed by (b) formulating the
PAC-Bayes optimization as an efficiently-solvable parametric convex
optimization problem. We demonstrate the efficacy of our approach for producing
strong generalization guarantees for learned vision-based motion planners
through two simulated examples: (1) an Unmanned Aerial Vehicle (UAV) navigating
obstacle fields with an onboard vision sensor, and (2) a dynamic quadrupedal
robot traversing rough terrains with proprioceptive and exteroceptive sensors.",arxiv
http://arxiv.org/abs/2006.10178v3,2021-03-15T17:11:08Z,2020-06-17T22:06:35Z,"Variational State-Space Models for Localisation and Dense 3D Mapping in
  6 DoF","We solve the problem of 6-DoF localisation and 3D dense reconstruction in
spatial environments as approximate Bayesian inference in a deep state-space
model. Our approach leverages both learning and domain knowledge from
multiple-view geometry and rigid-body dynamics. This results in an expressive
predictive model of the world, often missing in current state-of-the-art visual
SLAM solutions. The combination of variational inference, neural networks and a
differentiable raycaster ensures that our model is amenable to end-to-end
gradient-based optimisation. We evaluate our approach on realistic unmanned
aerial vehicle flight data, nearing the performance of state-of-the-art
visual-inertial odometry systems. We demonstrate the applicability of the model
to generative prediction and planning.",arxiv
http://arxiv.org/abs/2012.00546v1,2020-11-14T02:31:04Z,2020-11-14T02:31:04Z,"Power Control for a URLLC-enabled UAV system incorporated with DNN-Based
  Channel Estimation","This letter is concerned with power control for a ultra-reliable and
low-latency communications (URLLC) enabled unmanned aerial vehicle (UAV) system
incorporated with deep neural network (DNN) based channel estimation.
Particularly, we formulate the power control problem for the UAV system as an
optimization problem to accommodate the URLLC requirement of uplink control and
non-payload signal delivery while ensuring the downlink high-speed payload
transmission. This problem is challenging to be solved due to the requirement
of analytically tractable channel models and the non-convex characteristic as
well. To address the challenges, we propose a novel power control algorithm,
which constructs analytically tractable channel models based on DNN estimation
results and explores a semidefinite relaxation (SDR) scheme to tackle the
non-convexity. Simulation results demonstrate the accuracy of the DNN
estimation and verify the effectiveness of the proposed algorithm.",arxiv
http://arxiv.org/abs/2106.16048v2,2021-10-26T07:35:05Z,2021-06-30T13:24:26Z,"Resilient UAV Swarm Communications with Graph Convolutional Neural
  Network","In this paper, we study the self-healing problem of unmanned aerial vehicle
(UAV) swarm network (USNET) that is required to quickly rebuild the
communication connectivity under unpredictable external disruptions (UEDs).
Firstly, to cope with the one-off UEDs, we propose a graph convolutional neural
network (GCN) and find the recovery topology of the USNET in an on-line manner.
Secondly, to cope with general UEDs, we develop a GCN based trajectory planning
algorithm that can make UAVs rebuild the communication connectivity during the
self-healing process. We also design a meta learning scheme to facilitate the
on-line executions of the GCN. Numerical results show that the proposed
algorithms can rebuild the communication connectivity of the USNET more quickly
than the existing algorithms under both one-off UEDs and general UEDs. The
simulation results also show that the meta learning scheme can not only enhance
the performance of the GCN but also reduce the time complexity of the on-line
executions.",arxiv
http://arxiv.org/abs/1906.05023v1,2019-06-12T09:21:41Z,2019-06-12T09:21:41Z,"Towards Big data processing in IoT: Path Planning and Resource
  Management of UAV Base Stations in Mobile-Edge Computing System","Heavy data load and wide cover range have always been crucial problems for
online data processing in internet of things (IoT). Recently, mobile-edge
computing (MEC) and unmanned aerial vehicle base stations (UAV-BSs) have
emerged as promising techniques in IoT. In this paper, we propose a three-layer
online data processing network based on MEC technique. On the bottom layer, raw
data are generated by widely distributed sensors, which reflects local
information. Upon them, unmanned aerial vehicle base stations (UAV-BSs) are
deployed as moving MEC servers, which collect data and conduct initial steps of
data processing. On top of them, a center cloud receives processed results and
conducts further evaluation. As this is an online data processing system, the
edge nodes should stabilize delay to ensure data freshness. Furthermore,
limited onboard energy poses constraints to edge processing capability. To
smartly manage network resources for saving energy and stabilizing delay, we
develop an online determination policy based on Lyapunov Optimization. In cases
of low data rate, it tends to reduce edge processor frequency for saving
energy. In the presence of high data rate, it will smartly allocate bandwidth
for edge data offloading. Meanwhile, hovering UAV-BSs bring a large and
flexible service coverage, which results in the problem of effective path
planning. In this paper, we apply deep reinforcement learning and develop an
online path planning algorithm. Taking observations of around environment as
input, a CNN network is trained to predict the reward of each action. By
simulations, we validate its effectiveness in enhancing service coverage. The
result will contribute to big data processing in future IoT.",arxiv
http://arxiv.org/abs/1911.08111v2,2020-02-05T07:53:53Z,2019-11-19T06:35:15Z,"Placement Optimization of Aerial Base Stations with Deep Reinforcement
  Learning","Unmanned aerial vehicles (UAVs) can be utilized as aerial base stations
(ABSs) to assist terrestrial infrastructure for keeping wireless connectivity
in various emergency scenarios. To maximize the coverage rate of N ground users
(GUs) by jointly placing multiple ABSs with limited coverage range is known to
be a NP-hard problem with exponential complexity in N. The problem is further
complicated when the coverage range becomes irregular due to site-specific
blockage (e.g., buildings) on the air-ground channel in the 3-dimensional (3D)
space. To tackle this challenging problem, this paper applies the Deep
Reinforcement Learning (DRL) method by 1) representing the state by a coverage
bitmap to capture the spatial correlation of GUs/ABSs, whose dimension and
associated neural network complexity is invariant with arbitrarily large N; and
2) designing the action and reward for the DRL agent to effectively learn from
the dynamic interactions with the complicated propagation environment
represented by a 3D Terrain Map. Specifically, a novel two-level design
approach is proposed, consisting of a preliminary design based on the dominant
line-of-sight (LoS) channel model, and an advanced design to further refine the
ABS positions based on site-specific LoS/non-LoS channel states. The double
deep Q-network (DQN) with Prioritized Experience Replay (Prioritized Replay
DDQN) algorithm is applied to train the policy of multi-ABS placement decision.
Numerical results show that the proposed approach significantly improves the
coverage rate in complex environment, compared to the benchmark DQN and K-means
algorithms.",arxiv
http://arxiv.org/abs/2002.00831v1,2020-02-03T15:39:56Z,2020-02-03T15:39:56Z,An Actor-Critic-Based UAV-BSs Deployment Method for Dynamic Environments,"In this paper, the real-time deployment of unmanned aerial vehicles (UAVs) as
flying base stations (BSs) for optimizing the throughput of mobile users is
investigated for UAV networks. This problem is formulated as a time-varying
mixed-integer non-convex programming (MINP) problem, which is challenging to
find an optimal solution in a short time with conventional optimization
techniques. Hence, we propose an actor-critic-based (AC-based) deep
reinforcement learning (DRL) method to find near-optimal UAV positions at every
moment. In the proposed method, the process searching for the solution
iteratively at a particular moment is modeled as a Markov decision process
(MDP). To handle infinite state and action spaces and improve the robustness of
the decision process, two powerful neural networks (NNs) are configured to
evaluate the UAV position adjustments and make decisions, respectively.
Compared with the heuristic algorithm, sequential least-squares programming and
fixed UAVs methods, simulation results have shown that the proposed method
outperforms these three benchmarks in terms of the throughput at every moment
in UAV networks.",arxiv
http://arxiv.org/abs/2104.06256v2,2021-04-15T19:22:20Z,2021-04-03T22:22:20Z,"Learning-Based UAV Trajectory Optimization with Collision Avoidance and
  Connectivity Constraints","Unmanned aerial vehicles (UAVs) are expected to be an integral part of
wireless networks, and determining collision-free trajectories for multiple
UAVs while satisfying requirements of connectivity with ground base stations
(GBSs) is a challenging task. In this paper, we first reformulate the multi-UAV
trajectory optimization problem with collision avoidance and wireless
connectivity constraints as a sequential decision making problem in the
discrete time domain. We, then, propose a decentralized deep reinforcement
learning approach to solve the problem. More specifically, a value network is
developed to encode the expected time to destination given the agent's joint
state (including the agent's information, the nearby agents' observable
information, and the locations of the nearby GBSs). A
signal-to-interference-plus-noise ratio (SINR)-prediction neural network is
also designed, using accumulated SINR measurements obtained when interacting
with the cellular network, to map the GBSs' locations into the SINR levels in
order to predict the UAV's SINR. Numerical results show that with the value
network and SINR-prediction network, real-time navigation for multi-UAVs can be
efficiently performed in various environments with high success rate.",arxiv
http://arxiv.org/abs/2106.10423v1,2021-06-19T04:40:47Z,2021-06-19T04:40:47Z,"Joint Speed Control and Energy Replenishment Optimization for
  UAV-assisted IoT Data Collection with Deep Reinforcement Transfer Learning","Unmanned aerial vehicle (UAV)-assisted data collection has been emerging as a
prominent application due to its flexibility, mobility, and low operational
cost. However, under the dynamic and uncertainty of IoT data collection and
energy replenishment processes, optimizing the performance for UAV collectors
is a very challenging task. Thus, this paper introduces a novel framework that
jointly optimizes the flying speed and energy replenishment for each UAV to
significantly improve the data collection performance. Specifically, we first
develop a Markov decision process to help the UAV automatically and dynamically
make optimal decisions under the dynamics and uncertainties of the environment.
We then propose a highly-effective reinforcement learning algorithm leveraging
deep Q-learning, double deep Q-learning, and a deep dueling neural network
architecture to quickly obtain the UAV's optimal policy. The core ideas of this
algorithm are to estimate the state values and action advantages separately and
simultaneously and to employ double estimators for estimating the action
values. Thus, these proposed techniques can stabilize the learning process and
effectively address the overestimation problem of conventional Q-learning
algorithms. To further reduce the learning time as well as significantly
improve learning quality, we develop advanced transfer learning techniques to
allow UAVs to ``share'' and ``transfer'' learning knowledge. Extensive
simulations demonstrate that our proposed solution can improve the average data
collection performance of the system up to 200% compared with those of current
methods.",arxiv
http://arxiv.org/abs/2107.13869v2,2021-07-30T13:55:57Z,2021-07-29T10:11:36Z,"Autonomous UAV Base Stations for Next Generation Wireless Networks: A
  Deep Learning Approach","To address the ever-growing connectivity demands of wireless communications,
the adoption of ingenious solutions, such as Unmanned Aerial Vehicles (UAVs) as
mobile Base Stations (BSs), is imperative. In general, the location of a UAV
Base Station (UAV-BS) is determined by optimization algorithms, which have high
computationally complexities and place heavy demands on UAV resources. In this
paper, we show that a Convolutional Neural Network (CNN) model can be trained
to infer the location of a UAV-BS in real time. In so doing, we create a
framework to determine the UAV locations that considers the deployment of
Mobile Users (MUs) to generate labels by using the data obtained from an
optimization algorithm. Performance evaluations reveal that once the CNN model
is trained with the given labels and locations of MUs, the proposed approach is
capable of approximating the results given by the adopted optimization
algorithm with high fidelity, outperforming Reinforcement Learning (RL)-based
approaches. We also explore future research challenges and highlight key
issues.",arxiv
http://arxiv.org/abs/2101.10861v2,2021-01-29T14:09:43Z,2021-01-22T16:08:38Z,A Review on Deep Learning in UAV Remote Sensing,"Deep Neural Networks (DNNs) learn representation from data with an impressive
capability, and brought important breakthroughs for processing images,
time-series, natural language, audio, video, and many others. In the remote
sensing field, surveys and literature revisions specifically involving DNNs
algorithms' applications have been conducted in an attempt to summarize the
amount of information produced in its subfields. Recently, Unmanned Aerial
Vehicles (UAV) based applications have dominated aerial sensing research.
However, a literature revision that combines both ""deep learning"" and ""UAV
remote sensing"" thematics has not yet been conducted. The motivation for our
work was to present a comprehensive review of the fundamentals of Deep Learning
(DL) applied in UAV-based imagery. We focused mainly on describing
classification and regression techniques used in recent applications with
UAV-acquired data. For that, a total of 232 papers published in international
scientific journal databases was examined. We gathered the published material
and evaluated their characteristics regarding application, sensor, and
technique used. We relate how DL presents promising results and has the
potential for processing tasks associated with UAV-based image data. Lastly, we
project future perspectives, commentating on prominent DL paths to be explored
in the UAV remote sensing field. Our revision consists of a friendly-approach
to introduce, commentate, and summarize the state-of-the-art in UAV-based image
applications with DNNs algorithms in diverse subfields of remote sensing,
grouping it in the environmental, urban, and agricultural contexts.",arxiv
http://arxiv.org/abs/2007.10540v1,2020-07-21T00:39:50Z,2020-07-21T00:39:50Z,"Cluster-Head-Driven UAV Relaying with Recursive Maximum Minimum Distance
  using CRANs","In this letter, a C-RAN-type cluster-head-driven uplink model for
multiple-antenna Unmanned Aerial Vehicles (UAV) relaying schemes, which enables
joint Maximum Likelihood (ML) symbol detection in the UAV cluster-head and the
selection of UAV sources to communicate with each other aided by UAV-based
relays, {is presented. In this context,} a relay selection technique, named
Cluster-Head-Driven Best-Link (CHD-Best-Link), that employs cluster-head
buffers and physical-layer network coding, {is devised}. Then, a recursive
maximum minimum distance relay selection strategy that exploits time-correlated
channels and equips the CHD-Best-Link scheme is developed. Simulations
illustrate that CHD-Best-Link has superior average delay and bit error rate
performances to that of previous schemes.",arxiv
http://arxiv.org/abs/1907.06915v1,2019-07-16T09:41:13Z,2019-07-16T09:41:13Z,"Mango Tree Net -- A fully convolutional network for semantic
  segmentation and individual crown detection of mango trees","This work presents a method for semantic segmentation of mango trees in high
resolution aerial imagery, and, a novel method for individual crown detection
of mango trees using segmentation output. Mango Tree Net, a fully convolutional
neural network (FCN), is trained using supervised learning to perform semantic
segmentation of mango trees in imagery acquired using an unmanned aerial
vehicle (UAV). The proposed network is retrained to separate
touching/overlapping tree crowns in segmentation output. Contour based
connected object detection is performed on the segmentation output from
retrained network. Bounding boxes are drawn on the original images using
coordinates of connected objects to achieve individual crown detection. The
training dataset consists of 8,824 image patches of size 240 x 240. The
approach is tested for performance on segmentation and individual crown
detection tasks using test datasets containing 36 and 4 images respectively.
The performance is analyzed using standard metrics precision, recall, f1-score
and accuracy. Results obtained demonstrate the robustness of the proposed
methods despite variations in factors such as scale, occlusion, lighting
conditions and surrounding vegetation.",arxiv
http://arxiv.org/abs/2003.01287v2,2020-08-28T07:32:10Z,2020-03-03T01:37:00Z,"Intelligent Base Station Association for UAV Cellular Users: A
  Supervised Learning Approach","Fifth Generation (5G) cellular networks are expected to provide cellular
connectivity for vehicular users, including Unmanned Aerial Vehicles (UAVs).
When flying in the air, these users experience strong, unobstructed channel
conditions to a large number of Base Stations (BSs) on the ground. This creates
very strong interference conditions for the UAV users, while at the same time
offering them a large number of BSs to potentially associate with for cellular
service. Therefore, to maximise the performance of the UAV-BS wireless link,
the UAV user needs to be able to choose which BSs to connect to, based on the
observed environmental conditions. This paper proposes a supervised
learning-based association scheme, using which a UAV can intelligently
associate with the most appropriate BS. We train a Neural Network (NN) to
identify the most suitable BS from several candidate BSs, based on the received
signal powers from the BSs, known distances to the BSs, as well as the known
locations of potential interferers. We then compare the performance of the
NN-based association scheme against strongest-signal and closest-neighbour
association schemes, and demonstrate that the NN scheme significantly
outperforms the simple heuristic schemes.",arxiv
http://arxiv.org/abs/2104.04477v2,2021-04-15T19:11:40Z,2021-04-09T16:52:33Z,"Jamming-Resilient Path Planning for Multiple UAVs via Deep Reinforcement
  Learning","Unmanned aerial vehicles (UAVs) are expected to be an integral part of
wireless networks. In this paper, we aim to find collision-free paths for
multiple cellular-connected UAVs, while satisfying requirements of connectivity
with ground base stations (GBSs) in the presence of a dynamic jammer. We first
formulate the problem as a sequential decision making problem in discrete
domain, with connectivity, collision avoidance, and kinematic constraints. We,
then, propose an offline temporal difference (TD) learning algorithm with
online signal-to-interference-plus-noise ratio (SINR) mapping to solve the
problem. More specifically, a value network is constructed and trained offline
by TD method to encode the interactions among the UAVs and between the UAVs and
the environment; and an online SINR mapping deep neural network (DNN) is
designed and trained by supervised learning, to encode the influence and
changes due to the jammer. Numerical results show that, without any information
on the jammer, the proposed algorithm can achieve performance levels close to
that of the ideal scenario with the perfect SINR-map. Real-time navigation for
multi-UAVs can be efficiently performed with high success rates, and collisions
are avoided.",arxiv
http://arxiv.org/abs/2010.08546v1,2020-10-17T17:18:17Z,2020-10-17T17:18:17Z,"A Generative Model based Adversarial Security of Deep Learning and
  Linear Classifier Models","In recent years, machine learning algorithms have been applied widely in
various fields such as health, transportation, and the autonomous car. With the
rapid developments of deep learning techniques, it is critical to take the
security concern into account for the application of the algorithms. While
machine learning offers significant advantages in terms of the application of
algorithms, the issue of security is ignored. Since it has many applications in
the real world, security is a vital part of the algorithms. In this paper, we
have proposed a mitigation method for adversarial attacks against machine
learning models with an autoencoder model that is one of the generative ones.
The main idea behind adversarial attacks against machine learning models is to
produce erroneous results by manipulating trained models. We have also
presented the performance of autoencoder models to various attack methods from
deep neural networks to traditional algorithms by using different methods such
as non-targeted and targeted attacks to multi-class logistic regression, a fast
gradient sign method, a targeted fast gradient sign method and a basic
iterative method attack to neural networks for the MNIST dataset.",arxiv
http://arxiv.org/abs/2103.17162v2,2021-08-25T13:49:46Z,2021-03-31T15:25:36Z,RIS-Assisted UAV for Timely Data Collection in IoT Networks,"Intelligent Transportation Systems are thriving thanks to a wide range of
technological advances, namely 5G communications, Internet of Things,
artificial intelligence and edge computing. Central to this is the wide
deployment of smart sensing devices and accordingly the large amount of
harvested information to be processed for timely decision making. Robust
network access is, hence, essential for offloading the collected data before a
set deadline, beyond which the data loses its value. In environments where
direct communication can be impaired by, for instance, blockages such as in
urban cities, unmanned aerial vehicles (UAVs) can be considered as an
alternative for providing and enhancing connectivity, particularly when IoT
devices (IoTD) are constrained with their resources. Also, to conserve energy,
IoTDs are assumed to alternate between their active and passive modes. This
paper, therefore, considers a time-constrained data gathering problem from a
network of sensing devices and with assistance from a UAV. A Reconfigurable
Intelligent Surface (RIS) is deployed to further improve both the connectivity
and energy efficiency of the UAV, particularly when multiple devices are served
concurrently and experience different channel impairments. This integrated
problem brings challenges related to the configuration of the phase shift
elements of the RIS, the scheduling of IoTDs transmissions as well as the
trajectory of the UAV. First, the problem is formulated with the objective of
maximizing the total number of served devices each during its activation
period. Owing to its complexity and the incomplete knowledge about the
environment, we leverage deep reinforcement learning in our solution; the UAV
trajectory planning is modeled as a Markov Decision Process, and Proximal
Policy Optimization is invoked to solve it. Next, the RIS configuration is then
handled via Block Coordinate Descent.",arxiv
http://arxiv.org/abs/1909.05429v1,2019-09-12T01:40:00Z,2019-09-12T01:40:00Z,"Detection and Classification of UAVs Using RF Fingerprints in the
  Presence of Interference","This paper investigates the problem of detection and classification of
unmanned aerial vehicles (UAVs) in the presence of wireless interference
signals using a passive radio frequency (RF) surveillance system. The system
uses a multistage detector to distinguish signals transmitted by a UAV
controller from the background noise and interference signals. First, RF
signals from any source are detected using a Markov models-based na\""ive Bayes
decision mechanism. When the receiver operates at a signal-to-noise ratio (SNR)
of 10 dB, and the threshold, which defines the states of the models, is set at
a level 3.5 times the standard deviation of the preprocessed noise data, a
detection accuracy of 99.8% with a false alarm rate of 2.8% is achieved.
Second, signals from Wi-Fi and Bluetooth emitters, if present, are detected
based on the bandwidth and modulation features of the detected RF signal. Once
the input signal is identified as a UAV controller signal, it is classified
using machine learning (ML) techniques. Fifteen statistical features extracted
from the energy transients of the UAV controller signals are fed to
neighborhood component analysis (NCA), and the three most significant features
are selected. The performance of the NCA and five different ML classifiers are
studied for 15 different types of UAV controllers. A classification accuracy of
98.13% is achieved by k-nearest neighbor classifier at 25 dB SNR.
Classification performance is also investigated at different SNR levels and for
a set of 17 UAV controllers which includes two pairs from the same UAV
controller models.",arxiv
http://arxiv.org/abs/2002.08196v2,2020-06-10T16:19:18Z,2020-02-19T14:04:01Z,"Federated Learning in the Sky: Joint Power Allocation and Scheduling
  with UAV Swarms","Unmanned aerial vehicle (UAV) swarms must exploit machine learning (ML) in
order to execute various tasks ranging from coordinated trajectory planning to
cooperative target recognition. However, due to the lack of continuous
connections between the UAV swarm and ground base stations (BSs), using
centralized ML will be challenging, particularly when dealing with a large
volume of data. In this paper, a novel framework is proposed to implement
distributed federated learning (FL) algorithms within a UAV swarm that consists
of a leading UAV and several following UAVs. Each following UAV trains a local
FL model based on its collected data and then sends this trained local model to
the leading UAV who will aggregate the received models, generate a global FL
model, and transmit it to followers over the intra-swarm network. To identify
how wireless factors, like fading, transmission delay, and UAV antenna angle
deviations resulting from wind and mechanical vibrations, impact the
performance of FL, a rigorous convergence analysis for FL is performed. Then, a
joint power allocation and scheduling design is proposed to optimize the
convergence rate of FL while taking into account the energy consumption during
convergence and the delay requirement imposed by the swarm's control system.
Simulation results validate the effectiveness of the FL convergence analysis
and show that the joint design strategy can reduce the number of communication
rounds needed for convergence by as much as 35% compared with the baseline
design.",arxiv
http://arxiv.org/abs/2110.00695v1,2021-10-02T00:43:02Z,2021-10-02T00:43:02Z,Deep Learning for Rain Fade Prediction in Satellite Communications,"Line of sight satellite systems, unmanned aerial vehicles, high-altitude
platforms, and microwave links that operate on frequency bands such as Ka-band
or higher are extremely susceptible to rain. Thus, rain fade forecasting for
these systems is critical because it allows the system to switch between ground
gateways proactively before a rain fade event to maintain seamless service.
Although empirical, statistical, and fade slope models can predict rain fade to
some extent, they typically require statistical measurements of rain
characteristics in a given area and cannot be generalized to a large scale
system. Furthermore, such models typically predict near-future rain fade events
but are incapable of forecasting far into the future, making proactive resource
management more difficult. In this paper, a deep learning (DL)-based
architecture is proposed that forecasts future rain fade using satellite and
radar imagery data as well as link power measurements. Furthermore, the data
preprocessing and architectural design have been thoroughly explained and
multiple experiments have been conducted. Experiments show that the proposed DL
architecture outperforms current state-of-the-art machine learning-based
algorithms in rain fade forecasting in the near and long term. Moreover, the
results indicate that radar data with weather condition information is more
effective for short-term prediction, while satellite data with cloud movement
information is more effective for long-term predictions.",arxiv
http://arxiv.org/abs/1609.04147v1,2016-09-14T07:03:15Z,2016-09-14T07:03:15Z,"HMD Vision-based Teleoperating UGV and UAV for Hostile Environment using
  Deep Learning","The necessity of maintaining a robust antiterrorist task force has become
imperative in recent times with resurgence of rogue element in the society. A
well equipped combat force warrants the safety and security of citizens and the
integrity of the sovereign state. In this paper we propose a novel
teleoperating robot which can play a major role in combat, rescue and
reconnaissance missions by substantially reducing loss of human soldiers in
such hostile environments. The proposed robotic solution consists of an
unmanned ground vehicle equipped with an IP camera visual system broadcasting
real-time video data to a remote cloud server. With the advancement in machine
learning algorithms in the field of computer vision, we incorporate state of
the art deep convolutional neural networks to identify and predict individuals
with malevolent intent. The classification is performed on every frame of the
video stream by the trained network in the cloud server. The predicted output
of the network is overlaid on the video stream with specific colour marks and
prediction percentage. Finally the data is resized into half-side by side
format and streamed to the head mount display worn by the human controller
which facilitates first person view of the scenario. The ground vehicle is also
coupled with an unmanned aerial vehicle for aerial surveillance. The proposed
scheme is an assistive system and the final decision evidently lies with the
human handler.",arxiv
http://arxiv.org/abs/1912.00752v3,2020-07-15T14:08:12Z,2019-11-28T03:03:24Z,"Deep Learning for Optimal Deployment of UAVs with Visible Light
  Communications","In this paper, the problem of dynamical deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities
for optimizing the energy efficiency of UAV-enabled networks is studied. In the
studied model, the UAVs can simultaneously provide communications and
illumination to service ground users. Since ambient illumination increases the
interference over VLC links while reducing the illumination threshold of the
UAVs, it is necessary to consider the illumination distribution of the target
area for UAV deployment optimization. This problem is formulated as an
optimization problem which jointly optimizes UAV deployment, user association,
and power efficiency while meeting the illumination and communication
requirements of users. To solve this problem, an algorithm that combines the
machine learning framework of gated recurrent units (GRUs) with convolutional
neural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the
long-term historical illumination distribution and predict the future
illumination distribution. Given the prediction of illumination distribution,
the original nonconvex optimization problem can be divided into two
sub-problems and is then solved using a low-complexity, iterative algorithm.
Then, the proposed algorithm enables UAVs to determine the their deployment and
user association to minimize the total transmit power. Simulation results using
real data from the Earth observations group (EOG) at NOAA/NCEI show that the
proposed approach can achieve up to 68.9% reduction in total transmit power
compared to a conventional optimal UAV deployment that does not consider the
illumination distribution and user association.",arxiv
http://arxiv.org/abs/2012.06410v1,2020-12-11T15:08:59Z,2020-12-11T15:08:59Z,"Learning How to Trade-Off Safety with Agility Using Deep Covariance
  Estimation for Perception Driven UAV Motion Planning","We investigate how to utilize predictive models for selecting appropriate
motion planning strategies based on perception uncertainty estimation for agile
unmanned aerial vehicle (UAV) navigation tasks. Although there are variety of
motion planning and perception algorithms for such tasks, the impact of
perception uncertainty is not explicitly handled in many of the current motion
algorithms, which leads to performance loss in real-life scenarios where the
measurement are often noisy due to external disturbances. We develop a novel
framework for embedding perception uncertainty to high level motion planning
management, in order to select the best available motion planning approach for
the currently estimated perception uncertainty. We estimate the uncertainty in
visual inputs using a deep neural network (CovNet) that explicitly predicts the
covariance of the current measurements. Next, we train a high level machine
learning model for predicting the lowest cost motion planning algorithm given
the current estimate of covariance as well as the UAV states. We demonstrate on
both real-life data and drone racing simulations that our approach, named
uncertainty driven motion planning switcher (UDS) yields the safest and fastest
trajectories among compared alternatives. Furthermore, we show that the
developed approach learns how to trade-off safety with agility by switching to
motion planners that leads to more agile trajectories when the estimated
covariance is high and vice versa.",arxiv
http://arxiv.org/abs/2102.05346v2,2021-02-25T19:25:51Z,2021-02-10T09:33:48Z,"The Hessigheim 3D (H3D) Benchmark on Semantic Segmentation of
  High-Resolution 3D Point Clouds and Textured Meshes from UAV LiDAR and
  Multi-View-Stereo","Automated semantic segmentation and object detection are of great importance
in geospatial data analysis. However, supervised machine learning systems such
as convolutional neural networks require large corpora of annotated training
data. Especially in the geospatial domain, such datasets are quite scarce.
Within this paper, we aim to alleviate this issue by introducing a new
annotated 3D dataset that is unique in three ways: i) The dataset consists of
both an Unmanned Aerial Vehicle (UAV) laser scanning point cloud and a 3D
textured mesh. ii) The point cloud features a mean point density of about 800
pts/sqm and the oblique imagery used for 3D mesh texturing realizes a ground
sampling distance of about 2-3 cm. This enables the identification of
fine-grained structures and represents the state of the art in UAV-based
mapping. iii) Both data modalities will be published for a total of three
epochs allowing applications such as change detection. The dataset depicts the
village of Hessigheim (Germany), henceforth referred to as H3D. It is designed
to promote research in the field of 3D data analysis on one hand and to
evaluate and rank existing and emerging approaches for semantic segmentation of
both data modalities on the other hand. Ultimately, we hope that H3D will
become a widely used benchmark dataset in company with the well-established
ISPRS Vaihingen 3D Semantic Labeling Challenge benchmark (V3D). The dataset can
be downloaded from
https://ifpwww.ifp.uni-stuttgart.de/benchmark/hessigheim/default.aspx.",arxiv
http://arxiv.org/abs/2102.11894v1,2021-02-23T19:08:41Z,2021-02-23T19:08:41Z,"Wavelet Transform Analytics for RF-Based UAV Detection and
  Identification System Using Machine Learning","In this work, we performed a thorough comparative analysis on a radio
frequency (RF) based drone detection and identification system (DDI) under
wireless interference, such as WiFi and Bluetooth, by using machine learning
algorithms, and a pre-trained convolutional neural network-based algorithm
called SqueezeNet, as classifiers. In RF signal fingerprinting research, the
transient and steady state of the signals can be used to extract a unique
signature from an RF signal. By exploiting the RF control signals from unmanned
aerial vehicles (UAVs) for DDI, we considered each state of the signals
separately for feature extraction and compared the pros and cons for drone
detection and identification. Using various categories of wavelet transforms
(discrete wavelet transform, continuous wavelet transform, and wavelet
scattering transform) for extracting features from the signals, we built
different models using these features. We studied the performance of these
models under different signal to noise ratio (SNR) levels. By using the wavelet
scattering transform to extract signatures (scattergrams) from the steady state
of the RF signals at 30 dB SNR, and using these scattergrams to train
SqueezeNet, we achieved an accuracy of 98.9% at 10 dB SNR.",arxiv
http://arxiv.org/abs/2105.11013v1,2021-05-23T20:19:43Z,2021-05-23T20:19:43Z,"Distributed CNN Inference on Resource-Constrained UAVs for Surveillance
  Systems: Design and Optimization","Unmanned Aerial Vehicles (UAVs) have attracted great interest in the last few
years owing to their ability to cover large areas and access difficult and
hazardous target zones, which is not the case of traditional systems relying on
direct observations obtained from fixed cameras and sensors. Furthermore,
thanks to the advancements in computer vision and machine learning, UAVs are
being adopted for a broad range of solutions and applications. However, Deep
Neural Networks (DNNs) are progressing toward deeper and complex models that
prevent them from being executed on-board. In this paper, we propose a DNN
distribution methodology within UAVs to enable data classification in
resource-constrained devices and avoid extra delays introduced by the
server-based solutions due to data communication over air-to-ground links. The
proposed method is formulated as an optimization problem that aims to minimize
the latency between data collection and decision-making while considering the
mobility model and the resource constraints of the UAVs as part of the
air-to-air communication. We also introduce the mobility prediction to adapt
our system to the dynamics of UAVs and the network variation. The simulation
conducted to evaluate the performance and benchmark the proposed methods,
namely Optimal UAV-based Layer Distribution (OULD) and OULD with Mobility
Prediction (OULD-MP), were run in an HPC cluster. The obtained results show
that our optimization solution outperforms the existing and heuristic-based
approaches.",arxiv
http://arxiv.org/abs/1912.05220v1,2019-12-11T10:27:45Z,2019-12-11T10:27:45Z,Lane Detection For Prototype Autonomous Vehicle,"Unmanned vehicle technologies are an area of great interest in theory and
practice today. These technologies have advanced considerably after the first
applications have been implemented and cause a rapid change in human life.
Autonomous vehicles are also a big part of these technologies. The most
important action of a driver has to do is to follow the lanes on the way to the
destination. By using image processing and artificial intelligence techniques,
an autonomous vehicle can move successfully without a driver help. They can go
from the initial point to the specified target by applying pre-defined rules.
There are also rules for proper tracking of the lanes. Many accidents are
caused due to insufficient follow-up of the lanes and non-compliance with these
rules. The majority of these accidents also result in injury and death.
  In this paper, we present an autonomous vehicle prototype that follows lanes
via image processing techniques, which are a major part of autonomous vehicle
technology. Autonomous movement capability is provided by using some image
processing algorithms such as canny edge detection, Sobel filter, etc. We
implemented and tested these algorithms on the vehicle. The vehicle detected
and followed the determined lanes. By that way, it went to the destination
successfully.",arxiv
http://arxiv.org/abs/1611.06474v2,2017-08-22T08:27:52Z,2016-11-20T05:54:06Z,"Nazr-CNN: Fine-Grained Classification of UAV Imagery for Damage
  Assessment","We propose Nazr-CNN1, a deep learning pipeline for object detection and
fine-grained classification in images acquired from Unmanned Aerial Vehicles
(UAVs) for damage assessment and monitoring. Nazr-CNN consists of two
components. The function of the first component is to localize objects (e.g.
houses or infrastructure) in an image by carrying out a pixel-level
classification. In the second component, a hidden layer of a Convolutional
Neural Network (CNN) is used to encode Fisher Vectors (FV) of the segments
generated from the first component in order to help discriminate between
different levels of damage. To showcase our approach we use data from UAVs that
were deployed to assess the level of damage in the aftermath of a devastating
cyclone that hit the island of Vanuatu in 2015. The collected images were
labeled by a crowdsourcing effort and the labeling categories consisted of
fine-grained levels of damage to built structures. Since our data set is
relatively small, a pre- trained network for pixel-level classification and FV
encoding was used. Nazr-CNN attains promising results both for object detection
and damage assessment suggesting that the integrated pipeline is robust in the
face of small data sets and labeling errors by annotators. While the focus of
Nazr-CNN is on assessment of UAV images in a post-disaster scenario, our
solution is general and can be applied in many diverse settings. We show one
such case of transfer learning to assess the level of damage in aerial images
collected after a typhoon in Philippines.",arxiv
http://arxiv.org/abs/1903.09102v3,2020-11-02T15:52:04Z,2019-03-21T16:30:13Z,"Forecasting Time-to-Collision from Monocular Video: Feasibility,
  Dataset, and Challenges","We explore the possibility of using a single monocular camera to forecast the
time to collision between a suitcase-shaped robot being pushed by its user and
other nearby pedestrians. We develop a purely image-based deep learning
approach that directly estimates the time to collision without the need of
relying on explicit geometric depth estimates or velocity information to
predict future collisions. While previous work has focused on detecting
immediate collision in the context of navigating Unmanned Aerial Vehicles, the
detection was limited to a binary variable (i.e., collision or no collision).
We propose a more fine-grained approach to collision forecasting by predicting
the exact time to collision in terms of milliseconds, which is more helpful for
collision avoidance in the context of dynamic path planning. To evaluate our
method, we have collected a novel dataset of over 13,000 indoor video segments
each showing a trajectory of at least one person ending in a close proximity (a
near collision) with the camera mounted on a mobile suitcase-shaped platform.
Using this dataset, we do extensive experimentation on different temporal
windows as input using an exhaustive list of state-of-the-art convolutional
neural networks (CNNs). Our results show that our proposed multi-stream CNN is
the best model for predicting time to near-collision. The average prediction
error of our time to near collision is 0.75 seconds across the test videos.",arxiv
http://arxiv.org/abs/1905.04166v1,2019-05-10T13:34:18Z,2019-05-10T13:34:18Z,"An Open Source and Open Hardware Deep Learning-powered Visual Navigation
  Engine for Autonomous Nano-UAVs","Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter
and sub-10 Watts of total power budget, have so far been considered incapable
of running sophisticated visual-based autonomous navigation software without
external aid from base-stations, ad-hoc local positioning infrastructure, and
powerful external computation servers. In this work, we present what is, to the
best of our knowledge, the first 27g nano-UAV system able to run aboard an
end-to-end, closed-loop visual pipeline for autonomous navigation based on a
state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie
2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination
of an ultra-low power computing device (the GAP8 system-on-chip) with a novel
methodology for the deployment of deep convolutional neural networks (CNNs). We
enable onboard real-time execution of a state-of-the-art deep CNN at up to
18Hz. Field experiments demonstrate that the system's high responsiveness
prevents collisions with unexpected dynamic obstacles up to a flight speed of
1.5m/s. In addition, we also demonstrate the capability of our visual
navigation engine of fully autonomous indoor navigation on a 113m previously
unseen path. To share our key findings with the embedded and robotics
communities and foster further developments in autonomous nano-UAVs, we
publicly release all our code, datasets, and trained networks.",arxiv
http://arxiv.org/abs/1911.09598v1,2019-11-21T16:49:24Z,2019-11-21T16:49:24Z,"Deep Learning Based Joint Resource Scheduling Algorithms for Hybrid MEC
  Networks","In this paper, we consider a hybrid mobile edge computing (H-MEC) platform,
which includes ground stations (GSs), ground vehicles (GVs) and unmanned aerial
vehicle (UAVs), all with mobile edge cloud installed to enable user equipments
(UEs) or Internet of thing (IoT) devices with intensive computing tasks to
offload. Our objective is to obtain an online offloading algorithm to minimize
the energy consumption of all the UEs, by jointly optimizing the positions of
GVs and UAVs, user association and resource allocation in real-time, while
considering the dynamic environment. To this end, we propose a hybrid deep
learning based online offloading (H2O) framework where a large-scale path-loss
fuzzy c-means (LSFCM) algorithm is first proposed and used to predict the
optimal positions of GVs and UAVs. Secondly, a fuzzy membership matrix U-based
particle swarm optimization (U-PSO) algorithm is applied to solve the mixed
integer nonlinear programming (MINLP) problems and generate the sample datasets
for the deep neural network (DNN) where the fuzzy membership matrix can capture
the small-scale fading effects and the information of mutual interference.
Thirdly, a DNN with the scheduling layer is introduced to provide user
association and computing resource allocation under the practical latency
requirement of the tasks and limited available computing resource of H-MEC. In
addition, different from traditional DNN predictor, we only input one UE
information to the DNN at one time, which will be suitable for the scenarios
where the number of UE is varying and avoid the curse of dimensionality in DNN.",arxiv
http://arxiv.org/abs/1912.05281v1,2019-12-11T13:15:27Z,2019-12-11T13:15:27Z,"Vine disease detection in UAV multispectral images with deep learning
  segmentation approach","One of the major goals of tomorrow's agriculture is to increase agricultural
productivity but above all the quality of production while significantly
reducing the use of inputs. Meeting this goal is a real scientific and
technological challenge. Smart farming is among the promising approaches that
can lead to interesting solutions for vineyard management and reduce the
environmental impact. Automatic vine disease detection can increase efficiency
and flexibility in managing vineyard crops, while reducing the chemical inputs.
This is needed today more than ever, as the use of pesticides is coming under
increasing scrutiny and control. The goal is to map diseased areas in the
vineyard for fast and precise treatment, thus guaranteeing the maintenance of a
healthy state of the vine which is very important for yield management. To
tackle this problem, a method is proposed here for vine disease detection using
a deep learning segmentation approach on Unmanned Aerial Vehicle (UAV) images.
The method is based on the combination of the visible and infrared images
obtained from two different sensors. A new image registration method was
developed to align visible and infrared images, enabling fusion of the
information from the two sensors. A fully convolutional neural network approach
uses this information to classify each pixel according to different instances,
namely, shadow, ground, healthy and symptom. The proposed method achieved more
than 92% of detection at grapevine-level and 87% at leaf level, showing
promising perspectives for computer aided disease detection in vineyards.",arxiv
http://arxiv.org/abs/2004.14421v1,2020-04-29T18:34:48Z,2020-04-29T18:34:48Z,"UAV and Machine Learning Based Refinement of a Satellite-Driven
  Vegetation Index for Precision Agriculture","Precision agriculture is considered to be a fundamental approach in pursuing
a low-input, high-efficiency, and sustainable kind of agriculture when
performing site-specific management practices. To achieve this objective, a
reliable and updated description of the local status of crops is required.
Remote sensing, and in particular satellite-based imagery, proved to be a
valuable tool in crop mapping, monitoring, and diseases assessment. However,
freely available satellite imagery with low or moderate resolutions showed some
limits in specific agricultural applications, e.g., where crops are grown by
rows. Indeed, in this framework, the satellite's output could be biased by
intra-row covering, giving inaccurate information about crop status. This paper
presents a novel satellite imagery refinement framework, based on a deep
learning technique which exploits information properly derived from high
resolution images acquired by unmanned aerial vehicle (UAV) airborne
multispectral sensors. To train the convolutional neural network, only a single
UAV-driven dataset is required, making the proposed approach simple and
cost-effective. A vineyard in Serralunga d'Alba (Northern Italy) was chosen as
a case study for validation purposes. Refined satellite-driven normalized
difference vegetation index (NDVI) maps, acquired in four different periods
during the vine growing season, were shown to better describe crop status with
respect to raw datasets by correlation analysis and ANOVA. In addition, using a
K-means based classifier, 3-class vineyard vigor maps were profitably derived
from the NDVI maps, which are a valuable tool for growers.",arxiv
http://arxiv.org/abs/2008.08001v1,2020-08-18T16:00:36Z,2020-08-18T16:00:36Z,"Offloading Optimization in Edge Computing for Deep Learning Enabled
  Target Tracking by Internet-of-UAVs","The empowering unmanned aerial vehicles (UAVs) have been extensively used in
providing intelligence such as target tracking. In our field experiments, a
pre-trained convolutional neural network (CNN) is deployed at the UAV to
identify a target (a vehicle) from the captured video frames and enable the UAV
to keep tracking. However, this kind of visual target tracking demands a lot of
computational resources due to the desired high inference accuracy and
stringent delay requirement. This motivates us to consider offloading this type
of deep learning (DL) tasks to a mobile edge computing (MEC) server due to
limited computational resource and energy budget of the UAV, and further
improve the inference accuracy. Specifically, we propose a novel hierarchical
DL tasks distribution framework, where the UAV is embedded with lower layers of
the pre-trained CNN model, while the MEC server with rich computing resources
will handle the higher layers of the CNN model. An optimization problem is
formulated to minimize the weighted-sum cost including the tracking delay and
energy consumption introduced by communication and computing of the UAVs, while
taking into account the quality of data (e.g., video frames) input to the DL
model and the inference errors. Analytical results are obtained and insights
are provided to understand the tradeoff between the weighted-sum cost and
inference error rate in the proposed framework. Numerical results demonstrate
the effectiveness of the proposed offloading framework.",arxiv
http://arxiv.org/abs/2009.07478v1,2020-09-16T05:36:29Z,2020-09-16T05:36:29Z,"Location-aware Predictive Beamforming for UAV Communications: A Deep
  Learning Approach","Unmanned aerial vehicle (UAV)-assisted communication becomes a promising
technique to realize the beyond fifth generation (5G) wireless networks, due to
the high mobility and maneuverability of UAVs which can adapt to heterogeneous
requirements of different applications. However, the movement of UAVs impose
challenge for accurate beam alignment between the UAV and the ground user
equipment (UE). In this letter, we propose a deep learning-based location-aware
predictive beamforming scheme to track the beam for UAV communications in a
dynamic scenario. Specifically, a long short-term memory (LSTM)-based recurrent
neural network (LRNet) is designed for UAV location prediction. Based on the
predicted location, a predicted angle between the UAV and the UE can be
determined for effective and fast beam alignment in the next time slot, which
enables reliable communications between the UAV and the UE. Simulation results
demonstrate that the proposed scheme can achieve a satisfactory UAV-to-UE
communication rate, which is close to the upper bound of communication rate
obtained by the perfect genie-aided alignment scheme.",arxiv
http://arxiv.org/abs/2104.10511v1,2021-04-21T13:07:58Z,2021-04-21T13:07:58Z,"Hierarchical Convolutional Neural Network with Feature Preservation and
  Autotuned Thresholding for Crack Detection","Drone imagery is increasingly used in automated inspection for infrastructure
surface defects, especially in hazardous or unreachable environments. In
machine vision, the key to crack detection rests with robust and accurate
algorithms for image processing. To this end, this paper proposes a deep
learning approach using hierarchical convolutional neural networks with feature
preservation (HCNNFP) and an intercontrast iterative thresholding algorithm for
image binarization. First, a set of branch networks is proposed, wherein the
output of previous convolutional blocks is half-sizedly concatenated to the
current ones to reduce the obscuration in the down-sampling stage taking into
account the overall information loss. Next, to extract the feature map
generated from the enhanced HCNN, a binary contrast-based autotuned
thresholding (CBAT) approach is developed at the post-processing step, where
patterns of interest are clustered within the probability map of the identified
features. The proposed technique is then applied to identify surface cracks on
the surface of roads, bridges or pavements. An extensive comparison with
existing techniques is conducted on various datasets and subject to a number of
evaluation criteria including the average F-measure (AF\b{eta}) introduced here
for dynamic quantification of the performance. Experiments on crack images,
including those captured by unmanned aerial vehicles inspecting a monorail
bridge. The proposed technique outperforms the existing methods on various
tested datasets especially for GAPs dataset with an increase of about 1.4% in
terms of AF\b{eta} while the mean percentage error drops by 2.2%. Such
performance demonstrates the merits of the proposed HCNNFP architecture for
surface defect inspection.",arxiv
http://arxiv.org/abs/2106.15045v1,2021-06-29T01:16:01Z,2021-06-29T01:16:01Z,"EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing
  And Following","The rapid rise of accessibility of unmanned aerial vehicles or drones pose a
threat to general security and confidentiality. Most of the commercially
available or custom-built drones are multi-rotors and are comprised of multiple
propellers. Since these propellers rotate at a high-speed, they are generally
the fastest moving parts of an image and cannot be directly ""seen"" by a
classical camera without severe motion blur. We utilize a class of sensors that
are particularly suitable for such scenarios called event cameras, which have a
high temporal resolution, low-latency, and high dynamic range.
  In this paper, we model the geometry of a propeller and use it to generate
simulated events which are used to train a deep neural network called EVPropNet
to detect propellers from the data of an event camera. EVPropNet directly
transfers to the real world without any fine-tuning or retraining. We present
two applications of our network: (a) tracking and following an unmarked drone
and (b) landing on a near-hover drone. We successfully evaluate and demonstrate
the proposed approach in many real-world experiments with different propeller
shapes and sizes. Our network can detect propellers at a rate of 85.1% even
when 60% of the propeller is occluded and can run at upto 35Hz on a 2W power
budget. To our knowledge, this is the first deep learning-based solution for
detecting propellers (to detect drones). Finally, our applications also show an
impressive success rate of 92% and 90% for the tracking and landing tasks
respectively.",arxiv
http://arxiv.org/abs/2107.00422v1,2021-07-01T13:08:31Z,2021-07-01T13:08:31Z,"Generating Synthetic Training Data for Deep Learning-Based UAV
  Trajectory Prediction","Deep learning-based models, such as recurrent neural networks (RNNs), have
been applied to various sequence learning tasks with great success. Following
this, these models are increasingly replacing classic approaches in object
tracking applications for motion prediction. On the one hand, these models can
capture complex object dynamics with less modeling required, but on the other
hand, they depend on a large amount of training data for parameter tuning.
Towards this end, we present an approach for generating synthetic trajectory
data of unmanned-aerial-vehicles (UAVs) in image space. Since UAVs, or rather
quadrotors are dynamical systems, they can not follow arbitrary trajectories.
With the prerequisite that UAV trajectories fulfill a smoothness criterion
corresponding to a minimal change of higher-order motion, methods for planning
aggressive quadrotors flights can be utilized to generate optimal trajectories
through a sequence of 3D waypoints. By projecting these maneuver trajectories,
which are suitable for controlling quadrotors, to image space, a versatile
trajectory data set is realized. To demonstrate the applicability of the
synthetic trajectory data, we show that an RNN-based prediction model solely
trained on the generated data can outperform classic reference models on a
real-world UAV tracking dataset. The evaluation is done on the publicly
available ANTI-UAV dataset.",arxiv
http://arxiv.org/abs/2109.02716v2,2021-10-22T08:34:08Z,2021-09-06T19:58:54Z,"Vision Transformers For Weeds and Crops Classification Of High
  Resolution UAV Images","Crop and weed monitoring is an important challenge for agriculture and food
production nowadays. Thanks to recent advances in data acquisition and
computation technologies, agriculture is evolving to a more smart and precision
farming to meet with the high yield and high quality crop production.
Classification and recognition in Unmanned Aerial Vehicles (UAV) images are
important phases for crop monitoring. Advances in deep learning models relying
on Convolutional Neural Network (CNN) have achieved high performances in image
classification in the agricultural domain. Despite the success of this
architecture, CNN still faces many challenges such as high computation cost,
the need of large labelled datasets, ... Natural language processing's
transformer architecture can be an alternative approach to deal with CNN's
limitations. Making use of the self-attention paradigm, Vision Transformer
(ViT) models can achieve competitive or better results without applying any
convolution operations. In this paper, we adopt the self-attention mechanism
via the ViT models for plant classification of weeds and crops: red beet,
off-type beet (green leaves), parsley and spinach. Our experiments show that
with small set of labelled training data, ViT models perform better compared to
state-of-the-art CNN-based models EfficientNet and ResNet, with a top accuracy
of 99.8\% achieved by the ViT model.",arxiv
http://arxiv.org/abs/1907.12650v2,2020-01-18T19:33:53Z,2019-07-30T15:41:01Z,"Beyond Safety Drivers: Staffing a Teleoperations System for Autonomous
  Vehicles","Driverless vehicles promise a host of societal benefits including
dramatically improved safety, increased accessibility, greater productivity,
and higher quality of life. As this new technology approaches widespread
deployment, both industry and government are making provisions for
teleoperations systems, in which remote human agents provide assistance to
driverless vehicles. This assistance can involve real-time remote operation and
even ahead-of-time input via human-in-the-loop artificial intelligence systems.
In this paper, we address the problem of staffing such a remote support center.
Our analysis focuses on the tradeoffs between the total number of remote
agents, the reliability of the remote support system, and the resulting safety
of the driverless vehicles. By establishing a novel connection between queues
with large batch arrivals and storage processes, we determine the probability
of the system exceeding its service capacity. This connection drives our
staffing methodology. We also develop a numerical method to compute the exact
staffing level needed to achieve various performance measures. This moment
generating function based technique may be of independent interest, and our
overall staffing analysis may be of use in other applications that combine
human expertise and automated systems.",arxiv
http://arxiv.org/abs/2003.03576v1,2020-03-07T13:05:03Z,2020-03-07T13:05:03Z,"A machine learning environment for evaluating autonomous driving
  software","Autonomous vehicles need safe development and testing environments. Many
traffic scenarios are such that they cannot be tested in the real world. We see
hybrid photorealistic simulation as a viable tool for developing AI (artificial
intelligence) software for autonomous driving. We present a machine learning
environment for detecting autonomous vehicle corner case behavior. Our
environment is based on connecting the CARLA simulation software to TensorFlow
machine learning framework and custom AI client software. The AI client
software receives data from a simulated world via virtual sensors and
transforms the data into information using machine learning models. The AI
clients control vehicles in the simulated world. Our environment monitors the
state assumed by the vehicle AIs to the ground truth state derived from the
simulation model. Our system can search for corner cases where the vehicle AI
is unable to correctly understand the situation. In our paper, we present the
overall hybrid simulator architecture and compare different configurations. We
present performance measurements from real setups, and outline the main
parameters affecting the hybrid simulator performance.",arxiv
http://arxiv.org/abs/1610.07089v1,2016-10-22T19:27:20Z,2016-10-22T19:27:20Z,"Reinforcement Learning in Conflicting Environments for Autonomous
  Vehicles","In this work, we investigate the application of Reinforcement Learning to two
well known decision dilemmas, namely Newcomb's Problem and Prisoner's Dilemma.
These problems are exemplary for dilemmas that autonomous agents are faced with
when interacting with humans. Furthermore, we argue that a Newcomb-like
formulation is more adequate in the human-machine interaction case and
demonstrate empirically that the unmodified Reinforcement Learning algorithms
end up with the well known maximum expected utility solution.",arxiv
http://arxiv.org/abs/1705.01196v2,2018-02-27T03:09:02Z,2017-05-02T22:57:36Z,"Navigating Occluded Intersections with Autonomous Vehicles using Deep
  Reinforcement Learning","Providing an efficient strategy to navigate safely through unsignaled
intersections is a difficult task that requires determining the intent of other
drivers. We explore the effectiveness of Deep Reinforcement Learning to handle
intersection problems. Using recent advances in Deep RL, we are able to learn
policies that surpass the performance of a commonly-used heuristic approach in
several metrics including task completion time and goal success rate and have
limited ability to generalize. We then explore a system's ability to learn
active sensing behaviors to enable navigating safely in the case of occlusions.
Our analysis, provides insight into the intersection handling problem, the
solutions learned by the network point out several shortcomings of current
rule-based methods, and the failures of our current deep reinforcement learning
system point to future research directions.",arxiv
http://arxiv.org/abs/2008.12451v1,2020-08-28T02:57:11Z,2020-08-28T02:57:11Z,"Meta Reinforcement Learning-Based Lane Change Strategy for Autonomous
  Vehicles","Recent advances in supervised learning and reinforcement learning have
provided new opportunities to apply related methodologies to automated driving.
However, there are still challenges to achieve automated driving maneuvers in
dynamically changing environments. Supervised learning algorithms such as
imitation learning can generalize to new environments by training on a large
amount of labeled data, however, it can be often impractical or
cost-prohibitive to obtain sufficient data for each new environment. Although
reinforcement learning methods can mitigate this data-dependency issue by
training the agent in a trial-and-error way, they still need to re-train
policies from scratch when adapting to new environments. In this paper, we thus
propose a meta reinforcement learning (MRL) method to improve the agent's
generalization capabilities to make automated lane-changing maneuvers at
different traffic environments, which are formulated as different traffic
congestion levels. Specifically, we train the model at light to moderate
traffic densities and test it at a new heavy traffic density condition. We use
both collision rate and success rate to quantify the safety and effectiveness
of the proposed model. A benchmark model is developed based on a pretraining
method, which uses the same network structure and training tasks as our
proposed model for fair comparison. The simulation results shows that the
proposed method achieves an overall success rate up to 20% higher than the
benchmark model when it is generalized to the new environment of heavy traffic
density. The collision rate is also reduced by up to 18% than the benchmark
model. Finally, the proposed model shows more stable and efficient
generalization capabilities adapting to the new environment, and it can achieve
100% successful rate and 0% collision rate with only a few steps of gradient
updates.",arxiv
http://arxiv.org/abs/2103.07268v1,2021-03-12T13:42:25Z,2021-03-12T13:42:25Z,"Adversarial Machine Learning Security Problems for 6G: mmWave Beam
  Prediction Use-Case","6G is the next generation for the communication systems. In recent years,
machine learning algorithms have been applied widely in various fields such as
health, transportation, and the autonomous car. The predictive algorithms will
be used in 6G problems. With the rapid developments of deep learning
techniques, it is critical to take the security concern into account to apply
the algorithms. While machine learning offers significant advantages for 6G, AI
models' security is ignored. Since it has many applications in the real world,
security is a vital part of the algorithms. This paper has proposed a
mitigation method for adversarial attacks against proposed 6G machine learning
models for the millimeter-wave (mmWave) beam prediction with adversarial
learning. The main idea behind adversarial attacks against machine learning
models is to produce faulty results by manipulating trained deep learning
models for 6G applications for mmWave beam prediction use case. We have also
presented the adversarial learning mitigation method's performance for 6G
security in millimeter-wave beam prediction application with fast gradient sign
method attack. The mean square errors of the defended model and undefended
model are very close.",arxiv
http://arxiv.org/abs/1412.7006v2,2015-07-08T01:14:14Z,2014-12-22T14:54:53Z,"Multi-modal Sensor Registration for Vehicle Perception via Deep Neural
  Networks","The ability to simultaneously leverage multiple modes of sensor information
is critical for perception of an automated vehicle's physical surroundings.
Spatio-temporal alignment of registration of the incoming information is often
a prerequisite to analyzing the fused data. The persistence and reliability of
multi-modal registration is therefore the key to the stability of decision
support systems ingesting the fused information. LiDAR-video systems like on
those many driverless cars are a common example of where keeping the LiDAR and
video channels registered to common physical features is important. We develop
a deep learning method that takes multiple channels of heterogeneous data, to
detect the misalignment of the LiDAR-video inputs. A number of variations were
tested on the Ford LiDAR-video driving test data set and will be discussed. To
the best of our knowledge the use of multi-modal deep convolutional neural
networks for dynamic real-time LiDAR-video registration has not been presented.",arxiv
http://arxiv.org/abs/2103.10873v1,2021-03-19T15:56:58Z,2021-03-19T15:56:58Z,"Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power
  Autonomous Flying Nano-UAVs","Artificial intelligence-powered pocket-sized air robots have the potential to
revolutionize the Internet-of-Things ecosystem, acting as autonomous,
unobtrusive, and ubiquitous smart sensors. With a few cm$^{2}$ form-factor,
nano-sized unmanned aerial vehicles (UAVs) are the natural befit for indoor
human-drone interaction missions, as the pose estimation task we address in
this work. However, this scenario is challenged by the nano-UAVs' limited
payload and computational power that severely relegates the onboard brain to
the sub-100 mW microcontroller unit-class. Our work stands at the intersection
of the novel parallel ultra-low-power (PULP) architectural paradigm and our
general development methodology for deep neural network (DNN) visual pipelines,
i.e., covering from perception to control. Addressing the DNN model design,
from training and dataset augmentation to 8-bit quantization and deployment, we
demonstrate how a PULP-based processor, aboard a nano-UAV, is sufficient for
the real-time execution (up to 135 frame/s) of our novel DNN, called
PULP-Frontnet. We showcase how, scaling our model's memory and computational
requirement, we can significantly improve the onboard inference (top energy
efficiency of 0.43 mJ/frame) with no compromise in the quality-of-result vs. a
resource-unconstrained baseline (i.e., full-precision DNN). Field experiments
demonstrate a closed-loop top-notch autonomous navigation capability, with a
heavily resource-constrained 27-gram Crazyflie 2.1 nano-quadrotor. Compared
against the control performance achieved using an ideal sensing setup, onboard
relative pose inference yields excellent drone behavior in terms of median
absolute errors, such as positional (onboard: 41 cm, ideal: 26 cm) and angular
(onboard: 3.7$^{\circ}$, ideal: 4.1$^{\circ}$).",arxiv
http://arxiv.org/abs/2104.07246v1,2021-04-15T05:33:03Z,2021-04-15T05:33:03Z,"Human-in-the-Loop Deep Reinforcement Learning with Application to
  Autonomous Driving","Due to the limited smartness and abilities of machine intelligence, currently
autonomous vehicles are still unable to handle all kinds of situations and
completely replace drivers. Because humans exhibit strong robustness and
adaptability in complex driving scenarios, it is of great importance to
introduce humans into the training loop of artificial intelligence, leveraging
human intelligence to further advance machine learning algorithms. In this
study, a real-time human-guidance-based deep reinforcement learning (Hug-DRL)
method is developed for policy training of autonomous driving. Leveraging a
newly designed control transfer mechanism between human and automation, human
is able to intervene and correct the agent's unreasonable actions in real time
when necessary during the model training process. Based on this
human-in-the-loop guidance mechanism, an improved actor-critic architecture
with modified policy and value networks is developed. The fast convergence of
the proposed Hug-DRL allows real-time human guidance actions to be fused into
the agent's training loop, further improving the efficiency and performance of
deep reinforcement learning. The developed method is validated by
human-in-the-loop experiments with 40 subjects and compared with other
state-of-the-art learning approaches. The results suggest that the proposed
method can effectively enhance the training efficiency and performance of the
deep reinforcement learning algorithm under human guidance, without imposing
specific requirements on participant expertise and experience.",arxiv
http://arxiv.org/abs/1909.03664v2,2021-06-03T18:29:14Z,2019-09-09T07:11:20Z,Learning How to Dynamically Route Autonomous Vehicles on Shared Roads,"Road congestion induces significant costs across the world, and road network
disturbances, such as traffic accidents, can cause highly congested traffic
patterns. If a planner had control over the routing of all vehicles in the
network, they could easily reverse this effect. In a more realistic scenario,
we consider a planner that controls autonomous cars, which are a fraction of
all present cars. We study a dynamic routing game, in which the route choices
of autonomous cars can be controlled and the human drivers react selfishly and
dynamically. As the problem is prohibitively large, we use deep reinforcement
learning to learn a policy for controlling the autonomous vehicles. This policy
indirectly influences human drivers to route themselves in such a way that
minimizes congestion on the network. To gauge the effectiveness of our learned
policies, we establish theoretical results characterizing equilibria and
empirically compare the learned policy results with best possible equilibria.
We prove properties of equilibria on parallel roads and provide a
polynomial-time optimization for computing the most efficient equilibrium.
Moreover, we show that in the absence of these policies, high demand and
network perturbations would result in large congestion, whereas using the
policy greatly decreases the travel times by minimizing the congestion. To the
best of our knowledge, this is the first work that employs deep reinforcement
learning to reduce congestion by indirectly influencing humans' routing
decisions in mixed-autonomy traffic.",arxiv
http://arxiv.org/abs/1909.11315v1,2019-09-25T07:27:18Z,2019-09-25T07:27:18Z,"6G Wireless Communication Systems: Applications, Requirements,
  Technologies, Challenges, and Research Directions","Fifth-generation (5G) communication, which has many more features than
fourth-generation communication, will be officially launched very soon. A new
paradigm of wireless communication, the sixth-generation (6G) system, with the
full support of artificial intelligence is expected to be deployed between 2027
and 2030. In beyond 5G, there are some fundamental issues, which need to be
addressed are higher system capacity, higher data rate, lower latency, and
improved quality of service (QoS) compared to 5G system. This paper presents
the vision of future 6G wireless communication and its network architecture. We
discuss the emerging technologies such as artificial intelligence, terahertz
communications, optical wireless technology, free space optic network,
blockchain, three-dimensional networking, quantum communications, unmanned
aerial vehicle, cell-free communications, integration of wireless information
and energy transfer, integration of sensing and communication, integration of
access-backhaul networks, dynamic network slicing, holographic beamforming, and
big data analytics that can assist the 6G architecture development in
guaranteeing the QoS. We present the expected applications with the
requirements and the possible technologies for 6G communication. We also
outline the possible challenges and research directions to reach this goal.",arxiv
http://arxiv.org/abs/1809.04471v2,2018-10-19T16:09:37Z,2018-09-12T14:10:35Z,Learning structure-from-motion from motion,"This work is based on a questioning of the quality metrics used by deep
neural networks performing depth prediction from a single image, and then of
the usability of recently published works on unsupervised learning of depth
from videos. To overcome their limitations, we propose to learn in the same
unsupervised manner a depth map inference system from monocular videos that
takes a pair of images as input. This algorithm actually learns
structure-from-motion from motion, and not only structure from context
appearance. The scale factor issue is explicitly treated, and the absolute
depth map can be estimated from camera displacement magnitude, which can be
easily measured from cheap external sensors. Our solution is also much more
robust with respect to domain variation and adaptation via fine tuning, because
it does not rely entirely in depth from context. Two use cases are considered,
unstabilized moving camera videos, and stabilized ones. This choice is
motivated by the UAV (for Unmanned Aerial Vehicle) use case that generally
provides reliable orientation measurement. We provide a set of experiments
showing that, used in real conditions where only speed can be known, our
network outperforms competitors for most depth quality measures. Results are
given on the well known KITTI dataset, which provides robust stabilization for
our second use case, but also contains moving scenes which are very typical of
the in-car road context. We then present results on a synthetic dataset that we
believe to be more representative of typical UAV scenes. Lastly, we present two
domain adaptation use cases showing superior robustness of our method compared
to single view depth algorithms, which indicates that it is better suited for
highly variable visual contexts.",arxiv
http://arxiv.org/abs/2012.15754v1,2020-12-22T12:11:19Z,2020-12-22T12:11:19Z,"Limitations of Deep Neural Networks: a discussion of G. Marcus' critical
  appraisal of deep learning","Deep neural networks have triggered a revolution in artificial intelligence,
having been applied with great results in medical imaging, semi-autonomous
vehicles, ecommerce, genetics research, speech recognition, particle physics,
experimental art, economic forecasting, environmental science, industrial
manufacturing, and a wide variety of applications in nearly every field. This
sudden success, though, may have intoxicated the research community and blinded
them to the potential pitfalls of assigning deep learning a higher status than
warranted. Also, research directed at alleviating the weaknesses of deep
learning may seem less attractive to scientists and engineers, who focus on the
low-hanging fruit of finding more and more applications for deep learning
models, thus letting short-term benefits hamper long-term scientific progress.
Gary Marcus wrote a paper entitled Deep Learning: A Critical Appraisal, and
here we discuss Marcus' core ideas, as well as attempt a general assessment of
the subject. This study examines some of the limitations of deep neural
networks, with the intention of pointing towards potential paths for future
research, and of clearing up some metaphysical misconceptions, held by numerous
researchers, that may misdirect them.",arxiv
http://arxiv.org/abs/1905.00988v1,2019-05-02T22:45:26Z,2019-05-02T22:45:26Z,Behavior Planning of Autonomous Cars with Social Perception,"Autonomous cars have to navigate in dynamic environment which can be full of
uncertainties. The uncertainties can come either from sensor limitations such
as occlusions and limited sensor range, or from probabilistic prediction of
other road participants, or from unknown social behavior in a new area. To
safely and efficiently drive in the presence of these uncertainties, the
decision-making and planning modules of autonomous cars should intelligently
utilize all available information and appropriately tackle the uncertainties so
that proper driving strategies can be generated. In this paper, we propose a
social perception scheme which treats all road participants as distributed
sensors in a sensor network. By observing the individual behaviors as well as
the group behaviors, uncertainties of the three types can be updated uniformly
in a belief space. The updated beliefs from the social perception are then
explicitly incorporated into a probabilistic planning framework based on Model
Predictive Control (MPC). The cost function of the MPC is learned via inverse
reinforcement learning (IRL). Such an integrated probabilistic planning module
with socially enhanced perception enables the autonomous vehicles to generate
behaviors which are defensive but not overly conservative, and socially
compatible. The effectiveness of the proposed framework is verified in
simulation on an representative scenario with sensor occlusions.",arxiv
http://arxiv.org/abs/2010.11347v2,2021-01-23T21:36:32Z,2020-10-21T23:31:35Z,"Correlation-aware Cooperative Multigroup Broadcast 360 Video
  Delivery Network: A Hierarchical Deep Reinforcement Learning Approach","With the stringent requirement of receiving video from unmanned aerial
vehicle (UAV) from anywhere in the stadium of sports events and the
significant-high per-cell throughput for video transmission to virtual reality
(VR) users, a promising solution is a cell-free multi-group broadcast (CF-MB)
network with cooperative reception and broadcast access points (AP). To explore
the benefit of broadcasting user-correlated decode-dependent video resources to
spatially correlated VR users, the network should dynamically schedule the
video and cluster APs into virtual cells for a different group of VR users with
overlapped video requests. By decomposition the problem into scheduling and
association sub-problems, we first introduce the conventional
non-learning-based scheduling and association algorithms, and a centralized
deep reinforcement learning (DRL) association approach based on the rainbow
agent with a convolutional neural network (CNN) to generate decisions from
observation. To reduce its complexity, we then decompose the association
problem into multiple sub-problems, resulting in a networked-distributed
Partially Observable Markov decision process (ND-POMDP). To solve it, we
propose a multi-agent deep DRL algorithm. To jointly solve the coupled
association and scheduling problems, we further develop a hierarchical
federated DRL algorithm with scheduler as meta-controller, and association as
the controller. Our simulation results shown that our CF-MB network can
effectively handle real-time video transmission from UAVs to VR users. Our
proposed learning architectures is effective and scalable for a
high-dimensional cooperative association problem with increasing APs and VR
users. Also, our proposed algorithms outperform non-learning based methods with
significant performance improvement.",arxiv
http://arxiv.org/abs/1808.08413v1,2018-08-25T11:56:45Z,2018-08-25T11:56:45Z,"A Brief Survey and an Application of Semantic Image Segmentation for
  Autonomous Driving","Deep learning is a fast-growing machine learning approach to perceive and
understand large amounts of data. In this paper, general information about the
deep learning approach which is attracted much attention in the field of
machine learning is given in recent years and an application about semantic
image segmentation is carried out in order to help autonomous driving of
autonomous vehicles. This application is implemented with Fully Convolutional
Network (FCN) architectures obtained by modifying the Convolutional Neural
Network (CNN) architectures based on deep learning. Experimental studies for
the application are utilized 4 different FCN architectures named
FCN-AlexNet,FCN-8s, FCN-16s and FCN-32s. For the experimental studies, FCNs are
first trained separately and validation accuracies of these trained network
models on the used dataset is compared. In addition, image segmentation
inferences are visualized to take account of how precisely FCN architectures
can segment objects.",arxiv
http://arxiv.org/abs/2105.03834v2,2021-05-17T19:01:33Z,2021-05-09T04:34:10Z,Learning Image Attacks toward Vision Guided Autonomous Vehicles,"While adversarial neural networks have been shown successful for static image
attacks, very few approaches have been developed for attacking online image
streams while taking into account the underlying physical dynamics of
autonomous vehicles, their mission, and environment. This paper presents an
online adversarial machine learning framework that can effectively misguide
autonomous vehicles' missions. In the existing image attack methods devised
toward autonomous vehicles, optimization steps are repeated for every image
frame. This framework removes the need for fully converged optimization at
every frame to realize image attacks in real-time. Using reinforcement
learning, a generative neural network is trained over a set of image frames to
obtain an attack policy that is more robust to dynamic and uncertain
environments. A state estimator is introduced for processing image streams to
reduce the attack policy's sensitivity to physical variables such as unknown
position and velocity. A simulation study is provided to validate the results.",arxiv
http://arxiv.org/abs/1906.07064v1,2019-06-04T16:41:36Z,2019-06-04T16:41:36Z,"On-board Deep Q-Network for UAV-assisted Online Power Transfer and Data
  Collection","Unmanned Aerial Vehicles (UAVs) with Microwave Power Transfer (MPT)
capability provide a practical means to deploy a large number of wireless
powered sensing devices into areas with no access to persistent power supplies.
The UAV can charge the sensing devices remotely and harvest their data. A key
challenge is online MPT and data collection in the presence of on-board control
of a UAV (e.g., patrolling velocity) for preventing battery drainage and data
queue overflow of the sensing devices, while up-to-date knowledge on battery
level and data queue of the devices is not available at the UAV. In this paper,
an on-board deep Q-network is developed to minimize the overall data packet
loss of the sensing devices, by optimally deciding the device to be charged and
interrogated for data collection, and the instantaneous patrolling velocity of
the UAV. Specifically, we formulate a Markov Decision Process (MDP) with the
states of battery level and data queue length of sensing devices, channel
conditions, and waypoints given the trajectory of the UAV; and solve it
optimally with Q-learning. Furthermore, we propose the on-board deep Q-network
that can enlarge the state space of the MDP, and a deep reinforcement learning
based scheduling algorithm that asymptotically derives the optimal solution
online, even when the UAV has only outdated knowledge on the MDP states.
Numerical results demonstrate that the proposed deep reinforcement learning
algorithm reduces the packet loss by at least 69.2%, as compared to existing
non-learning greedy algorithms.",arxiv
http://arxiv.org/abs/1911.05478v1,2019-11-13T14:11:17Z,2019-11-13T14:11:17Z,"Deep Reinforcement Learning Attitude Control of Fixed-Wing UAVs Using
  Proximal Policy Optimization","Contemporary autopilot systems for unmanned aerial vehicles (UAVs) are far
more limited in their flight envelope as compared to experienced human pilots,
thereby restricting the conditions UAVs can operate in and the types of
missions they can accomplish autonomously. This paper proposes a deep
reinforcement learning (DRL) controller to handle the nonlinear attitude
control problem, enabling extended flight envelopes for fixed-wing UAVs. A
proof-of-concept controller using the proximal policy optimization (PPO)
algorithm is developed, and is shown to be capable of stabilizing a fixed-wing
UAV from a large set of initial conditions to reference roll, pitch and
airspeed values. The training process is outlined and key factors for its
progression rate are considered, with the most important factor found to be
limiting the number of variables in the observation vector, and including
values for several previous time steps for these variables. The trained
reinforcement learning (RL) controller is compared to a
proportional-integral-derivative (PID) controller, and is found to converge in
more cases than the PID controller, with comparable performance. Furthermore,
the RL controller is shown to generalize well to unseen disturbances in the
form of wind and turbulence, even in severe disturbance conditions.",arxiv
http://arxiv.org/abs/2004.11543v4,2020-08-27T03:18:12Z,2020-04-24T05:56:19Z,"Continuous Deep Hierarchical Reinforcement Learning for Ground-Air Swarm
  Shepherding","The control and guidance of multi-robots (swarm) is a non-trivial problem due
to the complexity inherent in the coupled interaction among the group. Whether
the swarm is cooperative or non-cooperative, lessons can be learnt from
sheepdogs herding sheep. Biomimicry of shepherding offers computational methods
for swarm control with the potential to generalize and scale in different
environments. However, learning to shepherd is complex due to the large search
space that a machine learner is faced with. We present a deep hierarchical
reinforcement learning approach for shepherding, whereby an unmanned aerial
vehicle (UAV) learns to act as an aerial sheepdog to control and guide a swarm
of unmanned ground vehicles (UGVs). The approach extends our previous work on
machine education to decompose the search space into a hierarchically organized
curriculum. Each lesson in the curriculum is learnt by a deep reinforcement
learning model. The hierarchy is formed by fusing the outputs of the model. The
approach is demonstrated first in a high-fidelity robotic-operating-system
(ROS)-based simulation environment, then with physical UGVs and a UAV in an
in-door testing facility. We investigate the ability of the method to
generalize as the models move from simulation to the real-world and as the
models move from one scale to another.",arxiv
http://arxiv.org/abs/2103.02676v1,2021-03-03T20:54:19Z,2021-03-03T20:54:19Z,Efficient UAV Trajectory-Planning using Economic Reinforcement Learning,"Advances in unmanned aerial vehicle (UAV) design have opened up applications
as varied as surveillance, firefighting, cellular networks, and delivery
applications. Additionally, due to decreases in cost, systems employing fleets
of UAVs have become popular. The uniqueness of UAVs in systems creates a novel
set of trajectory or path planning and coordination problems. Environments
include many more points of interest (POIs) than UAVs, with obstacles and
no-fly zones. We introduce REPlanner, a novel multi-agent reinforcement
learning algorithm inspired by economic transactions to distribute tasks
between UAVs. This system revolves around an economic theory, in particular an
auction mechanism where UAVs trade assigned POIs. We formulate the path
planning problem as a multi-agent economic game, where agents can cooperate and
compete for resources. We then translate the problem into a Partially
Observable Markov decision process (POMDP), which is solved using a
reinforcement learning (RL) model deployed on each agent. As the system
computes task distributions via UAV cooperation, it is highly resilient to any
change in the swarm size. Our proposed network and economic game architecture
can effectively coordinate the swarm as an emergent phenomenon while
maintaining the swarm's operation. Evaluation results prove that REPlanner
efficiently outperforms conventional RL-based trajectory search.",arxiv
http://arxiv.org/abs/2103.08181v1,2021-03-15T07:39:32Z,2021-03-15T07:39:32Z,"Multi-Agent Reinforcement Learning based Joint Cooperative Spectrum
  Sensing and Channel Access for Cognitive UAV Networks","Designing clustered unmanned aerial vehicle (UAV) communication networks
based on cognitive radio (CR) and reinforcement learning can significantly
improve the intelligence level of clustered UAV communication networks and the
robustness of the system in a time-varying environment. Among them, designing
smarter systems for spectrum sensing and access is a key research issue in CR.
Therefore, we focus on the dynamic cooperative spectrum sensing and channel
access in clustered cognitive UAV (CUAV) communication networks. Due to the
lack of prior statistical information on the primary user (PU) channel
occupancy state, we propose to use multi-agent reinforcement learning (MARL) to
model CUAV spectrum competition and cooperative decision-making problem in this
dynamic scenario, and a return function based on the weighted compound of
sensing-transmission cost and utility is introduced to characterize the
real-time rewards of multi-agent game. On this basis, a time slot multi-round
revisit exhaustive search algorithm based on virtual controller (VC-EXH), a
Q-learning algorithm based on independent learner (IL-Q) and a deep Q-learning
algorithm based on independent learner (IL-DQN) are respectively proposed.
Further, the information exchange overhead, execution complexity and
convergence of the three algorithms are briefly analyzed. Through the numerical
simulation analysis, all three algorithms can converge quickly, significantly
improve system performance and increase the utilization of idle spectrum
resources.",arxiv
http://arxiv.org/abs/2105.10605v1,2021-05-21T23:22:43Z,2021-05-21T23:22:43Z,"Programming and Deployment of Autonomous Swarms using Multi-Agent
  Reinforcement Learning","Autonomous systems (AS) carry out complex missions by continuously observing
the state of their surroundings and taking actions toward a goal. Swarms of AS
working together can complete missions faster and more effectively than single
AS alone. To build swarms today, developers handcraft their own software for
storing, aggregating, and learning from observations. We present the Fleet
Computer, a platform for developing and managing swarms. The Fleet Computer
provides a programming paradigm that simplifies multi-agent reinforcement
learning (MARL) -- an emerging class of algorithms that coordinate swarms of
agents. Using just two programmer-provided functions Map() and Eval(), the
Fleet Computer compiles and deploys swarms and continuously updates the
reinforcement learning models that govern actions. To conserve compute
resources, the Fleet Computer gives priority scheduling to models that
contribute to effective actions, drawing a novel link between online learning
and resource management. We developed swarms for unmanned aerial vehicles (UAV)
in agriculture and for video analytics on urban traffic. Compared to individual
AS, our swarms achieved speedup of 4.4X using 4 UAV and 62X using 130 video
cameras. Compared to a competing approach for building swarms that is widely
used in practice, our swarms were 3X more effective, using 3.9X less energy.",arxiv
http://arxiv.org/abs/2009.00173v1,2020-09-01T01:37:01Z,2020-09-01T01:37:01Z,"Automatic Radish Wilt Detection Using Image Processing Based Techniques
  and Machine Learning Algorithm","Image processing, computer vision, and pattern recognition have been playing
a vital role in diverse agricultural applications, such as species detection,
recognition, classification, identification, plant growth stages, plant disease
detection, and many more. On the other hand, there is a growing need to capture
high resolution images using unmanned aerial vehicles (UAV) and to develop
better algorithms in order to find highly accurate and to the point results. In
this paper, we propose a segmentation and extraction-based technique to detect
fusarium wilt in radish crops. Recent wilt detection algorithms are either
based on image processing techniques or conventional machine learning
algorithms. However, our methodology is based on a hybrid algorithm, which
combines image processing and machine learning. First, the crop image is
divided into three segments, which include viz., healthy vegetation, ground and
packing material. Based on the HSV decision tree algorithm, all the three
segments are segregated from the image. Second, the extracted segments are
summed together into an empty canvas of the same resolution as the image and
one new image is produced. Third, this new image is compared with the original
image, and a final noisy image, which contains traces of wilt is extracted.
Finally, a k-means algorithm is applied to eliminate the noise and to extract
the accurate wilt from it. Moreover, the extracted wilt is mapped on the
original image using the contouring method. The proposed combination of
algorithms detects the wilt appropriately, which surpasses the traditional
practice of separately using the image processing techniques or machine
learning.",arxiv
http://arxiv.org/abs/1901.10747v1,2019-01-30T10:22:37Z,2019-01-30T10:22:37Z,Autonomous Cars: Vision based Steering Wheel Angle Estimation,"Machine learning models, which are frequently used in self-driving cars, are
trained by matching the captured images of the road and the measured angle of
the steering wheel. The angle of the steering wheel is generally fetched from
steering angle sensor, which is tightly-coupled to the physical aspects of the
vehicle at hand. Therefore, a model-agnostic autonomous car-kit is very
difficult to be developed and autonomous vehicles need more training data. The
proposed vision based steering angle estimation system argues a new approach
which basically matches the images of the road captured by an outdoor camera
and the images of the steering wheel from an onboard camera, avoiding the
burden of collecting model-dependent training data and the use of any other
electromechanical hardware.",arxiv
http://arxiv.org/abs/2104.06219v1,2021-04-13T14:13:09Z,2021-04-13T14:13:09Z,UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification,"As unmanned aerial vehicles (UAVs) become more accessible with a growing
range of applications, the potential risk of UAV disruption increases. Recent
development in deep learning allows vision-based counter-UAV systems to detect
and track UAVs with a single camera. However, the coverage of a single camera
is limited, necessitating the need for multicamera configurations to match UAVs
across cameras - a problem known as re-identification (reID). While there has
been extensive research on person and vehicle reID to match objects across time
and viewpoints, to the best of our knowledge, there has been no research in UAV
reID. UAVs are challenging to re-identify: they are much smaller than
pedestrians and vehicles and they are often detected in the air so appear at a
greater range of angles. Because no UAV data sets currently use multiple
cameras, we propose the first new UAV re-identification data set, UAV-reID,
that facilitates the development of machine learning solutions in this emerging
area. UAV-reID has two settings: Temporally-Near to evaluate performance across
views to assist tracking frameworks, and Big-to-Small to evaluate reID
performance across scale and to allow early reID when UAVs are detected from a
long distance. We conduct a benchmark study by extensively evaluating different
reID backbones and loss functions. We demonstrate that with the right setup,
deep networks are powerful enough to learn good representations for UAVs,
achieving 81.9% mAP on the Temporally-Near setting and 46.5% on the challenging
Big-to-Small setting. Furthermore, we find that vision transformers are the
most robust to extreme variance of scale.",arxiv
http://arxiv.org/abs/1908.05895v1,2019-08-16T09:01:26Z,2019-08-16T09:01:26Z,Distilling On-Device Intelligence at the Network Edge,"Devices at the edge of wireless networks are the last mile data sources for
machine learning (ML). As opposed to traditional ready-made public datasets,
these user-generated private datasets reflect the freshest local environments
in real time. They are thus indispensable for enabling mission-critical
intelligent systems, ranging from fog radio access networks (RANs) to
driverless cars and e-Health wearables. This article focuses on how to distill
high-quality on-device ML models using fog computing, from such user-generated
private data dispersed across wirelessly connected devices. To this end, we
introduce communication-efficient and privacy-preserving distributed ML
frameworks, termed fog ML (FML), wherein on-device ML models are trained by
exchanging model parameters, model outputs, and surrogate data. We then present
advanced FML frameworks addressing wireless RAN characteristics, limited
on-device resources, and imbalanced data distributions. Our study suggests that
the full potential of FML can be reached by co-designing communication and
distributed ML operations while accounting for heterogeneous hardware
specifications, data characteristics, and user requirements.",arxiv
http://arxiv.org/abs/1804.10390v1,2018-04-27T08:38:22Z,2018-04-27T08:38:22Z,"Automatic classification of trees using a UAV onboard camera and deep
  learning","Automatic classification of trees using remotely sensed data has been a dream
of many scientists and land use managers. Recently, Unmanned aerial vehicles
(UAV) has been expected to be an easy-to-use, cost-effective tool for remote
sensing of forests, and deep learning has attracted attention for its ability
concerning machine vision. In this study, using a commercially available UAV
and a publicly available package for deep learning, we constructed a machine
vision system for the automatic classification of trees. In our method, we
segmented a UAV photography image of forest into individual tree crowns and
carried out object-based deep learning. As a result, the system was able to
classify 7 tree types at 89.0% accuracy. This performance is notable because we
only used basic RGB images from a standard UAV. In contrast, most of previous
studies used expensive hardware such as multispectral imagers to improve the
performance. This result means that our method has the potential to classify
individual trees in a cost-effective manner. This can be a usable tool for many
forest researchers and managements.",arxiv
http://arxiv.org/abs/1702.07600v1,2017-02-24T14:29:35Z,2017-02-24T14:29:35Z,"How hard is it to cross the room? -- Training (Recurrent) Neural
  Networks to steer a UAV","This work explores the feasibility of steering a drone with a (recurrent)
neural network, based on input from a forward looking camera, in the context of
a high-level navigation task. We set up a generic framework for training a
network to perform navigation tasks based on imitation learning. It can be
applied to both aerial and land vehicles. As a proof of concept we apply it to
a UAV (Unmanned Aerial Vehicle) in a simulated environment, learning to cross a
room containing a number of obstacles. So far only feedforward neural networks
(FNNs) have been used to train UAV control. To cope with more complex tasks, we
propose the use of recurrent neural networks (RNN) instead and successfully
train an LSTM (Long-Short Term Memory) network for controlling UAVs. Vision
based control is a sequential prediction problem, known for its highly
correlated input data. The correlation makes training a network hard,
especially an RNN. To overcome this issue, we investigate an alternative
sampling method during training, namely window-wise truncated backpropagation
through time (WW-TBPTT). Further, end-to-end training requires a lot of data
which often is not available. Therefore, we compare the performance of
retraining only the Fully Connected (FC) and LSTM control layers with networks
which are trained end-to-end. Performing the relatively simple task of crossing
a room already reveals important guidelines and good practices for training
neural control networks. Different visualizations help to explain the behavior
learned.",arxiv
http://arxiv.org/abs/1903.02091v1,2019-03-05T22:26:49Z,2019-03-05T22:26:49Z,"Geometric Adaptive Control with Neural Networks for a Quadrotor UAV in
  Wind fields","This paper proposes a geometric adaptive controller for a quadrotor unmanned
aerial vehicle with artificial neural networks. It is assumed that the dynamics
of a quadrotor is disturbed by arbitrary, unstructured forces and moments
caused by wind. To address this, the proposed control system is augmented with
multilayer neural networks, and the weights of neural networks are adjusted
online according to an adaptive law. By utilizing the universal approximation
theorem, it is shown that the effects of unknown disturbances can be mitigated.
More specifically, under the proposed control system, the tracking errors in
the position and the heading direction are uniformly ultimately bounded where
the ultimate bound can be reduced arbitrarily. These are developed directly on
the special Euclidean group to avoid complexities or singularities inherent to
local parameterizations. The efficacy of the proposed control system is first
illustrated by numerical examples. Then, several indoor flight experiments are
presented to demonstrate that the proposed controller successfully rejects the
effects of wind disturbances even for aggressive, agile maneuvers.",arxiv
http://arxiv.org/abs/2011.01558v1,2020-11-03T08:29:34Z,2020-11-03T08:29:34Z,"Enhanced RSS-based UAV Localization via Trajectory and Multi-base
  Stations","To improve the localization precision of unmanned aerial vehicle (UAV), a
novel framework is established by jointly utilizing multiple measurements of
received signal strength (RSS) from multiple base stations (BSs) and multiple
points on trajectory. First, a joint maximum likelihood (ML) of exploiting both
trajectory information and multi-BSs is proposed. To reduce its high
complexity, two low-complexity localization methods are designed. The first
method is from BS to trajectory (BST), called LCSL-BST. First, fixing the nth
BS, by exploiting multiple measurements along trajectory, the position of UAV
is computed by ML rule. Finally, all computed positions of UAV for different
BSs are combined to form the resulting position. The second method reverses the
order, called LCSL-TBS. We also derive the Cramer-Rao lower boundary (CRLB) of
the joint ML method. From simulation results, we can see that the proposed
joint ML and separate LCSL-BST methods have made a significant improvement over
conventional ML method without use of trajectory knowledge in terms of location
performance. The former achieves the joint CRLB and the latter is of
low-complexity.",arxiv
http://arxiv.org/abs/1904.10261v1,2019-04-23T11:59:36Z,2019-04-23T11:59:36Z,"Improving benchmarks for autonomous vehicles testing using synthetically
  generated images","Nowadays autonomous technologies are a very heavily explored area and
particularly computer vision as the main component of vehicle perception. The
quality of the whole vision system based on neural networks relies on the
dataset it was trained on. It is extremely difficult to find traffic sign
datasets from most of the counties of the world. Meaning autonomous vehicle
from the USA will not be able to drive though Lithuania recognizing all road
signs on the way. In this paper, we propose a solution on how to update model
using a small dataset from the country vehicle will be used in. It is important
to mention that is not panacea, rather small upgrade which can boost autonomous
car development in countries with limited data access. We achieved about 10
percent quality raise and expect even better results during future experiments.",arxiv
http://arxiv.org/abs/1804.03284v1,2018-04-10T00:25:37Z,2018-04-10T00:25:37Z,"Echo-Liquid State Deep Learning for $360^\circ$ Content Transmission and
  Caching in Wireless VR Networks with Cellular-Connected UAVs","In this paper, the problem of content caching and transmission is studied for
a wireless virtual reality (VR) network in which unmanned aerial vehicles
(UAVs) capture videos on live games or sceneries and transmit them to small
base stations (SBSs) that service the VR users. However, due to its limited
capacity, the wireless network may not be able to meet the delay requirements
of such 360 content transmissions. To meet the VR delay requirements, the UAVs
can extract specific visible content (e.g., user field of view) from the
original 360 data and send this visible content to the users so as to reduce
the traffic load over backhaul and radio access links. To further alleviate the
UAV-SBS backhaul traffic, the SBSs can also cache the popular contents that
users request. This joint content caching and transmission problem is
formulated as an optimization problem whose goal is to maximize the users'
reliability, defined as the probability that the content transmission delay of
each user satisfies the instantaneous VR delay target. To address this problem,
a distributed deep learning algorithm that brings together new neural network
ideas from liquid state machine (LSM) and echo state networks (ESNs) is
proposed. The proposed algorithm enables each SBS to predict the users'
reliability so as to find the optimal contents to cache and content
transmission format for each UAV. Analytical results are derived to expose the
various network factors that impact content caching and content transmission
format selection. Simulation results show that the proposed algorithm yields
25.4% gain of reliability compared to Q-learning. The results also show that
the proposed algorithm can achieve 14.7% gain of reliability due to the
reduction of traffic load over backhaul compared to the proposed algorithm with
random caching.",arxiv
http://arxiv.org/abs/1806.11368v1,2018-06-29T11:59:14Z,2018-06-29T11:59:14Z,"Detecting Mammals in UAV Images: Best Practices to address a
  substantially Imbalanced Dataset with Deep Learning","Knowledge over the number of animals in large wildlife reserves is a vital
necessity for park rangers in their efforts to protect endangered species.
Manual animal censuses are dangerous and expensive, hence Unmanned Aerial
Vehicles (UAVs) with consumer level digital cameras are becoming a popular
alternative tool to estimate livestock. Several works have been proposed that
semi-automatically process UAV images to detect animals, of which some employ
Convolutional Neural Networks (CNNs), a recent family of deep learning
algorithms that proved very effective in object detection in large datasets
from computer vision. However, the majority of works related to wildlife
focuses only on small datasets (typically subsets of UAV campaigns), which
might be detrimental when presented with the sheer scale of real study areas
for large mammal census. Methods may yield thousands of false alarms in such
cases. In this paper, we study how to scale CNNs to large wildlife census tasks
and present a number of recommendations to train a CNN on a large UAV dataset.
We further introduce novel evaluation protocols that are tailored to censuses
and model suitability for subsequent human verification of detections. Using
our recommendations, we are able to train a CNN reducing the number of false
positives by an order of magnitude compared to previous state-of-the-art.
Setting the requirements at 90% recall, our CNN allows to reduce the amount of
data required for manual verification by three times, thus making it possible
for rangers to screen all the data acquired efficiently and to detect almost
all animals in the reserve automatically.",arxiv
http://arxiv.org/abs/1812.00896v2,2020-06-28T08:06:42Z,2018-12-03T16:50:22Z,"A Coalition-Based Communication Framework for Task-Driven Flying Ad-Hoc
  Networks","In this paper, we develop a task-driven networking framework for Flying
Ad-hoc Networks (FANETs), where a coalition-based model is outlined. Firstly,
we present a brief survey to show the state-of-the-art studies on the
intra-communication of unmanned aerial vehicle (UAV) swarms. The features and
deficiencies of existing models are analyzed. To capture the task-driven
requirement of the flying multi-agent system, a coalition-based framework is
proposed. We discuss the composition, networking mode and the classification of
data transmission. After that, the application scenario of UAV coalitions is
given, where large-scale, distributed and highly dynamic characteristics
greatly increase the difficulty of resource optimization for UAVs. To tackle
the problem, we design an intelligence-based optimization architecture, which
mainly includes the game model, machine learning and real-time decision. Under
the guidance of game theories and machine learning, UAVs can make comprehensive
decisions by combining the previous training results with their sensing,
information interaction, and game strategies. Finally, a preliminary case and
promising open issues of UAV coalitions are studied.",arxiv
http://arxiv.org/abs/2004.11356v3,2020-04-28T21:08:37Z,2020-04-23T17:55:04Z,"From Physics-Based Models to Predictive Digital Twins via Interpretable
  Machine Learning","This work develops a methodology for creating a data-driven digital twin from
a library of physics-based models representing various asset states. The
digital twin is updated using interpretable machine learning. Specifically, we
use optimal trees---a recently developed scalable machine learning method---to
train an interpretable data-driven classifier. Training data for the classifier
are generated offline using simulated scenarios solved by the library of
physics-based models. These data can be further augmented using experimental or
other historical data. In operation, the classifier uses observational data
from the asset to infer which physics-based models in the model library are the
best candidates for the updated digital twin. The approach is demonstrated
through the development of a structural digital twin for a 12ft wingspan
unmanned aerial vehicle. This digital twin is built from a library of
reduced-order models of the vehicle in a range of structural states. The
data-driven digital twin dynamically updates in response to structural damage
or degradation and enables the aircraft to replan a safe mission accordingly.
Within this context, we study the performance of the optimal tree classifiers
and demonstrate how their interpretability enables explainable structural
assessments from sparse sensor measurements, and also informs optimal sensor
placement.",arxiv
http://arxiv.org/abs/1807.02009v1,2018-07-05T13:56:58Z,2018-07-05T13:56:58Z,"On-Demand Deployment of Multiple Aerial Base Stations for Traffic
  Offloading and Network Recovery","Unmanned aerial vehicles (UAVs) are being utilized for a wide spectrum of
applications in wireless networks leading to attractive business opportunities.
In the case of abrupt disruption to existing cellular network operation or
infrastructure, e.g., due to an unexpected surge in user demand or a natural
disaster, UAVs can be deployed to provide instant recovery via temporary
wireless coverage in designated areas. A major challenge is to determine
efficiently how many UAVs are needed and where to position them in a relatively
large 3D search space. To this end, we formulate the problem of 3D deployment
of a fleet of UAVs as a mixed integer linear program, and present a greedy
approach that mimics the optimal behavior assuming a grid composed of a finite
set of possible UAV locations. In addition, we propose and evaluate a novel low
complexity algorithm for multiple UAV deployment in a continuous 3D space,
based on an unsupervised learning technique that relies on the notion of
electrostatics with repulsion and attraction forces. We present performance
results for the proposed algorithm as a function of various system parameters
and demonstrate its effectiveness compared to the close-to-optimal greedy
approach and its superiority compared to recent related work from the
literature.",arxiv
http://arxiv.org/abs/2105.00286v1,2021-05-01T15:35:46Z,2021-05-01T15:35:46Z,"Backhaul-Aware Intelligent Positioning of UAVs and Association of
  Terrestrial Base Stations for Fronthaul Connectivity","The mushroom growth of cellular users requires novel advancements in the
existing cellular infrastructure. One way to handle such a tremendous increase
is to densely deploy terrestrial small-cell base stations (TSBSs) with careful
management of smart backhaul/fronthaul networks. Nevertheless, terrestrial
backhaul hubs significantly suffer from the dense fading environment and are
difficult to install in a typical urban environment. Therefore, this paper
considers the idea of replacing terrestrial backhaul network with an aerial
network consisting of unmanned aerial vehicles (UAVs) to provide the fronthaul
connectivity between the TSBSs and the ground core-network (GCN). To this end,
we focus on the joint positioning of UAVs and the association of TSBSs such
that the sum-rate of the overall system is maximized. In particular, the
association problem of TSBSs with UAVs is formulated under
communication-related constraints, i.e., bandwidth, number of connections to a
UAV, power limit, interference threshold, UAV heights, and backhaul data rate.
To meet this joint objective, we take advantage of the genetic algorithm (GA)
due to the offline nature of our optimization problem. The performance of the
proposed approach is evaluated using the unsupervised learning-based k-means
clustering algorithm. We observe that the proposed approach is highly effective
to satisfy the requirements of smart fronthaul networks.",arxiv
http://arxiv.org/abs/1709.03339v3,2018-02-27T10:14:24Z,2017-09-11T11:39:47Z,Autonomous Quadrotor Landing using Deep Reinforcement Learning,"Landing an unmanned aerial vehicle (UAV) on a ground marker is an open
problem despite the effort of the research community. Previous attempts mostly
focused on the analysis of hand-crafted geometric features and the use of
external sensors in order to allow the vehicle to approach the land-pad. In
this article, we propose a method based on deep reinforcement learning that
only requires low-resolution images taken from a down-looking camera in order
to identify the position of the marker and land the UAV on it. The proposed
approach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level
control policy for the navigation toward the marker. We implemented different
technical solutions, such as the combination of vanilla and double DQNs, and a
partitioned buffer replay. Using domain randomization we trained the vehicle on
uniform textures and we tested it on a large variety of simulated and
real-world environments. The overall performance is comparable with a
state-of-the-art algorithm and human pilots.",arxiv
http://arxiv.org/abs/1809.02934v1,2018-09-09T07:11:20Z,2018-09-09T07:11:20Z,"Reinforcement Learning for Decentralized Trajectory Design in Cellular
  UAV Networks with Sense-and-Send Protocol","Recently, the unmanned aerial vehicles (UAVs) have been widely used in
real-time sensing applications over cellular networks, which sense the
conditions of the tasks and transmit the real-time sensory data to the base
station (BS). The performance of a UAV is determined by the performance of both
its sensing and transmission processes, which are influenced by the trajectory
of the UAV. However, it is challenging for UAVs to design their trajectories
efficiently, since they work in a dynamic environment. To tackle this
challenge, in this paper, we adopt the reinforcement learning framework to
solve the UAV trajectory design problem in a decentralized manner. To
coordinate multiple UAVs performing the real-time sensing tasks, we first
propose a sense-and-send protocol, and analyze the probability for successful
valid data transmission using nested Markov chains. Then, we formulate the
decentralized trajectory design problem and propose an enhanced multi-UAV
Q-learning algorithm to solve this problem. Simulation results show that the
proposed enhanced multi-UAV Q-learning algorithm converges faster and achieves
higher utilities for the UAVs in the real-time task-sensing scenarios.",arxiv
http://arxiv.org/abs/1810.10408v1,2018-10-24T14:05:28Z,2018-10-24T14:05:28Z,"Multi-Agent Reinforcement Learning Based Resource Allocation for UAV
  Networks","Unmanned aerial vehicles (UAVs) are capable of serving as aerial base
stations (BSs) for providing both cost-effective and on-demand wireless
communications. This article investigates dynamic resource allocation of
multiple UAVs enabled communication networks with the goal of maximizing
long-term rewards. More particularly, each UAV communicates with a ground user
by automatically selecting its communicating users, power levels and
subchannels without any information exchange among UAVs. To model the
uncertainty of environments, we formulate the long-term resource allocation
problem as a stochastic game for maximizing the expected rewards, where each
UAV becomes a learning agent and each resource allocation solution corresponds
to an action taken by the UAVs. Afterwards, we develop a multi-agent
reinforcement learning (MARL) framework that each agent discovers its best
strategy according to its local observations using learning. More specifically,
we propose an agent-independent method, for which all agents conduct a decision
algorithm independently but share a common structure based on Q-learning.
Finally, simulation results reveal that: 1) appropriate parameters for
exploitation and exploration are capable of enhancing the performance of the
proposed MARL based resource allocation algorithm; 2) the proposed MARL
algorithm provides acceptable performance compared to the case with complete
information exchanges among UAVs. By doing so, it strikes a good tradeoff
between performance gains and information exchange overheads.",arxiv
http://arxiv.org/abs/1811.05053v1,2018-11-13T00:13:24Z,2018-11-13T00:13:24Z,"Distributed Cooperative Spectrum Sharing in UAV Networks Using
  Multi-Agent Reinforcement Learning","In this paper, we develop a distributed mechanism for spectrum sharing among
a network of unmanned aerial vehicles (UAV) and licensed terrestrial networks.
This method can provide a practical solution for situations where the UAV
network may need external spectrum when dealing with congested spectrum or need
to change its operating frequency due to security threats. Here we study a
scenario where the UAV network performs a remote sensing mission. In this
model, the UAVs are categorized into two clusters of relaying and sensing UAVs.
The relay UAVs provide a relaying service for a licensed network to obtain
spectrum access for the rest of UAVs that perform the sensing task. We develop
a distributed mechanism in which the UAVs locally decide whether they need to
participate in relaying or sensing considering the fact that communications
among UAVs may not be feasible or reliable. The UAVs learn the optimal task
allocation using a distributed reinforcement learning algorithm. Convergence of
the algorithm is discussed and simulation results are presented for different
scenarios to verify the convergence.",arxiv
http://arxiv.org/abs/1901.10832v5,2019-11-26T19:49:46Z,2019-01-30T14:06:50Z,"Deep Reinforcement Learning for UAV Navigation Through Massive MIMO
  Technique","Unmanned aerial vehicles (UAVs) technique has been recognized as a promising
solution in future wireless connectivity from the sky, and UAV navigation is
one of the most significant open research problems, which has attracted wide
interest in the research community. However, the current UAV navigation schemes
are unable to capture the UAV motion and select the best UAV-ground links in
real time, and these weaknesses overwhelm the UAV navigation performance. To
tackle these fundamental limitations, in this paper, we merge the
state-of-theart deep reinforcement learning with the UAV navigation through
massive multiple-input-multiple-output (MIMO) technique. To be specific, we
carefully design a deep Q-network (DQN) for optimizing the UAV navigation by
selecting the optimal policy, and then we propose a learning mechanism for
processing the DQN. The DQN is trained so that the agent is capable of making
decisions based on the received signal strengths for navigating theUAVs with
the aid of the powerful Q-learning. Simulation results are provided to
corroborate the superiority of the proposed schemes in terms of the coverage
and convergence compared with those of the other schemes.",arxiv
http://arxiv.org/abs/1904.07380v1,2019-04-16T00:28:01Z,2019-04-16T00:28:01Z,"A Solution for Dynamic Spectrum Management in Mission-Critical UAV
  Networks","In this paper, we study the problem of spectrum scarcity in a network of
unmanned aerial vehicles (UAVs) during mission-critical applications such as
disaster monitoring and public safety missions, where the pre-allocated
spectrum is not sufficient to offer a high data transmission rate for real-time
video-streaming. In such scenarios, the UAV network can lease part of the
spectrum of a terrestrial licensed network in exchange for providing relaying
service. In order to optimize the performance of the UAV network and prolong
its lifetime, some of the UAVs will function as a relay for the primary network
while the rest of the UAVs carry out their sensing tasks. Here, we propose a
team reinforcement learning algorithm performed by the UAV's controller unit to
determine the optimum allocation of sensing and relaying tasks among the UAVs
as well as their relocation strategy at each time. We analyze the convergence
of our algorithm and present simulation results to evaluate the system
throughput in different scenarios.",arxiv
http://arxiv.org/abs/1904.07961v1,2019-04-08T20:15:39Z,2019-04-08T20:15:39Z,"RL-Based User Association and Resource Allocation for Multi-UAV enabled
  MEC","In this paper, multi-unmanned aerial vehicle (UAV) enabled mobile edge
computing (MEC), i.e., UAVE is studied, where several UAVs are deployed as
flying MEC platform to provide computing resource to ground user equipments
(UEs). Compared to the traditional fixed location MEC, UAV enabled MEC (i.e.,
UAVE) is particular useful in case of temporary events, emergency situations
and on-demand services, due to its high flexibility, low cost and easy
deployment features. However, operation of UAVE faces several challenges, two
of which are how to achieve both 1) the association between multiple UEs and
UAVs and 2) the resource allocation from UAVs to UEs, while minimizing the
energy consumption for all the UEs. To address this, we formulate the above
problem into a mixed integer nonlinear programming (MINLP), which is difficult
to be solved in general, especially in the large-scale scenario. We then
propose a Reinforcement Learning (RL)-based user Association and resource
Allocation (RLAA) algorithm to tackle this problem efficiently and effectively.
Numerical results show that the proposed RLAA can achieve the optimal
performance with comparison to the exhaustive search in small scale, and have
considerable performance gain over other typical algorithms in large-scale
cases.",arxiv
http://arxiv.org/abs/1905.06471v1,2019-05-15T23:46:58Z,2019-05-15T23:46:58Z,Synthesis of Provably Correct Autonomy Protocols for Shared Control,"We synthesize shared control protocols subject to probabilistic temporal
logic specifications. More specifically, we develop a framework in which a
human and an autonomy protocol can issue commands to carry out a certain task.
We blend these commands into a joint input to a robot. We model the interaction
between the human and the robot as a Markov decision process (MDP) that
represents the shared control scenario. Using inverse reinforcement learning,
we obtain an abstraction of the human's behavior and decisions. We use
randomized strategies to account for randomness in human's decisions, caused by
factors such as complexity of the task specifications or imperfect interfaces.
We design the autonomy protocol to ensure that the resulting robot behavior
satisfies given safety and performance specifications in probabilistic temporal
logic. Additionally, the resulting strategies generate behavior as similar to
the behavior induced by the human's commands as possible. We solve the
underlying problem efficiently using quasiconvex programming. Case studies
involving autonomous wheelchair navigation and unmanned aerial vehicle mission
planning showcase the applicability of our approach.",arxiv
http://arxiv.org/abs/1907.03912v2,2019-07-13T00:15:25Z,2019-07-09T00:03:00Z,"UAV Access Point Placement for Connectivity to a User with Unknown
  Location Using Deep RL","In recent years, unmanned aerial vehicles (UAVs) have been considered for
telecommunications purposes as relays, caches, or IoT data collectors. In
addition to being easy to deploy, their maneuverability allows them to adjust
their location to optimize the capacity of the link to the user equipment on
the ground or of the link to the basestation. The majority of the previous work
that analyzes the optimal placement of such a UAV makes at least one of two
assumptions: the channel can be predicted using a simple model or the locations
of the users on the ground are known. In this paper, we use deep reinforcement
learning (deep RL) to optimally place a UAV serving a ground user in an urban
environment, without the previous knowledge of the channel or user location.
Our algorithm relies on signal-to-interference-plus-noise ratio (SINR)
measurements and a 3D map of the topology to account for blockage and
scatterers. Furthermore, it is designed to operate in any urban environment.
Results in conditions simulated by a ray tracing software show that with the
constraint on the maximum number of iterations our algorithm has a 90% success
rate in converging to a target SINR.",arxiv
http://arxiv.org/abs/1909.10914v1,2019-09-23T09:20:44Z,2019-09-23T09:20:44Z,Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs,"Recent advances in unmanned aerial vehicle (UAV) technology have
revolutionized a broad class of civil and military applications. However, the
designs of wireless technologies that enable real-time streaming of
high-definition video between UAVs and ground clients present a conundrum. Most
existing adaptive bitrate (ABR) algorithms are not optimized for the
air-to-ground links, which usually fluctuate dramatically due to the dynamic
flight states of the UAV. In this paper, we present SA-ABR, a new
sensor-augmented system that generates ABR video streaming algorithms with the
assistance of various kinds of inherent sensor data that are used to pilot
UAVs. By incorporating the inherent sensor data with network observations,
SA-ABR trains a deep reinforcement learning (DRL) model to extract salient
features from the flight state information and automatically learn an ABR
algorithm to adapt to the varying UAV channel capacity through the training
process. SA-ABR does not rely on any assumptions or models about UAV's flight
states or the environment, but instead, it makes decisions by exploiting
temporal properties of past throughput through the long short-term memory
(LSTM) to adapt itself to a wide range of highly dynamic environments. We have
implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare
SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the
results show that our system outperforms the best known existing ABR algorithm
by 21.4% in terms of the average quality of experience (QoE) reward.",arxiv
http://arxiv.org/abs/1911.03887v2,2021-02-13T15:42:03Z,2019-11-10T10:24:04Z,"Deep Reinforcement Learning Based Dynamic Trajectory Control for
  UAV-assisted Mobile Edge Computing","In this paper, we consider a platform of flying mobile edge computing
(F-MEC), where unmanned aerial vehicles (UAVs) serve as equipment providing
computation resource, and they enable task offloading from user equipment (UE).
We aim to minimize energy consumption of all the UEs via optimizing the user
association, resource allocation and the trajectory of UAVs. To this end, we
first propose a Convex optimizAtion based Trajectory control algorithm (CAT),
which solves the problem in an iterative way by using block coordinate descent
(BCD) method. Then, to make the real-time decision while taking into account
the dynamics of the environment (i.e., UAV may take off from different
locations), we propose a deep Reinforcement leArning based Trajectory control
algorithm (RAT). In RAT, we apply the Prioritized Experience Replay (PER) to
improve the convergence of the training procedure. Different from the convex
optimization based algorithm which may be susceptible to the initial points and
requires iterations, RAT can be adapted to any taking off points of the UAVs
and can obtain the solution more rapidly than CAT once training process has
been completed. Simulation results show that the proposed CAT and RAT achieve
the similar performance and both outperform traditional algorithms.",arxiv
http://arxiv.org/abs/1911.07653v1,2019-11-15T08:54:00Z,2019-11-15T08:54:00Z,"Resource Awareness in Unmanned Aerial Vehicle-Assisted Mobile-Edge
  Computing Systems","This paper investigates an unmanned aerial vehicle (UAV)-assisted mobile-edge
computing (MEC) system, in which the UAV provides complementary computation
resource to the terrestrial MEC system. The UAV processes the received
computation tasks from the mobile users (MUs) by creating the corresponding
virtual machines. Due to finite shared I/O resource of the UAV in the MEC
system, each MU competes to schedule local as well as remote task computations
across the decision epochs, aiming to maximize the expected long-term
computation performance. The non-cooperative interactions among the MUs are
modeled as a stochastic game, in which the decision makings of a MU depend on
the global state statistics and the task scheduling policies of all MUs are
coupled. To approximate the Nash equilibrium solutions, we propose a proactive
scheme based on the long short-term memory and deep reinforcement learning
(DRL) techniques. A digital twin of the MEC system is established to train the
proactive DRL scheme offline. Using the proposed scheme, each MU makes task
scheduling decisions only with its own information. Numerical experiments show
a significant performance gain from the scheme in terms of average utility per
MU across the decision epochs.",arxiv
http://arxiv.org/abs/1911.11343v1,2019-11-26T05:09:39Z,2019-11-26T05:09:39Z,"An Autonomous Spectrum Management Scheme for Unmanned Aerial Vehicle
  Networks in Disaster Relief Operations","This paper studies the problem of spectrum shortage in an unmanned aerial
vehicle (UAV) network during critical missions such as wildfire monitoring,
search and rescue, and disaster monitoring. Such applications involve a high
demand for high-throughput data transmissions such as real-time video-, image-,
and voice- streaming where the assigned spectrum to the UAV network may not be
adequate to provide the desired Quality of Service (QoS). In these scenarios,
the aerial network can borrow an additional spectrum from the available
terrestrial networks in the trade of a relaying service for them. We propose a
spectrum sharing model in which the UAVs are grouped into two classes of
relaying UAVs that service the spectrum owner and the sensing UAVs that perform
the disaster relief mission using the obtained spectrum. The operation of the
UAV network is managed by a hierarchical mechanism in which a central
controller assigns the tasks of the UAVs based on their resources and determine
their operation region based on the level of priority of impacted areas and
then the UAVs autonomously fine-tune their position using a model-free
reinforcement learning algorithm to maximize the individual throughput and
prolong their lifetime. We analyze the performance and the convergence for the
proposed method analytically and with extensive simulations in different
scenarios.",arxiv
http://arxiv.org/abs/2002.00073v2,2020-02-05T02:03:28Z,2020-01-31T22:05:30Z,"Constrained Deep Reinforcement Learning for Energy Sustainable Multi-UAV
  based Random Access IoT Networks with NOMA","In this paper, we apply the Non-Orthogonal Multiple Access (NOMA) technique
to improve the massive channel access of a wireless IoT network where
solar-powered Unmanned Aerial Vehicles (UAVs) relay data from IoT devices to
remote servers. Specifically, IoT devices contend for accessing the shared
wireless channel using an adaptive $p$-persistent slotted Aloha protocol; and
the solar-powered UAVs adopt Successive Interference Cancellation (SIC) to
decode multiple received data from IoT devices to improve access efficiency. To
enable an energy-sustainable capacity-optimal network, we study the joint
problem of dynamic multi-UAV altitude control and multi-cell wireless channel
access management of IoT devices as a stochastic control problem with multiple
energy constraints. To learn an optimal control policy, we first formulate this
problem as a Constrained Markov Decision Process (CMDP), and propose an online
model-free Constrained Deep Reinforcement Learning (CDRL) algorithm based on
Lagrangian primal-dual policy optimization to solve the CMDP. Extensive
simulations demonstrate that our proposed algorithm learns a cooperative policy
among UAVs in which the altitude of UAVs and channel access probability of IoT
devices are dynamically and jointly controlled to attain the maximal long-term
network capacity while maintaining energy sustainability of UAVs. The proposed
algorithm outperforms Deep RL based solutions with reward shaping to account
for energy costs, and achieves a temporal average system capacity which is
$82.4\%$ higher than that of a feasible DRL based solution, and only $6.47\%$
lower compared to that of the energy-constraint-free system.",arxiv
http://arxiv.org/abs/2002.01546v2,2020-03-10T16:11:31Z,2020-02-04T21:27:16Z,"Mobility Management for Cellular-Connected UAVs: A Learning-Based
  Approach","The pervasiveness of the wireless cellular network can be a key enabler for
the deployment of autonomous unmanned aerial vehicles (UAVs) in beyond visual
line of sight scenarios without human control. However, traditional cellular
networks are optimized for ground user equipment (GUE) such as smartphones
which makes providing connectivity to flying UAVs very challenging. Moreover,
ensuring better connectivity to a moving cellular-connected UAV is notoriously
difficult due to the complex air-to-ground path loss model. In this paper, a
novel mechanism is proposed to ensure robust wireless connectivity and mobility
support for cellular-connected UAVs by tuning the downtilt (DT) angles of all
the GBSs. By leveraging tools from reinforcement learning (RL), DT angles are
dynamically adjusted by using a model-free RL algorithm. The goal is to provide
efficient mobility support in the sky by maximizing the received signal quality
at the UAV while also maintaining good throughput performance of the ground
users. Simulation results show that the proposed RL-based mobility management
(MM) technique can reduce the number of handovers while maintaining the
performance goals, compared to the baseline MM scheme in which the network
always keeps the DT angle fixed.",arxiv
http://arxiv.org/abs/2002.03910v3,2021-06-29T14:46:56Z,2020-02-10T16:19:58Z,"Proficiency Constrained Multi-Agent Reinforcement Learning for
  Environment-Adaptive Multi UAV-UGV Teaming","A mixed aerial and ground robot team, which includes both unmanned ground
vehicles (UGVs) and unmanned aerial vehicles (UAVs), is widely used for
disaster rescue, social security, precision agriculture, and military missions.
However, team capability and corresponding configuration vary since robots have
different motion speeds, perceiving ranges, reaching areas, and resilient
capabilities to the dynamic environment. Due to heterogeneous robots inside a
team and the resilient capabilities of robots, it is challenging to perform a
task with an optimal balance between reasonable task allocations and maximum
utilization of robot capability. To address this challenge for effective mixed
ground and aerial teaming, this paper developed a novel teaming method,
proficiency aware multi-agent deep reinforcement learning (Mix-RL), to guide
ground and aerial cooperation by considering the best alignments between robot
capabilities, task requirements, and environment conditions. Mix-RL largely
exploits robot capabilities while being aware of the adaption of robot
capabilities to task requirements and environment conditions. Mix-RL's
effectiveness in guiding mixed teaming was validated with the task ""social
security for criminal vehicle tracking"".",arxiv
http://arxiv.org/abs/2002.08040v2,2020-03-12T14:25:06Z,2020-02-19T07:56:06Z,"Cellular UAV-to-Device Communications: Trajectory Design and Mode
  Selection by Multi-agent Deep Reinforcement Learning","In the current unmanned aircraft systems (UASs) for sensing services,
unmanned aerial vehicles (UAVs) transmit their sensory data to terrestrial
mobile devices over the unlicensed spectrum. However, the interference from
surrounding terminals is uncontrollable due to the opportunistic channel
access. In this paper, we consider a cellular Internet of UAVs to guarantee the
Quality-of-Service (QoS), where the sensory data can be transmitted to the
mobile devices either by UAV-to-Device (U2D) communications over cellular
networks, or directly through the base station (BS). Since UAVs' sensing and
transmission may influence their trajectories, we study the trajectory design
problem for UAVs in consideration of their sensing and transmission. This is a
Markov decision problem (MDP) with a large state-action space, and thus, we
utilize multi-agent deep reinforcement learning (DRL) to approximate the
state-action space, and then propose a multi-UAV trajectory design algorithm to
solve this problem. Simulation results show that our proposed algorithm can
achieve a higher total utility than policy gradient algorithm and single-agent
algorithm.",arxiv
http://arxiv.org/abs/2002.08415v1,2020-02-19T20:09:46Z,2020-02-19T20:09:46Z,UAV Aided Search and Rescue Operation Using Reinforcement Learning,"Owing to the enhanced flexibility in deployment and decreasing costs of
manufacturing, the demand for unmanned aerial vehicles (UAVs) is expected to
soar in the upcoming years. In this paper, we explore a UAV aided search and
rescue~(SAR) operation in indoor environments, where the GPS signals might not
be reliable. We consider a SAR scenario where the UAV tries to locate a victim
trapped in an indoor environment by sensing the RF signals emitted from a smart
device owned by the victim. To locate the victim as fast as possible, we
leverage tools from reinforcement learning~(RL). Received signal strength~(RSS)
at the UAV depends on the distance from the source, indoor shadowing, and
fading parameters, and antenna radiation pattern of the receiver mounted on the
UAV. To make our analysis more realistic, we model two indoor scenarios with
different dimensions using commercial ray-tracing software. Then, the
corresponding RSS values at each possible discrete UAV location are extracted
and used in a Q-learning framework. Unlike the traditional location-based
navigation approach that exploits GPS coordinates, our method uses the RSS to
define the states and rewards of the RL algorithm. We compare the performance
of the proposed method where directional and omnidirectional antennas are used.
The results reveal that the use of directional antennas provides faster
convergence rates than the omnidirectional antennas.",arxiv
http://arxiv.org/abs/2003.02609v2,2021-02-12T13:22:45Z,2020-03-05T13:43:47Z,"UAV Coverage Path Planning under Varying Power Constraints using Deep
  Reinforcement Learning","Coverage path planning (CPP) is the task of designing a trajectory that
enables a mobile agent to travel over every point of an area of interest. We
propose a new method to control an unmanned aerial vehicle (UAV) carrying a
camera on a CPP mission with random start positions and multiple options for
landing positions in an environment containing no-fly zones. While numerous
approaches have been proposed to solve similar CPP problems, we leverage
end-to-end reinforcement learning (RL) to learn a control policy that
generalizes over varying power constraints for the UAV. Despite recent
improvements in battery technology, the maximum flying range of small UAVs is
still a severe constraint, which is exacerbated by variations in the UAV's
power consumption that are hard to predict. By using map-like input channels to
feed spatial information through convolutional network layers to the agent, we
are able to train a double deep Q-network (DDQN) to make control decisions for
the UAV, balancing limited power budget and coverage goal. The proposed method
can be applied to a wide variety of environments and harmonizes complex goal
structures with system constraints.",arxiv
http://arxiv.org/abs/2003.04816v1,2020-02-21T07:29:15Z,2020-02-21T07:29:15Z,"Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep
  Reinforcement Learning Approach","In this paper, we design a navigation policy for multiple unmanned aerial
vehicles (UAVs) where mobile base stations (BSs) are deployed to improve the
data freshness and connectivity to the Internet of Things (IoT) devices. First,
we formulate an energy-efficient trajectory optimization problem in which the
objective is to maximize the energy efficiency by optimizing the UAV-BS
trajectory policy. We also incorporate different contextual information such as
energy and age of information (AoI) constraints to ensure the data freshness at
the ground BS. Second, we propose an agile deep reinforcement learning with
experience replay model to solve the formulated problem concerning the
contextual constraints for the UAV-BS navigation. Moreover, the proposed
approach is well-suited for solving the problem, since the state space of the
problem is extremely large and finding the best trajectory policy with useful
contextual features is too complex for the UAV-BSs. By applying the proposed
trained model, an effective real-time trajectory policy for the UAV-BSs
captures the observable network states over time. Finally, the simulation
results illustrate the proposed approach is 3.6% and 3.13% more energy
efficient than those of the greedy and baseline deep Q Network (DQN)
approaches.",arxiv
http://arxiv.org/abs/2003.05830v1,2020-03-12T14:57:02Z,2020-03-12T14:57:02Z,"UAV-to-Device Underlay Communications: Age of Information Minimization
  by Multi-agent Deep Reinforcement Learning","In recent years, unmanned aerial vehicles (UAVs) have found numerous sensing
applications, which are expected to add billions of dollars to the world
economy in the next decade. To further improve the Quality-of-Service (QoS) in
such applications, the 3rd Generation Partnership Project (3GPP) has considered
the adoption of terrestrial cellular networks to support UAV sensing services,
also known as the cellular Internet of UAVs. In this paper, we consider a
cellular Internet of UAVs, where the sensory data can be transmitted either to
base station (BS) via cellular links, or to mobile devices by underlay
UAV-to-Device (U2D) communications. To evaluate the freshness of data, the age
of information (AoI) is adopted, in which a lower AoI implies fresher data.
Since UAVs' AoIs are determined by their trajectories during sensing and
transmission, we investigate the AoI minimization problem for UAVs by designing
their trajectories. This problem is a Markov decision problem (MDP) with an
infinite state-action space, and thus we utilize multi-agent deep reinforcement
learning (DRL) to approximate the state-action space. Then, we propose a
multi-UAV trajectory design algorithm to solve this problem. Simulation results
show that our algorithm achieves a lower AoI than greedy algorithm and policy
gradient algorithm.",arxiv
http://arxiv.org/abs/2003.07574v1,2020-03-17T08:16:14Z,2020-03-17T08:16:14Z,"Simultaneous Navigation and Radio Mapping for Cellular-Connected UAV
  with Deep Reinforcement Learning","Cellular-connected unmanned aerial vehicle (UAV) is a promising technology to
unlock the full potential of UAVs in the future. However, how to achieve
ubiquitous three-dimensional (3D) communication coverage for the UAVs in the
sky is a new challenge. In this paper, we tackle this challenge by a new
coverage-aware navigation approach, which exploits the UAV's controllable
mobility to design its navigation/trajectory to avoid the cellular BSs'
coverage holes while accomplishing their missions. We formulate an UAV
trajectory optimization problem to minimize the weighted sum of its mission
completion time and expected communication outage duration, and propose a new
solution approach based on the technique of deep reinforcement learning (DRL).
To further improve the performance, we propose a new framework called
simultaneous navigation and radio mapping (SNARM), where the UAV's signal
measurement is used not only for training the deep Q network (DQN) directly,
but also to create a radio map that is able to predict the outage probabilities
at all locations in the area of interest. This thus enables the generation of
simulated UAV trajectories and predicting their expected returns, which are
then used to further train the DQN via Dyna technique, thus greatly improving
the learning efficiency.",arxiv
http://arxiv.org/abs/2006.13610v2,2020-06-29T09:17:00Z,2020-06-24T10:44:28Z,"Energy Minimization in UAV-Aided Networks: Actor-Critic Learning for
  Constrained Scheduling Optimization","In unmanned aerial vehicle (UAV) applications, the UAV's limited energy
supply and storage have triggered the development of intelligent
energy-conserving scheduling solutions. In this paper, we investigate energy
minimization for UAV-aided communication networks by jointly optimizing
data-transmission scheduling and UAV hovering time. The formulated problem is
combinatorial and non-convex with bilinear constraints. To tackle the problem,
firstly, we provide an optimal relax-and-approximate solution and develop a
near-optimal algorithm. Both the proposed solutions are served as offline
performance benchmarks but might not be suitable for online operation. To this
end, we develop a solution from a deep reinforcement learning (DRL) aspect. The
conventional RL/DRL, e.g., deep Q-learning, however, is limited in dealing with
two main issues in constrained combinatorial optimization, i.e., exponentially
increasing action space and infeasible actions. The novelty of solution
development lies in handling these two issues. To address the former, we
propose an actor-critic-based deep stochastic online scheduling (AC-DSOS)
algorithm and develop a set of approaches to confine the action space. For the
latter, we design a tailored reward function to guarantee the solution
feasibility. Numerical results show that, by consuming equal magnitude of time,
AC-DSOS is able to provide feasible solutions and saves 29.94% energy compared
with a conventional deep actor-critic method. Compared to the developed
near-optimal algorithm, AC-DSOS consumes around 10% higher energy but reduces
the computational time from minute-level to millisecond-level.",arxiv
http://arxiv.org/abs/2007.00544v2,2020-10-26T12:14:45Z,2020-07-01T15:14:16Z,"UAV Path Planning for Wireless Data Harvesting: A Deep Reinforcement
  Learning Approach","Autonomous deployment of unmanned aerial vehicles (UAVs) supporting
next-generation communication networks requires efficient trajectory planning
methods. We propose a new end-to-end reinforcement learning (RL) approach to
UAV-enabled data collection from Internet of Things (IoT) devices in an urban
environment. An autonomous drone is tasked with gathering data from distributed
sensor nodes subject to limited flying time and obstacle avoidance. While
previous approaches, learning and non-learning based, must perform expensive
recomputations or relearn a behavior when important scenario parameters such as
the number of sensors, sensor positions, or maximum flying time, change, we
train a double deep Q-network (DDQN) with combined experience replay to learn a
UAV control policy that generalizes over changing scenario parameters. By
exploiting a multi-layer map of the environment fed through convolutional
network layers to the agent, we show that our proposed network architecture
enables the agent to make movement decisions for a variety of scenario
parameters that balance the data collection goal with flight time efficiency
and safety constraints. Considerable advantages in learning efficiency from
using a map centered on the UAV's position over a non-centered map are also
illustrated.",arxiv
http://arxiv.org/abs/2007.14297v1,2020-07-28T15:13:06Z,2020-07-28T15:13:06Z,"Cooperative Internet of UAVs: Distributed Trajectory Design by
  Multi-agent Deep Reinforcement Learning","Due to the advantages of flexible deployment and extensive coverage, unmanned
aerial vehicles (UAVs) have great potential for sensing applications in the
next generation of cellular networks, which will give rise to a cellular
Internet of UAVs. In this paper, we consider a cellular Internet of UAVs, where
the UAVs execute sensing tasks through cooperative sensing and transmission to
minimize the age of information (AoI). However, the cooperative sensing and
transmission is tightly coupled with the UAVs' trajectories, which makes the
trajectory design challenging. To tackle this challenge, we propose a
distributed sense-and-send protocol, where the UAVs determine the trajectories
by selecting from a discrete set of tasks and a continuous set of locations for
sensing and transmission. Based on this protocol, we formulate the trajectory
design problem for AoI minimization and propose a compound-action actor-critic
(CA2C) algorithm to solve it based on deep reinforcement learning. The CA2C
algorithm can learn the optimal policies for actions involving both continuous
and discrete variables and is suited for the trajectory design. {Our simulation
results show that the CA2C algorithm outperforms four baseline algorithms}.
Also, we show that by dividing the tasks, cooperative UAVs can achieve a lower
AoI compared to non-cooperative UAVs.",arxiv
http://arxiv.org/abs/2008.02159v1,2020-08-05T14:25:39Z,2020-08-05T14:25:39Z,Learning from Sparse Demonstrations,"This paper proposes an approach which enables a robot to learn an objective
function from sparse demonstrations of an expert. The demonstrations are given
by a small number of sparse waypoints; the waypoints are desired outputs of the
robot's trajectory at certain time instances, sparsely located within a
demonstration time horizon. The duration of the expert's demonstration may be
different from the actual duration of the robot's execution. The proposed
method enables to jointly learn an objective function and a time-warping
function such that the robot's reproduced trajectory has minimal distance to
the sparse demonstration waypoints. Unlike existing inverse reinforcement
learning techniques, the proposed approach uses the differential Pontryagin's
maximum principle, which allows direct minimization of the distance between the
robot's trajectory and the sparse demonstration waypoints and enables
simultaneous learning of an objective function and a time-warping function. We
demonstrate the effectiveness of the proposed approach in various simulated
scenarios. We apply the method to learn motion planning/control of a 6-DoF
maneuvering unmanned aerial vehicle (UAV) and a robot arm in environments with
obstacles. The results show that a robot is able to learn a valid objective
function to avoid obstacles with few demonstrated waypoints.",arxiv
http://arxiv.org/abs/2009.08528v1,2020-09-17T20:51:17Z,2020-09-17T20:51:17Z,"SREC: Proactive Self-Remedy of Energy-Constrained UAV-Based Networks via
  Deep Reinforcement Learning","Energy-aware control for multiple unmanned aerial vehicles (UAVs) is one of
the major research interests in UAV based networking. Yet few existing works
have focused on how the network should react around the timing when the UAV
lineup is changed. In this work, we study proactive self-remedy of
energy-constrained UAV networks when one or more UAVs are short of energy and
about to quit for charging. We target at an energy-aware optimal UAV control
policy which proactively relocates the UAVs when any UAV is about to quit the
network, rather than passively dispatches the remaining UAVs after the quit.
Specifically, a deep reinforcement learning (DRL)-based self remedy approach,
named SREC-DRL, is proposed to maximize the accumulated user satisfaction
scores for a certain period within which at least one UAV will quit the
network. To handle the continuous state and action space in the problem, the
state-of-the-art algorithm of the actor-critic DRL, i.e., deep deterministic
policy gradient (DDPG), is applied with better convergence stability. Numerical
results demonstrate that compared with the passive reaction method, the
proposed SREC-DRL approach shows a $12.12\%$ gain in accumulative user
satisfaction score during the remedy period.",arxiv
http://arxiv.org/abs/2009.11277v1,2020-09-23T17:44:07Z,2020-09-23T17:44:07Z,"Multi-Agent Deep Reinforcement Learning Based Trajectory Planning for
  Multi-UAV Assisted Mobile Edge Computing","An unmanned aerial vehicle (UAV)-aided mobile edge computing (MEC) framework
is proposed, where several UAVs having different trajectories fly over the
target area and support the user equipments (UEs) on the ground. We aim to
jointly optimize the geographical fairness among all the UEs, the fairness of
each UAV' UE-load and the overall energy consumption of UEs. The above
optimization problem includes both integer and continues variables and it is
challenging to solve. To address the above problem, a multi-agent deep
reinforcement learning based trajectory control algorithm is proposed for
managing the trajectory of each UAV independently, where the popular
Multi-Agent Deep Deterministic Policy Gradient (MADDPG) method is applied.
Given the UAVs' trajectories, a low-complexity approach is introduced for
optimizing the offloading decisions of UEs. We show that our proposed solution
has considerable performance over other traditional algorithms, both in terms
of the fairness for serving UEs, fairness of UE-load at each UAV and energy
consumption for all the UEs.",arxiv
http://arxiv.org/abs/2010.01471v1,2020-10-04T02:58:03Z,2020-10-04T02:58:03Z,"Deep Reinforcement Learning for Delay-Oriented IoT Task Scheduling in
  Space-Air-Ground Integrated Network","In this paper, we investigate a computing task scheduling problem in
space-air-ground integrated network (SAGIN) for delay-oriented Internet of
Things (IoT) services. In the considered scenario, an unmanned aerial vehicle
(UAV) collects computing tasks from IoT devices and then makes online
offloading decisions, in which the tasks can be processed at the UAV or
offloaded to the nearby base station or the remote satellite. Our objective is
to design a task scheduling policy that minimizes offloading and computing
delay of all tasks given the UAV energy capacity constraint. To this end, we
first formulate the online scheduling problem as an energy-constrained Markov
decision process (MDP). Then, considering the task arrival dynamics, we develop
a novel deep risk-sensitive reinforcement learning algorithm. Specifically, the
algorithm evaluates the risk, which measures the energy consumption that
exceeds the constraint, for each state and searches the optimal parameter
weighing the minimization of delay and risk while learning the optimal policy.
Extensive simulation results demonstrate that the proposed algorithm can reduce
the task processing delay by up to 30% compared to probabilistic configuration
methods while satisfying the UAV energy capacity constraint.",arxiv
http://arxiv.org/abs/2010.06917v4,2021-10-21T09:19:03Z,2020-10-14T09:59:10Z,"UAV Path Planning using Global and Local Map Information with Deep
  Reinforcement Learning","Path planning methods for autonomous unmanned aerial vehicles (UAVs) are
typically designed for one specific type of mission. This work presents a
method for autonomous UAV path planning based on deep reinforcement learning
(DRL) that can be applied to a wide range of mission scenarios. Specifically,
we compare coverage path planning (CPP), where the UAV's goal is to survey an
area of interest to data harvesting (DH), where the UAV collects data from
distributed Internet of Things (IoT) sensor devices. By exploiting structured
map information of the environment, we train double deep Q-networks (DDQNs)
with identical architectures on both distinctly different mission scenarios to
make movement decisions that balance the respective mission goal with
navigation constraints. By introducing a novel approach exploiting a compressed
global map of the environment combined with a cropped but uncompressed local
map showing the vicinity of the UAV agent, we demonstrate that the proposed
method can efficiently scale to large environments. We also extend previous
results for generalizing control policies that require no retraining when
scenario parameters change and offer a detailed analysis of crucial map
processing parameters' effects on path planning performance.",arxiv
http://arxiv.org/abs/2010.10138v1,2020-10-20T09:07:10Z,2020-10-20T09:07:10Z,"Integrating LEO Satellites and Multi-UAV Reinforcement Learning for
  Hybrid FSO/RF Non-Terrestrial Networks","A mega-constellation of low-altitude earth orbit (LEO) satellites (SATs) and
burgeoning unmanned aerial vehicles (UAVs) are promising enablers for
high-speed and long-distance communications in beyond fifth-generation (5G)
systems. Integrating SATs and UAVs within a non-terrestrial network (NTN), in
this article we investigate the problem of forwarding packets between two
faraway ground terminals through SAT and UAV relays using either
millimeter-wave (mmWave) radio-frequency (RF) or free-space optical (FSO) link.
Towards maximizing the communication efficiency, the real-time associations
with orbiting SATs and the moving trajectories of UAVs should be optimized with
suitable FSO/RF links, which is challenging due to the time-varying network
topology and a huge number of possible control actions. To overcome the
difficulty, we lift this problem to multi-agent deep reinforcement learning
(MARL) with a novel action dimensionality reduction technique. Simulation
results corroborate that our proposed SAT-UAV integrated scheme achieves 1.99x
higher end-to-end sum throughput compared to a benchmark scheme with fixed
ground relays. While improving the throughput, our proposed scheme also aims to
reduce the UAV control energy, yielding 2.25x higher energy efficiency than a
baseline method only maximizing the throughput. Lastly, thanks to utilizing
hybrid FSO/RF links, the proposed scheme achieves up to 62.56x higher peak
throughput and 21.09x higher worst-case throughput than the cases utilizing
either RF or FSO links, highlighting the importance of co-designing SAT-UAV
associations, UAV trajectories, and hybrid FSO/RF links in beyond-5G NTNs.",arxiv
http://arxiv.org/abs/2011.01840v1,2020-11-03T16:50:37Z,2020-11-03T16:50:37Z,"Distributional Reinforcement Learning for mmWave Communications with
  Intelligent Reflectors on a UAV","In this paper, a novel communication framework that uses an unmanned aerial
vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance
multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In
order to maximize the downlink sum-rate, the optimal precoding matrix (at the
base station) and reflection coefficient (at the IR) are jointly derived. Next,
to address the uncertainty of mmWave channels and maintain line-of-sight links
in a real-time manner, a distributional reinforcement learning approach, based
on quantile regression optimization, is proposed to learn the propagation
environment of mmWave communications, and, then, optimize the location of the
UAV-IR so as to maximize the long-term downlink communication capacity.
Simulation results show that the proposed learning-based deployment of the
UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a
static IR, and a direct transmission schemes, in terms of the average data rate
and the achievable line-of-sight probability of downlink mmWave communications.",arxiv
http://arxiv.org/abs/2103.04666v1,2021-03-08T11:06:28Z,2021-03-08T11:06:28Z,"Distributed Reinforcement Learning for Flexible and Efficient UAV Swarm
  Control","Over the past few years, the use of swarms of Unmanned Aerial Vehicles (UAVs)
in monitoring and remote area surveillance applications has become widespread
thanks to the price reduction and the increased capabilities of drones. The
drones in the swarm need to cooperatively explore an unknown area, in order to
identify and monitor interesting targets, while minimizing their movements. In
this work, we propose a distributed Reinforcement Learning (RL) approach that
scales to larger swarms without modifications. The proposed framework relies on
the possibility for the UAVs to exchange some information through a
communication channel, in order to achieve context-awareness and implicitly
coordinate the swarm's actions. Our experiments show that the proposed method
can yield effective strategies, which are robust to communication channel
impairments, and that can easily deal with non-uniform distributions of targets
and obstacles. Moreover, when agents are trained in a specific scenario, they
can adapt to a new one with minimal additional training. We also show that our
approach achieves better performance compared to a computationally intensive
look-ahead heuristic.",arxiv
http://arxiv.org/abs/2103.06403v1,2021-03-11T01:15:26Z,2021-03-11T01:15:26Z,"A Vision Based Deep Reinforcement Learning Algorithm for UAV Obstacle
  Avoidance","Integration of reinforcement learning with unmanned aerial vehicles (UAVs) to
achieve autonomous flight has been an active research area in recent years. An
important part focuses on obstacle detection and avoidance for UAVs navigating
through an environment. Exploration in an unseen environment can be tackled
with Deep Q-Network (DQN). However, value exploration with uniform sampling of
actions may lead to redundant states, where often the environments inherently
bear sparse rewards. To resolve this, we present two techniques for improving
exploration for UAV obstacle avoidance. The first is a convergence-based
approach that uses convergence error to iterate through unexplored actions and
temporal threshold to balance exploration and exploitation. The second is a
guidance-based approach using a Domain Network which uses a Gaussian mixture
distribution to compare previously seen states to a predicted next state in
order to select the next action. Performance and evaluation of these approaches
were implemented in multiple 3-D simulation environments, with variation in
complexity. The proposed approach demonstrates a two-fold improvement in
average rewards compared to state of the art.",arxiv
http://arxiv.org/abs/2103.15374v1,2021-03-29T07:02:36Z,2021-03-29T07:02:36Z,"Lifelong Learning for Minimizing Age of Information in Internet of
  Things Networks","In this paper, a lifelong learning problem is studied for an Internet of
Things (IoT) system. In the considered model, each IoT device aims to balance
its information freshness and energy consumption tradeoff by controlling its
computational resource allocation at each time slot under dynamic environments.
An unmanned aerial vehicle (UAV) is deployed as a flying base station so as to
enable the IoT devices to adapt to novel environments. To this end, a new
lifelong reinforcement learning algorithm, used by the UAV, is proposed in
order to adapt the operation of the devices at each visit by the UAV. By using
the experience from previously visited devices and environments, the UAV can
help devices adapt faster to future states of their environment. To do so, a
knowledge base shared by all devices is maintained at the UAV. Simulation
results show that the proposed algorithm can converge $25\%$ to $50\%$ faster
than a policy gradient baseline algorithm that optimizes each device's decision
making problem in isolation.",arxiv
http://arxiv.org/abs/2104.10403v3,2021-10-05T09:29:46Z,2021-04-21T08:25:11Z,"Model-aided Deep Reinforcement Learning for Sample-efficient UAV
  Trajectory Design in IoT Networks","Deep Reinforcement Learning (DRL) is gaining attention as a potential
approach to design trajectories for autonomous unmanned aerial vehicles (UAV)
used as flying access points in the context of cellular or Internet of Things
(IoT) connectivity. DRL solutions offer the advantage of on-the-go learning
hence relying on very little prior contextual information. A corresponding
drawback however lies in the need for many learning episodes which severely
restricts the applicability of such approach in real-world time- and
energy-constrained missions. Here, we propose a model-aided deep Q-learning
approach that, in contrast to previous work, considerably reduces the need for
extensive training data samples, while still achieving the overarching goal of
DRL, i.e to guide a battery-limited UAV on an efficient data harvesting
trajectory, without prior knowledge of wireless channel characteristics and
limited knowledge of wireless node locations. The key idea consists in using a
small subset of nodes as anchors (i.e. with known location) and learning a
model of the propagation environment while implicitly estimating the positions
of regular nodes. Interaction with the model allows us to train a deep
Q-network (DQN) to approximate the optimal UAV control policy. We show that in
comparison with standard DRL approaches, the proposed model-aided approach
requires at least one order of magnitude less training data samples to reach
identical data collection performance, hence offering a first step towards
making DRL a viable solution to the problem.",arxiv
http://arxiv.org/abs/2105.01606v1,2021-05-04T16:29:44Z,2021-05-04T16:29:44Z,"Deep Reinforcement Learning for Adaptive Exploration of Unknown
  Environments","Performing autonomous exploration is essential for unmanned aerial vehicles
(UAVs) operating in unknown environments. Often, these missions start with
building a map for the environment via pure exploration and subsequently using
(i.e. exploiting) the generated map for downstream navigation tasks.
Accomplishing these navigation tasks in two separate steps is not always
possible or even disadvantageous for UAVs deployed in outdoor and dynamically
changing environments. Current exploration approaches either use a priori
human-generated maps or use heuristics such as frontier-based exploration.
Other approaches use learning but focus only on learning policies for specific
tasks by either using sample inefficient random exploration or by making
impractical assumptions about full map availability. In this paper, we develop
an adaptive exploration approach to trade off between exploration and
exploitation in one single step for UAVs searching for areas of interest (AoIs)
in unknown environments using Deep Reinforcement Learning (DRL). The proposed
approach uses a map segmentation technique to decompose the environment map
into smaller, tractable maps. Then, a simple information gain function is
repeatedly computed to determine the best target region to search during each
iteration of the process. DDQN and A2C algorithms are extended with a stack of
LSTM layers and trained to generate optimal policies for the exploration and
exploitation, respectively. We tested our approach in 3 different tasks against
4 baselines. The results demonstrate that our proposed approach is capable of
navigating through randomly generated environments and covering more AoI in
less time steps compared to the baselines.",arxiv
http://arxiv.org/abs/2105.10282v1,2021-05-21T11:13:06Z,2021-05-21T11:13:06Z,"AI-Based and Mobility-Aware Energy Efficient Resource Allocation and
  Trajectory Design for NFV Enabled Aerial Networks","In this paper, we propose a novel joint intelligent trajectory design and
resource allocation algorithm based on user's mobility and their requested
services for unmanned aerial vehicles (UAVs) assisted networks, where UAVs act
as nodes of a network function virtualization (NFV) enabled network. Our
objective is to maximize energy efficiency and minimize the average delay on
all services by allocating the limited radio and NFV resources. In addition,
due to the traffic conditions and mobility of users, we let some Virtual
Network Functions (VNFs) to migrate from their current locations to other
locations to satisfy the Quality of Service requirements. We formulate our
problem to find near-optimal locations of UAVs, transmit power, subcarrier
assignment, placement, and scheduling the requested service's functions over
the UAVs and perform suitable VNF migration. Then we propose a novel
Hierarchical Hybrid Continuous and Discrete Action (HHCDA) deep reinforcement
learning method to solve our problem. Finally, the convergence and
computational complexity of the proposed algorithm and its performance analyzed
for different parameters. Simulation results show that our proposed HHCDA
method decreases the request reject rate and average delay by 31.5% and 20% and
increases the energy efficiency by 40% compared to DDPG method.",arxiv
http://arxiv.org/abs/2106.00845v1,2021-06-01T22:49:42Z,2021-06-01T22:49:42Z,"Energy-aware placement optimization of UAV base stations via
  decentralized multi-agent Q-learning","Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be
deployed to provide wireless connectivity to ground devices in events of
increased network demand, points-of-failure in existing infrastructure, or
disasters. However, it is challenging to conserve the energy of UAVs during
prolonged coverage tasks, considering their limited on-board battery capacity.
Reinforcement learning-based (RL) approaches have been previously used to
improve energy utilization of multiple UAVs, however, a central cloud
controller is assumed to have complete knowledge of the end-devices' locations,
i.e., the controller periodically scans and sends updates for UAV
decision-making. This assumption is impractical in dynamic network environments
with mobile ground devices. To address this problem, we propose a decentralized
Q-learning approach, where each UAV-BS is equipped with an autonomous agent
that maximizes the connectivity to ground devices while improving its energy
utilization. Experimental results show that the proposed design significantly
outperforms the centralized approaches in jointly maximizing the number of
connected ground devices and the energy utilization of the UAV-BSs.",arxiv
http://arxiv.org/abs/2106.01016v2,2021-06-05T04:31:51Z,2021-06-02T08:30:14Z,"Deep Reinforcement Learning-based UAV Navigation and Control: A Soft
  Actor-Critic with Hindsight Experience Replay Approach","In this paper, we propose SACHER (soft actor-critic (SAC) with hindsight
experience replay (HER)), which constitutes a class of deep reinforcement
learning (DRL) algorithms. SAC is known as an off-policy model-free DRL
algorithm based on the maximum entropy framework, which outperforms earlier DRL
algorithms in terms of exploration, robustness and learning performance.
However, in SAC, maximizing the entropy-augmented objective may degrade the
optimality of learning outcomes. HER is known as a sample-efficient replay
method that enhances the performance of off-policy DRL algorithms by allowing
the agent to learn from both failures and successes. We apply HER to SAC and
propose SACHER to improve the learning performance of SAC. More precisely,
SACHER achieves the desired optimal outcomes faster and more accurately than
SAC, since HER improves the sample efficiency of SAC. We apply SACHER to the
navigation and control problem of unmanned aerial vehicles (UAVs), where SACHER
generates the optimal navigation path of the UAV under various obstacles in
operation. Specifically, we show the effectiveness of SACHER in terms of the
tracking error and cumulative reward in UAV operation by comparing them with
those of state-of-the-art DRL algorithms, SAC and DDPG. Note that SACHER in UAV
navigation and control problems can be applied to arbitrary models of UAVs.",arxiv
http://arxiv.org/abs/2106.03129v1,2021-06-06T14:08:41Z,2021-06-06T14:08:41Z,"3D UAV Trajectory and Data Collection Optimisation via Deep
  Reinforcement Learning","Unmanned aerial vehicles (UAVs) are now beginning to be deployed for
enhancing the network performance and coverage in wireless communication.
However, due to the limitation of their on-board power and flight time, it is
challenging to obtain an optimal resource allocation scheme for the
UAV-assisted Internet of Things (IoT). In this paper, we design a new
UAV-assisted IoT systems relying on the shortest flight path of the UAVs while
maximising the amount of data collected from IoT devices. Then, a deep
reinforcement learning-based technique is conceived for finding the optimal
trajectory and throughput in a specific coverage area. After training, the UAV
has the ability to autonomously collect all the data from user nodes at a
significant total sum-rate improvement while minimising the associated
resources used. Numerical results are provided to highlight how our techniques
strike a balance between the throughput attained, trajectory, and the time
spent. More explicitly, we characterise the attainable performance in terms of
the UAV trajectory, the expected reward and the total sum-rate.",arxiv
http://arxiv.org/abs/2107.11015v1,2021-07-23T03:33:29Z,2021-07-23T03:33:29Z,"Trajectory Design for UAV-Based Internet-of-Things Data Collection: A
  Deep Reinforcement Learning Approach","In this paper, we investigate an unmanned aerial vehicle (UAV)-assisted
Internet-of-Things (IoT) system in a sophisticated three-dimensional (3D)
environment, where the UAV's trajectory is optimized to efficiently collect
data from multiple IoT ground nodes. Unlike existing approaches focusing only
on a simplified two-dimensional scenario and the availability of perfect
channel state information (CSI), this paper considers a practical 3D urban
environment with imperfect CSI, where the UAV's trajectory is designed to
minimize data collection completion time subject to practical throughput and
flight movement constraints. Specifically, inspired from the state-of-the-art
deep reinforcement learning approaches, we leverage the twin-delayed deep
deterministic policy gradient (TD3) to design the UAV's trajectory and present
a TD3-based trajectory design for completion time minimization (TD3-TDCTM)
algorithm. In particular, we set an additional information, i.e., the merged
pheromone, to represent the state information of UAV and environment as a
reference of reward which facilitates the algorithm design. By taking the
service statuses of IoT nodes, the UAV's position, and the merged pheromone as
input, the proposed algorithm can continuously and adaptively learn how to
adjust the UAV's movement strategy. By interacting with the external
environment in the corresponding Markov decision process, the proposed
algorithm can achieve a near-optimal navigation strategy. Our simulation
results show the superiority of the proposed TD3-TDCTM algorithm over three
conventional non-learning based baseline methods.",arxiv
http://arxiv.org/abs/2108.00668v1,2021-08-02T07:10:00Z,2021-08-02T07:10:00Z,"Three-Dimensional Trajectory Design for Multi-User MISO UAV
  Communications: A Deep Reinforcement Learning Approach","In this paper, we investigate a multi-user downlink multiple-input
single-output (MISO) unmanned aerial vehicle (UAV) communication system, where
a multi-antenna UAV is employed to serve multiple ground terminals. Unlike
existing approaches focus only on a simplified two-dimensional scenario, this
paper considers a three-dimensional (3D) urban environment, where the UAV's 3D
trajectory is designed to minimize data transmission completion time subject to
practical throughput and flight movement constraints. Specifically, we propose
a deep reinforcement learning (DRL)-based trajectory design for completion time
minimization (DRL-TDCTM), which is developed from a deep deterministic policy
gradient algorithm. In particular, to represent the state information of UAV
and environment, we set an additional information, i.e., the merged pheromone,
as a reference of reward which facilitates the algorithm design. By interacting
with the external environment in the corresponding Markov decision process, the
proposed algorithm can continuously and adaptively learn how to adjust the
UAV's movement strategy. Finally, simulation results show the superiority of
the proposed DRL-TDCTM algorithm over the conventional baseline methods.",arxiv
http://arxiv.org/abs/2108.02889v1,2021-08-05T23:55:44Z,2021-08-05T23:55:44Z,"RIS-assisted UAV Communications for IoT with Wireless Power Transfer
  Using Deep Reinforcement Learning","Many of the devices used in Internet-of-Things (IoT) applications are
energy-limited, and thus supplying energy while maintaining seamless
connectivity for IoT devices is of considerable importance. In this context, we
propose a simultaneous wireless power transfer and information transmission
scheme for IoT devices with support from reconfigurable intelligent surface
(RIS)-aided unmanned aerial vehicle (UAV) communications. In particular, in a
first phase, IoT devices harvest energy from the UAV through wireless power
transfer; and then in a second phase, the UAV collects data from the IoT
devices through information transmission. To characterise the agility of the
UAV, we consider two scenarios: a hovering UAV and a mobile UAV. Aiming at
maximizing the total network sum-rate, we jointly optimize the trajectory of
the UAV, the energy harvesting scheduling of IoT devices, and the phaseshift
matrix of the RIS. We formulate a Markov decision process and propose two deep
reinforcement learning algorithms to solve the optimization problem of
maximizing the total network sum-rate. Numerical results illustrate the
effectiveness of the UAV's flying path optimization and the network's
throughput of our proposed techniques compared with other benchmark schemes.
Given the strict requirements of the RIS and UAV, the significant improvement
in processing time and throughput performance demonstrates that our proposed
scheme is well applicable for practical IoT applications.",arxiv
http://arxiv.org/abs/2108.11012v1,2021-08-25T02:04:13Z,2021-08-25T02:04:13Z,"Responsive Regulation of Dynamic UAV Communication Networks Based on
  Deep Reinforcement Learning","In this chapter, the regulation of Unmanned Aerial Vehicle (UAV)
communication network is investigated in the presence of dynamic changes in the
UAV lineup and user distribution. We target an optimal UAV control policy which
is capable of identifying the upcoming change in the UAV lineup (quit or
join-in) or user distribution, and proactively relocating the UAVs ahead of the
change rather than passively dispatching the UAVs after the change.
Specifically, a deep reinforcement learning (DRL)-based UAV control framework
is developed to maximize the accumulated user satisfaction (US) score for a
given time horizon which is able to handle the change in both the UAV lineup
and user distribution. The framework accommodates the changed dimension of the
state-action space before and after the UAV lineup change by deliberate state
transition design. In addition, to handle the continuous state and action
space, deep deterministic policy gradient (DDPG) algorithm, which is an
actor-critic based DRL, is exploited. Furthermore, to promote the learning
exploration around the timing of the change, the original DDPG is adapted into
an asynchronous parallel computing (APC) structure which leads to a better
training performance in both the critic and actor networks. Finally, extensive
simulations are conducted to validate the convergence of the proposed learning
approach, and demonstrate its capability in jointly handling the dynamics in
UAV lineup and user distribution as well as its superiority over a passive
reaction method.",arxiv
http://arxiv.org/abs/2110.06318v1,2021-10-12T20:12:59Z,2021-10-12T20:12:59Z,DQN-based Beamforming for Uplink mmWave Cellular-Connected UAVs,"Unmanned aerial vehicles (UAVs) are the emerging vital components of
millimeter wave (mmWave) wireless systems. Accurate beam alignment is essential
for efficient beam-based mmWave communications of UAVs with base stations
(BSs). Conventional beam sweeping approaches often have large overhead due to
the high mobility and autonomous operation of UAVs. Learning-based approaches
greatly reduce the overhead by leveraging UAV data, like position to identify
optimal beam directions. In this paper, we propose a reinforcement learning
(RL)-based framework for UAV-BS beam alignment using deep Q-Network (DQN) in a
mmWave setting. We consider uplink communications where the UAV hovers around
5G new radio (NR) BS coverage area, with varying channel conditions. The
proposed learning framework uses the location information to maximize data rate
through the optimal beam-pairs efficiently, upon every communication request
from UAV inside the multi-location environment. We compare our proposed
framework against the Multi-Armed Bandit (MAB) learning-based approach and the
traditional exhaustive approach, respectively, and also analyse the training
performance of DQN-based beam alignment over different coverage area
requirements and channel conditions. Our results show that the proposed
DQN-based beam alignment converges faster and generic for different
environmental conditions. The framework can also learn optimal beam alignment
comparable to the exhaustive approach in an online manner under real-time
conditions.",arxiv
http://arxiv.org/abs/1808.04507v1,2018-08-14T02:12:52Z,2018-08-14T02:12:52Z,"Alternating Iterative Secure Structure between Beamforming and Power
  Allocation for UAV-aided Directional Modulation Networks","In unmanned aerial vehicle (UAV) networks, directional modulation (DM) is
adopted to improve the secrecy rate (SR) performance. Alice, a ground base
station, behaves as a control center, and Bob is a UAV of flying along a linear
flight trajectory who optimizes its SR performance by dynamically adjusting its
beamforming vectors and power allocation (PA) strategy. Per fixed time interval
during the Bob's flight process, the transmit beamforming vectors for useful
messages and AN projection are given by the rule of maximizing
signal-to-leakage-and-noise ratio (Max-SLNR) and maximizing
AN-and-leakage-to-noise ratio (ANLNR), and the optimal PA strategy is based on
maximizing SR (Max-SR). More importantly, an alternating iterative structure
(AIS) between beamforming and PA is proposed to further improve the SR
performance. Simulation results show that the proposed AIS converges rapidly,
and can achieve substantial SR gains over Max-SLNR plus Max-ANLNR with fixed PA
such as PA factor $\beta=$ 0.5, and 0.9. In particular, in the case of
small-scale antenna array, the SR performance gain achieved by the proposed AIS
is more attractive. Additionally, as the number of antennas tends to be
large-scale, the average SR performance of the proposed AIS approaches an SR
ceil.",arxiv
http://arxiv.org/abs/1810.10438v2,2020-05-18T10:20:12Z,2018-10-24T15:08:11Z,UAVid: A Semantic Segmentation Dataset for UAV Imagery,"Semantic segmentation has been one of the leading research interests in
computer vision recently. It serves as a perception foundation for many fields,
such as robotics and autonomous driving. The fast development of semantic
segmentation attributes enormously to the large scale datasets, especially for
the deep learning related methods. There already exist several semantic
segmentation datasets for comparison among semantic segmentation methods in
complex urban scenes, such as the Cityscapes and CamVid datasets, where the
side views of the objects are captured with a camera mounted on the driving
car. There also exist semantic labeling datasets for the airborne images and
the satellite images, where the top views of the objects are captured. However,
only a few datasets capture urban scenes from an oblique Unmanned Aerial
Vehicle (UAV) perspective, where both of the top view and the side view of the
objects can be observed, providing more information for object recognition. In
this paper, we introduce our UAVid dataset, a new high-resolution UAV semantic
segmentation dataset as a complement, which brings new challenges, including
large scale variation, moving object recognition and temporal consistency
preservation. Our UAV dataset consists of 30 video sequences capturing 4K
high-resolution images in slanted views. In total, 300 images have been densely
labeled with 8 classes for the semantic labeling task. We have provided several
deep learning baseline methods with pre-training, among which the proposed
Multi-Scale-Dilation net performs the best via multi-scale feature extraction.
Our UAVid website and the labeling tool have been published https://uavid.nl/.",arxiv
http://arxiv.org/abs/1906.02809v1,2019-06-06T20:58:39Z,2019-06-06T20:58:39Z,Scene and Environment Monitoring Using Aerial Imagery and Deep Learning,"Unmanned Aerial vehicles (UAV) are a promising technology for smart farming
related applications. Aerial monitoring of agriculture farms with UAV enables
key decision-making pertaining to crop monitoring. Advancements in deep
learning techniques have further enhanced the precision and reliability of
aerial imagery based analysis. The capabilities to mount various kinds of
sensors (RGB, spectral cameras) on UAV allows remote crop analysis applications
such as vegetation classification and segmentation, crop counting, yield
monitoring and prediction, crop mapping, weed detection, disease and nutrient
deficiency detection and others. A significant amount of studies are found in
the literature that explores UAV for smart farming applications. In this paper,
a review of studies applying deep learning on UAV imagery for smart farming is
presented. Based on the application, we have classified these studies into five
major groups including: vegetation identification, classification and
segmentation, crop counting and yield predictions, crop mapping, weed detection
and crop disease and nutrient deficiency detection. An in depth critical
analysis of each study is provided.",arxiv
http://arxiv.org/abs/2003.09802v1,2020-03-22T04:09:59Z,2020-03-22T04:09:59Z,"Review of data analysis in vision inspection of power lines with an
  in-depth discussion of deep learning technology","The widespread popularity of unmanned aerial vehicles enables an immense
amount of power lines inspection data to be collected. How to employ massive
inspection data especially the visible images to maintain the reliability,
safety, and sustainability of power transmission is a pressing issue. To date,
substantial works have been conducted on the analysis of power lines inspection
data. With the aim of providing a comprehensive overview for researchers who
are interested in developing a deep-learning-based analysis system for power
lines inspection data, this paper conducts a thorough review of the current
literature and identifies the challenges for future research. Following the
typical procedure of inspection data analysis, we categorize current works in
this area into component detection and fault diagnosis. For each aspect, the
techniques and methodologies adopted in the literature are summarized. Some
valuable information is also included such as data description and method
performance. Further, an in-depth discussion of existing deep-learning-related
analysis methods in power lines inspection is proposed. Finally, we conclude
the paper with several research trends for the future of this area, such as
data quality problems, small object detection, embedded application, and
evaluation baseline.",arxiv
http://arxiv.org/abs/2004.13973v1,2020-04-29T06:29:49Z,2020-04-29T06:29:49Z,Deep Transfer Learning For Plant Center Localization,"Plant phenotyping focuses on the measurement of plant characteristics
throughout the growing season, typically with the goal of evaluating genotypes
for plant breeding. Estimating plant location is important for identifying
genotypes which have low emergence, which is also related to the environment
and management practices such as fertilizer applications. The goal of this
paper is to investigate methods that estimate plant locations for a field-based
crop using RGB aerial images captured using Unmanned Aerial Vehicles (UAVs).
Deep learning approaches provide promising capability for locating plants
observed in RGB images, but they require large quantities of labeled data
(ground truth) for training. Using a deep learning architecture fine-tuned on a
single field or a single type of crop on fields in other geographic areas or
with other crops may not have good results. The problem of generating ground
truth for each new field is labor-intensive and tedious. In this paper, we
propose a method for estimating plant centers by transferring an existing model
to a new scenario using limited ground truth data. We describe the use of
transfer learning using a model fine-tuned for a single field or a single type
of plant on a varied set of similar crops and fields. We show that transfer
learning provides promising results for detecting plant locations.",arxiv
http://arxiv.org/abs/2101.06414v1,2021-01-16T09:20:46Z,2021-01-16T09:20:46Z,"Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in
  GPS-Denied Environments","In this work, we present a pragmatic approach to enable unmanned aerial
vehicle (UAVs) to autonomously perform highly complicated tasks of object pick
and place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is
primarily focused on the task of assembling large 3D structures in outdoors and
GPS-denied environments. Primary contributions of this system are: (i) a novel
computationally efficient deep learning based unified multi-task visual
perception system for target localization, part segmentation, and tracking,
(ii) a novel deep learning based grasp state estimation, (iii) a retracting
electromagnetic gripper design, (iv) a remote computing approach which exploits
state-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the
UAVs to execute compute intensive tasks on remote high end compute servers, and
(v) system integration in which several system components are weaved together
in order to develop an optimized software stack. We use DJI Matrice-600 Pro, a
hex-rotor UAV and interface it with the custom designed gripper. Our framework
is deployed on the specified UAV in order to report the performance analysis of
the individual modules. Apart from the manipulation system, we also highlight
several hidden challenges associated with the UAVs in this context.",arxiv
http://arxiv.org/abs/2104.02108v1,2021-04-05T18:35:11Z,2021-04-05T18:35:11Z,Control of a Tail-Sitter VTOL UAV Based on Recurrent Neural Networks,"Tail-sitter vertical takeoff and landing (VTOL) unmanned aerial vehicles
(UAVs) have the capability of hovering and performing efficient level flight
with compact mechanical structures. We present a unified controller design for
such UAVs, based on recurrent neural networks. An advantage of this design
method is that the various flight modes (i.e., hovering, transition and level
flight) of a VTOL UAV are controlled in a unified manner, as opposed to
treating them separately and in the runtime switching one from another. The
proposed controller consists of an outer-loop position controller and an
inner-loop attitude controller. The inner-loop controller is composed of a
proportional attitude controller and a loop-shaping linear angular rate
controller. For the outer-loop controller, we propose a nonlinear solver to
compute the desired attitude and thrust, based on the UAV dynamics and an
aerodynamic model, in addition to a cascaded PID controller for the position
and velocity tracking. We employ a recurrent neural network (RNN) to
approximate the behavior of the nonlinear solver, which suffers from high
computational complexity. The proposed RNN has negligible approximation errors,
and can be implemented in real-time (e.g., 50 Hz). Moreover, the RNN generates
much smoother outputs than the nonlinear solver. We provide an analysis of the
stability and robustness of the overall closed-loop system. Simulation and
experiments are also presented to demonstrate the effectiveness of the proposed
method.",arxiv
http://arxiv.org/abs/2110.02846v1,2021-10-06T15:18:17Z,2021-10-06T15:18:17Z,"Seed Classification using Synthetic Image Datasets Generated from
  Low-Altitude UAV Imagery","Plant breeding programs extensively monitor the evolution of seed kernels for
seed certification, wherein lies the need to appropriately label the seed
kernels by type and quality. However, the breeding environments are large where
the monitoring of seed kernels can be challenging due to the minuscule size of
seed kernels. The use of unmanned aerial vehicles aids in seed monitoring and
labeling since they can capture images at low altitudes whilst being able to
access even the remotest areas in the environment. A key bottleneck in the
labeling of seeds using UAV imagery is drone altitude i.e. the classification
accuracy decreases as the altitude increases due to lower image detail.
Convolutional neural networks are a great tool for multi-class image
classification when there is a training dataset that closely represents the
different scenarios that the network might encounter during evaluation. The
article addresses the challenge of training data creation using Domain
Randomization wherein synthetic image datasets are generated from a meager
sample of seeds captured by the bottom camera of an autonomously driven Parrot
AR Drone 2.0. Besides, the article proposes a seed classification framework as
a proof-of-concept using the convolutional neural networks of Microsoft's
ResNet-100, Oxford's VGG-16, and VGG-19. To enhance the classification accuracy
of the framework, an ensemble model is developed resulting in an overall
accuracy of 94.6%.",arxiv
http://arxiv.org/abs/2104.06614v1,2021-04-14T03:49:35Z,2021-04-14T03:49:35Z,Semi-supervised Learning Framework for UAV Detection,"The use of supervised learning with various sensing techniques such as audio,
visual imaging, thermal sensing, RADAR, and radio frequency (RF) have been
widely applied in the detection of unmanned aerial vehicles (UAV) in an
environment. However, little or no attention has been given to the application
of unsupervised or semi-supervised algorithms for UAV detection. In this paper,
we proposed a semi-supervised technique and architecture for detecting UAVs in
an environment by exploiting the RF signals (i.e., fingerprints) between a UAV
and its flight-controller communication under wireless inference such as
Bluetooth and WiFi. By decomposing the RF signals using a two-level wavelet
packet transform, we estimated the second moment statistic (i.e., variance) of
the coefficients in each packet as a feature set. We developed a local outlier
factor model as the UAV detection algorithm using the coefficient variances of
the wavelet packets from WiFi and Bluetooth signals. When detecting the
presence of RF-based UAV, we achieved an accuracy of 96.7$\%$ and 86$\%$ at a
signal-to-noise ratio of 30~dB and 18~dB, respectively. The application of this
approach is not limited to UAV detection as it can be extended to the detection
of rogue RF devices in an environment.",arxiv
http://arxiv.org/abs/2002.12078v1,2020-02-27T13:14:53Z,2020-02-27T13:14:53Z,"Training Adversarial Agents to Exploit Weaknesses in Deep Control
  Policies","Deep learning has become an increasingly common technique for various control
problems, such as robotic arm manipulation, robot navigation, and autonomous
vehicles. However, the downside of using deep neural networks to learn control
policies is their opaque nature and the difficulties of validating their
safety. As the networks used to obtain state-of-the-art results become
increasingly deep and complex, the rules they have learned and how they operate
become more challenging to understand. This presents an issue, since in
safety-critical applications the safety of the control policy must be ensured
to a high confidence level. In this paper, we propose an automated black box
testing framework based on adversarial reinforcement learning. The technique
uses an adversarial agent, whose goal is to degrade the performance of the
target model under test. We test the approach on an autonomous vehicle problem,
by training an adversarial reinforcement learning agent, which aims to cause a
deep neural network-driven autonomous vehicle to collide. Two neural networks
trained for autonomous driving are compared, and the results from the testing
are used to compare the robustness of their learned control policies. We show
that the proposed framework is able to find weaknesses in both control policies
that were not evident during online testing and therefore, demonstrate a
significant benefit over manual testing methods.",arxiv
http://arxiv.org/abs/1703.09436v1,2017-03-28T07:43:42Z,2017-03-28T07:43:42Z,"Evaluation of Classifiers for Image Segmentation: Applications for
  Eucalypt Forest Inventory","The task of counting eucalyptus trees from aerial images collected by
unmanned aerial vehicles (UAVs) has been frequently explored by techniques of
estimation of the basal area, i.e, by determining the expected number of trees
based on sampling techniques. An alternative is the use of machine learning to
identify patterns that represent a tree unit, and then search for the
occurrence of these patterns throughout the image. This strategy depends on a
supervised image segmentation step to define predefined interest regions. Thus,
it is possible to automate the counting of eucalyptus trees in these images,
thereby increasing the efficiency of the eucalyptus forest inventory
management. In this paper, we evaluated 20 different classifiers for the image
segmentation task. A real sample was used to analyze the counting trees task
considering a practical environment. The results show that it possible to
automate this task with 0.7% counting error, in particular, by using strategies
based on a combination of classifiers. Moreover, we present some performance
considerations about each classifier that can be useful as a basis for
decision-making in future tasks.",arxiv
http://arxiv.org/abs/1703.10049v4,2021-08-10T07:28:52Z,2017-03-29T14:12:42Z,"Autonomous Recharging and Flight Mission Planning for Battery-operated
  Autonomous Drones","Unmanned aerial vehicles (UAVs), commonly known as drones, are being
increasingly deployed throughout the globe as a means to streamline logistic
and monitoring routines. When dispatched on autonomous missions, drones require
an intelligent decision-making system for trajectory planning and tour
optimization. Given the limited capacity of their onboard batteries, a key
design challenge is ensuring the underlying algorithms can efficiently optimize
the mission objectives along with recharging operations during long-haul
flights. Against this backdrop, the present work undertakes a comprehensive
study on automated management systems for battery-constrained drones: (1) We
construct a machine learning model to estimate the energy expenditure of
drones, considering diverse real-world factors and flight scenarios. (2)
Leveraging this model, the joint problem of flight mission planning and
recharging optimization is formulated as a multi-criteria combinatorial program
aimed at completing a tour mission for a set of target sites in the shortest
time while minimizing recharging duration. (3) We devise an efficient
approximation algorithm, with provable near-optimal performance guarantees, and
implement it in a drone management system, which supports real-time flight path
tracking and re-computation in dynamic environments. (4) We validate the
effectiveness and practicality of the proposed approach through extensive
numerical simulations as well as real-world experiments.",arxiv
http://arxiv.org/abs/1803.00680v2,2019-03-17T01:34:35Z,2018-03-02T01:34:06Z,"A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and
  Open Problems","The use of flying platforms such as unmanned aerial vehicles (UAVs),
popularly known as drones, is rapidly growing. In particular, with their
inherent attributes such as mobility, flexibility, and adaptive altitude, UAVs
admit several key potential applications in wireless systems. On the one hand,
UAVs can be used as aerial base stations to enhance coverage, capacity,
reliability, and energy efficiency of wireless networks. On the other hand,
UAVs can operate as flying mobile terminals within a cellular network. Such
cellular-connected UAVs can enable several applications ranging from real-time
video streaming to item delivery. In this paper, a comprehensive tutorial on
the potential benefits and applications of UAVs in wireless communications is
presented. Moreover, the important challenges and the fundamental tradeoffs in
UAV-enabled wireless networks are thoroughly investigated. In particular, the
key UAV challenges such as three-dimensional deployment, performance analysis,
channel modeling, and energy efficiency are explored along with representative
results. Then, open problems and potential research directions pertaining to
UAV communications are introduced. Finally, various analytical frameworks and
mathematical tools such as optimization theory, machine learning, stochastic
geometry, transport theory, and game theory are described. The use of such
tools for addressing unique UAV problems is also presented. In a nutshell, this
tutorial provides key guidelines on how to analyze, optimize, and design
UAV-based wireless communication systems.",arxiv
http://arxiv.org/abs/1810.09729v1,2018-10-23T08:51:54Z,2018-10-23T08:51:54Z,"Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A
  Comprehensive Survey, and Future Directions","Unmanned Aerial Vehicles (UAVs) have recently rapidly grown to facilitate a
wide range of innovative applications that can fundamentally change the way
cyber-physical systems (CPSs) are designed. CPSs are a modern generation of
systems with synergic cooperation between computational and physical potentials
that can interact with humans through several new mechanisms. The main
advantages of using UAVs in CPS application is their exceptional features,
including their mobility, dynamism, effortless deployment, adaptive altitude,
agility, adjustability, and effective appraisal of real-world functions anytime
and anywhere. Furthermore, from the technology perspective, UAVs are predicted
to be a vital element of the development of advanced CPSs. Therefore, in this
survey, we aim to pinpoint the most fundamental and important design challenges
of multi-UAV systems for CPS applications. We highlight key and versatile
aspects that span the coverage and tracking of targets and infrastructure
objects, energy-efficient navigation, and image analysis using machine learning
for fine-grained CPS applications. Key prototypes and testbeds are also
investigated to show how these practical technologies can facilitate CPS
applications. We present and propose state-of-the-art algorithms to address
design challenges with both quantitative and qualitative methods and map these
challenges with important CPS applications to draw insightful conclusions on
the challenges of each application. Finally, we summarize potential new
directions and ideas that could shape future research in these areas.",arxiv
http://arxiv.org/abs/1902.06610v2,2019-02-20T04:08:45Z,2019-02-18T15:24:57Z,"Optimized Trajectory Design in UAV Based Cellular Networks for 3D Users:
  A Double Q-Learning Approach","In this paper, the problem of trajectory design of unmanned aerial vehicles
(UAVs) for maximizing the number of satisfied users is studied in a UAV based
cellular network where the UAV works as a flying base station that serves
users, and the user indicates its satisfaction in terms of completion of its
data request within an allowable maximum waiting time. The trajectory design is
formulated as an optimization problem whose goal is to maximize the number of
satisfied users. To solve this problem, a machine learning framework based on
double Q-learning algorithm is proposed. The algorithm enables the UAV to find
the optimal trajectory that maximizes the number of satisfied users. Compared
to the traditional learning algorithms, such as Q-learning that selects and
evaluates the action using the same Q-table, the proposed algorithm can
decouple the selection from the evaluation, therefore avoid overestimation
which leads to sub-optimal policies. Simulation results show that the proposed
algorithm can achieve up to 19.4% and 14.1% gains in terms of the number of
satisfied users compared to random algorithm and Q-learning algorithm.",arxiv
http://arxiv.org/abs/1910.13538v1,2019-10-29T21:16:50Z,2019-10-29T21:16:50Z,"Machine-Learning Beam Tracking and Weight Optimization for mmWave
  Multi-UAV Links","Millimeter-wave (mmWave) hybrid analog-digital beamforming is a promising
approach to satisfy the low-latency constraint in multiple unmanned aerial
vehicles (UAVs) systems, which serve as network infrastructure for flexible
deployment. However, in highly dynamic multi-UAV environments, analog beam
tracking becomes a critical challenge. The overhead of additional pilot
transmission at the price of spectral efficiency is shown necessary to achieve
high resilience in operation. An efficient method to deal with high dynamics of
UAVs applies machine learning, particularly Q-learning, to analog beam
tracking. The proposed Q-learning-based beam tracking scheme uses current/past
observations to design rewards from environments to facilitate prediction,
which significantly increases the efficiency of data transmission and beam
switching. Given the selected analog beams, the goal of digital beamforming is
to maximize the SINR. The received pilot signals are utilized to approximate
the desired signal and interference power, which yield the SINR measurements as
well as the optimal digital weights. Since the selected analog beams based on
the received power do not guarantee the hybrid beamforming achieving the
maximization SINR, we therefore reserve additional analog beams as candidates
during the beam tracking. The combination of analog beams with their digital
weights achieving the maximum SINR consequently provides the optimal solution
to the hybrid beamforming.",arxiv
http://arxiv.org/abs/2001.11610v1,2020-01-30T23:49:15Z,2020-01-30T23:49:15Z,"UAV Autonomous Localization using Macro-Features Matching with a CAD
  Model","Research in the field of autonomous Unmanned Aerial Vehicles (UAVs) has
significantly advanced in recent years, mainly due to their relevance in a
large variety of commercial, industrial, and military applications. However,
UAV navigation in GPS-denied environments continues to be a challenging problem
that has been tackled in recent research through sensor-based approaches. This
paper presents a novel offline, portable, real-time in-door UAV localization
technique that relies on macro-feature detection and matching. The proposed
system leverages the support of machine learning, traditional computer vision
techniques, and pre-existing knowledge of the environment. The main
contribution of this work is the real-time creation of a macro-feature
description vector from the UAV captured images which are simultaneously
matched with an offline pre-existing vector from a Computer-Aided Design (CAD)
model. This results in a quick UAV localization within the CAD model. The
effectiveness and accuracy of the proposed system were evaluated through
simulations and experimental prototype implementation. Final results reveal the
algorithm's low computational burden as well as its ease of deployment in
GPS-denied environments.",arxiv
http://arxiv.org/abs/2003.02631v2,2020-07-30T13:21:21Z,2020-03-02T00:15:09Z,Machine Learning for Predictive Deployment of UAVs with Multiple Access,"In this paper, a machine learning based deployment framework of unmanned
aerial vehicles (UAVs) is studied. In the considered model, UAVs are deployed
as flying base stations (BS) to offload heavy traffic from ground BSs. Due to
time-varying traffic distribution, a long short-term memory (LSTM) based
prediction algorithm is introduced to predict the future cellular traffic. To
predict the user service distribution, a KEG algorithm, which is a joint
K-means and expectation maximization (EM) algorithm based on Gaussian mixture
model (GMM), is proposed for determining the service area of each UAV. Based on
the predicted traffic, the optimal UAV positions are derived and three
multi-access techniques are compared so as to minimize the total transmit
power. Simulation results show that the proposed method can reduce up to 24\%
of the total power consumption compared to the conventional method without
traffic prediction. Besides, rate splitting multiple access (RSMA) has the
lower required transmit power compared to frequency domain multiple access
(FDMA) and time domain multiple access (TDMA).",arxiv
http://arxiv.org/abs/2005.10937v4,2021-02-20T21:12:18Z,2020-05-21T23:08:37Z,"Non-Coherent and Backscatter Communications: Enabling Ultra-Massive
  Connectivity in 6G Wireless Networks","With the commencement of the 5G of wireless networks, researchers around the
globe have started paying their attention to the imminent challenges that may
emerge in the beyond 5G (B5G) era. Various revolutionary technologies and
innovative services are offered in 5G networks, which, along with many
principal advantages, are anticipated to bring a boom in the number of
connected wireless devices and the types of use-cases that may cause the
scarcity of network resources. These challenges partly emerged with the advent
of massive machine-type communications (mMTC) services, require extensive
research innovations to sustain the evolution towards enhanced-mMTC (e-mMTC)
with the scalable network cost in 6\textsuperscript{th} generation (6G)
wireless networks. Towards delivering the anticipated massive connectivity
requirements with optimal energy and spectral efficiency besides low hardware
cost, this paper presents an enabling framework for 6G networks, which utilizes
two emerging technologies, namely, non-coherent communications and backscatter
communications (BsC). Recognizing the coherence between these technologies for
their joint potential of delivering e-mMTC services in the B5G era, a
comprehensive review of their state-of-the-art is conducted. The joint scope of
non-coherent and BsC with other emerging 6G technologies is also identified,
where the reviewed technologies include unmanned aerial vehicles
(UAVs)-assisted communications, visible light communications (VLC),
quantum-assisted communications, reconfigurable large intelligent surfaces
(RLIS), non-orthogonal multiple access (NOMA), and machine learning-aided
intelligent networks. Subsequently, the scope of these enabling technologies
for different device types, service types, and optimization parameters is
analyzed...",arxiv
http://arxiv.org/abs/2005.14064v1,2020-05-28T14:57:23Z,2020-05-28T14:57:23Z,"Codebook-Based Beam Tracking for Conformal ArrayEnabled UAV MmWave
  Networks","Millimeter wave (mmWave) communications can potentially meet the high
data-rate requirements of unmanned aerial vehicle (UAV) networks. However, as
the prerequisite of mmWave communications, the narrow directional beam tracking
is very challenging because of the three-dimensional (3D) mobility and attitude
variation of UAVs. Aiming to address the beam tracking difficulties, we propose
to integrate the conformal array (CA) with the surface of each UAV, which
enables the full spatial coverage and the agile beam tracking in highly dynamic
UAV mmWave networks. More specifically, the key contributions of our work are
three-fold. 1) A new mmWave beam tracking framework is established for the
CA-enabled UAV mmWave network. 2) A specialized hierarchical codebook is
constructed to drive the directional radiating element (DRE)-covered
cylindrical conformal array (CCA), which contains both the angular beam pattern
and the subarray pattern to fully utilize the potential of the CA. 3) A
codebook-based multiuser beam tracking scheme is proposed, where the Gaussian
process machine learning enabled UAV position/attitude predication is developed
to improve the beam tracking efficiency in conjunction with the tracking-error
aware adaptive beamwidth control. Simulation results validate the effectiveness
of the proposed codebook-based beam tracking scheme in the CA-enabled UAV
mmWave network, and demonstrate the advantages of CA over the conventional
planner array in terms of spectrum efficiency and outage probability in the
highly dynamic scenarios.",arxiv
http://arxiv.org/abs/2011.10177v1,2020-11-20T02:30:39Z,2020-11-20T02:30:39Z,"Flight Sensor Data and Beamforming based Integrated UAV Tracking with
  Channel Estimation using Gaussian Process Regression","With explosively increasing demands for unmanned aerial vehicle (UAV)
applications, reliable link acquisition for serving UAVs is required.
Considering the dynamic characteristics of UAV, it is hugely challenging to
persist a reliable link without beam misalignment. In this paper, we propose a
flight sensor data and beamforming signal based integrated UAV tracking scheme
to deal with this problem. The proposed scheme provides a compatible integrated
system considering the practical specification of the flight sensor data and
the beamforming pilot signal. The UAV position tracking is comprised of two
steps: 1) UAV position prediction by the flight sensor data and 2) position
update with the beamforming signal using Gaussian process regression (GPR)
method, which is a nonparametric machine learning. The flight sensor data can
assist ground station (GS) or UAV nodes in designing the precoding and the
receive beamforming matrix with drastically reduced overheads. The beamforming
signal can accomplish high beamforming gain to be maintained even when the
flight sensor data is absent. Therefore, the proposed scheme can support the
moving target continuously by utilizing these two signals. The simulation
results are provided to confirm that the proposed scheme outperforms other
conventional beam tracking schemes. We also derive 3-dimensional (3D)
beamforming gain and spectral efficiency (SE) from the mean absolute error
(MAE) of the angular value estimation, which can be used as beamforming
performance metrics of the data transmission link in advance.",arxiv
http://arxiv.org/abs/2012.06707v2,2021-04-16T13:18:21Z,2020-12-12T02:59:05Z,"Channel Modeling for UAV Communications: State of the Art, Case Studies,
  and Future Directions","As essential aerial platforms, unmanned aerial vehicles (UAVs) play an
increasingly important role in broad wireless connectivity and high-data-rate
transmission for future communication systems. Notably, various communication
scenarios are involved in UAV communications, such as intercommunications
between UAVs and communications with the ground user equipment, the cellular
base station, and the ground station, to name a few. However, existing works
mostly focus on a single communication scenario, a designated channel type, and
a specific operating frequency, thus urgently requiring a comprehensive
understanding of multi-scenario, multi-frequency, and multi-type UAV channels.
This article pours attention into the essentials of corresponding air-to-air
(A2A) and air-to-ground (A2G) channels in UAV communications. We first identify
the latest key challenges of channel modeling for UAV communications. We then
provide the state of the art for A2A and A2G channel properties and models
based on extensive measurement campaigns. In particular, we conduct realistic
case studies to further demonstrate critical channel characterizations and
machine learning-based modeling methods. Last but not least, potential
directions are widely discussed for paving the way towards more accurate and
effective channel models for UAV communications.",arxiv
http://arxiv.org/abs/2103.01143v4,2021-07-06T16:03:36Z,2021-03-01T17:28:16Z,Towards 6G with Connected Sky: UAVs and Beyond,"The large-scale and ever-growing use of unmanned aerial vehicles (UAVs) in a
wide range of applications is foreseen to be a major part of beyond 5G and 6G
wireless networks in the next decade. The effective support of such massive
deployment of UAVs requires offering reliable, secure, and cost-effective
wireless connectivity. In this regard, cellular networks play essential roles
in serving UAVs acting as flying user equipments. While the cellular networks
provide promising connectivity solutions for UAVs, enabling robust UAV
operations faces several challenges. In this paper, an overview of key barriers
and design considerations of widespread commercial use of flying UAVs are
presented along with their potential solutions. In addition, we discuss how
cellular networks can support UAVs by relying on their advanced features,
network intelligence, key enabling technologies for beyond 5G and 6G, and
exploiting new tools from machine learning. Finally, we shed light on offering
wireless services to high altitudes and the integration of non-terrestrial
networks with terrestrial networks towards limitless connectivity in 6G.",arxiv
http://arxiv.org/abs/2106.07314v1,2021-06-14T11:38:13Z,2021-06-14T11:38:13Z,"Computer Vision Tool for Detection, Mapping and Fault Classification of
  PV Modules in Aerial IR Videos","Increasing deployment of photovoltaics (PV) plants demands for cheap and fast
inspection. A viable tool for this task is thermographic imaging by unmanned
aerial vehicles (UAV). In this work, we develop a computer vision tool for the
semi-automatic extraction of PV modules from thermographic UAV videos. We use
it to curate a dataset containing 4.3 million IR images of 107842 PV modules
from thermographic videos of seven different PV plants. To demonstrate its use
for automated PV plant inspection, we train a ResNet-50 to classify ten common
module anomalies with more than 90 % test accuracy. Experiments show that our
tool generalizes well to different PV plants. It successfully extracts PV
modules from 512 out of 561 plant rows. Failures are mostly due to an
inappropriate UAV trajectory and erroneous module segmentation. Including all
manual steps our tool enables inspection of 3.5 MW p to 9 MW p of PV
installations per day, potentially scaling to multi-gigawatt plants due to its
parallel nature. While we present an effective method for automated PV plant
inspection, we are also confident that our approach helps to meet the growing
demand for large thermographic datasets for machine learning tasks, such as
power prediction or unsupervised defect identification.",arxiv
http://arxiv.org/abs/2110.07296v1,2021-10-14T12:04:30Z,2021-10-14T12:04:30Z,"Resource Allocation for Simultaneous Wireless Information and Power
  Transfer Systems: A Tutorial Overview","Over the last decade, simultaneous wireless information and power transfer
(SWIPT) has become a practical and promising solution for connecting and
recharging battery-limited devices, thanks to significant advances in low-power
electronics technology and wireless communications techniques. To realize the
promised potentials, advanced resource allocation design plays a decisive role
in revealing, understanding, and exploiting the intrinsic rate-energy tradeoff
capitalizing on the dual use of radio frequency (RF) signals for wireless
charging and communication. In this paper, we provide a comprehensive tutorial
overview of SWIPT from the perspective of resource allocation design. The
fundamental concepts, system architectures, and RF energy harvesting (EH)
models are introduced. In particular, three commonly adopted EH models, namely
the linear EH model, the nonlinear saturation EH model, and the nonlinear
circuit-based EH model are characterized and discussed. Then, for a typical
wireless system setup, we establish a generalized resource allocation design
framework which subsumes conventional resource allocation design problems as
special cases. Subsequently, we elaborate on relevant tools from optimization
theory and exploit them for solving representative resource allocation design
problems for SWIPT systems with and without perfect channel state information
(CSI) available at the transmitter, respectively. The associated technical
challenges and insights are also highlighted. Furthermore, we discuss several
promising and exciting future research directions for resource allocation
design for SWIPT systems intertwined with cutting-edge communication
technologies, such as intelligent reflecting surfaces, unmanned aerial
vehicles, mobile edge computing, federated learning, and machine learning.",arxiv
http://arxiv.org/abs/1911.10735v1,2019-11-25T07:28:45Z,2019-11-25T07:28:45Z,"CAMUS: A Framework to Build Formal Specifications for Deep Perception
  Systems Using Simulators","The topic of provable deep neural network robustness has raised considerable
interest in recent years. Most research has focused on adversarial robustness,
which studies the robustness of perceptive models in the neighbourhood of
particular samples. However, other works have proved global properties of
smaller neural networks. Yet, formally verifying perception remains uncharted.
This is due notably to the lack of relevant properties to verify, as the
distribution of possible inputs cannot be formally specified. We propose to
take advantage of the simulators often used either to train machine learning
models or to check them with statistical tests, a growing trend in industry.
Our formulation allows us to formally express and verify safety properties on
perception units, covering all cases that could ever be generated by the
simulator, to the difference of statistical tests which cover only seen
examples. Along with this theoretical formulation , we provide a tool to
translate deep learning models into standard logical formulae. As a proof of
concept, we train a toy example mimicking an autonomous car perceptive unit,
and we formally verify that it will never fail to capture the relevant
information in the provided inputs.",arxiv
http://arxiv.org/abs/2010.12747v1,2020-10-24T02:18:39Z,2020-10-24T02:18:39Z,"Scale-, shift- and rotation-invariant diffractive optical networks","Recent research efforts in optical computing have gravitated towards
developing optical neural networks that aim to benefit from the processing
speed and parallelism of optics/photonics in machine learning applications.
Among these endeavors, Diffractive Deep Neural Networks (D2NNs) harness
light-matter interaction over a series of trainable surfaces, designed using
deep learning, to compute a desired statistical inference task as the light
waves propagate from the input plane to the output field-of-view. Although,
earlier studies have demonstrated the generalization capability of diffractive
optical networks to unseen data, achieving e.g., >98% image classification
accuracy for handwritten digits, these previous designs are in general
sensitive to the spatial scaling, translation and rotation of the input
objects. Here, we demonstrate a new training strategy for diffractive networks
that introduces input object translation, rotation and/or scaling during the
training phase as uniformly distributed random variables to build resilience in
their blind inference performance against such object transformations. This
training strategy successfully guides the evolution of the diffractive optical
network design towards a solution that is scale-, shift- and
rotation-invariant, which is especially important and useful for dynamic
machine vision applications in e.g., autonomous cars, in-vivo imaging of
biomedical specimen, among others.",arxiv
http://arxiv.org/abs/1808.00259v1,2018-08-01T10:50:47Z,2018-08-01T10:50:47Z,Drone Detection Using Depth Maps,"Obstacle avoidance is a key feature for safe Unmanned Aerial Vehicle (UAV)
navigation. While solutions have been proposed for static obstacle avoidance,
systems enabling avoidance of dynamic objects, such as drones, are hard to
implement due to the detection range and field-of-view (FOV) requirements, as
well as the constraints for integrating such systems on-board small UAVs. In
this work, a dataset of 6k synthetic depth maps of drones has been generated
and used to train a state-of-the-art deep learning-based drone detection model.
While many sensing technologies can only provide relative altitude and azimuth
of an obstacle, our depth map-based approach enables full 3D localization of
the obstacle. This is extremely useful for collision avoidance, as 3D
localization of detected drones is key to perform efficient collision-free path
planning. The proposed detection technique has been validated in several real
depth map sequences, with multiple types of drones flying at up to 2 m/s,
achieving an average precision of 98.7%, an average recall of 74.7% and a
record detection range of 9.5 meters.",arxiv
http://arxiv.org/abs/1710.08526v1,2017-10-23T22:09:45Z,2017-10-23T22:09:45Z,Video Labeling for Automatic Video Surveillance in Security Domains,"Beyond traditional security methods, unmanned aerial vehicles (UAVs) have
become an important surveillance tool used in security domains to collect the
required annotated data. However, collecting annotated data from videos taken
by UAVs efficiently, and using these data to build datasets that can be used
for learning payoffs or adversary behaviors in game-theoretic approaches and
security applications, is an under-explored research question. This paper
presents VIOLA, a novel labeling application that includes (i) a workload
distribution framework to efficiently gather human labels from videos in a
secured manner; (ii) a software interface with features designed for labeling
videos taken by UAVs in the domain of wildlife security. We also present the
evolution of VIOLA and analyze how the changes made in the development process
relate to the efficiency of labeling, including when seemingly obvious
improvements did not lead to increased efficiency. VIOLA enables collecting
massive amounts of data with detailed information from challenging security
videos such as those collected aboard UAVs for wildlife security. VIOLA will
lead to the development of new approaches that integrate deep learning for
real-time detection and response.",arxiv
http://arxiv.org/abs/1809.09195v1,2018-09-24T19:59:07Z,2018-09-24T19:59:07Z,"Towards Automated Post-Earthquake Inspections with Deep Learning-based
  Condition-Aware Models","In the aftermath of an earthquake, rapid structural inspections are required
to get citizens back in to their homes and offices in a safe and timely manner.
These inspections gfare typically conducted by municipal authorities through
structural engineer volunteers. As manual inspec-tions can be time consuming,
laborious and dangerous, research has been underway to develop methods to help
speed up and increase the automation of the entire process. Researchers
typi-cally envisage the use of unmanned aerial vehicles (UAV) for data
acquisition and computer vision for data processing to extract actionable
information. In this work we propose a new framework to generate vision-based
condition-aware models that can serve as the basis for speeding up or
automating higher level inspection decisions. The condition-aware models are
generated by projecting the inference of trained deep-learning models on a set
of images of a structure onto a 3D mesh model generated through multi-view
stereo from the same image set. Deep fully convolutional residual networks are
used for semantic segmentation of images of buildings to provide (i) damage
information such as cracks and spalling (ii) contextual infor-mation such as
the presence of a building and visually identifiable components like windows
and doors. The proposed methodology was implemented on a damaged building that
was sur-veyed by the authors after the Central Mexico Earthquake in September
2017 and qualitative-ly evaluated. Results demonstrate the promise of the
proposed method towards the ultimate goal of rapid and automated
post-earthquake inspections.",arxiv
http://arxiv.org/abs/1812.01803v3,2019-04-06T04:46:52Z,2018-12-05T03:31:02Z,"ECC: Platform-Independent Energy-Constrained Deep Neural Network
  Compression via a Bilinear Regression Model","Many DNN-enabled vision applications constantly operate under severe energy
constraints such as unmanned aerial vehicles, Augmented Reality headsets, and
smartphones. Designing DNNs that can meet a stringent energy budget is becoming
increasingly important. This paper proposes ECC, a framework that compresses
DNNs to meet a given energy constraint while minimizing accuracy loss. The key
idea of ECC is to model the DNN energy consumption via a novel bilinear
regression function. The energy estimate model allows us to formulate DNN
compression as a constrained optimization that minimizes the DNN loss function
over the energy constraint. The optimization problem, however, has nontrivial
constraints. Therefore, existing deep learning solvers do not apply directly.
We propose an optimization algorithm that combines the essence of the
Alternating Direction Method of Multipliers (ADMM) framework with
gradient-based learning algorithms. The algorithm decomposes the original
constrained optimization into several subproblems that are solved iteratively
and efficiently. ECC is also portable across different hardware platforms
without requiring hardware knowledge. Experiments show that ECC achieves higher
accuracy under the same or lower energy budget compared to state-of-the-art
resource-constrained DNN compression techniques.",arxiv
http://arxiv.org/abs/1905.09716v1,2019-05-23T15:22:16Z,2019-05-23T15:22:16Z,"A Convolutional Cost-Sensitive Crack Localization Algorithm for
  Automated and Reliable RC Bridge Inspection","Bridges are an essential part of the transportation infrastructure and need
to be monitored periodically. Visual inspections by dedicated teams have been
one of the primary tools in structural health monitoring (SHM) of bridge
structures. However, such conventional methods have certain shortcomings.
Manual inspections may be challenging in harsh environments and are commonly
biased in nature. In the last decade, camera-equipped unmanned aerial vehicles
(UAVs) have been widely used for visual inspections; however, the task of
automatically extracting useful information from raw images is still
challenging. In this paper, a deep learning semantic segmentation framework is
proposed to automatically localize surface cracks. Due to the high imbalance of
crack and background classes in images, different strategies are investigated
to improve performance and reliability. The trained models are tested on
real-world crack images showing impressive robustness in terms of the metrics
defined by the concepts of precision and recall. These techniques can be used
in SHM of bridges to extract useful information from the unprocessed images
taken from UAVs.",arxiv
http://arxiv.org/abs/2007.05854v3,2020-08-04T17:12:26Z,2020-07-11T21:12:24Z,Efficient resource management in UAVs for Visual Assistance,"There is an increased interest in the use of Unmanned Aerial Vehicles (UAVs)
for agriculture, military, disaster management and aerial photography around
the world. UAVs are scalable, flexible and are useful in various environments
where direct human intervention is difficult. In general, the use of UAVs with
cameras mounted to them has increased in number due to their wide range of
applications in real life scenarios. With the advent of deep learning models in
computer vision many models have shown great success in visual tasks. But most
of evaluation models are done on high end CPUs and GPUs. One of major
challenges in using UAVs for Visual Assistance tasks in real time is managing
the memory usage and power consumption of the these tasks which are
computationally intensive and are difficult to be performed on low end
processor board of the UAV. This projects describes a novel method to optimize
the general image processing tasks like object tracking and object detection
for UAV hardware in real time scenarios without affecting the flight time and
not tampering the latency and accuracy of these models.",arxiv
http://arxiv.org/abs/2012.02951v1,2020-12-05T05:15:36Z,2020-12-05T05:15:36Z,"FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene
  Understanding","Visual scene understanding is the core task in making any crucial decision in
any computer vision system. Although popular computer vision datasets like
Cityscapes, MS-COCO, PASCAL provide good benchmarks for several tasks (e.g.
image classification, segmentation, object detection), these datasets are
hardly suitable for post disaster damage assessments. On the other hand,
existing natural disaster datasets include mainly satellite imagery which have
low spatial resolution and a high revisit period. Therefore, they do not have a
scope to provide quick and efficient damage assessment tasks. Unmanned Aerial
Vehicle(UAV) can effortlessly access difficult places during any disaster and
collect high resolution imagery that is required for aforementioned tasks of
computer vision. To address these issues we present a high resolution UAV
imagery, FloodNet, captured after the hurricane Harvey. This dataset
demonstrates the post flooded damages of the affected areas. The images are
labeled pixel-wise for semantic segmentation task and questions are produced
for the task of visual question answering. FloodNet poses several challenges
including detection of flooded roads and buildings and distinguishing between
natural water and flooded water. With the advancement of deep learning
algorithms, we can analyze the impact of any disaster which can make a precise
understanding of the affected areas. In this paper, we compare and contrast the
performances of baseline methods for image classification, semantic
segmentation, and visual question answering on our dataset.",arxiv
http://arxiv.org/abs/2106.05082v2,2021-06-11T04:14:53Z,2021-06-09T14:01:34Z,Agile wide-field imaging with selective high resolution,"Wide-field and high-resolution (HR) imaging is essential for various
applications such as aviation reconnaissance, topographic mapping and safety
monitoring. The existing techniques require a large-scale detector array to
capture HR images of the whole field, resulting in high complexity and heavy
cost. In this work, we report an agile wide-field imaging framework with
selective high resolution that requires only two detectors. It builds on the
statistical sparsity prior of natural scenes that the important targets locate
only at small regions of interests (ROI), instead of the whole field. Under
this assumption, we use a short-focal camera to image wide field with a certain
low resolution, and use a long-focal camera to acquire the HR images of ROI. To
automatically locate ROI in the wide field in real time, we propose an
efficient deep-learning based multiscale registration method that is robust and
blind to the large setting differences (focal, white balance, etc) between the
two cameras. Using the registered location, the long-focal camera mounted on a
gimbal enables real-time tracking of the ROI for continuous HR imaging. We
demonstrated the novel imaging framework by building a proof-of-concept setup
with only 1181 gram weight, and assembled it on an unmanned aerial vehicle for
air-to-ground monitoring. Experiments show that the setup maintains
120$^{\circ}$ wide field-of-view (FOV) with selective 0.45$mrad$ instantaneous
FOV.",arxiv
http://arxiv.org/abs/2108.01884v1,2021-08-04T07:30:04Z,2021-08-04T07:30:04Z,"Adaptive Path Planning for UAV-based Multi-Resolution Semantic
  Segmentation","In this paper, we address the problem of adaptive path planning for accurate
semantic segmentation of terrain using unmanned aerial vehicles (UAVs). The
usage of UAVs for terrain monitoring and remote sensing is rapidly gaining
momentum due to their high mobility, low cost, and flexible deployment.
However, a key challenge is planning missions to maximize the value of acquired
data in large environments given flight time limitations. To address this, we
propose an online planning algorithm which adapts the UAV paths to obtain
high-resolution semantic segmentations necessary in areas on the terrain with
fine details as they are detected in incoming images. This enables us to
perform close inspections at low altitudes only where required, without wasting
energy on exhaustive mapping at maximum resolution. A key feature of our
approach is a new accuracy model for deep learning-based architectures that
captures the relationship between UAV altitude and semantic segmentation
accuracy. We evaluate our approach on the application of crop/weed segmentation
in precision agriculture using real-world field data.",arxiv
http://arxiv.org/abs/2109.12055v1,2021-09-24T16:19:37Z,2021-09-24T16:19:37Z,"Using Physiological Information to Classify Task Difficulty in
  Human-Swarm Interaction","Human-swarm interaction has recently gained attention due to its plethora of
new applications in disaster relief, surveillance, rescue, and exploration.
However, if the task difficulty increases, the performance of the human
operator decreases, thereby decreasing the overall efficacy of the human-swarm
team. Thus, it is critical to identify the task difficulty and adaptively
allocate the task to the human operator to maintain optimal performance. In
this direction, we study the classification of task difficulty in a human-swarm
interaction experiment performing a target search mission. The human may
control platoons of unmanned aerial vehicles (UAVs) and unmanned ground
vehicles (UGVs) to search a partially observable environment during the target
search mission. The mission complexity is increased by introducing adversarial
teams that humans may only see when the environment is explored. While the
human is completing the mission, their brain activity is recorded using an
electroencephalogram (EEG), which is used to classify the task difficulty. We
have used two different approaches for classification: A feature-based approach
using coherence values as input and a deep learning-based approach using raw
EEG as input. Both approaches can classify the task difficulty well above the
chance. The results showed the importance of the occipital lobe (O1 and O2)
coherence feature with the other brain regions. Moreover, we also study
individual differences (expert vs. novice) in the classification results. The
analysis revealed that the temporal lobe in experts (T4 and T3) is predominant
for task difficulty classification compared with novices.",arxiv
http://arxiv.org/abs/2110.12638v1,2021-10-25T04:43:24Z,2021-10-25T04:43:24Z,Deep Learning for UAV-based Object Detection and Tracking: A Survey,"Owing to effective and flexible data acquisition, unmanned aerial vehicle
(UAV) has recently become a hotspot across the fields of computer vision (CV)
and remote sensing (RS). Inspired by recent success of deep learning (DL), many
advanced object detection and tracking approaches have been widely applied to
various UAV-related tasks, such as environmental monitoring, precision
agriculture, traffic management. This paper provides a comprehensive survey on
the research progress and prospects of DL-based UAV object detection and
tracking methods. More specifically, we first outline the challenges,
statistics of existing methods, and provide solutions from the perspectives of
DL-based models in three research topics: object detection from the image,
object detection from the video, and object tracking from the video. Open
datasets related to UAV-dominated object detection and tracking are exhausted,
and four benchmark datasets are employed for performance evaluation using some
state-of-the-art methods. Finally, prospects and considerations for the future
work are discussed and summarized. It is expected that this survey can
facilitate those researchers who come from remote sensing field with an
overview of DL-based UAV object detection and tracking methods, along with some
thoughts on their further developments.",arxiv
http://arxiv.org/abs/1804.00294v1,2018-04-01T13:05:05Z,2018-04-01T13:05:05Z,QoS-Aware Routing in Wireless Networks Using Aerial Vehicles,"The next generation wireless networks need efficient mechanisms for data
dissemination that should support users with better Quality of Service (QoS).
Nevertheless, the existing solutions are unable to handle this demand and
require either network redeployment or replanning. Moreover, this upsurges the
overall operational cost and complexity of the network. This problem can be
addressed by deploying Unmanned Aerial Vehicles (UAVs), which can act as
on-demand relays in next generation wireless networks. In this work, a novel
strategy comprising a series of algorithms based on neural networks is devised,
which resolves the issues related to data dissemination, QoS, capacity, and
coverage. When compared with the existing methods, the proposed approach
demonstrates better outcomes for various parameters, namely, throughput,
message disseminations, service dissemination rate, UAV allocation time, route
acquisition delay, link utilization and signal to noise ratio for end users.
The experimental results exhibit the fact that the proposed approach utilizes
39.6%, 41.6%, 43.5%, 44.4%, and 46.9% lesser iterations than the EEDD, A-Star,
OCD, GPCR, and GyTAR, respectively. Therefore, it is evident that the proposed
approach surpasses the existing methods by means of superior performance and
augmented efficiency.",arxiv
http://arxiv.org/abs/1808.00100v2,2018-09-06T14:50:02Z,2018-07-31T22:45:11Z,"WeedMap: A large-scale semantic weed mapping framework using aerial
  multispectral imaging and deep neural network for precision farming","We present a novel weed segmentation and mapping framework that processes
multispectral images obtained from an unmanned aerial vehicle (UAV) using a
deep neural network (DNN). Most studies on crop/weed semantic segmentation only
consider single images for processing and classification. Images taken by UAVs
often cover only a few hundred square meters with either color only or color
and near-infrared (NIR) channels. Computing a single large and accurate
vegetation map (e.g., crop/weed) using a DNN is non-trivial due to difficulties
arising from: (1) limited ground sample distances (GSDs) in high-altitude
datasets, (2) sacrificed resolution resulting from downsampling high-fidelity
images, and (3) multispectral image alignment. To address these issues, we
adopt a stand sliding window approach that operates on only small portions of
multispectral orthomosaic maps (tiles), which are channel-wise aligned and
calibrated radiometrically across the entire map. We define the tile size to be
the same as that of the DNN input to avoid resolution loss. Compared to our
baseline model (i.e., SegNet with 3 channel RGB inputs) yielding an area under
the curve (AUC) of [background=0.607, crop=0.681, weed=0.576], our proposed
model with 9 input channels achieves [0.839, 0.863, 0.782]. Additionally, we
provide an extensive analysis of 20 trained models, both qualitatively and
quantitatively, in order to evaluate the effects of varying input channels and
tunable network hyperparameters. Furthermore, we release a large sugar
beet/weed aerial dataset with expertly guided annotations for further research
in the fields of remote sensing, precision agriculture, and agricultural
robotics.",arxiv
http://arxiv.org/abs/1704.04853v3,2017-11-05T11:31:55Z,2017-04-17T03:14:18Z,"Differential Evolution and Bayesian Optimisation for Hyper-Parameter
  Selection in Mixed-Signal Neuromorphic Circuits Applied to UAV Obstacle
  Avoidance","The Lobula Giant Movement Detector (LGMD) is a an identified neuron of the
locust that detects looming objects and triggers its escape responses.
Understanding the neural principles and networks that lead to these fast and
robust responses can lead to the design of efficient facilitate obstacle
avoidance strategies in robotic applications. Here we present a neuromorphic
spiking neural network model of the LGMD driven by the output of a neuromorphic
Dynamic Vision Sensor (DVS), which has been optimised to produce robust and
reliable responses in the face of the constraints and variability of its mixed
signal analogue-digital circuits. As this LGMD model has many parameters, we
use the Differential Evolution (DE) algorithm to optimise its parameter space.
We also investigate the use of Self-Adaptive Differential Evolution (SADE)
which has been shown to ameliorate the difficulties of finding appropriate
input parameters for DE. We explore the use of two biological mechanisms:
synaptic plasticity and membrane adaptivity in the LGMD. We apply DE and SADE
to find parameters best suited for an obstacle avoidance system on an unmanned
aerial vehicle (UAV), and show how it outperforms state-of-the-art Bayesian
optimisation used for comparison.",arxiv
http://arxiv.org/abs/1807.06789v1,2018-07-18T06:30:54Z,2018-07-18T06:30:54Z,"DroNet: Efficient convolutional neural network detector for real-time
  UAV applications","Unmanned Aerial Vehicles (drones) are emerging as a promising technology for
both environmental and infrastructure monitoring, with broad use in a plethora
of applications. Many such applications require the use of computer vision
algorithms in order to analyse the information captured from an on-board
camera. Such applications include detecting vehicles for emergency response and
traffic monitoring. This paper therefore, explores the trade-offs involved in
the development of a single-shot object detector based on deep convolutional
neural networks (CNNs) that can enable UAVs to perform vehicle detection under
a resource constrained environment such as in a UAV. The paper presents a
holistic approach for designing such systems; the data collection and training
stages, the CNN architecture, and the optimizations necessary to efficiently
map such a CNN on a lightweight embedded processing platform suitable for
deployment on UAVs. Through the analysis we propose a CNN architecture that is
capable of detecting vehicles from aerial UAV images and can operate between
5-18 frames-per-second for a variety of platforms with an overall accuracy of
~95%. Overall, the proposed architecture is suitable for UAV applications,
utilizing low-power embedded processors that can be deployed on commercial
UAVs.",arxiv
http://arxiv.org/abs/1807.11785v1,2018-07-31T12:17:41Z,2018-07-31T12:17:41Z,Transfer Learning-Based Crack Detection by Autonomous UAVs,"Unmanned Aerial Vehicles (UAVs) have recently shown great performance
collecting visual data through autonomous exploration and mapping in building
inspection. Yet, the number of studies is limited considering the post
processing of the data and its integration with autonomous UAVs. These will
enable huge steps onward into full automation of building inspection. In this
regard, this work presents a decision making tool for revisiting tasks in
visual building inspection by autonomous UAVs. The tool is an implementation of
fine-tuning a pretrained Convolutional Neural Network (CNN) for surface crack
detection. It offers an optional mechanism for task planning of revisiting
pinpoint locations during inspection. It is integrated to a quadrotor UAV
system that can autonomously navigate in GPS-denied environments. The UAV is
equipped with onboard sensors and computers for autonomous localization,
mapping and motion planning. The integrated system is tested through
simulations and real-world experiments. The results show that the system
achieves crack detection and autonomous navigation in GPS-denied environments
for building inspection.",arxiv
http://arxiv.org/abs/1904.11619v1,2019-04-25T23:10:54Z,2019-04-25T23:10:54Z,"Small Target Detection for Search and Rescue Operations using
  Distributed Deep Learning and Synthetic Data Generation","It is important to find the target as soon as possible for search and rescue
operations. Surveillance camera systems and unmanned aerial vehicles (UAVs) are
used to support search and rescue. Automatic object detection is important
because a person cannot monitor multiple surveillance screens simultaneously
for 24 hours. Also, the object is often too small to be recognized by the human
eye on the surveillance screen. This study used UAVs around the Port of Houston
and fixed surveillance cameras to build an automatic target detection system
that supports the US Coast Guard (USCG) to help find targets (e.g., person
overboard). We combined image segmentation, enhancement, and convolution neural
networks to reduce detection time to detect small targets. We compared the
performance between the auto-detection system and the human eye. Our system
detected the target within 8 seconds, but the human eye detected the target
within 25 seconds. Our systems also used synthetic data generation and data
augmentation techniques to improve target detection accuracy. This solution may
help the search and rescue operations of the first responders in a timely
manner.",arxiv
http://arxiv.org/abs/1905.11299v1,2019-05-27T15:32:59Z,2019-05-27T15:32:59Z,"ImgSensingNet: UAV Vision Guided Aerial-Ground Air Quality Sensing
  System","Given the increasingly serious air pollution problem, the monitoring of air
quality index (AQI) in urban areas has drawn considerable attention. This paper
presents ImgSensingNet, a vision guided aerial-ground sensing system, for
fine-grained air quality monitoring and forecasting using the fusion of haze
images taken by the unmanned-aerial-vehicle (UAV) and the AQI data collected by
an on-ground three-dimensional (3D) wireless sensor network (WSN).
Specifically, ImgSensingNet first leverages the computer vision technique to
tell the AQI scale in different regions from the taken haze images, where
haze-relevant features and a deep convolutional neural network (CNN) are
designed for direct learning between haze images and corresponding AQI scale.
Based on the learnt AQI scale, ImgSensingNet determines whether to wake up
on-ground wireless sensors for small-scale AQI monitoring and inference, which
can greatly reduce the energy consumption of the system. An entropy-based model
is employed for accurate real-time AQI inference at unmeasured locations and
future air quality distribution forecasting. We implement and evaluate
ImgSensingNet on two university campuses since Feb. 2018, and has collected
17,630 photos and 2.6 millions of AQI data samples. Experimental results
confirm that ImgSensingNet can achieve higher inference accuracy while greatly
reduce the energy consumption, compared to state-of-the-art AQI monitoring
approaches.",arxiv
http://arxiv.org/abs/1906.00052v1,2019-05-31T20:02:09Z,2019-05-31T20:02:09Z,"Training Detection-Range-Frugal Cooperative Collision Avoidance Models
  for Quadcopters via Neuroevolution","Cooperative autonomous approaches to avoiding collisions among small Unmanned
Aerial Vehicles (UAVs) is central to safe integration of UAVs within the
civilian airspace. One potential online cooperative approach is the concept of
reciprocal actions, where both UAVs take pre-trained mutually coherent actions
that do not require active online coordination (thereby avoiding the
computational burden and risk associated with it). This paper presents a
learning based approach to train such reciprocal maneuvers. Neuroevolution,
which uses evolutionary algorithms to simultaneously optimize the topology and
weights of neural networks, is used as the learning method -- which operates
over a set of sample approach scenarios. Unlike most existing work (that
minimize travel distance, energy or risk), the training process here focuses on
the objective of minimizing the required detection range; this has important
practical implications w.r.t. alleviating the dependency on sophisticated
sensing and their reliability under various environments. A specialized design
of experiments and line search is used to identify the minimum detection range
for each sample scenarios. In order to allow an efficient training process, a
classifier is used to discard actions (without simulating them) where the
controller would fail. The model obtained via neuroevolution is observed to
generalize well to (i.e., successful collision avoidance over) unseen approach
scenarios.",arxiv
http://arxiv.org/abs/1907.01195v1,2019-07-02T06:50:24Z,2019-07-02T06:50:24Z,Kite: Automatic speech recognition for unmanned aerial vehicles,"This paper addresses the problem of building a speech recognition system
attuned to the control of unmanned aerial vehicles (UAVs). Even though UAVs are
becoming widespread, the task of creating voice interfaces for them is largely
unaddressed. To this end, we introduce a multi-modal evaluation dataset for UAV
control, consisting of spoken commands and associated images, which represent
the visual context of what the UAV ""sees"" when the pilot utters the command. We
provide baseline results and address two research directions: (i) how robust
the language models are, given an incomplete list of commands at train time;
(ii) how to incorporate visual information in the language model. We find that
recurrent neural networks (RNNs) are a solution to both tasks: they can be
successfully adapted using a small number of commands and they can be extended
to use visual cues. Our results show that the image-based RNN outperforms its
text-only counterpart even if the command-image training associations are
automatically generated and inherently imperfect. The dataset and our code are
available at http://kite.speed.pub.ro.",arxiv
http://arxiv.org/abs/1907.07319v1,2019-07-17T04:06:17Z,2019-07-17T04:06:17Z,"Half a Percent of Labels is Enough: Efficient Animal Detection in UAV
  Imagery using Deep CNNs and Active Learning","We present an Active Learning (AL) strategy for re-using a deep Convolutional
Neural Network (CNN)-based object detector on a new dataset. This is of
particular interest for wildlife conservation: given a set of images acquired
with an Unmanned Aerial Vehicle (UAV) and manually labeled gound truth, our
goal is to train an animal detector that can be re-used for repeated
acquisitions, e.g. in follow-up years. Domain shifts between datasets typically
prevent such a direct model application. We thus propose to bridge this gap
using AL and introduce a new criterion called Transfer Sampling (TS). TS uses
Optimal Transport to find corresponding regions between the source and the
target datasets in the space of CNN activations. The CNN scores in the source
dataset are used to rank the samples according to their likelihood of being
animals, and this ranking is transferred to the target dataset. Unlike
conventional AL criteria that exploit model uncertainty, TS focuses on very
confident samples, thus allowing a quick retrieval of true positives in the
target dataset, where positives are typically extremely rare and difficult to
find by visual inspection. We extend TS with a new window cropping strategy
that further accelerates sample retrieval. Our experiments show that with both
strategies combined, less than half a percent of oracle-provided labels are
enough to find almost 80% of the animals in challenging sets of UAV images,
beating all baselines by a margin.",arxiv
http://arxiv.org/abs/2003.02649v2,2020-08-12T15:21:49Z,2020-03-02T21:36:55Z,"An Audio-Based Fault Diagnosis Method for Quadrotors Using Convolutional
  Neural Network and Transfer Learning","Quadrotor unmanned aerial vehicles (UAVs) have been developed and applied
into several types of workplaces, such as warehouses, which usually involve
human workers. The co-existence of human and UAVs brings new challenges to
UAVs: potential failure of UAVs may cause risk and danger to surrounding human.
Effective and efficient detection of such failure may provide early warning to
the surrounding human workers and reduce such risk to human beings as much as
possible. One of the commonest reasons that cause the failure of the UAV's
flight is the physical damage to the propellers. This paper presents a method
to detect the propellers' damage only based on the audio noise caused by the
UAV's flight. The diagnostic model is developed based on convolutional neural
network (CNN) and transfer learning techniques. The audio data is collected
from the UAVs in real time, transformed into the time-frequency spectrogram,
and used to train the CNN-based diagnostic model. The developed model is able
to detect the abnormal features of the spectrogram and thus the physical damage
of the propellers. To reduce the data dependence on the UAV's dynamic models
and enable the utilization of the training data from UAVs with different
dynamic models, the CNN-based diagnostic model is further augmented by transfer
learning. As such, the refinement of the well-trained diagnostic model ground
on other UAVs only requires a small amount of UAV's training data. Experimental
tests are conducted to validate the diagnostic model with an accuracy of higher
than 90%.",arxiv
http://arxiv.org/abs/2007.12004v1,2020-07-23T13:32:47Z,2020-07-23T13:32:47Z,"Federated Learning in the Sky: Aerial-Ground Air Quality Sensing
  Framework with UAV Swarms","Due to air quality significantly affects human health, it is becoming
increasingly important to accurately and timely predict the Air Quality Index
(AQI). To this end, this paper proposes a new federated learning-based
aerial-ground air quality sensing framework for fine-grained 3D air quality
monitoring and forecasting. Specifically, in the air, this framework leverages
a light-weight Dense-MobileNet model to achieve energy-efficient end-to-end
learning from haze features of haze images taken by Unmanned Aerial Vehicles
(UAVs) for predicting AQI scale distribution. Furthermore, the Federated
Learning Framework not only allows various organizations or institutions to
collaboratively learn a well-trained global model to monitor AQI without
compromising privacy, but also expands the scope of UAV swarms monitoring. For
ground sensing systems, we propose a Graph Convolutional neural network-based
Long Short-Term Memory (GC-LSTM) model to achieve accurate, real-time and
future AQI inference. The GC-LSTM model utilizes the topological structure of
the ground monitoring station to capture the spatio-temporal correlation of
historical observation data, which helps the aerial-ground sensing system to
achieve accurate AQI inference. Through extensive case studies on a real-world
dataset, numerical results show that the proposed framework can achieve
accurate and energy-efficient AQI sensing without compromising the privacy of
raw data.",arxiv
http://arxiv.org/abs/2008.05168v1,2020-08-12T08:33:51Z,2020-08-12T08:33:51Z,"Caching Placement and Resource Allocation for Cache-Enabling UAV NOMA
  Networks","This article investigates the cache-enabling unmanned aerial vehicle (UAV)
cellular networks with massive access capability supported by non-orthogonal
multiple access (NOMA). The delivery of a large volume of multimedia contents
for ground users is assisted by a mobile UAV base station, which caches some
popular contents for wireless backhaul link traffic offloading. In
cache-enabling UAV NOMA networks, the caching placement of content caching
phase and radio resource allocation of content delivery phase are crucial for
network performance. To cope with the dynamic UAV locations and content
requests in practical scenarios, we formulate the long-term caching placement
and resource allocation optimization problem for content delivery delay
minimization as a Markov decision process (MDP). The UAV acts as an agent to
take actions for caching placement and resource allocation, which includes the
user scheduling of content requests and the power allocation of NOMA users. In
order to tackle the MDP, we propose a Q-learning based caching placement and
resource allocation algorithm, where the UAV learns and selects action with
\emph{soft ${\varepsilon}$-greedy} strategy to search for the optimal match
between actions and states. Since the action-state table size of Q-learning
grows with the number of states in the dynamic networks, we propose a function
approximation based algorithm with combination of stochastic gradient descent
and deep neural networks, which is suitable for large-scale networks. Finally,
the numerical results show that the proposed algorithms provide considerable
performance compared to benchmark algorithms, and obtain a trade-off between
network performance and calculation complexity.",arxiv
http://arxiv.org/abs/2009.05519v2,2020-09-21T15:39:08Z,2020-09-11T16:42:38Z,"RF-Based Low-SNR Classification of UAVs Using Convolutional Neural
  Networks","This paper investigates the problem of classification of unmanned aerial
vehicles (UAVs) from radio frequency (RF) fingerprints at the low
signal-to-noise ratio (SNR) regime. We use convolutional neural networks (CNNs)
trained with both RF time-series images and the spectrograms of 15 different
off-the-shelf drone controller RF signals. When using time-series signal
images, the CNN extracts features from the signal transient and envelope. As
the SNR decreases, this approach fails dramatically because the information in
the transient is lost in the noise, and the envelope is distorted heavily. In
contrast to time-series representation of the RF signals, with spectrograms, it
is possible to focus only on the desired frequency interval, i.e., 2.4 GHz ISM
band, and filter out any other signal component outside of this band. These
advantages provide a notable performance improvement over the time-series
signals-based methods. To further increase the classification accuracy of the
spectrogram-based CNN, we denoise the spectrogram images by truncating them to
a limited spectral density interval. Creating a single model using spectrogram
images of noisy signals and tuning the CNN model parameters, we achieve a
classification accuracy varying from 92% to 100% for an SNR range from -10 dB
to 30 dB, which significantly outperforms the existing approaches to our best
knowledge.",arxiv
http://arxiv.org/abs/2010.09094v1,2020-10-18T20:22:05Z,2020-10-18T20:22:05Z,"Multi-Agent Reinforcement Learning in NOMA-aided UAV Networks for
  Cellular Offloading","A novel framework is proposed for cellular offloading with the aid of
multiple unmanned aerial vehicles (UAVs), while the non-orthogonal multiple
access (NOMA) technique is employed at each UAV to further improve the spectrum
efficiency of the wireless network. The optimization problem of joint
three-dimensional (3D) trajectory design and power allocation is formulated for
maximizing the throughput. Since ground mobile users are considered as roaming
continuously, the UAVs need to be re-deployed timely based on the movement of
users. In an effort to solve this pertinent dynamic problem, a K-means based
clustering algorithm is first adopted for periodically partitioning users.
Afterward, a mutual deep Q-network (MDQN) algorithm is proposed to jointly
determine the optimal 3D trajectory and power allocation of UAVs. In contrast
to the conventional DQN algorithm, the MDQN algorithm enables the experience of
multi-agent to be input into a shared neural network to shorten the training
time with the assistance of state abstraction. Numerical results demonstrate
that: 1) the proposed MDQN algorithm is capable of converging under minor
constraints and has a faster convergence rate than the conventional DQN
algorithm in the multi-agent case; 2) The achievable sum rate of the NOMA
enhanced UAV network is 23% superior to the case of orthogonal multiple access
(OMA); 3) By designing the optimal 3D trajectory of UAVs with the aid of the
MDON algorithm, the sum rate of the network enjoys 142% and 56% gains than that
of invoking the circular trajectory and the 2D trajectory, respectively.",arxiv
http://arxiv.org/abs/2011.06134v1,2020-11-12T00:38:36Z,2020-11-12T00:38:36Z,"Fast or Slow: An Autonomous Speed Control Approach for UAV-assisted IoT
  Data Collection Networks","Unmanned Aerial Vehicles (UAVs) have been emerging as an effective solution
for IoT data collection networks thanks to their outstanding flexibility,
mobility, and low operation costs. However, due to the limited energy and
uncertainty from the data collection process, speed control is one of the most
important factors to optimize the energy usage efficiency and performance for
UAV collectors. This work aims to develop a novel autonomous speed control
approach to address this issue. To that end, we first formulate the dynamic
speed control task of a UAV as a Markov decision process taking into account
its energy status and location. In this way, the Q-learning algorithm can be
adopted to obtain the optimal speed control policy for the UAV. To further
improve the system performance, we develop an highly-effective deep dueling
double Q-learning algorithm utilizing outstanding features of the deep neural
networks as well as advanced dueling architecture to quickly stabilize the
learning process and obtain the optimal policy. Through simulation results, we
show that our proposed solution can achieve up to 40% greater performance
compared with other conventional methods. Importantly, the simulation results
also reveal significant impacts of UAV's energy and charging time on the system
performance.",arxiv
http://arxiv.org/abs/2011.14776v1,2020-10-18T17:38:48Z,2020-10-18T17:38:48Z,NOMA in UAV-aided cellular offloading: A machine learning approach,"A novel framework is proposed for cellular offloading with the aid of
multiple unmanned aerial vehicles (UAVs), while non-orthogonal multiple access
(NOMA) technique is employed at each UAV to further improve the spectrum
efficiency of the wireless network. The optimization problem of joint
three-dimensional (3D) trajectory design and power allocation is formulated for
maximizing the throughput. In an effort to solve this pertinent dynamic
problem, a K-means based clustering algorithm is first adopted for periodically
partitioning users. Afterward, a mutual deep Q-network (MDQN) algorithm is
proposed to jointly determine the optimal 3D trajectory and power allocation of
UAVs. In contrast to the conventional deep Q-network (DQN) algorithm, the MDQN
algorithm enables the experience of multi-agent to be input into a shared
neural network to shorten the training time with the assistance of state
abstraction. Numerical results demonstrate that: 1) the proposed MDQN algorithm
has a faster convergence rate than the conventional DQN algorithm in the
multi-agent case; 2) The achievable sum rate of the NOMA enhanced UAV network
is $23\%$ superior to the case of orthogonal multiple access (OMA); 3) By
designing the optimal 3D trajectory of UAVs with the aid of the MDON algorithm,
the sum rate of the network enjoys ${142\%}$ and ${56\%}$ gains than that of
invoking the circular trajectory and the 2D trajectory, respectively.",arxiv
http://arxiv.org/abs/2012.09133v2,2021-08-26T15:33:05Z,2020-12-16T18:22:56Z,"Generative Neural Network Channel Modeling for Millimeter-Wave UAV
  Communication","The millimeter wave bands are being increasingly considered for wireless
communication to unmanned aerial vehicles (UAVs). Critical to this undertaking
are statistical channel models that describe the distribution of constituent
parameters in scenarios of interest. This paper presents a general modeling
methodology based on data-training a generative neural network. The proposed
generative model has a two-stage structure that first predicts the link state
(line-of-sight, non-line-of-sight, or outage), and subsequently feeds this
state into a conditional variational autoencoder (VAE) that generates the path
losses, delays, and angles of arrival and departure for all the propagation
paths. The methodology is demonstrated for 28 GHz air-to-ground channels
between UAVs and a cellular system in representative urban environments, with
training datasets produced through ray tracing. The demonstration extends to
both standard base stations (installed at street level and downtilted) as well
as dedicated base stations (mounted on rooftops and uptilted). The proposed
approach is able to capture complex statistical relations in the data and it
significantly outperforms standard 3GPP models, even after refitting the
parameters of those models to the data.",arxiv
http://arxiv.org/abs/2101.03498v1,2021-01-10T08:21:49Z,2021-01-10T08:21:49Z,"Sum-Rate Maximization for UAV-assisted Visible Light Communications
  using NOMA: Swarm Intelligence meets Machine Learning","As the integration of unmanned aerial vehicles (UAVs) into visible light
communications (VLC) can offer many benefits for massive-connectivity
applications and services in 5G and beyond, this work considers a UAV-assisted
VLC using non-orthogonal multiple-access. More specifically, we formulate a
joint problem of power allocation and UAV's placement to maximize the sum rate
of all users, subject to constraints on power allocation, quality of service of
users, and UAV's position. Since the problem is non-convex and NP-hard in
general, it is difficult to be solved optimally. Moreover, the problem is not
easy to be solved by conventional approaches, e.g., coordinate descent
algorithms, due to channel modeling in VLC. Therefore, we propose using harris
hawks optimization (HHO) algorithm to solve the formulated problem and obtain
an efficient solution. We then use the HHO algorithm together with artificial
neural networks to propose a design which can be used in real-time applications
and avoid falling into the ""local minima"" trap in conventional trainers.
Numerical results are provided to verify the effectiveness of the proposed
algorithm and further demonstrate that the proposed algorithm/HHO trainer is
superior to several alternative schemes and existing metaheuristic algorithms.",arxiv
http://arxiv.org/abs/2102.02318v1,2021-02-03T22:45:09Z,2021-02-03T22:45:09Z,"System Intelligence for UAV-Based Mission Critical with Challenging
  5G/B5G Connectivity","Unmanned aerial vehicles (UAVs) and communication systems are fundamental
elements in Mission Critical services, such as search and rescue. In this
article, we introduce an architecture for managing and orchestrating 5G and
beyond networks that operate over a heterogeneous infrastructure with UAVs'
aid. UAVs are used for collecting and processing data, as well as improving
communications. The proposed System Intelligence (SI) architecture was designed
to comply with recent standardization works, especially the ETSI Experiential
Networked Intelligence specifications. Another contribution of this article is
an evaluation using a testbed based on a virtualized non-standalone 5G core and
a 4G Radio Access Network (RAN) implemented with open-source software. The
experimental results indicate, for instance, that SI can substantially improve
the latency of UAV-based services by splitting deep neural networks between UAV
and edge or cloud equipment. Other experiments explore the slicing of RAN
resources and efficient placement of virtual network functions to assess the
benefits of incorporating intelligence in UAV-based mission-critical services.",arxiv
http://arxiv.org/abs/2102.08768v1,2021-02-06T18:33:26Z,2021-02-06T18:33:26Z,"Heuristic Algorithms for Co-scheduling of Edge Analytics and Routes for
  UAV Fleet Missions","Unmanned Aerial Vehicles (UAVs) or drones are increasingly used for urban
applications like traffic monitoring and construction surveys. Autonomous
navigation allows drones to visit waypoints and accomplish activities as part
of their mission. A common activity is to hover and observe a location using
on-board cameras. Advances in Deep Neural Networks (DNNs) allow such videos to
be analyzed for automated decision making. UAVs also host edge computing
capability for on-board inferencing by such DNNs. To this end, for a fleet of
drones, we propose a novel Mission Scheduling Problem (MSP) that co-schedules
the flight routes to visit and record video at waypoints, and their subsequent
on-board edge analytics. The proposed schedule maximizes the utility from the
activities while meeting activity deadlines as well as energy and computing
constraints. We first prove that MSP is NP-hard and then optimally solve it by
formulating a mixed integer linear programming (MILP) problem. Next, we design
two efficient heuristic algorithms, JSC and VRC, that provide fast sub-optimal
solutions. Evaluation of these three schedulers using real drone traces
demonstrate utility-runtime trade-offs under diverse workloads.",arxiv
http://arxiv.org/abs/2102.13253v1,2021-02-26T01:31:28Z,2021-02-26T01:31:28Z,"On the Visual-based Safe Landing of UAVs in Populated Areas: a Crucial
  Aspect for Urban Deployment","Autonomous landing of Unmanned Aerial Vehicles (UAVs) in crowded scenarios is
crucial for successful deployment of UAVs in populated areas, particularly in
emergency landing situations where the highest priority is to avoid hurting
people. In this work, a new visual-based algorithm for identifying Safe Landing
Zones (SLZ) in crowded scenarios is proposed, considering a camera mounted on
an UAV, where the people in the scene move with unknown dynamics. To do so, a
density map is generated for each image frame using a Deep Neural Network, from
where a binary occupancy map is obtained aiming to overestimate the people's
location for security reasons. Then, the occupancy map is projected to the
head's plane, and the SLZ candidates are obtained as circular regions in the
head's plane with a minimum security radius. Finally, to keep track of the SLZ
candidates, a multiple instance tracking algorithm is implemented using Kalman
Filters along with the Hungarian algorithm for data association. Several
scenarios were studied to prove the validity of the proposed strategy,
including public datasets and real uncontrolled scenarios with people moving in
public squares, taken from an UAV in flight. The study showed promising results
in the search of preventing the UAV from hurting people during emergency
landing.",arxiv
http://arxiv.org/abs/2104.06781v1,2021-04-14T11:12:04Z,2021-04-14T11:12:04Z,"Context-Dependent Anomaly Detection for Low Altitude Traffic
  Surveillance","The detection of contextual anomalies is a challenging task for surveillance
since an observation can be considered anomalous or normal in a specific
environmental context. An unmanned aerial vehicle (UAV) can utilize its aerial
monitoring capability and employ multiple sensors to gather contextual
information about the environment and perform contextual anomaly detection. In
this work, we introduce a deep neural network-based method (CADNet) to find
point anomalies (i.e., single instance anomalous data) and contextual anomalies
(i.e., context-specific abnormality) in an environment using a UAV. The method
is based on a variational autoencoder (VAE) with a context sub-network. The
context sub-network extracts contextual information regarding the environment
using GPS and time data, then feeds it to the VAE to predict anomalies
conditioned on the context. To the best of our knowledge, our method is the
first contextual anomaly detection method for UAV-assisted aerial surveillance.
We evaluate our method on the AU-AIR dataset in a traffic surveillance
scenario. Quantitative comparisons against several baselines demonstrate the
superiority of our approach in the anomaly detection tasks. The codes and data
will be available at https://bozcani.github.io/cadnet.",arxiv
http://arxiv.org/abs/2105.07209v1,2021-05-15T12:01:16Z,2021-05-15T12:01:16Z,Aerial-PASS: Panoramic Annular Scene Segmentation in Drone Videos,"Aerial pixel-wise scene perception of the surrounding environment is an
important task for UAVs (Unmanned Aerial Vehicles). Previous research works
mainly adopt conventional pinhole cameras or fisheye cameras as the imaging
device. However, these imaging systems cannot achieve large Field of View
(FoV), small size, and lightweight at the same time. To this end, we design a
UAV system with a Panoramic Annular Lens (PAL), which has the characteristics
of small size, low weight, and a 360-degree annular FoV. A lightweight
panoramic annular semantic segmentation neural network model is designed to
achieve high-accuracy and real-time scene parsing. In addition, we present the
first drone-perspective panoramic scene segmentation dataset Aerial-PASS, with
annotated labels of track, field, and others. A comprehensive variety of
experiments shows that the designed system performs satisfactorily in aerial
panoramic scene parsing. In particular, our proposed model strikes an excellent
trade-off between segmentation performance and inference speed suitable,
validated on both public street-scene and our established aerial-scene
datasets.",arxiv
http://arxiv.org/abs/2105.08253v1,2021-05-18T03:22:03Z,2021-05-18T03:22:03Z,"Finding a Needle in a Haystack: Tiny Flying Object Detection in 4K
  Videos using a Joint Detection-and-Tracking Approach","Detecting tiny objects in a high-resolution video is challenging because the
visual information is little and unreliable. Specifically, the challenge
includes very low resolution of the objects, MPEG artifacts due to compression
and a large searching area with many hard negatives. Tracking is equally
difficult because of the unreliable appearance, and the unreliable motion
estimation. Luckily, we found that by combining this two challenging tasks
together, there will be mutual benefits. Following the idea, in this paper, we
present a neural network model called the Recurrent Correlational Network,
where detection and tracking are jointly performed over a multi-frame
representation learned through a single, trainable, and end-to-end network. The
framework exploits a convolutional long short-term memory network for learning
informative appearance changes for detection, while the learned representation
is shared in tracking for enhancing its performance. In experiments with
datasets containing images of scenes with small flying objects, such as birds
and unmanned aerial vehicles, the proposed method yielded consistent
improvements in detection performance over deep single-frame detectors and
existing motion-based detectors. Furthermore, our network performs as well as
state-of-the-art generic object trackers when it was evaluated as a tracker on
a bird image dataset.",arxiv
http://arxiv.org/abs/2106.03459v2,2021-10-11T11:00:04Z,2021-06-07T09:40:23Z,"Systematic Online Tuning of Multirotor UAVs for Accurate Trajectory
  Tracking Under Wind Disturbances and In-Flight Dynamics Changes","The demand for accurate and fast trajectory tracking for multirotor Unmanned
Aerial Vehicles (UAVs) have grown recently due to advances in UAV avionics
technology and application domains. In many applications, the multirotor UAV is
required to accurately perform aggressive maneuvers in challenging scenarios
like the presence of external wind disturbances or in-flight payload changes.
In this paper, we propose a systematic controller tuning approach based on
identification results obtained by a recently developed Deep Neural Networks
with the Modified Relay Feedback Test (DNN-MRFT) algorithm. We formulate a
linear equivalent representation suitable for DNN-MRFT using feedback
linearization. This representation enables the analytical investigation of
different controller structures and tuning settings, and captures the
non-linearity trends of the system. With this approach, the trade-off between
performance and robustness in design was made possible which is convenient for
the design of controllers of UAVs operating in uncertain environments. We
demonstrate that our approach is adaptive and robust through a set of
experiments, where accurate trajectory tracking is maintained despite
significant changes to the UAV aerodynamic characteristics and the application
of wind disturbance. Due to the model-based system design, it was possible to
obtain low discrepancy between simulation and experimental results which is
beneficial for potential use of the proposed approach for real-time model-based
planning and fault detection tasks. We obtained RMSE of $3.59 \; cm$ when
tracking aggressive trajectories in the presence of strong wind, which is on
par with state-of-the-art.",arxiv
http://arxiv.org/abs/2106.07299v1,2021-06-14T11:05:53Z,2021-06-14T11:05:53Z,"Dynamic Based Estimator for UAVs with Real-time Identification Using DNN
  and the Modified Relay Feedback Test","Control performance of Unmanned Aerial Vehicles (UAVs) is directly affected
by their ability to estimate their states accurately. With the increasing
popularity of autonomous UAV solutions in real world applications, it is
imperative to develop robust adaptive estimators that can ameliorate sensor
noises in low-cost UAVs. Utilizing the knowledge of UAV dynamics in estimation
can provide significant advantages, but remains challenging due to the complex
and expensive pre-flight experiments required to obtain UAV dynamic parameters.
In this paper, we propose two decoupled dynamic model based Extended Kalman
Filters for UAVs, that provide high rate estimates for position, and velocity
of rotational and translational states, as well as filtered inertial
acceleration. The dynamic model parameters are estimated online using the Deep
Neural Network and Modified Relay Feedback Test (DNN-MRFT) framework, without
requiring any prior knowledge of the UAV physical parameters. The designed
filters with real-time identified process model parameters are tested
experimentally and showed two advantages. Firstly, smooth and lag-free
estimates of the UAV rotational speed and inertial acceleration are obtained,
and used to improve the closed loop system performance, reducing the controller
action by over 6 %. Secondly, the proposed approach enabled the UAV to track
aggressive trajectories with low rate position measurements, a task usually
infeasible under those conditions. The experimental data shows that we achieved
estimation performance matching other methods that requires full knowledge of
the UAV parameters.",arxiv
http://arxiv.org/abs/2107.01581v1,2021-07-04T09:37:45Z,2021-07-04T09:37:45Z,"Unified Identification and Tuning Approach Using Deep Neural Networks
  For Visual Servoing Applications","Vision based control of Unmanned Aerial Vehicles (UAVs) has been adopted by a
wide range of applications due to the availability of low-cost on-board sensors
and computers. Tuning such systems to work properly requires extensive domain
specific experience which limits the growth of emerging applications. Moreover,
obtaining performance limits of UAV based visual servoing with the current
state-of-the-art is not possible due to the complexity of the models used. In
this paper, we present a systematic approach for real-time identification and
tuning of visual servoing systems based on a novel robustified version of the
recent deep neural networks with the modified relay feedback test (DNN-MRFT)
approach. The proposed robust DNN-MRFT algorithm can be used with a multitude
of vision sensors and estimation algorithms despite the high levels of sensor's
noise. Sensitivity of MRFT to perturbations is investigated and its effect on
identification and tuning performance is analyzed. DNN-MRFT was able to detect
performance changes due to the use of slower vision sensors, or due to the
integration of accelerometer measurements. Experimental identification results
were closely matching simulation results, which can be used to explain system
behaviour and anticipate the closed loop performance limits given a certain
hardware and software setup. Finally, we demonstrate the capability of the
DNN-MRFT tuned visual servoing systems to reject external disturbances. Some
advantages of the suggested robust identification approach compared to existing
visual servoing design approaches are presented.",arxiv
http://arxiv.org/abs/2107.06151v1,2021-07-13T14:56:22Z,2021-07-13T14:56:22Z,"Adaptive dynamic programming-based adaptive-gain sliding mode tracking
  control for fixed-wing UAV with disturbances","This paper proposes an adaptive dynamic programming-based adaptive-gain
sliding mode control (ADP-ASMC) scheme for a fixed-wing unmanned aerial vehicle
(UAV) with matched and unmatched disturbances. Starting from the dynamic of
fixed-wing UAV, the control-oriented model composed of attitude subsystem and
airspeed subsystem is established. According to the different issues in two
subsystems, two novel adaptive-gain generalized super-twisting (AGST)
algorithms are developed to eliminate the effects of disturbances in two
subsystems and make the system trajectories tend to the designed integral
sliding manifolds (ISMs) in finite time. Then, based on the expected equivalent
sliding-mode dynamics, the modified adaptive dynamic programming (ADP) approach
with actor-critic (AC) structure is utilized to generate the nearly optimal
control laws and achieve the nearly optimal performance of the sliding-mode
dynamics. Furthermore, through the Lyapunov stability theorem, the tracking
errors and the weight estimation errors of two neural networks (NNs) are all
uniformly ultimately bounded (UUB). Finally, comparative simulations
demonstrate the superior performance of the proposed control scheme for the
fixed-wing UAV.",arxiv
http://arxiv.org/abs/2107.14389v1,2021-07-30T01:37:24Z,2021-07-30T01:37:24Z,DarkLighter: Light Up the Darkness for UAV Tracking,"Recent years have witnessed the fast evolution and promising performance of
the convolutional neural network (CNN)-based trackers, which aim at imitating
biological visual systems. However, current CNN-based trackers can hardly
generalize well to low-light scenes that are commonly lacked in the existing
training set. In indistinguishable night scenarios frequently encountered in
unmanned aerial vehicle (UAV) tracking-based applications, the robustness of
the state-of-the-art (SOTA) trackers drops significantly. To facilitate aerial
tracking in the dark through a general fashion, this work proposes a low-light
image enhancer namely DarkLighter, which dedicates to alleviate the impact of
poor illumination and noise iteratively. A lightweight map estimation network,
i.e., ME-Net, is trained to efficiently estimate illumination maps and noise
maps jointly. Experiments are conducted with several SOTA trackers on numerous
UAV dark tracking scenes. Exhaustive evaluations demonstrate the reliability
and universality of DarkLighter, with high efficiency. Moreover, DarkLighter
has further been implemented on a typical UAV system. Real-world tests at night
scenes have verified its practicability and dependability.",arxiv
http://arxiv.org/abs/2110.01930v1,2021-10-05T10:43:10Z,2021-10-05T10:43:10Z,CNN-based Human Detection for UAVs in Search and Rescue,"The use of Unmanned Aerial Vehicles (UAVs) as a substitute for ordinary
vehicles in applications of search and rescue is being studied all over the
world due to its flexible mobility and less obstruction, including two main
tasks: search and rescue. This paper proposes an approach for the first task of
searching and detecting victims using a type of convolutional neural network
technique, the Single Shot Detector (SSD) model, with the Quadcopter hardware
platform, a type of UAVs. The model used in the research is a pre-trained model
and is applied to test on a Raspberry Pi model B, which is attached on a
Quadcopter, while a single camera is equipped at the bottom of the Quadcopter
to look from above for search and detection. The Quadcopter in this research is
a DIY hardware model that uses accelerometer and gyroscope sensors and
ultrasonic sensor as the essential components for balancing control, however,
these sensors are susceptible to noise caused by the driving forces on the
model, such as the vibration of the motors, therefore, the issues about the PID
controller, noise processing for the sensors are also mentioned in the paper.
Experimental results proved that the Quadcopter is able to stably flight and
the SSD model works well on the Raspberry Pi model B with a processing speed of
3 fps and produces the best detection results at the distance of 1 to 20 meters
to objects.",arxiv
http://arxiv.org/abs/1909.07707v1,2019-09-17T10:41:40Z,2019-09-17T10:41:40Z,"A Review of Tracking, Prediction and Decision Making Methods for
  Autonomous Driving","This literature review focuses on three important aspects of an autonomous
car system: tracking (assessing the identity of the actors such as cars,
pedestrians or obstacles in a sequence of observations), prediction (predicting
the future motion of surrounding vehicles in order to navigate through various
traffic scenarios) and decision making (analyzing the available actions of the
ego car and their consequences to the entire driving context). For tracking and
prediction, approaches based on (deep) neural networks and other, especially
stochastic techniques, are reported. For decision making, deep reinforcement
learning algorithms are presented, together with methods used to explore
different alternative actions, such as Monte Carlo Tree Search.",arxiv
http://arxiv.org/abs/2106.11379v1,2021-06-21T19:27:16Z,2021-06-21T19:27:16Z,BEyond observation: an approach for ObjectNav,"With the rise of automation, unmanned vehicles became a hot topic both as
commercial products and as a scientific research topic. It composes a
multi-disciplinary field of robotics that encompasses embedded systems, control
theory, path planning, Simultaneous Localization and Mapping (SLAM), scene
reconstruction, and pattern recognition. In this work, we present our
exploratory research of how sensor data fusion and state-of-the-art machine
learning algorithms can perform the Embodied Artificial Intelligence (E-AI)
task called Visual Semantic Navigation. This task, a.k.a Object-Goal Navigation
(ObjectNav) consists of autonomous navigation using egocentric visual
observations to reach an object belonging to the target semantic class without
prior knowledge of the environment. Our method reached fourth place on the
Habitat Challenge 2021 ObjectNav on the Minival phase and the Test-Standard
Phase.",arxiv
http://arxiv.org/abs/1405.1124v1,2014-05-06T02:05:04Z,2014-05-06T02:05:04Z,"An ASP-Based Architecture for Autonomous UAVs in Dynamic Environments:
  Progress Report","Traditional AI reasoning techniques have been used successfully in many
domains, including logistics, scheduling and game playing. This paper is part
of a project aimed at investigating how such techniques can be extended to
coordinate teams of unmanned aerial vehicles (UAVs) in dynamic environments.
Specifically challenging are real-world environments where UAVs and other
network-enabled devices must communicate to coordinate---and communication
actions are neither reliable nor free. Such network-centric environments are
common in military, public safety and commercial applications, yet most
research (even multi-agent planning) usually takes communications among
distributed agents as a given. We address this challenge by developing an agent
architecture and reasoning algorithms based on Answer Set Programming (ASP).
ASP has been chosen for this task because it enables high flexibility of
representation, both of knowledge and of reasoning tasks. Although ASP has been
used successfully in a number of applications, and ASP-based architectures have
been studied for about a decade, to the best of our knowledge this is the first
practical application of a complete ASP-based agent architecture. It is also
the first practical application of ASP involving a combination of centralized
reasoning, decentralized reasoning, execution monitoring, and reasoning about
network communications. This work has been empirically validated using a
distributed network-centric software evaluation testbed and the results provide
guidance to designers in how to understand and control intelligent systems that
operate in these environments.",arxiv
http://arxiv.org/abs/1405.5443v1,2014-05-21T14:55:12Z,2014-05-21T14:55:12Z,"Towards an ASP-Based Architecture for Autonomous UAVs in Dynamic
  Environments (Extended Abstract)","Traditional AI reasoning techniques have been used successfully in many
domains, including logistics, scheduling and game playing. This paper is part
of a project aimed at investigating how such techniques can be extended to
coordinate teams of unmanned aerial vehicles (UAVs) in dynamic environments.
Specifically challenging are real-world environments where UAVs and other
network-enabled devices must communicate to coordinate -- and communication
actions are neither reliable nor free. Such network-centric environments are
common in military, public safety and commercial applications, yet most
research (even multi-agent planning) usually takes communications among
distributed agents as a given. We address this challenge by developing an agent
architecture and reasoning algorithms based on Answer Set Programming (ASP).
Although ASP has been used successfully in a number of applications, to the
best of our knowledge this is the first practical application of a complete
ASP-based agent architecture. It is also the first practical application of ASP
involving a combination of centralized reasoning, decentralized reasoning,
execution monitoring, and reasoning about network communications.",arxiv
http://arxiv.org/abs/2004.13351v1,2020-04-28T08:04:06Z,2020-04-28T08:04:06Z,Communication-Efficient Edge AI Inference Over Wireless Networks,"Given the fast growth of intelligent devices, it is expected that a large
number of high-stake artificial intelligence (AI) applications, e.g., drones,
autonomous cars, tactile robots, will be deployed at the edge of wireless
networks in the near future. As such, the intelligent communication networks
will be designed to leverage advanced wireless techniques and edge computing
technologies to support AI-enabled applications at various end devices with
limited communication, computation, hardware and energy resources. In this
article, we shall present the principles of efficient deployment of model
inference at network edge to provide low-latency and energy-efficient AI
services. This includes the wireless distributed computing framework for
low-latency device distributed model inference as well as the wireless
cooperative transmission strategy for energy-efficient edge cooperative model
inference. The communication efficiency of edge inference systems is further
improved by building up a smart radio propagation environment via intelligent
reflecting surface.",arxiv
http://arxiv.org/abs/2003.01347v1,2020-03-03T06:02:30Z,2020-03-03T06:02:30Z,"Single photonic perceptron based on a soliton crystal Kerr microcomb for
  high-speed, scalable, optical neural networks","Optical artificial neural networks (ONNs), analog computing hardware tailored
for machine learning, have significant potential for ultra-high computing speed
and energy efficiency. We propose a new approach to architectures for ONNs
based on integrated Kerr micro-comb sources that is programmable, highly
scalable and capable of reaching ultra-high speeds. We experimentally
demonstrate the building block of the ONN, a single neuron perceptron, by
mapping synapses onto 49 wavelengths of a micro-comb to achieve a high
single-unit throughput of 11.9 Giga-FLOPS at 8 bits per FLOP, corresponding to
95.2 Gbps. We test the perceptron on simple standard benchmark datasets,
handwritten-digit recognition and cancer-cell detection, achieving over 90% and
85% accuracy, respectively. This performance is a direct result of the record
small wavelength spacing (49GHz) for a coherent integrated microcomb source,
which results in an unprecedented number of wavelengths for neuromorphic
optics. Finally, we propose an approach to scaling the perceptron to a deep
learning network using the same single micro-comb device and standard
off-the-shelf telecommunications technology, for high-throughput operation
involving full matrix multiplication for applications such as real-time massive
data processing for unmanned vehicle and aircraft tracking.",arxiv
http://arxiv.org/abs/2110.13484v1,2021-10-26T08:26:55Z,2021-10-26T08:26:55Z,"Applications of Multi-Agent Reinforcement Learning in Future Internet: A
  Comprehensive Survey","Future Internet involves several emerging technologies such as 5G and beyond
5G networks, vehicular networks, unmanned aerial vehicle (UAV) networks, and
Internet of Things (IoTs). Moreover, future Internet becomes heterogeneous and
decentralized with a large number of involved network entities. Each entity may
need to make its local decision to improve the network performance under
dynamic and uncertain network environments. Standard learning algorithms such
as single-agent Reinforcement Learning (RL) or Deep Reinforcement Learning
(DRL) have been recently used to enable each network entity as an agent to
learn an optimal decision-making policy adaptively through interacting with the
unknown environments. However, such an algorithm fails to model the
cooperations or competitions among network entities, and simply treats other
entities as a part of the environment that may result in the non-stationarity
issue. Multi-agent Reinforcement Learning (MARL) allows each network entity to
learn its optimal policy by observing not only the environments, but also other
entities' policies. As a result, MARL can significantly improve the learning
efficiency of the network entities, and it has been recently used to solve
various issues in the emerging networks. In this paper, we thus review the
applications of MARL in the emerging networks. In particular, we provide a
tutorial of MARL and a comprehensive survey of applications of MARL in next
generation Internet. In particular, we first introduce single-agent RL and
MARL. Then, we review a number of applications of MARL to solve emerging issues
in future Internet. The issues consist of network access, transmit power
control, computation offloading, content caching, packet routing, trajectory
design for UAV-aided networks, and network security issues.",arxiv
http://arxiv.org/abs/2109.06628v1,2021-09-10T19:06:37Z,2021-09-10T19:06:37Z,Open-World Active Learning with Stacking Ensemble for Self-Driving Cars,"The environments, in which autonomous cars act, are high-risky, dynamic, and
full of uncertainty, demanding a continuous update of their sensory information
and knowledge bases. The frequency of facing an unknown object is too high
making hard the usage of Artificial Intelligence (AI) classical classification
models that usually rely on the close-world assumption. This problem of
classifying objects in this domain is better faced with and open-world AI
approach. We propose an algorithm to identify not only all the known entities
that may appear in front of the car, but also to detect and learn the classes
of those unknown objects that may be rare to stand on an highway (e.g., a lost
box from a truck). Our approach relies on the DOC algorithm from Lei Shu et.
al. as well as on the Query-by-Committee algorithm.",arxiv
http://arxiv.org/abs/2010.12461v3,2021-06-03T11:38:05Z,2020-10-23T14:59:30Z,"Multi-UAV Path Planning for Wireless Data Harvesting with Deep
  Reinforcement Learning","Harvesting data from distributed Internet of Things (IoT) devices with
multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem
requiring flexible path planning methods. We propose a multi-agent
reinforcement learning (MARL) approach that, in contrast to previous work, can
adapt to profound changes in the scenario parameters defining the data
harvesting mission, such as the number of deployed UAVs, number, position and
data amount of IoT devices, or the maximum flying time, without the need to
perform expensive recomputations or relearn control policies. We formulate the
path planning problem for a cooperative, non-communicating, and homogeneous
team of UAVs tasked with maximizing collected data from distributed IoT sensor
nodes subject to flying time and collision avoidance constraints. The path
planning problem is translated into a decentralized partially observable Markov
decision process (Dec-POMDP), which we solve through a deep reinforcement
learning (DRL) approach, approximating the optimal UAV control policy without
prior knowledge of the challenging wireless channel characteristics in dense
urban environments. By exploiting a combination of centered global and local
map representations of the environment that are fed into convolutional layers
of the agents, we show that our proposed network architecture enables the
agents to cooperate effectively by carefully dividing the data collection task
among themselves, adapt to large complex environments and state spaces, and
make movement decisions that balance data collection goals, flight-time
efficiency, and navigation constraints. Finally, learning a control policy that
generalizes over the scenario parameter space enables us to analyze the
influence of individual parameters on collection performance and provide some
intuition about system-level benefits.",arxiv
http://arxiv.org/abs/1806.01368v1,2018-06-04T20:17:40Z,2018-06-04T20:17:40Z,"Adversarial Reinforcement Learning Framework for Benchmarking Collision
  Avoidance Mechanisms in Autonomous Vehicles","With the rapidly growing interest in autonomous navigation, the body of
research on motion planning and collision avoidance techniques has enjoyed an
accelerating rate of novel proposals and developments. However, the complexity
of new techniques and their safety requirements render the bulk of current
benchmarking frameworks inadequate, thus leaving the need for efficient
comparison techniques unanswered. This work proposes a novel framework based on
deep reinforcement learning for benchmarking the behavior of collision
avoidance mechanisms under the worst-case scenario of dealing with an optimal
adversarial agent, trained to drive the system into unsafe states. We describe
the architecture and flow of this framework as a benchmarking solution, and
demonstrate its efficacy via a practical case study of comparing the
reliability of two collision avoidance mechanisms in response to intentional
collision attempts.",arxiv
http://arxiv.org/abs/1812.03216v1,2018-12-07T21:05:22Z,2018-12-07T21:05:22Z,"Zero-shot Deep Reinforcement Learning Driving Policy Transfer for
  Autonomous Vehicles based on Robust Control","Although deep reinforcement learning (deep RL) methods have lots of strengths
that are favorable if applied to autonomous driving, real deep RL applications
in autonomous driving have been slowed down by the modeling gap between the
source (training) domain and the target (deployment) domain. Unlike current
policy transfer approaches, which generally limit to the usage of
uninterpretable neural network representations as the transferred features, we
propose to transfer concrete kinematic quantities in autonomous driving. The
proposed robust-control-based (RC) generic transfer architecture, which we call
RL-RC, incorporates a transferable hierarchical RL trajectory planner and a
robust tracking controller based on disturbance observer (DOB). The deep RL
policies trained with known nominal dynamics model are transfered directly to
the target domain, DOB-based robust tracking control is applied to tackle the
modeling gap including the vehicle dynamics errors and the external
disturbances such as side forces. We provide simulations validating the
capability of the proposed method to achieve zero-shot transfer across multiple
driving scenarios such as lane keeping, lane changing and obstacle avoidance.",arxiv
http://arxiv.org/abs/1909.06953v2,2020-05-09T08:50:33Z,2019-09-16T02:46:02Z,"Off-road Autonomous Vehicles Traversability Analysis and Trajectory
  Planning Based on Deep Inverse Reinforcement Learning","Terrain traversability analysis is a fundamental issue to achieve the
autonomy of a robot at off-road environments. Geometry-based and
appearance-based methods have been studied in decades, while behavior-based
methods exploiting learning from demonstration (LfD) are new trends.
Behavior-based methods learn cost functions that guide trajectory planning in
compliance with experts' demonstrations, which can be more scalable to various
scenes and driving behaviors. This research proposes a method of off-road
traversability analysis and trajectory planning using Deep Maximum Entropy
Inverse Reinforcement Learning. To incorporate vehicle's kinematics while
solving the problem of exponential increase of state-space complexity, two
convolutional neural networks, i.e., RL ConvNet and Svf ConvNet, are developed
to encode kinematics into convolution kernels and achieve efficient forward
reinforcement learning. We conduct experiments in off-road environments. Scene
maps are generated using 3D LiDAR data, and expert demonstrations are either
the vehicle's real driving trajectories at the scene or synthesized ones to
represent specific behaviors such as crossing negative obstacles. Different
cost functions of traversability analysis are learned and tested at various
scenes of capability in guiding the trajectory planning of different behaviors.
We also demonstrate the performance and computation efficiency of the proposed
method.",arxiv
http://arxiv.org/abs/2104.06506v2,2021-09-24T23:05:32Z,2021-03-06T14:01:29Z,"SAINT-ACC: Safety-Aware Intelligent Adaptive Cruise Control for
  Autonomous Vehicles Using Deep Reinforcement Learning","We present a novel adaptive cruise control (ACC) system namely SAINT-ACC:
{S}afety-{A}ware {Int}elligent {ACC} system (SAINT-ACC) that is designed to
achieve simultaneous optimization of traffic efficiency, driving safety, and
driving comfort through dynamic adaptation of the inter-vehicle gap based on
deep reinforcement learning (RL). A novel dual RL agent-based approach is
developed to seek and adapt the optimal balance between traffic efficiency and
driving safety/comfort by effectively controlling the driving safety model
parameters and inter-vehicle gap based on macroscopic and microscopic traffic
information collected from dynamically changing and complex traffic
environments. Results obtained through over 12,000 simulation runs with varying
traffic scenarios and penetration rates demonstrate that SAINT-ACC
significantly enhances traffic flow, driving safety and comfort compared with a
state-of-the-art approach.",arxiv
http://arxiv.org/abs/2110.00640v1,2021-10-01T20:32:25Z,2021-10-01T20:32:25Z,"Motion Planning for Autonomous Vehicles in the Presence of Uncertainty
  Using Reinforcement Learning","Motion planning under uncertainty is one of the main challenges in developing
autonomous driving vehicles. In this work, we focus on the uncertainty in
sensing and perception, resulted from a limited field of view, occlusions, and
sensing range. This problem is often tackled by considering hypothetical hidden
objects in occluded areas or beyond the sensing range to guarantee passive
safety. However, this may result in conservative planning and expensive
computation, particularly when numerous hypothetical objects need to be
considered. We propose a reinforcement learning (RL) based solution to manage
uncertainty by optimizing for the worst case outcome. This approach is in
contrast to traditional RL, where the agents try to maximize the average
expected reward. The proposed approach is built on top of the Distributional RL
with its policy optimization maximizing the stochastic outcomes' lower bound.
This modification can be applied to a range of RL algorithms. As a
proof-of-concept, the approach is applied to two different RL algorithms, Soft
Actor-Critic and DQN. The approach is evaluated against two challenging
scenarios of pedestrians crossing with occlusion and curved roads with a
limited field of view. The algorithm is trained and evaluated using the SUMO
traffic simulator. The proposed approach yields much better motion planning
behavior compared to conventional RL algorithms and behaves comparably to
humans driving style.",arxiv
http://arxiv.org/abs/1811.11277v1,2018-11-27T21:53:09Z,2018-11-27T21:53:09Z,"Is it Safe to Drive? An Overview of Factors, Challenges, and Datasets
  for Driveability Assessment in Autonomous Driving","With recent advances in learning algorithms and hardware development,
autonomous cars have shown promise when operating in structured environments
under good driving conditions. However, for complex, cluttered and unseen
environments with high uncertainty, autonomous driving systems still frequently
demonstrate erroneous or unexpected behaviors, that could lead to catastrophic
outcomes. Autonomous vehicles should ideally adapt to driving conditions; while
this can be achieved through multiple routes, it would be beneficial as a first
step to be able to characterize Driveability in some quantified form. To this
end, this paper aims to create a framework for investigating different factors
that can impact driveability. Also, one of the main mechanisms to adapt
autonomous driving systems to any driving condition is to be able to learn and
generalize from representative scenarios. The machine learning algorithms that
currently do so learn predominantly in a supervised manner and consequently
need sufficient data for robust and efficient learning. Therefore, we also
perform a comparative overview of 45 public driving datasets that enable
learning and publish this dataset index at
https://sites.google.com/view/driveability-survey-datasets. Specifically, we
categorize the datasets according to use cases, and highlight the datasets that
capture complicated and hazardous driving conditions which can be better used
for training robust driving models. Furthermore, by discussions of what driving
scenarios are not covered by existing public datasets and what driveability
factors need more investigation and data acquisition, this paper aims to
encourage both targeted dataset collection and the proposal of novel
driveability metrics that enhance the robustness of autonomous cars in adverse
environments.",arxiv
http://arxiv.org/abs/2107.04908v1,2021-07-10T20:51:55Z,2021-07-10T20:51:55Z,Hierarchical Learning Framework for UAV Detection and Identification,"The ubiquity of unmanned aerial vehicles (UAVs) or drones is posing both
security and safety risks to the public as UAVs are now used for cybercrimes.
To mitigate these risks, it is important to have a system that can detect or
identify the presence of an intruding UAV in a restricted environment. In this
work, we propose a radio frequency (RF) based UAV detection and identification
system by exploiting signals emanating from both the UAV and its flight
controller, respectively. While several RF devices (i.e., Bluetooth and WiFi
devices) operate in the same frequency band as UAVs, the proposed framework
utilizes a semi-supervised learning approach for the detection of UAV or UAV's
control signals in the presence of other wireless signals such as Bluetooth and
WiFi. The semi-supervised learning approach uses stacked denoising autoencoder
and local outlier factor algorithms. After the detection of UAV or UAV's
control signals, the signal is decomposed by using Hilbert-Huang transform and
wavelet packet transform to extract features from the time-frequency-energy
domain of the signal. The extracted feature sets are used to train a
three-level hierarchical classifier for identifying the type of signals (i.e.,
UAV or UAV control signal), UAV models, and flight mode of UAV. To demonstrate
the feasibility of the proposed framework, we carried out an outdoor experiment
for data collection using six UAVs, five Bluetooth devices, and two WiFi
devices. The acquired data is called Cardinal RF (CardRF) dataset, and it is
available for public use to foster UAV detection and identification research.",arxiv
http://arxiv.org/abs/1712.05990v1,2017-12-16T17:01:40Z,2017-12-16T17:01:40Z,Using Machine Learning to Enhance Vehicles Traffic in ATN (PRT) Systems,"This paper discusses new techniques to enhance Automated Transit Networks
(ATN, previously called Personal Rapid Transit - PRT) based on Artificial
Intelligence tools. The main direction is improvement of the cooperation of
autonomous modules that use negotiation protocols, following the IoT paradigm.
One of the goals is to increase ATN system throughput by tuning up autonomous
vehicles cooperation. Machine learning (ML) was used to improve algorithms
designed by human programmers. We used ""existing controls"" corresponding to
near-optimal solutions and built refinement models to more accurately relate a
system's dynamics to its performance. A mechanism that mostly influences ATN
performance is Empty Vehicle Management (EVM). The algorithms designed by human
programmers was used: calls to empty vehicles for waiting passengers and
balancing based on reallocation of empty vehicles to achieve better regularity
of their settlement. In this paper we discuss how we can improve these
algorithms (and tune them to current conditions) by using ML to tailor
individual behavioral policies. Using ML techniques was possible because our
algorithm is based on a set of parameters. A number of weights and thresholds
could be tuned up to give better decisions on moving empty vehicles across the
track.",arxiv
http://arxiv.org/abs/1611.05379v1,2016-11-16T17:32:10Z,2016-11-16T17:32:10Z,"PCT and Beyond: Towards a Computational Framework for `Intelligent'
  Communicative Systems","Recent years have witnessed increasing interest in the potential benefits of
`intelligent' autonomous machines such as robots. Honda's Asimo humanoid robot,
iRobot's Roomba robot vacuum cleaner and Google's driverless cars have fired
the imagination of the general public, and social media buzz with speculation
about a utopian world of helpful robot assistants or the coming robot
apocalypse! However, there is a long way to go before autonomous systems reach
the level of capabilities required for even the simplest of tasks involving
human-robot interaction - especially if it involves communicative behaviour
such as speech and language. Of course the field of Artificial Intelligence
(AI) has made great strides in these areas, and has moved on from abstract
high-level rule-based paradigms to embodied architectures whose operations are
grounded in real physical environments. What is still missing, however, is an
overarching theory of intelligent communicative behaviour that informs
system-level design decisions in order to provide a more coherent approach to
system integration. This chapter introduces the beginnings of such a framework
inspired by the principles of Perceptual Control Theory (PCT). In particular,
it is observed that PCT has hitherto tended to view perceptual processes as a
relatively straightforward series of transformations from sensation to
perception, and has overlooked the potential of powerful generative model-based
solutions that have emerged in practical fields such as visual or auditory
scene analysis. Starting from first principles, a sequence of arguments is
presented which not only shows how these ideas might be integrated into PCT,
but which also extend PCT towards a remarkably symmetric architecture for a
needs-driven communicative agent. It is concluded that, if behaviour is the
control of perception, then perception is the simulation of behaviour.",arxiv
http://arxiv.org/abs/1803.09938v1,2018-03-27T07:44:04Z,2018-03-27T07:44:04Z,"Directional Modulation: A Secure Solution to 5G and Beyond Mobile
  Networks","Directional modulation (DM), as an efficient secure transmission way, offers
security through its directive property and is suitable for line-of-propagation
(LoP) channels such as millimeter wave (mmWave) massive multiple-input
multiple-output (MIMO), satellite communication, unmanned aerial vehicle (UAV),
and smart transportation. If the direction angle of the desired received is
known, the desired channel gain vector is obtainable. Thus, in advance, the DM
transmitter knows the values of directional angles of desired user and
eavesdropper, or their direction of arrival (DOAs) because the beamforming
vector of confidential messages and artificial noise (AN) projection matrix is
mainly determined by directional angles of desired user and eavesdropper. For a
DM transceiver, working as a receiver, the first step is to measure the DOAs of
desired user and eavesdropper. Then, in the second step, using the measured
DOAs, the beamforming vector of confidential messages and AN projection matrix
is designed. In this paper, we describe the DOA measurement methods, power
allocation, and beamforming in DM networks. A machine learning-based DOA
measurement method is proposed to make a substantial SR performance gain
compared to single-snapshot measurement without machine learning for a given
null-space projection beamforming scheme. However, for a conventional DM
network, there still exists a serious secure issue: the eavesdropper moves
inside the main beam of the desired user and may intercept the confidential
messages intended to the desired users because the beamforming vector of
confidential messages and AN projection matrix are only angle-dependence. To
address this problem, we present a new concept of secure and precise
transmission, where the transmit waveform has two-dimensional even
three-dimensional dependence by using DM, random frequency selection, and phase
alignment at DM transmitter.",arxiv
http://arxiv.org/abs/1801.05500v1,2018-01-16T22:35:55Z,2018-01-16T22:35:55Z,"Cellular-Connected UAVs over 5G: Deep Reinforcement Learning for
  Interference Management","In this paper, an interference-aware path planning scheme for a network of
cellular-connected unmanned aerial vehicles (UAVs) is proposed. In particular,
each UAV aims at achieving a tradeoff between maximizing energy efficiency and
minimizing both wireless latency and the interference level caused on the
ground network along its path. The problem is cast as a dynamic game among
UAVs. To solve this game, a deep reinforcement learning algorithm, based on
echo state network (ESN) cells, is proposed. The introduced deep ESN
architecture is trained to allow each UAV to map each observation of the
network state to an action, with the goal of minimizing a sequence of
time-dependent utility functions. Each UAV uses ESN to learn its optimal path,
transmission power level, and cell association vector at different locations
along its path. The proposed algorithm is shown to reach a subgame perfect Nash
equilibrium (SPNE) upon convergence. Moreover, an upper and lower bound for the
altitude of the UAVs is derived thus reducing the computational complexity of
the proposed algorithm. Simulation results show that the proposed scheme
achieves better wireless latency per UAV and rate per ground user (UE) while
requiring a number of steps that is comparable to a heuristic baseline that
considers moving via the shortest distance towards the corresponding
destinations. The results also show that the optimal altitude of the UAVs
varies based on the ground network density and the UE data rate requirements
and plays a vital role in minimizing the interference level on the ground UEs
as well as the wireless transmission delay of the UAV.",arxiv
http://arxiv.org/abs/1905.02993v2,2019-08-18T02:57:59Z,2019-05-08T10:14:37Z,"Deep Reinforcement Learning for Minimizing Age-of-Information in
  UAV-assisted Networks","Unmanned aerial vehicles (UAVs) are expected to be a key component of the
next-generation wireless systems. Due to their deployment flexibility, UAVs are
being considered as an efficient solution for collecting information data from
ground nodes and transmitting it wirelessly to the network. In this paper, a
UAV-assisted wireless network is studied, in which energy-constrained ground
nodes are deployed to observe different physical processes. In this network, a
UAV that has a time constraint for its operation due to its limited battery,
moves towards the ground nodes to receive status update packets about their
observed processes. The flight trajectory of the UAV and scheduling of status
update packets are jointly optimized with the objective of achieving the
minimum weighted sum for the age-of-information (AoI) values of different
processes at the UAV, referred to as weighted sum-AoI. The problem is modeled
as a finite-horizon Markov decision process (MDP) with finite state and action
spaces. Since the state space is extremely large, a deep reinforcement learning
(RL) algorithm is proposed to obtain the optimal policy that minimizes the
weighted sum-AoI, referred to as the age-optimal policy. Several simulation
scenarios are considered to showcase the convergence of the proposed deep RL
algorithm. Moreover, the results also demonstrate that the proposed deep RL
approach can significantly improve the achievable sum-AoI per process compared
to the baseline policies, such as the distance-based and random walk policies.
The impact of various system design parameters on the optimal achievable
sum-AoI per process is also shown through extensive simulations.",arxiv
http://arxiv.org/abs/2006.15863v1,2020-06-29T08:23:42Z,2020-06-29T08:23:42Z,"Neural Combinatorial Deep Reinforcement Learning for Age-optimal Joint
  Trajectory and Scheduling Design in UAV-assisted Networks","In this paper, an unmanned aerial vehicle (UAV)-assisted wireless network is
considered in which a battery-constrained UAV is assumed to move towards
energy-constrained ground nodes to receive status updates about their observed
processes. The UAV's flight trajectory and scheduling of status updates are
jointly optimized with the objective of minimizing the normalized weighted sum
of Age of Information (NWAoI) values for different physical processes at the
UAV. The problem is first formulated as a mixed-integer program. Then, for a
given scheduling policy, a convex optimization-based solution is proposed to
derive the UAV's optimal flight trajectory and time instants on updates.
However, finding the optimal scheduling policy is challenging due to the
combinatorial nature of the formulated problem. Therefore, to complement the
proposed convex optimization-based solution, a finite-horizon Markov decision
process (MDP) is used to find the optimal scheduling policy. Since the state
space of the MDP is extremely large, a novel neural combinatorial-based deep
reinforcement learning (NCRL) algorithm using deep Q-network (DQN) is proposed
to obtain the optimal policy. However, for large-scale scenarios with numerous
nodes, the DQN architecture cannot efficiently learn the optimal scheduling
policy anymore. Motivated by this, a long short-term memory (LSTM)-based
autoencoder is proposed to map the state space to a fixed-size vector
representation in such large-scale scenarios. A lower bound on the minimum
NWAoI is analytically derived which provides system design guidelines on the
appropriate choice of importance weights for different nodes. The numerical
results also demonstrate that the proposed NCRL approach can significantly
improve the achievable NWAoI per process compared to the baseline policies,
such as weight-based and discretized state DQN policies.",arxiv
http://arxiv.org/abs/2102.13222v2,2021-10-04T11:27:09Z,2021-02-25T23:08:49Z,"Joint Resource Block and Beamforming Optimization for Cellular-Connected
  UAV Networks: A Hybrid D3QN-DDPG Approach","Integrating unmanned aerial vehicle (UAV) into the existing cellular networks
that are delicately designed for terrestrial transmissions faces lots of
challenges, in which one of the most striking concerns is how to adopt UAV into
the cellular networks with less (or even without) adverse effects to ground
users. In this paper, a cellular-connected UAV network is considered, in which
multiple UAVs receive messages from terrestrial base stations (BSs) in the
down-link, while BSs are serving ground users in their cells. Besides, the
line-of-sight (LoS) wireless links are more likely to be established in
ground-to-air (G2A) transmission scenarios. On one hand, UAVs may potentially
get access to more BSs. On the other hand, more co-channel interferences could
be involved. To enhance wireless transmission quality between UAVs and BSs
while protecting the ground users from being interfered by the G2A
communications, a joint time-frequency resource block (RB) and beamforming
optimization problem is proposed and investigated in this paper. Specifically,
with given flying trajectory, the ergodic outage duration (EOD) of UAV is
minimized with the aid of RB resource allocation and beamforming design.
Unfortunately, the proposed optimization problem is hard to be solved via
standard optimization techniques, if not impossible. To crack this nut, a deep
reinforcement learning (DRL) solution is proposed, where deep double duelling Q
network (D3QN) and deep deterministic policy gradient (DDPG) are invoked to
deal with RB allocation in discrete action domain and beamforming design in
continuous action regime, respectively. The hybrid D3QN-DDPG solution is
applied to solve the outer Markov decision process (MDP) and the inner MDP
interactively so that it can achieve the sub-optimal result for the considered
optimization problem.",arxiv
http://arxiv.org/abs/2108.00354v1,2021-08-01T03:02:11Z,2021-08-01T03:02:11Z,"UAV Trajectory Planning in Wireless Sensor Networks for Energy
  Consumption Minimization by Deep Reinforcement Learning","Unmanned aerial vehicles (UAVs) have emerged as a promising candidate
solution for data collection of large-scale wireless sensor networks (WSNs). In
this paper, we investigate a UAV-aided WSN, where cluster heads (CHs) receive
data from their member nodes, and a UAV is dispatched to collect data from CHs
along the planned trajectory. We aim to minimize the total energy consumption
of the UAV-WSN system in a complete round of data collection. Toward this end,
we formulate the energy consumption minimization problem as a constrained
combinatorial optimization problem by jointly selecting CHs from nodes within
clusters and planning the UAV's visiting order to the selected CHs. The
formulated energy consumption minimization problem is NP-hard, and hence, hard
to solve optimally. In order to tackle this challenge, we propose a novel deep
reinforcement learning (DRL) technique, pointer network-A* (Ptr-A*), which can
efficiently learn from experiences the UAV trajectory policy for minimizing the
energy consumption. The UAV's start point and the WSN with a set of
pre-determined clusters are fed into the Ptr-A*, and the Ptr-A* outputs a group
of CHs and the visiting order to these CHs, i.e., the UAV's trajectory. The
parameters of the Ptr-A* are trained on small-scale clusters problem instances
for faster training by using the actor-critic algorithm in an unsupervised
manner. At inference, three search strategies are also proposed to improve the
quality of solutions. Simulation results show that the trained models based on
20-clusters and 40-clusters have a good generalization ability to solve the
UAV's trajectory planning problem in WSNs with different numbers of clusters,
without the need to retrain the models. Furthermore, the results show that our
proposed DRL algorithm outperforms two baseline techniques.",arxiv
http://arxiv.org/abs/1912.03821v1,2019-12-09T02:33:57Z,2019-12-09T02:33:57Z,"Decentralized Multi-Agent Reinforcement Learning with Networked Agents:
  Recent Advances","Multi-agent reinforcement learning (MARL) has long been a significant and
everlasting research topic in both machine learning and control. With the
recent development of (single-agent) deep RL, there is a resurgence of
interests in developing new MARL algorithms, especially those that are backed
by theoretical analysis. In this paper, we review some recent advances a
sub-area of this topic: decentralized MARL with networked agents. Specifically,
multiple agents perform sequential decision-making in a common environment,
without the coordination of any central controller. Instead, the agents are
allowed to exchange information with their neighbors over a communication
network. Such a setting finds broad applications in the control and operation
of robots, unmanned vehicles, mobile sensor networks, and smart grid. This
review is built upon several our research endeavors in this direction, together
with some progresses made by other researchers along the line. We hope this
review to inspire the devotion of more research efforts to this exciting yet
challenging area.",arxiv
http://arxiv.org/abs/2002.05149v6,2020-07-02T19:03:24Z,2020-02-12T18:50:11Z,Self-explaining AI as an alternative to interpretable AI,"The ability to explain decisions made by AI systems is highly sought after,
especially in domains where human lives are at stake such as medicine or
autonomous vehicles. While it is often possible to approximate the input-output
relations of deep neural networks with a few human-understandable rules, the
discovery of the double descent phenomena suggests that such approximations do
not accurately capture the mechanism by which deep neural networks work. Double
descent indicates that deep neural networks typically operate by smoothly
interpolating between data points rather than by extracting a few high level
rules. As a result, neural networks trained on complex real world data are
inherently hard to interpret and prone to failure if asked to extrapolate. To
show how we might be able to trust AI despite these problems we introduce the
concept of self-explaining AI. Self-explaining AIs are capable of providing a
human-understandable explanation of each decision along with confidence levels
for both the decision and explanation. For this approach to work, it is
important that the explanation actually be related to the decision, ideally
capturing the mechanism used to arrive at the explanation. Finally, we argue it
is important that deep learning based systems include a ""warning light"" based
on techniques from applicability domain analysis to warn the user if a model is
asked to extrapolate outside its training distribution. For a video
presentation of this talk see https://www.youtube.com/watch?v=Py7PVdcu7WY& .",arxiv
http://arxiv.org/abs/1901.08630v1,2019-01-24T20:14:28Z,2019-01-24T20:14:28Z,"Real-time Scene Segmentation Using a Light Deep Neural Network
  Architecture for Autonomous Robot Navigation on Construction Sites","Camera-equipped unmanned vehicles (UVs) have received a lot of attention in
data collection for construction monitoring applications. To develop an
autonomous platform, the UV should be able to process multiple modules (e.g.,
context-awareness, control, localization, and mapping) on an embedded platform.
Pixel-wise semantic segmentation provides a UV with the ability to be
contextually aware of its surrounding environment. However, in the case of
mobile robotic systems with limited computing resources, the large size of the
segmentation model and high memory usage requires high computing resources,
which a major challenge for mobile UVs (e.g., a small-scale vehicle with
limited payload and space). To overcome this challenge, this paper presents a
light and efficient deep neural network architecture to run on an embedded
platform in real-time. The proposed model segments navigable space on an image
sequence (i.e., a video stream), which is essential for an autonomous vehicle
that is based on machine vision. The results demonstrate the performance
efficiency of the proposed architecture compared to the existing models and
suggest possible improvements that could make the model even more efficient,
which is necessary for the future development of the autonomous robotics
systems.",arxiv
http://arxiv.org/abs/1708.00921v1,2017-08-02T20:28:41Z,2017-08-02T20:28:41Z,"Echo State Learning for Wireless Virtual Reality Resource Allocation in
  UAV-enabled LTE-U Networks","In this paper, the problem of resource management is studied for a network of
wireless virtual reality (VR) users communicating using an unmanned aerial
vehicle (UAV)-enabled LTE-U network. In the studied model, the UAVs act as VR
control centers that collect tracking information from the VR users over the
wireless uplink and, then, send the constructed VR images to the VR users over
an LTE-U downlink. Therefore, resource allocation in such a UAV-enabled LTE-U
network must jointly consider the uplink and downlink links over both licensed
and unlicensed bands. In such a VR setting, the UAVs can dynamically adjust the
image quality and format of each VR image to change the data size of each VR
image, then meet the delay requirement. Therefore, resource allocation must
also take into account the image quality and format. This VR-centric resource
allocation problem is formulated as a noncooperative game that enables a joint
allocation of licensed and unlicensed spectrum bands, as well as a dynamic
adaptation of VR image quality and format. To solve this game, a learning
algorithm based on the machine learning tools of echo state networks (ESNs)
with leaky integrator neurons is proposed. Unlike conventional ESN based
learning algorithms that are suitable for discrete-time systems, the proposed
algorithm can dynamically adjust the update speed of the ESN's state and,
hence, it can enable the UAVs to learn the continuous dynamics of their
associated VR users. Simulation results show that the proposed algorithm
achieves up to 14% and 27.1% gains in terms of total VR QoE for all users
compared to Q-learning using LTE-U and Q-learning using LTE.",arxiv
http://arxiv.org/abs/1610.01585v1,2016-10-05T19:41:12Z,2016-10-05T19:41:12Z,"Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned
  Aerial Vehicles for Optimized Quality-of-Experience","In this paper, the problem of proactive deployment of cache-enabled unmanned
aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of
wireless devices in a cloud radio access network (CRAN) is studied. In the
considered model, the network can leverage human-centric information such as
users' visited locations, requested contents, gender, job, and device type to
predict the content request distribution and mobility pattern of each user.
Then, given these behavior predictions, the proposed approach seeks to find the
user-UAV associations, the optimal UAVs' locations, and the contents to cache
at UAVs. This problem is formulated as an optimization problem whose goal is to
maximize the users' QoE while minimizing the transmit power used by the UAVs.
To solve this problem, a novel algorithm based on the machine learning
framework of conceptor-based echo state networks (ESNs) is proposed. Using
ESNs, the network can effectively predict each user's content request
distribution and its mobility pattern when limited information on the states of
users and the network is available. Based on the predictions of the users'
content request distribution and their mobility patterns, we derive the optimal
user-UAV association, optimal locations of the UAVs as well as the content to
cache at UAVs. Simulation results using real pedestrian mobility patterns from
BUPT and actual content transmission data from Youku show that the proposed
algorithm can yield 40% and 61% gains, respectively, in terms of the average
transmit power and the percentage of the users with satisfied QoE compared to a
benchmark algorithm without caching and a benchmark solution without UAVs.",arxiv
http://arxiv.org/abs/1812.07665v2,2019-06-04T09:28:00Z,2018-12-18T22:10:42Z,"Trajectory Design and Power Control for Multi-UAV Assisted Wireless
  Networks: A Machine Learning Approach","A novel framework is proposed for the trajectory design of multiple unmanned
aerial vehicles (UAVs) based on the prediction of users' mobility information.
The problem of joint trajectory design and power control is formulated for
maximizing the instantaneous sum transmit rate while satisfying the rate
requirement of users. In an effort to solve this pertinent problem, a
three-step approach is proposed which is based on machine learning techniques
to obtain both the position information of users and the trajectory design of
UAVs. Firstly, a multi-agent Q-learning based placement algorithm is proposed
for determining the optimal positions of the UAVs based on the initial location
of the users. Secondly, in an effort to determine the mobility information of
users based on a real dataset, their position data is collected from Twitter to
describe the anonymous user-trajectories in the physical world. In the
meantime, an echo state network (ESN) based prediction algorithm is proposed
for predicting the future positions of users based on the real dataset.
Thirdly, a multi-agent Q-learning based algorithm is conceived for predicting
the position of UAVs in each time slot based on the movement of users. In this
algorithm, multiple UAVs act as agents to find optimal actions by interacting
with their environment and learn from their mistakes. Additionally, we also
prove that the proposed multi-agent Q-learning based trajectory design and
power control algorithm can converge under mild conditions. Numerical results
are provided to demonstrate that as the size of the reservoir increases, the
proposed ESN approach improves the prediction accuracy. Finally, we demonstrate
that throughput gains of about 17% are achieved.",arxiv
http://arxiv.org/abs/1901.07703v2,2019-04-10T18:41:28Z,2019-01-23T03:14:21Z,"Micro-UAV Detection and Classification from RF Fingerprints Using
  Machine Learning Techniques","This paper focuses on the detection and classification of micro-unmanned
aerial vehicles (UAVs) using radio frequency (RF) fingerprints of the signals
transmitted from the controller to the micro-UAV. In the detection phase, raw
signals are split into frames and transformed into the wavelet domain. A Markov
models-based naive Bayes approach is used to check for the presence of a UAV in
each frame. In the classification phase, unlike the traditional approaches that
rely solely on time-domain signals and corresponding features, the proposed
technique uses the energy transient signal. This approach is more robust to
noise and can cope with different modulation techniques. First, the normalized
energy trajectory is generated from the energy-time-frequency distribution of
the raw control signal. Next, the start and end points of the energy transient
are detected by searching for the most abrupt changes in the mean of the energy
trajectory. Then, a set of statistical features is extracted from the energy
transient. Significant features are selected by performing neighborhood
component analysis (NCA) to keep the computational cost of the algorithm low.
Finally, selected features are fed to several machine learning algorithms for
classification. The algorithms are evaluated experimentally using a database
containing 100 RF signals from each of 14 different UAV controllers. The
signals are recorded wirelessly using a high-frequency oscilloscope. The data
set is randomly partitioned into training and test sets for validation with the
ratio 4:1. Ten Monte Carlo simulations are run and results are averaged to
assess the performance of the methods. All the micro-UAVs are detected
correctly and an average accuracy of 96.3% is achieved using the k-nearest
neighbor (kNN) classification. Proposed methods are also tested for different
signal-to-noise ratio (SNR) levels and results are reported.",arxiv
http://arxiv.org/abs/1905.06396v2,2019-12-17T21:45:36Z,2019-05-15T19:12:43Z,"Machine Learning-Based Delay-Aware UAV Detection and Operation Mode
  Identification over Encrypted Wi-Fi Traffic","The consumer UAV (unmanned aerial vehicle) market has grown significantly
over the past few years. Despite its huge potential in spurring economic growth
by supporting various applications, the increase of consumer UAVs poses
potential risks to public security and personal privacy. To minimize the risks,
efficiently detecting and identifying invading UAVs is in urgent need for both
invasion detection and forensics purposes. Given the fact that consumer UAVs
are usually used in a civilian environment, existing physical detection methods
(such as radar, vision, and sound) may become ineffective in many scenarios.
Aiming to complement the existing physical detection mechanisms, we propose a
machine learning-based framework for fast UAV identification over encrypted
Wi-Fi traffic. It is motivated by the observation that many consumer UAVs use
Wi-Fi links for control and video streaming. The proposed framework extracts
features derived only from packet size and inter-arrival time of encrypted
Wi-Fi traffic, and can efficiently detect UAVs and identify their operation
modes. In order to reduce the online identification time, our framework adopts
a re-weighted $\ell_1$-norm regularization, which considers the number of
samples and computation cost of different features. This framework jointly
optimizes feature selection and prediction performance in a unified objective
function. To tackle the packet inter-arrival time uncertainty when optimizing
the trade-off between the detection accuracy and delay, we utilize Maximum
Likelihood Estimation (MLE) method to estimate the packet inter-arrival time.
We collect a large number of real-world Wi-Fi data traffic of eight types of
consumer UAVs and conduct extensive evaluation on the performance of our
proposed method.",arxiv
http://arxiv.org/abs/1909.07554v1,2019-09-17T02:22:09Z,2019-09-17T02:22:09Z,"Gated Recurrent Units Learning for Optimal Deployment of Visible Light
  Communications Enabled UAVs","In this paper, the problem of optimizing the deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities is
studied. In the studied model, the UAVs can simultaneously provide
communications and illumination to service ground users. Ambient illumination
increases the interference over VLC links while reducing the illumination
threshold of the UAVs. Therefore, it is necessary to consider the illumination
distribution of the target area for UAV deployment optimization. This problem
is formulated as an optimization problem whose goal is to minimize the total
transmit power while meeting the illumination and communication requirements of
users. To solve this problem, an algorithm based on the machine learning
framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can
model the long-term historical illumination distribution and predict the future
illumination distribution. In order to reduce the complexity of the prediction
algorithm while accurately predicting the illumination distribution, a Gaussian
mixture model (GMM) is used to fit the illumination distribution of the target
area at each time slot. Based on the predicted illumination distribution, the
optimization problem is proved to be a convex optimization problem that can be
solved by using duality. Simulations using real data from the Earth
observations group (EOG) at NOAA/NCEI show that the proposed approach can
achieve up to 22.1% reduction in transmit power compared to a conventional
optimal UAV deployment that does not consider the illumination distribution.
The results also show that UAVs must hover at areas having strong illumination,
thus providing useful guidelines on the deployment of VLC-enabled UAVs.",arxiv
http://arxiv.org/abs/2006.06624v1,2020-06-11T17:22:56Z,2020-06-11T17:22:56Z,"SLIC-UAV: A Method for monitoring recovery in tropical restoration
  projects through identification of signature species using UAVs","Logged forests cover four million square kilometres of the tropics and
restoring these forests is essential if we are to avoid the worst impacts of
climate change, yet monitoring recovery is challenging. Tracking the abundance
of visually identifiable, early-successional species enables successional
status and thereby restoration progress to be evaluated. Here we present a new
pipeline, SLIC-UAV, for processing Unmanned Aerial Vehicle (UAV) imagery to map
early-successional species in tropical forests. The pipeline is novel because
it comprises: (a) a time-efficient approach for labelling crowns from UAV
imagery; (b) machine learning of species based on spectral and textural
features within individual tree crowns, and (c) automatic segmentation of
orthomosaiced UAV imagery into 'superpixels', using Simple Linear Iterative
Clustering (SLIC). Creating superpixels reduces the dataset's dimensionality
and focuses prediction onto clusters of pixels, greatly improving accuracy. To
demonstrate SLIC-UAV, support vector machines and random forests were used to
predict the species of hand-labelled crowns in a restoration concession in
Indonesia. Random forests were most accurate at discriminating species for
whole crowns, with accuracy ranging from 79.3% when mapping five common
species, to 90.5% when mapping the three most visually-distinctive species. In
contrast, support vector machines proved better for labelling automatically
segmented superpixels, with accuracy ranging from 74.3% to 91.7% for the same
species. Models were extended to map species across 100 hectares of forest. The
study demonstrates the power of SLIC-UAV for mapping characteristic
early-successional tree species as an indicator of successional stage within
tropical forest restoration areas. Continued effort is needed to develop
easy-to-implement and low-cost technology to improve the affordability of
project management.",arxiv
http://arxiv.org/abs/2007.06378v1,2020-07-13T13:42:13Z,2020-07-13T13:42:13Z,"Joint Auction-Coalition Formation Framework for Communication-Efficient
  Federated Learning in UAV-Enabled Internet of Vehicles","Due to the advanced capabilities of the Internet of Vehicles (IoV) components
such as vehicles, Roadside Units (RSUs) and smart devices as well as the
increasing amount of data generated, Federated Learning (FL) becomes a
promising tool given that it enables privacy-preserving machine learning that
can be implemented in the IoV. However, the performance of the FL suffers from
the failure of communication links and missing nodes, especially when
continuous exchanges of model parameters are required. Therefore, we propose
the use of Unmanned Aerial Vehicles (UAVs) as wireless relays to facilitate the
communications between the IoV components and the FL server and thus improving
the accuracy of the FL. However, a single UAV may not have sufficient resources
to provide services for all iterations of the FL process. In this paper, we
present a joint auction-coalition formation framework to solve the allocation
of UAV coalitions to groups of IoV components. Specifically, the coalition
formation game is formulated to maximize the sum of individual profits of the
UAVs. The joint auction-coalition formation algorithm is proposed to achieve a
stable partition of UAV coalitions in which an auction scheme is applied to
solve the allocation of UAV coalitions. The auction scheme is designed to take
into account the preferences of IoV components over heterogeneous UAVs. The
simulation results show that the grand coalition, where all UAVs join a single
coalition, is not always stable due to the profit-maximizing behavior of the
UAVs. In addition, we show that as the cooperation cost of the UAVs increases,
the UAVs prefer to support the IoV components independently and not to form any
coalition.",arxiv
http://arxiv.org/abs/1703.04318v1,2017-03-13T10:28:24Z,2017-03-13T10:28:24Z,"Blocking Transferability of Adversarial Examples in Black-Box Learning
  Systems","Advances in Machine Learning (ML) have led to its adoption as an integral
component in many applications, including banking, medical diagnosis, and
driverless cars. To further broaden the use of ML models, cloud-based services
offered by Microsoft, Amazon, Google, and others have developed ML-as-a-service
tools as black-box systems. However, ML classifiers are vulnerable to
adversarial examples: inputs that are maliciously modified can cause the
classifier to provide adversary-desired outputs. Moreover, it is known that
adversarial examples generated on one classifier are likely to cause another
classifier to make the same mistake, even if the classifiers have different
architectures or are trained on disjoint datasets. This property, which is
known as transferability, opens up the possibility of attacking black-box
systems by generating adversarial examples on a substitute classifier and
transferring the examples to the target classifier. Therefore, the key to
protect black-box learning systems against the adversarial examples is to block
their transferability. To this end, we propose a training method that, as the
input is more perturbed, the classifier smoothly outputs lower confidence on
the original label and instead predicts that the input is ""invalid"". In
essence, we augment the output class set with a NULL label and train the
classifier to reject the adversarial examples by classifying them as NULL. In
experiments, we apply a wide range of attacks based on adversarial examples on
the black-box systems. We show that a classifier trained with the proposed
method effectively resists against the adversarial examples, while maintaining
the accuracy on clean data.",arxiv
http://arxiv.org/abs/1804.06760v4,2019-01-07T20:58:40Z,2018-04-18T14:32:35Z,"Simulation-based Adversarial Test Generation for Autonomous Vehicles
  with Machine Learning Components","Many organizations are developing autonomous driving systems, which are
expected to be deployed at a large scale in the near future. Despite this,
there is a lack of agreement on appropriate methods to test, debug, and certify
the performance of these systems. One of the main challenges is that many
autonomous driving systems have machine learning components, such as deep
neural networks, for which formal properties are difficult to characterize. We
present a testing framework that is compatible with test case generation and
automatic falsification methods, which are used to evaluate cyber-physical
systems. We demonstrate how the framework can be used to evaluate closed-loop
properties of an autonomous driving system model that includes the ML
components, all within a virtual environment. We demonstrate how to use test
case generation methods, such as covering arrays, as well as requirement
falsification methods to automatically identify problematic test scenarios. The
resulting framework can be used to increase the reliability of autonomous
driving systems.",arxiv
http://arxiv.org/abs/1805.12395v1,2018-05-31T09:43:40Z,2018-05-31T09:43:40Z,"Deep Learning with unsupervised data labeling for weeds detection on UAV
  images","In modern agriculture, usually weeds control consists in spraying herbicides
all over the agricultural field. This practice involves significant waste and
cost of herbicide for farmers and environmental pollution. One way to reduce
the cost and environmental impact is to allocate the right doses of herbicide
at the right place and at the right time (Precision Agriculture). Nowadays,
Unmanned Aerial Vehicle (UAV) is becoming an interesting acquisition system for
weeds localization and management due to its ability to obtain the images of
the entire agricultural field with a very high spatial resolution and at low
cost. Despite the important advances in UAV acquisition systems, automatic
weeds detection remains a challenging problem because of its strong similarity
with the crops. Recently Deep Learning approach has shown impressive results in
different complex classification problem. However, this approach needs a
certain amount of training data but, creating large agricultural datasets with
pixel-level annotations by expert is an extremely time consuming task. In this
paper, we propose a novel fully automatic learning method using Convolutional
Neuronal Networks (CNNs) with unsupervised training dataset collection for
weeds detection from UAV images. The proposed method consists in three main
phases. First we automatically detect the crop lines and using them to identify
the interline weeds. In the second phase, interline weeds are used to
constitute the training dataset. Finally, we performed CNNs on this dataset to
build a model able to detect the crop and weeds in the images. The results
obtained are comparable to the traditional supervised training data labeling.
The accuracy gaps are 1.5% in the spinach field and 6% in the bean field.",arxiv
http://arxiv.org/abs/1910.09184v1,2019-10-21T07:36:08Z,2019-10-21T07:36:08Z,State-Aware Rate Adaptation for UAVs by Incorporating On-Board Sensors,"Nowadays unmanned aerial vehicles (UAVs) are being widely applied to a wealth
of civil and military applications. Robust and high-throughput wireless
communication is the crux of these UAV applications. Yet, air-to-ground links
suffer from time-varying channels induced by the agile mobility and dynamic
environments. Rate adaptation algorithms are generally used to choose the
optimal data rate based on the current channel conditions. State-of-the-art
approaches leverage physical layer information for rate adaptation, and they
work well under certain conditions. However, the above protocols still have
limitation under constantly changing flight states and environments for
air-to-ground links. To solve this problem, we propose StateRate, a
state-optimized rate adaptation algorithm that fully exploits the
characteristics of UAV systems using a hybrid deep learning model. The key
observation is that the rate adaptation strategy needs to be adjusted according
to motion-dependent channel models, which can be reflected by flight states. In
this work, the rate adaptation protocol is enhanced with the help of the
on-board sensors in UAVs. To make full use of the sensor data, we introduce a
learning-based prediction module by leveraging the internal state to
dynamically store temporal features under variable flight states. We also
present an online learning algorithm by employing the pre-trained model that
adapts the rate adaptation algorithm to different environments. We implement
our algorithm on a commercial UAV platform and evaluate it in various
environments. The results demonstrate that our system outperforms the
best-known rate adaptation algorithm up to 53% in terms of throughput when the
velocity is 2-6~m/s.",arxiv
http://arxiv.org/abs/2109.12398v1,2021-09-25T16:17:23Z,2021-09-25T16:17:23Z,Channel State Information Based Localization with Deep Learning,"Localization is one of the most important problems in various fields such as
robotics and wireless communications. For instance, Unmanned Aerial Vehicles
(UAVs) require the information of the position precisely for an adequate
control strategy. This problem is handled very efficiently with integrated GPS
units for outdoor applications. However, indoor applications require special
treatment due to the unavailability of GPS signals. Another aspect of mobile
robots such as UAVs is that there is constant wireless communication between
the mobile robot and a computational unit. This communication is mainly done
for obtaining telemetry information or computation of control actions directly.
The responsible integrated units for this transmission are commercial wireless
communication chipsets. These units on the receiver side are responsible for
getting rid of the diverse effects of the communication channel with various
mathematical techniques. These techniques mainly require the Channel State
Information (CSI) of the current channel to compensate the channel itself.
After the compensation, the chipset has nothing to do with CSI. However, the
locations of both the transmitter and receiver have a direct impact on CSI.
Even though CSI contains such rich information about the environment, the
accessibility of these data is blocked by the commercial wireless chipsets
since they are manufactured to provide only the processed information data bits
to the user. However, with the IEEE 802.11n standardization, certain chipsets
provide access to CSI. Therefore, CSI data became processible and integrable to
localization schemes. In this project, a test environment was constructed for
the localization task. Two routers with proper chipsets were assigned as
transmitter and receiver. They were operationalized for the CSI data
collection. Lastly, these data were processed with various deep learning
models.",arxiv
http://arxiv.org/abs/1906.09666v1,2019-06-23T22:48:08Z,2019-06-23T22:48:08Z,"Aerial hyperspectral imagery and deep neural networks for
  high-throughput yield phenotyping in wheat","Crop production needs to increase in a sustainable manner to meet the growing
global demand for food. To identify crop varieties with high yield potential,
plant scientists and breeders evaluate the performance of hundreds of lines in
multiple locations over several years. To facilitate the process of selecting
advanced varieties, an automated framework was developed in this study. A
hyperspectral camera was mounted on an unmanned aerial vehicle to collect
aerial imagery with high spatial and spectral resolution. Aerial images were
captured in two consecutive growing seasons from three experimental yield
fields composed of hundreds experimental plots (1x2.4 meter), each contained a
single wheat line. The grain of more than thousand wheat plots was harvested by
a combine, weighed, and recorded as the ground truth data. To leverage the high
spatial resolution and investigate the yield variation within the plots, images
of plots were divided into sub-plots by integrating image processing techniques
and spectral mixture analysis with the expert domain knowledge. Afterwards, the
sub-plot dataset was divided into train, validation, and test sets using
stratified sampling. Subsequent to extracting features from each sub-plot, deep
neural networks were trained for yield estimation. The coefficient of
determination for predicting the yield of the test dataset at sub-plot scale
was 0.79 with root mean square error of 5.90 grams. In addition to providing
insights into yield variation at sub-plot scale, the proposed framework can
facilitate the process of high-throughput yield phenotyping as a valuable
decision support tool. It offers the possibility of (i) remote visual
inspection of the plots, (ii) studying the effect of crop density on yield, and
(iii) optimizing plot size to investigate more lines in a dedicated field each
year.",arxiv
http://arxiv.org/abs/2005.01305v1,2020-05-04T07:32:01Z,2020-05-04T07:32:01Z,"Energy Model for UAV Communications: Experimental Validation and Model
  Generalization","Wireless communication involving unmanned aerial vehicles (UAVs) is expected
to play an important role in future wireless networks. However, different from
conventional terrestrial communication systems, UAVs typically have rather
limited onboard energy on one hand, and require additional flying energy
consumption on the other hand, which renders energy-efficient UAV communication
with smart energy expenditure of paramount importance. In this paper, via
extensive flight experiments, we aim to firstly validate the recently derived
theoretical energy model for rotary-wing UAVs, and then develop a general model
for those complicated flight scenarios where rigorous theoretical model
derivation is quite challenging, if not impossible. Specifically, we first
investigate how UAV power consumption varies with its flying speed for the
simplest straight-and-level flight. With about 12,000 valid power-speed data
points collected, we first apply the model-based curve fitting to obtain the
modelling parameters based on the theoretical closed-form energy model in the
existing literature. In addition, in order to exclude the potential bias caused
by the theoretical energy model, the obtained measurement data is also trained
using a model-free deep neural network. It is found that the obtained curve
from both methods can match quite well with the theoretical energy model. Next,
we further extend the study to arbitrary 2-dimensional (2-D) flight, where, to
our best knowledge, no rigorous theoretical derivation is available for the
closed-form energy model as a function of its flying speed, direction, and
acceleration. To fill the gap, we first propose a heuristic energy model for
these more complicated cases, and then provide experimental validation based on
the measurement results for circular level flight.",arxiv
http://arxiv.org/abs/2010.02645v2,2021-09-06T10:03:55Z,2020-10-06T11:45:11Z,"Multirotors from Takeoff to Real-Time Full Identification Using the
  Modified Relay Feedback Test and Deep Neural Networks","Low cost real-time identification of multirotor unmanned aerial vehicle (UAV)
dynamics is an active area of research supported by the surge in demand and
emerging application domains. Such real-time identification capabilities
shorten development time and cost, making UAVs' technology more accessible, and
enable a wide variety of advanced applications. In this paper, we present a
novel comprehensive approach, called DNN-MRFT, for real-time identification and
tuning of multirotor UAVs using the Modified Relay Feedback Test (MRFT) and
Deep Neural Networks (DNN). The main contribution is the development of a
generalized framework for the application of DNN-MRFT to higher-order systems.
One of the notable advantages of DNN-MRFT is the exact estimation of identified
process gain, which mitigates the inaccuracies introduced due to the use of the
describing function method in approximating the response of Lure's systems. A
secondary contribution is a generalized controller based on DNN-MRFT that
takes-off a UAV with unknown dynamics and identifies the inner loops dynamics
in-flight. Using the developed framework, DNN-MRFT is sequentially applied to
the outer translational loops of the UAV utilizing in-flight results obtained
for the inner attitude loops. DNN-MRFT takes on average 15 seconds to get the
full knowledge of multirotor UAV dynamics and without any further tuning or
calibration the UAV would be able to pass through a vertical window, and
accurately follow trajectories achieving state-of-the-art performance. Such
demonstrated accuracy, speed, and robustness of identification pushes the
limits of state-of-the-art in real-time identification of UAVs.",arxiv
http://arxiv.org/abs/2109.12221v1,2021-09-24T22:29:26Z,2021-09-24T22:29:26Z,"Ground material classification and for UAV-based photogrammetric 3D data
  A 2D-3D Hybrid Approach","In recent years, photogrammetry has been widely used in many areas to create
photorealistic 3D virtual data representing the physical environment. The
innovation of small unmanned aerial vehicles (sUAVs) has provided additional
high-resolution imaging capabilities with low cost for mapping a relatively
large area of interest. These cutting-edge technologies have caught the US Army
and Navy's attention for the purpose of rapid 3D battlefield reconstruction,
virtual training, and simulations. Our previous works have demonstrated the
importance of information extraction from the derived photogrammetric data to
create semantic-rich virtual environments (Chen et al., 2019). For example, an
increase of simulation realism and fidelity was achieved by segmenting and
replacing photogrammetric trees with game-ready tree models. In this work, we
further investigated the semantic information extraction problem and focused on
the ground material segmentation and object detection tasks. The main
innovation of this work was that we leveraged both the original 2D images and
the derived 3D photogrammetric data to overcome the challenges faced when using
each individual data source. For ground material segmentation, we utilized an
existing convolutional neural network architecture (i.e., 3DMV) which was
originally designed for segmenting RGB-D sensed indoor data. We improved its
performance for outdoor photogrammetric data by introducing a depth pooling
layer in the architecture to take into consideration the distance between the
source images and the reconstructed terrain model. To test the performance of
our improved 3DMV, a ground truth ground material database was created using
data from the One World Terrain (OWT) data repository. Finally, a workflow for
importing the segmented ground materials into a virtual simulation scene was
introduced, and visual results are reported in this paper.",arxiv
http://arxiv.org/abs/2004.11070v1,2020-04-23T11:00:05Z,2020-04-23T11:00:05Z,"Millimeter-Wave Full-Duplex UAV Relay: Joint Positioning, Beamforming,
  and Power Control","In this paper, a full-duplex unmanned aerial vehicle (FD-UAV) relay is
employed to increase the communication capacity of millimeter-wave (mmWave)
networks. Large antenna arrays are equipped at the source node (SN),
destination node (DN), and FD-UAV relay to overcome the high path loss of
mmWave channels and to help mitigate the self-interference at the FD-UAV relay.
Specifically, we formulate a problem for maximization of the achievable rate
from the SN to the DN, where the UAV position, analog beamforming, and power
control are jointly optimized. Since the problem is highly non-convex and
involves high-dimensional, highly coupled variable vectors, we first obtain the
conditional optimal position of the FD-UAV relay for maximization of an
approximate upper bound on the achievable rate in closed form, under the
assumption of a line-of-sight (LoS) environment and ideal beamforming. Then,
the UAV is deployed to the position which is closest to the conditional optimal
position and yields LoS paths for both air-to-ground links. Subsequently, we
propose an alternating interference suppression (AIS) algorithm for the joint
design of the beamforming vectors and the power control variables. In each
iteration, the beamforming vectors are optimized for maximization of the
beamforming gains of the target signals and the successive reduction of the
interference, where the optimal power control variables are obtained in closed
form. Our simulation results confirm the superiority of the proposed
positioning, beamforming, and power control method compared to three benchmark
schemes. Furthermore, our results show that the proposed solution closely
approaches a performance upper bound for mmWave FD-UAV systems.",arxiv
http://arxiv.org/abs/2006.09293v1,2020-06-03T10:12:37Z,2020-06-03T10:12:37Z,"An agent-based self-protective method to secure communication between
  UAVs in unmanned aerial vehicle networks","UAVNs (unmanned aerial vehicle networks) may become vulnerable to threats and
attacks due to their characteristic features such as highly dynamic network
topology, open-air wireless environments, and high mobility. Since previous
work has focused on classical and metaheuristic-based approaches, none of these
approaches have a self-adaptive approach. In this paper, the challenges and
weaknesses of previous methods are examined in the form of a table.
Furthermore, we propose an agent-based self-protective method (ASP-UAVN) for
UAVNs that is based on the Human Immune System (HIS). In ASP-UAS, the safest
route from the source UAV to the destination UAV is chosen according to a
self-protective system. In this method, a multi-agent system using an
Artificial Immune System (AIS) is employed to detect the attacking UAV and
choose the safest route. In the proposed ASP-UAVN, the route request packet
(RREQ) is initially transmitted from the source UAV to the destination UAV to
detect the existing routes. Then, once the route reply packet (RREP) is
received, a self-protective method using agents and the knowledge base is
employed to choose the safest route and detect the attacking UAVs. The proposed
ASP-UAVN has been validated and evaluated in two ways: simulation and
theoretical analysis. The results of simulation evaluation and theory analysis
showed that the ASP-UAS increases the Packet Delivery Rate (PDR) by more than
17.4, 20.8, and 25.91%, and detection rate by more than 17.2, 23.1, and 29.3%,
and decreases the Packet Loss Rate (PLR) by more than 14.4, 16.8, and 20.21%,
the false-positive and false-negative rate by more than 16.5, 25.3, and 31.21%
those of SUAS-HIS, SFA and BRUIDS methods, respectively.",arxiv
http://arxiv.org/abs/1909.02562v1,2019-09-05T13:21:22Z,2019-09-05T13:21:22Z,"TFCheck : A TensorFlow Library for Detecting Training Issues in Neural
  Network Programs","The increasing inclusion of Machine Learning (ML) models in safety critical
systems like autonomous cars have led to the development of multiple
model-based ML testing techniques. One common denominator of these testing
techniques is their assumption that training programs are adequate and
bug-free. These techniques only focus on assessing the performance of the
constructed model using manually labeled data or automatically generated data.
However, their assumptions about the training program are not always true as
training programs can contain inconsistencies and bugs. In this paper, we
examine training issues in ML programs and propose a catalog of verification
routines that can be used to detect the identified issues, automatically. We
implemented the routines in a Tensorflow-based library named TFCheck. Using
TFCheck, practitioners can detect the aforementioned issues automatically. To
assess the effectiveness of TFCheck, we conducted a case study with real-world,
mutants, and synthetic training programs. Results show that TFCheck can
successfully detect training issues in ML code implementations.",arxiv
http://arxiv.org/abs/1901.07223v2,2019-01-24T11:22:55Z,2019-01-22T09:25:08Z,"DF-SLAM: A Deep-Learning Enhanced Visual SLAM System based on Deep Local
  Features","As the foundation of driverless vehicle and intelligent robots, Simultaneous
Localization and Mapping(SLAM) has attracted much attention these days.
However, non-geometric modules of traditional SLAM algorithms are limited by
data association tasks and have become a bottleneck preventing the development
of SLAM. To deal with such problems, many researchers seek to Deep Learning for
help. But most of these studies are limited to virtual datasets or specific
environments, and even sacrifice efficiency for accuracy. Thus, they are not
practical enough.
  We propose DF-SLAM system that uses deep local feature descriptors obtained
by the neural network as a substitute for traditional hand-made features.
Experimental results demonstrate its improvements in efficiency and stability.
DF-SLAM outperforms popular traditional SLAM systems in various scenes,
including challenging scenes with intense illumination changes. Its versatility
and mobility fit well into the need for exploring new environments. Since we
adopt a shallow network to extract local descriptors and remain others the same
as original SLAM systems, our DF-SLAM can still run in real-time on GPU.",arxiv
http://arxiv.org/abs/2010.10270v2,2021-05-20T11:14:35Z,2020-10-20T13:42:31Z,Pedestrian Intention Prediction: A Multi-task Perspective,"In order to be globally deployed, autonomous cars must guarantee the safety
of pedestrians. This is the reason why forecasting pedestrians' intentions
sufficiently in advance is one of the most critical and challenging tasks for
autonomous vehicles. This work tries to solve this problem by jointly
predicting the intention and visual states of pedestrians. In terms of visual
states, whereas previous work focused on x-y coordinates, we will also predict
the size and indeed the whole bounding box of the pedestrian. The method is a
recurrent neural network in a multi-task learning approach. It has one head
that predicts the intention of the pedestrian for each one of its future
position and another one predicting the visual states of the pedestrian.
Experiments on the JAAD dataset show the superiority of the performance of our
method compared to previous works for intention prediction. Also, although its
simple architecture (more than 2 times faster), the performance of the bounding
box prediction is comparable to the ones yielded by much more complex
architectures. Our code is available online.",arxiv
http://arxiv.org/abs/2011.00413v2,2021-03-18T15:47:37Z,2020-11-01T03:57:42Z,"Collision Avoidance in Tightly-Constrained Environments without
  Coordination: a Hierarchical Control Approach","We present a hierarchical control approach for maneuvering an autonomous
vehicle (AV) in tightly-constrained environments where other moving AVs and/or
human driven vehicles are present. A two-level hierarchy is proposed: a
high-level data-driven strategy predictor and a lower-level model-based
feedback controller. The strategy predictor maps an encoding of a dynamic
environment to a set of high-level strategies via a neural network. Depending
on the selected strategy, a set of time-varying hyperplanes in the AV's
position space is generated online and the corresponding halfspace constraints
are included in a lower-level model-based receding horizon controller. These
strategy-dependent constraints drive the vehicle towards areas where it is
likely to remain feasible. Moreover, the predicted strategy also informs
switching between a discrete set of policies, which allows for more
conservative behavior when prediction confidence is low. We demonstrate the
effectiveness of the proposed data-driven hierarchical control framework in a
two-car collision avoidance scenario through simulations and experiments on a
1/10 scale autonomous car platform where the strategy-guided approach
outperforms a model predictive control baseline in both cases.",arxiv
http://arxiv.org/abs/2106.11125v1,2021-06-15T15:56:00Z,2021-06-15T15:56:00Z,"Classification of Documents Extracted from Images with Optical Character
  Recognition Methods","Over the past decade, machine learning methods have given us driverless cars,
voice recognition, effective web search, and a much better understanding of the
human genome. Machine learning is so common today that it is used dozens of
times a day, possibly unknowingly. Trying to teach a machine some processes or
some situations can make them predict some results that are difficult to
predict by the human brain. These methods also help us do some operations that
are often impossible or difficult to do with human activities in a short time.
For these reasons, machine learning is so important today. In this study, two
different machine learning methods were combined. In order to solve a
real-world problem, the manuscript documents were first transferred to the
computer and then classified. We used three basic methods to realize the whole
process. Handwriting or printed documents have been digitalized by a scanner or
digital camera. These documents have been processed with two different Optical
Character Recognition (OCR) operation. After that generated texts are
classified by using Naive Bayes algorithm. All project was programmed in
Microsoft Visual Studio 12 platform on Windows operating system. C# programming
language was used for all parts of the study. Also, some prepared codes and
DLLs were used.",arxiv
http://arxiv.org/abs/1710.03804v3,2017-11-22T13:03:45Z,2017-10-10T20:10:25Z,"End-to-End Deep Learning for Steering Autonomous Vehicles Considering
  Temporal Dependencies","Steering a car through traffic is a complex task that is difficult to cast
into algorithms. Therefore, researchers turn to training artificial neural
networks from front-facing camera data stream along with the associated
steering angles. Nevertheless, most existing solutions consider only the visual
camera frames as input, thus ignoring the temporal relationship between frames.
In this work, we propose a Convolutional Long Short-Term Memory Recurrent
Neural Network (C-LSTM), that is end-to-end trainable, to learn both visual and
dynamic temporal dependencies of driving. Additionally, We introduce posing the
steering angle regression problem as classification while imposing a spatial
relationship between the output layer neurons. Such method is based on learning
a sinusoidal function that encodes steering angles. To train and validate our
proposed methods, we used the publicly available Comma.ai dataset. Our solution
improved steering root mean square error by 35% over recent methods, and led to
a more stable steering by 87%.",arxiv
http://arxiv.org/abs/1803.09386v2,2018-10-13T00:04:29Z,2018-03-26T01:58:07Z,"A Systematic Comparison of Deep Learning Architectures in an Autonomous
  Vehicle","Self-driving technology is advancing rapidly --- albeit with significant
challenges and limitations. This progress is largely due to recent developments
in deep learning algorithms. To date, however, there has been no systematic
comparison of how different deep learning architectures perform at such tasks,
or an attempt to determine a correlation between classification performance and
performance in an actual vehicle, a potentially critical factor in developing
self-driving systems. Here, we introduce the first controlled comparison of
multiple deep-learning architectures in an end-to-end autonomous driving task
across multiple testing conditions. We compared performance, under identical
driving conditions, across seven architectures including a fully-connected
network, a simple 2 layer CNN, AlexNet, VGG-16, Inception-V3, ResNet, and an
LSTM by assessing the number of laps each model was able to successfully
complete without crashing while traversing an indoor racetrack. We compared
performance across models when the conditions exactly matched those in training
as well as when the local environment and track were configured differently and
objects that were not included in the training dataset were placed on the track
in various positions. In addition, we considered performance using several
different data types for training and testing including single grayscale and
color frames, and multiple grayscale frames stacked together in sequence. With
the exception of a fully-connected network, all models performed reasonably
well (around or above 80\%) and most very well (~95\%) on at least one input
type but with considerable variation across models and inputs. Overall,
AlexNet, operating on single color frames as input, achieved the best level of
performance (100\% success rate in phase one and 55\% in phase two) while
VGG-16 performed well most consistently across image types.",arxiv
http://arxiv.org/abs/2003.00946v1,2020-03-02T14:48:29Z,2020-03-02T14:48:29Z,"A Self-Supervised Learning Approach to Rapid Path Planning for Car-Like
  Vehicles Maneuvering in Urban Environment","An efficient path planner for autonomous car-like vehicles should handle the
strong kinematic constraints, particularly in confined spaces commonly
encountered while maneuvering in city traffic, and should enable rapid
planning, as the city traffic scenarios are highly dynamic. State-of-the-art
planning algorithms handle such difficult cases at high computational cost,
often yielding non-deterministic results. However, feasible local paths can be
quickly generated leveraging the past planning experience gained in the same or
similar environment. While learning through supervised training is problematic
for real traffic scenarios, we introduce in this paper a novel neural
network-based method for path planning, which employs a gradient-based
self-supervised learning algorithm to predict feasible paths. This approach
strongly exploits the experience gained in the past and rapidly yields feasible
maneuver plans for car-like vehicles with limited steering-angle. The
effectiveness of such an approach has been confirmed by computational
experiments.",arxiv
http://arxiv.org/abs/1705.10432v1,2017-05-30T02:04:29Z,2017-05-30T02:04:29Z,"Fine-grained acceleration control for autonomous intersection management
  using deep reinforcement learning","Recent advances in combining deep learning and Reinforcement Learning have
shown a promising path for designing new control agents that can learn optimal
policies for challenging control tasks. These new methods address the main
limitations of conventional Reinforcement Learning methods such as customized
feature engineering and small action/state space dimension requirements. In
this paper, we leverage one of the state-of-the-art Reinforcement Learning
methods, known as Trust Region Policy Optimization, to tackle intersection
management for autonomous vehicles. We show that using this method, we can
perform fine-grained acceleration control of autonomous vehicles in a grid
street plan to achieve a global design objective.",arxiv
http://arxiv.org/abs/1805.02754v1,2018-05-07T21:32:56Z,2018-05-07T21:32:56Z,"Verisimilar Percept Sequences Tests for Autonomous Driving Intelligent
  Agent Assessment","The autonomous car technology promises to replace human drivers with safer
driving systems. But although autonomous cars can become safer than human
drivers this is a long process that is going to be refined over time. Before
these vehicles are deployed on urban roads a minimum safety level must be
assured. Since the autonomous car technology is still under development there
is no standard methodology to evaluate such systems. It is important to
completely understand the technology that is being developed to design
efficient means to evaluate it. In this paper we assume safety-critical systems
reliability as a safety measure. We model an autonomous road vehicle as an
intelligent agent and we approach its evaluation from an artificial
intelligence perspective. Our focus is the evaluation of perception and
decision making systems and also to propose a systematic method to evaluate
their integration in the vehicle. We identify critical aspects of the data
dependency from the artificial intelligence state of the art models and we also
propose procedures to reproduce them.",arxiv
http://arxiv.org/abs/2101.07337v1,2021-01-18T21:45:35Z,2021-01-18T21:45:35Z,Dissonance Between Human and Machine Understanding,"Complex machine learning models are deployed in several critical domains
including healthcare and autonomous vehicles nowadays, albeit as functional
black boxes. Consequently, there has been a recent surge in interpreting
decisions of such complex models in order to explain their actions to humans.
Models that correspond to human interpretation of a task are more desirable in
certain contexts and can help attribute liability, build trust, expose biases
and in turn build better models. It is, therefore, crucial to understand how
and which models conform to human understanding of tasks. In this paper, we
present a large-scale crowdsourcing study that reveals and quantifies the
dissonance between human and machine understanding, through the lens of an
image classification task. In particular, we seek to answer the following
questions: Which (well-performing) complex ML models are closer to humans in
their use of features to make accurate predictions? How does task difficulty
affect the feature selection capability of machines in comparison to humans?
Are humans consistently better at selecting features that make image
recognition more accurate? Our findings have important implications on
human-machine collaboration, considering that a long term goal in the field of
artificial intelligence is to make machines capable of learning and reasoning
like humans.",arxiv
http://arxiv.org/abs/1511.04508v2,2016-03-14T13:08:09Z,2015-11-14T04:51:04Z,"Distillation as a Defense to Adversarial Perturbations against Deep
  Neural Networks","Deep learning algorithms have been shown to perform extremely well on many
classical machine learning problems. However, recent studies have shown that
deep learning, like other machine learning techniques, is vulnerable to
adversarial samples: inputs crafted to force a deep neural network (DNN) to
provide adversary-selected outputs. Such attacks can seriously undermine the
security of the system supported by the DNN, sometimes with devastating
consequences. For example, autonomous vehicles can be crashed, illicit or
illegal content can bypass content filters, or biometric authentication systems
can be manipulated to allow improper access. In this work, we introduce a
defensive mechanism called defensive distillation to reduce the effectiveness
of adversarial samples on DNNs. We analytically investigate the
generalizability and robustness properties granted by the use of defensive
distillation when training DNNs. We also empirically study the effectiveness of
our defense mechanisms on two DNNs placed in adversarial settings. The study
shows that defensive distillation can reduce effectiveness of sample creation
from 95% to less than 0.5% on a studied DNN. Such dramatic gains can be
explained by the fact that distillation leads gradients used in adversarial
sample creation to be reduced by a factor of 10^30. We also find that
distillation increases the average minimum number of features that need to be
modified to create adversarial samples by about 800% on one of the DNNs we
tested.",arxiv
http://arxiv.org/abs/2107.14046v1,2021-07-14T15:16:40Z,2021-07-14T15:16:40Z,"Audit and Assurance of AI Algorithms: A framework to ensure ethical
  algorithmic practices in Artificial Intelligence","Algorithms are becoming more widely used in business, and businesses are
becoming increasingly concerned that their algorithms will cause significant
reputational or financial damage. We should emphasize that any of these damages
stem from situations in which the United States lacks strict legislative
prohibitions or specified protocols for measuring damages. As a result,
governments are enacting legislation and enforcing prohibitions, regulators are
fining businesses, and the judiciary is debating whether or not to make
artificially intelligent computer models as the decision-makers in the eyes of
the law. From autonomous vehicles and banking to medical care, housing, and
legal decisions, there will soon be enormous amounts of algorithms that make
decisions with limited human interference. Governments, businesses, and society
would have an algorithm audit, which would have systematic verification that
algorithms are lawful, ethical, and secure, similar to financial audits. A
modern market, auditing, and assurance of algorithms developed to
professionalize and industrialize AI, machine learning, and related algorithms.
Stakeholders of this emerging field include policymakers and regulators, along
with industry experts and entrepreneurs. In addition, we foresee audit
thresholds and frameworks providing valuable information to all who are
concerned with governance and standardization. This paper aims to review the
critical areas required for auditing and assurance and spark discussion in this
novel field of study and practice.",arxiv
http://arxiv.org/abs/1709.03138v1,2017-09-10T17:06:23Z,2017-09-10T17:06:23Z,"Fully Convolutional Neural Networks for Dynamic Object Detection in Grid
  Maps (Masters Thesis)","One of the most important parts of environment perception is the detection of
obstacles in the surrounding of the vehicle. To achieve that, several sensors
like radars, LiDARs and cameras are installed in autonomous vehicles. The
produced sensor data is fused to a general representation of the surrounding.
In this thesis the dynamic occupancy grid map approach of Nuss et al. is used
while three goals are achieved. First, the approach of Nuss et al. to
distinguish between moving and non-moving obstacles is improved by using Fully
Convolutional Neural Networks to create a class prediction for each grid cell.
For this purpose, the network is initialized with public pre-trained network
models and the training is executed with a semi-automatic generated dataset.
The second goal is to provide orientation information for each detected moving
obstacle. This could improve tracking algorithms, which are based on the
dynamic occupancy grid map. The orientation extraction based on the
Convolutional Neural Network shows a better performance in comparison to an
orientation extraction directly over the velocity information of the dynamic
occupancy grid map. A general problem of developing machine learning approaches
like Neural Networks is the number of labeled data, which can always be
increased. For this reason, the last goal is to evaluate a semi-supervised
learning algorithm, to generate automatically more labeled data. The result of
this evaluation shows that the automated labeled data does not improve the
performance of the Convolutional Neural Network. All in all, the best results
are combined to compare the detection against the approach of Nuss et al. [36]
and a relative improvement of 34.8% is reached.",arxiv
http://arxiv.org/abs/2008.07971v2,2021-05-09T16:03:52Z,2020-08-18T15:06:44Z,"Super-Human Performance in Gran Turismo Sport Using Deep Reinforcement
  Learning","Autonomous car racing is a major challenge in robotics. It raises fundamental
problems for classical approaches such as planning minimum-time trajectories
under uncertain dynamics and controlling the car at the limits of its handling.
Besides, the requirement of minimizing the lap time, which is a sparse
objective, and the difficulty of collecting training data from human experts
have also hindered researchers from directly applying learning-based approaches
to solve the problem. In the present work, we propose a learning-based system
for autonomous car racing by leveraging a high-fidelity physical car
simulation, a course-progress proxy reward, and deep reinforcement learning. We
deploy our system in Gran Turismo Sport, a world-leading car simulator known
for its realistic physics simulation of different race cars and tracks, which
is even used to recruit human race car drivers. Our trained policy achieves
autonomous racing performance that goes beyond what had been achieved so far by
the built-in AI, and, at the same time, outperforms the fastest driver in a
dataset of over 50,000 human players.",arxiv
http://arxiv.org/abs/1908.00732v1,2019-08-02T07:48:31Z,2019-08-02T07:48:31Z,Road Context-aware Intrusion Detection System for Autonomous Cars,"Security is of primary importance to vehicles. The viability of performing
remote intrusions onto the in-vehicle network has been manifested. In regard to
unmanned autonomous cars, limited work has been done to detect intrusions for
them while existing intrusion detection systems (IDSs) embrace limitations
against strong adversaries. In this paper, we consider the very nature of
autonomous car and leverage the road context to build a novel IDS, named Road
context-aware IDS (RAIDS). When a computer-controlled car is driving through
continuous roads, road contexts and genuine frames transmitted on the car's
in-vehicle network should resemble a regular and intelligible pattern. RAIDS
hence employs a lightweight machine learning model to extract road contexts
from sensory information (e.g., camera images and distance sensor values) that
are used to generate control signals for maneuvering the car. With such ongoing
road context, RAIDS validates corresponding frames observed on the in-vehicle
network. Anomalous frames that substantially deviate from road context will be
discerned as intrusions. We have implemented a prototype of RAIDS with neural
networks, and conducted experiments on a Raspberry Pi with extensive datasets
and meaningful intrusion cases. Evaluations show that RAIDS significantly
outperforms state-of-the-art IDS without using road context by up to 99.9%
accuracy and short response time.",arxiv
http://arxiv.org/abs/2012.06992v1,2020-12-13T07:28:18Z,2020-12-13T07:28:18Z,"Edge Intelligence for Autonomous Driving in 6G Wireless System: Design
  Challenges and Solutions","In a level-5 autonomous driving system, the autonomous driving vehicles (AVs)
are expected to sense the surroundings via analyzing a large amount of data
captured by a variety of onboard sensors in near-real-time. As a result,
enormous computing costs will be introduced to the AVs for processing the tasks
with the deployed machine learning (ML) model, while the inference accuracy may
not be guaranteed. In this context, the advent of edge intelligence (EI) and
sixth-generation (6G) wireless networking are expected to pave the way to more
reliable and safer autonomous driving by providing multi-access edge computing
(MEC) together with ML to AVs in close proximity. To realize this goal, we
propose a two-tier EI-empowered autonomous driving framework. In the
autonomous-vehicles tier, the autonomous vehicles are deployed with the shallow
layers by splitting the trained deep neural network model. In the
edge-intelligence tier, an edge server is implemented with the remaining layers
(also deep layers) and an appropriately trained multi-task learning (MTL)
model. In particular, obtaining the optimal offloading strategy (including the
binary offloading decision and the computational resources allocation) can be
formulated as a mixed-integer nonlinear programming (MINLP) problem, which is
solved via MTL in near-real-time with high accuracy. On another note, an
edge-vehicle joint inference is proposed through neural network segmentation to
achieve efficient online inference with data privacy-preserving and less
communication delay. Experiments demonstrate the effectiveness of the proposed
framework, and open research topics are finally listed.",arxiv
http://arxiv.org/abs/2003.07859v4,2021-08-26T10:42:36Z,2020-03-17T08:20:43Z,"Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement
  Learning-based Traffic Congestion Control Systems","Recent work has shown that the introduction of autonomous vehicles (AVs) in
traffic could help reduce traffic jams. Deep reinforcement learning methods
demonstrate good performance in complex control problems, including autonomous
vehicle control, and have been used in state-of-the-art AV controllers.
However, deep neural networks (DNNs) render automated driving vulnerable to
machine learning-based attacks. In this work, we explore the
backdooring/trojanning of DRL-based AV controllers. We develop a trigger design
methodology that is based on well-established principles of traffic physics.
The malicious actions include vehicle deceleration and acceleration to cause
stop-and-go traffic waves to emerge (congestion attacks) or AV acceleration
resulting in the AV crashing into the vehicle in front (insurance attack). We
test our attack on single-lane and two-lane circuits. Our experimental results
show that the backdoored model does not compromise normal operation
performance, with the maximum decrease in cumulative rewards being 1%. Still,
it can be maliciously activated to cause a crash or congestion when the
corresponding triggers appear.",arxiv
http://arxiv.org/abs/1804.05132v2,2018-09-07T08:10:46Z,2018-04-13T22:13:30Z,"Towards Safe Autonomous Driving: Capture Uncertainty in the Deep Neural
  Network For Lidar 3D Vehicle Detection","To assure that an autonomous car is driving safely on public roads, its
object detection module should not only work correctly, but show its prediction
confidence as well. Previous object detectors driven by deep learning do not
explicitly model uncertainties in the neural network. We tackle with this
problem by presenting practical methods to capture uncertainties in a 3D
vehicle detector for Lidar point clouds. The proposed probabilistic detector
represents reliable epistemic uncertainty and aleatoric uncertainty in
classification and localization tasks. Experimental results show that the
epistemic uncertainty is related to the detection accuracy, whereas the
aleatoric uncertainty is influenced by vehicle distance and occlusion. The
results also show that we can improve the detection performance by 1%-5% by
modeling the aleatoric uncertainty.",arxiv
http://arxiv.org/abs/1805.06776v1,2018-05-17T13:52:34Z,2018-05-17T13:52:34Z,"Situation Assessment for Planning Lane Changes: Combining Recurrent
  Models and Prediction","One of the greatest challenges towards fully autonomous cars is the
understanding of complex and dynamic scenes. Such understanding is needed for
planning of maneuvers, especially those that are particularly frequent such as
lane changes. While in recent years advanced driver-assistance systems have
made driving safer and more comfortable, these have mostly focused on car
following scenarios, and less on maneuvers involving lane changes. In this work
we propose a situation assessment algorithm for classifying driving situations
with respect to their suitability for lane changing. For this, we propose a
deep learning architecture based on a Bidirectional Recurrent Neural Network,
which uses Long Short-Term Memory units, and integrates a prediction component
in the form of the Intelligent Driver Model. We prove the feasibility of our
algorithm on the publicly available NGSIM datasets, where we outperform
existing methods.",arxiv
http://arxiv.org/abs/2103.13224v3,2021-03-27T01:58:12Z,2021-03-24T14:30:59Z,"Pole-like Objects Mapping and Long-Term Robot Localization in Dynamic
  Urban Scenarios","Localization on 3D data is a challenging task for unmanned vehicles,
especially in long-term dynamic urban scenarios. Due to the generality and
long-term stability, the pole-like objects are very suitable as landmarks for
unmanned vehicle localization in time-varing scenarios. In this paper, a
long-term LiDAR-only localization algorithm based on semantic cluster map is
proposed. At first, the Convolutional Neural Network(CNN) is used to infer the
semantics of LiDAR point clouds. Combined with the point cloud segmentation,
the long-term static objects pole/trunk in the scene are extracted and
registered into a semantic cluster map. When the unmanned vehicle re-enters the
environment again, the relocalization is completed by matching the clusters of
the local map with the clusters of the global map. Furthermore, the continuous
matching between the local and global maps stably outputs the global pose at
2Hz to correct the drift of the 3D LiDAR odometry. The proposed approach
realizes localization in the long-term scenarios without maintaining the
high-precision point cloud map. The experimental results on our campus dataset
demonstrate that the proposed approach performs better in localization accuracy
compared with the current state-of-the-art methods. The source of this paper is
available at: http://www.github.com/HITSZ-NRSL/long-term-localization.",arxiv
http://arxiv.org/abs/1810.03913v1,2018-10-09T11:13:44Z,2018-10-09T11:13:44Z,Analyzing the Noise Robustness of Deep Neural Networks,"Deep neural networks (DNNs) are vulnerable to maliciously generated
adversarial examples. These examples are intentionally designed by making
imperceptible perturbations and often mislead a DNN into making an incorrect
prediction. This phenomenon means that there is significant risk in applying
DNNs to safety-critical applications, such as driverless cars. To address this
issue, we present a visual analytics approach to explain the primary cause of
the wrong predictions introduced by adversarial examples. The key is to analyze
the datapaths of the adversarial examples and compare them with those of the
normal examples. A datapath is a group of critical neurons and their
connections. To this end, we formulate the datapath extraction as a subset
selection problem and approximately solve it based on back-propagation. A
multi-level visualization consisting of a segmented DAG (layer level), an Euler
diagram (feature map level), and a heat map (neuron level), has been designed
to help experts investigate datapaths from the high-level layers to the
detailed neuron activations. Two case studies are conducted that demonstrate
the promise of our approach in support of explaining the working mechanism of
adversarial examples.",arxiv
http://arxiv.org/abs/1909.00205v1,2019-08-31T12:11:13Z,2019-08-31T12:11:13Z,"Real-time image processing with a 2D semiconductor neural network vision
  sensor","In recent years, machine vision has taken huge leaps and is now becoming an
integral part of various intelligent systems, including autonomous vehicles,
robotics, and many others. Usually, visual information is captured by a
frame-based camera, converted into a digital format, and processed afterwards
using a machine learning algorithm such as an artificial neural network (ANN).
A large amount of (mostly redundant) data being passed through the entire
signal chain, however, results in low frame rates and large power consumption.
Various visual data preprocessing techniques have thus been developed that
allow to increase the efficiency of the subsequent signal processing in an ANN.
Here, we demonstrate that an image sensor itself can constitute an ANN that is
able to simultaneously sense and process optical images without latency. Our
device is based on a reconfigurable two-dimensional (2D) semiconductor
photodiode array, with the synaptic weights of the network being stored in a
continuously tunable photoresponsivity matrix. We demonstrate both supervised
and unsupervised learning and successfully train the sensor to classify and
encode images, that are optically projected onto the chip, with a throughput of
20 million bins per second.",arxiv
http://arxiv.org/abs/1711.08740v1,2017-11-23T15:37:21Z,2017-11-23T15:37:21Z,"fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural
  Networks on Embedded FPGAs","In recent years, Convolutional Neural Networks (ConvNets) have become an
enabling technology for a wide range of novel embedded Artificial Intelligence
systems. Across the range of applications, the performance needs vary
significantly, from high-throughput video surveillance to the very low-latency
requirements of autonomous cars. In this context, FPGAs can provide a potential
platform that can be optimally configured based on the different performance
needs. However, the complexity of ConvNet models keeps increasing making their
mapping to an FPGA device a challenging task. This work presents fpgaConvNet,
an end-to-end framework for mapping ConvNets on FPGAs. The proposed framework
employs an automated design methodology based on the Synchronous Dataflow (SDF)
paradigm and defines a set of SDF transformations in order to efficiently
explore the architectural design space. By selectively optimising for
throughput, latency or multiobjective criteria, the presented tool is able to
efficiently explore the design space and generate hardware designs from
high-level ConvNet specifications, explicitly optimised for the performance
metric of interest. Overall, our framework yields designs that improve the
performance by up to 6.65x over highly optimised embedded GPU designs for the
same power constraints in embedded environments.",arxiv
http://arxiv.org/abs/2010.08776v1,2020-10-17T12:25:18Z,2020-10-17T12:25:18Z,The NVIDIA PilotNet Experiments,"Four years ago, an experimental system known as PilotNet became the first
NVIDIA system to steer an autonomous car along a roadway. This system
represents a departure from the classical approach for self-driving in which
the process is manually decomposed into a series of modules, each performing a
different task. In PilotNet, on the other hand, a single deep neural network
(DNN) takes pixels as input and produces a desired vehicle trajectory as
output; there are no distinct internal modules connected by human-designed
interfaces. We believe that handcrafted interfaces ultimately limit performance
by restricting information flow through the system and that a learned approach,
in combination with other artificial intelligence systems that add redundancy,
will lead to better overall performing systems. We continue to conduct research
toward that goal.
  This document describes the PilotNet lane-keeping effort, carried out over
the past five years by our NVIDIA PilotNet group in Holmdel, New Jersey. Here
we present a snapshot of system status in mid-2020 and highlight some of the
work done by the PilotNet group.",arxiv
http://arxiv.org/abs/2011.07393v1,2020-11-14T21:24:01Z,2020-11-14T21:24:01Z,"11 TeraFLOPs per second photonic convolutional accelerator for deep
  learning optical neural networks","Convolutional neural networks (CNNs), inspired by biological visual cortex
systems, are a powerful category of artificial neural networks that can extract
the hierarchical features of raw data to greatly reduce the network parametric
complexity and enhance the predicting accuracy. They are of significant
interest for machine learning tasks such as computer vision, speech
recognition, playing board games and medical diagnosis. Optical neural networks
offer the promise of dramatically accelerating computing speed to overcome the
inherent bandwidth bottleneck of electronics. Here, we demonstrate a universal
optical vector convolutional accelerator operating beyond 10 TeraFLOPS
(floating point operations per second), generating convolutions of images of
250,000 pixels with 8 bit resolution for 10 kernels simultaneously, enough for
facial image recognition. We then use the same hardware to sequentially form a
deep optical CNN with ten output neurons, achieving successful recognition of
full 10 digits with 900 pixel handwritten digit images with 88% accuracy. Our
results are based on simultaneously interleaving temporal, wavelength and
spatial dimensions enabled by an integrated microcomb source. This approach is
scalable and trainable to much more complex networks for demanding applications
such as unmanned vehicle and real-time video recognition.",arxiv
http://arxiv.org/abs/2105.06296v1,2021-05-12T05:22:32Z,2021-05-12T05:22:32Z,"Optical neuromorphic processing at Tera-OP/s speeds based on Kerr
  soliton crystal microcombs","Convolutional neural networks (CNNs), inspired by biological visual cortex
systems, are a powerful category of artificial neural networks that can extract
the hierarchical features of raw data to greatly reduce the network parametric
complexity and enhance the predicting accuracy. They are of significant
interest for machine learning tasks such as computer vision, speech
recognition, playing board games and medical diagnosis. Optical neural networks
offer the promise of dramatically accelerating computing speed to overcome the
inherent bandwidth bottleneck of electronics. Here, we demonstrate a universal
optical vector convolutional accelerator operating beyond 10 TeraOPS (TOPS:
operations per second), generating convolutions of images of 250,000 pixels
with 8 bit resolution for 10 kernels simultaneously, enough for facial image
recognition. We then use the same hardware to sequentially form a deep optical
CNN with ten output neurons, achieving successful recognition of full 10 digits
with 900 pixel handwritten digit images with 88% accuracy. Our results are
based on simultaneously interleaving temporal, wavelength and spatial
dimensions enabled by an integrated microcomb source. This approach is scalable
and trainable to much more complex networks for demanding applications such as
unmanned vehicle and real time video recognition.",arxiv
http://arxiv.org/abs/2008.07371v1,2020-07-20T22:23:50Z,2020-07-20T22:23:50Z,Artificial Intelligence is stupid and causal reasoning won't fix it,"Artificial Neural Networks have reached Grandmaster and even super-human
performance across a variety of games: from those involving perfect-information
(such as Go) to those involving imperfect-information (such as Starcraft). Such
technological developments from AI-labs have ushered concomitant applications
across the world of business - where an AI brand tag is fast becoming
ubiquitous. A corollary of such widespread commercial deployment is that when
AI gets things wrong - an autonomous vehicle crashes; a chatbot exhibits racist
behaviour; automated credit scoring processes discriminate on gender etc. -
there are often significant financial, legal and brand consequences and the
incident becomes major news. As Judea Pearl sees it, the underlying reason for
such mistakes is that, 'all the impressive achievements of deep learning amount
to just curve fitting'. The key, Judea Pearl suggests, is to replace reasoning
by association with causal-reasoning - the ability to infer causes from
observed phenomena. It is a point that was echoed by Gary Marcus and Ernest
Davis in a recent piece for the New York Times: 'we need to stop building
computer systems that merely get better and better at detecting statistical
patterns in data sets - often using an approach known as Deep Learning - and
start building computer systems that from the moment of their assembly innately
grasp three basic concepts: time, space and causality'. In this paper,
foregrounding what in 1949 Gilbert Ryle termed a category mistake, I will offer
an alternative explanation for AI errors: it is not so much that AI machinery
cannot grasp causality, but that AI machinery - qua computation - cannot
understand anything at all.",arxiv
http://arxiv.org/abs/2008.01302v1,2020-08-04T03:21:34Z,2020-08-04T03:21:34Z,"A Comparative Analysis of Deep Reinforcement Learning-enabled Freeway
  Decision-making for Automated Vehicles","Deep reinforcement learning (DRL) is becoming a prevalent and powerful
methodology to address the artificial intelligent problems. Owing to its
tremendous potentials in self-learning and self-improvement, DRL is broadly
serviced in many research fields. This article conducted a comprehensive
comparison of multiple DRL approaches on the freeway decision-making problem
for autonomous vehicles. These techniques include the common deep Q learning
(DQL), double DQL (DDQL), dueling DQL, and prioritized replay DQL. First, the
reinforcement learning (RL) framework is introduced. As an extension, the
implementations of the above mentioned DRL methods are established
mathematically. Then, the freeway driving scenario for the automated vehicles
is constructed, wherein the decision-making problem is transferred as a control
optimization problem. Finally, a series of simulation experiments are achieved
to evaluate the control performance of these DRL-enabled decision-making
strategies. A comparative analysis is realized to connect the autonomous
driving results with the learning characteristics of these DRL techniques.",arxiv
http://arxiv.org/abs/1906.10251v1,2019-06-24T22:12:48Z,2019-06-24T22:12:48Z,"Artificial Neural Network with Physical Dynamic Metasurface Layer for
  Optimal Sensing","We address the fundamental question of how to optimally probe a scene with
electromagnetic (EM) radiation to yield a maximum amount of information
relevant to a particular task. Machine learning (ML) techniques have emerged as
powerful tools to extract task-relevant information from a wide variety of EM
measurements, ranging from optics to the microwave domain. However, given the
ability to actively illuminate a particular scene with a programmable EM
wavefront, it is often not clear what wavefronts optimally encode information
for the task at hand (e.g., object detection, classification). Here, we show
that by integrating a physical model of scene illumination and detection into a
ML pipeline, we can jointly learn optimal sampling and measurement processing
strategies for a given task. We consider in simulation the example of
classifying objects using microwave radiation produced by dynamic metasurfaces.
By integrating an analytical forward model describing the metamaterial elements
as coupled dipoles into the ML pipeline, we jointly train analog model weights
with digital neural network weights. The learned non-intuitive illumination
settings yield a higher classification accuracy using fewer measurements. On
the practical level, these results are highly relevant to emerging
context-aware systems such as autonomous vehicles, touchless human-interactive
devices or within smart health care, where strict time constraints place severe
limits on measurement strategies. On the conceptual level, our work serves as a
bridge between wavefront shaping and tunable metasurface design on the physical
layer and ML techniques on the processing layer.",arxiv
http://arxiv.org/abs/2011.13098v1,2020-11-26T02:40:07Z,2020-11-26T02:40:07Z,"An End-to-end Deep Reinforcement Learning Approach for the Long-term
  Short-term Planning on the Frenet Space","Tactical decision making and strategic motion planning for autonomous highway
driving are challenging due to the complication of predicting other road users'
behaviors, diversity of environments, and complexity of the traffic
interactions. This paper presents a novel end-to-end continuous deep
reinforcement learning approach towards autonomous cars' decision-making and
motion planning. For the first time, we define both states and action spaces on
the Frenet space to make the driving behavior less variant to the road
curvatures than the surrounding actors' dynamics and traffic interactions. The
agent receives time-series data of past trajectories of the surrounding
vehicles and applies convolutional neural networks along the time channels to
extract features in the backbone. The algorithm generates continuous
spatiotemporal trajectories on the Frenet frame for the feedback controller to
track. Extensive high-fidelity highway simulations on CARLA show the
superiority of the presented approach compared with commonly used baselines and
discrete reinforcement learning on various traffic scenarios. Furthermore, the
proposed method's advantage is confirmed with a more comprehensive performance
evaluation against 1000 randomly generated test scenarios.",arxiv
http://arxiv.org/abs/2011.03635v1,2020-11-06T23:40:37Z,2020-11-06T23:40:37Z,Motion Prediction on Self-driving Cars: A Review,"The autonomous vehicle motion prediction literature is reviewed. Motion
prediction is the most challenging task in autonomous vehicles and self-drive
cars. These challenges have been discussed. Later on, the state-of-theart has
reviewed based on the most recent literature and the current challenges are
discussed. The state-of-the-art consists of classical and physical methods,
deep learning networks, and reinforcement learning. prons and cons of the
methods and gap of the research presented in this review. Finally, the
literature surrounding object tracking and motion will be presented. As a
result, deep reinforcement learning is the best candidate to tackle
self-driving cars.",arxiv
http://arxiv.org/abs/1904.00842v1,2019-03-29T11:50:13Z,2019-03-29T11:50:13Z,"Deep, spatially coherent Inverse Sensor Models with Uncertainty
  Incorporation using the evidential Framework","To perform high speed tasks, sensors of autonomous cars have to provide as
much information in as few time steps as possible. However, radars, one of the
sensor modalities autonomous cars heavily rely on, often only provide sparse,
noisy detections. These have to be accumulated over time to reach a high enough
confidence about the static parts of the environment. For radars, the state is
typically estimated by accumulating inverse detection models (IDMs). We employ
the recently proposed evidential convolutional neural networks which, in
contrast to IDMs, compute dense, spatially coherent inference of the
environment state. Moreover, these networks are able to incorporate sensor
noise in a principled way which we further extend to also incorporate model
uncertainty. We present experimental results that show This makes it possible
to obtain a denser environment perception in fewer time steps.",arxiv
http://arxiv.org/abs/1803.09719v4,2020-07-08T02:14:14Z,2018-03-26T17:19:40Z,"On the Importance of Stereo for Accurate Depth Estimation: An Efficient
  Semi-Supervised Deep Neural Network Approach","We revisit the problem of visual depth estimation in the context of
autonomous vehicles. Despite the progress on monocular depth estimation in
recent years, we show that the gap between monocular and stereo depth accuracy
remains large$-$a particularly relevant result due to the prevalent reliance
upon monocular cameras by vehicles that are expected to be self-driving. We
argue that the challenges of removing this gap are significant, owing to
fundamental limitations of monocular vision. As a result, we focus our efforts
on depth estimation by stereo. We propose a novel semi-supervised learning
approach to training a deep stereo neural network, along with a novel
architecture containing a machine-learned argmax layer and a custom runtime
(that will be shared publicly) that enables a smaller version of our stereo DNN
to run on an embedded GPU. Competitive results are shown on the KITTI 2015
stereo dataset. We also evaluate the recent progress of stereo algorithms by
measuring the impact upon accuracy of various design criteria.",arxiv
http://arxiv.org/abs/2003.08300v1,2020-03-18T15:56:10Z,2020-03-18T15:56:10Z,Vision-Based Autonomous Driving: A Model Learning Approach,"We present an integrated approach for perception and control for an
autonomous vehicle and demonstrate this approach in a high-fidelity urban
driving simulator. Our approach first builds a model for the environment, then
trains a policy exploiting the learned model to identify the action to take at
each time-step. To build a model for the environment, we leverage several deep
learning algorithms. To that end, first we train a variational autoencoder to
encode the input image into an abstract latent representation. We then utilize
a recurrent neural network to predict the latent representation of the next
frame and handle temporal information. Finally, we utilize an
evolutionary-based reinforcement learning algorithm to train a controller based
on these latent representations to identify the action to take. We evaluate our
approach in CARLA, a high-fidelity urban driving simulator, and conduct an
extensive generalization study. Our results demonstrate that our approach
outperforms several previously reported approaches in terms of the percentage
of successfully completed episodes for a lane keeping task.",arxiv
http://arxiv.org/abs/2108.07804v1,2021-08-18T14:06:08Z,2021-08-18T14:06:08Z,"A Framework for Understanding AI-Induced Field Change: How AI
  Technologies are Legitimized and Institutionalized","Artificial intelligence (AI) systems operate in increasingly diverse areas,
from healthcare to facial recognition, the stock market, autonomous vehicles,
and so on. While the underlying digital infrastructure of AI systems is
developing rapidly, each area of implementation is subject to different degrees
and processes of legitimization. By combining elements from institutional
theory and information systems-theory, this paper presents a conceptual
framework to analyze and understand AI-induced field-change. The introduction
of novel AI-agents into new or existing fields creates a dynamic in which
algorithms (re)shape organizations and institutions while existing
institutional infrastructures determine the scope and speed at which
organizational change is allowed to occur. Where institutional infrastructure
and governance arrangements, such as standards, rules, and regulations, still
are unelaborate, the field can move fast but is also more likely to be
contested. The institutional infrastructure surrounding AI-induced fields is
generally little elaborated, which could be an obstacle to the broader
institutionalization of AI-systems going forward.",arxiv
http://arxiv.org/abs/1810.01835v1,2018-10-03T16:36:22Z,2018-10-03T16:36:22Z,"Human-Centered Autonomous Vehicle Systems: Principles of Effective
  Shared Autonomy","Building effective, enjoyable, and safe autonomous vehicles is a lot harder
than has historically been considered. The reason is that, simply put, an
autonomous vehicle must interact with human beings. This interaction is not a
robotics problem nor a machine learning problem nor a psychology problem nor an
economics problem nor a policy problem. It is all of these problems put into
one. It challenges our assumptions about the limitations of human beings at
their worst and the capabilities of artificial intelligence systems at their
best. This work proposes a set of principles for designing and building
autonomous vehicles in a human-centered way that does not run away from the
complexity of human nature but instead embraces it. We describe our development
of the Human-Centered Autonomous Vehicle (HCAV) as an illustrative case study
of implementing these principles in practice.",arxiv
http://arxiv.org/abs/1905.10691v3,2020-10-21T14:27:24Z,2019-05-25T23:09:44Z,"Safe Reinforcement Learning with Nonlinear Dynamics via Model Predictive
  Shielding","Reinforcement learning is a promising approach to synthesizing policies for
challenging robotics tasks. A key problem is how to ensure safety of the
learned policy---e.g., that a walking robot does not fall over or that an
autonomous car does not run into an obstacle. We focus on the setting where the
dynamics are known, and the goal is to ensure that a policy trained in
simulation satisfies a given safety constraint. We propose an approach, called
model predictive shielding (MPS), that switches on-the-fly between a learned
policy and a backup policy to ensure safety. We prove that our approach
guarantees safety, and empirically evaluate it on the cart-pole.",arxiv
http://arxiv.org/abs/2007.08793v1,2020-07-17T07:36:27Z,2020-07-17T07:36:27Z,Towards Enabling Critical mMTC: A Review of URLLC within mMTC,"Massive machine-type communication (mMTC) and ultra-reliable and low-latency
communication (URLLC) are two key service types in the fifth-generation (5G)
communication systems, pursuing scalability and reliability with low-latency,
respectively. These two extreme services are envisaged to agglomerate together
into \emph{critical mMTC} shortly with emerging use cases (e.g., wide-area
disaster monitoring, wireless factory automation), creating new challenges to
designing wireless systems beyond 5G. While conventional network slicing is
effective in supporting a simple mixture of mMTC and URLLC, it is difficult to
simultaneously guarantee the reliability, latency, and scalability requirements
of critical mMTC (e.g., < 4ms latency, $10^6$ devices/km$^2$ for factory
automation) with limited radio resources. Furthermore, recently proposed
solutions to scalable URLLC (e.g., machine learning aided URLLC for driverless
vehicles) are ill-suited to critical mMTC whose machine type users have minimal
energy budget and computing capability that should be (tightly) optimized for
given tasks. To this end, our paper aims to characterize promising use cases of
critical mMTC and search for their possible solutions. To this end, we first
review the state-of-the-art (SOTA) technologies for separate mMTC and URLLC
services and then identify key challenges from conflicting SOTA requirements,
followed by potential approaches to prospective critical mMTC solutions at
different layers.",arxiv
http://arxiv.org/abs/1805.03183v2,2018-05-14T18:57:37Z,2018-05-08T17:34:31Z,Visual Global Localization with a Hybrid WNN-CNN Approach,"Currently, self-driving cars rely greatly on the Global Positioning System
(GPS) infrastructure, albeit there is an increasing demand for alternative
methods for GPS-denied environments. One of them is known as place recognition,
which associates images of places with their corresponding positions. We
previously proposed systems based on Weightless Neural Networks (WNN) to
address this problem as a classification task. This encompasses solely one part
of the global localization, which is not precise enough for driverless cars.
Instead of just recognizing past places and outputting their poses, it is
desired that a global localization system estimates the pose of current place
images. In this paper, we propose to tackle this problem as follows. Firstly,
given a live image, the place recognition system returns the most similar image
and its pose. Then, given live and recollected images, a visual localization
system outputs the relative camera pose represented by those images. To
estimate the relative camera pose between the recollected and the current
images, a Convolutional Neural Network (CNN) is trained with the two images as
input and a relative pose vector as output. Together, these systems solve the
global localization problem using the topological and metric information to
approximate the current vehicle pose. The full approach is compared to a Real-
Time Kinematic GPS system and a Simultaneous Localization and Mapping (SLAM)
system. Experimental results show that the proposed approach correctly
localizes a vehicle 90% of the time with a mean error of 1.20m compared to
1.12m of the SLAM system and 0.37m of the GPS, 89% of the time.",arxiv
http://arxiv.org/abs/1907.08985v2,2020-02-08T22:59:03Z,2019-07-21T15:16:12Z,"Achieving Super-Linear Speedup across Multi-FPGA for Real-Time DNN
  Inference","Real-time Deep Neural Network (DNN) inference with low-latency requirement
has become increasingly important for numerous applications in both cloud
computing (e.g., Apple's Siri) and edge computing (e.g., Google/Waymo's
driverless car). FPGA-based DNN accelerators have demonstrated both superior
flexibility and performance; in addition, for real-time inference with low
batch size, FPGA is expected to achieve further performance improvement.
However, the performance gain from the single-FPGA design is obstructed by the
limited on-chip resource. In this paper, we employ multiple FPGAs to
cooperatively run DNNs with the objective of achieving super-linear speed-up
against single-FPGA design. In implementing such systems, we found two barriers
that hinder us from achieving the design goal: (1) the lack of a clear
partition scheme for each DNN layer to fully exploit parallelism, and (2) the
insufficient bandwidth between the off-chip memory and the accelerator due to
the growing size of DNNs. To tackle these issues, we propose a general
framework, ""Super-LIP"", which can support different kinds of DNNs. In this
paper, we take Convolutional Neural Network (CNN) as a vehicle to illustrate
Super-LIP. We first formulate an accurate system-level model to support the
exploration of best partition schemes. Then, we develop a novel design
methodology to effectively alleviate the heavy loads on memory bandwidth by
moving traffic from memory bus to inter-FPGA links. We implement Super-LIP
based on ZCU102 FPGA boards. Results demonstrate that Super-LIP with 2 FPGAs
can achieve 3.48x speedup, compared to the state-of-the-art single-FPGA design.
What is more, as the number of FPGAs scales up, the system latency can be
further reduced while maintaining high energy efficiency.",arxiv
http://arxiv.org/abs/1707.03501v1,2017-07-12T00:09:50Z,2017-07-12T00:09:50Z,"NO Need to Worry about Adversarial Examples in Object Detection in
  Autonomous Vehicles","It has been shown that most machine learning algorithms are susceptible to
adversarial perturbations. Slightly perturbing an image in a carefully chosen
direction in the image space may cause a trained neural network model to
misclassify it. Recently, it was shown that physical adversarial examples
exist: printing perturbed images then taking pictures of them would still
result in misclassification. This raises security and safety concerns.
  However, these experiments ignore a crucial property of physical objects: the
camera can view objects from different distances and at different angles. In
this paper, we show experiments that suggest that current constructions of
physical adversarial examples do not disrupt object detection from a moving
platform. Instead, a trained neural network classifies most of the pictures
taken from different distances and angles of a perturbed image correctly. We
believe this is because the adversarial property of the perturbation is
sensitive to the scale at which the perturbed picture is viewed, so (for
example) an autonomous car will misclassify a stop sign only from a small range
of distances.
  Our work raises an important question: can one construct examples that are
adversarial for many or most viewing conditions? If so, the construction should
offer very significant insights into the internal representation of patterns by
deep networks. If not, there is a good prospect that adversarial examples can
be reduced to a curiosity with little practical impact.",arxiv
http://arxiv.org/abs/2003.06917v2,2020-08-16T16:47:40Z,2020-03-15T20:30:16Z,End-to-End Velocity Estimation For Autonomous Racing,"Velocity estimation plays a central role in driverless vehicles, but standard
and affordable methods struggle to cope with extreme scenarios like aggressive
maneuvers due to the presence of high sideslip. To solve this, autonomous race
cars are usually equipped with expensive external velocity sensors. In this
paper, we present an end-to-end recurrent neural network that takes available
raw sensors as input (IMU, wheel odometry, and motor currents) and outputs
velocity estimates. The results are compared to two state-of-the-art Kalman
filters, which respectively include and exclude expensive velocity sensors. All
methods have been extensively tested on a formula student driverless race car
with very high sideslip (10{\deg} at the rear axle) and slip ratio (~20%),
operating close to the limits of handling. The proposed network is able to
estimate lateral velocity up to 15x better than the Kalman filter with the
equivalent sensor input and matches (0.06 m/s RMSE) the Kalman filter with the
expensive velocity sensor setup.",arxiv
http://arxiv.org/abs/2103.09726v1,2021-03-17T15:30:36Z,2021-03-17T15:30:36Z,"Weakly Supervised Reinforcement Learning for Autonomous Highway Driving
  via Virtual Safety Cages","The use of neural networks and reinforcement learning has become increasingly
popular in autonomous vehicle control. However, the opaqueness of the resulting
control policies presents a significant barrier to deploying neural
network-based control in autonomous vehicles. In this paper, we present a
reinforcement learning based approach to autonomous vehicle longitudinal
control, where the rule-based safety cages provide enhanced safety for the
vehicle as well as weak supervision to the reinforcement learning agent. By
guiding the agent to meaningful states and actions, this weak supervision
improves the convergence during training and enhances the safety of the final
trained policy. This rule-based supervisory controller has the further
advantage of being fully interpretable, thereby enabling traditional validation
and verification approaches to ensure the safety of the vehicle. We compare
models with and without safety cages, as well as models with optimal and
constrained model parameters, and show that the weak supervision consistently
improves the safety of exploration, speed of convergence, and model
performance. Additionally, we show that when the model parameters are
constrained or sub-optimal, the safety cages can enable a model to learn a safe
driving policy even when the model could not be trained to drive through
reinforcement learning alone.",arxiv
http://arxiv.org/abs/1407.5197v2,2016-08-25T16:24:26Z,2014-07-19T15:04:44Z,"Design and Autonomous Control of the Active Adaptive Suspension System
  Rudra Mars Rover","Semi or completely autonomous unmanned vehicles, remotely driven or
controlled through artificial intelligence, are instrumental to foster space
exploration. One of the most essential tasks of a rover is terrain traversing
which requires the need of efficient suspension systems. This communication
presents a suspension system giving degrees of freedom to every wheel with the
help of linear actuators connected through bell crank levers. The actuation of
linear actuators directly varies the height of every wheel from the chassis
hence offering articulation to the rover. A control system is developed
offering an algorithm for its autonomous actuation. This system proves
instrumental for leveling of the chassis where any kind of slope, roll or
pitch, may impute abstaining of payloads from efficient working. This was tried
and tested successfully as a part of the rover developed by Team RUDRA from SRM
University, INDIA (first Team from Asia and finishing at the fifth position) at
University Rover Challenge 2013, held at UTAH, USA in May-June.",arxiv
http://arxiv.org/abs/1707.03184v1,2017-07-11T09:15:46Z,2017-07-11T09:15:46Z,A Survey on Resilient Machine Learning,"Machine learning based system are increasingly being used for sensitive tasks
such as security surveillance, guiding autonomous vehicle, taking investment
decisions, detecting and blocking network intrusion and malware etc. However,
recent research has shown that machine learning models are venerable to attacks
by adversaries at all phases of machine learning (eg, training data collection,
training, operation). All model classes of machine learning systems can be
misled by providing carefully crafted inputs making them wrongly classify
inputs. Maliciously created input samples can affect the learning process of a
ML system by either slowing down the learning process, or affecting the
performance of the learned mode, or causing the system make error(s) only in
attacker's planned scenario. Because of these developments, understanding
security of machine learning algorithms and systems is emerging as an important
research area among computer security and machine learning researchers and
practitioners. We present a survey of this emerging area in machine learning.",arxiv
http://arxiv.org/abs/2107.04991v1,2021-07-11T08:31:15Z,2021-07-11T08:31:15Z,"Prediction Surface Uncertainty Quantification in Object Detection Models
  for Autonomous Driving","Object detection in autonomous cars is commonly based on camera images and
Lidar inputs, which are often used to train prediction models such as deep
artificial neural networks for decision making for object recognition,
adjusting speed, etc. A mistake in such decision making can be damaging; thus,
it is vital to measure the reliability of decisions made by such prediction
models via uncertainty measurement. Uncertainty, in deep learning models, is
often measured for classification problems. However, deep learning models in
autonomous driving are often multi-output regression models. Hence, we propose
a novel method called PURE (Prediction sURface uncErtainty) for measuring
prediction uncertainty of such regression models. We formulate the object
recognition problem as a regression model with more than one outputs for
finding object locations in a 2-dimensional camera view. For evaluation, we
modified three widely-applied object recognition models (i.e., YoLo, SSD300 and
SSD512) and used the KITTI, Stanford Cars, Berkeley DeepDrive, and NEXET
datasets. Results showed the statistically significant negative correlation
between prediction surface uncertainty and prediction accuracy suggesting that
uncertainty significantly impacts the decisions made by autonomous driving.",arxiv
http://arxiv.org/abs/2010.16285v1,2020-10-30T14:16:39Z,2020-10-30T14:16:39Z,All-Weather Object Recognition Using Radar and Infrared Sensing,"Autonomous cars are an emergent technology which has the capacity to change
human lives. The current sensor systems which are most capable of perception
are based on optical sensors. For example, deep neural networks show
outstanding results in recognising objects when used to process data from
cameras and Light Detection And Ranging (LiDAR) sensors. However these sensors
perform poorly under adverse weather conditions such as rain, fog, and snow due
to the sensor wavelengths. This thesis explores new sensing developments based
on long wave polarised infrared (IR) imagery and imaging radar to recognise
objects. First, we developed a methodology based on Stokes parameters using
polarised infrared data to recognise vehicles using deep neural networks.
Second, we explored the potential of using only the power spectrum captured by
low-THz radar sensors to perform object recognition in a controlled scenario.
This latter work is based on a data-driven approach together with the
development of a data augmentation method based on attenuation, range and
speckle noise. Last, we created a new large-scale dataset in the ""wild"" with
many different weather scenarios (sunny, overcast, night, fog, rain and snow)
showing radar robustness to detect vehicles in adverse weather. High resolution
radar and polarised IR imagery, combined with a deep learning approach, are
shown as a potential alternative to current automotive sensing systems based on
visible spectrum optical technology as they are more robust in severe weather
and adverse light conditions.",arxiv
http://arxiv.org/abs/1604.08275v1,2016-04-28T00:35:32Z,2016-04-28T00:35:32Z,Crafting Adversarial Input Sequences for Recurrent Neural Networks,"Machine learning models are frequently used to solve complex security
problems, as well as to make decisions in sensitive situations like guiding
autonomous vehicles or predicting financial market behaviors. Previous efforts
have shown that numerous machine learning models were vulnerable to adversarial
manipulations of their inputs taking the form of adversarial samples. Such
inputs are crafted by adding carefully selected perturbations to legitimate
inputs so as to force the machine learning model to misbehave, for instance by
outputting a wrong class if the machine learning task of interest is
classification. In fact, to the best of our knowledge, all previous work on
adversarial samples crafting for neural network considered models used to solve
classification tasks, most frequently in computer vision applications. In this
paper, we contribute to the field of adversarial machine learning by
investigating adversarial input sequences for recurrent neural networks
processing sequential data. We show that the classes of algorithms introduced
previously to craft adversarial samples misclassified by feed-forward neural
networks can be adapted to recurrent neural networks. In a experiment, we show
that adversaries can craft adversarial sequences misleading both categorical
and sequential recurrent neural networks.",arxiv
http://arxiv.org/abs/1802.09354v1,2018-02-22T13:20:19Z,2018-02-22T13:20:19Z,"Low Intensity LiDAR using Compressed Sensing and a Photon Number
  Resolving Detector","LiDAR (laser based radar) systems are a major part of many new real-world
interactive systems, one of the most notable being autonomous cars. The current
market LiDAR systems are limited by detector sensitivity: when output power is
at eye-safe levels, the range is limited. Long range operation also slows image
acquisition as flight-time increases. We present an approach that combines a
high sensitivity photon number resolving diode with machine learning and a
micro-mechanical digital mirror device to achieve safe and fast long range 3D
scanning.",arxiv
http://arxiv.org/abs/1711.05934v1,2017-11-16T05:37:14Z,2017-11-16T05:37:14Z,Enhanced Attacks on Defensively Distilled Deep Neural Networks,"Deep neural networks (DNNs) have achieved tremendous success in many tasks of
machine learning, such as the image classification. Unfortunately, researchers
have shown that DNNs are easily attacked by adversarial examples, slightly
perturbed images which can mislead DNNs to give incorrect classification
results. Such attack has seriously hampered the deployment of DNN systems in
areas where security or safety requirements are strict, such as autonomous
cars, face recognition, malware detection. Defensive distillation is a
mechanism aimed at training a robust DNN which significantly reduces the
effectiveness of adversarial examples generation. However, the state-of-the-art
attack can be successful on distilled networks with 100% probability. But it is
a white-box attack which needs to know the inner information of DNN. Whereas,
the black-box scenario is more general. In this paper, we first propose the
epsilon-neighborhood attack, which can fool the defensively distilled networks
with 100% success rate in the white-box setting, and it is fast to generate
adversarial examples with good visual quality. On the basis of this attack, we
further propose the region-based attack against defensively distilled DNNs in
the black-box setting. And we also perform the bypass attack to indirectly
break the distillation defense as a complementary method. The experimental
results show that our black-box attacks have a considerable success rate on
defensively distilled networks.",arxiv
http://arxiv.org/abs/1809.09310v2,2019-06-21T01:12:24Z,2018-09-25T03:57:00Z,Scenic: A Language for Scenario Specification and Scene Generation,"We propose a new probabilistic programming language for the design and
analysis of perception systems, especially those based on machine learning.
Specifically, we consider the problems of training a perception system to
handle rare events, testing its performance under different conditions, and
debugging failures. We show how a probabilistic programming language can help
address these problems by specifying distributions encoding interesting types
of inputs and sampling these to generate specialized training and test sets.
More generally, such languages can be used for cyber-physical systems and
robotics to write environment models, an essential prerequisite to any formal
analysis. In this paper, we focus on systems like autonomous cars and robots,
whose environment is a ""scene"", a configuration of physical objects and agents.
We design a domain-specific language, Scenic, for describing ""scenarios"" that
are distributions over scenes. As a probabilistic programming language, Scenic
allows assigning distributions to features of the scene, as well as
declaratively imposing hard and soft constraints over the scene. We develop
specialized techniques for sampling from the resulting distribution, taking
advantage of the structure provided by Scenic's domain-specific syntax.
Finally, we apply Scenic in a case study on a convolutional neural network
designed to detect cars in road images, improving its performance beyond that
achieved by state-of-the-art synthetic data generation methods.",arxiv
http://arxiv.org/abs/1906.10044v2,2019-06-25T11:07:24Z,2019-06-24T16:07:52Z,"Complex Signal Denoising and Interference Mitigation for Automotive
  Radar Using Convolutional Neural Networks","Driver assistance systems as well as autonomous cars have to rely on sensors
to perceive their environment. A heterogeneous set of sensors is used to
perform this task robustly. Among them, radar sensors are indispensable because
of their range resolution and the possibility to directly measure velocity.
Since more and more radar sensors are deployed on the streets, mutual
interference must be dealt with. In the so far unregulated automotive radar
frequency band, a sensor must be capable of detecting, or even mitigating the
harmful effects of interference, which include a decreased detection
sensitivity. In this paper, we address this issue with Convolutional Neural
Networks (CNNs), which are state-of-the-art machine learning tools. We show
that the ability of CNNs to find structured information in data while
preserving local information enables superior denoising performance. To achieve
this, CNN parameters are found using training with simulated data and
integrated into the automotive radar signal processing chain. The presented
method is compared with the state of the art, highlighting its promising
performance. Hence, CNNs can be employed for interference mitigation as an
alternative to conventional signal processing methods. Code and pre-trained
models are available at https://github.com/johanna-rock/imRICnn.",arxiv
http://arxiv.org/abs/2010.06580v1,2020-10-13T17:58:31Z,2020-10-13T17:58:31Z,Scenic: A Language for Scenario Specification and Data Generation,"We propose a new probabilistic programming language for the design and
analysis of cyber-physical systems, especially those based on machine learning.
Specifically, we consider the problems of training a system to be robust to
rare events, testing its performance under different conditions, and debugging
failures. We show how a probabilistic programming language can help address
these problems by specifying distributions encoding interesting types of
inputs, then sampling these to generate specialized training and test data.
More generally, such languages can be used to write environment models, an
essential prerequisite to any formal analysis. In this paper, we focus on
systems like autonomous cars and robots, whose environment at any point in time
is a 'scene', a configuration of physical objects and agents. We design a
domain-specific language, Scenic, for describing scenarios that are
distributions over scenes and the behaviors of their agents over time. As a
probabilistic programming language, Scenic allows assigning distributions to
features of the scene, as well as declaratively imposing hard and soft
constraints over the scene. We develop specialized techniques for sampling from
the resulting distribution, taking advantage of the structure provided by
Scenic's domain-specific syntax. Finally, we apply Scenic in a case study on a
convolutional neural network designed to detect cars in road images, improving
its performance beyond that achieved by state-of-the-art synthetic data
generation methods.",arxiv
http://arxiv.org/abs/2106.05997v2,2021-09-16T17:42:34Z,2021-06-10T18:27:45Z,Verifying Quantized Neural Networks using SMT-Based Model Checking,"Artificial Neural Networks (ANNs) are being deployed for an increasing number
of safety-critical applications, including autonomous cars and medical
diagnosis. However, concerns about their reliability have been raised due to
their black-box nature and apparent fragility to adversarial attacks. These
concerns are amplified when ANNs are deployed on restricted system, which limit
the precision of mathematical operations and thus introduce additional
quantization errors. Here, we develop and evaluate a novel symbolic
verification framework using software model checking (SMC) and satisfiability
modulo theories (SMT) to check for vulnerabilities in ANNs. More specifically,
we propose several ANN-related optimizations for SMC, including invariant
inference via interval analysis, slicing, expression simplifications, and
discretization of non-linear activation functions. With this verification
framework, we can provide formal guarantees on the safe behavior of ANNs
implemented both in floating- and fixed-point arithmetic. In this regard, our
verification approach was able to verify and produce adversarial examples for
$52$ test cases spanning image classification and general machine learning
applications. Furthermore, for small- to medium-sized ANN, our approach
completes most of its verification runs in minutes. Moreover, in contrast to
most state-of-the-art methods, our approach is not restricted to specific
choices regarding activation functions and non-quantized representations. Our
experiments show that our approach can analyze larger ANN implementations and
substantially reduce the verification time compared to state-of-the-art
techniques that use SMT solving.",arxiv
http://arxiv.org/abs/2102.02326v1,2021-02-03T23:04:38Z,2021-02-03T23:04:38Z,"Effects of Number of Filters of Convolutional Layers on Speech
  Recognition Model Accuracy","Inspired by the progress of the End-to-End approach [1], this paper
systematically studies the effects of Number of Filters of convolutional layers
on the model prediction accuracy of CNN+RNN (Convolutional Neural Networks
adding to Recurrent Neural Networks) for ASR Models (Automatic Speech
Recognition). Experimental results show that only when the CNN Number of
Filters exceeds a certain threshold value is adding CNN to RNN able to improve
the performance of the CNN+RNN speech recognition model, otherwise some
parameter ranges of CNN can render it useless to add the CNN to the RNN model.
Our results show a strong dependency of word accuracy on the Number of Filters
of convolutional layers. Based on the experimental results, the paper suggests
a possible hypothesis of Sound-2-Vector Embedding (Convolutional Embedding) to
explain the above observations.
  Based on this Embedding hypothesis and the optimization of parameters, the
paper develops an End-to-End speech recognition system which has a high word
accuracy but also has a light model-weight. The developed LVCSR (Large
Vocabulary Continuous Speech Recognition) model has achieved quite a high word
accuracy of 90.2% only by its Acoustic Model alone, without any assistance from
intermediate phonetic representation and any Language Model. Its acoustic model
contains only 4.4 million weight parameters, compared to the 35~68 million
acoustic-model weight parameters in DeepSpeech2 [2] (one of the top
state-of-the-art LVCSR models) which can achieve a word accuracy of 91.5%. The
light-weighted model is good for improving the transcribing computing
efficiency and also useful for mobile devices, Driverless Vehicles, etc. Our
model weight is reduced to ~10% the size of DeepSpeech2, but our model accuracy
remains close to that of DeepSpeech2. If combined with a Language Model, our
LVCSR system is able to achieve 91.5% word accuracy.",arxiv
http://arxiv.org/abs/2007.11102v1,2020-07-21T21:33:26Z,2020-07-21T21:33:26Z,"Fully Convolutional Neural Networks for Automotive Radar Interference
  Mitigation","The interest of the automotive industry has progressively focused on subjects
related to driver assistance systems as well as autonomous cars. Cars combine a
variety of sensors to perceive their surroundings robustly. Among them, radar
sensors are indispensable because of their independence of lighting conditions
and the possibility to directly measure velocity. However, radar interference
is an issue that becomes prevalent with the increasing amount of radar systems
in automotive scenarios. In this paper, we address this issue for frequency
modulated continuous wave (FMCW) radars with fully convolutional neural
networks (FCNs), a state-of-the-art deep learning technique. We propose two
FCNs that take spectrograms of the beat signals as input, and provide the
corresponding clean range profiles as output. We propose two architectures for
interference mitigation which outperform the classical zeroing technique.
Moreover, considering the lack of databases for this task, we release as open
source a large scale data set that closely replicates real world automotive
scenarios for single-interference cases, allowing others to objectively compare
their future work in this domain. The data set is available for download at:
http://github.com/ristea/arim.",arxiv
http://arxiv.org/abs/1806.02952v1,2018-06-08T02:50:19Z,2018-06-08T02:50:19Z,RGCNN: Regularized Graph CNN for Point Cloud Segmentation,"Point cloud, an efficient 3D object representation, has become popular with
the development of depth sensing and 3D laser scanning techniques. It has
attracted attention in various applications such as 3D tele-presence,
navigation for unmanned vehicles and heritage reconstruction. The understanding
of point clouds, such as point cloud segmentation, is crucial in exploiting the
informative value of point clouds for such applications. Due to the
irregularity of the data format, previous deep learning works often convert
point clouds to regular 3D voxel grids or collections of images before feeding
them into neural networks, which leads to voluminous data and quantization
artifacts. In this paper, we instead propose a regularized graph convolutional
neural network (RGCNN) that directly consumes point clouds. Leveraging on
spectral graph theory, we treat features of points in a point cloud as signals
on graph, and define the convolution over graph by Chebyshev polynomial
approximation. In particular, we update the graph Laplacian matrix that
describes the connectivity of features in each layer according to the
corresponding learned features, which adaptively captures the structure of
dynamic graphs. Further, we deploy a graph-signal smoothness prior in the loss
function, thus regularizing the learning process. Experimental results on the
ShapeNet part dataset show that the proposed approach significantly reduces the
computational complexity while achieving competitive performance with the state
of the art. Also, experiments show RGCNN is much more robust to both noise and
point cloud density in comparison with other methods. We further apply RGCNN to
point cloud classification and achieve competitive results on ModelNet40
dataset.",arxiv
http://arxiv.org/abs/1911.02703v1,2019-11-07T01:23:37Z,2019-11-07T01:23:37Z,"Fuzzy Logic based Autonomous Parking Systems -- Part IV: A
  Multiple-Model Adaptive Neural-Fuzzy Controller","In this paper, a Multiple Models Adaptive Fuzzy Logic Controller (MM-AFLC)
with Neural Network Identification is designed to control the unmanned vehicle
in Intelligent Autonomous Parking System. The objective is to achieve robust
control while maintaining a low implementation cost. The proposed controller
design incorporates the following control theorems -- non-linear system
identification using neural network, fuzzy logic control, adaptive control as
well as multiple models adaptation. Such integration ensures superior
performance compared to previous work. The generalized controller can be
applied to different systems without prior knowledge of the actual plant model.
In the intelligent autonomous parking system, the proposed controller can be
used for both vehicle speed control and steering wheel turning. With a multiple
model adaptive fuzzy logic controller, robustness can be also assured under
various operating environments regardless of unpredictable disturbances. Last
but not least, comparative experiments have also demonstrated that systems
equipped with the new controller are able to achieve faster and smoother
convergence.",arxiv
http://arxiv.org/abs/2003.08034v1,2020-03-18T04:00:47Z,2020-03-18T04:00:47Z,"Generating Socially Acceptable Perturbations for Efficient Evaluation of
  Autonomous Vehicles","Deep reinforcement learning methods have been widely used in recent years for
autonomous vehicle's decision-making. A key issue is that deep neural networks
can be fragile to adversarial attacks or other unseen inputs. In this paper, we
address the latter issue: we focus on generating socially acceptable
perturbations (SAP), so that the autonomous vehicle (AV agent), instead of the
challenging vehicle (attacker), is primarily responsible for the crash. In our
process, one attacker is added to the environment and trained by deep
reinforcement learning to generate the desired perturbation. The reward is
designed so that the attacker aims to fail the AV agent in a socially
acceptable way. After training the attacker, the agent policy is evaluated in
both the original naturalistic environment and the environment with one
attacker. The results show that the agent policy which is safe in the
naturalistic environment has many crashes in the perturbed environment.",arxiv
http://arxiv.org/abs/1903.03438v1,2019-03-03T19:37:26Z,2019-03-03T19:37:26Z,"Towards a Framework to Manage Perceptual Uncertainty for Safe Automated
  Driving","Perception is a safety-critical function of autonomous vehicles and machine
learning (ML) plays a key role in its implementation. This position paper
identifies (1) perceptual uncertainty as a performance measure used to define
safety requirements and (2) its influence factors when using supervised ML.
This work is a first step towards a framework for measuring and controling the
effects of these factors and supplying evidence to support claims about
perceptual uncertainty.",arxiv
http://arxiv.org/abs/1804.10662v1,2018-04-27T19:45:54Z,2018-04-27T19:45:54Z,Mapping Road Lanes Using Laser Remission and Deep Neural Networks,"We propose the use of deep neural networks (DNN) for solving the problem of
inferring the position and relevant properties of lanes of urban roads with
poor or absent horizontal signalization, in order to allow the operation of
autonomous cars in such situations. We take a segmentation approach to the
problem and use the Efficient Neural Network (ENet) DNN for segmenting LiDAR
remission grid maps into road maps. We represent road maps using what we called
road grid maps. Road grid maps are square matrixes and each element of these
matrixes represents a small square region of real-world space. The value of
each element is a code associated with the semantics of the road map. Our road
grid maps contain all information about the roads' lanes required for building
the Road Definition Data Files (RDDFs) that are necessary for the operation of
our autonomous car, IARA (Intelligent Autonomous Robotic Automobile). We have
built a dataset of tens of kilometers of manually marked road lanes and used
part of it to train ENet to segment road grid maps from remission grid maps.
After being trained, ENet achieved an average segmentation accuracy of 83.7%.
We have tested the use of inferred road grid maps in the real world using IARA
on a stretch of 3.7 km of urban roads and it has shown performance equivalent
to that of the previous IARA's subsystem that uses a manually generated RDDF.",arxiv
http://arxiv.org/abs/2106.04823v1,2021-06-09T05:56:42Z,2021-06-09T05:56:42Z,Practical Machine Learning Safety: A Survey and Primer,"The open-world deployment of Machine Learning (ML) algorithms in
safety-critical applications such as autonomous vehicles needs to address a
variety of ML vulnerabilities such as interpretability, verifiability, and
performance limitations. Research explores different approaches to improve ML
dependability by proposing new models and training techniques to reduce
generalization error, achieve domain adaptation, and detect outlier examples
and adversarial attacks. In this paper, we review and organize practical ML
techniques that can improve the safety and dependability of ML algorithms and
therefore ML-based software. Our organization maps state-of-the-art ML
techniques to safety strategies in order to enhance the dependability of the ML
algorithm from different aspects, and discuss research gaps as well as
promising solutions.",arxiv
http://arxiv.org/abs/1709.04574v1,2017-09-14T01:27:44Z,2017-09-14T01:27:44Z,"Towards personalized human AI interaction - adapting the behavior of AI
  agents using neural signatures of subjective interest","Reinforcement Learning AI commonly uses reward/penalty signals that are
objective and explicit in an environment -- e.g. game score, completion time,
etc. -- in order to learn the optimal strategy for task performance. However,
Human-AI interaction for such AI agents should include additional reinforcement
that is implicit and subjective -- e.g. human preferences for certain AI
behavior -- in order to adapt the AI behavior to idiosyncratic human
preferences. Such adaptations would mirror naturally occurring processes that
increase trust and comfort during social interactions. Here, we show how a
hybrid brain-computer-interface (hBCI), which detects an individual's level of
interest in objects/events in a virtual environment, can be used to adapt the
behavior of a Deep Reinforcement Learning AI agent that is controlling a
virtual autonomous vehicle. Specifically, we show that the AI learns a driving
strategy that maintains a safe distance from a lead vehicle, and most novelly,
preferentially slows the vehicle when the human passengers of the vehicle
encounter objects of interest. This adaptation affords an additional 20\%
viewing time for subjectively interesting objects. This is the first
demonstration of how an hBCI can be used to provide implicit reinforcement to
an AI agent in a way that incorporates user preferences into the control
system.",arxiv
http://arxiv.org/abs/2104.00859v1,2021-04-02T02:39:53Z,2021-04-02T02:39:53Z,An NCAP-like Safety Indicator for Self-Driving Cars,"This paper proposes a mechanism to assess the safety of autonomous cars. It
assesses the car's safety in scenarios where the car must avoid collision with
an adversary. Core to this mechanism is a safety measure, called Safe-Kamikaze
Distance (SKD), which computes the average similarity between sets of safe
adversary's trajectories and kamikaze trajectories close to the safe
trajectories. The kamikaze trajectories are generated based on planning under
uncertainty techniques, namely the Partially Observable Markov Decision
Processes, to account for the partially observed car policy from the point of
view of the adversary. We found that SKD is inversely proportional to the upper
bound on the probability that a small deformation changes a collision-free
trajectory of the adversary into a colliding one. We perform systematic tests
on a scenario where the adversary is a pedestrian crossing a single-lane road
in front of the car being assessed --which is, one of the scenarios in the
Euro-NCAP's Vulnerable Road User (VRU) tests on Autonomous Emergency Braking.
Simulation results on assessing cars with basic controllers and a test on a
Machine-Learning controller using a high-fidelity simulator indicates promising
results for SKD to measure the safety of autonomous cars. Moreover, the time
taken for each simulation test is under 11 seconds, enabling a sufficient
statistics to compute SKD from simulation to be generated on a quad-core
desktop in less than 25 minutes.",arxiv
http://arxiv.org/abs/1804.08597v1,2018-04-23T17:44:29Z,2018-04-23T17:44:29Z,Towards Symbolic Reinforcement Learning with Common Sense,"Deep Reinforcement Learning (deep RL) has made several breakthroughs in
recent years in applications ranging from complex control tasks in unmanned
vehicles to game playing. Despite their success, deep RL still lacks several
important capacities of human intelligence, such as transfer learning,
abstraction and interpretability. Deep Symbolic Reinforcement Learning (DSRL)
seeks to incorporate such capacities to deep Q-networks (DQN) by learning a
relevant symbolic representation prior to using Q-learning. In this paper, we
propose a novel extension of DSRL, which we call Symbolic Reinforcement
Learning with Common Sense (SRL+CS), offering a better balance between
generalization and specialization, inspired by principles of common sense when
assigning rewards and aggregating Q-values. Experiments reported in this paper
show that SRL+CS learns consistently faster than Q-learning and DSRL, achieving
also a higher accuracy. In the hardest case, where agents were trained in a
deterministic environment and tested in a random environment, SRL+CS achieves
nearly 100% average accuracy compared to DSRL's 70% and DQN's 50% accuracy. To
the best of our knowledge, this is the first case of near perfect zero-shot
transfer learning using Reinforcement Learning.",arxiv
http://arxiv.org/abs/1806.07987v2,2018-09-13T17:20:44Z,2018-06-20T21:12:43Z,"A Hierarchical Deep Architecture and Mini-Batch Selection Method For
  Joint Traffic Sign and Light Detection","Traffic light and sign detectors on autonomous cars are integral for road
scene perception. The literature is abundant with deep learning networks that
detect either lights or signs, not both, which makes them unsuitable for
real-life deployment due to the limited graphics processing unit (GPU) memory
and power available on embedded systems. The root cause of this issue is that
no public dataset contains both traffic light and sign labels, which leads to
difficulties in developing a joint detection framework. We present a deep
hierarchical architecture in conjunction with a mini-batch proposal selection
mechanism that allows a network to detect both traffic lights and signs from
training on separate traffic light and sign datasets. Our method solves the
overlapping issue where instances from one dataset are not labelled in the
other dataset. We are the first to present a network that performs joint
detection on traffic lights and signs. We measure our network on the
Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small
Traffic Lights benchmark for traffic light detection and show it outperforms
the existing Bosch Small Traffic light state-of-the-art method. We focus on
autonomous car deployment and show our network is more suitable than others
because of its low memory footprint and real-time image processing time.
Qualitative results can be viewed at https://youtu.be/_YmogPzBXOw",arxiv
http://arxiv.org/abs/1812.04082v1,2018-12-10T20:53:49Z,2018-12-10T20:53:49Z,"Visual Depth Mapping from Monocular Images using Recurrent Convolutional
  Neural Networks","A reliable sense-and-avoid system is critical to enabling safe autonomous
operation of unmanned aircraft. Existing sense-and-avoid methods often require
specialized sensors that are too large or power intensive for use on small
unmanned vehicles. This paper presents a method to estimate object distances
based on visual image sequences, allowing for the use of low-cost, on-board
monocular cameras as simple collision avoidance sensors. We present a deep
recurrent convolutional neural network and training method to generate depth
maps from video sequences. Our network is trained using simulated camera and
depth data generated with Microsoft's AirSim simulator. Empirically, we show
that our model achieves superior performance compared to models generated using
prior methods.We further demonstrate that the method can be used for
sense-and-avoid of obstacles in simulation.",arxiv
http://arxiv.org/abs/1709.07894v3,2018-02-08T00:07:15Z,2017-09-22T18:05:50Z,On Encoding Temporal Evolution for Real-time Action Prediction,"Anticipating future actions is a key component of intelligence, specifically
when it applies to real-time systems, such as robots or autonomous cars. While
recent works have addressed prediction of raw RGB pixel values, we focus on
anticipating the motion evolution in future video frames. To this end, we
construct dynamic images (DIs) by summarising moving pixels through a sequence
of future frames. We train a convolutional LSTMs to predict the next DIs based
on an unsupervised learning process, and then recognise the activity associated
with the predicted DI. We demonstrate the effectiveness of our approach on 3
benchmark action datasets showing that despite running on videos with complex
activities, our approach is able to anticipate the next human action with high
accuracy and obtain better results than the state-of-the-art methods.",arxiv
http://arxiv.org/abs/1901.05195v1,2019-01-16T09:43:39Z,2019-01-16T09:43:39Z,"GridSim: A Vehicle Kinematics Engine for Deep Neuroevolutionary Control
  in Autonomous Driving","Current state of the art solutions in the control of an autonomous vehicle
mainly use supervised end-to-end learning, or decoupled perception, planning
and action pipelines. Another possible solution is deep reinforcement learning,
but such a method requires that the agent interacts with its surroundings in a
simulated environment. In this paper we introduce GridSim, which is an
autonomous driving simulator engine running a car-like robot architecture to
generate occupancy grids from simulated sensors. We use GridSim to study the
performance of two deep learning approaches, deep reinforcement learning and
driving behavioral learning through genetic algorithms. The deep network
encodes the desired behavior in a two elements fitness function describing a
maximum travel distance and a maximum forward speed, bounded to a specific
interval. The algorithms are evaluated on simulated highways, curved roads and
inner-city scenarios, all including different driving limitations.",arxiv
http://arxiv.org/abs/2110.11573v1,2021-10-22T03:52:45Z,2021-10-22T03:52:45Z,"ModEL: A Modularized End-to-end Reinforcement Learning Framework for
  Autonomous Driving","Heated debates continue over the best autonomous driving framework. The
classic modular pipeline is widely adopted in the industry owing to its great
interpretability and stability, whereas the end-to-end paradigm has
demonstrated considerable simplicity and learnability along with the rise of
deep learning. We introduce a new modularized end-to-end reinforcement learning
framework (ModEL) for autonomous driving, which combines the merits of both
previous approaches. The autonomous driving stack of ModEL is decomposed into
perception, planning, and control module, leveraging scene understanding,
end-to-end reinforcement learning, and PID control respectively. Furthermore,
we build a fully functional autonomous vehicle to deploy this framework.
Through extensive simulation and real-world experiments, our framework has
shown great generalizability to various complicated scenarios and outperforms
the competing baselines.",arxiv
http://arxiv.org/abs/1709.02802v1,2017-09-08T06:34:44Z,2017-09-08T06:34:44Z,Towards Proving the Adversarial Robustness of Deep Neural Networks,"Autonomous vehicles are highly complex systems, required to function reliably
in a wide variety of situations. Manually crafting software controllers for
these vehicles is difficult, but there has been some success in using deep
neural networks generated using machine-learning. However, deep neural networks
are opaque to human engineers, rendering their correctness very difficult to
prove manually; and existing automated techniques, which were not designed to
operate on neural networks, fail to scale to large systems. This paper focuses
on proving the adversarial robustness of deep neural networks, i.e. proving
that small perturbations to a correctly-classified input to the network cannot
cause it to be misclassified. We describe some of our recent and ongoing work
on verifying the adversarial robustness of networks, and discuss some of the
open questions we have encountered and how they might be addressed.",arxiv
http://arxiv.org/abs/1804.00495v2,2019-09-18T23:51:54Z,2018-03-15T23:58:19Z,Transferable Pedestrian Motion Prediction Models at Intersections,"One desirable capability of autonomous cars is to accurately predict the
pedestrian motion near intersections for safe and efficient trajectory
planning. We are interested in developing transfer learning algorithms that can
be trained on the pedestrian trajectories collected at one intersection and yet
still provide accurate predictions of the trajectories at another, previously
unseen intersection. We first discussed the feature selection for transferable
pedestrian motion models in general. Following this discussion, we developed
one transferable pedestrian motion prediction algorithm based on Inverse
Reinforcement Learning (IRL) that infers pedestrian intentions and predicts
future trajectories based on observed trajectory. We evaluated our algorithm on
a dataset collected at two intersections, trained at one intersection and
tested at the other intersection. We used the accuracy of augmented
semi-nonnegative sparse coding (ASNSC), trained and tested at the same
intersection as a baseline. The result shows that the proposed algorithm
improves the baseline accuracy by 40% in the non-transfer task, and 16% in the
transfer task.",arxiv
http://arxiv.org/abs/1706.05904v2,2017-06-20T07:25:49Z,2017-06-19T12:40:30Z,Pedestrian Prediction by Planning using Deep Neural Networks,"Accurate traffic participant prediction is the prerequisite for collision
avoidance of autonomous vehicles. In this work, we predict pedestrians by
emulating their own motion planning. From online observations, we infer a
mixture density function for possible destinations. We use this result as the
goal states of a planning stage that performs motion prediction based on common
behavior patterns. The entire system is modeled as one monolithic neural
network and trained via inverse reinforcement learning. Experimental validation
on real world data shows the system's ability to predict both, destinations and
trajectories accurately.",arxiv
http://arxiv.org/abs/1911.07931v2,2020-05-21T02:32:29Z,2019-11-14T10:32:43Z,"CAGFuzz: Coverage-Guided Adversarial Generative Fuzzing Testing of Deep
  Learning Systems","Deep Learning systems (DL) based on Deep Neural Networks (DNNs) are more and
more used in various aspects of our life, including unmanned vehicles, speech
processing, and robotics. However, due to the limited dataset and the
dependence on manual labeling data, DNNs often fail to detect their erroneous
behaviors, which may lead to serious problems. Several approaches have been
proposed to enhance the input examples for testing DL systems. However, they
have the following limitations. First, they design and generate adversarial
examples from the perspective of model, which may cause low generalization
ability when they are applied to other models. Second, they only use surface
feature constraints to judge the difference between the adversarial example
generated and the original example. The deep feature constraints, which contain
high-level semantic information, such as image object category and scene
semantics are completely neglected. To address these two problems, in this
paper, we propose CAGFuzz, a Coverage-guided Adversarial Generative Fuzzing
testing approach, which generates adversarial examples for a targeted DNN to
discover its potential defects. First, we train an adversarial case generator
(AEG) from the perspective of general data set. Second, we extract the depth
features of the original and adversarial examples, and constrain the
adversarial examples by cosine similarity to ensure that the semantic
information of adversarial examples remains unchanged. Finally, we retrain
effective adversarial examples to improve neuron testing coverage rate. Based
on several popular data sets, we design a set of dedicated experiments to
evaluate CAGFuzz. The experimental results show that CAGFuzz can improve the
neuron coverage rate, detect hidden errors, and also improve the accuracy of
the target DNN.",arxiv
http://arxiv.org/abs/2109.13446v1,2021-09-28T02:50:17Z,2021-09-28T02:50:17Z,"Runtime Safety Assurance for Learning-enabled Control of Autonomous
  Driving Vehicles","Providing safety guarantees for Autonomous Vehicle (AV) systems with
machine-learning-based controllers remains a challenging issue. In this work,
we propose Simplex-Drive, a framework that can achieve runtime safety assurance
for machine-learning enabled controllers of AVs. The proposed Simplex-Drive
consists of an unverified Deep Reinforcement Learning (DRL)-based advanced
controller (AC) that achieves desirable performance in complex scenarios, a
Velocity-Obstacle (VO) based baseline safe controller (BC) with provably safety
guarantees, and a verified mode management unit that monitors the operation
status and switches the control authority between AC and BC based on
safety-related conditions. We provide a formal correctness proof of
Simplex-Drive and conduct a lane-changing case study in dense traffic
scenarios. The simulation experiment results demonstrate that Simplex-Drive can
always ensure operation safety without sacrificing control performance, even if
the DRL policy may lead to deviations from the safe status.",arxiv
http://arxiv.org/abs/1711.02079v1,2017-11-06T18:51:47Z,2017-11-06T18:51:47Z,"Cone Detection using a Combination of LiDAR and Vision-based Machine
  Learning","The classification and the position estimation of objects become more and
more relevant as the field of robotics is expanding in diverse areas of
society. In this Bachelor Thesis, we developed a cone detection algorithm for
an autonomous car using a LiDAR sensor and a colour camera. By evaluating
simple constraints, the LiDAR detection algorithm preselects cone candidates in
the 3 dimensional space. The candidates are projected into the image plane of
the colour camera and an image candidate is cropped out. A convolutional neural
networks classifies the image candidates as cone or not a cone. With the fusion
of the precise position estimation of the LiDAR sensor and the high
classification accuracy of a neural network, a reliable cone detection
algorithm was implemented. Furthermore, a path planning algorithm generates a
path around the detected cones. The final system detects cones even at higher
velocity and has the potential to drive fully autonomous around the cones.",arxiv
http://arxiv.org/abs/1909.10568v1,2019-09-23T18:41:28Z,2019-09-23T18:41:28Z,"Design of neural nonlinear PFC Controller to control speed of Autonomous
  Car","In this research, we are going to design a neural nonlinear predictive
functional controller (PFC) to achieve a reduced fuel consumption for a chosen
autonomous car walks according to a supplied speed trajectory on known roads.
We used a fitting neural network as a simple tool for modelling the car's
engine and control laws needed to calculate the suitable control commands
passed to the brakes and gas pedals' actuators. Independent model method and
constraints handling are used to provide controller robustness. We used MATLAB
Simulink and IPG CarMaker to design and test our PFC controller. The
performance of designed PFC controller is compared to the performance of a PI
controller which exists within IPG CarMaker simulator. Keywords :- Predictive
Functional Controller, Fuel Consumption, Neural Network, Independent Model,
Constraint Handling, PI Controller.",arxiv
http://arxiv.org/abs/1803.07170v2,2018-03-21T04:12:03Z,2018-03-19T21:20:56Z,"Blaming humans in autonomous vehicle accidents: Shared responsibility
  across levels of automation","When a semi-autonomous car crashes and harms someone, how are blame and
causal responsibility distributed across the human and machine drivers? In this
article, we consider cases in which a pedestrian was hit and killed by a car
being operated under shared control of a primary and a secondary driver. We
find that when only one driver makes an error, that driver receives the blame
and is considered causally responsible for the harm, regardless of whether that
driver is a machine or a human. However, when both drivers make errors in cases
of shared control between a human and a machine, the blame and responsibility
attributed to the machine is reduced. This finding portends a public
under-reaction to the malfunctioning AI components of semi-autonomous cars and
therefore has a direct policy implication: a bottom-up regulatory scheme (which
operates through tort law that is adjudicated through the jury system) could
fail to properly regulate the safety of shared-control vehicles; instead, a
top-down scheme (enacted through federal laws) may be called for.",arxiv
http://arxiv.org/abs/1904.08477v1,2019-04-17T19:58:45Z,2019-04-17T19:58:45Z,"A Game Theoretical Framework for the Evaluation of Unmanned Aircraft
  Systems Airspace Integration Concepts","Predicting the outcomes of integrating Unmanned Aerial Systems (UAS) into the
National Aerospace (NAS) is a complex problem which is required to be addressed
by simulation studies before allowing the routine access of UAS into the NAS.
This thesis focuses on providing 2D and 3D simulation frameworks using a game
theoretical methodology to evaluate integration concepts in scenarios where
manned and unmanned air vehicles co-exist. The fundamental gap in the
literature is that the models of interaction between manned and unmanned
vehicles are insufficient: a) they assume that pilot behavior is known a priori
and b) they disregard decision making processes. The contribution of this work
is to propose a modeling framework, in which, human pilot reactions are modeled
using reinforcement learning and a game theoretical concept called level-k
reasoning to fill this gap. The level-k reasoning concept is based on the
assumption that humans have various levels of decision making. Reinforcement
learning is a mathematical learning method that is rooted in human learning. In
this work, a classical and an approximate reinforcement learning (Neural Fitted
Q Iteration) methods are used to model time-extended decisions of pilots with
2D and 3D maneuvers. An analysis of UAS integration is conducted using example
scenarios in the presence of manned aircraft and fully autonomous UAS equipped
with sense and avoid algorithms.",arxiv
http://arxiv.org/abs/1909.05314v1,2019-09-11T19:10:07Z,2019-09-11T19:10:07Z,"ScieNet: Deep Learning with Spike-assisted Contextual Information
  Extraction","Deep neural networks (DNNs) provide high image classification accuracy, but
experience significant performance degradation when perturbation from various
sources are present in the input. The lack of resilience to input perturbations
makes DNN less reliable for systems interacting with physical world such as
autonomous vehicles, robotics, to name a few, where imperfect input is the
normal condition. We present a hybrid deep network architecture with
spike-assisted contextual information extraction (ScieNet). ScieNet integrates
unsupervised learning using spiking neural network (SNN) for unsupervised
contextual informationextraction with a back-end DNN trained for
classification. The integrated network demonstrates high resilience to input
perturbations without relying on prior training on perturbed inputs. We
demonstrate ScieNet with different back-end DNNs for image classification using
CIFAR dataset considering stochastic (noise) and structured (rain) input
perturbations. Experimental results demonstrate significant improvement in
accuracy on noisy and rainy images without prior training, while maintaining
state-of-the-art accuracy on clean images.",arxiv
http://arxiv.org/abs/2109.06783v1,2021-09-14T15:54:35Z,2021-09-14T15:54:35Z,"Learning to Navigate Intersections with Unsupervised Driver Trait
  Inference","Navigation through uncontrolled intersections is one of the key challenges
for autonomous vehicles. Identifying the subtle differences in hidden traits of
other drivers can bring significant benefits when navigating in such
environments. We propose an unsupervised method for inferring driver traits
such as driving styles from observed vehicle trajectories. We use a variational
autoencoder with recurrent neural networks to learn a latent representation of
traits without any ground truth trait labels. Then, we use this trait
representation to learn a policy for an autonomous vehicle to navigate through
a T-intersection with deep reinforcement learning. Our pipeline enables the
autonomous vehicle to adjust its actions when dealing with drivers of different
traits to ensure safety and efficiency. Our method demonstrates promising
performance and outperforms state-of-the-art baselines in the T-intersection
scenario.",arxiv
http://arxiv.org/abs/2101.03042v1,2021-01-08T14:43:58Z,2021-01-08T14:43:58Z,Towards a Robust and Trustworthy Machine Learning System Development,"Machine Learning (ML) technologies have been widely adopted in many mission
critical fields, such as cyber security, autonomous vehicle control,
healthcare, etc. to support intelligent decision-making. While ML has
demonstrated impressive performance over conventional methods in these
applications, concerns arose with respect to system resilience against
ML-specific security attacks and privacy breaches as well as the trust that
users have in these systems. In this article, firstly we present our recent
systematic and comprehensive survey on the state-of-the-art ML robustness and
trustworthiness technologies from a security engineering perspective, which
covers all aspects of secure ML system development including threat modeling,
common offensive and defensive technologies, privacy-preserving machine
learning, user trust in the context of machine learning, and empirical
evaluation for ML model robustness. Secondly, we then push our studies forward
above and beyond a survey by describing a metamodel we created that represents
the body of knowledge in a standard and visualized way for ML practitioners. We
further illustrate how to leverage the metamodel to guide a systematic threat
analysis and security design process in a context of generic ML system
development, which extends and scales up the classic process. Thirdly, we
propose future research directions motivated by our findings to advance the
development of robust and trustworthy ML systems. Our work differs from
existing surveys in this area in that, to the best of our knowledge, it is the
first of its kind of engineering effort to (i) explore the fundamental
principles and best practices to support robust and trustworthy ML system
development; and (ii) study the interplay of robustness and user trust in the
context of ML systems.",arxiv
http://arxiv.org/abs/1912.00074v1,2019-11-29T21:32:32Z,2019-11-29T21:32:32Z,"Quadratic Q-network for Learning Continuous Control for Autonomous
  Vehicles","Reinforcement Learning algorithms have recently been proposed to learn
time-sequential control policies in the field of autonomous driving. Direct
applications of Reinforcement Learning algorithms with discrete action space
will yield unsatisfactory results at the operational level of driving where
continuous control actions are actually required. In addition, the design of
neural networks often fails to incorporate the domain knowledge of the
targeting problem such as the classical control theories in our case. In this
paper, we propose a hybrid model by combining Q-learning and classic PID
(Proportion Integration Differentiation) controller for handling continuous
vehicle control problems under dynamic driving environment. Particularly,
instead of using a big neural network as Q-function approximation, we design a
Quadratic Q-function over actions with multiple simple neural networks for
finding optimal values within a continuous space. We also build an action
network based on the domain knowledge of the control mechanism of a PID
controller to guide the agent to explore optimal actions more efficiently.We
test our proposed approach in simulation under two common but challenging
driving situations, the lane change scenario and ramp merge scenario. Results
show that the autonomous vehicle agent can successfully learn a smooth and
efficient driving behavior in both situations.",arxiv
http://arxiv.org/abs/2009.13200v1,2020-09-28T10:30:09Z,2020-09-28T10:30:09Z,"The Development of Visualization Psychology Analysis Tools to Account
  for Trust","Defining trust is an important endeavor given its applicability to assessing
public mood to much of the innovation in the newly formed autonomous industry,
such as artificial intelligence (AI),medical bots, drones, autonomous vehicles,
and smart factories [19].Through developing a reliable index or means to
measure trust,this may have wide impact from fostering acceptance and adoption
of smart systems to informing policy makers about the public atmosphere and
willingness to adopt innovate change, and has been identified as an important
indicator in a recent UK policy brief [8].In this paper, we reflect on the
importance and potential impact of developing Visualization Psychology in the
context of solving definitions and policy decision making problems for complex
constructs such as ""trust"".",arxiv
http://arxiv.org/abs/1901.05203v1,2019-01-16T10:03:08Z,2019-01-16T10:03:08Z,"Deep Grid Net (DGN): A Deep Learning System for Real-Time Driving
  Context Understanding","Grid maps obtained from fused sensory information are nowadays among the most
popular approaches for motion planning for autonomous driving cars. In this
paper, we introduce Deep Grid Net (DGN), a deep learning (DL) system designed
for understanding the context in which an autonomous car is driving. DGN
incorporates a learned driving environment representation based on Occupancy
Grids (OG) obtained from raw Lidar data and constructed on top of the
Dempster-Shafer (DS) theory. The predicted driving context is further used for
switching between different driving strategies implemented within EB robinos,
Elektrobit's Autonomous Driving (AD) software platform. Based on genetic
algorithms (GAs), we also propose a neuroevolutionary approach for learning the
tuning hyperparameters of DGN. The performance of the proposed deep network has
been evaluated against similar competing driving context estimation
classifiers.",arxiv
http://arxiv.org/abs/1902.01031v1,2019-02-04T04:49:59Z,2019-02-04T04:49:59Z,"Towards Pedestrian Detection Using RetinaNet in ECCV 2018 Wider
  Pedestrian Detection Challenge","The main essence of this paper is to investigate the performance of RetinaNet
based object detectors on pedestrian detection. Pedestrian detection is an
important research topic as it provides a baseline for general object detection
and has a great number of practical applications like autonomous car, robotics
and Security camera. Though extensive research has made huge progress in
pedestrian detection, there are still many issues and open for more research
and improvement. Recent deep learning based methods have shown state-of-the-art
performance in computer vision tasks such as image classification, object
detection, and segmentation. Wider pedestrian detection challenge aims at
finding improve solutions for pedestrian detection problem. In this paper, We
propose a pedestrian detection system based on RetinaNet. Our solution has
scored 0.4061 mAP. The code is available at
https://github.com/miltonbd/ECCV_2018_pedestrian_detection_challenege.",arxiv
http://arxiv.org/abs/2012.00093v1,2020-11-30T21:08:07Z,2020-11-30T21:08:07Z,Why model why? Assessing the strengths and limitations of LIME,"When it comes to complex machine learning models, commonly referred to as
black boxes, understanding the underlying decision making process is crucial
for domains such as healthcare and financial services, and also when it is used
in connection with safety critical systems such as autonomous vehicles. As such
interest in explainable artificial intelligence (xAI) tools and techniques has
increased in recent years. However, the effectiveness of existing xAI
frameworks, especially concerning algorithms that work with data as opposed to
images, is still an open research question. In order to address this gap, in
this paper we examine the effectiveness of the Local Interpretable
Model-Agnostic Explanations (LIME) xAI framework, one of the most popular model
agnostic frameworks found in the literature, with a specific focus on its
performance in terms of making tabular models more interpretable. In
particular, we apply several state of the art machine learning algorithms on a
tabular dataset, and demonstrate how LIME can be used to supplement
conventional performance assessment methods. In addition, we evaluate the
understandability of the output produced by LIME both via a usability study,
involving participants who are not familiar with LIME, and its overall
usability via an assessment framework, which is derived from the International
Organisation for Standardisation 9241-11:1998 standard.",arxiv
http://arxiv.org/abs/2106.09527v1,2021-06-16T13:13:04Z,2021-06-16T13:13:04Z,"Federated Learning for Intrusion Detection System: Concepts, Challenges
  and Future Directions","The rapid development of the Internet and smart devices trigger surge in
network traffic making its infrastructure more complex and heterogeneous. The
predominated usage of mobile phones, wearable devices and autonomous vehicles
are examples of distributed networks which generate huge amount of data each
and every day. The computational power of these devices have also seen steady
progression which has created the need to transmit information, store data
locally and drive network computations towards edge devices. Intrusion
detection systems play a significant role in ensuring security and privacy of
such devices. Machine Learning and Deep Learning with Intrusion Detection
Systems have gained great momentum due to their achievement of high
classification accuracy. However the privacy and security aspects potentially
gets jeopardised due to the need of storing and communicating data to
centralized server. On the contrary, federated learning (FL) fits in
appropriately as a privacy-preserving decentralized learning technique that
does not transfer data but trains models locally and transfers the parameters
to the centralized server. The present paper aims to present an extensive and
exhaustive review on the use of FL in intrusion detection system. In order to
establish the need for FL, various types of IDS, relevant ML approaches and its
associated issues are discussed. The paper presents detailed overview of the
implementation of FL in various aspects of anomaly detection. The allied
challenges of FL implementations are also identified which provides idea on the
scope of future direction of research. The paper finally presents the plausible
solutions associated with the identified challenges in FL based intrusion
detection system implementation acting as a baseline for prospective research.",arxiv
http://arxiv.org/abs/1602.07360v4,2016-11-04T21:26:08Z,2016-02-24T00:09:45Z,"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB
  model size","Recent research on deep neural networks has focused primarily on improving
accuracy. For a given accuracy level, it is typically possible to identify
multiple DNN architectures that achieve that accuracy level. With equivalent
accuracy, smaller DNN architectures offer at least three advantages: (1)
Smaller DNNs require less communication across servers during distributed
training. (2) Smaller DNNs require less bandwidth to export a new model from
the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on
FPGAs and other hardware with limited memory. To provide all of these
advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet
achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.
Additionally, with model compression techniques we are able to compress
SqueezeNet to less than 0.5MB (510x smaller than AlexNet).
  The SqueezeNet architecture is available for download here:
https://github.com/DeepScale/SqueezeNet",arxiv
http://arxiv.org/abs/1808.06940v1,2018-08-20T09:25:30Z,2018-08-20T09:25:30Z,End to End Vehicle Lateral Control Using a Single Fisheye Camera,"Convolutional neural networks are commonly used to control the steering angle
for autonomous cars. Most of the time, multiple long range cameras are used to
generate lateral failure cases. In this paper we present a novel model to
generate this data and label augmentation using only one short range fisheye
camera. We present our simulator and how it can be used as a consistent metric
for lateral end-to-end control evaluation. Experiments are conducted on a
custom dataset corresponding to more than 10000 km and 200 hours of open road
driving. Finally we evaluate this model on real world driving scenarios, open
road and a custom test track with challenging obstacle avoidance and sharp
turns. In our simulator based on real-world videos, the final model was capable
of more than 99% autonomy on urban road",arxiv
http://arxiv.org/abs/1702.04125v2,2017-07-24T11:11:25Z,2017-02-14T09:21:23Z,"One-Step Time-Dependent Future Video Frame Prediction with a
  Convolutional Encoder-Decoder Neural Network","There is an inherent need for autonomous cars, drones, and other robots to
have a notion of how their environment behaves and to anticipate changes in the
near future. In this work, we focus on anticipating future appearance given the
current frame of a video. Existing work focuses on either predicting the future
appearance as the next frame of a video, or predicting future motion as optical
flow or motion trajectories starting from a single video frame. This work
stretches the ability of CNNs (Convolutional Neural Networks) to predict an
anticipation of appearance at an arbitrarily given future time, not necessarily
the next video frame. We condition our predicted future appearance on a
continuous time variable that allows us to anticipate future frames at a given
temporal distance, directly from the input video frame. We show that CNNs can
learn an intrinsic representation of typical appearance changes over time and
successfully generate realistic predictions at a deliberate time difference in
the near future.",arxiv
http://arxiv.org/abs/1801.10130v3,2018-02-25T13:43:49Z,2018-01-30T18:28:30Z,Spherical CNNs,"Convolutional Neural Networks (CNNs) have become the method of choice for
learning problems involving 2D planar images. However, a number of problems of
recent interest have created a demand for models that can analyze spherical
images. Examples include omnidirectional vision for drones, robots, and
autonomous cars, molecular regression problems, and global weather and climate
modelling. A naive application of convolutional networks to a planar projection
of the spherical signal is destined to fail, because the space-varying
distortions introduced by such a projection will make translational weight
sharing ineffective.
  In this paper we introduce the building blocks for constructing spherical
CNNs. We propose a definition for the spherical cross-correlation that is both
expressive and rotation-equivariant. The spherical correlation satisfies a
generalized Fourier theorem, which allows us to compute it efficiently using a
generalized (non-commutative) Fast Fourier Transform (FFT) algorithm. We
demonstrate the computational efficiency, numerical accuracy, and effectiveness
of spherical CNNs applied to 3D model recognition and atomization energy
regression.",arxiv
http://arxiv.org/abs/1904.07537v1,2019-04-16T08:49:06Z,2019-04-16T08:49:06Z,"Complexer-YOLO: Real-Time 3D Object Detection and Tracking on Semantic
  Point Clouds","Accurate detection of 3D objects is a fundamental problem in computer vision
and has an enormous impact on autonomous cars, augmented/virtual reality and
many applications in robotics. In this work we present a novel fusion of neural
network based state-of-the-art 3D detector and visual semantic segmentation in
the context of autonomous driving. Additionally, we introduce
Scale-Rotation-Translation score (SRTs), a fast and highly parameterizable
evaluation metric for comparison of object detections, which speeds up our
inference time up to 20\% and halves training time. On top, we apply
state-of-the-art online multi target feature tracking on the object
measurements to further increase accuracy and robustness utilizing temporal
information. Our experiments on KITTI show that we achieve same results as
state-of-the-art in all related categories, while maintaining the performance
and accuracy trade-off and still run in real-time. Furthermore, our model is
the first one that fuses visual semantic with 3D object detection.",arxiv
http://arxiv.org/abs/2001.07769v3,2020-02-16T22:19:32Z,2020-01-21T20:41:27Z,"Massif: Interactive Interpretation of Adversarial Attacks on Deep
  Learning","Deep neural networks (DNNs) are increasingly powering high-stakes
applications such as autonomous cars and healthcare; however, DNNs are often
treated as ""black boxes"" in such applications. Recent research has also
revealed that DNNs are highly vulnerable to adversarial attacks, raising
serious concerns over deploying DNNs in the real world. To overcome these
deficiencies, we are developing Massif, an interactive tool for deciphering
adversarial attacks. Massif identifies and interactively visualizes neurons and
their connections inside a DNN that are strongly activated or suppressed by an
adversarial attack. Massif provides both a high-level, interpretable overview
of the effect of an attack on a DNN, and a low-level, detailed description of
the affected neurons. These tightly coupled views in Massif help people better
understand which input features are most vulnerable or important for correct
predictions.",arxiv
http://arxiv.org/abs/2010.09185v1,2020-10-19T03:18:35Z,2020-10-19T03:18:35Z,MaskNet: A Fully-Convolutional Network to Estimate Inlier Points,"Point clouds have grown in importance in the way computers perceive the
world. From LIDAR sensors in autonomous cars and drones to the time of flight
and stereo vision systems in our phones, point clouds are everywhere. Despite
their ubiquity, point clouds in the real world are often missing points because
of sensor limitations or occlusions, or contain extraneous points from sensor
noise or artifacts. These problems challenge algorithms that require computing
correspondences between a pair of point clouds. Therefore, this paper presents
a fully-convolutional neural network that identifies which points in one point
cloud are most similar (inliers) to the points in another. We show improvements
in learning-based and classical point cloud registration approaches when
retrofitted with our network. We demonstrate these improvements on synthetic
and real-world datasets. Finally, our network produces impressive results on
test datasets that were unseen during training, thus exhibiting
generalizability. Code and videos are available at
https://github.com/vinits5/masknet",arxiv
http://arxiv.org/abs/2011.04065v2,2020-12-07T16:29:50Z,2020-11-08T20:04:43Z,"Bait and Switch: Online Training Data Poisoning of Autonomous Driving
  Systems","We show that by controlling parts of a physical environment in which a
pre-trained deep neural network (DNN) is being fine-tuned online, an adversary
can launch subtle data poisoning attacks that degrade the performance of the
system. While the attack can be applied in general to any perception task, we
consider a DNN based traffic light classifier for an autonomous car that has
been trained in one city and is being fine-tuned online in another city. We
show that by injecting environmental perturbations that do not modify the
traffic lights themselves or ground-truth labels, the adversary can cause the
deep network to learn spurious concepts during the online learning phase. The
attacker can leverage the introduced spurious concepts in the environment to
cause the model's accuracy to degrade during operation; therefore, causing the
system to malfunction.",arxiv
http://arxiv.org/abs/2105.11717v1,2021-05-25T07:39:44Z,2021-05-25T07:39:44Z,Learning an Overlap-based Observation Model for 3D LiDAR Localization,"Localization is a crucial capability for mobile robots and autonomous cars.
In this paper, we address learning an observation model for Monte-Carlo
localization using 3D LiDAR data. We propose a novel, neural network-based
observation model that computes the expected overlap of two 3D LiDAR scans. The
model predicts the overlap and yaw angle offset between the current sensor
reading and virtual frames generated from a pre-built map. We integrate this
observation model into a Monte-Carlo localization framework and tested it on
urban datasets collected with a car in different seasons. The experiments
presented in this paper illustrate that our method can reliably localize a
vehicle in typical urban environments. We furthermore provide comparisons to a
beam-end point and a histogram-based method indicating a superior global
localization performance of our method with fewer particles.",arxiv
http://arxiv.org/abs/2105.14052v1,2021-05-28T18:37:12Z,2021-05-28T18:37:12Z,"Targeted Deep Learning: Framework, Methods, and Applications","Deep learning systems are typically designed to perform for a wide range of
test inputs. For example, deep learning systems in autonomous cars are supposed
to deal with traffic situations for which they were not specifically trained.
In general, the ability to cope with a broad spectrum of unseen test inputs is
called generalization. Generalization is definitely important in applications
where the possible test inputs are known but plentiful or simply unknown, but
there are also cases where the possible inputs are few and unlabeled but known
beforehand. For example, medicine is currently interested in targeting
treatments to individual patients; the number of patients at any given time is
usually small (typically one), their diagnoses/responses/... are still unknown,
but their general characteristics (such as genome information, protein levels
in the blood, and so forth) are known before the treatment. We propose to call
deep learning in such applications targeted deep learning. In this paper, we
introduce a framework for targeted deep learning, and we devise and test an
approach for adapting standard pipelines to the requirements of targeted deep
learning. The approach is very general yet easy to use: it can be implemented
as a simple data-preprocessing step. We demonstrate on a variety of real-world
data that our approach can indeed render standard deep learning faster and more
accurate when the test inputs are known beforehand.",arxiv
http://arxiv.org/abs/1810.03967v3,2019-05-20T17:31:59Z,2018-09-27T02:08:21Z,"Vision-based Navigation of Autonomous Vehicle in Roadway Environments
  with Unexpected Hazards","Vision-based navigation of autonomous vehicles primarily depends on the Deep
Neural Network (DNN) based systems in which the controller obtains input from
sensors/detectors, such as cameras and produces a vehicle control output, such
as a steering wheel angle to navigate the vehicle safely in a roadway traffic
environment. Typically, these DNN-based systems of the autonomous vehicle are
trained through supervised learning; however, recent studies show that a
trained DNN-based system can be compromised by perturbation or adversarial
inputs. Similarly, this perturbation can be introduced into the DNN-based
systems of autonomous vehicle by unexpected roadway hazards, such as debris and
roadblocks. In this study, we first introduce a roadway hazardous environment
(both intentional and unintentional roadway hazards) that can compromise the
DNN-based navigational system of an autonomous vehicle, and produces an
incorrect steering wheel angle, which can cause crashes resulting in fatality
and injury. Then, we develop a DNN-based autonomous vehicle driving system
using object detection and semantic segmentation to mitigate the adverse effect
of this type of hazardous environment, which helps the autonomous vehicle to
navigate safely around such hazards. We find that our developed DNN-based
autonomous vehicle driving system including hazardous object detection and
semantic segmentation improves the navigational ability of an autonomous
vehicle to avoid a potential hazard by 21% compared to the traditional
DNN-based autonomous vehicle driving system.",arxiv
http://arxiv.org/abs/1810.08303v1,2018-10-18T23:16:23Z,2018-10-18T23:16:23Z,"Compositional Verification for Autonomous Systems with Deep Learning
  Components","As autonomy becomes prevalent in many applications, ranging from
recommendation systems to fully autonomous vehicles, there is an increased need
to provide safety guarantees for such systems. The problem is difficult, as
these are large, complex systems which operate in uncertain environments,
requiring data-driven machine-learning components. However, learning techniques
such as Deep Neural Networks, widely used today, are inherently unpredictable
and lack the theoretical foundations to provide strong assurance guarantees. We
present a compositional approach for the scalable, formal verification of
autonomous systems that contain Deep Neural Network components. The approach
uses assume-guarantee reasoning whereby {\em contracts}, encoding the
input-output behavior of individual components, allow the designer to model and
incorporate the behavior of the learning-enabled components working
side-by-side with the other components. We illustrate the approach on an
example taken from the autonomous vehicles domain.",arxiv
http://arxiv.org/abs/2001.08726v3,2020-07-07T06:23:50Z,2020-01-23T18:36:35Z,"Interpretable End-to-end Urban Autonomous Driving with Latent Deep
  Reinforcement Learning","Unlike popular modularized framework, end-to-end autonomous driving seeks to
solve the perception, decision and control problems in an integrated way, which
can be more adapting to new scenarios and easier to generalize at scale.
However, existing end-to-end approaches are often lack of interpretability, and
can only deal with simple driving tasks like lane keeping. In this paper, we
propose an interpretable deep reinforcement learning method for end-to-end
autonomous driving, which is able to handle complex urban scenarios. A
sequential latent environment model is introduced and learned jointly with the
reinforcement learning process. With this latent model, a semantic birdeye mask
can be generated, which is enforced to connect with a certain intermediate
property in today's modularized framework for the purpose of explaining the
behaviors of learned policy. The latent space also significantly reduces the
sample complexity of reinforcement learning. Comparison tests with a simulated
autonomous car in CARLA show that the performance of our method in urban
scenarios with crowded surrounding vehicles dominates many baselines including
DQN, DDPG, TD3 and SAC. Moreover, through masked outputs, the learned policy is
able to provide a better explanation of how the car reasons about the driving
environment. The codes and videos of this work are available at our github repo
and project website.",arxiv
http://arxiv.org/abs/2005.02979v3,2021-10-14T16:40:00Z,2020-05-06T17:31:51Z,"A Survey of Algorithms for Black-Box Safety Validation of Cyber-Physical
  Systems","Autonomous cyber-physical systems (CPS) can improve safety and efficiency for
safety-critical applications, but require rigorous testing before deployment.
The complexity of these systems often precludes the use of formal verification
and real-world testing can be too dangerous during development. Therefore,
simulation-based techniques have been developed that treat the system under
test as a black box operating in a simulated environment. Safety validation
tasks include finding disturbances in the environment that cause the system to
fail (falsification), finding the most-likely failure, and estimating the
probability that the system fails. Motivated by the prevalence of
safety-critical artificial intelligence, this work provides a survey of
state-of-the-art safety validation techniques for CPS with a focus on applied
algorithms and their modifications for the safety validation problem. We
present and discuss algorithms in the domains of optimization, path planning,
reinforcement learning, and importance sampling. Problem decomposition
techniques are presented to help scale algorithms to large state spaces, which
are common for CPS. A brief overview of safety-critical applications is given,
including autonomous vehicles and aircraft collision avoidance systems.
Finally, we present a survey of existing academic and commercially available
safety validation tools.",arxiv
http://arxiv.org/abs/1810.12552v2,2019-08-20T13:28:21Z,2018-10-30T07:21:43Z,3D Traffic Simulation for Autonomous Vehicles in Unity and Python,"Over the recent years, there has been an explosion of studies on autonomous
vehicles. Many collected large amount of data from human drivers. However,
compared to the tedious data collection approach, building a virtual simulation
of traffic makes the autonomous vehicle research more flexible, time-saving,
and scalable. Our work features a 3D simulation that takes in real time
position information parsed from street cameras. The simulation can easily
switch between a global bird view of the traffic and a local perspective of a
car. It can also filter out certain objects in its customized camera, creating
various channels for objects of different categories. This provides alternative
supervised or unsupervised ways to train deep neural networks. Another
advantage of the 3D simulation is its conformation to physical laws. Its
naturalness to accelerate and collide prepares the system for potential deep
reinforcement learning needs.",arxiv
http://arxiv.org/abs/2102.10398v3,2021-02-28T00:47:42Z,2021-02-20T17:35:23Z,All-Chalcogenide Programmable All-Optical Deep Neural Networks,"Deeplearning algorithms are revolutionising many aspects of modern life.
Typically, they are implemented in CMOS-based hardware with severely limited
memory access times and inefficient data-routing. All-optical neural networks
without any electro-optic conversions could alleviate these shortcomings.
However, an all-optical nonlinear activation function, which is a vital
building block for optical neural networks, needs to be developed efficiently
on-chip. Here, we introduce and demonstrate both optical synapse weighting and
all-optical nonlinear thresholding using two different effects in a
chalcogenide material photonic platform. We show how the structural phase
transitions in a wide-bandgap phase-change material enables storing the neural
network weights via non-volatile photonic memory, whilst resonant bond
destabilisation is used as a nonlinear activation threshold without changing
the material. These two different transitions within chalcogenides enable
programmable neural networks with near-zero static power consumption once
trained, in addition to picosecond delays performing inference tasks not
limited by wire charging that limit electrical circuits; for instance, we show
that nanosecond-order weight programming and near-instantaneous weight updates
enable accurate inference tasks within 20 picoseconds in a 3-layer all-optical
neural network. Optical neural networks that bypass electro-optic conversion
altogether hold promise for network-edge machine learning applications where
decision-making in real-time are critical, such as for autonomous vehicles or
navigation systems such as signal pre-processing of LIDAR systems.",arxiv
http://arxiv.org/abs/2004.01743v1,2020-04-03T19:26:23Z,2020-04-03T19:26:23Z,"TensorFI: A Flexible Fault Injection Framework for TensorFlow
  Applications","As machine learning (ML) has seen increasing adoption in safety-critical
domains (e.g., autonomous vehicles), the reliability of ML systems has also
grown in importance. While prior studies have proposed techniques to enable
efficient error-resilience techniques (e.g., selective instruction
duplication), a fundamental requirement for realizing these techniques is a
detailed understanding of the application's resilience.
  In this work, we present TensorFI, a high-level fault injection (FI)
framework for TensorFlow-based applications. TensorFI is able to inject both
hardware and software faults in general TensorFlow programs. TensorFI is a
configurable FI tool that is flexible, easy to use, and portable. It can be
integrated into existing TensorFlow programs to assess their resilience for
different fault types (e.g., faults in particular operators). We use TensorFI
to evaluate the resilience of 12 ML programs, including DNNs used in the
autonomous vehicle domain. Our tool is publicly available at
https://github.com/DependableSystemsLab/TensorFI.",arxiv
http://arxiv.org/abs/1710.00814v1,2017-10-02T17:56:26Z,2017-10-02T17:56:26Z,"Detecting Adversarial Attacks on Neural Network Policies with Visual
  Foresight","Deep reinforcement learning has shown promising results in learning control
policies for complex sequential decision-making tasks. However, these neural
network-based policies are known to be vulnerable to adversarial examples. This
vulnerability poses a potentially serious threat to safety-critical systems
such as autonomous vehicles. In this paper, we propose a defense mechanism to
defend reinforcement learning agents from adversarial attacks by leveraging an
action-conditioned frame prediction module. Our core idea is that the
adversarial examples targeting at a neural network-based policy are not
effective for the frame prediction model. By comparing the action distribution
produced by a policy from processing the current observed frame to the action
distribution produced by the same policy from processing the predicted frame
from the action-conditioned frame prediction module, we can detect the presence
of adversarial examples. Beyond detecting the presence of adversarial examples,
our method allows the agent to continue performing the task using the predicted
frame when the agent is under attack. We evaluate the performance of our
algorithm using five games in Atari 2600. Our results demonstrate that the
proposed defense mechanism achieves favorable performance against baseline
algorithms in detecting adversarial examples and in earning rewards when the
agents are under attack.",arxiv
http://arxiv.org/abs/1909.00084v2,2019-12-27T23:48:38Z,2019-08-30T22:37:15Z,"Cloudy with high chance of DBMS: A 10-year prediction for
  Enterprise-Grade ML","Machine learning (ML) has proven itself in high-value web applications such
as search ranking and is emerging as a powerful tool in a much broader range of
enterprise scenarios including voice recognition and conversational
understanding for customer support, autotuning for videoconferencing,
intelligent feedback loops in large-scale sysops, manufacturing and autonomous
vehicle management, complex financial predictions, just to name a few.
Meanwhile, as the value of data is increasingly recognized and monetized,
concerns about securing valuable data and risks to individual privacy have been
growing. Consequently, rigorous data management has emerged as a key
requirement in enterprise settings. How will these trends (ML growing
popularity, and stricter data governance) intersect? What are the unmet
requirements for applying ML in enterprise settings? What are the technical
challenges for the DB community to solve? In this paper, we present our vision
of how ML and database systems are likely to come together, and early steps we
take towards making this vision a reality.",arxiv
http://arxiv.org/abs/1906.03199v2,2020-10-25T10:42:37Z,2019-06-07T16:08:19Z,Multimodal End-to-End Autonomous Driving,"A crucial component of an autonomous vehicle (AV) is the artificial
intelligence (AI) is able to drive towards a desired destination. Today, there
are different paradigms addressing the development of AI drivers. On the one
hand, we find modular pipelines, which divide the driving task into sub-tasks
such as perception and maneuver planning and control. On the other hand, we
find end-to-end driving approaches that try to learn a direct mapping from
input raw sensor data to vehicle control signals. The later are relatively less
studied, but are gaining popularity since they are less demanding in terms of
sensor data annotation. This paper focuses on end-to-end autonomous driving. So
far, most proposals relying on this paradigm assume RGB images as input sensor
data. However, AVs will not be equipped only with cameras, but also with active
sensors providing accurate depth information (e.g., LiDARs). Accordingly, this
paper analyses whether combining RGB and depth modalities, i.e. using RGBD
data, produces better end-to-end AI drivers than relying on a single modality.
We consider multimodality based on early, mid and late fusion schemes, both in
multisensory and single-sensor (monocular depth estimation) settings. Using the
CARLA simulator and conditional imitation learning (CIL), we show how, indeed,
early fusion multimodality outperforms single-modality.",arxiv
http://arxiv.org/abs/2102.02928v1,2021-02-04T23:52:31Z,2021-02-04T23:52:31Z,"Toward a Rational and Ethical Sociotechnical System of Autonomous
  Vehicles: A Novel Application of Multi-Criteria Decision Analysis","The expansion of artificial intelligence (AI) and autonomous systems has
shown the potential to generate enormous social good while also raising serious
ethical and safety concerns. AI technology is increasingly adopted in
transportation. A survey of various in-vehicle technologies found that
approximately 64% of the respondents used a smartphone application to assist
with their travel. The top-used applications were navigation and real-time
traffic information systems. Among those who used smartphones during their
commutes, the top-used applications were navigation and entertainment. There is
a pressing need to address relevant social concerns to allow for the
development of systems of intelligent agents that are informed and cognizant of
ethical standards. Doing so will facilitate the responsible integration of
these systems in society. To this end, we have applied Multi-Criteria Decision
Analysis (MCDA) to develop a formal Multi-Attribute Impact Assessment (MAIA)
questionnaire for examining the social and ethical issues associated with the
uptake of AI. We have focused on the domain of autonomous vehicles (AVs)
because of their imminent expansion. However, AVs could serve as a stand-in for
any domain where intelligent, autonomous agents interact with humans, either on
an individual level (e.g., pedestrians, passengers) or a societal level.",arxiv
http://arxiv.org/abs/2001.09684v2,2021-09-08T07:46:42Z,2020-01-27T10:53:11Z,"Challenges and Countermeasures for Adversarial Attacks on Deep
  Reinforcement Learning","Deep Reinforcement Learning (DRL) has numerous applications in the real world
thanks to its outstanding ability in quickly adapting to the surrounding
environments. Despite its great advantages, DRL is susceptible to adversarial
attacks, which precludes its use in real-life critical systems and applications
(e.g., smart grids, traffic controls, and autonomous vehicles) unless its
vulnerabilities are addressed and mitigated. Thus, this paper provides a
comprehensive survey that discusses emerging attacks in DRL-based systems and
the potential countermeasures to defend against these attacks. We first cover
some fundamental backgrounds about DRL and present emerging adversarial attacks
on machine learning techniques. We then investigate more details of the
vulnerabilities that the adversary can exploit to attack DRL along with the
state-of-the-art countermeasures to prevent such attacks. Finally, we highlight
open issues and research challenges for developing solutions to deal with
attacks for DRL-based intelligent systems.",arxiv
http://arxiv.org/abs/2105.12249v2,2021-05-27T02:14:17Z,2021-05-25T22:40:44Z,"Bayesian Nonparametric Reinforcement Learning in LTE and Wi-Fi
  Coexistence","With the formation of next generation wireless communication, a growing
number of new applications like internet of things, autonomous car, and drone
is crowding the unlicensed spectrum. Licensed network such as the long-term
evolution (LTE) also comes to the unlicensed spectrum for better providing
high-capacity contents with low cost. However, LTE was not designed for sharing
spectrum with others. A cooperation center for these networks is costly because
they possess heterogeneous properties and everyone can enter and leave the
spectrum unrestrictedly, so the design will be challenging. Since it is
infeasible to incorporate potentially infinite scenarios with one unified
design, an alternative solution is to let each network learn its own
coexistence policy. Previous solutions only work on fixed scenarios. In this
work a reinforcement learning algorithm is presented to cope with the
coexistence between Wi-Fi and LTE agents in 5 GHz unlicensed spectrum. The
coexistence problem was modeled as a decentralized partially observable Markov
decision process (Dec-POMDP) and Bayesian approach was adopted for policy
learning with nonparametric prior to accommodate the uncertainty of policy for
different agents. A fairness measure was introduced in the reward function to
encourage fair sharing between agents. The reinforcement learning was turned
into an optimization problem by transforming the value function as likelihood
and variational inference for posterior approximation. Simulation results
demonstrate that this algorithm can reach high value with compact policy
representations, and stay computationally efficient when applying to agent set.",arxiv
http://arxiv.org/abs/2101.03525v1,2021-01-10T11:21:17Z,2021-01-10T11:21:17Z,"Cross-Modal Contrastive Learning of Representations for Navigation using
  Lightweight, Low-Cost Millimeter Wave Radar for Adverse Environmental
  Conditions","Deep reinforcement learning (RL), where the agent learns from mistakes, has
been successfully applied to a variety of tasks. With the aim of learning
collision-free policies for unmanned vehicles, deep RL has been used for
training with various types of data, such as colored images, depth images, and
LiDAR point clouds, without the use of classic map--localize--plan approaches.
However, existing methods are limited by their reliance on cameras and LiDAR
devices, which have degraded sensing under adverse environmental conditions
(e.g., smoky environments). In response, we propose the use of single-chip
millimeter-wave (mmWave) radar, which is lightweight and inexpensive, for
learning-based autonomous navigation. However, because mmWave radar signals are
often noisy and sparse, we propose a cross-modal contrastive learning for
representation (CM-CLR) method that maximizes the agreement between mmWave
radar data and LiDAR data in the training stage. We evaluated our method in
real-world robot compared with 1) a method with two separate networks using
cross-modal generative reconstruction and an RL policy and 2) a baseline RL
policy without cross-modal representation. Our proposed end-to-end deep RL
policy with contrastive learning successfully navigated the robot through
smoke-filled maze environments and achieved better performance compared with
generative reconstruction methods, in which noisy artifact walls or obstacles
were produced. All pretrained models and hardware settings are open access for
reproducing this study and can be obtained at
https://arg-nctu.github.io/projects/deeprl-mmWave.html",arxiv
http://arxiv.org/abs/2107.12940v1,2021-07-27T16:54:04Z,2021-07-27T16:54:04Z,"Finding Failures in High-Fidelity Simulation using Adaptive Stress
  Testing and the Backward Algorithm","Validating the safety of autonomous systems generally requires the use of
high-fidelity simulators that adequately capture the variability of real-world
scenarios. However, it is generally not feasible to exhaustively search the
space of simulation scenarios for failures. Adaptive stress testing (AST) is a
method that uses reinforcement learning to find the most likely failure of a
system. AST with a deep reinforcement learning solver has been shown to be
effective in finding failures across a range of different systems. This
approach generally involves running many simulations, which can be very
expensive when using a high-fidelity simulator. To improve efficiency, we
present a method that first finds failures in a low-fidelity simulator. It then
uses the backward algorithm, which trains a deep neural network policy using a
single expert demonstration, to adapt the low-fidelity failures to
high-fidelity. We have created a series of autonomous vehicle validation case
studies that represent some of the ways low-fidelity and high-fidelity
simulators can differ, such as time discretization. We demonstrate in a variety
of case studies that this new AST approach is able to find failures with
significantly fewer high-fidelity simulation steps than are needed when just
running AST directly in high-fidelity. As a proof of concept, we also
demonstrate AST on NVIDIA's DriveSim simulator, an industry state-of-the-art
high-fidelity simulator for finding failures in autonomous vehicles.",arxiv
http://arxiv.org/abs/2007.11218v1,2020-07-22T06:05:41Z,2020-07-22T06:05:41Z,Regulating human control over autonomous systems,"In recent years, many sectors have experienced significant progress in
automation, associated with the growing advances in artificial intelligence and
machine learning. There are already automated robotic weapons, which are able
to evaluate and engage with targets on their own, and there are already
autonomous vehicles that do not need a human driver. It is argued that the use
of increasingly autonomous systems (AS) should be guided by the policy of human
control, according to which humans should execute a certain significant level
of judgment over AS. While in the military sector there is a fear that AS could
mean that humans lose control over life and death decisions, in the
transportation domain, on the contrary, there is a strongly held view that
autonomy could bring significant operational benefits by removing the need for
a human driver. This article explores the notion of human control in the United
States in the two domains of defense and transportation. The operationalization
of emerging policies of human control results in the typology of direct and
indirect human controls exercised over the use of AS. The typology helps to
steer the debate away from the linguistic complexities of the term autonomy. It
identifies instead where human factors are undergoing important changes and
ultimately informs about more detailed rules and standards formulation, which
differ across domains, applications, and sectors.",arxiv
http://arxiv.org/abs/2101.10463v2,2021-01-27T02:22:33Z,2021-01-25T22:34:06Z,"RTGPU: Real-Time GPU Scheduling of Hard Deadline Parallel Tasks with
  Fine-Grain Utilization","Many emerging cyber-physical systems, such as autonomous vehicles and robots,
rely heavily on artificial intelligence and machine learning algorithms to
perform important system operations. Since these highly parallel applications
are computationally intensive, they need to be accelerated by graphics
processing units (GPUs) to meet stringent timing constraints. However, despite
the wide adoption of GPUs, efficiently scheduling multiple GPU applications
while providing rigorous real-time guarantees remains a challenge. In this
paper, we propose RTGPU, which can schedule the execution of multiple GPU
applications in real-time to meet hard deadlines. Each GPU application can have
multiple CPU execution and memory copy segments, as well as GPU kernels. We
start with a model to explicitly account for the CPU and memory copy segments
of these applications. We then consider the GPU architecture in the development
of a precise timing model for the GPU kernels and leverage a technique known as
persistent threads to implement fine-grained kernel scheduling with improved
performance through interleaved execution. Next, we propose a general method
for scheduling parallel GPU applications in real time. Finally, to schedule
multiple parallel GPU applications, we propose a practical real-time scheduling
algorithm based on federated scheduling and grid search (for GPU kernel
segments) with uniprocessor fixed priority scheduling (for multiple CPU and
memory copy segments). Our approach provides superior schedulability compared
with previous work, and gives real-time guarantees to meet hard deadlines for
multiple GPU applications according to comprehensive validation and evaluation
on a real NVIDIA GTX1080Ti GPU system.",arxiv
http://arxiv.org/abs/1610.04256v1,2016-10-13T20:34:48Z,2016-10-13T20:34:48Z,Assessing Threat of Adversarial Examples on Deep Neural Networks,"Deep neural networks are facing a potential security threat from adversarial
examples, inputs that look normal but cause an incorrect classification by the
deep neural network. For example, the proposed threat could result in
hand-written digits on a scanned check being incorrectly classified but looking
normal when humans see them. This research assesses the extent to which
adversarial examples pose a security threat, when one considers the normal
image acquisition process. This process is mimicked by simulating the
transformations that normally occur in acquiring the image in a real world
application, such as using a scanner to acquire digits for a check amount or
using a camera in an autonomous car. These small transformations negate the
effect of the carefully crafted perturbations of adversarial examples,
resulting in a correct classification by the deep neural network. Thus just
acquiring the image decreases the potential impact of the proposed security
threat. We also show that the already widely used process of averaging over
multiple crops neutralizes most adversarial examples. Normal preprocessing,
such as text binarization, almost completely neutralizes adversarial examples.
This is the first paper to show that for text driven classification,
adversarial examples are an academic curiosity, not a security threat.",arxiv
http://arxiv.org/abs/1905.10117v1,2019-05-24T09:55:57Z,2019-05-24T09:55:57Z,"Robust Semantic Segmentation in Adverse Weather Conditions by means of
  Sensor Data Fusion","A robust and reliable semantic segmentation in adverse weather conditions is
very important for autonomous cars, but most state-of-the-art approaches only
achieve high accuracy rates in optimal weather conditions. The reason is that
they are only optimized for good weather conditions and given noise models.
However, most of them fail, if data with unknown disturbances occur, and their
performance decrease enormously. One possibility to still obtain reliable
results is to observe the environment with different sensor types, such as
camera and lidar, and to fuse the sensor data by means of neural networks,
since different sensors behave differently in diverse weather conditions.
Hence, the sensors can complement each other by means of an appropriate sensor
data fusion. Nevertheless, the fusion-based approaches are still susceptible to
disturbances and fail to classify disturbed image areas correctly. This problem
can be solved by means of a special training method, the so called Robust
Learning Method (RLM), a method by which the neural network learns to handle
unknown noise. In this work, two different sensor fusion architectures for
semantic segmentation are compared and evaluated on several datasets.
Furthermore, it is shown that the RLM increases the robustness in adverse
weather conditions enormously, and achieve good results although no disturbance
model has been learned by the neural network.",arxiv
http://arxiv.org/abs/2011.01112v1,2020-11-02T16:43:04Z,2020-11-02T16:43:04Z,Scheduling Real-time Deep Learning Services as Imprecise Computations,"The paper presents an efficient real-time scheduling algorithm for
intelligent real-time edge services, defined as those that perform machine
intelligence tasks, such as voice recognition, LIDAR processing, or machine
vision, on behalf of local embedded devices that are themselves unable to
support extensive computations. The work contributes to a recent direction in
real-time computing that develops scheduling algorithms for machine
intelligence tasks with anytime prediction. We show that deep neural network
workflows can be cast as imprecise computations, each with a mandatory part and
(several) optional parts whose execution utility depends on input data. The
goal of the real-time scheduler is to maximize the average accuracy of deep
neural network outputs while meeting task deadlines, thanks to opportunistic
shedding of the least necessary optional parts. The work is motivated by the
proliferation of increasingly ubiquitous but resource-constrained embedded
devices (for applications ranging from autonomous cars to the Internet of
Things) and the desire to develop services that endow them with intelligence.
Experiments on recent GPU hardware and a state of the art deep neural network
for machine vision illustrate that our scheme can increase the overall accuracy
by 10%-20% while incurring (nearly) no deadline misses.",arxiv
http://arxiv.org/abs/2010.01931v1,2020-10-05T11:41:11Z,2020-10-05T11:41:11Z,Offline Learning for Planning: A Summary,"The training of autonomous agents often requires expensive and unsafe
trial-and-error interactions with the environment. Nowadays several data sets
containing recorded experiences of intelligent agents performing various tasks,
spanning from the control of unmanned vehicles to human-robot interaction and
medical applications are accessible on the internet. With the intention of
limiting the costs of the learning procedure it is convenient to exploit the
information that is already available rather than collecting new data.
Nevertheless, the incapability to augment the batch can lead the autonomous
agents to develop far from optimal behaviours when the sampled experiences do
not allow for a good estimate of the true distribution of the environment.
Offline learning is the area of machine learning concerned with efficiently
obtaining an optimal policy with a batch of previously collected experiences
without further interaction with the environment. In this paper we adumbrate
the ideas motivating the development of the state-of-the-art offline learning
baselines. The listed methods consist in the introduction of epistemic
uncertainty dependent constraints during the classical resolution of a Markov
Decision Process, with and without function approximators, that aims to
alleviate the bad effects of the distributional mismatch between the available
samples and real world. We provide comments on the practical utility of the
theoretical bounds that justify the application of these algorithms and suggest
the utilization of Generative Adversarial Networks to estimate the
distributional shift that affects all of the proposed model-free and
model-based approaches.",arxiv
http://arxiv.org/abs/2101.09750v1,2021-01-24T16:54:53Z,2021-01-24T16:54:53Z,"Deployable, Data-Driven Unmanned Vehicle Navigation System in
  GPS-Denied, Feature-Deficient Environments","This paper presents a novel data-driven navigation system to navigate an
Unmanned Vehicle (UV) in GPS-denied, feature-deficient environments such as
tunnels, or mines. The method utilizes Radio Frequency Identification (RFID)
tags, also referred to as landmarks, as range sensors that are carried by the
vehicle and are deployed in the environment to enable localization as the
vehicle traverses its pre-defined path through the tunnel. A key question that
arises in such scenario is to estimate and reduce the number of landmarks
required for localization before the start of the mission, given some
information about the environment. The main constraint of the problem is to
keep the maximum uncertainty in the position estimate near a desired value. In
this article, we combine techniques from estimation, machine learning, and
mixed-integer convex optimization to develop a systematic method to perform
localization and navigate the UV through the environment while ensuring minimum
number of landmarks are used and all the mission constraints are satisfied.",arxiv
http://arxiv.org/abs/2105.09493v1,2021-05-20T03:34:05Z,2021-05-20T03:34:05Z,Futuristic Intelligent Transportation System,"The emerging autonomous vehicles (AVs) will inevitably revolutionize the
transportation systems. This is because of a key feature of AVs; instead of
being managed by human drivers as the conventional vehicles, AVs are of the
complete capability to manage the driving by themselves. As a result, the
futuristic intelligent transportation system (FITS) can be a centrally managed
and optimized system with the fully coordinated driving of vehicles, which is
impossible by the current transportation systems controlled by humans. In this
article, we envision the operation of such FITS when AVs, advanced vehicular
networks (VANETs) and artificial intelligence (AI) are adopted. Specifically,
we first develop the autonomous vehicular networks (AVNs) based on the advanced
development of AVs and heterogeneous vehicular communication technologies to
achieve global data collection and real-time data sharing. With this network
architecture, we then integrate AVNs and AI based on the intelligent digital
twin (IDT) to design the FITS with the target of setting up an accurate and
efficient global traffic scheduling system. After that, compared with the
conventional schemes, a customized path planning case is studied to evaluate
the performance of the proposed FITS. Finally, we highlight the emerging issues
related to the FITS for future research.",arxiv
http://arxiv.org/abs/1709.02538v4,2018-08-21T02:54:23Z,2017-09-08T04:53:51Z,DeepFense: Online Accelerated Defense Against Adversarial Deep Learning,"Recent advances in adversarial Deep Learning (DL) have opened up a largely
unexplored surface for malicious attacks jeopardizing the integrity of
autonomous DL systems. With the wide-spread usage of DL in critical and
time-sensitive applications, including unmanned vehicles, drones, and video
surveillance systems, online detection of malicious inputs is of utmost
importance. We propose DeepFense, the first end-to-end automated framework that
simultaneously enables efficient and safe execution of DL models. DeepFense
formalizes the goal of thwarting adversarial attacks as an optimization problem
that minimizes the rarely observed regions in the latent feature space spanned
by a DL network. To solve the aforementioned minimization problem, a set of
complementary but disjoint modular redundancies are trained to validate the
legitimacy of the input samples in parallel with the victim DL model. DeepFense
leverages hardware/software/algorithm co-design and customized acceleration to
achieve just-in-time performance in resource-constrained settings. The proposed
countermeasure is unsupervised, meaning that no adversarial sample is leveraged
to train modular redundancies. We further provide an accompanying API to reduce
the non-recurring engineering cost and ensure automated adaptation to various
platforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders
of magnitude performance improvement while enabling online adversarial sample
detection.",arxiv
http://arxiv.org/abs/2002.06770v2,2021-10-29T01:13:59Z,2020-02-17T04:53:30Z,"Unsupervised Image-generation Enhanced Adaptation for Object Detection
  in Thermal images","Object detection in thermal images is an important computer vision task and
has many applications such as unmanned vehicles, robotics, surveillance and
night vision. Deep learning based detectors have achieved major progress, which
usually need large amount of labelled training data. However, labelled data for
object detection in thermal images is scarce and expensive to collect. How to
take advantage of the large number labelled visible images and adapt them into
thermal image domain, is expected to solve. This paper proposes an unsupervised
image-generation enhanced adaptation method for object detection in thermal
images. To reduce the gap between visible domain and thermal domain, the
proposed method manages to generate simulated fake thermal images that are
similar to the target images, and preserves the annotation information of the
visible source domain. The image generation includes a CycleGAN based
image-to-image translation and an intensity inversion transformation. Generated
fake thermal images are used as renewed source domain. And then the
off-the-shelf Domain Adaptive Faster RCNN is utilized to reduce the gap between
generated intermediate domain and the thermal target domain. Experiments
demonstrate the effectiveness and superiority of the proposed method.",arxiv
http://arxiv.org/abs/2102.05843v1,2021-02-11T04:33:43Z,2021-02-11T04:33:43Z,"Driving Style Representation in Convolutional Recurrent Neural Network
  Model of Driver Identification","Identifying driving styles is the task of analyzing the behavior of drivers
in order to capture variations that will serve to discriminate different
drivers from each other. This task has become a prerequisite for a variety of
applications, including usage-based insurance, driver coaching, driver action
prediction, and even in designing autonomous vehicles; because driving style
encodes essential information needed by these applications. In this paper, we
present a deep-neural-network architecture, we term D-CRNN, for building
high-fidelity representations for driving style, that combine the power of
convolutional neural networks (CNN) and recurrent neural networks (RNN). Using
CNN, we capture semantic patterns of driver behavior from trajectories (such as
a turn or a braking event). We then find temporal dependencies between these
semantic patterns using RNN to encode driving style. We demonstrate the
effectiveness of these techniques for driver identification by learning driving
style through extensive experiments conducted on several large, real-world
datasets, and comparing the results with the state-of-the-art deep-learning and
non-deep-learning solutions. These experiments also demonstrate a useful
example of bias removal, by presenting how we preprocess the input data by
sampling dissimilar trajectories for each driver to prevent spatial
memorization. Finally, this paper presents an analysis of the contribution of
different attributes for driver identification; we find that engine RPM, Speed,
and Acceleration are the best combination of features.",arxiv
http://arxiv.org/abs/2108.10617v1,2021-08-24T10:06:53Z,2021-08-24T10:06:53Z,Image-free single-pixel segmentation,"The existing segmentation techniques require high-fidelity images as input to
perform semantic segmentation. Since the segmentation results contain most of
edge information that is much less than the acquired images, the throughput gap
leads to both hardware and software waste. In this letter, we report an
image-free single-pixel segmentation technique. The technique combines
structured illumination and single-pixel detection together, to efficiently
samples and multiplexes scene's segmentation information into compressed
one-dimensional measurements. The illumination patterns are optimized together
with the subsequent reconstruction neural network, which directly infers
segmentation maps from the single-pixel measurements. The end-to-end
encoding-and-decoding learning framework enables optimized illumination with
corresponding network, which provides both high acquisition and segmentation
efficiency. Both simulation and experimental results validate that accurate
segmentation can be achieved using two-order-of-magnitude less input data. When
the sampling ratio is 1%, the Dice coefficient reaches above 80% and the pixel
accuracy reaches above 96%. We envision that this image-free segmentation
technique can be widely applied in various resource-limited platforms such as
UAV and unmanned vehicle that require real-time sensing.",arxiv
http://arxiv.org/abs/1907.06831v2,2019-08-15T21:13:50Z,2019-07-16T04:25:39Z,"Evaluating Explanation Without Ground Truth in Interpretable Machine
  Learning","Interpretable Machine Learning (IML) has become increasingly important in
many real-world applications, such as autonomous cars and medical diagnosis,
where explanations are significantly preferred to help people better understand
how machine learning systems work and further enhance their trust towards
systems. However, due to the diversified scenarios and subjective nature of
explanations, we rarely have the ground truth for benchmark evaluation in IML
on the quality of generated explanations. Having a sense of explanation quality
not only matters for assessing system boundaries, but also helps to realize the
true benefits to human users in practical settings. To benchmark the evaluation
in IML, in this article, we rigorously define the problem of evaluating
explanations, and systematically review the existing efforts from
state-of-the-arts. Specifically, we summarize three general aspects of
explanation (i.e., generalizability, fidelity and persuasibility) with formal
definitions, and respectively review the representative methodologies for each
of them under different tasks. Further, a unified evaluation framework is
designed according to the hierarchical needs from developers and end-users,
which could be easily adopted for different scenarios in practice. In the end,
open problems are discussed, and several limitations of current evaluation
techniques are raised for future explorations.",arxiv
http://arxiv.org/abs/1801.02190v1,2018-01-07T13:46:03Z,2018-01-07T13:46:03Z,Approximate FPGA-based LSTMs under Computation Time Constraints,"Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM)
networks have demonstrated state-of-the-art accuracy in several emerging
Artificial Intelligence tasks. However, the models are becoming increasingly
demanding in terms of computational and memory load. Emerging latency-sensitive
applications including mobile robots and autonomous vehicles often operate
under stringent computation time constraints. In this paper, we address the
challenge of deploying computationally demanding LSTMs at a constrained time
budget by introducing an approximate computing scheme that combines iterative
low-rank compression and pruning, along with a novel FPGA-based LSTM
architecture. Combined in an end-to-end framework, the approximation method's
parameters are optimised and the architecture is configured to address the
problem of high-performance LSTM execution in time-constrained applications.
Quantitative evaluation on a real-life image captioning application indicates
that the proposed methods required up to 6.5x less time to achieve the same
application-level accuracy compared to a baseline method, while achieving an
average of 25x higher accuracy under the same computation time constraints.",arxiv
http://arxiv.org/abs/2010.00972v1,2020-10-02T13:04:58Z,2020-10-02T13:04:58Z,6G Cellular Networks and Connected Autonomous Vehicles,"With 5G mobile communication systems been commercially rolled out, research
discussions on next generation mobile systems, i.e., 6G, have started. On the
other hand, vehicular technologies are also evolving rapidly, from connected
vehicles as coined by V2X (vehicle to everything) to autonomous vehicles to the
combination of the two, i.e., the networks of connected autonomous vehicles
(CAV). How fast the evolution of these two areas will go head-in-head is of
great importance, which is the focus of this paper. Based on a brief overview
on the technological evolution of V2X to CAV and 6G key technologies, this
paper explores two complementary research directions, namely, 6G for CAVs
versus CAVs for 6G. The former investigates how various 6G key enablers, such
as THz, cell free communication and artificial intelligence (AI), can be
utilized to provide CAV mission-critical services. The latter discusses how
CAVs can facilitate effective deployment and operation of 6G systems. This
paper attempts to investigate the interactions between the two technologies to
spark more research efforts in these areas.",arxiv
http://arxiv.org/abs/1909.04886v1,2019-09-11T07:38:53Z,2019-09-11T07:38:53Z,"Towards Safe Machine Learning for CPS: Infer Uncertainty from Training
  Data","Machine learning (ML) techniques are increasingly applied to decision-making
and control problems in Cyber-Physical Systems among which many are
safety-critical, e.g., chemical plants, robotics, autonomous vehicles. Despite
the significant benefits brought by ML techniques, they also raise additional
safety issues because 1) most expressive and powerful ML models are not
transparent and behave as a black box and 2) the training data which plays a
crucial role in ML safety is usually incomplete. An important technique to
achieve safety for ML models is ""Safe Fail"", i.e., a model selects a reject
option and applies the backup solution, a traditional controller or a human
operator for example, when it has low confidence in a prediction.
  Data-driven models produced by ML algorithms learn from training data, and
hence they are only as good as the examples they have learnt. As pointed in
[17], ML models work well in the ""training space"" (i.e., feature space with
sufficient training data), but they could not extrapolate beyond the training
space. As observed in many previous studies, a feature space that lacks
training data generally has a much higher error rate than the one that contains
sufficient training samples [31]. Therefore, it is essential to identify the
training space and avoid extrapolating beyond the training space. In this
paper, we propose an efficient Feature Space Partitioning Tree (FSPT) to
address this problem. Using experiments, we also show that, a strong
relationship exists between model performance and FSPT score.",arxiv
http://arxiv.org/abs/1901.02858v1,2019-01-09T18:25:14Z,2019-01-09T18:25:14Z,"Adaptive Feature Processing for Robust Human Activity Recognition on a
  Novel Multi-Modal Dataset","Human Activity Recognition (HAR) is a key building block of many emerging
applications such as intelligent mobility, sports analytics, ambient-assisted
living and human-robot interaction. With robust HAR, systems will become more
human-aware, leading towards much safer and empathetic autonomous systems.
While human pose detection has made significant progress with the dawn of deep
convolutional neural networks (CNNs), the state-of-the-art research has almost
exclusively focused on a single sensing modality, especially video. However, in
safety critical applications it is imperative to utilize multiple sensor
modalities for robust operation. To exploit the benefits of state-of-the-art
machine learning techniques for HAR, it is extremely important to have
multimodal datasets. In this paper, we present a novel, multi-modal sensor
dataset that encompasses nine indoor activities, performed by 16 participants,
and captured by four types of sensors that are commonly used in indoor
applications and autonomous vehicles. This multimodal dataset is the first of
its kind to be made openly available and can be exploited for many applications
that require HAR, including sports analytics, healthcare assistance and indoor
intelligent mobility. We propose a novel data preprocessing algorithm to enable
adaptive feature extraction from the dataset to be utilized by different
machine learning algorithms. Through rigorous experimental evaluations, this
paper reviews the performance of machine learning approaches to posture
recognition, and analyses the robustness of the algorithms. When performing HAR
with the RGB-Depth data from our new dataset, machine learning algorithms such
as a deep neural network reached a mean accuracy of up to 96.8% for
classification across all stationary and dynamic activities",arxiv
http://arxiv.org/abs/1903.08792v1,2019-03-21T01:29:14Z,2019-03-21T01:29:14Z,"End-to-End Safe Reinforcement Learning through Barrier Functions for
  Safety-Critical Continuous Control Tasks","Reinforcement Learning (RL) algorithms have found limited success beyond
simulated applications, and one main reason is the absence of safety guarantees
during the learning process. Real world systems would realistically fail or
break before an optimal controller can be learned. To address this issue, we
propose a controller architecture that combines (1) a model-free RL-based
controller with (2) model-based controllers utilizing control barrier functions
(CBFs) and (3) on-line learning of the unknown system dynamics, in order to
ensure safety during learning. Our general framework leverages the success of
RL algorithms to learn high-performance controllers, while the CBF-based
controllers both guarantee safety and guide the learning process by
constraining the set of explorable polices. We utilize Gaussian Processes (GPs)
to model the system dynamics and its uncertainties.
  Our novel controller synthesis algorithm, RL-CBF, guarantees safety with high
probability during the learning process, regardless of the RL algorithm used,
and demonstrates greater policy exploration efficiency. We test our algorithm
on (1) control of an inverted pendulum and (2) autonomous car-following with
wireless vehicle-to-vehicle communication, and show that our algorithm attains
much greater sample efficiency in learning than other state-of-the-art
algorithms and maintains safety during the entire learning process.",arxiv
http://arxiv.org/abs/2007.00178v1,2020-07-01T01:41:45Z,2020-07-01T01:41:45Z,"Reinforcement Learning based Control of Imitative Policies for
  Near-Accident Driving","Autonomous driving has achieved significant progress in recent years, but
autonomous cars are still unable to tackle high-risk situations where a
potential accident is likely. In such near-accident scenarios, even a minor
change in the vehicle's actions may result in drastically different
consequences. To avoid unsafe actions in near-accident scenarios, we need to
fully explore the environment. However, reinforcement learning (RL) and
imitation learning (IL), two widely-used policy learning methods, cannot model
rapid phase transitions and are not scalable to fully cover all the states. To
address driving in near-accident scenarios, we propose a hierarchical
reinforcement and imitation learning (H-ReIL) approach that consists of
low-level policies learned by IL for discrete driving modes, and a high-level
policy learned by RL that switches between different driving modes. Our
approach exploits the advantages of both IL and RL by integrating them into a
unified learning framework. Experimental results and user studies suggest our
approach can achieve higher efficiency and safety compared to other methods.
Analyses of the policies demonstrate our high-level policy appropriately
switches between different low-level policies in near-accident driving
situations.",arxiv
http://arxiv.org/abs/2010.05150v2,2021-08-04T02:46:48Z,2020-10-11T03:41:56Z,Safe Reinforcement Learning with Natural Language Constraints,"While safe reinforcement learning (RL) holds great promise for many practical
applications like robotics or autonomous cars, current approaches require
specifying constraints in mathematical form. Such specifications demand domain
expertise, limiting the adoption of safe RL. In this paper, we propose learning
to interpret natural language constraints for safe RL. To this end, we first
introduce HazardWorld, a new multi-task benchmark that requires an agent to
optimize reward while not violating constraints specified in free-form text. We
then develop an agent with a modular architecture that can interpret and adhere
to such textual constraints while learning new tasks. Our model consists of (1)
a constraint interpreter that encodes textual constraints into spatial and
temporal representations of forbidden states, and (2) a policy network that
uses these representations to produce a policy achieving minimal constraint
violations during training. Across different domains in HazardWorld, we show
that our method achieves higher rewards (up to11x) and fewer constraint
violations (by 1.8x) compared to existing approaches. However, in terms of
absolute performance, HazardWorld still poses significant challenges for agents
to learn efficiently, motivating the need for future work.",arxiv
http://arxiv.org/abs/2106.00922v2,2021-06-11T20:57:53Z,2021-06-02T03:45:43Z,"An Empirical Comparison of Off-policy Prediction Learning Algorithms on
  the Collision Task","Off-policy prediction -- learning the value function for one policy from data
generated while following another policy -- is one of the most challenging
subproblems in reinforcement learning. This paper presents empirical results
with eleven prominent off-policy learning algorithms that use linear function
approximation: five Gradient-TD methods, two Emphatic-TD methods, Off-policy
TD($\lambda$), Vtrace, and versions of Tree Backup and ABQ modified to apply to
a prediction setting. Our experiments used the Collision task, a small
idealized off-policy problem analogous to that of an autonomous car trying to
predict whether it will collide with an obstacle. We assessed the performance
of the algorithms according to their learning rate, asymptotic error level, and
sensitivity to step-size and bootstrapping parameters. By these measures, the
eleven algorithms can be partially ordered on the Collision task. In the top
tier, the two Emphatic-TD algorithms learned the fastest, reached the lowest
errors, and were robust to parameter settings. In the middle tier, the five
Gradient-TD algorithms and Off-policy TD($\lambda$) were more sensitive to the
bootstrapping parameter. The bottom tier comprised Vtrace, Tree Backup, and
ABQ; these algorithms were no faster and had higher asymptotic error than the
others. Our results are definitive for this task, though of course experiments
with more tasks are needed before an overall assessment of the algorithms'
merits can be made.",arxiv
http://arxiv.org/abs/2110.00808v1,2021-10-02T13:55:50Z,2021-10-02T13:55:50Z,Cycle-Consistent World Models for Domain Independent Latent Imagination,"End-to-end autonomous driving seeks to solve the perception, decision, and
control problems in an integrated way, which can be easier to generalize at
scale and be more adapting to new scenarios. However, high costs and risks make
it very hard to train autonomous cars in the real world. Simulations can
therefore be a powerful tool to enable training. Due to slightly different
observations, agents trained and evaluated solely in simulation often perform
well there but have difficulties in real-world environments. To tackle this
problem, we propose a novel model-based reinforcement learning approach called
Cycleconsistent World Models. Contrary to related approaches, our model can
embed two modalities in a shared latent space and thereby learn from samples in
one modality (e.g., simulated data) and be used for inference in different
domain (e.g., real-world data). Our experiments using different modalities in
the CARLA simulator showed that this enables CCWM to outperform
state-of-the-art domain adaptation approaches. Furthermore, we show that CCWM
can decode a given latent representation into semantically coherent
observations in both modalities.",arxiv
http://arxiv.org/abs/2007.00691v2,2020-07-17T16:29:31Z,2020-07-01T18:32:05Z,Falsification-Based Robust Adversarial Reinforcement Learning,"Reinforcement learning (RL) has achieved tremendous progress in solving
various sequential decision-making problems, e.g., control tasks in robotics.
However, RL methods often fail to generalize to safety-critical scenarios since
policies are overfitted to training environments. Previously, robust
adversarial reinforcement learning (RARL) was proposed to train an adversarial
network that applies disturbances to a system, which improves robustness in
test scenarios. A drawback of neural-network-based adversaries is that
integrating system requirements without handcrafting sophisticated reward
signals is difficult. Safety falsification methods allow one to find a set of
initial conditions as well as an input sequence, such that the system violates
a given property formulated in temporal logic. In this paper, we propose
falsification-based RARL (FRARL), the first generic framework for integrating
temporal-logic falsification in adversarial learning to improve policy
robustness. With falsification method, we do not need to construct an extra
reward function for the adversary. We evaluate our approach on a braking
assistance system and an adaptive cruise control system of autonomous vehicles.
Experiments show that policies trained with a falsification-based adversary
generalize better and show less violation of the safety specification in test
scenarios than the ones trained without an adversary or with an adversarial
network.",arxiv
http://arxiv.org/abs/2110.05437v1,2021-10-11T17:26:55Z,2021-10-11T17:26:55Z,"Autonomous Racing using a Hybrid Imitation-Reinforcement Learning
  Architecture","In this work, we present a rigorous end-to-end control strategy for
autonomous vehicles aimed at minimizing lap times in a time attack racing
event. We also introduce AutoRACE Simulator developed as a part of this
research project, which was employed to simulate accurate vehicular and
environmental dynamics along with realistic audio-visual effects. We adopted a
hybrid imitation-reinforcement learning architecture and crafted a novel reward
function to train a deep neural network policy to drive (using imitation
learning) and race (using reinforcement learning) a car autonomously in less
than 20 hours. Deployment results were reported as a direct comparison of 10
autonomous laps against 100 manual laps by 10 different human players. The
autonomous agent not only exhibited superior performance by gaining 0.96
seconds over the best manual lap, but it also dominated the human players by
1.46 seconds with regard to the mean lap time. This dominance could be
justified in terms of better trajectory optimization and lower reaction time of
the autonomous agent.",arxiv
http://arxiv.org/abs/1808.09526v2,2018-08-30T13:03:16Z,2018-08-28T20:27:16Z,Deep Lidar CNN to Understand the Dynamics of Moving Vehicles,"Perception technologies in Autonomous Driving are experiencing their golden
age due to the advances in Deep Learning. Yet, most of these systems rely on
the semantically rich information of RGB images. Deep Learning solutions
applied to the data of other sensors typically mounted on autonomous cars (e.g.
lidars or radars) are not explored much. In this paper we propose a novel
solution to understand the dynamics of moving vehicles of the scene from only
lidar information. The main challenge of this problem stems from the fact that
we need to disambiguate the proprio-motion of the 'observer' vehicle from that
of the external 'observed' vehicles. For this purpose, we devise a CNN
architecture which at testing time is fed with pairs of consecutive lidar
scans. However, in order to properly learn the parameters of this network,
during training we introduce a series of so-called pretext tasks which also
leverage on image data. These tasks include semantic information about
vehicleness and a novel lidar-flow feature which combines standard image-based
optical flow with lidar scans. We obtain very promising results and show that
including distilled image information only during training, allows improving
the inference results of the network at test time, even when image data is no
longer used.",arxiv
http://arxiv.org/abs/1912.10241v1,2019-12-21T10:33:56Z,2019-12-21T10:33:56Z,"Seek and You Will Find: A New Optimized Framework for Efficient
  Detection of Pedestrian","Studies of object detection and localization, particularly pedestrian
detection have received considerable attention in recent times due to its
several prospective applications such as surveillance, driving assistance,
autonomous cars, etc. Also, a significant trend of latest research studies in
related problem areas is the use of sophisticated Deep Learning based
approaches to improve the benchmark performance on various standard datasets. A
trade-off between the speed (number of video frames processed per second) and
detection accuracy has often been reported in the existing literature. In this
article, we present a new but simple deep learning based strategy for
pedestrian detection that improves this trade-off. Since training of similar
models using publicly available sample datasets failed to improve the detection
performance to some significant extent, particularly for the instances of
pedestrians of smaller sizes, we have developed a new sample dataset consisting
of more than 80K annotated pedestrian figures in videos recorded under varying
traffic conditions. Performance of the proposed model on the test samples of
the new dataset and two other existing datasets, namely Caltech Pedestrian
Dataset (CPD) and CityPerson Dataset (CD) have been obtained. Our proposed
system shows nearly 16\% improvement over the existing state-of-the-art result.",arxiv
http://arxiv.org/abs/2101.06175v1,2021-01-15T15:36:22Z,2021-01-15T15:36:22Z,PaddleSeg: A High-Efficient Development Toolkit for Image Segmentation,"Image Segmentation plays an essential role in computer vision and image
processing with various applications from medical diagnosis to autonomous car
driving. A lot of segmentation algorithms have been proposed for addressing
specific problems. In recent years, the success of deep learning techniques has
tremendously influenced a wide range of computer vision areas, and the modern
approaches of image segmentation based on deep learning are becoming prevalent.
In this article, we introduce a high-efficient development toolkit for image
segmentation, named PaddleSeg. The toolkit aims to help both developers and
researchers in the whole process of designing segmentation models, training
models, optimizing performance and inference speed, and deploying models.
Currently, PaddleSeg supports around 20 popular segmentation models and more
than 50 pre-trained models from real-time and high-accuracy levels. With
modular components and backbone networks, users can easily build over one
hundred models for different requirements. Furthermore, we provide
comprehensive benchmarks and evaluations to show that these segmentation
algorithms trained on our toolkit have more competitive accuracy. Also, we
provide various real industrial applications and practical cases based on
PaddleSeg. All codes and examples of PaddleSeg are available at
https://github.com/PaddlePaddle/PaddleSeg.",arxiv
http://arxiv.org/abs/1906.01562v2,2019-09-27T13:22:08Z,2019-06-04T16:27:47Z,Privacy-preserving Crowd-guided AI Decision-making in Ethical Dilemmas,"With the rapid development of artificial intelligence (AI), ethical issues
surrounding AI have attracted increasing attention. In particular, autonomous
vehicles may face moral dilemmas in accident scenarios, such as staying the
course resulting in hurting pedestrians or swerving leading to hurting
passengers. To investigate such ethical dilemmas, recent studies have adopted
preference aggregation, in which each voter expresses her/his preferences over
decisions for the possible ethical dilemma scenarios, and a centralized system
aggregates these preferences to obtain the winning decision. Although a useful
methodology for building ethical AI systems, such an approach can potentially
violate the privacy of voters since moral preferences are sensitive information
and their disclosure can be exploited by malicious parties. In this paper, we
report a first-of-its-kind privacy-preserving crowd-guided AI decision-making
approach in ethical dilemmas. We adopt the notion of differential privacy to
quantify privacy and consider four granularities of privacy protection by
taking voter-/record-level privacy protection and centralized/distributed
perturbation into account, resulting in four approaches VLCP, RLCP, VLDP, and
RLDP. Moreover, we propose different algorithms to achieve these privacy
protection granularities, while retaining the accuracy of the learned moral
preference model. Specifically, VLCP and RLCP are implemented with the data
aggregator setting a universal privacy parameter and perturbing the averaged
moral preference to protect the privacy of voters' data. VLDP and RLDP are
implemented in such a way that each voter perturbs her/his local moral
preference with a personalized privacy parameter. Extensive experiments on both
synthetic and real data demonstrate that the proposed approach can achieve high
accuracy of preference aggregation while protecting individual voter's privacy.",arxiv
http://arxiv.org/abs/1901.08394v1,2019-01-24T13:20:25Z,2019-01-24T13:20:25Z,"Application of Decision Rules for Handling Class Imbalance in Semantic
  Segmentation","As part of autonomous car driving systems, semantic segmentation is an
essential component to obtain a full understanding of the car's environment.
One difficulty, that occurs while training neural networks for this purpose, is
class imbalance of training data. Consequently, a neural network trained on
unbalanced data in combination with maximum a-posteriori classification may
easily ignore classes that are rare in terms of their frequency in the dataset.
However, these classes are often of highest interest. We approach such
potential misclassifications by weighting the posterior class probabilities
with the prior class probabilities which in our case are the inverse
frequencies of the corresponding classes in the training dataset. More
precisely, we adopt a localized method by computing the priors pixel-wise such
that the impact can be analyzed at pixel level as well. In our experiments, we
train one network from scratch using a proprietary dataset containing 20,000
annotated frames of video sequences recorded from street scenes. The evaluation
on our test set shows an increase of average recall with regard to instances of
pedestrians and info signs by $25\%$ and $23.4\%$, respectively. In addition,
we significantly reduce the non-detection rate for instances of the same
classes by $61\%$ and $38\%$.",arxiv
http://arxiv.org/abs/2106.00687v1,2021-06-01T18:00:02Z,2021-06-01T18:00:02Z,"Online Detection of Vibration Anomalies Using Balanced Spiking Neural
  Networks","Vibration patterns yield valuable information about the health state of a
running machine, which is commonly exploited in predictive maintenance tasks
for large industrial systems. However, the overhead, in terms of size,
complexity and power budget, required by classical methods to exploit this
information is often prohibitive for smaller-scale applications such as
autonomous cars, drones or robotics. Here we propose a neuromorphic approach to
perform vibration analysis using spiking neural networks that can be applied to
a wide range of scenarios. We present a spike-based end-to-end pipeline able to
detect system anomalies from vibration data, using building blocks that are
compatible with analog-digital neuromorphic circuits. This pipeline operates in
an online unsupervised fashion, and relies on a cochlea model, on feedback
adaptation and on a balanced spiking neural network. We show that the proposed
method achieves state-of-the-art performance or better against two publicly
available data sets. Further, we demonstrate a working proof-of-concept
implemented on an asynchronous neuromorphic processor device. This work
represents a significant step towards the design and implementation of
autonomous low-power edge-computing devices for online vibration monitoring.",arxiv
http://arxiv.org/abs/1712.04248v2,2018-02-16T14:40:42Z,2017-12-12T11:36:26Z,"Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box
  Machine Learning Models","Many machine learning algorithms are vulnerable to almost imperceptible
perturbations of their inputs. So far it was unclear how much risk adversarial
perturbations carry for the safety of real-world machine learning applications
because most methods used to generate such perturbations rely either on
detailed model information (gradient-based attacks) or on confidence scores
such as class probabilities (score-based attacks), neither of which are
available in most real-world scenarios. In many such cases one currently needs
to retreat to transfer-based attacks which rely on cumbersome substitute
models, need access to the training data and can be defended against. Here we
emphasise the importance of attacks which solely rely on the final model
decision. Such decision-based attacks are (1) applicable to real-world
black-box models such as autonomous cars, (2) need less knowledge and are
easier to apply than transfer-based attacks and (3) are more robust to simple
defences than gradient- or score-based attacks. Previous attacks in this
category were limited to simple models or simple datasets. Here we introduce
the Boundary Attack, a decision-based attack that starts from a large
adversarial perturbation and then seeks to reduce the perturbation while
staying adversarial. The attack is conceptually simple, requires close to no
hyperparameter tuning, does not rely on substitute models and is competitive
with the best gradient-based attacks in standard computer vision tasks like
ImageNet. We apply the attack on two black-box algorithms from Clarifai.com.
The Boundary Attack in particular and the class of decision-based attacks in
general open new avenues to study the robustness of machine learning models and
raise new questions regarding the safety of deployed machine learning systems.
An implementation of the attack is available as part of Foolbox at
https://github.com/bethgelab/foolbox .",arxiv
http://arxiv.org/abs/2006.15175v1,2020-06-26T19:06:32Z,2020-06-26T19:06:32Z,Application of Neuroevolution in Autonomous Cars,"With the onset of Electric vehicles, and them becoming more and more popular,
autonomous cars are the future in the travel/driving experience. The barrier to
reaching level 5 autonomy is the difficulty in the collection of data that
incorporates good driving habits and the lack thereof. The problem with current
implementations of self-driving cars is the need for massively large datasets
and the need to evaluate the driving in the dataset. We propose a system that
requires no data for its training. An evolutionary model would have the
capability to optimize itself towards the fitness function. We have implemented
Neuroevolution, a form of genetic algorithm, to train/evolve self-driving cars
in a simulated virtual environment with the help of Unreal Engine 4, which
utilizes Nvidia's PhysX Physics Engine to portray real-world vehicle dynamics
accurately. We were able to observe the serendipitous nature of evolution and
have exploited it to reach our optimal solution. We also demonstrate the ease
in generalizing attributes brought about by genetic algorithms and how they may
be used as a boilerplate upon which other machine learning techniques may be
used to improve the overall driving experience.",arxiv
http://arxiv.org/abs/2005.07474v1,2020-05-15T11:31:54Z,2020-05-15T11:31:54Z,Robot Accident Investigation: a case study in Responsible Robotics,"Robot accidents are inevitable. Although rare, they have been happening since
assembly-line robots were first introduced in the 1960s. But a new generation
of social robots are now becoming commonplace. Often with sophisticated
embedded artificial intelligence (AI) social robots might be deployed as care
robots to assist elderly or disabled people to live independently. Smart robot
toys offer a compelling interactive play experience for children and
increasingly capable autonomous vehicles (AVs) the promise of hands-free
personal transport and fully autonomous taxis. Unlike industrial robots which
are deployed in safety cages, social robots are designed to operate in human
environments and interact closely with humans; the likelihood of robot
accidents is therefore much greater for social robots than industrial robots.
This paper sets out a draft framework for social robot accident investigation;
a framework which proposes both the technology and processes that would allow
social robot accidents to be investigated with no less rigour than we expect of
air or rail accident investigations. The paper also places accident
investigation within the practice of responsible robotics, and makes the case
that social robotics without accident investigation would be no less
irresponsible than aviation without air accident investigation.",arxiv
http://arxiv.org/abs/1611.05497v4,2019-03-13T18:40:29Z,2016-11-16T23:24:38Z,Explicablility as Minimizing Distance from Expected Behavior,"In order to have effective human-AI collaboration, it is necessary to address
how the AI agent's behavior is being perceived by the humans-in-the-loop. When
the agent's task plans are generated without such considerations, they may
often demonstrate inexplicable behavior from the human's point of view. This
problem may arise due to the human's partial or inaccurate understanding of the
agent's planning model. This may have serious implications from increased
cognitive load to more serious concerns of safety around a physical agent. In
this paper, we address this issue by modeling plan explicability as a function
of the distance between a plan that agent makes and the plan that human expects
it to make. We learn a regression model for mapping the plan distances to
explicability scores of plans and develop an anytime search algorithm that can
use this model as a heuristic to come up with progressively explicable plans.
We evaluate the effectiveness of our approach in a simulated autonomous car
domain and a physical robot domain.",arxiv
http://arxiv.org/abs/1801.08618v2,2020-02-04T20:53:08Z,2018-01-25T22:20:11Z,"JointDNN: An Efficient Training and Inference Engine for Intelligent
  Mobile Cloud Computing Services","Deep learning models are being deployed in many mobile intelligent
applications. End-side services, such as intelligent personal assistants,
autonomous cars, and smart home services often employ either simple local
models on the mobile or complex remote models on the cloud. However, recent
studies have shown that partitioning the DNN computations between the mobile
and cloud can increase the latency and energy efficiencies. In this paper, we
propose an efficient, adaptive, and practical engine, JointDNN, for
collaborative computation between a mobile device and cloud for DNNs in both
inference and training phase. JointDNN not only provides an energy and
performance efficient method of querying DNNs for the mobile side but also
benefits the cloud server by reducing the amount of its workload and
communications compared to the cloud-only approach. Given the DNN architecture,
we investigate the efficiency of processing some layers on the mobile device
and some layers on the cloud server. We provide optimization formulations at
layer granularity for forward- and backward-propagations in DNNs, which can
adapt to mobile battery limitations and cloud server load constraints and
quality of service. JointDNN achieves up to 18 and 32 times reductions on the
latency and mobile energy consumption of querying DNNs compared to the
status-quo approaches, respectively.",arxiv
http://arxiv.org/abs/1911.08644v1,2019-11-20T00:43:07Z,2019-11-20T00:43:07Z,Generate (non-software) Bugs to Fool Classifiers,"In adversarial attacks intended to confound deep learning models, most
studies have focused on limiting the magnitude of the modification so that
humans do not notice the attack. On the other hand, during an attack against
autonomous cars, for example, most drivers would not find it strange if a small
insect image were placed on a stop sign, or they may overlook it. In this
paper, we present a systematic approach to generate natural adversarial
examples against classification models by employing such natural-appearing
perturbations that imitate a certain object or signal. We first show the
feasibility of this approach in an attack against an image classifier by
employing generative adversarial networks that produce image patches that have
the appearance of a natural object to fool the target model. We also introduce
an algorithm to optimize placement of the perturbation in accordance with the
input image, which makes the generation of adversarial examples fast and likely
to succeed. Moreover, we experimentally show that the proposed approach can be
extended to the audio domain, for example, to generate perturbations that sound
like the chirping of birds to fool a speech classifier.",arxiv
http://arxiv.org/abs/2004.08118v1,2020-04-17T08:49:54Z,2020-04-17T08:49:54Z,"Object Detection and Recognition of Swap-Bodies using Camera mounted on
  a Vehicle","Object detection and identification is a challenging area of computer vision
and a fundamental requirement for autonomous cars. This project aims to jointly
perform object detection of a swap-body and to find the type of swap-body by
reading an ILU code using an efficient optical character recognition (OCR)
method. Recent research activities have drastically improved deep learning
techniques which proves to enhance the field of computer vision. Collecting
enough images for training the model is a critical step towards achieving good
results. The data for training were collected from different locations with
maximum possible variations and the details are explained. In addition, data
augmentation methods applied for training has proved to be effective in
improving the performance of the trained model. Training the model achieved
good results and the test results are also provided. The final model was tested
with images and videos. Finally, this paper also draws attention to some of the
major challenges faced during various stages of the project and the possible
solutions applied.",arxiv
http://arxiv.org/abs/2104.08862v1,2021-04-18T14:05:18Z,2021-04-18T14:05:18Z,"End-to-End Interactive Prediction and Planning with Optical Flow
  Distillation for Autonomous Driving","With the recent advancement of deep learning technology, data-driven
approaches for autonomous car prediction and planning have achieved
extraordinary performance. Nevertheless, most of these approaches follow a
non-interactive prediction and planning paradigm, hypothesizing that a
vehicle's behaviors do not affect others. The approaches based on such a
non-interactive philosophy typically perform acceptably in sparse traffic
scenarios but can easily fail in dense traffic scenarios. Therefore, we propose
an end-to-end interactive neural motion planner (INMP) for autonomous driving
in this paper. Given a set of past surrounding-view images and a high
definition map, our INMP first generates a feature map in bird's-eye-view
space, which is then processed to detect other agents and perform interactive
prediction and planning jointly. Also, we adopt an optical flow distillation
paradigm, which can effectively improve the network performance while still
maintaining its real-time inference speed. Extensive experiments on the
nuScenes dataset and in the closed-loop Carla simulation environment
demonstrate the effectiveness and efficiency of our INMP for the detection,
prediction, and planning tasks. Our project page is at
sites.google.com/view/inmp-ofd.",arxiv
http://arxiv.org/abs/2106.12735v2,2021-06-25T15:39:13Z,2021-06-24T02:52:12Z,Multi-Modal 3D Object Detection in Autonomous Driving: a Survey,"In the past few years, we have witnessed rapid development of autonomous
driving. However, achieving full autonomy remains a daunting task due to the
complex and dynamic driving environment. As a result, self-driving cars are
equipped with a suite of sensors to conduct robust and accurate environment
perception. As the number and type of sensors keep increasing, combining them
for better perception is becoming a natural trend. So far, there has been no
indepth review that focuses on multi-sensor fusion based perception. To bridge
this gap and motivate future research, this survey devotes to review recent
fusion-based 3D detection deep learning models that leverage multiple sensor
data sources, especially cameras and LiDARs. In this survey, we first introduce
the background of popular sensors for autonomous cars, including their common
data representations as well as object detection networks developed for each
type of sensor data. Next, we discuss some popular datasets for multi-modal 3D
object detection, with a special focus on the sensor data included in each
dataset. Then we present in-depth reviews of recent multi-modal 3D detection
networks by considering the following three aspects of the fusion: fusion
location, fusion data representation, and fusion granularity. After a detailed
review, we discuss open challenges and point out possible solutions. We hope
that our detailed review can help researchers to embark investigations in the
area of multi-modal 3D object detection.",arxiv
http://arxiv.org/abs/2003.01886v1,2020-03-04T04:35:22Z,2020-03-04T04:35:22Z,"Efficient statistical validation with edge cases to evaluate Highly
  Automated Vehicles","The widescale deployment of Autonomous Vehicles (AV) seems to be imminent
despite many safety challenges that are yet to be resolved. It is well known
that there are no universally agreed Verification and Validation (VV)
methodologies to guarantee absolute safety, which is crucial for the acceptance
of this technology. Existing standards focus on deterministic processes where
the validation requires only a set of test cases that cover the requirements.
Modern autonomous vehicles will undoubtedly include machine learning and
probabilistic techniques that require a much more comprehensive testing regime
due to the non-deterministic nature of the operating design domain. A rigourous
statistical validation process is an essential component required to address
this challenge. Most research in this area focuses on evaluating system
performance in large scale real-world data gathering exercises (number of miles
travelled), or randomised test scenarios in simulation.
  This paper presents a new approach to compute the statistical characteristics
of a system's behaviour by biasing automatically generated test cases towards
the worst case scenarios, identifying potential unsafe edge cases.We use
reinforcement learning (RL) to learn the behaviours of simulated actors that
cause unsafe behaviour measured by the well established RSS safety metric. We
demonstrate that by using the method we can more efficiently validate a system
using a smaller number of test cases by focusing the simulation towards the
worst case scenario, generating edge cases that correspond to unsafe
situations.",arxiv
http://arxiv.org/abs/1805.05010v2,2018-05-17T08:38:04Z,2018-05-14T04:48:24Z,"Detecting Adversarial Samples for Deep Neural Networks through Mutation
  Testing","Recently, it has been shown that deep neural networks (DNN) are subject to
attacks through adversarial samples. Adversarial samples are often crafted
through adversarial perturbation, i.e., manipulating the original sample with
minor modifications so that the DNN model labels the sample incorrectly. Given
that it is almost impossible to train perfect DNN, adversarial samples are
shown to be easy to generate. As DNN are increasingly used in safety-critical
systems like autonomous cars, it is crucial to develop techniques for defending
such attacks. Existing defense mechanisms which aim to make adversarial
perturbation challenging have been shown to be ineffective. In this work, we
propose an alternative approach. We first observe that adversarial samples are
much more sensitive to perturbations than normal samples. That is, if we impose
random perturbations on a normal and an adversarial sample respectively, there
is a significant difference between the ratio of label change due to the
perturbations. Observing this, we design a statistical adversary detection
algorithm called nMutant (inspired by mutation testing from software
engineering community). Our experiments show that nMutant effectively detects
most of the adversarial samples generated by recently proposed attacking
methods. Furthermore, we provide an error bound with certain statistical
significance along with the detection.",arxiv
http://arxiv.org/abs/1812.00733v2,2019-04-07T11:51:26Z,2018-12-03T13:50:40Z,"Attention-based Adaptive Selection of Operations for Image Restoration
  in the Presence of Unknown Combined Distortions","Many studies have been conducted so far on image restoration, the problem of
restoring a clean image from its distorted version. There are many different
types of distortion which affect image quality. Previous studies have focused
on single types of distortion, proposing methods for removing them. However,
image quality degrades due to multiple factors in the real world. Thus,
depending on applications, e.g., vision for autonomous cars or surveillance
cameras, we need to be able to deal with multiple combined distortions with
unknown mixture ratios. For this purpose, we propose a simple yet effective
layer architecture of neural networks. It performs multiple operations in
parallel, which are weighted by an attention mechanism to enable selection of
proper operations depending on the input. The layer can be stacked to form a
deep network, which is differentiable and thus can be trained in an end-to-end
fashion by gradient descent. The experimental results show that the proposed
method works better than previous methods by a good margin on tasks of
restoring images with multiple combined distortions.",arxiv
http://arxiv.org/abs/1911.05904v1,2019-11-14T02:36:40Z,2019-11-14T02:36:40Z,"There is Limited Correlation between Coverage and Robustness for Deep
  Neural Networks","Deep neural networks (DNN) are increasingly applied in safety-critical
systems, e.g., for face recognition, autonomous car control and malware
detection. It is also shown that DNNs are subject to attacks such as
adversarial perturbation and thus must be properly tested. Many coverage
criteria for DNN since have been proposed, inspired by the success of code
coverage criteria for software programs. The expectation is that if a DNN is a
well tested (and retrained) according to such coverage criteria, it is more
likely to be robust. In this work, we conduct an empirical study to evaluate
the relationship between coverage, robustness and attack/defense metrics for
DNN. Our study is the largest to date and systematically done based on 100 DNN
models and 25 metrics. One of our findings is that there is limited correlation
between coverage and robustness, i.e., improving coverage does not help improve
the robustness. Our dataset and implementation have been made available to
serve as a benchmark for future studies on testing DNN.",arxiv
http://arxiv.org/abs/1911.10621v1,2019-11-24T22:18:54Z,2019-11-24T22:18:54Z,DeepSmartFuzzer: Reward Guided Test Generation For Deep Learning,"Testing Deep Neural Network (DNN) models has become more important than ever
with the increasing usage of DNN models in safety-critical domains such as
autonomous cars. The traditional approach of testing DNNs is to create a test
set, which is a random subset of the dataset about the problem of interest.
This kind of approach is not enough for testing most of the real-world
scenarios since these traditional test sets do not include corner cases, while
a corner case input is generally considered to introduce erroneous behaviors.
Recent works on adversarial input generation, data augmentation, and
coverage-guided fuzzing (CGF) have provided new ways to extend traditional test
sets. Among those, CGF aims to produce new test inputs by fuzzing existing ones
to achieve high coverage on a test adequacy criterion (i.e. coverage
criterion). Given that the subject test adequacy criterion is a
well-established one, CGF can potentially find error inducing inputs for
different underlying reasons. In this paper, we propose a novel CGF solution
for structural testing of DNNs. The proposed fuzzer employs Monte Carlo Tree
Search to drive the coverage-guided search in the pursuit of achieving high
coverage. Our evaluation shows that the inputs generated by our method result
in higher coverage than the inputs produced by the previously introduced
coverage-guided fuzzing techniques.",arxiv
http://arxiv.org/abs/2001.04074v3,2020-05-29T07:23:43Z,2020-01-13T06:07:27Z,"Evolution of Image Segmentation using Deep Convolutional Neural Network:
  A Survey","From the autonomous car driving to medical diagnosis, the requirement of the
task of image segmentation is everywhere. Segmentation of an image is one of
the indispensable tasks in computer vision. This task is comparatively
complicated than other vision tasks as it needs low-level spatial information.
Basically, image segmentation can be of two types: semantic segmentation and
instance segmentation. The combined version of these two basic tasks is known
as panoptic segmentation. In the recent era, the success of deep convolutional
neural networks (CNN) has influenced the field of segmentation greatly and gave
us various successful models to date. In this survey, we are going to take a
glance at the evolution of both semantic and instance segmentation work based
on CNN. We have also specified comparative architectural details of some
state-of-the-art models and discuss their training details to present a lucid
understanding of hyper-parameter tuning of those models. We have also drawn a
comparison among the performance of those models on different datasets. Lastly,
we have given a glimpse of some state-of-the-art panoptic segmentation models.",arxiv
http://arxiv.org/abs/2004.05077v1,2020-04-10T15:44:52Z,2020-04-10T15:44:52Z,"CNN Encoder to Reduce the Dimensionality of Data Image for Motion
  Planning","Many real-world applications need path planning algorithms to solve tasks in
different areas, such as social applications, autonomous cars, and tracking
activities. And most importantly motion planning. Although the use of path
planning is sufficient in most motion planning scenarios, they represent
potential bottlenecks in large environments with dynamic changes. To tackle
this problem, the number of possible routes could be reduced to make it easier
for path planning algorithms to find the shortest path with less efforts. An
traditional algorithm for path planning is the A*, it uses an heuristic to work
faster than other solutions. In this work, we propose a CNN encoder capable of
eliminating useless routes for motion planning problems, then we combine the
proposed neural network output with A*. To measure the efficiency of our
solution, we propose a database with different scenarios of motion planning
problems. The evaluated metric is the number of the iterations to find the
shortest path. The A* was compared with the CNN Encoder (proposal) with A*. In
all evaluated scenarios, our solution reduced the number of iterations by more
than 60\%.",arxiv
http://arxiv.org/abs/2006.00894v2,2020-09-07T05:43:23Z,2020-05-29T06:33:55Z,"Reducing DNN Labelling Cost using Surprise Adequacy: An Industrial Case
  Study for Autonomous Driving","Deep Neural Networks (DNNs) are rapidly being adopted by the automotive
industry, due to their impressive performance in tasks that are essential for
autonomous driving. Object segmentation is one such task: its aim is to
precisely locate boundaries of objects and classify the identified objects,
helping autonomous cars to recognise the road environment and the traffic
situation. Not only is this task safety critical, but developing a DNN based
object segmentation module presents a set of challenges that are significantly
different from traditional development of safety critical software. The
development process in use consists of multiple iterations of data collection,
labelling, training, and evaluation. Among these stages, training and
evaluation are computation intensive while data collection and labelling are
manual labour intensive. This paper shows how development of DNN based object
segmentation can be improved by exploiting the correlation between Surprise
Adequacy (SA) and model performance. The correlation allows us to predict model
performance for inputs without manually labelling them. This, in turn, enables
understanding of model performance, more guided data collection, and informed
decisions about further training. In our industrial case study the technique
allows cost savings of up to 50% with negligible evaluation inaccuracy.
Furthermore, engineers can trade off cost savings versus the tolerable level of
inaccuracy depending on different development phases and scenarios.",arxiv
http://arxiv.org/abs/2012.02529v1,2020-12-04T11:22:13Z,2020-12-04T11:22:13Z,"Deep Interference Mitigation and Denoising of Real-World FMCW Radar
  Signals","Radar sensors are crucial for environment perception of driver assistance
systems as well as autonomous cars. Key performance factors are a fine range
resolution and the possibility to directly measure velocity. With a rising
number of radar sensors and the so far unregulated automotive radar frequency
band, mutual interference is inevitable and must be dealt with. Sensors must be
capable of detecting, or even mitigating the harmful effects of interference,
which include a decreased detection sensitivity. In this paper, we evaluate a
Convolutional Neural Network (CNN)-based approach for interference mitigation
on real-world radar measurements. We combine real measurements with simulated
interference in order to create input-output data suitable for training the
model. We analyze the performance to model complexity relation on simulated and
measurement data, based on an extensive parameter search. Further, a finite
sample size performance comparison shows the effectiveness of the model trained
on either simulated or real data as well as for transfer learning. A
comparative performance analysis with the state of the art emphasizes the
potential of CNN-based models for interference mitigation and denoising of
real-world measurements, also considering resource constraints of the hardware.",arxiv
http://arxiv.org/abs/2105.04529v1,2021-05-10T17:32:23Z,2021-05-10T17:32:23Z,"Identification of the nonlinear steering dynamics of an autonomous
  vehicle","Automated driving applications require accurate vehicle specific models to
precisely predict and control the motion dynamics. However, modern vehicles
have a wide array of digital and mechatronic components that are difficult to
model, manufactures do not disclose all details required for modelling and even
existing models of subcomponents require coefficient estimation to match the
specific characteristics of each vehicle and their change over time. Hence, it
is attractive to use data-driven modelling to capture the relevant vehicle
dynamics and synthesise model-based control solutions. In this paper, we
address identification of the steering system of an autonomous car based on
measured data. We show that the underlying dynamics are highly nonlinear and
challenging to be captured, necessitating the use of data-driven methods that
fuse the approximation capabilities of learning and the efficiency of dynamic
system identification. We demonstrate that such a neural network based
subspace-encoder method can successfully capture the underlying dynamics while
other methods fall short to provide reliable results.",arxiv
http://arxiv.org/abs/2105.10843v2,2021-07-25T17:13:43Z,2021-05-23T01:50:44Z,"Exploring Robustness of Unsupervised Domain Adaptation in Semantic
  Segmentation","Recent studies imply that deep neural networks are vulnerable to adversarial
examples -- inputs with a slight but intentional perturbation are incorrectly
classified by the network. Such vulnerability makes it risky for some
security-related applications (e.g., semantic segmentation in autonomous cars)
and triggers tremendous concerns on the model reliability. For the first time,
we comprehensively evaluate the robustness of existing UDA methods and propose
a robust UDA approach. It is rooted in two observations: (i) the robustness of
UDA methods in semantic segmentation remains unexplored, which pose a security
concern in this field; and (ii) although commonly used self-supervision (e.g.,
rotation and jigsaw) benefits image tasks such as classification and
recognition, they fail to provide the critical supervision signals that could
learn discriminative representation for segmentation tasks. These observations
motivate us to propose adversarial self-supervision UDA (or ASSUDA) that
maximizes the agreement between clean images and their adversarial examples by
a contrastive loss in the output space. Extensive empirical studies on commonly
used benchmarks demonstrate that ASSUDA is resistant to adversarial attacks.",arxiv
http://arxiv.org/abs/2105.11344v1,2021-05-24T15:28:32Z,2021-05-24T15:28:32Z,OverlapNet: Loop Closing for LiDAR-based SLAM,"Simultaneous localization and mapping (SLAM) is a fundamental capability
required by most autonomous systems. In this paper, we address the problem of
loop closing for SLAM based on 3D laser scans recorded by autonomous cars. Our
approach utilizes a deep neural network exploiting different cues generated
from LiDAR data for finding loop closures. It estimates an image overlap
generalized to range images and provides a relative yaw angle estimate between
pairs of scans. Based on such predictions, we tackle loop closure detection and
integrate our approach into an existing SLAM system to improve its mapping
results. We evaluate our approach on sequences of the KITTI odometry benchmark
and the Ford campus dataset. We show that our method can effectively detect
loop closures surpassing the detection performance of state-of-the-art methods.
To highlight the generalization capabilities of our approach, we evaluate our
model on the Ford campus dataset while using only KITTI for training. The
experiments show that the learned representation is able to provide reliable
loop closure candidates, also in unseen environments.",arxiv
http://arxiv.org/abs/2107.04863v1,2021-07-10T15:40:12Z,2021-07-10T15:40:12Z,"HOMRS: High Order Metamorphic Relations Selector for Deep Neural
  Networks","Deep Neural Networks (DNN) applications are increasingly becoming a part of
our everyday life, from medical applications to autonomous cars. Traditional
validation of DNN relies on accuracy measures, however, the existence of
adversarial examples has highlighted the limitations of these accuracy
measures, raising concerns especially when DNN are integrated into
safety-critical systems. In this paper, we present HOMRS, an approach to boost
metamorphic testing by automatically building a small optimized set of high
order metamorphic relations from an initial set of elementary metamorphic
relations. HOMRS' backbone is a multi-objective search; it exploits ideas drawn
from traditional systems testing such as code coverage, test case, and path
diversity. We applied HOMRS to LeNet5 DNN with MNIST dataset and we report
evidence that it builds a small but effective set of high order transformations
achieving a 95% kill ratio. Five raters manually labeled a pool of images
before and after high order transformation; Fleiss' Kappa and statistical tests
confirmed that they are metamorphic properties. HOMRS built-in relations are
also effective to confront adversarial or out-of-distribution examples; HOMRS
detected 92% of randomly sampled out-of-distribution images. HOMRS
transformations are also suitable for online real-time use.",arxiv
http://arxiv.org/abs/2109.07365v1,2021-09-15T15:20:36Z,2021-09-15T15:20:36Z,"Maneuver-based Trajectory Prediction for Self-driving Cars Using
  Spatio-temporal Convolutional Networks","The ability to predict the future movements of other vehicles is a
subconscious and effortless skill for humans and key to safe autonomous
driving. Therefore, trajectory prediction for autonomous cars has gained a lot
of attention in recent years. It is, however, still a hard task to achieve
human-level performance. Interdependencies between vehicle behaviors and the
multimodal nature of future intentions in a dynamic and complex driving
environment render trajectory prediction a challenging problem. In this work,
we propose a new, data-driven approach for predicting the motion of vehicles in
a road environment. The model allows for inferring future intentions from the
past interaction among vehicles in highway driving scenarios. Using our
neighborhood-based data representation, the proposed system jointly exploits
correlations in the spatial and temporal domain using convolutional neural
networks. Our system considers multiple possible maneuver intentions and their
corresponding motion and predicts the trajectory for five seconds into the
future. We implemented our approach and evaluated it on two highway datasets
taken in different countries and are able to achieve a competitive prediction
performance.",arxiv
http://arxiv.org/abs/1904.00035v1,2019-03-29T18:15:24Z,2019-03-29T18:15:24Z,Autonomous Highway Driving using Deep Reinforcement Learning,"The operational space of an autonomous vehicle (AV) can be diverse and vary
significantly. This may lead to a scenario that was not postulated in the
design phase. Due to this, formulating a rule based decision maker for
selecting maneuvers may not be ideal. Similarly, it may not be effective to
design an a-priori cost function and then solve the optimal control problem in
real-time. In order to address these issues and to avoid peculiar behaviors
when encountering unforeseen scenario, we propose a reinforcement learning (RL)
based method, where the ego car, i.e., an autonomous vehicle, learns to make
decisions by directly interacting with simulated traffic. The decision maker
for AV is implemented as a deep neural network providing an action choice for a
given system state. In a critical application such as driving, an RL agent
without explicit notion of safety may not converge or it may need extremely
large number of samples before finding a reliable policy. To best address the
issue, this paper incorporates reinforcement learning with an additional short
horizon safety check (SC). In a critical scenario, the safety check will also
provide an alternate safe action to the agent provided if it exists. This leads
to two novel contributions. First, it generalizes the states that could lead to
undesirable ""near-misses"" or ""collisions "". Second, inclusion of safety check
can provide a safe and stable training environment. This significantly enhances
learning efficiency without inhibiting meaningful exploration to ensure safe
and optimal learned behavior. We demonstrate the performance of the developed
algorithm in highway driving scenario where the trained AV encounters varying
traffic density in a highway setting.",arxiv
http://arxiv.org/abs/2010.09548v2,2020-11-03T02:16:21Z,2020-10-19T14:22:47Z,"RONELD: Robust Neural Network Output Enhancement for Active Lane
  Detection","Accurate lane detection is critical for navigation in autonomous vehicles,
particularly the active lane which demarcates the single road space that the
vehicle is currently traveling on. Recent state-of-the-art lane detection
algorithms utilize convolutional neural networks (CNNs) to train deep learning
models on popular benchmarks such as TuSimple and CULane. While each of these
models works particularly well on train and test inputs obtained from the same
dataset, the performance drops significantly on unseen datasets of different
environments. In this paper, we present a real-time robust neural network
output enhancement for active lane detection (RONELD) method to identify,
track, and optimize active lanes from deep learning probability map outputs. We
first adaptively extract lane points from the probability map outputs, followed
by detecting curved and straight lanes before using weighted least squares
linear regression on straight lanes to fix broken lane edges resulting from
fragmentation of edge maps in real images. Lastly, we hypothesize true active
lanes through tracking preceding frames. Experimental results demonstrate an up
to two-fold increase in accuracy using RONELD on cross-dataset validation
tests.",arxiv
http://arxiv.org/abs/2106.08961v2,2021-07-31T02:25:10Z,2021-06-09T01:41:02Z,Intelligent-Tire-Based Slip Ratio Estimation Using Machine Learning,"Autonomous vehicles are most concerned about safety control issues, and the
slip ratio is critical to the safety of the vehicle control system. In this
paper, different machine learning algorithms (Neural Networks, Gradient
Boosting Machine, Random Forest, and Support Vector Machine) are used to train
the slip ratio estimation model based on the acceleration signals ($a_x$,
$a_y$, and $a_z$) from the tri-axial Micro-Electro Mechanical System (MEMS)
accelerometer utilized in the intelligent tire system, where the acceleration
signals are divided into four sets ($a_x/a_y/a_z$, $a_x/a_z$, $a_y/a_z$, and
$a_z$) as algorithm inputs. The experimental data used in this study are
collected through the MTS Flat-Trac tire test platform. Performance of
different slip ratio estimation models is compared using the NRMS errors in
10-fold cross-validation (CV). The results indicate that NN and GBM have more
promising accuracy, and the $a_z$ input type has a better performance compared
to other input types, with the best result being the estimation model of the NN
algorithm with $a_z$ as input, which results is 4.88\%. The present study with
the fusion of intelligent tire system and machine learning paves the way for
the accurate estimation of tire slip ratio under different driving conditions,
which will open up a new way of Autonomous vehicles, intelligent tires, and
tire slip ratio estimation.",arxiv
http://arxiv.org/abs/2110.05523v1,2021-10-11T18:02:43Z,2021-10-11T18:02:43Z,"UnfairGAN: An Enhanced Generative Adversarial Network for Raindrop
  Removal from A Single Image","Image deraining is a new challenging problem in real-world applications, such
as autonomous vehicles. In a bad weather condition of heavy rainfall,
raindrops, mainly hitting glasses or windshields, can significantly reduce
observation ability. Moreover, raindrops spreading over the glass can yield
refraction's physical effect, which seriously impedes the sightline or
undermine machine learning systems. In this paper, we propose an enhanced
generative adversarial network to deal with the challenging problems of
raindrops. UnfairGAN is an enhanced generative adversarial network that can
utilize prior high-level information, such as edges and rain estimation, to
boost deraining performance. To demonstrate UnfairGAN, we introduce a large
dataset for training deep learning models of rain removal. The experimental
results show that our proposed method is superior to other state-of-the-art
approaches of deraining raindrops regarding quantitative metrics and visual
quality.",arxiv
http://arxiv.org/abs/2110.08322v1,2021-10-15T19:12:42Z,2021-10-15T19:12:42Z,"Robustness of different loss functions and their impact on networks
  learning capability","Recent developments in AI have made it ubiquitous, every industry is trying
to adopt some form of intelligent processing of their data. Despite so many
advances in the field, AIs full capability is yet to be exploited by the
industry. Industries that involve some risk factors still remain cautious about
the usage of AI due to the lack of trust in such autonomous systems.
Present-day AI might be very good in a lot of things but it is very bad in
reasoning and this behavior of AI can lead to catastrophic results. Autonomous
cars crashing into a person or a drone getting stuck in a tree are a few
examples where AI decisions lead to catastrophic results. To develop insight
and generate an explanation about the learning capability of AI, we will try to
analyze the working of loss functions. For our case, we will use two sets of
loss functions, generalized loss functions like Binary cross-entropy or BCE and
specialized loss functions like Dice loss or focal loss. Through a series of
experiments, we will establish whether combining different loss functions is
better than using a single loss function and if yes, then what is the reason
behind it. In order to establish the difference between generalized loss and
specialized losses, we will train several models using the above-mentioned
losses and then compare their robustness on adversarial examples. In
particular, we will look at how fast the accuracy of different models decreases
when we change the pixels corresponding to the most salient gradients.",arxiv
http://arxiv.org/abs/2110.01232v1,2021-10-04T07:52:23Z,2021-10-04T07:52:23Z,Benchmarking Safety Monitors for Image Classifiers with Machine Learning,"High-accurate machine learning (ML) image classifiers cannot guarantee that
they will not fail at operation. Thus, their deployment in safety-critical
applications such as autonomous vehicles is still an open issue. The use of
fault tolerance mechanisms such as safety monitors is a promising direction to
keep the system in a safe state despite errors of the ML classifier. As the
prediction from the ML is the core information directly impacting safety, many
works are focusing on monitoring the ML model itself. Checking the efficiency
of such monitors in the context of safety-critical applications is thus a
significant challenge. Therefore, this paper aims at establishing a baseline
framework for benchmarking monitors for ML image classifiers. Furthermore, we
propose a framework covering the entire pipeline, from data generation to
evaluation. Our approach measures monitor performance with a broader set of
metrics than usually proposed in the literature. Moreover, we benchmark three
different monitor approaches in 79 benchmark datasets containing five
categories of out-of-distribution data for image classifiers: class novelty,
noise, anomalies, distributional shifts, and adversarial attacks. Our results
indicate that these monitors are no more accurate than a random monitor. We
also release the code of all experiments for reproducibility.",arxiv
http://arxiv.org/abs/2102.13190v1,2021-02-25T21:49:20Z,2021-02-25T21:49:20Z,"Machine Biometrics -- Towards Identifying Machines in a Smart City
  Environment","This paper deals with the identification of machines in a smart city
environment. The concept of machine biometrics is proposed in this work for the
first time, as a way to authenticate machine identities interacting with humans
in everyday life. This definition is imposed in modern years where autonomous
vehicles, social robots, etc. are considered active members of contemporary
societies. In this context, the case of car identification from the engine
behavioral biometrics is examined. For this purpose, 22 sound features were
extracted and their discrimination capabilities were tested in combination with
9 different machine learning classifiers, towards identifying 5 car
manufacturers. The experimental results revealed the ability of the proposed
biometrics to identify cars with high accuracy up to 98% for the case of the
Multilayer Perceptron (MLP) neural network model.",arxiv
http://arxiv.org/abs/2110.14010v2,2021-10-29T10:09:46Z,2021-10-26T20:39:36Z,MisConv: Convolutional Neural Networks for Missing Data,"Processing of missing data by modern neural networks, such as CNNs, remains a
fundamental, yet unsolved challenge, which naturally arises in many practical
applications, like image inpainting or autonomous vehicles and robots. While
imputation-based techniques are still one of the most popular solutions, they
frequently introduce unreliable information to the data and do not take into
account the uncertainty of estimation, which may be destructive for a machine
learning model. In this paper, we present MisConv, a general mechanism, for
adapting various CNN architectures to process incomplete images. By modeling
the distribution of missing values by the Mixture of Factor Analyzers, we cover
the spectrum of possible replacements and find an analytical formula for the
expected value of convolution operator applied to the incomplete image. The
whole framework is realized by matrix operations, which makes MisConv extremely
efficient in practice. Experiments performed on various image processing tasks
demonstrate that MisConv achieves superior or comparable performance to the
state-of-the-art methods.",arxiv
http://arxiv.org/abs/1910.14215v2,2021-06-14T22:54:51Z,2019-10-31T02:25:16Z,Multivariate Uncertainty in Deep Learning,"Deep learning has the potential to dramatically impact navigation and
tracking state estimation problems critical to autonomous vehicles and
robotics. Measurement uncertainties in state estimation systems based on Kalman
and other Bayes filters are typically assumed to be a fixed covariance matrix.
This assumption is risky, particularly for ""black box"" deep learning models, in
which uncertainty can vary dramatically and unexpectedly. Accurate
quantification of multivariate uncertainty will allow for the full potential of
deep learning to be used more safely and reliably in these applications. We
show how to model multivariate uncertainty for regression problems with neural
networks, incorporating both aleatoric and epistemic sources of heteroscedastic
uncertainty. We train a deep uncertainty covariance matrix model in two ways:
directly using a multivariate Gaussian density loss function, and indirectly
using end-to-end training through a Kalman filter. We experimentally show in a
visual tracking problem the large impact that accurate multivariate uncertainty
quantification can have on Kalman filter performance for both in-domain and
out-of-domain evaluation data. We additionally show in a challenging visual
odometry problem how end-to-end filter training can allow uncertainty
predictions to compensate for filter weaknesses.",arxiv
http://arxiv.org/abs/2008.11830v1,2020-08-26T21:41:37Z,2020-08-26T21:41:37Z,Designing Neural Networks for Real-Time Systems,"Artificial Neural Networks (ANNs) are increasingly being used within
safety-critical Cyber-Physical Systems (CPSs). They are often co-located with
traditional embedded software, and may perform advisory or control-based roles.
It is important to validate both the timing and functional correctness of these
systems. However, most approaches in the literature consider guaranteeing only
the functionality of ANN based controllers. This issue stems largely from the
implementation strategies used within common neural network frameworks -- their
underlying source code is often simply unsuitable for formal techniques such as
static timing analysis. As a result, developers of safety-critical CPS must
rely on informal techniques such as measurement based approaches to prove
correctness, techniques that provide weak guarantees at best. In this work we
address this challenge. We propose a design pipeline whereby neural networks
trained using the popular deep learning framework Keras are compiled to
functionally equivalent C code. This C code is restricted to simple constructs
that may be analysed by existing static timing analysis tools. As a result, if
compiled to a suitable time-predictable platform all execution bounds may be
statically derived. To demonstrate the benefits of our approach we execute an
ANN trained to drive an autonomous vehicle around a race track. We compile the
ANN to the Patmos time-predictable controller, and show that we can derive
worst case execution timings.",arxiv
http://arxiv.org/abs/2104.09005v1,2021-04-19T01:42:34Z,2021-04-19T01:42:34Z,Scalable Bayesian Deep Learning with Kernel Seed Networks,"This paper addresses the scalability problem of Bayesian deep neural
networks. The performance of deep neural networks is undermined by the fact
that these algorithms have poorly calibrated measures of uncertainty. This
restricts their application in high risk domains such as computer aided
diagnosis and autonomous vehicle navigation. Bayesian Deep Learning (BDL)
offers a promising method for representing uncertainty in neural network.
However, BDL requires a separate set of parameters to store the mean and
standard deviation of model weights to learn a distribution. This results in a
prohibitive 2-fold increase in the number of model parameters. To address this
problem we present a method for performing BDL, namely Kernel Seed Networks
(KSN), which does not require a 2-fold increase in the number of parameters.
KSNs use 1x1 Convolution operations to learn a compressed latent space
representation of the parameter distribution. In this paper we show how this
allows KSNs to outperform conventional BDL methods while reducing the number of
required parameters by up to a factor of 6.6.",arxiv
http://arxiv.org/abs/2104.13617v2,2021-05-01T07:17:36Z,2021-04-28T07:54:40Z,"End-to-End Intersection Handling using Multi-Agent Deep Reinforcement
  Learning","Navigating through intersections is one of the main challenging tasks for an
autonomous vehicle. However, for the majority of intersections regulated by
traffic lights, the problem could be solved by a simple rule-based method in
which the autonomous vehicle behavior is closely related to the traffic light
states. In this work, we focus on the implementation of a system able to
navigate through intersections where only traffic signs are provided. We
propose a multi-agent system using a continuous, model-free Deep Reinforcement
Learning algorithm used to train a neural network for predicting both the
acceleration and the steering angle at each time step. We demonstrate that
agents learn both the basic rules needed to handle intersections by
understanding the priorities of other learners inside the environment, and to
drive safely along their paths. Moreover, a comparison between our system and a
rule-based method proves that our model achieves better results especially with
dense traffic conditions. Finally, we test our system on real world scenarios
using real recorded traffic data, proving that our module is able to generalize
both to unseen environments and to different traffic conditions.",arxiv
http://arxiv.org/abs/2103.05154v3,2021-10-25T20:23:49Z,2021-03-09T00:31:30Z,Explanations in Autonomous Driving: A Survey,"The automotive industry has witnessed an increasing level of development in
the past decades; from manufacturing manually operated vehicles to
manufacturing vehicles with a high level of automation. With the recent
developments in Artificial Intelligence (AI), automotive companies now employ
blackbox AI models to enable vehicles to perceive their environments and make
driving decisions with little or no input from a human. With the hope to deploy
autonomous vehicles (AV) on a commercial scale, the acceptance of AV by society
becomes paramount and may largely depend on their degree of transparency,
trustworthiness, and compliance with regulations. The assessment of the
compliance of AVs to these acceptance requirements can be facilitated through
the provision of explanations for AVs' behaviour. Explainability is therefore
seen as an important requirement for AVs. AVs should be able to explain what
they have 'seen', done, and might do in environments in which they operate.
  In this paper, we provide a comprehensive survey of the existing body of work
around explainable autonomous driving. First, we open with a motivation for
explanations by highlighting and emphasising the importance of transparency,
accountability, and trust in AVs; and examining existing regulations and
standards related to AVs. Second, we identify and categorise the different
stakeholders involved in the development, use, and regulation of AVs and elicit
their explanation requirements for AV. Third, we provide a rigorous review of
previous work on explanations for the different AV operations (i.e.,
perception, localisation, planning, control, and system management). Finally,
we identify pertinent challenges and provide recommendations, such as a
conceptual framework for AV explainability. This survey aims to provide the
fundamental knowledge required of researchers who are interested in
explainability in AVs.",arxiv
http://arxiv.org/abs/2006.00820v1,2020-06-01T09:55:38Z,2020-06-01T09:55:38Z,N 2 C : Neural Network Controller Design Using Behavioral Cloning,"Modern vehicles communicate data to and from sensors, actuators, and
electronic control units (ECUs) using Controller Area Network (CAN) bus, which
operates on differential signaling. An autonomous ECU responsible for the
execution of decision commands to an autonomous vehicle is developed by
assimilating the information from the CAN bus. The conventional way of parsing
the decision commands is motion planning, which uses a path tracking algorithm
to evaluate the decision commands. This study focuses on designing a robust
controller using behavioral cloning and motion planning of autonomous vehicle
using a deep learning framework. In the first part of this study, we explore
the pipeline of parsing decision commands from the path tracking algorithm to
the controller and proposed a neural network-based controller (N 2 C) using
behavioral cloning. The proposed network predicts throttle, brake, and torque
when trained with the manual driving data acquired from the CAN bus. The
efficacy of the proposed method is demonstrated by comparing the accuracy with
the Proportional-Derivative-Integral (PID) controller in conjunction with the
path tracking algorithm (pure pursuit and model predictive control based path
follower). The second part of this study complements N 2 C, in which an
end-to-end neural network for predicting the speed and steering angle is
proposed with image data as an input. The performance of the proposed
frameworks are evaluated in real-time and on the Udacity dataset, showing
better metric scores in the former and reliable prediction in the later case
when compared with the state-of-the-art methods.",arxiv
http://arxiv.org/abs/2106.10319v1,2021-06-18T19:07:59Z,2021-06-18T19:07:59Z,"A system of vision sensor based deep neural networks for complex driving
  scene analysis in support of crash risk assessment and prevention","To assist human drivers and autonomous vehicles in assessing crash risks,
driving scene analysis using dash cameras on vehicles and deep learning
algorithms is of paramount importance. Although these technologies are
increasingly available, driving scene analysis for this purpose still remains a
challenge. This is mainly due to the lack of annotated large image datasets for
analyzing crash risk indicators and crash likelihood, and the lack of an
effective method to extract lots of required information from complex driving
scenes. To fill the gap, this paper develops a scene analysis system. The
Multi-Net of the system includes two multi-task neural networks that perform
scene classification to provide four labels for each scene. The DeepLab v3 and
YOLO v3 are combined by the system to detect and locate risky pedestrians and
the nearest vehicles. All identified information can provide the situational
awareness to autonomous vehicles or human drivers for identifying crash risks
from the surrounding traffic. To address the scarcity of annotated image
datasets for studying traffic crashes, two completely new datasets have been
developed by this paper and made available to the public, which were proved to
be effective in training the proposed deep neural networks. The paper further
evaluates the performance of the Multi-Net and the efficiency of the developed
system. Comprehensive scene analysis is further illustrated with representative
examples. Results demonstrate the effectiveness of the developed system and
datasets for driving scene analysis, and their supportiveness for crash risk
assessment and crash prevention.",arxiv
http://arxiv.org/abs/1806.05859v2,2018-09-29T12:23:34Z,2018-06-15T08:44:26Z,DeepLaser: Practical Fault Attack on Deep Neural Networks,"As deep learning systems are widely adopted in safety- and security-critical
applications, such as autonomous vehicles, banking systems, etc., malicious
faults and attacks become a tremendous concern, which potentially could lead to
catastrophic consequences. In this paper, we initiate the first study of
leveraging physical fault injection attacks on Deep Neural Networks (DNNs), by
using laser injection technique on embedded systems. In particular, our
exploratory study targets four widely used activation functions in DNNs
development, that are the general main building block of DNNs that creates
non-linear behaviors -- ReLu, softmax, sigmoid, and tanh. Our results show that
by targeting these functions, it is possible to achieve a misclassification by
injecting faults into the hidden layer of the network. Such result can have
practical implications for real-world applications, where faults can be
introduced by simpler means (such as altering the supply voltage).",arxiv
http://arxiv.org/abs/1904.11008v3,2019-08-08T20:19:10Z,2019-04-16T00:04:11Z,"DeepWait: Pedestrian Wait Time Estimation in Mixed Traffic Conditions
  Using Deep Survival Analysis","Pedestrian's road crossing behaviour is one of the important aspects of urban
dynamics that will be affected by the introduction of autonomous vehicles. In
this study we introduce DeepSurvival, a novel framework for estimating
pedestrian's waiting time at unsignalized mid-block crosswalks in mixed traffic
conditions. We exploit the strengths of deep learning in capturing the
nonlinearities in the data and develop a cox proportional hazard model with a
deep neural network as the log-risk function. An embedded feature selection
algorithm for reducing data dimensionality and enhancing the interpretability
of the network is also developed. We test our framework on a dataset collected
from 160 participants using an immersive virtual reality environment.
Validation results showed that with a C-index of 0.64 our proposed framework
outperformed the standard cox proportional hazard-based model with a C-index of
0.58.",arxiv
http://arxiv.org/abs/2101.03705v1,2021-01-11T05:27:37Z,2021-01-11T05:27:37Z,"FedAR: Activity and Resource-Aware Federated Learning Model for
  Distributed Mobile Robots","Smartphones, autonomous vehicles, and the Internet-of-things (IoT) devices
are considered the primary data source for a distributed network. Due to a
revolutionary breakthrough in internet availability and continuous improvement
of the IoT devices capabilities, it is desirable to store data locally and
perform computation at the edge, as opposed to share all local information with
a centralized computation agent. A recently proposed Machine Learning (ML)
algorithm called Federated Learning (FL) paves the path towards preserving data
privacy, performing distributed learning, and reducing communication overhead
in large-scale machine learning (ML) problems. This paper proposes an FL model
by monitoring client activities and leveraging available local computing
resources, particularly for resource-constrained IoT devices (e.g., mobile
robots), to accelerate the learning process. We assign a trust score to each FL
client, which is updated based on the client's activities. We consider a
distributed mobile robot as an FL client with resource limitations either in
memory, bandwidth, processor, or battery life. We consider such mobile robots
as FL clients to understand their resource-constrained behavior in a real-world
setting. We consider an FL client to be untrustworthy if the client infuses
incorrect models or repeatedly gives slow responses during the FL process.
After disregarding the ineffective and unreliable client, we perform local
training on the selected FL clients. To further reduce the straggler issue, we
enable an asynchronous FL mechanism by performing aggregation on the FL server
without waiting for a long period to receive a particular client's response.",arxiv
http://arxiv.org/abs/1811.02188v3,2020-12-04T18:56:44Z,2018-11-06T06:49:47Z,"Adaptive Stress Testing: Finding Likely Failure Events with
  Reinforcement Learning","Finding the most likely path to a set of failure states is important to the
analysis of safety-critical systems that operate over a sequence of time steps,
such as aircraft collision avoidance systems and autonomous cars. In many
applications such as autonomous driving, failures cannot be completely
eliminated due to the complex stochastic environment in which the system
operates. As a result, safety validation is not only concerned about whether a
failure can occur, but also discovering which failures are most likely to
occur. This article presents adaptive stress testing (AST), a framework for
finding the most likely path to a failure event in simulation. We consider a
general black box setting for partially observable and continuous-valued
systems operating in an environment with stochastic disturbances. We formulate
the problem as a Markov decision process and use reinforcement learning to
optimize it. The approach is simulation-based and does not require internal
knowledge of the system, making it suitable for black-box testing of large
systems. We present formulations for fully observable and partially observable
systems. In the latter case, we present a modified Monte Carlo tree search
algorithm that only requires access to the pseudorandom number generator of the
simulator to overcome partial observability. We also present an extension of
the framework, called differential adaptive stress testing (DAST), that can
find failures that occur in one system but not in another. This type of
differential analysis is useful in applications such as regression testing,
where we are concerned with finding areas of relative weakness compared to a
baseline. We demonstrate the effectiveness of the approach on an aircraft
collision avoidance application, where a prototype aircraft collision avoidance
system is stress tested to find the most likely scenarios of near mid-air
collision.",arxiv
http://arxiv.org/abs/2011.05617v1,2020-11-11T08:17:08Z,2020-11-11T08:17:08Z,Sim-To-Real Transfer for Miniature Autonomous Car Racing,"Sim-to-real, a term that describes where a model is trained in a simulator
then transferred to the real world, is a technique that enables faster deep
reinforcement learning (DRL) training. However, differences between the
simulator and the real world often cause the model to perform poorly in the
real world. Domain randomization is a way to bridge the sim-to-real gap by
exposing the model to a wide range of scenarios so that it can generalize to
real-world situations. However, following domain randomization to train an
autonomous car racing model with DRL can lead to undesirable outcomes. Namely,
a model trained with randomization tends to run slower; a higher completion
rate on the testing track comes at the expense of longer lap times. This paper
aims to boost the robustness of a trained race car model without compromising
racing lap times. For a training track and a testing track having the same
shape (and same optimal paths), but with different lighting, background, etc.,
we first train a model (teacher model) that overfits the training track, moving
along a near optimal path. We then use this model to teach a student model the
correct actions along with randomization. With our method, a model with 18.4\%
completion rate on the testing track is able to help teach a student model with
52\% completion. Moreover, over an average of 50 trials, the student is able to
finish a lap 0.23 seconds faster than the teacher. This 0.23 second gap is
significant in tight races, with lap times of about 10 to 12 seconds.",arxiv
http://arxiv.org/abs/2108.04001v1,2021-08-09T12:49:48Z,2021-08-09T12:49:48Z,"Development of Human Motion Prediction Strategy using Inception Residual
  Block","Human Motion Prediction is a crucial task in computer vision and robotics. It
has versatile application potentials such as in the area of human-robot
interactions, human action tracking for airport security systems, autonomous
car navigation, computer gaming to name a few. However, predicting human motion
based on past actions is an extremely challenging task due to the difficulties
in detecting spatial and temporal features correctly. To detect temporal
features in human poses, we propose an Inception Residual Block(IRB), due to
its inherent capability of processing multiple kernels to capture salient
features. Here, we propose to use multiple 1-D Convolution Neural Network (CNN)
with different kernel sizes and input sequence lengths and concatenate them to
get proper embedding. As kernels strides over different receptive fields, they
detect smaller and bigger salient features at multiple temporal scales. Our
main contribution is to propose a residual connection between input and the
output of the inception block to have a continuity between the previously
observed pose and the next predicted pose. With this proposed architecture, it
learns prior knowledge much better about human poses and we achieve much higher
prediction accuracy as detailed in the paper. Subsequently, we further propose
to feed the output of the inception residual block as an input to the Graph
Convolution Neural Network (GCN) due to its better spatial feature learning
capability. We perform a parametric analysis for better designing of our model
and subsequently, we evaluate our approach on the Human 3.6M dataset and
compare our short-term as well as long-term predictions with the state of the
art papers, where our model outperforms most of the pose results, the detailed
reasons of which have been elaborated in the paper.",arxiv
http://arxiv.org/abs/1910.06070v2,2021-07-17T15:37:49Z,2019-10-02T19:19:48Z,"Review of Learning-based Longitudinal Motion Planning for Autonomous
  Vehicles: Research Gaps between Self-driving and Traffic Congestion","Self-driving technology companies and the research community are accelerating
their pace to use machine learning longitudinal motion planning (mMP) for
autonomous vehicles (AVs). This paper reviews the current state of the art in
mMP, with an exclusive focus on its impact on traffic congestion. We identify
the availability of congestion scenarios in current datasets, and summarize the
required features for training mMP. For learning methods, we survey the major
methods in both imitation learning and non-imitation learning. We also
highlight the emerging technologies adopted by some leading AV companies, e.g.
Tesla, Waymo, and Comma.ai. We find that: i) the AV industry has been mostly
focusing on the long tail problem related to safety and overlooked the impact
on traffic congestion, ii) the current public self-driving datasets have not
included enough congestion scenarios, and mostly lack the necessary input
features/output labels to train mMP, and iii) albeit reinforcement learning
(RL) approach can integrate congestion mitigation into the learning goal, the
major mMP method adopted by industry is still behavior cloning (BC), whose
capability to learn a congestion-mitigating mMP remains to be seen. Based on
the review, the study identifies the research gaps in current mMP development.
Some suggestions towards congestion mitigation for future mMP studies are
proposed: i) enrich data collection to facilitate the congestion learning, ii)
incorporate non-imitation learning methods to combine traffic efficiency into a
safety-oriented technical route, and iii) integrate domain knowledge from the
traditional car following (CF) theory to improve the string stability of mMP.",arxiv
http://arxiv.org/abs/2004.02379v1,2020-04-06T02:35:23Z,2020-04-06T02:35:23Z,Reinforcement Learning for Accident Risk-Adaptive V2X Networking,"The significance of vehicle-to-everything (V2X) communications has been ever
increased as connected and autonomous vehicles get more emergent in practice.
The key challenge is the dynamicity: each vehicle needs to recognize the
frequent changes of the surroundings and apply them to its networking behavior.
This is the point where the need for machine learning is highlighted. However,
the learning itself is extremely complicated due to the dynamicity as well,
which necessitates that the learning framework itself must be resilient and
flexible according to the environment. As such, this paper proposes a V2X
networking framework integrating reinforcement learning (RL) into scheduling of
multiple access. Specifically, the learning mechanism is formulated as a
multi-armed bandit (MAB) problem, which enables a vehicle, without any
assistance from external infrastructure, to (i) learn the environment, (ii)
quantify the accident risk, and (iii) adapt its backoff counter according to
the risk. The results of this paper show that the proposed learning protocol is
able to (i) evaluate an accident risk close to optimal and (ii) as a result,
yields a higher chance of transmission for a dangerous vehicle.",arxiv
http://arxiv.org/abs/2006.04734v3,2021-07-19T18:52:16Z,2020-06-08T16:40:12Z,Reinforcement Learning Under Moral Uncertainty,"An ambitious goal for machine learning is to create agents that behave
ethically: The capacity to abide by human moral norms would greatly expand the
context in which autonomous agents could be practically and safely deployed,
e.g. fully autonomous vehicles will encounter charged moral decisions that
complicate their deployment. While ethical agents could be trained by rewarding
correct behavior under a specific moral theory (e.g. utilitarianism), there
remains widespread disagreement about the nature of morality. Acknowledging
such disagreement, recent work in moral philosophy proposes that ethical
behavior requires acting under moral uncertainty, i.e. to take into account
when acting that one's credence is split across several plausible ethical
theories. This paper translates such insights to the field of reinforcement
learning, proposes two training methods that realize different points among
competing desiderata, and trains agents in simple environments to act under
moral uncertainty. The results illustrate (1) how such uncertainty can help
curb extreme behavior from commitment to single theories and (2) several
technical complications arising from attempting to ground moral philosophy in
RL (e.g. how can a principled trade-off between two competing but incomparable
reward functions be reached). The aim is to catalyze progress towards
morally-competent agents and highlight the potential of RL to contribute
towards the computational grounding of moral philosophy.",arxiv
http://arxiv.org/abs/1708.04485v1,2017-05-23T22:11:11Z,2017-05-23T22:11:11Z,SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks,"Convolutional Neural Networks (CNNs) have emerged as a fundamental technology
for machine learning. High performance and extreme energy efficiency are
critical for deployments of CNNs in a wide range of situations, especially
mobile platforms such as autonomous vehicles, cameras, and electronic personal
assistants. This paper introduces the Sparse CNN (SCNN) accelerator
architecture, which improves performance and energy efficiency by exploiting
the zero-valued weights that stem from network pruning during training and
zero-valued activations that arise from the common ReLU operator applied during
inference. Specifically, SCNN employs a novel dataflow that enables maintaining
the sparse weights and activations in a compressed encoding, which eliminates
unnecessary data transfers and reduces storage requirements. Furthermore, the
SCNN dataflow facilitates efficient delivery of those weights and activations
to the multiplier array, where they are extensively reused. In addition, the
accumulation of multiplication products are performed in a novel accumulator
array. Our results show that on contemporary neural networks, SCNN can improve
both performance and energy by a factor of 2.7x and 2.3x, respectively, over a
comparably provisioned dense CNN accelerator.",arxiv
http://arxiv.org/abs/2102.12680v1,2021-02-25T04:40:27Z,2021-02-25T04:40:27Z,Confidence Calibration with Bounded Error Using Transformations,"As machine learning techniques become widely adopted in new domains,
especially in safety-critical systems such as autonomous vehicles, it is
crucial to provide accurate output uncertainty estimation. As a result, many
approaches have been proposed to calibrate neural networks to accurately
estimate the likelihood of misclassification. However, while these methods
achieve low expected calibration error (ECE), few techniques provide
theoretical performance guarantees on the calibration error (CE). In this
paper, we introduce Hoki, a novel calibration algorithm with a theoretical
bound on the CE. Hoki works by transforming the neural network logits and/or
inputs and recursively performing calibration leveraging the information from
the corresponding change in the output. We provide a PAC-like bounds on CE that
is shown to decrease with the number of samples used for calibration, and
increase proportionally with ECE and the number of discrete bins used to
calculate ECE. We perform experiments on multiple datasets, including ImageNet,
and show that the proposed approach generally outperforms state-of-the-art
calibration algorithms across multiple datasets and models - providing nearly
an order or magnitude improvement in ECE on ImageNet. In addition, Hoki is fast
algorithm which is comparable to temperature scaling in terms of learning time.",arxiv
http://arxiv.org/abs/2109.01896v3,2021-10-28T17:14:06Z,2021-09-04T16:26:31Z,"GamePlan: Game-Theoretic Multi-Agent Planning with Human Drivers at
  Intersections, Roundabouts, and Merging","We present a new method for multi-agent planning involving human drivers and
autonomous vehicles (AVs) in unsignaled intersections, roundabouts, and during
merging. In multi-agent planning, the main challenge is to predict the actions
of other agents, especially human drivers, as their intentions are hidden from
other agents. Our algorithm uses game theory to develop a new auction, called
GamePlan, that directly determines the optimal action for each agent based on
their driving style (which is observable via commonly available sensors).
GamePlan assigns a higher priority to more aggressive or impatient drivers and
a lower priority to more conservative or patient drivers; we theoretically
prove that such an approach is game-theoretically optimal prevents collisions
and deadlocks. We compare our approach with prior state-of-the-art auction
techniques including economic auctions, time-based auctions (first-in
first-out), and random bidding and show that each of these methods result in
collisions among agents when taking into account driver behavior. We
additionally compare with methods based on deep reinforcement learning, deep
learning, and game theory and present our benefits over these approaches.
Finally, we show that our approach can be implemented in the real-world with
human drivers.",arxiv
http://arxiv.org/abs/1906.07946v1,2019-06-19T07:15:51Z,2019-06-19T07:15:51Z,"Ethically Aligned Design of Autonomous Systems: Industry viewpoint and
  an empirical study","Progress in the field of artificial intelligence has been accelerating
rapidly in the past two decades. Various autonomous systems from purely digital
ones to autonomous vehicles are being developed and deployed out on the field.
As these systems exert a growing impact on society, ethics in relation to
artificial intelligence and autonomous systems have recently seen growing
attention among the academia. However, the current literature on the topic has
focused almost exclusively on theory and more specifically on conceptualization
in the area. To widen the body of knowledge in the area, we conduct an
empirical study on the current state of practice in artificial intelligence
ethics. We do so by means of a multiple case study of five case companies, the
results of which indicate a gap between research and practice in the area.
Based on our findings we propose ways to tackle the gap.",arxiv
http://arxiv.org/abs/1710.05465v3,2020-12-29T16:47:01Z,2017-10-16T01:51:51Z,Flow: A Modular Learning Framework for Autonomy in Traffic,"The rapid development of autonomous vehicles (AVs) holds vast potential for
transportation systems through improved safety, efficiency, and access to
mobility. However, due to numerous technical, political, and human factors
challenges, new methodologies are needed to design vehicles and transportation
systems for these positive outcomes. This article tackles technical challenges
arising from the partial adoption of autonomy: partial control, partial
observation, complex multi-vehicle interactions, and the sheer variety of
traffic settings represented by real-world networks. The article presents a
modular learning framework which leverages deep Reinforcement Learning methods
to address complex traffic dynamics. Modules are composed to capture common
traffic phenomena (traffic jams, lane changing, intersections). Learned control
laws are found to exceed human driving performance by at least 40% with only
5-10% adoption of AVs. In partially-observed single-lane traffic, a small
neural network control law can eliminate stop-and-go traffic -- surpassing all
known model-based controllers, achieving near-optimal performance, and
generalizing to out-of-distribution traffic densities.",arxiv
http://arxiv.org/abs/1910.12908v3,2020-03-06T19:20:21Z,2019-10-28T18:45:38Z,Certified Adversarial Robustness for Deep Reinforcement Learning,"Deep Neural Network-based systems are now the state-of-the-art in many
robotics tasks, but their application in safety-critical domains remains
dangerous without formal guarantees on network robustness. Small perturbations
to sensor inputs (from noise or adversarial examples) are often enough to
change network-based decisions, which was already shown to cause an autonomous
vehicle to swerve into oncoming traffic. In light of these dangers, numerous
algorithms have been developed as defensive mechanisms from these adversarial
inputs, some of which provide formal robustness guarantees or certificates.
This work leverages research on certified adversarial robustness to develop an
online certified defense for deep reinforcement learning algorithms. The
proposed defense computes guaranteed lower bounds on state-action values during
execution to identify and choose the optimal action under a worst-case
deviation in input space due to possible adversaries or noise. The approach is
demonstrated on a Deep Q-Network policy and is shown to increase robustness to
noise and adversaries in pedestrian collision avoidance scenarios and a classic
control task.",arxiv
http://arxiv.org/abs/2004.06496v5,2021-01-26T02:21:10Z,2020-04-11T21:36:13Z,"Certifiable Robustness to Adversarial State Uncertainty in Deep
  Reinforcement Learning","Deep Neural Network-based systems are now the state-of-the-art in many
robotics tasks, but their application in safety-critical domains remains
dangerous without formal guarantees on network robustness. Small perturbations
to sensor inputs (from noise or adversarial examples) are often enough to
change network-based decisions, which was recently shown to cause an autonomous
vehicle to swerve into another lane. In light of these dangers, numerous
algorithms have been developed as defensive mechanisms from these adversarial
inputs, some of which provide formal robustness guarantees or certificates.
This work leverages research on certified adversarial robustness to develop an
online certifiably robust for deep reinforcement learning algorithms. The
proposed defense computes guaranteed lower bounds on state-action values during
execution to identify and choose a robust action under a worst-case deviation
in input space due to possible adversaries or noise. Moreover, the resulting
policy comes with a certificate of solution quality, even though the true state
and optimal action are unknown to the certifier due to the perturbations. The
approach is demonstrated on a Deep Q-Network policy and is shown to increase
robustness to noise and adversaries in pedestrian collision avoidance scenarios
and a classic control task. This work extends one of our prior works with new
performance guarantees, extensions to other RL algorithms, expanded results
aggregated across more scenarios, an extension into scenarios with adversarial
behavior, comparisons with a more computationally expensive method, and
visualizations that provide intuition about the robustness algorithm.",arxiv
http://arxiv.org/abs/2010.05437v1,2020-10-12T03:53:58Z,2020-10-12T03:53:58Z,"A DRL-based Multiagent Cooperative Control Framework for CAV Networks: a
  Graphic Convolution Q Network","Connected Autonomous Vehicle (CAV) Network can be defined as a collection of
CAVs operating at different locations on a multilane corridor, which provides a
platform to facilitate the dissemination of operational information as well as
control instructions. Cooperation is crucial in CAV operating systems since it
can greatly enhance operation in terms of safety and mobility, and high-level
cooperation between CAVs can be expected by jointly plan and control within CAV
network. However, due to the highly dynamic and combinatory nature such as
dynamic number of agents (CAVs) and exponentially growing joint action space in
a multiagent driving task, achieving cooperative control is NP hard and cannot
be governed by any simple rule-based methods. In addition, existing literature
contains abundant information on autonomous driving's sensing technology and
control logic but relatively little guidance on how to fuse the information
acquired from collaborative sensing and build decision processor on top of
fused information. In this paper, a novel Deep Reinforcement Learning (DRL)
based approach combining Graphic Convolution Neural Network (GCN) and Deep Q
Network (DQN), namely Graphic Convolution Q network (GCQ) is proposed as the
information fusion module and decision processor. The proposed model can
aggregate the information acquired from collaborative sensing and output safe
and cooperative lane changing decisions for multiple CAVs so that individual
intention can be satisfied even under a highly dynamic and partially observed
mixed traffic. The proposed algorithm can be deployed on centralized control
infrastructures such as road-side units (RSU) or cloud platforms to improve the
CAV operation.",arxiv
http://arxiv.org/abs/2101.01279v1,2021-01-04T23:27:19Z,2021-01-04T23:27:19Z,Computing Research Challenges in Next Generation Wireless Networking,"By all measures, wireless networking has seen explosive growth over the past
decade. Fourth Generation Long Term Evolution (4G LTE) cellular technology has
increased the bandwidth available for smartphones, in essence, delivering
broadband speeds to mobile devices. The most recent 5G technology is further
enhancing the transmission speeds and cell capacity, as well as, reducing
latency through the use of different radio technologies and is expected to
provide Internet connections that are an order of magnitude faster than 4G LTE.
Technology continues to advance rapidly, however, and the next generation, 6G,
is already being envisioned. 6G will make possible a wide range of powerful,
new applications including holographic telepresence, telehealth, remote
education, ubiquitous robotics and autonomous vehicles, smart cities and
communities (IoT), and advanced manufacturing (Industry 4.0, sometimes referred
to as the Fourth Industrial Revolution), to name but a few. The advances we
will see begin at the hardware level and extend all the way to the top of the
software ""stack.""
  Artificial Intelligence (AI) will also start playing a greater role in the
development and management of wireless networking infrastructure by becoming
embedded in applications throughout all levels of the network. The resulting
benefits to society will be enormous.
  At the same time these exciting new wireless capabilities are appearing
rapidly on the horizon, a broad range of research challenges loom ahead. These
stem from the ever-increasing complexity of the hardware and software systems,
along with the need to provide infrastructure that is robust and secure while
simultaneously protecting the privacy of users. Here we outline some of those
challenges and provide recommendations for the research that needs to be done
to address them.",arxiv
http://arxiv.org/abs/1911.03441v1,2019-11-08T18:49:12Z,2019-11-08T18:49:12Z,"Data-Driven Multi-step Demand Prediction for Ride-hailing Services Using
  Convolutional Neural Network","Ride-hailing services are growing rapidly and becoming one of the most
disruptive technologies in the transportation realm. Accurate prediction of
ride-hailing trip demand not only enables cities to better understand people's
activity patterns, but also helps ride-hailing companies and drivers make
informed decisions to reduce deadheading vehicle miles traveled, traffic
congestion, and energy consumption. In this study, a convolutional neural
network (CNN)-based deep learning model is proposed for multi-step ride-hailing
demand prediction using the trip request data in Chengdu, China, offered by
DiDi Chuxing. The CNN model is capable of accurately predicting the
ride-hailing pick-up demand at each 1-km by 1-km zone in the city of Chengdu
for every 10 minutes. Compared with another deep learning model based on long
short-term memory, the CNN model is 30% faster for the training and predicting
process. The proposed model can also be easily extended to make multi-step
predictions, which would benefit the on-demand shared autonomous vehicles
applications and fleet operators in terms of supply-demand rebalancing. The
prediction error attenuation analysis shows that the accuracy stays acceptable
as the model predicts more steps.",arxiv
http://arxiv.org/abs/2012.13014v1,2020-12-23T22:54:43Z,2020-12-23T22:54:43Z,Low-latency Perception in Off-Road Dynamical Low Visibility Environments,"This work proposes a perception system for autonomous vehicles and advanced
driver assistance specialized on unpaved roads and off-road environments. In
this research, the authors have investigated the behavior of Deep Learning
algorithms applied to semantic segmentation of off-road environments and
unpaved roads under differents adverse conditions of visibility. Almost 12,000
images of different unpaved and off-road environments were collected and
labeled. It was assembled an off-road proving ground exclusively for its
development. The proposed dataset also contains many adverse situations such as
rain, dust, and low light. To develop the system, we have used convolutional
neural networks trained to segment obstacles and areas where the car can pass
through. We developed a Configurable Modular Segmentation Network (CMSNet)
framework to help create different architectures arrangements and test them on
the proposed dataset. Besides, we also have ported some CMSNet configurations
by removing and fusing many layers using TensorRT, C++, and CUDA to achieve
embedded real-time inference and allow field tests. The main contributions of
this work are: a new dataset for unpaved roads and off-roads environments
containing many adverse conditions such as night, rain, and dust; a CMSNet
framework; an investigation regarding the feasibility of applying deep learning
to detect region where the vehicle can pass through when there is no clear
boundary of the track; a study of how our proposed segmentation algorithms
behave in different severity levels of visibility impairment; and an evaluation
of field tests carried out with semantic segmentation architectures ported for
real-time inference.",arxiv
http://arxiv.org/abs/1802.05591v1,2018-02-15T15:09:19Z,2018-02-15T15:09:19Z,Towards End-to-End Lane Detection: an Instance Segmentation Approach,"Modern cars are incorporating an increasing number of driver assist features,
among which automatic lane keeping. The latter allows the car to properly
position itself within the road lanes, which is also crucial for any subsequent
lane departure or trajectory planning decision in fully autonomous cars.
Traditional lane detection methods rely on a combination of highly-specialized,
hand-crafted features and heuristics, usually followed by post-processing
techniques, that are computationally expensive and prone to scalability due to
road scene variations. More recent approaches leverage deep learning models,
trained for pixel-wise lane segmentation, even when no markings are present in
the image due to their big receptive field. Despite their advantages, these
methods are limited to detecting a pre-defined, fixed number of lanes, e.g.
ego-lanes, and can not cope with lane changes. In this paper, we go beyond the
aforementioned limitations and propose to cast the lane detection problem as an
instance segmentation problem - in which each lane forms its own instance -
that can be trained end-to-end. To parametrize the segmented lane instances
before fitting the lane, we further propose to apply a learned perspective
transformation, conditioned on the image, in contrast to a fixed ""bird's-eye
view"" transformation. By doing so, we ensure a lane fitting which is robust
against road plane changes, unlike existing approaches that rely on a fixed,
pre-defined transformation. In summary, we propose a fast lane detection
algorithm, running at 50 fps, which can handle a variable number of lanes and
cope with lane changes. We verify our method on the tuSimple dataset and
achieve competitive results.",arxiv
http://arxiv.org/abs/1710.06270v2,2017-10-18T06:46:05Z,2017-10-17T13:38:16Z,"Procedural Modeling and Physically Based Rendering for Synthetic Data
  Generation in Automotive Applications","We present an overview and evaluation of a new, systematic approach for
generation of highly realistic, annotated synthetic data for training of deep
neural networks in computer vision tasks. The main contribution is a procedural
world modeling approach enabling high variability coupled with physically
accurate image synthesis, and is a departure from the hand-modeled virtual
worlds and approximate image synthesis methods used in real-time applications.
The benefits of our approach include flexible, physically accurate and scalable
image synthesis, implicit wide coverage of classes and features, and complete
data introspection for annotations, which all contribute to quality and cost
efficiency. To evaluate our approach and the efficacy of the resulting data, we
use semantic segmentation for autonomous vehicles and robotic navigation as the
main application, and we train multiple deep learning architectures using
synthetic data with and without fine tuning on organic (i.e. real-world) data.
The evaluation shows that our approach improves the neural network's
performance and that even modest implementation efforts produce
state-of-the-art results.",arxiv
http://arxiv.org/abs/1905.06712v1,2019-05-16T13:04:52Z,2019-05-16T13:04:52Z,"Autonomous Vehicle Control: End-to-end Learning in Simulated Urban
  Environments","In recent years, considerable progress has been made towards a vehicle's
ability to operate autonomously. An end-to-end approach attempts to achieve
autonomous driving using a single, comprehensive software component. Recent
breakthroughs in deep learning have significantly increased end-to-end systems'
capabilities, and such systems are now considered a possible alternative to the
current state-of-the-art solutions. This paper examines end-to-end learning for
autonomous vehicles in simulated urban environments containing other vehicles,
traffic lights, and speed limits. Furthermore, the paper explores end-to-end
systems' ability to execute navigational commands and examines whether improved
performance can be achieved by utilizing temporal dependencies between
subsequent visual cues. Two end-to-end architectures are proposed: a
traditional Convolutional Neural Network and an extended design combining a
Convolutional Neural Network with a recurrent layer. The models are trained
using expert driving data from a simulated urban setting, and are evaluated by
their driving performance in an unseen simulated environment. The results of
this paper indicate that end-to-end systems can operate autonomously in simple
urban environments. Moreover, it is found that the exploitation of temporal
information in subsequent images enhances a system's ability to judge movement
and distance.",arxiv
http://arxiv.org/abs/1910.04870v1,2019-10-02T13:47:46Z,2019-10-02T13:47:46Z,"Road scenes analysis in adverse weather conditions by
  polarization-encoded images and adapted deep learning","Object detection in road scenes is necessary to develop both autonomous
vehicles and driving assistance systems. Even if deep neural networks for
recognition task have shown great performances using conventional images, they
fail to detect objects in road scenes in complex acquisition situations. In
contrast, polarization images, characterizing the light wave, can robustly
describe important physical properties of the object even under poor
illumination or strong reflections. This paper shows how non-conventional
polarimetric imaging modality overcomes the classical methods for object
detection especially in adverse weather conditions. The efficiency of the
proposed method is mostly due to the high power of the polarimetry to
discriminate any object by its reflective properties and on the use of deep
neural networks for object detection. Our goal by this work, is to prove that
polarimetry brings a real added value compared with RGB images for object
detection. Experimental results on our own dataset composed of road scene
images taken during adverse weather conditions show that polarimetry together
with deep learning can improve the state-of-the-art by about 20% to 50% on
different detection tasks.",arxiv
http://arxiv.org/abs/1805.07569v2,2018-11-16T09:09:15Z,2018-05-19T11:09:27Z,"Reliable counting of weakly labeled concepts by a single spiking neuron
  model","Making an informed, correct and quick decision can be life-saving. It's
crucial for animals during an escape behaviour or for autonomous cars during
driving. The decision can be complex and may involve an assessment of the
amount of threats present and the nature of each threat. Thus, we should expect
early sensory processing to supply classification information fast and
accurately, even before relying the information to higher brain areas or more
complex system components downstream. Today, advanced convolutional artificial
neural networks can successfully solve visual detection and classification
tasks and are commonly used to build complex decision making systems. However,
in order to perform well on these tasks they require increasingly complex,
""very deep"" model structure, which is costly in inference run-time, energy
consumption and number of training samples, only trainable on cloud-computing
clusters. A single spiking neuron has been shown to be able to solve
recognition tasks for homogeneous Poisson input statistics, a commonly used
model for spiking activity in the neocortex. When modeled as leaky integrate
and fire with gradient decent learning algorithm it was shown to posses a
variety of complex computational capabilities. Here we improve its
implementation. We also account for more natural stimulus generated inputs that
deviate from this homogeneous Poisson spiking. The improved gradient-based
local learning rule allows for significantly better and stable generalization.
We also show that with its improved capabilities it can count weakly labeled
concepts by applying our model to a problem of multiple instance learning (MIL)
with counting where labels are only available for collections of concepts. In
this counting MNIST task the neuron exploits the improved implementation and
outperforms conventional ConvNet architecture under similar condtions.",arxiv
http://arxiv.org/abs/2004.13866v1,2020-04-28T21:56:10Z,2020-04-28T21:56:10Z,Deflating Dataset Bias Using Synthetic Data Augmentation,"Deep Learning has seen an unprecedented increase in vision applications since
the publication of large-scale object recognition datasets and introduction of
scalable compute hardware. State-of-the-art methods for most vision tasks for
Autonomous Vehicles (AVs) rely on supervised learning and often fail to
generalize to domain shifts and/or outliers. Dataset diversity is thus key to
successful real-world deployment. No matter how big the size of the dataset,
capturing long tails of the distribution pertaining to task-specific
environmental factors is impractical. The goal of this paper is to investigate
the use of targeted synthetic data augmentation - combining the benefits of
gaming engine simulations and sim2real style transfer techniques - for filling
gaps in real datasets for vision tasks. Empirical studies on three different
computer vision tasks of practical use to AVs - parking slot detection, lane
detection and monocular depth estimation - consistently show that having
synthetic data in the training mix provides a significant boost in
cross-dataset generalization performance as compared to training on real data
only, for the same size of the training set.",arxiv
http://arxiv.org/abs/2005.07424v1,2020-05-15T09:05:17Z,2020-05-15T09:05:17Z,"Exploring the Capabilities and Limits of 3D Monocular Object Detection
  -- A Study on Simulation and Real World Data","3D object detection based on monocular camera data is a key enabler for
autonomous driving. The task however, is ill-posed due to lack of depth
information in 2D images. Recent deep learning methods show promising results
to recover depth information from single images by learning priors about the
environment. Several competing strategies tackle this problem. In addition to
the network design, the major difference of these competing approaches lies in
using a supervised or self-supervised optimization loss function, which require
different data and ground truth information. In this paper, we evaluate the
performance of a 3D object detection pipeline which is parameterizable with
different depth estimation configurations. We implement a simple distance
calculation approach based on camera intrinsics and 2D bounding box size, a
self-supervised, and a supervised learning approach for depth estimation.
  Ground truth depth information cannot be recorded reliable in real world
scenarios. This shifts our training focus to simulation data. In simulation,
labeling and ground truth generation can be automatized. We evaluate the
detection pipeline on simulator data and a real world sequence from an
autonomous vehicle on a race track. The benefit of simulation training to real
world application is investigated. Advantages and drawbacks of the different
depth estimation strategies are discussed.",arxiv
http://arxiv.org/abs/2109.06668v2,2021-09-15T17:25:20Z,2021-09-14T13:16:33Z,Exploration in Deep Reinforcement Learning: A Comprehensive Survey,"Deep Reinforcement Learning (DRL) and Deep Multi-agent Reinforcement Learning
(MARL) have achieved significant success across a wide range of domains, such
as game AI, autonomous vehicles, robotics and finance. However, DRL and deep
MARL agents are widely known to be sample-inefficient and millions of
interactions are usually needed even for relatively simple game settings, thus
preventing the wide application in real-industry scenarios. One bottleneck
challenge behind is the well-known exploration problem, i.e., how to
efficiently explore the unknown environments and collect informative
experiences that could benefit the policy learning most.
  In this paper, we conduct a comprehensive survey on existing exploration
methods in DRL and deep MARL for the purpose of providing understandings and
insights on the critical problems and solutions. We first identify several key
challenges to achieve efficient exploration, which most of the exploration
methods aim at addressing. Then we provide a systematic survey of existing
approaches by classifying them into two major categories: uncertainty-oriented
exploration and intrinsic motivation-oriented exploration. The essence of
uncertainty-oriented exploration is to leverage the quantification of the
epistemic and aleatoric uncertainty to derive efficient exploration. By
contrast, intrinsic motivation-oriented exploration methods usually incorporate
different reward agnostic information for intrinsic exploration guidance.
Beyond the above two main branches, we also conclude other exploration methods
which adopt sophisticated techniques but are difficult to be classified into
the above two categories. In addition, we provide a comprehensive empirical
comparison of exploration methods for DRL on a set of commonly used benchmarks.
Finally, we summarize the open problems of exploration in DRL and deep MARL and
point out a few future directions.",arxiv
http://arxiv.org/abs/2010.06318v1,2020-10-13T11:56:48Z,2020-10-13T11:56:48Z,Audio-Visual Self-Supervised Terrain Type Discovery for Mobile Platforms,"The ability to both recognize and discover terrain characteristics is an
important function required for many autonomous ground robots such as social
robots, assistive robots, autonomous vehicles, and ground exploration robots.
Recognizing and discovering terrain characteristics is challenging because
similar terrains may have very different appearances (e.g., carpet comes in
many colors), while terrains with very similar appearance may have very
different physical properties (e.g. mulch versus dirt). In order to address the
inherent ambiguity in vision-based terrain recognition and discovery, we
propose a multi-modal self-supervised learning technique that switches between
audio features extracted from a mic attached to the underside of a mobile
platform and image features extracted by a camera on the platform to cluster
terrain types. The terrain cluster labels are then used to train an image-based
convolutional neural network to predict changes in terrain types. Through
experiments, we demonstrate that the proposed self-supervised terrain type
discovery method achieves over 80% accuracy, which greatly outperforms several
baselines and suggests strong potential for assistive applications.",arxiv
http://arxiv.org/abs/2012.07890v3,2021-03-12T21:22:09Z,2020-12-14T19:14:35Z,"Learning Collision-Free Space Detection from Stereo Images: Homography
  Matrix Brings Better Data Augmentation","Collision-free space detection is a critical component of autonomous vehicle
perception. The state-of-the-art algorithms are typically based on supervised
learning. The performance of such approaches is always dependent on the quality
and amount of labeled training data. Additionally, it remains an open challenge
to train deep convolutional neural networks (DCNNs) using only a small quantity
of training samples. Therefore, this paper mainly explores an effective
training data augmentation approach that can be employed to improve the overall
DCNN performance, when additional images captured from different views are
available. Due to the fact that the pixels of the collision-free space
(generally regarded as a planar surface) between two images captured from
different views can be associated by a homography matrix, the scenario of the
target image can be transformed into the reference view. This provides a simple
but effective way of generating training data from additional multi-view
images. Extensive experimental results, conducted with six state-of-the-art
semantic segmentation DCNNs on three datasets, demonstrate the effectiveness of
our proposed training data augmentation algorithm for enhancing collision-free
space detection performance. When validated on the KITTI road benchmark, our
approach provides the best results for stereo vision-based collision-free space
detection.",arxiv
http://arxiv.org/abs/2010.11344v2,2021-03-17T22:07:18Z,2020-10-21T23:18:42Z,Trajectory Prediction using Equivariant Continuous Convolution,"Trajectory prediction is a critical part of many AI applications, for
example, the safe operation of autonomous vehicles. However, current methods
are prone to making inconsistent and physically unrealistic predictions. We
leverage insights from fluid dynamics to overcome this limitation by
considering internal symmetry in real-world trajectories. We propose a novel
model, Equivariant Continous COnvolution (ECCO) for improved trajectory
prediction. ECCO uses rotationally-equivariant continuous convolutions to embed
the symmetries of the system. On both vehicle and pedestrian trajectory
datasets, ECCO attains competitive accuracy with significantly fewer
parameters. It is also more sample efficient, generalizing automatically from
few data points in any orientation. Lastly, ECCO improves generalization with
equivariance, resulting in more physically consistent predictions. Our method
provides a fresh perspective towards increasing trust and transparency in deep
learning models.",arxiv
http://arxiv.org/abs/2110.05556v1,2021-10-11T18:54:05Z,2021-10-11T18:54:05Z,"Addressing crash-imminent situations caused by human driven vehicle
  errors in a mixed traffic stream: a model-based reinforcement learning
  approach for CAV","It is anticipated that the era of fully autonomous vehicle operations will be
preceded by a lengthy ""Transition Period"" where the traffic stream will be
mixed, that is, consisting of connected autonomous vehicles (CAVs),
human-driven vehicles (HDVs) and connected human-driven vehicles (CHDVs). In
recognition of the fact that public acceptance of CAVs will hinge on safety
performance of automated driving systems, and that there will likely be safety
challenges in the early part of the transition period, significant research
efforts have been expended in the development of safety-conscious automated
driving systems. Yet still, there appears to be a lacuna in the literature
regarding the handling of the crash-imminent situations that are caused by
errant human driven vehicles (HDVs) in the vicinity of the CAV during
operations on the roadway. In this paper, we develop a simple model-based
Reinforcement Learning (RL) based system that can be deployed in the CAV to
generate trajectories that anticipate and avoid potential collisions caused by
drivers of the HDVs. The model involves an end-to-end data-driven approach that
contains a motion prediction model based on deep learning, and a fast
trajectory planning algorithm based on model predictive control (MPC). The
proposed system requires no prior knowledge or assumption about the physical
environment including the vehicle dynamics, and therefore represents a general
approach that can be deployed on any type of vehicle (e.g., truck, buse,
motorcycle, etc.). The framework is trained and tested in the CARLA simulator
with multiple collision imminent scenarios, and the results indicate the
proposed model can avoid the collision at high successful rate (>85%) even in
highly compact and dangerous situations.",arxiv
http://arxiv.org/abs/1906.01493v2,2019-12-03T02:05:07Z,2019-06-04T15:02:30Z,"Constructing Energy-efficient Mixed-precision Neural Networks through
  Principal Component Analysis for Edge Intelligence","The `Internet of Things' has brought increased demand for AI-based edge
computing in applications ranging from healthcare monitoring systems to
autonomous vehicles. Quantization is a powerful tool to address the growing
computational cost of such applications, and yields significant compression
over full-precision networks. However, quantization can result in substantial
loss of performance for complex image classification tasks. To address this, we
propose a Principal Component Analysis (PCA) driven methodology to identify the
important layers of a binary network, and design mixed-precision networks. The
proposed Hybrid-Net achieves a more than 10% improvement in classification
accuracy over binary networks such as XNOR-Net for ResNet and VGG architectures
on CIFAR-100 and ImageNet datasets while still achieving up to 94% of the
energy-efficiency of XNOR-Nets. This work furthers the feasibility of using
highly compressed neural networks for energy-efficient neural computing in edge
devices.",arxiv
http://arxiv.org/abs/1809.03478v1,2018-09-10T17:48:58Z,2018-09-10T17:48:58Z,"Towards a Fatality-Aware Benchmark of Probabilistic Reaction Prediction
  in Highly Interactive Driving Scenarios","Autonomous vehicles should be able to generate accurate probabilistic
predictions for uncertain behavior of other road users. Moreover, reactive
predictions are necessary in highly interactive driving scenarios to answer
""what if I take this action in the future"" for autonomous vehicles. There is no
existing unified framework to homogenize the problem formulation,
representation simplification, and evaluation metric for various prediction
methods, such as probabilistic graphical models (PGM), neural networks (NN) and
inverse reinforcement learning (IRL). In this paper, we formulate a
probabilistic reaction prediction problem, and reveal the relationship between
reaction and situation prediction problems. We employ prototype trajectories
with designated motion patterns other than ""intention"" to homogenize the
representation so that probabilities corresponding to each trajectory generated
by different methods can be evaluated. We also discuss the reasons why
""intention"" is not suitable to serve as a motion indicator in highly
interactive scenarios. We propose to use Brier score as the baseline metric for
evaluation. In order to reveal the fatality of the consequences when the
predictions are adopted by decision-making and planning, we propose a
fatality-aware metric, which is a weighted Brier score based on the criticality
of the trajectory pairs of the interacting entities. Conservatism and
non-defensiveness are defined from the weighted Brier score to indicate the
consequences caused by inaccurate predictions. Modified methods based on PGM,
NN and IRL are provided to generate probabilistic reaction predictions in an
exemplar scenario of nudging from a highway ramp. The results are evaluated by
the baseline and proposed metrics to construct a mini benchmark. Analysis on
the properties of each method is also provided by comparing the baseline and
proposed metric scores.",arxiv
http://arxiv.org/abs/1805.04829v2,2019-05-24T01:10:40Z,2018-05-13T06:19:14Z,Spatial Uncertainty Sampling for End-to-End Control,"End-to-end trained neural networks (NNs) are a compelling approach to
autonomous vehicle control because of their ability to learn complex tasks
without manual engineering of rule-based decisions. However, challenging road
conditions, ambiguous navigation situations, and safety considerations require
reliable uncertainty estimation for the eventual adoption of full-scale
autonomous vehicles. Bayesian deep learning approaches provide a way to
estimate uncertainty by approximating the posterior distribution of weights
given a set of training data. Dropout training in deep NNs approximates
Bayesian inference in a deep Gaussian process and can thus be used to estimate
model uncertainty. In this paper, we propose a Bayesian NN for end-to-end
control that estimates uncertainty by exploiting feature map correlation during
training. This approach achieves improved model fits, as well as tighter
uncertainty estimates, than traditional element-wise dropout. We evaluate our
algorithms on a challenging dataset collected over many different road types,
times of day, and weather conditions, and demonstrate how uncertainties can be
used in conjunction with a human controller in a parallel autonomous setting.",arxiv
http://arxiv.org/abs/1907.05274v1,2019-07-06T04:53:49Z,2019-07-06T04:53:49Z,Affine Disentangled GAN for Interpretable and Robust AV Perception,"Autonomous vehicles (AV) have progressed rapidly with the advancements in
computer vision algorithms. The deep convolutional neural network as the main
contributor to this advancement has boosted the classification accuracy
dramatically. However, the discovery of adversarial examples reveals the
generalization gap between dataset and the real world. Furthermore, affine
transformations may also confuse computer vision based object detectors. The
degradation of the perception system is undesirable for safety critical systems
such as autonomous vehicles. In this paper, a deep learning system is proposed:
Affine Disentangled GAN (ADIS-GAN), which is robust against affine
transformations and adversarial attacks. It is demonstrated that conventional
data augmentation for affine transformation and adversarial attacks are
orthogonal, while ADIS-GAN can handle both attacks at the same time. Useful
information such as image rotation angle and scaling factor are also generated
in ADIS-GAN. On MNIST dataset, ADIS-GAN can achieve over 98 percent
classification accuracy within 30 degrees rotation, and over 90 percent
classification accuracy against FGSM and PGD adversarial attack.",arxiv
http://arxiv.org/abs/2106.04625v1,2021-06-08T18:24:02Z,2021-06-08T18:24:02Z,"Don't Get Yourself into Trouble! Risk-aware Decision-Making for
  Autonomous Vehicles","Risk is traditionally described as the expected likelihood of an undesirable
outcome, such as collisions for autonomous vehicles. Accurately predicting risk
or potentially risky situations is critical for the safe operation of
autonomous vehicles. In our previous work, we showed that risk could be
characterized by two components: 1) the probability of an undesirable outcome
and 2) an estimate of how undesirable the outcome is (loss). This paper is an
extension to our previous work. In this paper, using our trained deep
reinforcement learning model for navigating around crowds, we developed a
risk-based decision-making framework for the autonomous vehicle that integrates
the high-level risk-based path planning with the reinforcement learning-based
low-level control. We evaluated our method in a high-fidelity simulation such
as CARLA. This work can improve safety by allowing an autonomous vehicle to one
day avoid and react to risky situations.",arxiv
http://arxiv.org/abs/2003.13839v1,2020-03-30T22:02:13Z,2020-03-30T22:02:13Z,"Model-Reference Reinforcement Learning Control of Autonomous Surface
  Vehicles with Uncertainties","This paper presents a novel model-reference reinforcement learning control
method for uncertain autonomous surface vehicles. The proposed control combines
a conventional control method with deep reinforcement learning. With the
conventional control, we can ensure the learning-based control law provides
closed-loop stability for the overall system, and potentially increase the
sample efficiency of the deep reinforcement learning. With the reinforcement
learning, we can directly learn a control law to compensate for modeling
uncertainties. In the proposed control, a nominal system is employed for the
design of a baseline control law using a conventional control approach. The
nominal system also defines the desired performance for uncertain autonomous
vehicles to follow. In comparison with traditional deep reinforcement learning
methods, our proposed learning-based control can provide stability guarantees
and better sample efficiency. We demonstrate the performance of the new
algorithm via extensive simulation results.",arxiv
http://arxiv.org/abs/2006.09540v1,2020-06-16T22:05:58Z,2020-06-16T22:05:58Z,"COLREG-Compliant Collision Avoidance for Unmanned Surface Vehicle using
  Deep Reinforcement Learning","Path Following and Collision Avoidance, be it for unmanned surface vessels or
other autonomous vehicles, are two fundamental guidance problems in robotics.
For many decades, they have been subject to academic study, leading to a vast
number of proposed approaches. However, they have mostly been treated as
separate problems, and have typically relied on non-linear first-principles
models with parameters that can only be determined experimentally. The rise of
Deep Reinforcement Learning (DRL) in recent years suggests an alternative
approach: end-to-end learning of the optimal guidance policy from scratch by
means of a trial-and-error based approach. In this article, we explore the
potential of Proximal Policy Optimization (PPO), a DRL algorithm with
demonstrated state-of-the-art performance on Continuous Control tasks, when
applied to the dual-objective problem of controlling an underactuated
Autonomous Surface Vehicle in a COLREGs compliant manner such that it follows
an a priori known desired path while avoiding collisions with other vessels
along the way. Based on high-fidelity elevation and AIS tracking data from the
Trondheim Fjord, an inlet of the Norwegian sea, we evaluate the trained agent's
performance in challenging, dynamic real-world scenarios where the ultimate
success of the agent rests upon its ability to navigate non-uniform marine
terrain while handling challenging, but realistic vessel encounters.",arxiv
http://arxiv.org/abs/1811.10277v1,2018-11-26T10:36:26Z,2018-11-26T10:36:26Z,Autonomous Systems -- An Architectural Characterization,"The concept of autonomy is key to the IoT vision promising increasing
integration of smart services and systems minimizing human intervention. This
vision challenges our capability to build complex open trustworthy autonomous
systems. We lack a rigorous common semantic framework for autonomous systems.
It is remarkable that the debate about autonomous vehicles focuses almost
exclusively on AI and learning techniques while it ignores many other equally
important autonomous system design issues. Autonomous systems involve agents
and objects coordinated in some common environment so that their collective
behavior meets a set of global goals. We propose a general computational model
combining a system architecture model and an agent model. The architecture
model allows expression of dynamic reconfigurable multi-mode coordination
between components. The agent model consists of five interacting modules
implementing each one a characteristic function: Perception, Reflection, Goal
management, Planning and Self-adaptation. It determines a concept of autonomic
complexity accounting for the specific difficulty to build autonomous systems.
We emphasize that the main characteristic of autonomous systems is their
ability to handle knowledge and adaptively respond to environment changes. We
advocate that autonomy should be associated with functionality and not with
specific techniques. Machine learning is essential for autonomy although it can
meet only a small portion of the needs implied by autonomous system design. We
conclude that autonomy is a kind of broad intelligence. Building trustworthy
and optimal autonomous systems goes far beyond the AI challenge.",arxiv
http://arxiv.org/abs/2109.07960v2,2021-10-18T13:45:47Z,2021-09-16T13:11:53Z,"Efficient and Effective Generation of Test Cases for Pedestrian
  Detection -- Search-based Software Testing of Baidu Apollo in SVL","With the growing capabilities of autonomous vehicles, there is a higher
demand for sophisticated and pragmatic quality assurance approaches for machine
learning-enabled systems in the automotive AI context. The use of
simulation-based prototyping platforms provides the possibility for early-stage
testing, enabling inexpensive testing and the ability to capture critical
corner-case test scenarios. Simulation-based testing properly complements
conventional on-road testing. However, due to the large space of test input
parameters in these systems, the efficient generation of effective test
scenarios leading to the unveiling of failures is a challenge. This paper
presents a study on testing pedestrian detection and emergency braking system
of the Baidu Apollo autonomous driving platform within the SVL simulator. We
propose an evolutionary automated test generation technique that generates
failure-revealing scenarios for Apollo in the SVL environment. Our approach
models the input space using a generic and flexible data structure and benefits
a multi-criteria safety-based heuristic for the objective function targeted for
optimization. This paper presents the results of our proposed test generation
technique in the 2021 IEEE Autonomous Driving AI Test Challenge. In order to
demonstrate the efficiency and effectiveness of our approach, we also report
the results from a baseline random generation technique. Our evaluation shows
that the proposed evolutionary test case generator is more effective at
generating failure-revealing test cases and provides higher diversity between
the generated failures than the random baseline.",arxiv
http://arxiv.org/abs/1610.01934v5,2016-12-13T20:13:33Z,2016-10-06T16:20:45Z,"Using Non-invertible Data Transformations to Build Adversarial-Robust
  Neural Networks","Deep neural networks have proven to be quite effective in a wide variety of
machine learning tasks, ranging from improved speech recognition systems to
advancing the development of autonomous vehicles. However, despite their
superior performance in many applications, these models have been recently
shown to be susceptible to a particular type of attack possible through the
generation of particular synthetic examples referred to as adversarial samples.
These samples are constructed by manipulating real examples from the training
data distribution in order to ""fool"" the original neural model, resulting in
misclassification (with high confidence) of previously correctly classified
samples. Addressing this weakness is of utmost importance if deep neural
architectures are to be applied to critical applications, such as those in the
domain of cybersecurity. In this paper, we present an analysis of this
fundamental flaw lurking in all neural architectures to uncover limitations of
previously proposed defense mechanisms. More importantly, we present a unifying
framework for protecting deep neural models using a non-invertible data
transformation--developing two adversary-resilient architectures utilizing both
linear and nonlinear dimensionality reduction. Empirical results indicate that
our framework provides better robustness compared to state-of-art solutions
while having negligible degradation in accuracy.",arxiv
http://arxiv.org/abs/1801.01397v1,2018-01-03T15:29:44Z,2018-01-03T15:29:44Z,"Implementation of Deep Convolutional Neural Network in Multi-class
  Categorical Image Classification","Convolutional Neural Networks has been implemented in many complex machine
learning takes such as image classification, object identification, autonomous
vehicle and robotic vision tasks. However, ConvNet architecture efficiency and
accuracy depend on a large number of fac- tors. Also, the complex architecture
requires a significant amount of data to train and involves with a large number
of hyperparameters that increases the computational expenses and difficul-
ties. Hence, it is necessary to address the limitations and techniques to
overcome the barriers to ensure that the architecture performs well in complex
visual tasks. This article is intended to develop an efficient ConvNet
architecture for multi-class image categorical classification applica- tion. In
the development of the architecture, large pool of grey scale images are taken
as input information images and split into training and test datasets. The
numerously available technique is implemented to reduce the overfitting and
poor generalization of the network. The hyperpa- rameters of determined by
Bayesian Optimization with Gaussian Process prior algorithm. ReLu non-linear
activation function is implemented after the convolutional layers. Max pooling
op- eration is carried out to downsampling the data points in pooling layers.
Cross-entropy loss function is used to measure the performance of the
architecture where the softmax is used in the classification layer. Mini-batch
gradient descent with Adam optimizer algorithm is used for backpropagation.
Developed architecture is validated with confusion matrix and classification
report.",arxiv
http://arxiv.org/abs/2103.00345v1,2021-02-27T22:36:32Z,2021-02-27T22:36:32Z,"End-to-end Uncertainty-based Mitigation of Adversarial Attacks to
  Automated Lane Centering","In the development of advanced driver-assistance systems (ADAS) and
autonomous vehicles, machine learning techniques that are based on deep neural
networks (DNNs) have been widely used for vehicle perception. These techniques
offer significant improvement on average perception accuracy over traditional
methods, however, have been shown to be susceptible to adversarial attacks,
where small perturbations in the input may cause significant errors in the
perception results and lead to system failure. Most prior works addressing such
adversarial attacks focus only on the sensing and perception modules. In this
work, we propose an end-to-end approach that addresses the impact of
adversarial attacks throughout perception, planning, and control modules. In
particular, we choose a target ADAS application, the automated lane centering
system in OpenPilot, quantify the perception uncertainty under adversarial
attacks, and design a robust planning and control module accordingly based on
the uncertainty analysis. We evaluate our proposed approach using both the
public dataset and production-grade autonomous driving simulator. The
experiment results demonstrate that our approach can effectively mitigate the
impact of adversarial attacks and can achieve 55% to 90% improvement over the
original OpenPilot.",arxiv
http://arxiv.org/abs/2104.10076v1,2021-04-20T15:57:07Z,2021-04-20T15:57:07Z,"MixDefense: A Defense-in-Depth Framework for Adversarial Example
  Detection Based on Statistical and Semantic Analysis","Machine learning with deep neural networks (DNNs) has become one of the
foundation techniques in many safety-critical systems, such as autonomous
vehicles and medical diagnosis systems. DNN-based systems, however, are known
to be vulnerable to adversarial examples (AEs) that are maliciously perturbed
variants of legitimate inputs. While there has been a vast body of research to
defend against AE attacks in the literature, the performances of existing
defense techniques are still far from satisfactory, especially for adaptive
attacks, wherein attackers are knowledgeable about the defense mechanisms and
craft AEs accordingly. In this work, we propose a multilayer defense-in-depth
framework for AE detection, namely MixDefense. For the first layer, we focus on
those AEs with large perturbations. We propose to leverage the `noise' features
extracted from the inputs to discover the statistical difference between
natural images and tampered ones for AE detection. For AEs with small
perturbations, the inference result of such inputs would largely deviate from
their semantic information. Consequently, we propose a novel learning-based
solution to model such contradictions for AE detection. Both layers are
resilient to adaptive attacks because there do not exist gradient propagation
paths for AE generation. Experimental results with various AE attack methods on
image classification datasets show that the proposed MixDefense solution
outperforms the existing AE detection techniques by a considerable margin.",arxiv
http://arxiv.org/abs/1704.05519v3,2021-03-17T19:16:56Z,2017-04-18T20:33:50Z,"Computer Vision for Autonomous Vehicles: Problems, Datasets and State of
  the Art","Recent years have witnessed enormous progress in AI-related fields such as
computer vision, machine learning, and autonomous vehicles. As with any rapidly
growing field, it becomes increasingly difficult to stay up-to-date or enter
the field as a beginner. While several survey papers on particular sub-problems
have appeared, no comprehensive survey on problems, datasets, and methods in
computer vision for autonomous vehicles has been published. This book attempts
to narrow this gap by providing a survey on the state-of-the-art datasets and
techniques. Our survey includes both the historically most relevant literature
as well as the current state of the art on several specific topics, including
recognition, reconstruction, motion estimation, tracking, scene understanding,
and end-to-end learning for autonomous driving. Towards this goal, we analyze
the performance of the state of the art on several challenging benchmarking
datasets, including KITTI, MOT, and Cityscapes. Besides, we discuss open
problems and current research challenges. To ease accessibility and accommodate
missing references, we also provide a website that allows navigating topics as
well as methods and provides additional information.",arxiv
http://arxiv.org/abs/1906.08662v1,2019-06-20T14:31:48Z,2019-06-20T14:31:48Z,Cooperative Lane Changing via Deep Reinforcement Learning,"In this paper, we study how to learn an appropriate lane changing strategy
for autonomous vehicles by using deep reinforcement learning. We show that the
reward of the system should consider the overall traffic efficiency instead of
the travel efficiency of an individual vehicle. In summary, cooperation leads
to a more harmonic and efficient traffic system rather than competition",arxiv
http://arxiv.org/abs/2102.07000v2,2021-07-30T04:34:43Z,2021-02-13T20:54:27Z,"Adaptive Optimization of Autonomous Vehicle Computational Resources for
  Performance and Energy Improvement","Autonomous vehicles usually consume a large amount of computational power for
their operations, especially for the tasks of sensing and perception with
artificial intelligence algorithms. Such a computation may not only cost a
significant amount of energy but also cause performance issues when the onboard
computational resources are limited. To address this issue, this paper proposes
an adaptive optimization method to online allocate the onboard computational
resources of an autonomous vehicle amongst multiple vehicular subsystems
depending on the contexts of the situations that the vehicle is facing.
Different autonomous driving scenarios were designed to validate the proposed
approach and the results showed that it could help improve the overall
performance and energy consumption of autonomous vehicles compared to existing
computational arrangement.",arxiv
http://arxiv.org/abs/1910.09910v1,2019-10-22T12:03:44Z,2019-10-22T12:03:44Z,"WeatherNet: Recognising weather and visual conditions from street-level
  images using deep residual learning","Extracting information related to weather and visual conditions at a given
time and space is indispensable for scene awareness, which strongly impacts our
behaviours, from simply walking in a city to riding a bike, driving a car, or
autonomous drive-assistance. Despite the significance of this subject, it is
still not been fully addressed by the machine intelligence relying on deep
learning and computer vision to detect the multi-labels of weather and visual
conditions with a unified method that can be easily used for practice. What has
been achieved to-date is rather sectorial models that address limited number of
labels that do not cover the wide spectrum of weather and visual conditions.
Nonetheless, weather and visual conditions are often addressed individually. In
this paper, we introduce a novel framework to automatically extract this
information from street-level images relying on deep learning and computer
vision using a unified method without any pre-defined constraints in the
processed images. A pipeline of four deep Convolutional Neural Network (CNN)
models, so-called the WeatherNet, is trained, relying on residual learning
using ResNet50 architecture, to extract various weather and visual conditions
such as Dawn/dusk, day and night for time detection, and glare for lighting
conditions, and clear, rainy, snowy, and foggy for weather conditions. The
WeatherNet shows strong performance in extracting this information from
user-defined images or video streams that can be used not limited to:
autonomous vehicles and drive-assistance systems, tracking behaviours,
safety-related research, or even for better understanding cities through images
for policy-makers.",arxiv
http://arxiv.org/abs/1808.07935v1,2018-08-23T20:30:04Z,2018-08-23T20:30:04Z,"Deconvolutional Networks for Point-Cloud Vehicle Detection and Tracking
  in Driving Scenarios","Vehicle detection and tracking is a core ingredient for developing autonomous
driving applications in urban scenarios. Recent image-based Deep Learning (DL)
techniques are obtaining breakthrough results in these perceptive tasks.
However, DL research has not yet advanced much towards processing 3D point
clouds from lidar range-finders. These sensors are very common in autonomous
vehicles since, despite not providing as semantically rich information as
images, their performance is more robust under harsh weather conditions than
vision sensors. In this paper we present a full vehicle detection and tracking
system that works with 3D lidar information only. Our detection step uses a
Convolutional Neural Network (CNN) that receives as input a featured
representation of the 3D information provided by a Velodyne HDL-64 sensor and
returns a per-point classification of whether it belongs to a vehicle or not.
The classified point cloud is then geometrically processed to generate
observations for a multi-object tracking system implemented via a number of
Multi-Hypothesis Extended Kalman Filters (MH-EKF) that estimate the position
and velocity of the surrounding vehicles. The system is thoroughly evaluated on
the KITTI tracking dataset, and we show the performance boost provided by our
CNN-based vehicle detector over a standard geometric approach. Our lidar-based
approach uses about a 4% of the data needed for an image-based detector with
similarly competitive results.",arxiv
http://arxiv.org/abs/1809.04734v2,2019-01-15T19:07:31Z,2018-09-13T01:36:55Z,"DispSegNet: Leveraging Semantics for End-to-End Learning of Disparity
  Estimation from Stereo Imagery","Recent work has shown that convolutional neural networks (CNNs) can be
applied successfully in disparity estimation, but these methods still suffer
from errors in regions of low-texture, occlusions and reflections.
Concurrently, deep learning for semantic segmentation has shown great progress
in recent years. In this paper, we design a CNN architecture that combines
these two tasks to improve the quality and accuracy of disparity estimation
with the help of semantic segmentation. Specifically, we propose a network
structure in which these two tasks are highly coupled. One key novelty of this
approach is the two-stage refinement process. Initial disparity estimates are
refined with an embedding learned from the semantic segmentation branch of the
network. The proposed model is trained using an unsupervised approach, in which
images from one half of the stereo pair are warped and compared against images
from the other camera. Another key advantage of the proposed approach is that a
single network is capable of outputting disparity estimates and semantic
labels. These outputs are of great use in autonomous vehicle operation; with
real-time constraints being key, such performance improvements increase the
viability of driving applications. Experiments on KITTI and Cityscapes datasets
show that our model can achieve state-of-the-art results and that leveraging
embedding learned from semantic segmentation improves the performance of
disparity estimation.",arxiv
http://arxiv.org/abs/1903.01860v1,2019-03-05T14:39:04Z,2019-03-05T14:39:04Z,Stochastic Sampling Simulation for Pedestrian Trajectory Prediction,"Urban environments pose a significant challenge for autonomous vehicles (AVs)
as they must safely navigate while in close proximity to many pedestrians. It
is crucial for the AV to correctly understand and predict the future
trajectories of pedestrians to avoid collision and plan a safe path. Deep
neural networks (DNNs) have shown promising results in accurately predicting
pedestrian trajectories, relying on large amounts of annotated real-world data
to learn pedestrian behavior. However, collecting and annotating these large
real-world pedestrian datasets is costly in both time and labor. This paper
describes a novel method using a stochastic sampling-based simulation to train
DNNs for pedestrian trajectory prediction with social interaction. Our novel
simulation method can generate vast amounts of automatically-annotated,
realistic, and naturalistic synthetic pedestrian trajectories based on small
amounts of real annotation. We then use such synthetic trajectories to train an
off-the-shelf state-of-the-art deep learning approach Social GAN (Generative
Adversarial Network) to perform pedestrian trajectory prediction. Our proposed
architecture, trained only using synthetic trajectories, achieves better
prediction results compared to those trained on human-annotated real-world data
using the same network. Our work demonstrates the effectiveness and potential
of using simulation as a substitution for human annotation efforts to train
high-performing prediction algorithms such as the DNNs.",arxiv
http://arxiv.org/abs/1909.10363v2,2019-09-26T17:08:30Z,2019-09-23T13:47:38Z,Shadow Transfer: Single Image Relighting For Urban Road Scenes,"Illumination effects in images, specifically cast shadows and shading, have
been shown to decrease the performance of deep neural networks on a large
number of vision-based detection, recognition and segmentation tasks in urban
driving scenes. A key factor that contributes to this performance gap is the
lack of `time-of-day' diversity within real, labeled datasets. There have been
impressive advances in the realm of image to image translation in transferring
previously unseen visual effects into a dataset, specifically in day to night
translation. However, it is not easy to constrain what visual effects, let
alone illumination effects, are transferred from one dataset to another during
the training process. To address this problem, we propose deep learning
framework, called Shadow Transfer, that can relight complex outdoor scenes by
transferring realistic shadow, shading, and other lighting effects onto a
single image. The novelty of the proposed framework is that it is both
self-supervised, and is designed to operate on sensor and label information
that is easily available in autonomous vehicle datasets. We show the
effectiveness of this method on both synthetic and real datasets, and we
provide experiments that demonstrate that the proposed method produces images
of higher visual quality than state of the art image to image translation
methods.",arxiv
http://arxiv.org/abs/2010.06626v2,2020-12-29T01:09:57Z,2020-10-13T18:37:38Z,"On Deep Learning Techniques to Boost Monocular Depth Estimation for
  Autonomous Navigation","Inferring the depth of images is a fundamental inverse problem within the
field of Computer Vision since depth information is obtained through 2D images,
which can be generated from infinite possibilities of observed real scenes.
Benefiting from the progress of Convolutional Neural Networks (CNNs) to explore
structural features and spatial image information, Single Image Depth
Estimation (SIDE) is often highlighted in scopes of scientific and
technological innovation, as this concept provides advantages related to its
low implementation cost and robustness to environmental conditions. In the
context of autonomous vehicles, state-of-the-art CNNs optimize the SIDE task by
producing high-quality depth maps, which are essential during the autonomous
navigation process in different locations. However, such networks are usually
supervised by sparse and noisy depth data, from Light Detection and Ranging
(LiDAR) laser scans, and are carried out at high computational cost, requiring
high-performance Graphic Processing Units (GPUs). Therefore, we propose a new
lightweight and fast supervised CNN architecture combined with novel feature
extraction models which are designed for real-world autonomous navigation. We
also introduce an efficient surface normals module, jointly with a simple
geometric 2.5D loss function, to solve SIDE problems. We also innovate by
incorporating multiple Deep Learning techniques, such as the use of
densification algorithms and additional semantic, surface normals and depth
information to train our framework. The method introduced in this work focuses
on robotic applications in indoor and outdoor environments and its results are
evaluated on the competitive and publicly available NYU Depth V2 and KITTI
Depth datasets.",arxiv
http://arxiv.org/abs/2010.12728v1,2020-10-24T00:57:31Z,2020-10-24T00:57:31Z,"Differentiate Quality of Experience Scheduling for Deep Learning
  Applications with Docker Containers in the Cloud","With the prevalence of big-data-driven applications, such as face recognition
on smartphones and tailored recommendations from Google Ads, we are on the road
to a lifestyle with significantly more intelligence than ever before. For
example, Aipoly Vision [1] is an object and color recognizer that helps the
blind, visually impaired, and color blind understand their surroundings. At the
back end side of their intelligence, various neural networks powered models are
running to enable quick responses to users. Supporting those models requires
lots of cloud-based computational resources, e.g. CPUs and GPUs. The cloud
providers charge their clients by the amount of resources that they occupied.
From clients' perspective, they have to balance the budget and quality of
experiences (e.g. response time). The budget leans on individual business
owners and the required Quality of Experience (QoE) depends on usage scenarios
of different applications, for instance, an autonomous vehicle requires
realtime response, but, unlocking your smartphone can tolerate delays. However,
cloud providers fail to offer a QoE based option to their clients. In this
paper, we propose DQoES, a differentiate quality of experience scheduler for
deep learning applications. DQoES accepts client's specification on targeted
QoEs, and dynamically adjust resources to approach their targets. Through
extensive, cloud-based experiments, DQoES demonstrates that it can schedule
multiple concurrent jobs with respect to various QoEs and achieve up to 8x
times more satisfied models compared to the existing system.",arxiv
http://arxiv.org/abs/2104.11907v1,2021-04-24T08:16:44Z,2021-04-24T08:16:44Z,CFNet: LiDAR-Camera Registration Using Calibration Flow Network,"As an essential procedure of data fusion, LiDAR-camera calibration is
critical for autonomous vehicles and robot navigation. Most calibration methods
rely on hand-crafted features and require significant amounts of extracted
features or specific calibration targets. With the development of deep learning
(DL) techniques, some attempts take advantage of convolutional neural networks
(CNNs) to regress the 6 degrees of freedom (DOF) extrinsic parameters.
Nevertheless, the performance of these DL-based methods is reported to be worse
than the non-DL methods. This paper proposed an online LiDAR-camera extrinsic
calibration algorithm that combines the DL and the geometry methods. We define
a two-channel image named calibration flow to illustrate the deviation from the
initial projection to the ground truth. EPnP algorithm within the RANdom SAmple
Consensus (RANSAC) scheme is applied to estimate the extrinsic parameters with
2D-3D correspondences constructed by the calibration flow. Experiments on KITTI
datasets demonstrate that our proposed method is superior to the
state-of-the-art methods. Furthermore, we propose a semantic initialization
algorithm with the introduction of instance centroids (ICs). The code will be
publicly available at https://github.com/LvXudong-HIT/CFNet.",arxiv
http://arxiv.org/abs/2105.00203v2,2021-09-21T07:37:26Z,2021-05-01T09:55:17Z,"Adversarial Example Detection for DNN Models: A Review and Experimental
  Comparison","Deep learning (DL) has shown great success in many human-related tasks, which
has led to its adoption in many computer vision based applications, such as
security surveillance systems, autonomous vehicles and healthcare. Such
safety-critical applications have to draw their path to success deployment once
they have the capability to overcome safety-critical challenges. Among these
challenges are the defense against or/and the detection of the adversarial
examples (AEs). Adversaries can carefully craft small, often imperceptible,
noise called perturbations to be added to the clean image to generate the AE.
The aim of AE is to fool the DL model which makes it a potential risk for DL
applications. Many test-time evasion attacks and countermeasures,i.e., defense
or detection methods, are proposed in the literature. Moreover, few reviews and
surveys were published and theoretically showed the taxonomy of the threats and
the countermeasure methods with little focus in AE detection methods. In this
paper, we focus on image classification tasks and attempt to provide a survey
for detection methods of test-time evasion attacks on neural network
classifiers. A detailed discussion for such methods is provided with
experimental results for eight state-of-the-art detectors under different
scenarios on four datasets. We also provide potential challenges and future
perspectives for this research direction.",arxiv
http://arxiv.org/abs/2105.09932v1,2021-05-20T17:52:37Z,2021-05-20T17:52:37Z,Efficient and Robust LiDAR-Based End-to-End Navigation,"Deep learning has been used to demonstrate end-to-end neural network learning
for autonomous vehicle control from raw sensory input. While LiDAR sensors
provide reliably accurate information, existing end-to-end driving solutions
are mainly based on cameras since processing 3D data requires a large memory
footprint and computation cost. On the other hand, increasing the robustness of
these systems is also critical; however, even estimating the model's
uncertainty is very challenging due to the cost of sampling-based methods. In
this paper, we present an efficient and robust LiDAR-based end-to-end
navigation framework. We first introduce Fast-LiDARNet that is based on sparse
convolution kernel optimization and hardware-aware model design. We then
propose Hybrid Evidential Fusion that directly estimates the uncertainty of the
prediction from only a single forward pass and then fuses the control
predictions intelligently. We evaluate our system on a full-scale vehicle and
demonstrate lane-stable as well as navigation capabilities. In the presence of
out-of-distribution events (e.g., sensor failures), our system significantly
improves robustness and reduces the number of takeovers in the real world.",arxiv
http://arxiv.org/abs/2004.00801v1,2020-04-02T03:52:03Z,2020-04-02T03:52:03Z,"Exploration of Reinforcement Learning for Event Camera using Car-like
  Robots","We demonstrate the first reinforcement-learning application for robots
equipped with an event camera. Because of the considerably lower latency of the
event camera, it is possible to achieve much faster control of robots compared
with the existing vision-based reinforcement-learning applications using
standard cameras. To handle a stream of events for reinforcement learning, we
introduced an image-like feature and demonstrated the feasibility of training
an agent in a simulator for two tasks: fast collision avoidance and obstacle
tracking. Finally, we set up a robot with an event camera in the real world and
then transferred the agent trained in the simulator, resulting in successful
fast avoidance of randomly thrown objects. Incorporating event camera into
reinforcement learning opens new possibilities for various robotics
applications that require swift control, such as autonomous vehicles and
drones, through end-to-end learning approaches.",arxiv
http://arxiv.org/abs/2005.11895v1,2020-05-25T02:57:19Z,2020-05-25T02:57:19Z,"Reinforcement Learning with Iterative Reasoning for Merging in Dense
  Traffic","Maneuvering in dense traffic is a challenging task for autonomous vehicles
because it requires reasoning about the stochastic behaviors of many other
participants. In addition, the agent must achieve the maneuver within a limited
time and distance. In this work, we propose a combination of reinforcement
learning and game theory to learn merging behaviors. We design a training
curriculum for a reinforcement learning agent using the concept of level-$k$
behavior. This approach exposes the agent to a broad variety of behaviors
during training, which promotes learning policies that are robust to model
discrepancies. We show that our approach learns more efficient policies than
traditional training methods.",arxiv
http://arxiv.org/abs/2006.14480v2,2020-11-16T21:16:49Z,2020-06-25T15:23:41Z,One Thousand and One Hours: Self-driving Motion Prediction Dataset,"Motivated by the impact of large-scale datasets on ML systems we present the
largest self-driving dataset for motion prediction to date, containing over
1,000 hours of data. This was collected by a fleet of 20 autonomous vehicles
along a fixed route in Palo Alto, California, over a four-month period. It
consists of 170,000 scenes, where each scene is 25 seconds long and captures
the perception output of the self-driving system, which encodes the precise
positions and motions of nearby vehicles, cyclists, and pedestrians over time.
On top of this, the dataset contains a high-definition semantic map with 15,242
labelled elements and a high-definition aerial view over the area. We show that
using a dataset of this size dramatically improves performance for key
self-driving problems. Combined with the provided software kit, this collection
forms the largest and most detailed dataset to date for the development of
self-driving machine learning tasks, such as motion forecasting, motion
planning and simulation. The full dataset is available at
http://level5.lyft.com/.",arxiv
http://arxiv.org/abs/2105.12527v1,2021-05-26T13:04:05Z,2021-05-26T13:04:05Z,"Dimensioning of V2X Services in 5G Networks through Forecast-based
  Scaling","With the increasing adoption of intelligent transportation systems and the
upcoming era of autonomous vehicles, vehicular services (such as, remote
driving, cooperative awareness, and hazard warning) will face an ever changing
and dynamic environment. Traffic flows on the roads is a critical condition for
these services and, therefore, it is of paramount importance to forecast how
they will evolve over time. By knowing future events (such as, traffic jams),
vehicular services can be dimensioned in an on-demand fashion in order to
minimize Service Level Agreements (SLAs) violations, thus reducing the chances
of car accidents. This research departs from an evaluation of traditional
time-series techniques with recent Machine Learning (ML)-based solutions to
forecast traffic flows in the roads of Torino (Italy). Given the accuracy of
the selected forecasting techniques, a forecast-based scaling algorithm is
proposed and evaluated over a set of dimensioning experiments of three distinct
vehicular services with strict latency requirements. Results show that the
proposed scaling algorithm enables resource savings of up to a 5% at the cost
of incurring in an increase of less than 0.4% of latency violations.",arxiv
http://arxiv.org/abs/1807.08415v2,2019-03-16T02:02:40Z,2018-07-23T03:07:43Z,"Clustering of Driving Encounter Scenarios Using Connected Vehicle
  Trajectories","Multi-vehicle interaction behavior classification and analysis offer in-depth
knowledge to make an efficient decision for autonomous vehicles. This paper
aims to cluster a wide range of driving encounter scenarios based only on
multi-vehicle GPS trajectories. Towards this end, we propose a generic
unsupervised learning framework comprising two layers: feature representation
layer and clustering layer. In the layer of feature representation, we combine
the deep autoencoders with a distance-based measure to map the sequential
observations of driving encounters into a computationally tractable space that
allows quantifying the spatiotemporal interaction characteristics of two
vehicles. The clustering algorithm is then applied to the extracted
representations to gather homogeneous driving encounters into groups. Our
proposed generic framework is then evaluated using 2,568 naturalistic driving
encounters. Experimental results demonstrate that our proposed generic
framework incorporated with unsupervised learning can cluster multi-trajectory
data into distinct groups. These clustering results could benefit
decision-making policy analysis and design for autonomous vehicles.",arxiv
http://arxiv.org/abs/2101.02780v1,2021-01-07T22:01:30Z,2021-01-07T22:01:30Z,"SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things
  and Cyber-Physical Systems based on Machine Learning","Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are
increasingly being deployed across multiple functionalities, ranging from
healthcare devices and wearables to critical infrastructures, e.g., nuclear
power plants, autonomous vehicles, smart cities, and smart homes. These devices
are inherently not secure across their comprehensive software, hardware, and
network stacks, thus presenting a large attack surface that can be exploited by
hackers. In this article, we present an innovative technique for detecting
unknown system vulnerabilities, managing these vulnerabilities, and improving
incident response when such vulnerabilities are exploited. The novelty of this
approach lies in extracting intelligence from known real-world CPS/IoT attacks,
representing them in the form of regular expressions, and employing machine
learning (ML) techniques on this ensemble of regular expressions to generate
new attack vectors and security vulnerabilities. Our results show that 10 new
attack vectors and 122 new vulnerability exploits can be successfully generated
that have the potential to exploit a CPS or an IoT ecosystem. The ML
methodology achieves an accuracy of 97.4% and enables us to predict these
attacks efficiently with an 87.2% reduction in the search space. We demonstrate
the application of our method to the hacking of the in-vehicle network of a
connected car. To defend against the known attacks and possible novel exploits,
we discuss a defense-in-depth mechanism for various classes of attacks and the
classification of data targeted by such attacks. This defense mechanism
optimizes the cost of security measures based on the sensitivity of the
protected resource, thus incentivizing its adoption in real-world CPS/IoT by
cybersecurity practitioners.",arxiv
http://arxiv.org/abs/2003.07739v2,2020-07-12T15:00:40Z,2020-03-17T14:17:52Z,"Formal Scenario-Based Testing of Autonomous Vehicles: From Simulation to
  the Real World","We present a new approach to automated scenario-based testing of the safety
of autonomous vehicles, especially those using advanced artificial
intelligence-based components, spanning both simulation-based evaluation as
well as testing in the real world. Our approach is based on formal methods,
combining formal specification of scenarios and safety properties, algorithmic
test case generation using formal simulation, test case selection for track
testing, executing test cases on the track, and analyzing the resulting data.
Experiments with a real autonomous vehicle at an industrial testing facility
support our hypotheses that (i) formal simulation can be effective at
identifying test cases to run on the track, and (ii) the gap between simulated
and real worlds can be systematically evaluated and bridged.",arxiv
http://arxiv.org/abs/1712.01106v1,2017-11-30T06:46:19Z,2017-11-30T06:46:19Z,"Transferring Autonomous Driving Knowledge on Simulated and Real
  Intersections","We view intersection handling on autonomous vehicles as a reinforcement
learning problem, and study its behavior in a transfer learning setting. We
show that a network trained on one type of intersection generally is not able
to generalize to other intersections. However, a network that is pre-trained on
one intersection and fine-tuned on another performs better on the new task
compared to training in isolation. This network also retains knowledge of the
prior task, even though some forgetting occurs. Finally, we show that the
benefits of fine-tuning hold when transferring simulated intersection handling
knowledge to a real autonomous vehicle.",arxiv
http://arxiv.org/abs/1612.01401v2,2017-08-19T01:40:36Z,2016-12-05T15:46:21Z,Learning Adversary-Resistant Deep Neural Networks,"Deep neural networks (DNNs) have proven to be quite effective in a vast array
of machine learning tasks, with recent examples in cyber security and
autonomous vehicles. Despite the superior performance of DNNs in these
applications, it has been recently shown that these models are susceptible to a
particular type of attack that exploits a fundamental flaw in their design.
This attack consists of generating particular synthetic examples referred to as
adversarial samples. These samples are constructed by slightly manipulating
real data-points in order to ""fool"" the original DNN model, forcing it to
mis-classify previously correctly classified samples with high confidence.
Addressing this flaw in the model is essential if DNNs are to be used in
critical applications such as those in cyber security.
  Previous work has provided various learning algorithms to enhance the
robustness of DNN models, and they all fall into the tactic of ""security
through obscurity"". This means security can be guaranteed only if one can
obscure the learning algorithms from adversaries. Once the learning technique
is disclosed, DNNs protected by these defense mechanisms are still susceptible
to adversarial samples. In this work, we investigate this issue shared across
previous research work and propose a generic approach to escalate a DNN's
resistance to adversarial samples. More specifically, our approach integrates a
data transformation module with a DNN, making it robust even if we reveal the
underlying learning algorithm. To demonstrate the generality of our proposed
approach and its potential for handling cyber security applications, we
evaluate our method and several other existing solutions on datasets publicly
available. Our results indicate that our approach typically provides superior
classification performance and resistance in comparison with state-of-art
solutions.",arxiv
http://arxiv.org/abs/1809.04120v3,2019-03-03T18:37:06Z,2018-09-11T19:39:51Z,Humans can decipher adversarial images,"How similar is the human mind to the sophisticated machine-learning systems
that mirror its performance? Models of object categorization based on
convolutional neural networks (CNNs) have achieved human-level benchmarks in
assigning known labels to novel images. These advances promise to support
transformative technologies such as autonomous vehicles and machine diagnosis;
beyond this, they also serve as candidate models for the visual system itself
-- not only in their output but perhaps even in their underlying mechanisms and
principles. However, unlike human vision, CNNs can be ""fooled"" by adversarial
examples -- carefully crafted images that appear as nonsense patterns to humans
but are recognized as familiar objects by machines, or that appear as one
object to humans and a different object to machines. This seemingly extreme
divergence between human and machine classification challenges the promise of
these new advances, both as applied image-recognition systems and also as
models of the human mind. Surprisingly, however, little work has empirically
investigated human classification of such adversarial stimuli: Does human and
machine performance fundamentally diverge? Or could humans decipher such images
and predict the machine's preferred labels? Here, we show that human and
machine classification of adversarial stimuli are robustly related: In eight
experiments on five prominent and diverse adversarial imagesets, human subjects
reliably identified the machine's chosen label over relevant foils. This
pattern persisted for images with strong antecedent identities, and even for
images described as ""totally unrecognizable to human eyes"". We suggest that
human intuition may be a more reliable guide to machine (mis)classification
than has typically been imagined, and we explore the consequences of this
result for minds and machines alike.",arxiv
http://arxiv.org/abs/1905.07679v1,2019-05-19T03:16:14Z,2019-05-19T03:16:14Z,"Predicting Model Failure using Saliency Maps in Autonomous Driving
  Systems","While machine learning systems show high success rate in many complex tasks,
research shows they can also fail in very unexpected situations. Rise of
machine learning products in safety-critical industries cause an increase in
attention in evaluating model robustness and estimating failure probability in
machine learning systems. In this work, we propose a design to train a student
model -- a failure predictor -- to predict the main model's error for input
instances based on their saliency map. We implement and review the preliminary
results of our failure predictor model on an autonomous vehicle steering
control system as an example of safety-critical applications.",arxiv
http://arxiv.org/abs/1905.09046v1,2019-05-22T09:56:07Z,2019-05-22T09:56:07Z,"A Deep Reinforcement Learning Driving Policy for Autonomous Road
  Vehicles","This work regards our preliminary investigation on the problem of path
planning for autonomous vehicles that move on a freeway. We approach this
problem by proposing a driving policy based on Reinforcement Learning. The
proposed policy makes minimal or no assumptions about the environment, since no
a priori knowledge about the system dynamics is required. We compare the
performance of the proposed policy against an optimal policy derived via
Dynamic Programming and against manual driving simulated by SUMO traffic
simulator.",arxiv
http://arxiv.org/abs/2011.08712v5,2021-05-28T15:33:37Z,2020-11-17T15:36:42Z,"A Simple Framework to Quantify Different Types of Uncertainty in Deep
  Neural Networks for Image Classification","Quantifying uncertainty in a model's predictions is important as it enables
the safety of an AI system to be increased by acting on the model's output in
an informed manner. This is crucial for applications where the cost of an error
is high, such as in autonomous vehicle control, medical image analysis,
financial estimations or legal fields. Deep Neural Networks are powerful
predictors that have recently achieved state-of-the-art performance on a wide
spectrum of tasks. Quantifying predictive uncertainty in DNNs is a challenging
and yet on-going problem. In this paper we propose a complete framework to
capture and quantify three known types of uncertainty in DNNs for the task of
image classification. This framework includes an ensemble of CNNs for model
uncertainty, a supervised reconstruction auto-encoder to capture distributional
uncertainty and using the output of activation functions in the last layer of
the network, to capture data uncertainty. Finally we demonstrate the efficiency
of our method on popular image datasets for classification.",arxiv
http://arxiv.org/abs/1904.04706v2,2019-11-21T09:04:07Z,2019-04-09T14:40:32Z,Towards Safety Verification of Direct Perception Neural Networks,"We study the problem of safety verification of direct perception neural
networks, where camera images are used as inputs to produce high-level features
for autonomous vehicles to make control decisions. Formal verification of
direct perception neural networks is extremely challenging, as it is difficult
to formulate the specification that requires characterizing input as
constraints, while the number of neurons in such a network can reach millions.
We approach the specification problem by learning an input property
characterizer which carefully extends a direct perception neural network at
close-to-output layers, and address the scalability problem by a novel
assume-guarantee based verification approach. The presented workflow is used to
understand a direct perception neural network (developed by Audi) which
computes the next waypoint and orientation for autonomous vehicles to follow.",arxiv
http://arxiv.org/abs/2004.14143v3,2020-11-29T03:27:44Z,2020-04-29T12:45:35Z,"Zero-Shot Learning and its Applications from Autonomous Vehicles to
  COVID-19 Diagnosis: A Review","The challenge of learning a new concept, object, or a new medical disease
recognition without receiving any examples beforehand is called Zero-Shot
Learning (ZSL). One of the major issues in deep learning based methodologies
such as in Medical Imaging and other real-world applications is the requirement
of large annotated datasets prepared by clinicians or experts to train the
model. ZSL is known for having minimal human intervention by relying only on
previously known or trained concepts plus currently existing auxiliary
information. This makes the ZSL applicable in many real-world scenarios, from
unknown object detection in autonomous vehicles to medical imaging and
unforeseen diseases such as COVID-19 Chest X-Ray (CXR) based diagnosis. We
introduce a novel and broaden solution called Few/one-shot learning, and
present the definition of the ZSL problem as an extreme case of the few-shot
learning. We review over fundamentals and the challenging steps of Zero-Shot
Learning, including state-of-the-art categories of solutions, as well as our
recommended solution, motivations behind each approach, their advantages over
each category to guide both clinicians and AI researchers to proceed with the
best techniques and practices based on their applications. We then review
through different datasets inducing medical and non-medical images, the variety
of splits, and the evaluation protocols proposed so far. Finally, we discuss
the recent applications and future directions of ZSL. We aim to convey a useful
intuition through this paper towards the goal of handling complex learning
tasks more similar to the way humans learn. We mainly focus on two applications
in the current modern yet challenging era: coping with an early and fast
diagnosis of COVID-19 cases, and also encouraging the readers to develop other
similar AI-based automated detection/recognition systems using ZSL.",arxiv
http://arxiv.org/abs/2109.09188v1,2021-09-19T18:28:20Z,2021-09-19T18:28:20Z,"DeepPoint: A Deep Learning Model for 3D Reconstruction in Point Clouds
  via mmWave Radar","Recent research has shown that mmWave radar sensing is effective for object
detection in low visibility environments, which makes it an ideal technique in
autonomous navigation systems such as autonomous vehicles. However, due to the
characteristics of radar signals such as sparsity, low resolution, specularity,
and high noise, it is still quite challenging to reconstruct 3D object shapes
via mmWave radar sensing. Built on our recent proposed 3DRIMR (3D
Reconstruction and Imaging via mmWave Radar), we introduce in this paper
DeepPoint, a deep learning model that generates 3D objects in point cloud
format that significantly outperforms the original 3DRIMR design. The model
adopts a conditional Generative Adversarial Network (GAN) based deep neural
network architecture. It takes as input the 2D depth images of an object
generated by 3DRIMR's Stage 1, and outputs smooth and dense 3D point clouds of
the object. The model consists of a novel generator network that utilizes a
sequence of DeepPoint blocks or layers to extract essential features of the
union of multiple rough and sparse input point clouds of an object when
observed from various viewpoints, given that those input point clouds may
contain many incorrect points due to the imperfect generation process of
3DRIMR's Stage 1. The design of DeepPoint adopts a deep structure to capture
the global features of input point clouds, and it relies on an optimally chosen
number of DeepPoint blocks and skip connections to achieve performance
improvement over the original 3DRIMR design. Our experiments have demonstrated
that this model significantly outperforms the original 3DRIMR and other
standard techniques in reconstructing 3D objects.",arxiv
http://arxiv.org/abs/1807.03515v1,2018-07-10T08:00:22Z,2018-07-10T08:00:22Z,"A Reinforcement Learning Approach to Jointly Adapt Vehicular
  Communications and Planning for Optimized Driving","Our premise is that autonomous vehicles must optimize communications and
motion planning jointly. Specifically, a vehicle must adapt its motion plan
staying cognizant of communications rate related constraints and adapt the use
of communications while being cognizant of motion planning related restrictions
that may be imposed by the on-road environment. To this end, we formulate a
reinforcement learning problem wherein an autonomous vehicle jointly chooses
(a) a motion planning action that executes on-road and (b) a communications
action of querying sensed information from the infrastructure. The goal is to
optimize the driving utility of the autonomous vehicle. We apply the Q-learning
algorithm to make the vehicle learn the optimal policy, which makes the optimal
choice of planning and communications actions at any given time. We demonstrate
the ability of the optimal policy to smartly adapt communications and planning
actions, while achieving large driving utilities, using simulations.",arxiv
http://arxiv.org/abs/1908.01046v2,2019-08-06T18:27:43Z,2019-08-02T20:39:59Z,"Adaptive Stress Testing with Reward Augmentation for Autonomous Vehicle
  Validation","Determining possible failure scenarios is a critical step in the evaluation
of autonomous vehicle systems. Real-world vehicle testing is commonly employed
for autonomous vehicle validation, but the costs and time requirements are
high. Consequently, simulation-driven methods such as Adaptive Stress Testing
(AST) have been proposed to aid in validation. AST formulates the problem of
finding the most likely failure scenarios as a Markov decision process, which
can be solved using reinforcement learning. In practice, AST tends to find
scenarios where failure is unavoidable and tends to repeatedly discover the
same types of failures of a system. This work addresses these issues by
encoding domain relevant information into the search procedure. With this
modification, the AST method discovers a larger and more expressive subset of
the failure space when compared to the original AST formulation. We show that
our approach is able to identify useful failure scenarios of an autonomous
vehicle policy.",arxiv
http://arxiv.org/abs/2004.06531v2,2020-11-23T20:27:40Z,2020-04-14T14:12:17Z,Adversarial Evaluation of Autonomous Vehicles in Lane-Change Scenarios,"Autonomous vehicles must be comprehensively evaluated before deployed in
cities and highways. However, most existing evaluation approaches for
autonomous vehicles are static and lack adaptability, so they are usually
inefficient in generating challenging scenarios for tested vehicles. In this
paper, we propose an adaptive evaluation framework to efficiently evaluate
autonomous vehicles in adversarial environments generated by deep reinforcement
learning. Considering the multimodal nature of dangerous scenarios, we use
ensemble models to represent different local optimums for diversity. We then
utilize a nonparametric Bayesian method to cluster the adversarial policies.
The proposed method is validated in a typical lane-change scenario that
involves frequent interactions between the ego vehicle and the surrounding
vehicles. Results show that the adversarial scenarios generated by our method
significantly degrade the performance of the tested vehicles. We also
illustrate different patterns of generated adversarial environments, which can
be used to infer the weaknesses of the tested vehicles.",arxiv
http://arxiv.org/abs/2006.15110v1,2020-06-26T17:17:47Z,2020-06-26T17:17:47Z,"Learning predictive representations in autonomous driving to improve
  deep reinforcement learning","Reinforcement learning using a novel predictive representation is applied to
autonomous driving to accomplish the task of driving between lane markings
where substantial benefits in performance and generalization are observed on
unseen test roads in both simulation and on a real Jackal robot. The novel
predictive representation is learned by general value functions (GVFs) to
provide out-of-policy, or counter-factual, predictions of future lane
centeredness and road angle that form a compact representation of the state of
the agent improving learning in both online and offline reinforcement learning
to learn to drive an autonomous vehicle with methods that generalizes well to
roads not in the training data. Experiments in both simulation and the
real-world demonstrate that predictive representations in reinforcement
learning improve learning efficiency, smoothness of control and generalization
to roads that the agent was never shown during training, including damaged lane
markings. It was found that learning a predictive representation that consists
of several predictions over different time scales, or discount factors,
improves the performance and smoothness of the control substantially. The
Jackal robot was trained in a two step process where the predictive
representation is learned first followed by a batch reinforcement learning
algorithm (BCQ) from data collected through both automated and human-guided
exploration in the environment. We conclude that out-of-policy predictive
representations with GVFs offer reinforcement learning many benefits in
real-world problems.",arxiv
http://arxiv.org/abs/1907.05246v2,2020-02-18T09:22:25Z,2019-07-10T11:44:09Z,"Deep Reinforcement-Learning-based Driving Policy for Autonomous Road
  Vehicles","In this work the problem of path planning for an autonomous vehicle that
moves on a freeway is considered. The most common approaches that are used to
address this problem are based on optimal control methods, which make
assumptions about the model of the environment and the system dynamics. On the
contrary, this work proposes the development of a driving policy based on
reinforcement learning. In this way, the proposed driving policy makes minimal
or no assumptions about the environment, since a priori knowledge about the
system dynamics is not required. Driving scenarios where the road is occupied
both by autonomous and manual driving vehicles are considered. To the best of
our knowledge, this is one of the first approaches that propose a reinforcement
learning driving policy for mixed driving environments. The derived
reinforcement learning policy, firstly, is compared against an optimal policy
derived via dynamic programming, and, secondly, its efficiency is evaluated
under realistic scenarios generated by the established SUMO microscopic traffic
flow simulator. Finally, some initial results regarding the effect of
autonomous vehicles' behavior on the overall traffic flow are presented.",arxiv
http://arxiv.org/abs/1804.04701v1,2018-04-12T19:28:59Z,2018-04-12T19:28:59Z,Reputation in M2M Economy,"Triggered by modern technologies, our possibilities may now expand beyond the
unthinkable. Cars externally may look similar to decades ago, but a dramatic
revolution happened inside the cabin as a result of their computation,
communications, and storage capabilities. With the advent of Electric
Autonomous Vehicles (EAVs), Artificial Intelligence and ecological technologies
found the best synergy. Several transportation problems may be solved
(accidents, emissions, and congestion among others), and the foundation of
Machine-to-Machine (M2M) economy could be established, in addition to
value-added services such as infotainment (information and entertainment).
  In the world where intelligent technologies are pervading everyday life,
software and algorithms play a major role. Software has been lately introduced
in virtually every technological product available on the market, from phones
to television sets to cars and even housing. Artificial Intelligence is one of
the consequences of this pervasive presence of algorithms. The role of software
is becoming dominant and technology is, at times pervasive, of our existence.
Concerns, such as privacy and security, demand high attention and have been
already explored to some level of detail. However, intelligent agents and
actors are often considered as perfect entities that will overcome human
error-prone nature. This may not always be the case and we advocate that the
notion of reputation is also applicable to intelligent artificial agents, in
particular to EAVs.",arxiv
http://arxiv.org/abs/1605.03150v1,2016-05-10T18:53:09Z,2016-05-10T18:53:09Z,Road Detection through Supervised Classification,"Autonomous driving is a rapidly evolving technology. Autonomous vehicles are
capable of sensing their environment and navigating without human input through
sensory information such as radar, lidar, GNSS, vehicle odometry, and computer
vision. This sensory input provides a rich dataset that can be used in
combination with machine learning models to tackle multiple problems in
supervised settings. In this paper we focus on road detection through
gray-scale images as the sole sensory input. Our contributions are twofold:
first, we introduce an annotated dataset of urban roads for machine learning
tasks; second, we introduce a road detection framework on this dataset through
supervised classification and hand-crafted feature vectors.",arxiv
http://arxiv.org/abs/1409.2373v1,2014-09-08T14:42:50Z,2014-09-08T14:42:50Z,"Rapid Integration and Calibration of New Sensors Using the Berkeley
  Aachen Robotics Toolkit (BART)","After the three DARPA Grand Challenge contests many groups around the world
have continued to actively research and work toward an autonomous vehicle
capable of accomplishing a mission in a given context (e.g. desert, city) while
following a set of prescribed rules, but none has been completely successful in
uncontrolled environments, a task that many people trivially fulfill every day.
We believe that, together with improving the sensors used in cars and the
artificial intelligence algorithms used to process the information, the
community should focus on the systems engineering aspects of the problem, i.e.
the limitations of the car (in terms of space, power, or heat dissipation) and
the limitations of the software development cycle. This paper explores these
issues and our experiences overcoming them.",arxiv
http://arxiv.org/abs/2005.07740v1,2020-05-15T18:53:07Z,2020-05-15T18:53:07Z,"Online Verification Concept for Autonomous Vehicles -- Illustrative
  Study for a Trajectory Planning Module","Regulatory approval and safety guarantees for autonomous vehicles facing
frequent functional updates and complex software stacks, including artificial
intelligence, are a challenging topic. This paper proposes a concept and
guideline for the development of an online verification module -- the
Supervisor -- capable of handling the aforementioned challenges. The concept
presented for the establishment of a Supervisor is designed in a way to
identify and monitor an extensive list of features contributing to safe
operation. As a result, a safe overall (sub)system is attained. Safeguarding a
motion planner of an autonomous race vehicle is used to illustrate the
procedure and practicability of the framework at hand. The capabilities of the
proposed method are evaluated in a scenario-based test environment and on
full-scale vehicle data.",arxiv
http://arxiv.org/abs/2106.03799v1,2021-06-07T17:09:22Z,2021-06-07T17:09:22Z,"Deterministic Iteratively Built KD-Tree with KNN Search for Exact
  Applications","K-Nearest Neighbors (KNN) search is a fundamental algorithm in artificial
intelligence software with applications in robotics, and autonomous vehicles.
These wide-ranging applications utilize KNN either directly for simple
classification or combine KNN results as input to other algorithms such as
Locally Weighted Learning (LWL). Similar to binary trees, kd-trees become
unbalanced as new data is added in online applications which can lead to rapid
degradation in search performance unless the tree is rebuilt. Although
approximate methods are suitable for graphics applications, which prioritize
query speed over query accuracy, they are unsuitable for certain applications
in autonomous systems, aeronautics, and robotic manipulation where exact
solutions are desired. In this paper, we will attempt to assess the performance
of non-recursive deterministic kd-tree functions and KNN functions. We will
also present a ""forest of interval kd-trees"" which reduces the number of tree
rebuilds, without compromising the exactness of query results.",arxiv
http://arxiv.org/abs/1808.05819v3,2020-03-04T06:35:56Z,2018-08-17T10:37:51Z,"Uncertainty-aware Short-term Motion Prediction of Traffic Actors for
  Autonomous Driving","We address one of the crucial aspects necessary for safe and efficient
operations of autonomous vehicles, namely predicting future state of traffic
actors in the autonomous vehicle's surroundings. We introduce a deep
learning-based approach that takes into account a current world state and
produces raster images of each actor's vicinity. The rasters are then used as
inputs to deep convolutional models to infer future movement of actors while
also accounting for and capturing inherent uncertainty of the prediction task.
Extensive experiments on real-world data strongly suggest benefits of the
proposed approach. Moreover, following completion of the offline tests the
system was successfully tested onboard self-driving vehicles.",arxiv
http://arxiv.org/abs/2108.02940v1,2021-08-06T04:52:09Z,2021-08-06T04:52:09Z,"Evaluating Adversarial Attacks on Driving Safety in Vision-Based
  Autonomous Vehicles","In recent years, many deep learning models have been adopted in autonomous
driving. At the same time, these models introduce new vulnerabilities that may
compromise the safety of autonomous vehicles. Specifically, recent studies have
demonstrated that adversarial attacks can cause a significant decline in
detection precision of deep learning-based 3D object detection models. Although
driving safety is the ultimate concern for autonomous driving, there is no
comprehensive study on the linkage between the performance of deep learning
models and the driving safety of autonomous vehicles under adversarial attacks.
In this paper, we investigate the impact of two primary types of adversarial
attacks, perturbation attacks and patch attacks, on the driving safety of
vision-based autonomous vehicles rather than the detection precision of deep
learning models. In particular, we consider two state-of-the-art models in
vision-based 3D object detection, Stereo R-CNN and DSGN. To evaluate driving
safety, we propose an end-to-end evaluation framework with a set of driving
safety performance metrics. By analyzing the results of our extensive
evaluation experiments, we find that (1) the attack's impact on the driving
safety of autonomous vehicles and the attack's impact on the precision of 3D
object detectors are decoupled, and (2) the DSGN model demonstrates stronger
robustness to adversarial attacks than the Stereo R-CNN model. In addition, we
further investigate the causes behind the two findings with an ablation study.
The findings of this paper provide a new perspective to evaluate adversarial
attacks and guide the selection of deep learning models in autonomous driving.",arxiv
http://arxiv.org/abs/1902.01909v1,2019-02-05T21:10:37Z,2019-02-05T21:10:37Z,Adaptive Stress Testing for Autonomous Vehicles,"This paper presents a method for testing the decision making systems of
autonomous vehicles. Our approach involves perturbing stochastic elements in
the vehicle's environment until the vehicle is involved in a collision. Instead
of applying direct Monte Carlo sampling to find collision scenarios, we
formulate the problem as a Markov decision process and use reinforcement
learning algorithms to find the most likely failure scenarios. This paper
presents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL)
solutions that can scale to large environments. We show that DRL can find more
likely failure scenarios than MCTS with fewer calls to the simulator. A
simulation scenario involving a vehicle approaching a crosswalk is used to
validate the framework. Our proposed approach is very general and can be easily
applied to other scenarios given the appropriate models of the vehicle and the
environment.",arxiv
http://arxiv.org/abs/1906.11021v1,2019-06-26T12:22:13Z,2019-06-26T12:22:13Z,Cooperation-Aware Reinforcement Learning for Merging in Dense Traffic,"Decision making in dense traffic can be challenging for autonomous vehicles.
An autonomous system only relying on predefined road priorities and considering
other drivers as moving objects will cause the vehicle to freeze and fail the
maneuver. Human drivers leverage the cooperation of other drivers to avoid such
deadlock situations and convince others to change their behavior. Decision
making algorithms must reason about the interaction with other drivers and
anticipate a broad range of driver behaviors. In this work, we present a
reinforcement learning approach to learn how to interact with drivers with
different cooperation levels. We enhanced the performance of traditional
reinforcement learning algorithms by maintaining a belief over the level of
cooperation of other drivers. We show that our agent successfully learns how to
navigate a dense merging scenario with less deadlocks than with online planning
methods.",arxiv
http://arxiv.org/abs/1711.06976v4,2019-08-14T11:17:00Z,2017-11-19T06:46:21Z,"MIT Advanced Vehicle Technology Study: Large-Scale Naturalistic Driving
  Study of Driver Behavior and Interaction with Automation","For the foreseeble future, human beings will likely remain an integral part
of the driving task, monitoring the AI system as it performs anywhere from just
over 0% to just under 100% of the driving. The governing objectives of the MIT
Autonomous Vehicle Technology (MIT-AVT) study are to (1) undertake large-scale
real-world driving data collection that includes high-definition video to fuel
the development of deep learning based internal and external perception
systems, (2) gain a holistic understanding of how human beings interact with
vehicle automation technology by integrating video data with vehicle state
data, driver characteristics, mental models, and self-reported experiences with
technology, and (3) identify how technology and other factors related to
automation adoption and use can be improved in ways that save lives. In
pursuing these objectives, we have instrumented 23 Tesla Model S and Model X
vehicles, 2 Volvo S90 vehicles, 2 Range Rover Evoque, and 2 Cadillac CT6
vehicles for both long-term (over a year per driver) and medium term (one month
per driver) naturalistic driving data collection. Furthermore, we are
continually developing new methods for analysis of the massive-scale dataset
collected from the instrumented vehicle fleet. The recorded data streams
include IMU, GPS, CAN messages, and high-definition video streams of the driver
face, the driver cabin, the forward roadway, and the instrument cluster (on
select vehicles). The study is on-going and growing. To date, we have 122
participants, 15,610 days of participation, 511,638 miles, and 7.1 billion
video frames. This paper presents the design of the study, the data collection
hardware, the processing of the data, and the computer vision algorithms
currently being used to extract actionable knowledge from the data.",arxiv
http://arxiv.org/abs/1804.03406v1,2018-04-10T09:07:23Z,2018-04-10T09:07:23Z,"Proceedings 2nd International Workshop on Safe Control of Autonomous
  Vehicles","These are the proceedings of the Second International Workshop on Safe
Control of Autonomous Vehicles, which took place on the 10th of April 2018 in
Porto, Portugal as an affiliated workshop of CSPWeek. The task of this workshop
is to identify open research problems, discuss recent achievements, bring
together researchers in, e.g., control theory, adaptive systems, machine
self-organization and autonomy, mobile intelligent robotics, transportation,
traffic control, machine learning, software verification, and dependability and
security engineering.",arxiv
http://arxiv.org/abs/1902.03601v1,2019-02-10T13:51:47Z,2019-02-10T13:51:47Z,Vulnerable road user detection: state-of-the-art and open challenges,"Correctly identifying vulnerable road users (VRUs), e.g. cyclists and
pedestrians, remains one of the most challenging environment perception tasks
for autonomous vehicles (AVs). This work surveys the current state-of-the-art
in VRU detection, covering topics such as benchmarks and datasets, object
detection techniques and relevant machine learning algorithms. The article
concludes with a discussion of remaining open challenges and promising future
research directions for this domain.",arxiv
http://arxiv.org/abs/2105.02613v1,2021-05-06T12:40:28Z,2021-05-06T12:40:28Z,"Challenges and Obstacles Towards Deploying Deep Learning Models on
  Mobile Devices","From computer vision and speech recognition to forecasting trajectories in
autonomous vehicles, deep learning approaches are at the forefront of so many
domains. Deep learning models are developed using plethora of high-level,
generic frameworks and libraries. Running those models on the mobile devices
require hardware-aware optimizations and in most cases converting the models to
other formats or using a third-party framework. In reality, most of the
developed models need to undergo a process of conversion, adaptation, and, in
some cases, full retraining to match the requirements and features of the
framework that is deploying the model on the target platform. Variety of
hardware platforms with heterogeneous computing elements, from wearable devices
to high-performance GPU clusters are used to run deep learning models. In this
paper, we present the existing challenges, obstacles, and practical solutions
towards deploying deep learning models on mobile devices.",arxiv
http://arxiv.org/abs/2007.08343v1,2020-07-16T14:09:20Z,2020-07-16T14:09:20Z,"Dueling Deep Q Network for Highway Decision Making in Autonomous
  Vehicles: A Case Study","This work optimizes the highway decision making strategy of autonomous
vehicles by using deep reinforcement learning (DRL). First, the highway driving
environment is built, wherein the ego vehicle, surrounding vehicles, and road
lanes are included. Then, the overtaking decision-making problem of the
automated vehicle is formulated as an optimal control problem. Then relevant
control actions, state variables, and optimization objectives are elaborated.
Finally, the deep Q-network is applied to derive the intelligent driving
policies for the ego vehicle. Simulation results reveal that the ego vehicle
could safely and efficiently accomplish the driving task after learning and
training.",arxiv
http://arxiv.org/abs/2007.09101v1,2020-07-16T14:37:50Z,2020-07-16T14:37:50Z,"Reinforcement Learning-Enabled Decision-Making Strategies for a
  Vehicle-Cyber-Physical-System in Connected Environment","As a typical vehicle-cyber-physical-system (V-CPS), connected automated
vehicles attracted more and more attention in recent years. This paper focuses
on discussing the decision-making (DM) strategy for autonomous vehicles in a
connected environment. First, the highway DM problem is formulated, wherein the
vehicles can exchange information via wireless networking. Then, two classical
reinforcement learning (RL) algorithms, Q-learning and Dyna, are leveraged to
derive the DM strategies in a predefined driving scenario. Finally, the control
performance of the derived DM policies in safety and efficiency is analyzed.
Furthermore, the inherent differences of the RL algorithms are embodied and
discussed in DM strategies.",arxiv
http://arxiv.org/abs/1811.05594v1,2018-11-14T01:50:20Z,2018-11-14T01:50:20Z,"TrolleyMod v1.0: An Open-Source Simulation and Data-Collection Platform
  for Ethical Decision Making in Autonomous Vehicles","This paper presents TrolleyMod v1.0, an open-source platform based on the
CARLA simulator for the collection of ethical decision-making data for
autonomous vehicles. This platform is designed to facilitate experiments aiming
to observe and record human decisions and actions in high-fidelity simulations
of ethical dilemmas that occur in the context of driving. Targeting experiments
in the class of trolley problems, TrolleyMod provides a seamless approach to
creating new experimental settings and environments with the realistic
physics-engine and the high-quality graphical capabilities of CARLA and the
Unreal Engine. Also, TrolleyMod provides a straightforward interface between
the CARLA environment and Python to enable the implementation of custom
controllers, such as deep reinforcement learning agents. The results of such
experiments can be used for sociological analyses, as well as the training and
tuning of value-aligned autonomous vehicles based on social values that are
inferred from observations.",arxiv
http://arxiv.org/abs/1903.05252v4,2020-06-22T16:11:57Z,2019-03-12T23:04:03Z,"Zero-Shot Autonomous Vehicle Policy Transfer: From Simulation to
  Real-World via Adversarial Learning","In this article, we demonstrate a zero-shot transfer of an autonomous driving
policy from simulation to University of Delaware's scaled smart city with
adversarial multi-agent reinforcement learning, in which an adversary attempts
to decrease the net reward by perturbing both the inputs and outputs of the
autonomous vehicles during training. We train the autonomous vehicles to
coordinate with each other while crossing a roundabout in the presence of an
adversary in simulation. The adversarial policy successfully reproduces the
simulated behavior and incidentally outperforms, in terms of travel time, both
a human-driving baseline and adversary-free trained policies. Finally, we
demonstrate that the addition of adversarial training considerably improves the
performance \eat{stability and robustness} of the policies after transfer to
the real world compared to Gaussian noise injection.",arxiv
http://arxiv.org/abs/2108.10222v1,2021-08-19T06:27:01Z,2021-08-19T06:27:01Z,"Cooperative Localization Utilizing Reinforcement Learning for 5G
  Networks","The demand for accurate localization has risen in recent years to enable the
emerging of autonomous vehicles. To have these vehicles in the traffic
ecosystem of smart cities, the need for an accurate positioning system is
emphasized. To realize accurate positioning, collaborative localization plays
an important role. This type of localization computes range measurements
between vehicles and improves the accuracy of position by correcting the
possibly faulty values of one of them by using the more accurate values of the
other. 5G signals with the technology of Millimeter Wave (mmWave) support
precise range measurements and 5G networks provide Device to Device (D2D)
communication which improves collaborative localization. The aim of this paper
is to provide an accurate collaborative positioning for autonomous vehicles,
which is less prone to errors utilizing reinforcement learning technique for
selecting the most accurate and suitable range measurement technique for the 5G
signal.",arxiv
http://arxiv.org/abs/2011.11912v1,2020-11-24T06:23:51Z,2020-11-24T06:23:51Z,Variational Monocular Depth Estimation for Reliability Prediction,"Self-supervised learning for monocular depth estimation is widely
investigated as an alternative to supervised learning approach, that requires a
lot of ground truths. Previous works have successfully improved the accuracy of
depth estimation by modifying the model structure, adding objectives, and
masking dynamic objects and occluded area. However, when using such estimated
depth image in applications, such as autonomous vehicles, and robots, we have
to uniformly believe the estimated depth at each pixel position. This could
lead to fatal errors in performing the tasks, because estimated depth at some
pixels may make a bigger mistake. In this paper, we theoretically formulate a
variational model for the monocular depth estimation to predict the reliability
of the estimated depth image. Based on the results, we can exclude the
estimated depths with low reliability or refine them for actual use. The
effectiveness of the proposed method is quantitatively and qualitatively
demonstrated using the KITTI benchmark and Make3D dataset.",arxiv
http://arxiv.org/abs/1808.10854v1,2018-08-25T02:35:47Z,2018-08-25T02:35:47Z,Forecasting solar radiation during dust storms using deep learning,"Dust storms are common in arid zones on the earth and others planets such as
Mars. The impact of dust storms on solar radiation has significant implications
for solar power plants and autonomous vehicles powered by solar panels. This
paper deals with the analysis of solar radiation and power output of a rooftop
photovoltaic plant during a dust storm and proposes a forecasting methodology
using deep learning network. The increased aerosol content due to dust storms
increases the diffuse component of the solar radiation. This effect persists
for a long duration and can impact the quality of forecasting of solar
radiation. Deep learning networks that capture long range structure can improve
the quality of solar radiation forecasting during dust storms. These results
can help explain the sudden drop in power output of solar plants due to dust
storms originating in another continent. They can shed light on mysterious
cleaning events in autonomous vehicles powered by solar panels to be used in
space missions.",arxiv
http://arxiv.org/abs/2006.00049v1,2020-05-29T19:42:25Z,2020-05-29T19:42:25Z,PointNet on FPGA for Real-Time LiDAR Point Cloud Processing,"LiDAR sensors have been widely used in many autonomous vehicle modalities,
such as perception, mapping, and localization. This paper presents an
FPGA-based deep learning platform for real-time point cloud processing targeted
on autonomous vehicles. The software driver for the Velodyne LiDAR sensor is
modified and moved into the on-chip processor system, while the programmable
logic is designed as a customized hardware accelerator. As the state-of-art
deep learning algorithm for point cloud processing, PointNet is successfully
implemented on the proposed FPGA platform. Targeted on a Xilinx Zynq
UltraScale+ MPSoC ZCU104 development board, the FPGA implementations of
PointNet achieve the computing performance of 182.1 GOPS and 280.0 GOPS for
classification and segmentation respectively. The proposed design can support
an input up to 4096 points per frame. The processing time is 19.8 ms for
classification and 34.6 ms for segmentation, which meets the real-time
requirement for most of the existing LiDAR sensors.",arxiv
http://arxiv.org/abs/2107.12692v1,2021-07-27T09:42:18Z,2021-07-27T09:42:18Z,"Dynamic and Static Object Detection Considering Fusion Regions and
  Point-wise Features","Object detection is a critical problem for the safe interaction between
autonomous vehicles and road users. Deep-learning methodologies allowed the
development of object detection approaches with better performance. However,
there is still the challenge to obtain more characteristics from the objects
detected in real-time. The main reason is that more information from the
environment's objects can improve the autonomous vehicle capacity to face
different urban situations. This paper proposes a new approach to detect static
and dynamic objects in front of an autonomous vehicle. Our approach can also
get other characteristics from the objects detected, like their position,
velocity, and heading. We develop our proposal fusing results of the
environment's interpretations achieved of YoloV3 and a Bayesian filter. To
demonstrate our proposal's performance, we asses it through a benchmark dataset
and real-world data obtained from an autonomous platform. We compared the
results achieved with another approach.",arxiv
http://arxiv.org/abs/1707.05303v1,2017-07-17T17:57:42Z,2017-07-17T17:57:42Z,Aggressive Deep Driving: Model Predictive Control with a CNN Cost Model,"We present a framework for vision-based model predictive control (MPC) for
the task of aggressive, high-speed autonomous driving. Our approach uses deep
convolutional neural networks to predict cost functions from input video which
are directly suitable for online trajectory optimization with MPC. We
demonstrate the method in a high speed autonomous driving scenario, where we
use a single monocular camera and a deep convolutional neural network to
predict a cost map of the track in front of the vehicle. Results are
demonstrated on a 1:5 scale autonomous vehicle given the task of high speed,
aggressive driving.",arxiv
http://arxiv.org/abs/1704.02696v1,2017-04-10T03:46:00Z,2017-04-10T03:46:00Z,Implementing a Cloud Platform for Autonomous Driving,"Autonomous driving clouds provide essential services to support autonomous
vehicles. Today these services include but not limited to distributed
simulation tests for new algorithm deployment, offline deep learning model
training, and High-Definition (HD) map generation. These services require
infrastructure support including distributed computing, distributed storage, as
well as heterogeneous computing. In this paper, we present the details of how
we implement a unified autonomous driving cloud infrastructure, and how we
support these services on top of this infrastructure.",arxiv
http://arxiv.org/abs/1810.11211v2,2019-03-22T08:59:39Z,2018-10-26T07:31:53Z,"Deep-Reinforcement-Learning-Based Distributed Vehicle Position Controls
  for Coverage Expansion in mmWave V2X","In millimeter wave (mmWave) vehicular communications, multi-hop relay
disconnection by line-of-sight (LOS) blockage is a critical problem, especially
in the early diffusion phase of mmWave-available vehicles, where not all the
vehicles have mmWave communication devices. This paper proposes a distributed
position control method for autonomous vehicles to make long relays connecting
to road side units (RSUs) by avoiding blockages to communicate with each other
via LOS paths. Even though vehicles with the proposed method do not use the
whole information of the environments and cooperate with each other, they can
decide their action (e.g., lane change and overtaking) to form long relays
using only information of its surroundings (e.g., surrounding vehicle
positions). The decision-making problem is formulated as a Markov decision
process so that autonomous vehicles can learn a practical movement strategy of
making long relays by a reinforcement learning (RL) algorithm. This paper
designs a learning algorithm based on a sophisticated deep reinforcement
learning algorithm, asynchronous advantage actor-critic (A3C), which enables
vehicles to learn a complex movement strategy quickly by its deepneural-network
architecture and multi-agent-learning mechanism. Once the strategy is well
trained, vehicles can distributedly move to positions where the long relay to
the RSU is established. Simulations results confirm that the proposed method
can increase the relay length and coverage even if the traffic conditions and
penetration ratio of mmWave communication devices in learning and operation
phases are different.",arxiv
http://arxiv.org/abs/1812.06120v2,2019-02-22T21:41:17Z,2018-12-14T19:20:09Z,"Simulation to Scaled City: Zero-Shot Policy Transfer for Traffic Control
  via Autonomous Vehicles","Using deep reinforcement learning, we train control policies for autonomous
vehicles leading a platoon of vehicles onto a roundabout. Using Flow, a library
for deep reinforcement learning in micro-simulators, we train two policies, one
policy with noise injected into the state and action space and one without any
injected noise. In simulation, the autonomous vehicle learns an emergent
metering behavior for both policies in which it slows to allow for smoother
merging. We then directly transfer this policy without any tuning to the
University of Delaware Scaled Smart City (UDSSC), a 1:25 scale testbed for
connected and automated vehicles. We characterize the performance of both
policies on the scaled city. We show that the noise-free policy winds up
crashing and only occasionally metering. However, the noise-injected policy
consistently performs the metering behavior and remains collision-free,
suggesting that the noise helps with the zero-shot policy transfer.
Additionally, the transferred, noise-injected policy leads to a 5% reduction of
average travel time and a reduction of 22% in maximum travel time in the UDSSC.
Videos of the controllers can be found at
https://sites.google.com/view/iccps-policy-transfer.",arxiv
http://arxiv.org/abs/2007.12565v1,2020-07-24T15:16:27Z,2020-07-24T15:16:27Z,"Integrated Longitudinal Speed Decision-Making and Energy Efficiency
  Control for Connected Electrified Vehicles","To improve the driving mobility and energy efficiency of connected autonomous
electrified vehicles, this paper presents an integrated longitudinal speed
decision-making and energy efficiency control strategy. The proposed approach
is a hierarchical control architecture, which is assumed to consist of
higher-level and lower-level controls. As the core of this study, model
predictive control and reinforcement learning are combined to improve the
powertrain mobility and fuel economy for a group of automated vehicles. The
higher-level exploits the signal phase and timing and state information of
connected autonomous vehicles via vehicle to infrastructure and vehicle to
vehicle communication to reduce stopping at red lights. The higher-level
outputs the optimal vehicle velocity using model predictive control technique
and receives the power split control from the lower-level con-troller. These
two levels communicate with each other via a controller area network in the
real vehicle. The lower-level utilizes a model-free reinforcement learning
method to improve the fuel economy for each connected autonomous vehicle.
Numerical tests illustrate that vehicle mobility can be noticeably improved
(traveling time reduced by 30%) by reducing red-light idling. The effectiveness
and performance of the proposed method are validated via comparison analysis
among different energy efficiency controls (fuel economy promoted by 13%).",arxiv
http://arxiv.org/abs/2005.09830v1,2020-05-20T03:01:40Z,2020-05-20T03:01:40Z,Deep Learning for LiDAR Point Clouds in Autonomous Driving: A Review,"Recently, the advancement of deep learning in discriminative feature learning
from 3D LiDAR data has led to rapid development in the field of autonomous
driving. However, automated processing uneven, unstructured, noisy, and massive
3D point clouds is a challenging and tedious task. In this paper, we provide a
systematic review of existing compelling deep learning architectures applied in
LiDAR point clouds, detailing for specific tasks in autonomous driving such as
segmentation, detection, and classification. Although several published
research papers focus on specific topics in computer vision for autonomous
vehicles, to date, no general survey on deep learning applied in LiDAR point
clouds for autonomous vehicles exists. Thus, the goal of this paper is to
narrow the gap in this topic. More than 140 key contributions in the recent
five years are summarized in this survey, including the milestone 3D deep
architectures, the remarkable deep learning applications in 3D semantic
segmentation, object detection, and classification; specific datasets,
evaluation metrics, and the state of the art performance. Finally, we conclude
the remaining challenges and future researches.",arxiv
http://arxiv.org/abs/2001.03864v1,2020-01-12T06:06:03Z,2020-01-12T06:06:03Z,"Learning to drive via Apprenticeship Learning and Deep Reinforcement
  Learning","With the implementation of reinforcement learning (RL) algorithms, current
state-of-art autonomous vehicle technology have the potential to get closer to
full automation. However, most of the applications have been limited to game
domains or discrete action space which are far from the real world driving.
Moreover, it is very tough to tune the parameters of reward mechanism since the
driving styles vary a lot among the different users. For instance, an
aggressive driver may prefer driving with high acceleration whereas some
conservative drivers prefer a safer driving style. Therefore, we propose an
apprenticeship learning in combination with deep reinforcement learning
approach that allows the agent to learn the driving and stopping behaviors with
continuous actions. We use gradient inverse reinforcement learning (GIRL)
algorithm to recover the unknown reward function and employ REINFORCE as well
as Deep Deterministic Policy Gradient algorithm (DDPG) to learn the optimal
policy. The performance of our method is evaluated in simulation-based scenario
and the results demonstrate that the agent performs human like driving and even
better in some aspects after training.",arxiv
http://arxiv.org/abs/2005.05441v2,2020-08-29T01:27:43Z,2020-05-11T21:21:50Z,"Delay-Aware Multi-Agent Reinforcement Learning for Cooperative and
  Competitive Environments","Action and observation delays exist prevalently in the real-world
cyber-physical systems which may pose challenges in reinforcement learning
design. It is particularly an arduous task when handling multi-agent systems
where the delay of one agent could spread to other agents. To resolve this
problem, this paper proposes a novel framework to deal with delays as well as
the non-stationary training issue of multi-agent tasks with model-free deep
reinforcement learning. We formally define the Delay-Aware Markov Game that
incorporates the delays of all agents in the environment. To solve Delay-Aware
Markov Games, we apply centralized training and decentralized execution that
allows agents to use extra information to ease the non-stationarity issue of
the multi-agent systems during training, without the need of a centralized
controller during execution. Experiments are conducted in multi-agent particle
environments including cooperative communication, cooperative navigation, and
competitive experiments. We also test the proposed algorithm in traffic
scenarios that require coordination of all autonomous vehicles to show the
practical value of delay-awareness. Results show that the proposed delay-aware
multi-agent reinforcement learning algorithm greatly alleviates the performance
degradation introduced by delay. Codes and demo videos are available at:
https://github.com/baimingc/delay-aware-MARL.",arxiv
http://arxiv.org/abs/2102.03127v1,2021-02-05T12:08:11Z,2021-02-05T12:08:11Z,"Experience-Based Heuristic Search: Robust Motion Planning with Deep
  Q-Learning","Interaction-aware planning for autonomous driving requires an exploration of
a combinatorial solution space when using conventional search- or
optimization-based motion planners. With Deep Reinforcement Learning, optimal
driving strategies for such problems can be derived also for higher-dimensional
problems. However, these methods guarantee optimality of the resulting policy
only in a statistical sense, which impedes their usage in safety critical
systems, such as autonomous vehicles. Thus, we propose the
Experience-Based-Heuristic-Search algorithm, which overcomes the statistical
failure rate of a Deep-reinforcement-learning-based planner and still benefits
computationally from the pre-learned optimal policy. Specifically, we show how
experiences in the form of a Deep Q-Network can be integrated as heuristic into
a heuristic search algorithm. We benchmark our algorithm in the field of path
planning in semi-structured valet parking scenarios. There, we analyze the
accuracy of such estimates and demonstrate the computational advantages and
robustness of our method. Our method may encourage further investigation of the
applicability of reinforcement-learning-based planning in the field of
self-driving vehicles.",arxiv
http://arxiv.org/abs/2106.07256v1,2021-06-14T09:19:47Z,2021-06-14T09:19:47Z,Deterministic Guided LiDAR Depth Map Completion,"Accurate dense depth estimation is crucial for autonomous vehicles to analyze
their environment. This paper presents a non-deep learning-based approach to
densify a sparse LiDAR-based depth map using a guidance RGB image. To achieve
this goal the RGB image is at first cleared from most of the camera-LiDAR
misalignment artifacts. Afterward, it is over segmented and a plane for each
superpixel is approximated. In the case a superpixel is not well represented by
a plane, a plane is approximated for a convex hull of the most inlier. Finally,
the pinhole camera model is used for the interpolation process and the
remaining areas are interpolated. The evaluation of this work is executed using
the KITTI depth completion benchmark, which validates the proposed work and
shows that it outperforms the state-of-the-art non-deep learning-based methods,
in addition to several deep learning-based methods.",arxiv
http://arxiv.org/abs/2001.10117v3,2020-02-27T17:23:40Z,2020-01-27T23:21:38Z,Canadian Adverse Driving Conditions Dataset,"The Canadian Adverse Driving Conditions (CADC) dataset was collected with the
Autonomoose autonomous vehicle platform, based on a modified Lincoln MKZ. The
dataset, collected during winter within the Region of Waterloo, Canada, is the
first autonomous vehicle dataset that focuses on adverse driving conditions
specifically. It contains 7,000 frames collected through a variety of winter
weather conditions of annotated data from 8 cameras (Ximea MQ013CG-E2), Lidar
(VLP-32C) and a GNSS+INS system (Novatel OEM638). The sensors are time
synchronized and calibrated with the intrinsic and extrinsic calibrations
included in the dataset. Lidar frame annotations that represent ground truth
for 3D object detection and tracking have been provided by Scale AI.",arxiv
http://arxiv.org/abs/2110.13585v1,2021-10-26T11:34:41Z,2021-10-26T11:34:41Z,Concepts for Automated Machine Learning in Smart Grid Applications,"Undoubtedly, the increase of available data and competitive machine learning
algorithms has boosted the popularity of data-driven modeling in energy
systems. Applications are forecasts for renewable energy generation and energy
consumption. Forecasts are elementary for sector coupling, where
energy-consuming sectors are interconnected with the power-generating sector to
address electricity storage challenges by adding flexibility to the power
system. However, the large-scale application of machine learning methods in
energy systems is impaired by the need for expert knowledge, which covers
machine learning expertise and a profound understanding of the application's
process. The process knowledge is required for the problem formalization, as
well as the model validation and application. The machine learning skills
include the processing steps of i) data pre-processing, ii) feature
engineering, extraction, and selection, iii) algorithm selection, iv)
hyperparameter optimization, and possibly v) post-processing of the model's
output. Tailoring a model for a particular application requires selecting the
data, designing various candidate models and organizing the data flow between
the processing steps, selecting the most suitable model, and monitoring the
model during operation - an iterative and time-consuming procedure. Automated
design and operation of machine learning aim to reduce the human effort to
address the increasing demand for data-driven models. We define five levels of
automation for forecasting in alignment with the SAE standard for autonomous
vehicles, where manual design and application reflect Automation level 0.",arxiv
http://arxiv.org/abs/1904.06025v2,2020-02-21T18:00:23Z,2019-04-12T04:01:18Z,"Interaction-aware Decision Making with Adaptive Strategies under Merging
  Scenarios","In order to drive safely and efficiently under merging scenarios, autonomous
vehicles should be aware of their surroundings and make decisions by
interacting with other road participants. Moreover, different strategies should
be made when the autonomous vehicle is interacting with drivers having
different level of cooperativeness. Whether the vehicle is on the merge-lane or
main-lane will also influence the driving maneuvers since drivers will behave
differently when they have the right-of-way than otherwise. Many traditional
methods have been proposed to solve decision making problems under merging
scenarios. However, these works either are incapable of modeling complicated
interactions or require implementing hand-designed rules which cannot properly
handle the uncertainties in real-world scenarios. In this paper, we proposed an
interaction-aware decision making with adaptive strategies (IDAS) approach that
can let the autonomous vehicle negotiate the road with other drivers by
leveraging their cooperativeness under merging scenarios. A single policy is
learned under the multi-agent reinforcement learning (MARL) setting via the
curriculum learning strategy, which enables the agent to automatically infer
other drivers' various behaviors and make decisions strategically. A masking
mechanism is also proposed to prevent the agent from exploring states that
violate common sense of human judgment and increase the learning efficiency. An
exemplar merging scenario was used to implement and examine the proposed
method.",arxiv
http://arxiv.org/abs/2109.13077v1,2021-09-27T14:25:44Z,2021-09-27T14:25:44Z,"Validating human driver models for interaction-aware automated vehicle
  controllers: A human factors approach","A major challenge for autonomous vehicles is interacting with other traffic
participants safely and smoothly. A promising approach to handle such traffic
interactions is equipping autonomous vehicles with interaction-aware
controllers (IACs). These controllers predict how surrounding human drivers
will respond to the autonomous vehicle's actions, based on a driver model.
However, the predictive validity of driver models used in IACs is rarely
validated, which can limit the interactive capabilities of IACs outside the
simple simulated environments in which they are demonstrated. In this paper, we
argue that besides evaluating the interactive capabilities of IACs, their
underlying driver models should be validated on natural human driving behavior.
We propose a workflow for this validation that includes scenario-based data
extraction and a two-stage (tactical/operational) evaluation procedure based on
human factors literature. We demonstrate this workflow in a case study on an
inverse-reinforcement-learning-based driver model replicated from an existing
IAC. This model only showed the correct tactical behavior in 40% of the
predictions. The model's operational behavior was inconsistent with observed
human behavior. The case study illustrates that a principled evaluation
workflow is useful and needed. We believe that our workflow will support the
development of appropriate driver models for future automated vehicles.",arxiv
http://arxiv.org/abs/2011.08729v3,2021-09-10T20:37:18Z,2020-11-17T16:04:39Z,Control Strategies for Autonomous Vehicles,"This chapter focuses on the self-driving technology from a control
perspective and investigates the control strategies used in autonomous vehicles
and advanced driver-assistance systems from both theoretical and practical
viewpoints. First, we introduce the self-driving technology as a whole,
including perception, planning and control techniques required for
accomplishing the challenging task of autonomous driving. We then dwell upon
each of these operations to explain their role in the autonomous system
architecture, with a prime focus on control strategies. The core portion of
this chapter commences with detailed mathematical modeling of autonomous
vehicles followed by a comprehensive discussion on control strategies. The
chapter covers longitudinal as well as lateral control strategies for
autonomous vehicles with coupled and de-coupled control schemes. We as well
discuss some of the machine learning techniques applied to autonomous vehicle
control task. Finally, we briefly summarize some of the research works that our
team has carried out at the Autonomous Systems Lab and conclude the chapter
with a few thoughtful remarks.",arxiv
http://arxiv.org/abs/1806.02609v1,2018-06-07T11:08:53Z,2018-06-07T11:08:53Z,"Learning Multi-Modal Self-Awareness Models for Autonomous Vehicles from
  Human Driving","This paper presents a novel approach for learning self-awareness models for
autonomous vehicles. The proposed technique is based on the availability of
synchronized multi-sensor dynamic data related to different maneuvering tasks
performed by a human operator. It is shown that different machine learning
approaches can be used to first learn single modality models using coupled
Dynamic Bayesian Networks; such models are then correlated at event level to
discover contextual multi-modal concepts. In the presented case, visual
perception and localization are used as modalities. Cross-correlations among
modalities in time is discovered from data and are described as probabilistic
links connecting shared and private multi-modal DBNs at the event (discrete)
level. Results are presented on experiments performed on an autonomous vehicle,
highlighting potentiality of the proposed approach to allow anomaly detection
and autonomous decision making based on learned self-awareness models.",arxiv
http://arxiv.org/abs/2103.14225v1,2021-03-26T02:25:42Z,2021-03-26T02:25:42Z,SD-VEC: Software-Defined Vehicular Edge Computing with Ultra-Low Latency,"New paradigm shifts and 6G technological revolution in vehicular services
have emerged toward unmanned driving, automated transportation, and
self-driving vehicles. As the technology for autonomous vehicles becomes
mature, real challenges come from reliable, safe, real-time connected
transportation operations to achieve ubiquitous and prompt information
exchanges with massive connected and autonomous vehicles. This article aims at
introducing novel wireless distributed architectures that embed the edge
computing capability inside software-defined vehicular networking
infrastructure. Such edge networks consist of open-loop grant-free
communications and computing-based control frameworks, which enable dynamic
eco-routing with ultra-low latency and mobile data-driven orchestration. Thus,
this work advances the frontiers of machine learning potentials and
next-generation mobile system realization in vehicular networking applications.",arxiv
http://arxiv.org/abs/2008.00706v1,2020-08-03T08:19:57Z,2020-08-03T08:19:57Z,LiDAR point-cloud processing based on projection methods: a comparison,"An accurate and rapid-response perception system is fundamental for
autonomous vehicles to operate safely. 3D object detection methods handle point
clouds given by LiDAR sensors to provide accurate depth and position
information for each detection, together with its dimensions and
classification. The information is then used to track vehicles and other
obstacles in the surroundings of the autonomous vehicle, and also to feed
control units that guarantee collision avoidance and motion planning. Nowadays,
object detection systems can be divided into two main categories. The first
ones are the geometric based, which retrieve the obstacles using geometric and
morphological operations on the 3D points. The seconds are the deep
learning-based, which process the 3D points, or an elaboration of the 3D
point-cloud, with deep learning techniques to retrieve a set of obstacles. This
paper presents a comparison between those two approaches, presenting one
implementation of each class on a real autonomous vehicle. Accuracy of the
estimates of the algorithms has been evaluated with experimental tests carried
in the Monza ENI circuit. The position of the ego vehicle and the obstacle is
given by GPS sensors with RTK correction, which guarantees an accurate ground
truth for the comparison. Both algorithms have been implemented on ROS and run
on a consumer laptop.",arxiv
http://arxiv.org/abs/1709.06692v2,2018-12-18T23:16:48Z,2017-09-20T01:17:49Z,A Voting-Based System for Ethical Decision Making,"We present a general approach to automating ethical decisions, drawing on
machine learning and computational social choice. In a nutshell, we propose to
learn a model of societal preferences, and, when faced with a specific ethical
dilemma at runtime, efficiently aggregate those preferences to identify a
desirable choice. We provide a concrete algorithm that instantiates our
approach; some of its crucial steps are informed by a new theory of
swap-dominance efficient voting rules. Finally, we implement and evaluate a
system for ethical decision making in the autonomous vehicle domain, using
preference data collected from 1.3 million people through the Moral Machine
website.",arxiv
http://arxiv.org/abs/1807.11332v1,2018-07-30T13:11:21Z,2018-07-30T13:11:21Z,Action Detection from a Robot-Car Perspective,"We present the new Road Event and Activity Detection (READ) dataset, designed
and created from an autonomous vehicle perspective to take action detection
challenges to autonomous driving. READ will give scholars in computer vision,
smart cars and machine learning at large the opportunity to conduct research
into exciting new problems such as understanding complex (road) activities,
discerning the behaviour of sentient agents, and predicting both the label and
the location of future actions and events, with the final goal of supporting
autonomous decision making.",arxiv
http://arxiv.org/abs/2002.03556v1,2020-02-10T05:32:11Z,2020-02-10T05:32:11Z,Vehicle Driving Assistant,"Autonomous vehicles has been a common term in our day to day life with car
manufacturers like Tesla shipping cars that are SAE Level 3. While these
vehicles include a slew of features such as parking assistance and cruise
control,they have mostly been tailored to foreign roads. Potholes, and the
abundance of them, is something that is unique to our Indian roads. We believe
that successful detection of potholes from visual images can be applied in a
variety of scenarios. Moreover, the sheer variety in the color, shape and size
of potholes makes this problem an apt candidate to be solved using modern
machine learning and image processing techniques.",arxiv
http://arxiv.org/abs/2108.05805v1,2021-08-12T15:37:30Z,2021-08-12T15:37:30Z,Reimagining an autonomous vehicle,"The self driving challenge in 2021 is this century's technological equivalent
of the space race, and is now entering the second major decade of development.
Solving the technology will create social change which parallels the invention
of the automobile itself. Today's autonomous driving technology is laudable,
though rooted in decisions made a decade ago. We argue that a rethink is
required, reconsidering the autonomous vehicle (AV) problem in the light of the
body of knowledge that has been gained since the DARPA challenges which seeded
the industry. What does AV2.0 look like? We present an alternative vision: a
recipe for driving with machine learning, and grand challenges for research in
driving.",arxiv
http://arxiv.org/abs/2108.12114v1,2021-08-27T04:28:14Z,2021-08-27T04:28:14Z,"Identification of Vehicle Dynamics Parameters Using Simulation-based
  Inference","Identifying tire and vehicle parameters is an essential step in designing
control and planning algorithms for autonomous vehicles. This paper proposes a
new method: Simulation-Based Inference (SBI), a modern interpretation of
Approximate Bayesian Computation methods (ABC) for parameter identification.
The simulation-based inference is an emerging method in the machine learning
literature and has proven to yield accurate results for many parameter sets in
complex problems. We demonstrate in this paper that it can handle the
identification of highly nonlinear vehicle dynamics parameters and gives
accurate estimates of the parameters for the governing equations.",arxiv
http://arxiv.org/abs/2004.05224v2,2020-09-09T14:12:13Z,2020-04-10T20:43:14Z,"Deep Learning for Image and Point Cloud Fusion in Autonomous Driving: A
  Review","Autonomous vehicles were experiencing rapid development in the past few
years. However, achieving full autonomy is not a trivial task, due to the
nature of the complex and dynamic driving environment. Therefore, autonomous
vehicles are equipped with a suite of different sensors to ensure robust,
accurate environmental perception. In particular, the camera-LiDAR fusion is
becoming an emerging research theme. However, so far there has been no critical
review that focuses on deep-learning-based camera-LiDAR fusion methods. To
bridge this gap and motivate future research, this paper devotes to review
recent deep-learning-based data fusion approaches that leverage both image and
point cloud. This review gives a brief overview of deep learning on image and
point cloud data processing. Followed by in-depth reviews of camera-LiDAR
fusion methods in depth completion, object detection, semantic segmentation,
tracking and online cross-sensor calibration, which are organized based on
their respective fusion levels. Furthermore, we compare these methods on
publicly available datasets. Finally, we identified gaps and over-looked
challenges between current academic researches and real-world applications.
Based on these observations, we provide our insights and point out promising
research directions.",arxiv
http://arxiv.org/abs/1405.5581v1,2014-05-22T00:30:20Z,2014-05-22T00:30:20Z,"Real-Time Predictive Modeling and Robust Avoidance of Pedestrians with
  Uncertain, Changing Intentions","To plan safe trajectories in urban environments, autonomous vehicles must be
able to quickly assess the future intentions of dynamic agents. Pedestrians are
particularly challenging to model, as their motion patterns are often uncertain
and/or unknown a priori. This paper presents a novel changepoint detection and
clustering algorithm that, when coupled with offline unsupervised learning of a
Gaussian process mixture model (DPGP), enables quick detection of changes in
intent and online learning of motion patterns not seen in prior training data.
The resulting long-term movement predictions demonstrate improved accuracy
relative to offline learning alone, in terms of both intent and trajectory
prediction. By embedding these predictions within a chance-constrained motion
planner, trajectories which are probabilistically safe to pedestrian motions
can be identified in real-time. Hardware experiments demonstrate that this
approach can accurately predict pedestrian motion patterns from onboard
sensor/perception data and facilitate robust navigation within a dynamic
environment.",arxiv
http://arxiv.org/abs/2007.08501v1,2020-07-16T17:53:02Z,2020-07-16T17:53:02Z,Accelerating 3D Deep Learning with PyTorch3D,"Deep learning has significantly improved 2D image recognition. Extending into
3D may advance many new applications including autonomous vehicles, virtual and
augmented reality, authoring 3D content, and even improving 2D recognition.
However despite growing interest, 3D deep learning remains relatively
underexplored. We believe that some of this disparity is due to the engineering
challenges involved in 3D deep learning, such as efficiently processing
heterogeneous data and reframing graphics operations to be differentiable. We
address these challenges by introducing PyTorch3D, a library of modular,
efficient, and differentiable operators for 3D deep learning. It includes a
fast, modular differentiable renderer for meshes and point clouds, enabling
analysis-by-synthesis approaches. Compared with other differentiable renderers,
PyTorch3D is more modular and efficient, allowing users to more easily extend
it while also gracefully scaling to large meshes and images. We compare the
PyTorch3D operators and renderer with other implementations and demonstrate
significant speed and memory improvements. We also use PyTorch3D to improve the
state-of-the-art for unsupervised 3D mesh and point cloud prediction from 2D
images on ShapeNet. PyTorch3D is open-source and we hope it will help
accelerate research in 3D deep learning.",arxiv
http://arxiv.org/abs/2003.00789v1,2020-02-28T16:27:53Z,2020-02-28T16:27:53Z,"Towards Identifying and closing Gaps in Assurance of autonomous Road
  vehicleS -- a collection of Technical Notes Part 1","This report provides an introduction and overview of the Technical Topic
Notes (TTNs) produced in the Towards Identifying and closing Gaps in Assurance
of autonomous Road vehicleS (Tigars) project. These notes aim to support the
development and evaluation of autonomous vehicles. Part 1 addresses:
Assurance-overview and issues, Resilience and Safety Requirements, Open Systems
Perspective and Formal Verification and Static Analysis of ML Systems. Part 2:
Simulation and Dynamic Testing, Defence in Depth and Diversity,
Security-Informed Safety Analysis, Standards and Guidelines.",arxiv
http://arxiv.org/abs/1705.05065v2,2017-07-18T05:30:28Z,2017-05-15T04:06:22Z,"AirSim: High-Fidelity Visual and Physical Simulation for Autonomous
  Vehicles","Developing and testing algorithms for autonomous vehicles in real world is an
expensive and time consuming process. Also, in order to utilize recent advances
in machine intelligence and deep learning we need to collect a large amount of
annotated training data in a variety of conditions and environments. We present
a new simulator built on Unreal Engine that offers physically and visually
realistic simulations for both of these goals. Our simulator includes a physics
engine that can operate at a high frequency for real-time hardware-in-the-loop
(HITL) simulations with support for popular protocols (e.g. MavLink). The
simulator is designed from the ground up to be extensible to accommodate new
types of vehicles, hardware platforms and software protocols. In addition, the
modular design enables various components to be easily usable independently in
other projects. We demonstrate the simulator by first implementing a quadrotor
as an autonomous vehicle and then experimentally comparing the software
components with real-world flights.",arxiv
http://arxiv.org/abs/2004.08467v1,2020-04-17T22:00:23Z,2020-04-17T22:00:23Z,"Lidar for Autonomous Driving: The principles, challenges, and trends for
  automotive lidar and perception systems","Autonomous vehicles rely on their perception systems to acquire information
about their immediate surroundings. It is necessary to detect the presence of
other vehicles, pedestrians and other relevant entities. Safety concerns and
the need for accurate estimations have led to the introduction of Light
Detection and Ranging (LiDAR) systems in complement to the camera or
radar-based perception systems. This article presents a review of
state-of-the-art automotive LiDAR technologies and the perception algorithms
used with those technologies. LiDAR systems are introduced first by analyzing
the main components, from laser transmitter to its beam scanning mechanism.
Advantages/disadvantages and the current status of various solutions are
introduced and compared. Then, the specific perception pipeline for LiDAR data
processing, from an autonomous vehicle perspective is detailed. The
model-driven approaches and the emerging deep learning solutions are reviewed.
Finally, we provide an overview of the limitations, challenges and trends for
automotive LiDARs and perception systems.",arxiv
http://arxiv.org/abs/2006.11670v1,2020-06-20T22:51:48Z,2020-06-20T22:51:48Z,Affordable Modular Autonomous Vehicle Development Platform,"Road accidents are estimated to be the ninth leading cause of death across
all age groups globally. 1.25 million people die annually from road accidents
and Africa has the highest rate of road fatalities [1]. Research shows that
three out of five road accidents are caused by driver-related behavioral
factors [2]. Self-driving technology has the potential of saving lives lost to
these preventable road accidents. Africa accounts for the majority of road
fatalities and as such would benefit immensely from this technology. However,
financial constraints prevent viable experimentation and research into
self-driving technology in Africa. This paper describes the design of RollE, an
affordable modular autonomous vehicle development platform. It is capable of
driving via remote control for data collection and also capable of autonomous
driving using a convolutional neural network. This system is aimed at providing
students and researchers with an affordable autonomous vehicle to develop and
test self-driving car technology.",arxiv
http://arxiv.org/abs/1910.14002v1,2019-10-30T17:40:32Z,2019-10-30T17:40:32Z,"A Distributed Model-Free Algorithm for Multi-hop Ride-sharing using Deep
  Reinforcement Learning","The growth of autonomous vehicles, ridesharing systems, and self driving
technology will bring a shift in the way ride hailing platforms plan out their
services. However, these advances in technology coupled with road congestion,
environmental concerns, fuel usage, vehicles emissions, and the high cost of
the vehicle usage have brought more attention to better utilize the use of
vehicles and their capacities. In this paper, we propose a novel multi-hop
ride-sharing (MHRS) algorithm that uses deep reinforcement learning to learn
optimal vehicle dispatch and matching decisions by interacting with the
external environment. By allowing customers to transfer between vehicles, i.e.,
ride with one vehicle for sometime and then transfer to another one, MHRS helps
in attaining 30\% lower cost and 20\% more efficient utilization of fleets, as
compared to the ride-sharing algorithms. This flexibility of multi-hop feature
gives a seamless experience to customers and ride-sharing companies, and thus
improves ride-sharing services.",arxiv
http://arxiv.org/abs/1912.03408v1,2019-12-07T01:18:53Z,2019-12-07T01:18:53Z,"Increasing performance of electric vehicles in ride-hailing services
  using deep reinforcement learning","New forms of on-demand transportation such as ride-hailing and connected
autonomous vehicles are proliferating, yet are a challenging use case for
electric vehicles (EV). This paper explores the feasibility of using deep
reinforcement learning (DRL) to optimize a driving and charging policy for a
ride-hailing EV agent, with the goal of reducing costs and emissions while
increasing transportation service provided. We introduce a data-driven
simulation of a ride-hailing EV agent that provides transportation service and
charges energy at congested charging infrastructure. We then formulate a test
case for the sequential driving and charging decision making problem of the
agent and apply DRL to optimize the agent's decision making policy. We evaluate
the performance against hand-written policies and show that our agent learns to
act competitively without any prior knowledge.",arxiv
http://arxiv.org/abs/2001.01377v1,2020-01-06T03:05:52Z,2020-01-06T03:05:52Z,High-speed Autonomous Drifting with Deep Reinforcement Learning,"Drifting is a complicated task for autonomous vehicle control. Most
traditional methods in this area are based on motion equations derived by the
understanding of vehicle dynamics, which is difficult to be modeled precisely.
We propose a robust drift controller without explicit motion equations, which
is based on the latest model-free deep reinforcement learning algorithm soft
actor-critic. The drift control problem is formulated as a trajectory following
task, where the errorbased state and reward are designed. After being trained
on tracks with different levels of difficulty, our controller is capable of
making the vehicle drift through various sharp corners quickly and stably in
the unseen map. The proposed controller is further shown to have excellent
generalization ability, which can directly handle unseen vehicle types with
different physical properties, such as mass, tire friction, etc.",arxiv
http://arxiv.org/abs/2006.09792v1,2020-06-17T11:54:53Z,2020-06-17T11:54:53Z,"Deep Reinforcement Learning Controller for 3D Path-following and
  Collision Avoidance by Autonomous Underwater Vehicles","Control theory provides engineers with a multitude of tools to design
controllers that manipulate the closed-loop behavior and stability of dynamical
systems. These methods rely heavily on insights about the mathematical model
governing the physical system. However, in complex systems, such as autonomous
underwater vehicles performing the dual objective of path-following and
collision avoidance, decision making becomes non-trivial. We propose a solution
using state-of-the-art Deep Reinforcement Learning (DRL) techniques, to develop
autonomous agents capable of achieving this hybrid objective without having \`a
priori knowledge about the goal or the environment. Our results demonstrate the
viability of DRL in path-following and avoiding collisions toward achieving
human-level decision making in autonomous vehicle systems within extreme
obstacle configurations.",arxiv
http://arxiv.org/abs/2008.08812v2,2020-08-21T01:14:04Z,2020-08-20T07:32:45Z,"Expressing Diverse Human Driving Behavior with Probabilistic Rewards and
  Online Inference","In human-robot interaction (HRI) systems, such as autonomous vehicles,
understanding and representing human behavior are important. Human behavior is
naturally rich and diverse. Cost/reward learning, as an efficient way to learn
and represent human behavior, has been successfully applied in many domains.
Most of traditional inverse reinforcement learning (IRL) algorithms, however,
cannot adequately capture the diversity of human behavior since they assume
that all behavior in a given dataset is generated by a single cost function.In
this paper, we propose a probabilistic IRL framework that directly learns a
distribution of cost functions in continuous domain. Evaluations on both
synthetic data and real human driving data are conducted. Both the quantitative
and subjective results show that our proposed framework can better express
diverse human driving behaviors, as well as extracting different driving styles
that match what human participants interpret in our user study.",arxiv
http://arxiv.org/abs/2011.04950v1,2020-11-10T07:31:47Z,2020-11-10T07:31:47Z,"Model-based Reinforcement Learning from Signal Temporal Logic
  Specifications","Techniques based on Reinforcement Learning (RL) are increasingly being used
to design control policies for robotic systems. RL fundamentally relies on
state-based reward functions to encode desired behavior of the robot and bad
reward functions are prone to exploitation by the learning agent, leading to
behavior that is undesirable in the best case and critically dangerous in the
worst. On the other hand, designing good reward functions for complex tasks is
a challenging problem. In this paper, we propose expressing desired high-level
robot behavior using a formal specification language known as Signal Temporal
Logic (STL) as an alternative to reward/cost functions. We use STL
specifications in conjunction with model-based learning to design model
predictive controllers that try to optimize the satisfaction of the STL
specification over a finite time horizon. The proposed algorithm is empirically
evaluated on simulations of robotic system such as a pick-and-place robotic
arm, and adaptive cruise control for autonomous vehicles.",arxiv
http://arxiv.org/abs/2103.04909v1,2021-03-08T17:15:23Z,2021-03-08T17:15:23Z,"Model-based versus Model-free Deep Reinforcement Learning for Autonomous
  Racing Cars","Despite the rich theoretical foundation of model-based deep reinforcement
learning (RL) agents, their effectiveness in real-world robotics-applications
is less studied and understood. In this paper, we, therefore, investigate how
such agents generalize to real-world autonomous-vehicle control-tasks, where
advanced model-free deep RL algorithms fail. In particular, we set up a series
of time-lap tasks for an F1TENTH racing robot, equipped with high-dimensional
LiDAR sensors, on a set of test tracks with a gradual increase in their
complexity. In this continuous-control setting, we show that model-based agents
capable of learning in imagination, substantially outperform model-free agents
with respect to performance, sample efficiency, successful task completion, and
generalization. Moreover, we show that the generalization ability of
model-based agents strongly depends on the observation-model choice. Finally,
we provide extensive empirical evidence for the effectiveness of model-based
agents provided with long enough memory horizons in sim2real tasks.",arxiv
http://arxiv.org/abs/2104.00357v1,2021-04-01T09:23:54Z,2021-04-01T09:23:54Z,"Bounding the Inefficiency of Route Control in Intelligent Transport
  Systems","Route controlled autonomous vehicles could have a significant impact in
reducing congestion in the future. Before applying multi-agent reinforcement
learning algorithms to route control, we can model the system using a
congestion game to predict and mitigate potential issues. We consider the
problem of distributed operating systems in a transportation network that
control the routing choices of their assigned vehicles. We formulate an
associated network control game, consisting of multiple actors seeking to
optimise the social welfare of their assigned subpopulations in an underlying
nonatomic congestion game. Then we find the inefficiency of the routing
equilibria by calculating the Price of Anarchy for polynomial cost functions.
Finally, we extend the analysis to allow vehicles to choose their operating
system.",arxiv
http://arxiv.org/abs/2105.00153v1,2021-05-01T03:02:21Z,2021-05-01T03:02:21Z,"Pedestrian Collision Avoidance for Autonomous Vehicles at Unsignalized
  Intersection Using Deep Q-Network","Prior research has extensively explored Autonomous Vehicle (AV) navigation in
the presence of other vehicles, however, navigation among pedestrians, who are
the most vulnerable element in urban environments, has been less examined. This
paper explores AV navigation in crowded, unsignalized intersections. We compare
the performance of different deep reinforcement learning methods trained on our
reward function and state representation. The performance of these methods and
a standard rule-based approach were evaluated in two ways, first at the
unsignalized intersection on which the methods were trained, and secondly at an
unknown unsignalized intersection with a different topology. For both
scenarios, the rule-based method achieves less than 40\% collision-free
episodes, whereas our methods result in a performance of approximately 100\%.
Of the three methods used, DDQN/PER outperforms the other two methods while it
also shows the smallest average intersection crossing time, the greatest
average speed, and the greatest distance from the closest pedestrian.",arxiv
http://arxiv.org/abs/2106.12755v1,2021-06-24T03:41:00Z,2021-06-24T03:41:00Z,"Control of a Mixed Autonomy Signalised Urban Intersection: An
  Action-Delayed Reinforcement Learning Approach","We consider a mixed autonomy scenario where the traffic intersection
controller decides whether the traffic light will be green or red at each lane
for multiple traffic-light blocks. The objective of the traffic intersection
controller is to minimize the queue length at each lane and maximize the
outflow of vehicles over each block. We consider that the traffic intersection
controller informs the autonomous vehicle (AV) whether the traffic light will
be green or red for the future traffic-light block. Thus, the AV can adapt its
dynamics by solving an optimal control problem. We model the decision process
of the traffic intersection controller as a deterministic delay Markov decision
process owing to the delayed action by the traffic controller. We propose
Reinforcement-learning based algorithm to obtain the optimal policy. We show -
empirically - that our algorithm converges and reduces the energy costs of AVs
drastically as the traffic controller communicates with the AVs.",arxiv
http://arxiv.org/abs/2107.11762v1,2021-07-25T09:15:46Z,2021-07-25T09:15:46Z,"DR2L: Surfacing Corner Cases to Robustify Autonomous Driving via Domain
  Randomization Reinforcement Learning","How to explore corner cases as efficiently and thoroughly as possible has
long been one of the top concerns in the context of deep reinforcement learning
(DeepRL) autonomous driving. Training with simulated data is less costly and
dangerous than utilizing real-world data, but the inconsistency of parameter
distribution and the incorrect system modeling in simulators always lead to an
inevitable Sim2real gap, which probably accounts for the underperformance in
novel, anomalous and risky cases that simulators can hardly generate. Domain
Randomization(DR) is a methodology that can bridge this gap with little or no
real-world data. Consequently, in this research, an adversarial model is put
forward to robustify DeepRL-based autonomous vehicles trained in simulation to
gradually surfacing harder events, so that the models could readily transfer to
the real world.",arxiv
http://arxiv.org/abs/2109.03037v1,2021-09-05T04:45:37Z,2021-09-05T04:45:37Z,"A drl based distributed formation control scheme with stream based
  collision avoidance","Formation and collision avoidance abilities are essential for multi-agent
systems. Conventional methods usually require a central controller and global
information to achieve collaboration, which is impractical in an unknown
environment. In this paper, we propose a deep reinforcement learning (DRL)
based distributed formation control scheme for autonomous vehicles. A modified
stream-based obstacle avoidance method is applied to smoothen the optimal
trajectory, and onboard sensors such as Lidar and antenna arrays are used to
obtain local relative distance and angle information. The proposed scheme
obtains a scalable distributed control policy which jointly optimizes formation
tracking error and average collision rate with local observations. Simulation
results demonstrate that our method outperforms two other state-of-the-art
algorithms on maintaining formation and collision avoidance.",arxiv
http://arxiv.org/abs/1311.6981v1,2013-11-13T04:46:57Z,2013-11-13T04:46:57Z,"A customized flocking algorithm for swarms of sensors tracking a swarm
  of targets","Wireless mobile sensor networks (WMSNs) are groups of mobile sensing agents
with multi-modal sensing capabilities that communicate over wireless networks.
WMSNs have more flexibility in terms of deployment and exploration abilities
over static sensor networks. Sensor networks have a wide range of applications
in security and surveillance systems, environmental monitoring, data gathering
for network-centric healthcare systems, monitoring seismic activities and
atmospheric events, tracking traffic congestion and air pollution levels,
localization of autonomous vehicles in intelligent transportation systems, and
detecting failures of sensing, storage, and switching components of smart
grids. The above applications require target tracking for processes and events
of interest occurring in an environment. Various methods and approaches have
been proposed in order to track one or more targets in a pre-defined area.
Usually, this turns out to be a complicated job involving higher order
mathematics coupled with artificial intelligence due to the dynamic nature of
the targets. To optimize the resources we need to have an approach that works
in a more straightforward manner while resulting in fairly satisfactory data.
In this paper we have discussed the various cases that might arise while
flocking a group of sensors to track targets in a given environment. The
approach has been developed from scratch although some basic assumptions have
been made keeping in mind some previous theories. This paper outlines a
customized approach for feasibly tracking swarms of targets in a specific area
so as to minimize the resources and optimize tracking efficiency.",arxiv
http://arxiv.org/abs/1609.04285v2,2017-02-27T15:03:15Z,2016-09-14T14:17:25Z,Even Good Bots Fight: The Case of Wikipedia,"In recent years, there has been a huge increase in the number of bots online,
varying from Web crawlers for search engines, to chatbots for online customer
service, spambots on social media, and content-editing bots in online
collaboration communities. The online world has turned into an ecosystem of
bots. However, our knowledge of how these automated agents are interacting with
each other is rather poor. Bots are predictable automatons that do not have the
capacity for emotions, meaning-making, creativity, and sociality and it is
hence natural to expect interactions between bots to be relatively predictable
and uneventful. In this article, we analyze the interactions between bots that
edit articles on Wikipedia. We track the extent to which bots undid each
other's edits over the period 2001-2010, model how pairs of bots interact over
time, and identify different types of interaction trajectories. We find that,
although Wikipedia bots are intended to support the encyclopedia, they often
undo each other's edits and these sterile ""fights"" may sometimes continue for
years. Unlike humans on Wikipedia, bots' interactions tend to occur over longer
periods of time and to be more reciprocated. Yet, just like humans, bots in
different cultural environments may behave differently. Our research suggests
that even relatively ""dumb"" bots may give rise to complex interactions, and
this carries important implications for Artificial Intelligence research.
Understanding what affects bot-bot interactions is crucial for managing social
media well, providing adequate cyber-security, and designing well functioning
autonomous vehicles.",arxiv
http://arxiv.org/abs/1809.10732v2,2019-03-01T14:07:02Z,2018-09-18T04:07:13Z,"Multimodal Trajectory Predictions for Autonomous Driving using Deep
  Convolutional Networks","Autonomous driving presents one of the largest problems that the robotics and
artificial intelligence communities are facing at the moment, both in terms of
difficulty and potential societal impact. Self-driving vehicles (SDVs) are
expected to prevent road accidents and save millions of lives while improving
the livelihood and life quality of many more. However, despite large interest
and a number of industry players working in the autonomous domain, there still
remains more to be done in order to develop a system capable of operating at a
level comparable to best human drivers. One reason for this is high uncertainty
of traffic behavior and large number of situations that an SDV may encounter on
the roads, making it very difficult to create a fully generalizable system. To
ensure safe and efficient operations, an autonomous vehicle is required to
account for this uncertainty and to anticipate a multitude of possible
behaviors of traffic actors in its surrounding. We address this critical
problem and present a method to predict multiple possible trajectories of
actors while also estimating their probabilities. The method encodes each
actor's surrounding context into a raster image, used as input by deep
convolutional networks to automatically derive relevant features for the task.
Following extensive offline evaluation and comparison to state-of-the-art
baselines, the method was successfully tested on SDVs in closed-course tests.",arxiv
http://arxiv.org/abs/1905.00689v2,2019-10-30T13:31:09Z,2019-05-02T12:09:59Z,"Approximate LSTMs for Time-Constrained Inference: Enabling Fast Reaction
  in Self-Driving Cars","The need to recognise long-term dependencies in sequential data such as video
streams has made Long Short-Term Memory (LSTM) networks a prominent Artificial
Intelligence model for many emerging applications. However, the high
computational and memory demands of LSTMs introduce challenges in their
deployment on latency-critical systems such as self-driving cars which are
equipped with limited computational resources on-board. In this paper, we
introduce a progressive inference computing scheme that combines model pruning
and computation restructuring leading to the best possible approximation of the
result given the available latency budget of the target application. The
proposed methodology enables mission-critical systems to make informed
decisions even in early stages of the computation, based on approximate LSTM
inference, meeting their specifications on safety and robustness. Our
experiments on a state-of-the-art driving model for autonomous vehicle
navigation demonstrate that the proposed approach can yield outputs with
similar quality of result compared to a faithful LSTM baseline, up to 415x
faster (198x on average, 76x geo. mean).",arxiv
http://arxiv.org/abs/2007.13371v1,2020-07-27T08:42:07Z,2020-07-27T08:42:07Z,"Building Trust in Autonomous Vehicles: Role of Virtual Reality Driving
  Simulators in HMI Design","The investigation of factors contributing at making humans trust Autonomous
Vehicles (AVs) will play a fundamental role in the adoption of such technology.
The user's ability to form a mental model of the AV, which is crucial to
establish trust, depends on effective user-vehicle communication; thus, the
importance of Human-Machine Interaction (HMI) is poised to increase. In this
work, we propose a methodology to validate the user experience in AVs based on
continuous, objective information gathered from physiological signals, while
the user is immersed in a Virtual Reality-based driving simulation. We applied
this methodology to the design of a head-up display interface delivering visual
cues about the vehicle' sensory and planning systems. Through this approach, we
obtained qualitative and quantitative evidence that a complete picture of the
vehicle's surrounding, despite the higher cognitive load, is conducive to a
less stressful experience. Moreover, after having been exposed to a more
informative interface, users involved in the study were also more willing to
test a real AV. The proposed methodology could be extended by adjusting the
simulation environment, the HMI and/or the vehicle's Artificial Intelligence
modules to dig into other aspects of the user experience.",arxiv
http://arxiv.org/abs/2104.04572v3,2021-10-05T20:01:47Z,2021-04-09T19:08:34Z,"Smart and Secure CAV Networks Empowered by AI-Enabled Blockchain: Next
  Frontier for Intelligent Safe-Driving Assessment","Securing safe-driving for connected and autonomous vehicles (CAVs) continues
to be a widespread concern despite various sophisticated functions delivered by
artificial intelligence for in-vehicle devices. Besides, diverse malicious
network attacks become ubiquitous along with the worldwide implementation of
the Internet of Vehicles, which exposes a range of reliability and privacy
threats for managing data in CAV networks. Combined with the fact that the
capability of existing CAVs in handling intensive computation tasks is limited,
this implies a need for designing an efficient assessment system to guarantee
autonomous driving safety without compromising data security. Motivated by
this, in this article, we propose a novel framework, namely Blockchain-enabled
intElligent Safe-driving assessmenT (BEST), that offers a smart and reliable
approach for conducting safe driving supervision while protecting vehicular
information. Specifically, a promising solution that exploits a long short-term
memory model is introduced to assess the safety level of the moving CAVs. Then,
we investigate how a distributed blockchain obtains adequate trustworthiness
and robustness for CAV data by adopting a byzantine fault tolerance-based
delegated proof-of-stake consensus mechanism. Simulation results demonstrate
that our presented BEST gains better data credibility with a higher prediction
accuracy for vehicular safety assessment when compared with existing schemes.
Finally, we discuss several open challenges that need to be addressed in future
CAV networks.",arxiv
http://arxiv.org/abs/2107.02959v1,2021-07-07T00:44:12Z,2021-07-07T00:44:12Z,Towards Achieving Trust Through Transparency and Ethics (Pre-Print),"The ubiquitous presence of software in the products we use, together with
Artificial Intelligence in these products, has led to an increasing need for
consumer trust. Consumers often lose faith in products, and the lack of Trust
propagates to the companies behind them. This is even more so in
mission-critical systems such as autonomous vehicles and clinical support
systems. This paper follows grounded theory principles to elicit knowledge
related to Trust, Ethics, and Transparency. We approach these qualities as
Non-Functional Requirements (NFRs), aiming to build catalogs to subsidize the
construction of Socially Responsible Software. The corpus we have used was
built on a selected collection of literature on Corporate Social
Responsibility, with an emphasis on Business Ethics. Our challenge is how to
encode the social perspective knowledge, mainly through the view of Corporate
Social Responsibility, on how organizations or institutions achieve
trustworthiness. Since our ground perspective is that of NFRs, results are
presented by a catalogue of Trust as a Non-Functional Requirement, represented
as a Softgoal Interdependency Graph (SIG). The SIG language helps software
engineers in understanding alternatives they have to improve Trust in software
products.",arxiv
http://arxiv.org/abs/1504.03494v1,2015-04-14T11:19:50Z,2015-04-14T11:19:50Z,"Distributed Nonlinear MPC of Multi-Agent Systems with Data Compression
  and Random Delays - Extended Version","This is an extended version of a technical note accepted for publication in
IEEE Transactions on Automatic Control. The note proposes an Input to State
practically Stable (ISpS) formulation of distributed nonlinear model predictive
controller (NMPC) for formation control of constrained autonomous vehicles in
presence of communication bandwidth limitation and transmission delays. Planned
trajectories are compressed using neural networks resulting in considerable
reduction of data packet size, while being robust to propagation delays and
uncertainty in neighbors' trajectories. Collision avoidance is achieved by
means of spatially filtered potential field. Analytical results proving ISpS
and generalized small gain conditions are presented for both strongly- and
weakly-connected networks, and illustrated by simulations.",arxiv
http://arxiv.org/abs/1708.03309v2,2017-08-11T17:34:23Z,2017-08-10T17:33:52Z,"Systematic Testing of Convolutional Neural Networks for Autonomous
  Driving","We present a framework to systematically analyze convolutional neural
networks (CNNs) used in classification of cars in autonomous vehicles. Our
analysis procedure comprises an image generator that produces synthetic
pictures by sampling in a lower dimension image modification subspace and a
suite of visualization tools. The image generator produces images which can be
used to test the CNN and hence expose its vulnerabilities. The presented
framework can be used to extract insights of the CNN classifier, compare across
classification models, or generate training and validation datasets.",arxiv
http://arxiv.org/abs/1901.10951v2,2019-05-17T09:45:42Z,2019-01-30T17:01:01Z,Distant Vehicle Detection Using Radar and Vision,"For autonomous vehicles to be able to operate successfully they need to be
aware of other vehicles with sufficient time to make safe, stable plans. Given
the possible closing speeds between two vehicles, this necessitates the ability
to accurately detect distant vehicles. Many current image-based object
detectors using convolutional neural networks exhibit excellent performance on
existing datasets such as KITTI. However, the performance of these networks
falls when detecting small (distant) objects. We demonstrate that incorporating
radar data can boost performance in these difficult situations. We also
introduce an efficient automated method for training data generation using
cameras of different focal lengths.",arxiv
http://arxiv.org/abs/1910.14479v1,2019-10-31T14:15:11Z,2019-10-31T14:15:11Z,In-Place Zero-Space Memory Protection for CNN,"Convolutional Neural Networks (CNN) are being actively explored for
safety-critical applications such as autonomous vehicles and aerospace, where
it is essential to ensure the reliability of inference results in the presence
of possible memory faults. Traditional methods such as error correction codes
(ECC) and Triple Modular Redundancy (TMR) are CNN-oblivious and incur
substantial memory overhead and energy cost. This paper introduces in-place
zero-space ECC assisted with a new training scheme weight distribution-oriented
training. The new method provides the first known zero space cost memory
protection for CNNs without compromising the reliability offered by traditional
ECC.",arxiv
http://arxiv.org/abs/1911.07347v1,2019-11-17T21:40:05Z,2019-11-17T21:40:05Z,Fast 3D Pose Refinement with RGB Images,"Pose estimation is a vital step in many robotics and perception tasks such as
robotic manipulation, autonomous vehicle navigation, etc. Current
state-of-the-art pose estimation methods rely on deep neural networks with
complicated structures and long inference times. While highly robust, they
require computing power often unavailable on mobile robots. We propose a
CNN-based pose refinement system which takes a coarsely estimated 3D pose from
a computationally cheaper algorithm along with a bounding box image of the
object, and returns a highly refined pose. Our experiments on the YCB-Video
dataset show that our system can refine 3D poses to an extremely high precision
with minimal training data.",arxiv
http://arxiv.org/abs/2007.07482v1,2020-07-15T05:01:27Z,2020-07-15T05:01:27Z,Decoding CNN based Object Classifier Using Visualization,"This paper investigates how working of Convolutional Neural Network (CNN) can
be explained through visualization in the context of machine perception of
autonomous vehicles. We visualize what type of features are extracted in
different convolution layers of CNN that helps to understand how CNN gradually
increases spatial information in every layer. Thus, it concentrates on region
of interests in every transformation. Visualizing heat map of activation helps
us to understand how CNN classifies and localizes different objects in image.
This study also helps us to reason behind low accuracy of a model helps to
increase trust on object detection module.",arxiv
http://arxiv.org/abs/2007.12668v2,2020-08-21T10:43:18Z,2020-07-24T17:35:14Z,KPRNet: Improving projection-based LiDAR semantic segmentation,"Semantic segmentation is an important component in the perception systems of
autonomous vehicles. In this work, we adopt recent advances in both image and
point cloud segmentation to achieve a better accuracy in the task of segmenting
LiDAR scans. KPRNet improves the convolutional neural network architecture of
2D projection methods and utilizes KPConv to replace the commonly used
post-processing techniques with a learnable point-wise component which allows
us to obtain more accurate 3D labels. With these improvements our model
outperforms the current best method on the SemanticKITTI benchmark, reaching an
mIoU of 63.1.",arxiv
http://arxiv.org/abs/2109.07110v2,2021-10-22T12:58:12Z,2021-09-15T06:46:23Z,"Image Deraining and Denoising Convolutional Neural Network ForAutonomous
  Driving","Perception plays an important role in reliable decision-making for autonomous
vehicles. Over the last ten years, huge advances have been made in the field of
perception. However, perception in extreme weather conditions is still a
difficult problem, especially in rainy weather conditions. In order to improve
the detection effect of road targets in rainy environments, we analyze the
physical characteristics of the rain layer and propose a deraining
convolutional neural network structure. Based on this network structure, we
design an ablation experiment and experiment results show that our method can
effectively improve the accuracy of object detection in rainy conditions.",arxiv
http://arxiv.org/abs/2105.10688v1,2021-05-22T11:00:09Z,2021-05-22T11:00:09Z,"V2V Spatiotemporal Interactive Pattern Recognition and Risk Analysis in
  Lane Changes","In complex lane change (LC) scenarios, semantic interpretation and safety
analysis of dynamic interactive pattern are necessary for autonomous vehicles
to make appropriate decisions. This study proposes an unsupervised learning
framework that combines primitive-based interactive pattern recognition methods
and risk analysis methods. The Hidden Markov Model with the Gaussian mixture
model (GMM-HMM) approach is developed to decompose the LC scenarios into
primitives. Then the Dynamic Time Warping (DTW) distance based K-means
clustering is applied to gather the primitives to 13 types of interactive
patterns. Finally, this study considers two types of time-to-collision (TTC)
involved in the LC process as indicators to analyze the risk of the interactive
patterns and extract high-risk LC interactive patterns. The results obtained
from The Highway Drone Dataset (highD) demonstrate that the identified LC
interactive patterns contain interpretable semantic information. This study
explores the spatiotemporal evolution law and risk formation mechanism of the
LC interactive patterns and the findings are useful for comprehensively
understanding the latent interactive patterns, improving the rationality and
safety of autonomous vehicle's decision-making.",arxiv
http://arxiv.org/abs/1905.08314v2,2019-07-05T14:29:09Z,2019-05-07T18:39:29Z,"Longitudinal Dynamic versus Kinematic Models for Car-Following Control
  Using Deep Reinforcement Learning","The majority of current studies on autonomous vehicle control via deep
reinforcement learning (DRL) utilize point-mass kinematic models, neglecting
vehicle dynamics which includes acceleration delay and acceleration command
dynamics. The acceleration delay, which results from sensing and actuation
delays, results in delayed execution of the control inputs. The acceleration
command dynamics dictates that the actual vehicle acceleration does not rise up
to the desired command acceleration instantaneously due to dynamics. In this
work, we investigate the feasibility of applying DRL controllers trained using
vehicle kinematic models to more realistic driving control with vehicle
dynamics. We consider a particular longitudinal car-following control, i.e.,
Adaptive Cruise Control (ACC), problem solved via DRL using a point-mass
kinematic model. When such a controller is applied to car following with
vehicle dynamics, we observe significantly degraded car-following performance.
Therefore, we redesign the DRL framework to accommodate the acceleration delay
and acceleration command dynamics by adding the delayed control inputs and the
actual vehicle acceleration to the reinforcement learning environment state,
respectively. The training results show that the redesigned DRL controller
results in near-optimal control performance of car following with vehicle
dynamics considered when compared with dynamic programming solutions.",arxiv
http://arxiv.org/abs/1910.04803v1,2019-10-10T18:33:42Z,2019-10-10T18:33:42Z,"Autonomous Driving using Safe Reinforcement Learning by Incorporating a
  Regret-based Human Lane-Changing Decision Model","It is expected that many human drivers will still prefer to drive themselves
even if the self-driving technologies are ready. Therefore, human-driven
vehicles and autonomous vehicles (AVs) will coexist in a mixed traffic for a
long time. To enable AVs to safely and efficiently maneuver in this mixed
traffic, it is critical that the AVs can understand how humans cope with risks
and make driving-related decisions. On the other hand, the driving environment
is highly dynamic and ever-changing, and it is thus difficult to enumerate all
the scenarios and hard-code the controllers. To face up these challenges, in
this work, we incorporate a human decision-making model in reinforcement
learning to control AVs for safe and efficient operations. Specifically, we
adapt regret theory to describe a human driver's lane-changing behavior, and
fit the personalized models to individual drivers for predicting their
lane-changing decisions. The predicted decisions are incorporated in the safety
constraints for reinforcement learning in training and in implementation. We
then use an extended version of double deep Q-network (DDQN) to train our AV
controller within the safety set. By doing so, the amount of collisions in
training is reduced to zero, while the training accuracy is not impinged.",arxiv
http://arxiv.org/abs/2006.13704v1,2020-06-22T01:41:13Z,2020-06-22T01:41:13Z,"Efficient Sampling-Based Maximum Entropy Inverse Reinforcement Learning
  with Application to Autonomous Driving","In the past decades, we have witnessed significant progress in the domain of
autonomous driving. Advanced techniques based on optimization and reinforcement
learning (RL) become increasingly powerful at solving the forward problem:
given designed reward/cost functions, how should we optimize them and obtain
driving policies that interact with the environment safely and efficiently.
Such progress has raised another equally important question: \emph{what should
we optimize}? Instead of manually specifying the reward functions, it is
desired that we can extract what human drivers try to optimize from real
traffic data and assign that to autonomous vehicles to enable more naturalistic
and transparent interaction between humans and intelligent agents. To address
this issue, we present an efficient sampling-based maximum-entropy inverse
reinforcement learning (IRL) algorithm in this paper. Different from existing
IRL algorithms, by introducing an efficient continuous-domain trajectory
sampler, the proposed algorithm can directly learn the reward functions in the
continuous domain while considering the uncertainties in demonstrated
trajectories from human drivers. We evaluate the proposed algorithm on real
driving data, including both non-interactive and interactive scenarios. The
experimental results show that the proposed algorithm achieves more accurate
prediction performance with faster convergence speed and better generalization
compared to other baseline IRL algorithms.",arxiv
http://arxiv.org/abs/2101.05970v1,2021-01-15T05:21:25Z,2021-01-15T05:21:25Z,Affordance-based Reinforcement Learning for Urban Driving,"Traditional autonomous vehicle pipelines that follow a modular approach have
been very successful in the past both in academia and industry, which has led
to autonomy deployed on road. Though this approach provides ease of
interpretation, its generalizability to unseen environments is limited and
hand-engineering of numerous parameters is required, especially in the
prediction and planning systems. Recently, deep reinforcement learning has been
shown to learn complex strategic games and perform challenging robotic tasks,
which provides an appealing framework for learning to drive. In this work, we
propose a deep reinforcement learning framework to learn optimal control policy
using waypoints and low-dimensional visual representations, also known as
affordances. We demonstrate that our agents when trained from scratch learn the
tasks of lane-following, driving around inter-sections as well as stopping in
front of other actors or traffic lights even in the dense traffic setting. We
note that our method achieves comparable or better performance than the
baseline methods on the original and NoCrash benchmarks on the CARLA simulator.",arxiv
http://arxiv.org/abs/2101.06778v2,2021-06-09T17:53:03Z,2021-01-17T20:45:42Z,"A Safe Hierarchical Planning Framework for Complex Driving Scenarios
  based on Reinforcement Learning","Autonomous vehicles need to handle various traffic conditions and make safe
and efficient decisions and maneuvers. However, on the one hand, a single
optimization/sampling-based motion planner cannot efficiently generate safe
trajectories in real time, particularly when there are many interactive
vehicles near by. On the other hand, end-to-end learning methods cannot assure
the safety of the outcomes. To address this challenge, we propose a
hierarchical behavior planning framework with a set of low-level safe
controllers and a high-level reinforcement learning algorithm (H-CtRL) as a
coordinator for the low-level controllers. Safety is guaranteed by the
low-level optimization/sampling-based controllers, while the high-level
reinforcement learning algorithm makes H-CtRL an adaptive and efficient
behavior planner. To train and test our proposed algorithm, we built a
simulator that can reproduce traffic scenes using real-world datasets. The
proposed H-CtRL is proved to be effective in various realistic simulation
scenarios, with satisfying performance in terms of both safety and efficiency.",arxiv
http://arxiv.org/abs/2101.10369v2,2021-04-01T17:30:45Z,2021-01-02T10:43:41Z,"Effective Communications: A Joint Learning and Communication Framework
  for Multi-Agent Reinforcement Learning over Noisy Channels","We propose a novel formulation of the ""effectiveness problem"" in
communications, put forth by Shannon and Weaver in their seminal work [2], by
considering multiple agents communicating over a noisy channel in order to
achieve better coordination and cooperation in a multi-agent reinforcement
learning (MARL) framework. Specifically, we consider a multi-agent partially
observable Markov decision process (MA-POMDP), in which the agents, in addition
to interacting with the environment can also communicate with each other over a
noisy communication channel. The noisy communication channel is considered
explicitly as part of the dynamics of the environment and the message each
agent sends is part of the action that the agent can take. As a result, the
agents learn not only to collaborate with each other but also to communicate
""effectively"" over a noisy channel. This framework generalizes both the
traditional communication problem, where the main goal is to convey a message
reliably over a noisy channel, and the ""learning to communicate"" framework that
has received recent attention in the MARL literature, where the underlying
communication channels are assumed to be error-free. We show via examples that
the joint policy learned using the proposed framework is superior to that where
the communication is considered separately from the underlying MA-POMDP. This
is a very powerful framework, which has many real world applications, from
autonomous vehicle planning to drone swarm control, and opens up the rich
toolbox of deep reinforcement learning for the design of multi-user
communication systems.",arxiv
http://arxiv.org/abs/2106.06369v1,2021-06-11T13:16:48Z,2021-06-11T13:16:48Z,"Courteous Behavior of Automated Vehicles at Unsignalized Intersections
  via Reinforcement Learning","The transition from today's mostly human-driven traffic to a purely automated
one will be a gradual evolution, with the effect that we will likely experience
mixed traffic in the near future. Connected and automated vehicles can benefit
human-driven ones and the whole traffic system in different ways, for example
by improving collision avoidance and reducing traffic waves. Many studies have
been carried out to improve intersection management, a significant bottleneck
in traffic, with intelligent traffic signals or exclusively automated vehicles.
However, the problem of how to improve mixed traffic at unsignalized
intersections has received less attention. In this paper, we propose a novel
approach to optimizing traffic flow at intersections in mixed traffic
situations using deep reinforcement learning. Our reinforcement learning agent
learns a policy for a centralized controller to let connected autonomous
vehicles at unsignalized intersections give up their right of way and yield to
other vehicles to optimize traffic flow. We implemented our approach and tested
it in the traffic simulator SUMO based on simulated and real traffic data. The
experimental evaluation demonstrates that our method significantly improves
traffic flow through unsignalized intersections in mixed traffic settings and
also provides better performance on a wide range of traffic situations compared
to the state-of-the-art traffic signal controller for the corresponding
signalized intersection.",arxiv
http://arxiv.org/abs/1804.03973v1,2018-04-11T13:28:07Z,2018-04-11T13:28:07Z,"Reasoning about Safety of Learning-Enabled Components in Autonomous
  Cyber-physical Systems","We present a simulation-based approach for generating barrier certificate
functions for safety verification of cyber-physical systems (CPS) that contain
neural network-based controllers. A linear programming solver is utilized to
find a candidate generator function from a set of simulation traces obtained by
randomly selecting initial states for the CPS model. A level set of the
generator function is then selected to act as a barrier certificate for the
system, meaning it demonstrates that no unsafe system states are reachable from
a given set of initial states. The barrier certificate properties are verified
with an SMT solver. This approach is demonstrated on a case study in which a
Dubins car model of an autonomous vehicle is controlled by a neural network to
follow a given path.",arxiv
http://arxiv.org/abs/1804.05164v1,2018-04-14T04:27:47Z,2018-04-14T04:27:47Z,Road Segmentation Using CNN with GRU,"This paper presents an accurate and fast algorithm for road segmentation
using convolutional neural network (CNN) and gated recurrent units (GRU). For
autonomous vehicles, road segmentation is a fundamental task that can provide
the drivable area for path planning. The existing deep neural network based
segmentation algorithms usually take a very deep encoder-decoder structure to
fuse pixels, which requires heavy computations, large memory and long
processing time. Hereby, a CNN-GRU network model is proposed and trained to
perform road segmentation using data captured by the front camera of a vehicle.
GRU network obtains a long spatial sequence with lower computational
complexity, comparing to traditional encoder-decoder architecture. The proposed
road detector is evaluated on the KITTI road benchmark and achieves high
accuracy for road segmentation at real-time processing speed.",arxiv
http://arxiv.org/abs/1805.04549v1,2018-05-11T18:37:48Z,2018-05-11T18:37:48Z,Networked Model Predictive Control Using a Wavelet Neural Network,"In this study, we use a wavelet neural network with a feedforward component
and a model predictive controller for online nonlinear system identification
over a communication network. The wavelet neural network (WNN) performs the
online identification of the nonlinear system. The model predictive controller
(MPC) uses the model to predict the future outputs of the system over an
extended prediction horizon and calculates the optimal future inputs by
minimizing a controller cost function. The Lyapunov theory is used to prove the
stability of the MPC. We apply the methodology to the online identification and
control of an unmanned autonomous vehicle. Simulation results show that the MPC
with extended prediction horizon can effectively control the system in the
presence of fixed or random network delay.",arxiv
http://arxiv.org/abs/1905.05162v1,2019-05-13T17:45:02Z,2019-05-13T17:45:02Z,"Locally Weighted Regression Pseudo-Rehearsal for Online Learning of
  Vehicle Dynamics","We consider the problem of online adaptation of a neural network designed to
represent vehicle dynamics. The neural network model is intended to be used by
an MPC control law to autonomously control the vehicle. This problem is
challenging because both the input and target distributions are non-stationary,
and naive approaches to online adaptation result in catastrophic forgetting,
which can in turn lead to controller failures. We present a novel online
learning method, which combines the pseudo-rehearsal method with locally
weighted projection regression. We demonstrate the effectiveness of the
resulting Locally Weighted Projection Regression Pseudo-Rehearsal (LW-PR$^2$)
method in simulation and on a large real world dataset collected with a 1/5
scale autonomous vehicle.",arxiv
http://arxiv.org/abs/1907.01294v2,2019-07-17T18:52:21Z,2019-07-02T10:54:06Z,Lane Detection and Classification using Cascaded CNNs,"Lane detection is extremely important for autonomous vehicles. For this
reason, many approaches use lane boundary information to locate the vehicle
inside the street, or to integrate GPS-based localization. As many other
computer vision based tasks, convolutional neural networks (CNNs) represent the
state-of-the-art technology to indentify lane boundaries. However, the position
of the lane boundaries w.r.t. the vehicle may not suffice for a reliable
positioning, as for path planning or localization information regarding lane
types may also be needed. In this work, we present an end-to-end system for
lane boundary identification, clustering and classification, based on two
cascaded neural networks, that runs in real-time. To build the system, 14336
lane boundaries instances of the TuSimple dataset for lane detection have been
labelled using 8 different classes. Our dataset and the code for inference are
available online.",arxiv
http://arxiv.org/abs/2002.11226v1,2020-02-26T00:05:19Z,2020-02-26T00:05:19Z,"Deep Learning and Statistical Models for Time-Critical Pedestrian
  Behaviour Prediction","The time it takes for a classifier to make an accurate prediction can be
crucial in many behaviour recognition problems. For example, an autonomous
vehicle should detect hazardous pedestrian behaviour early enough for it to
take appropriate measures. In this context, we compare the switching linear
dynamical system (SLDS) and a three-layered bi-directional long short-term
memory (LSTM) neural network, which are applied to infer pedestrian behaviour
from motion tracks. We show that, though the neural network model achieves an
accuracy of 80%, it requires long sequences to achieve this (100 samples or
more). The SLDS, has a lower accuracy of 74%, but it achieves this result with
short sequences (10 samples). To our knowledge, such a comparison on sequence
length has not been considered in the literature before. The results provide a
key intuition of the suitability of the models in time-critical problems.",arxiv
http://arxiv.org/abs/2108.05118v1,2021-08-11T09:41:54Z,2021-08-11T09:41:54Z,"Capture Uncertainties in Deep Neural Networks for Safe Operation of
  Autonomous Driving Vehicles","Uncertainties in Deep Neural Network (DNN)-based perception and vehicle's
motion pose challenges to the development of safe autonomous driving vehicles.
In this paper, we propose a safe motion planning framework featuring the
quantification and propagation of DNN-based perception uncertainties and motion
uncertainties. Contributions of this work are twofold: (1) A Bayesian Deep
Neural network model which detects 3D objects and quantitatively captures the
associated aleatoric and epistemic uncertainties of DNNs; (2) An
uncertainty-aware motion planning algorithm (PU-RRT) that accounts for
uncertainties in object detection and ego-vehicle's motion. The proposed
approaches are validated via simulated complex scenarios built in CARLA.
Experimental results show that the proposed motion planning scheme can cope
with uncertainties of DNN-based perception and vehicle motion, and improve the
operational safety of autonomous vehicles while still achieving desirable
efficiency.",arxiv
http://arxiv.org/abs/1912.03426v3,2020-11-18T04:14:23Z,2019-12-07T03:44:28Z,Self-Supervised 3D Keypoint Learning for Ego-motion Estimation,"Detecting and matching robust viewpoint-invariant keypoints is critical for
visual SLAM and Structure-from-Motion. State-of-the-art learning-based methods
generate training samples via homography adaptation to create 2D synthetic
views with known keypoint matches from a single image. This approach, however,
does not generalize to non-planar 3D scenes with illumination variations
commonly seen in real-world videos. In this work, we propose self-supervised
learning of depth-aware keypoints directly from unlabeled videos. We jointly
learn keypoint and depth estimation networks by combining appearance and
geometric matching via a differentiable structure-from-motion module based on
Procrustean residual pose correction. We describe how our self-supervised
keypoints can be integrated into state-of-the-art visual odometry frameworks
for robust and accurate ego-motion estimation of autonomous vehicles in
real-world conditions.",arxiv
http://arxiv.org/abs/2103.12496v1,2021-03-23T12:45:00Z,2021-03-23T12:45:00Z,Revisiting Self-Supervised Monocular Depth Estimation,"Self-supervised learning of depth map prediction and motion estimation from
monocular video sequences is of vital importance -- since it realizes a broad
range of tasks in robotics and autonomous vehicles. A large number of research
efforts have enhanced the performance by tackling illumination variation,
occlusions, and dynamic objects, to name a few. However, each of those efforts
targets individual goals and endures as separate works. Moreover, most of
previous works have adopted the same CNN architecture, not reaping
architectural benefits. Therefore, the need to investigate the inter-dependency
of the previous methods and the effect of architectural factors remains. To
achieve these objectives, we revisit numerous previously proposed
self-supervised methods for joint learning of depth and motion, perform a
comprehensive empirical study, and unveil multiple crucial insights.
Furthermore, we remarkably enhance the performance as a result of our study --
outperforming previous state-of-the-art performance.",arxiv
http://arxiv.org/abs/1903.11027v5,2020-05-05T09:13:24Z,2019-03-26T17:19:56Z,nuScenes: A multimodal dataset for autonomous driving,"Robust detection and tracking of objects is crucial for the deployment of
autonomous vehicle technology. Image based benchmark datasets have driven
development in computer vision tasks such as object detection, tracking and
segmentation of agents in the environment. Most autonomous vehicles, however,
carry a combination of cameras and range sensors such as lidar and radar. As
machine learning based methods for detection and tracking become more
prevalent, there is a need to train and evaluate such methods on datasets
containing range sensor data along with images. In this work we present
nuTonomy scenes (nuScenes), the first dataset to carry the full autonomous
vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree
field of view. nuScenes comprises 1000 scenes, each 20s long and fully
annotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as
many annotations and 100x as many images as the pioneering KITTI dataset. We
define novel 3D detection and tracking metrics. We also provide careful dataset
analysis as well as baselines for lidar and image based detection and tracking.
Data, development kit and more information are available online.",arxiv
http://arxiv.org/abs/1911.02620v1,2019-11-06T20:27:27Z,2019-11-06T20:27:27Z,Argoverse: 3D Tracking and Forecasting with Rich Maps,"We present Argoverse -- two datasets designed to support autonomous vehicle
machine learning tasks such as 3D tracking and motion forecasting. Argoverse
was collected by a fleet of autonomous vehicles in Pittsburgh and Miami. The
Argoverse 3D Tracking dataset includes 360 degree images from 7 cameras with
overlapping fields of view, 3D point clouds from long range LiDAR, 6-DOF pose,
and 3D track annotations. Notably, it is the only modern AV dataset that
provides forward-facing stereo imagery. The Argoverse Motion Forecasting
dataset includes more than 300,000 5-second tracked scenarios with a particular
vehicle identified for trajectory forecasting. Argoverse is the first
autonomous vehicle dataset to include ""HD maps"" with 290 km of mapped lanes
with geometric and semantic metadata. All data is released under a Creative
Commons license at www.argoverse.org. In our baseline experiments, we
illustrate how detailed map information such as lane direction, driveable area,
and ground height improves the accuracy of 3D object tracking and motion
forecasting. Our tracking and forecasting experiments represent only an initial
exploration of the use of rich maps in robotic perception. We hope that
Argoverse will enable the research community to explore these problems in
greater depth.",arxiv
http://arxiv.org/abs/2110.06164v1,2021-10-12T16:58:33Z,2021-10-12T16:58:33Z,"M2GAN: A Multi-Stage Self-Attention Network for Image Rain Removal on
  Autonomous Vehicles","Image deraining is a new challenging problem in applications of autonomous
vehicles. In a bad weather condition of heavy rainfall, raindrops, mainly
hitting the vehicle's windshield, can significantly reduce observation ability
even though the windshield wipers might be able to remove part of it. Moreover,
rain flows spreading over the windshield can yield the physical effect of
refraction, which seriously impede the sightline or undermine the machine
learning system equipped in the vehicle. In this paper, we propose a new
multi-stage multi-task recurrent generative adversarial network (M2GAN) to deal
with challenging problems of raindrops hitting the car's windshield. This
method is also applicable for removing raindrops appearing on a glass window or
lens. M2GAN is a multi-stage multi-task generative adversarial network that can
utilize prior high-level information, such as semantic segmentation, to boost
deraining performance. To demonstrate M2GAN, we introduce the first real-world
dataset for rain removal on autonomous vehicles. The experimental results show
that our proposed method is superior to other state-of-the-art approaches of
deraining raindrops in respect of quantitative metrics and visual quality.
M2GAN is considered the first method to deal with challenging problems of
real-world rains under unconstrained environments such as autonomous vehicles.",arxiv
http://arxiv.org/abs/2105.12822v1,2021-05-26T20:33:51Z,2021-05-26T20:33:51Z,Issues in Object Detection in Videos using Common Single-Image CNNs,"A growing branch of computer vision is object detection. Object detection is
used in many applications such as industrial process, medical imaging analysis,
and autonomous vehicles. The ability to detect objects in videos is crucial.
Object detection systems are trained on large image datasets. For applications
such as autonomous vehicles, it is crucial that the object detection system can
identify objects through multiple frames in video. There are many problems with
applying these systems to video. Shadows or changes in brightness that can
cause the system to incorrectly identify objects frame to frame and cause an
unintended system response. There are many neural networks that have been used
for object detection and if there was a way of connecting objects between
frames then these problems could be eliminated. For these neural networks to
get better at identifying objects in video, they need to be re-trained. A
dataset must be created with images that represent consecutive video frames and
have matching ground-truth layers. A method is proposed that can generate these
datasets. The ground-truth layer contains only moving objects. To generate this
layer, FlowNet2-Pytorch was used to create the flow mask using the novel
Magnitude Method. As well, a segmentation mask will be generated using networks
such as Mask R-CNN or Refinenet. These segmentation masks will contain all
objects detected in a frame. By comparing this segmentation mask to the flow
mask ground-truth layer, a loss function is generated. This loss function can
be used to train a neural network to be better at making consistent predictions
on video. The system was tested on multiple video samples and a loss was
generated for each frame, proving the Magnitude Method's ability to be used to
train object detection neural networks in future work.",arxiv
http://arxiv.org/abs/1909.06710v2,2020-11-16T16:50:59Z,2019-09-15T01:59:10Z,Driving in Dense Traffic with Model-Free Reinforcement Learning,"Traditional planning and control methods could fail to find a feasible
trajectory for an autonomous vehicle to execute amongst dense traffic on roads.
This is because the obstacle-free volume in spacetime is very small in these
scenarios for the vehicle to drive through. However, that does not mean the
task is infeasible since human drivers are known to be able to drive amongst
dense traffic by leveraging the cooperativeness of other drivers to open a gap.
The traditional methods fail to take into account the fact that the actions
taken by an agent affect the behaviour of other vehicles on the road. In this
work, we rely on the ability of deep reinforcement learning to implicitly model
such interactions and learn a continuous control policy over the action space
of an autonomous vehicle. The application we consider requires our agent to
negotiate and open a gap in the road in order to successfully merge or change
lanes. Our policy learns to repeatedly probe into the target road lane while
trying to find a safe spot to move in to. We compare against two
model-predictive control-based algorithms and show that our policy outperforms
them in simulation.",arxiv
http://arxiv.org/abs/1911.11699v2,2020-02-10T21:06:43Z,2019-11-26T17:08:40Z,"Multi-Vehicle Mixed-Reality Reinforcement Learning for Autonomous
  Multi-Lane Driving","Autonomous driving promises to transform road transport. Multi-vehicle and
multi-lane scenarios, however, present unique challenges due to constrained
navigation and unpredictable vehicle interactions. Learning-based
methods---such as deep reinforcement learning---are emerging as a promising
approach to automatically design intelligent driving policies that can cope
with these challenges. Yet, the process of safely learning multi-vehicle
driving behaviours is hard: while collisions---and their near-avoidance---are
essential to the learning process, directly executing immature policies on
autonomous vehicles raises considerable safety concerns. In this article, we
present a safe and efficient framework that enables the learning of driving
policies for autonomous vehicles operating in a shared workspace, where the
absence of collisions cannot be guaranteed. Key to our learning procedure is a
sim2real approach that uses real-world online policy adaptation in a
mixed-reality setup, where other vehicles and static obstacles exist in the
virtual domain. This allows us to perform safe learning by simulating (and
learning from) collisions between the learning agent(s) and other objects in
virtual reality. Our results demonstrate that, after only a few runs in
mixed-reality, collisions are significantly reduced.",arxiv
http://arxiv.org/abs/2003.11071v1,2020-03-24T18:59:17Z,2020-03-24T18:59:17Z,"Driver Modeling through Deep Reinforcement Learning and Behavioral Game
  Theory","In this paper, a synergistic combination of deep reinforcement learning and
hierarchical game theory is proposed as a modeling framework for behavioral
predictions of drivers in highway driving scenarios. The need for a modeling
framework that can address multiple human-human and human-automation
interactions, where all the agents can be modeled as decision makers
simultaneously, is the main motivation behind this work. Such a modeling
framework may be utilized for the validation and verification of autonomous
vehicles: It is estimated that for an autonomous vehicle to reach the same
safety level of cars with drivers, millions of miles of driving tests are
required. The modeling framework presented in this paper may be used in a
high-fidelity traffic simulator consisting of multiple human decision makers to
reduce the time and effort spent for testing by allowing safe and quick
assessment of self-driving algorithms. To demonstrate the fidelity of the
proposed modeling framework, game theoretical driver models are compared with
real human driver behavior patterns extracted from traffic data.",arxiv
http://arxiv.org/abs/2011.04697v1,2020-11-09T19:23:26Z,2020-11-09T19:23:26Z,"Behavior Planning at Urban Intersections through Hierarchical
  Reinforcement Learning","For autonomous vehicles, effective behavior planning is crucial to ensure
safety of the ego car. In many urban scenarios, it is hard to create
sufficiently general heuristic rules, especially for challenging scenarios that
some new human drivers find difficult. In this work, we propose a behavior
planning structure based on reinforcement learning (RL) which is capable of
performing autonomous vehicle behavior planning with a hierarchical structure
in simulated urban environments. Application of the hierarchical structure
allows the various layers of the behavior planning system to be satisfied. Our
algorithms can perform better than heuristic-rule-based methods for elective
decisions such as when to turn left between vehicles approaching from the
opposite direction or possible lane-change when approaching an intersection due
to lane blockage or delay in front of the ego car. Such behavior is hard to
evaluate as correct or incorrect, but for some aggressive expert human drivers
handle such scenarios effectively and quickly. On the other hand, compared to
traditional RL methods, our algorithm is more sample-efficient, due to the use
of a hybrid reward mechanism and heuristic exploration during the training
process. The results also show that the proposed method converges to an optimal
policy faster than traditional RL methods.",arxiv
http://arxiv.org/abs/2109.10557v1,2021-09-22T07:38:23Z,2021-09-22T07:38:23Z,"A Reinforcement Learning Benchmark for Autonomous Driving in
  Intersection Scenarios","In recent years, control under urban intersection scenarios becomes an
emerging research topic. In such scenarios, the autonomous vehicle confronts
complicated situations since it must deal with the interaction with social
vehicles timely while obeying the traffic rules. Generally, the autonomous
vehicle is supposed to avoid collisions while pursuing better efficiency. The
existing work fails to provide a framework that emphasizes the integrity of the
scenarios while being able to deploy and test reinforcement learning(RL)
methods. Specifically, we propose a benchmark for training and testing RL-based
autonomous driving agents in complex intersection scenarios, which is called
RL-CIS. Then, a set of baselines are deployed consists of various algorithms.
The test benchmark and baselines are to provide a fair and comprehensive
training and testing platform for the study of RL for autonomous driving in the
intersection scenario, advancing the progress of RL-based methods for
intersection autonomous driving control. The code of our proposed framework can
be found at https://github.com/liuyuqi123/ComplexUrbanScenarios.",arxiv
http://arxiv.org/abs/2010.02363v1,2020-10-05T22:09:44Z,2020-10-05T22:09:44Z,"Learning to Localise Automated Vehicles in Challenging Environments
  using Inertial Navigation Systems (INS)","An algorithm based on Artificial Neural Networks is proposed in this paper to
improve the accuracy of Inertial Navigation System (INS)/ Global Navigation
Satellite System (GNSS) integrated navigation during the absence of GNSS
signals. The INS which can be used to continuously position autonomous vehicles
during GNSS signal losses around urban canyons, bridges, tunnels and trees,
suffers from unbounded exponential error drifts cascaded over time during the
integration of the gyroscope and double integration of the accelerometer to
displacement. More so, the error drift is characterised by a pattern dependent
on time. The Input Delay Neural Network (IDNN) has the ability to learn the
error drift over time [1] and possesses the quality of being more
computationally efficient than the Recurrent Neural Network (RNN), Long
Short-Term Memory, and the Gated Recurrent Unit Network. Furthermore published
literatures focus on travel routes which do not take complex driving scenarios
into consideration, we therefore investigate in this paper the performance of
the proposed algorithm on challenging scenarios, such as hard brake,
roundabouts, sharp cornering, successive left and right turns and quick changes
in vehicular acceleration across numerous test sequences. The results obtained
show that the Neural Network-based approaches are able to provide up to 89.55 %
improvement on the INS displacement estimation and 93.35 % on the INS
orientation rate estimation.",arxiv
http://arxiv.org/abs/2012.05032v1,2020-12-09T13:21:39Z,2020-12-09T13:21:39Z,"ReCoG: A Deep Learning Framework with Heterogeneous Graph for
  Interaction-Aware Trajectory Prediction","Predicting the future trajectory of surrounding vehicles is essential for the
navigation of autonomous vehicles in complex real-world driving scenarios. It
is challenging as a vehicle's motion is affected by many factors, including its
surrounding infrastructures and vehicles. In this work, we develop the ReCoG
(Recurrent Convolutional and Graph Neural Networks), which is a general scheme
that represents vehicle interactions with infrastructure information as a
heterogeneous graph and applies graph neural networks (GNNs) to model the
high-level interactions for trajectory prediction. Nodes in the graph contain
corresponding features, where a vehicle node contains its sequential feature
encoded using Recurrent Neural Network (RNN), and an infrastructure node
contains spatial feature encoded using Convolutional Neural Network (CNN). Then
the ReCoG predicts the future trajectory of the target vehicle by jointly
considering all of the features. Experiments are conducted by using the
INTERACTION dataset. Experimental results show that the proposed ReCoG
outperforms other state-of-the-art methods in terms of different types of
displacement error, validating the feasibility and effectiveness of the
developed approach.",arxiv
http://arxiv.org/abs/1901.05101v1,2019-01-16T01:20:00Z,2019-01-16T01:20:00Z,"ReNeg and Backseat Driver: Learning from Demonstration with Continuous
  Human Feedback","In autonomous vehicle (AV) control, allowing mistakes can be quite dangerous
and costly in the real world. For this reason we investigate methods of
training an AV without allowing the agent to explore and instead having a human
explorer collect the data. Supervised learning has been explored for AV
control, but it encounters the issue of the covariate shift. That is, training
data collected from an optimal demonstration consists only of the states
induced by the optimal control policy, but at runtime, the trained agent may
encounter a vastly different state distribution with little relevant training
data. To mitigate this issue, we have our human explorer make sub-optimal
decisions. In order to have our agent not replicate these sub-optimal
decisions, supervised learning requires that we either erase these actions, or
replace these action with the correct action. Erasing is wasteful and replacing
is difficult, since it is not easy to know the correct action without driving.
We propose an alternate framework that includes continuous scalar feedback for
each action, marking which actions we should replicate, which we should avoid,
and how sure we are. Our framework learns continuous control from sub-optimal
demonstration and evaluative feedback collected before training. We find that a
human demonstrator can explore sub-optimal states in a safe manner, while still
getting enough gradation to benefit learning. The collection method for data
and feedback we call ""Backseat Driver."" We call the more general learning
framework ReNeg, since it learns a regression from states to actions given
negative as well as positive examples. We empirically validate several models
in the ReNeg framework, testing on lane-following with limited data. We find
that the best solution is a generalization of mean-squared error and
outperforms supervised learning on the positive examples alone.",arxiv
http://arxiv.org/abs/1907.06826v2,2019-08-20T13:26:03Z,2019-07-16T04:00:56Z,"Adversarial Sensor Attack on LiDAR-based Perception in Autonomous
  Driving","In Autonomous Vehicles (AVs), one fundamental pillar is perception, which
leverages sensors like cameras and LiDARs (Light Detection and Ranging) to
understand the driving environment. Due to its direct impact on road safety,
multiple prior efforts have been made to study its the security of perception
systems. In contrast to prior work that concentrates on camera-based
perception, in this work we perform the first security study of LiDAR-based
perception in AV settings, which is highly important but unexplored. We
consider LiDAR spoofing attacks as the threat model and set the attack goal as
spoofing obstacles close to the front of a victim AV. We find that blindly
applying LiDAR spoofing is insufficient to achieve this goal due to the machine
learning-based object detection process. Thus, we then explore the possibility
of strategically controlling the spoofed attack to fool the machine learning
model. We formulate this task as an optimization problem and design modeling
methods for the input perturbation function and the objective function. We also
identify the inherent limitations of directly solving the problem using
optimization and design an algorithm that combines optimization and global
sampling, which improves the attack success rates to around 75%. As a case
study to understand the attack impact at the AV driving decision level, we
construct and evaluate two attack scenarios that may damage road safety and
mobility. We also discuss defense directions at the AV system, sensor, and
machine learning model levels.",arxiv
http://arxiv.org/abs/1801.04340v4,2019-05-16T16:56:16Z,2018-01-12T22:16:05Z,"Predicting Future Lane Changes of Other Highway Vehicles using RNN-based
  Deep Models","In the event of sensor failure, autonomous vehicles need to safely execute
emergency maneuvers while avoiding other vehicles on the road. To accomplish
this, the sensor-failed vehicle must predict the future semantic behaviors of
other drivers, such as lane changes, as well as their future trajectories given
a recent window of past sensor observations. We address the first issue of
semantic behavior prediction in this paper, which is a precursor to trajectory
prediction, by introducing a framework that leverages the power of recurrent
neural networks (RNNs) and graphical models. Our goal is to predict the future
categorical driving intent, for lane changes, of neighboring vehicles up to
three seconds into the future given as little as a one-second window of past
LIDAR, GPS, inertial, and map data.
  We collect real-world data containing over 20 hours of highway driving using
an autonomous Toyota vehicle. We propose a composite RNN model by adopting the
methodology of Structural Recurrent Neural Networks (RNNs) to learn factor
functions and take advantage of both the high-level structure of graphical
models and the sequence modeling power of RNNs, which we expect to afford more
transparent modeling and activity than opaque, single RNN models. To
demonstrate our approach, we validate our model using authentic interstate
highway driving to predict the future lane change maneuvers of other vehicles
neighboring our autonomous vehicle. We find that our composite Structural RNN
outperforms baselines by as much as 12% in balanced accuracy metrics.",arxiv
http://arxiv.org/abs/2106.11716v2,2021-06-30T09:22:52Z,2021-06-22T12:33:07Z,"Robust EMRAN based Neural Aided Learning Controller for Autonomous
  Vehicles","This paper presents an online evolving neural network-based inverse dynamics
learning controller for an autonomous vehicle's longitudinal and lateral
control under model uncertainties and disturbances. The inverse dynamics of the
vehicle are approximated using a feedback error learning mechanism that
utilizes a dynamic Radial Basis Function neural network, referred to as the
Extended Minimal Resource Allocating Network (EMRAN). EMRAN uses an extended
Kalman filter approach for learning and a growing/pruning condition helps in
keeping the number of hidden neurons minimum. The online learning algorithm
helps in handling the uncertainties and dynamic variations and also the unknown
disturbances on the road. The proposed control architecture employs two coupled
conventional controllers aided by the EMRAN inverse dynamics controller. The
control architecture has a conventional PID controller for longitudinal cruise
control and a Stanley controller for lateral path-tracking. Performances of
both the longitudinal and lateral controllers are compared with existing
control methods and the simulation results clearly indicate that the proposed
control scheme handles the disturbances and parametric uncertainties better,
and also provides better tracking performance in autonomous vehicles.",arxiv
http://arxiv.org/abs/2005.07460v1,2020-05-15T10:34:51Z,2020-05-15T10:34:51Z,"Collective Risk Minimization via a Bayesian Model for Statistical
  Software Testing","In the last four years, the number of distinct autonomous vehicles platforms
deployed in the streets of California increased 6-fold, while the reported
accidents increased 12-fold. This can become a trend with no signs of subsiding
as it is fueled by a constant stream of innovations in hardware sensors and
machine learning software. Meanwhile, if we expect the public and regulators to
trust the autonomous vehicle platforms, we need to find better ways to solve
the problem of adding technological complexity without increasing the risk of
accidents. We studied this problem from the perspective of reliability
engineering in which a given risk of an accident has severity and probability
of occurring. Timely information on accidents is important for engineers to
anticipate and reuse previous failures to approximate the risk of accidents in
a new city. However, this is challenging in the context of autonomous vehicles
because of the sparse nature of data on the operational scenarios (driving
trajectories in a new city). Our approach was to mitigate data sparsity by
reducing the state space through monitoring of multiple-vehicles operations. We
then minimized the risk of accidents by determining proper allocation of tests
for each equivalence class. Our contributions comprise (1) a set of strategies
to monitor the operational data of multiple autonomous vehicles, (2) a Bayesian
model that estimates changes in the risk of accidents, and (3) a feedback
control-loop that minimizes these risks by reallocating test effort. Our
results are promising in the sense that we were able to measure and control
risk for a diversity of changes in the operational scenarios. We evaluated our
models with data from two real cities with distinct traffic patterns and made
the data available for the community.",arxiv
http://arxiv.org/abs/2010.11722v1,2020-10-16T18:26:59Z,2020-10-16T18:26:59Z,Prediction-Based GNSS Spoofing Attack Detection for Autonomous Vehicles,"Global Navigation Satellite System (GNSS) provides Positioning, Navigation,
and Timing (PNT) services for autonomous vehicles (AVs) using satellites and
radio communications. Due to the lack of encryption, open-access of the coarse
acquisition (C/A) codes, and low strength of the signal, GNSS is vulnerable to
spoofing attacks compromising the navigational capability of the AV. A spoofed
attack is difficult to detect as a spoofer (attacker who performs spoofing
attack) can mimic the GNSS signal and transmit inaccurate location coordinates
to an AV. In this study, we have developed a prediction-based spoofing attack
detection strategy using the long short-term memory (LSTM) model, a recurrent
neural network model. The LSTM model is used to predict the distance traveled
between two consecutive locations of an autonomous vehicle. In order to develop
the LSTM prediction model, we have used a publicly available real-world
comma2k19 driving dataset. The training dataset contains different features
(i.e., acceleration, steering wheel angle, speed, and distance traveled between
two consecutive locations) extracted from the controlled area network (CAN),
GNSS, and inertial measurement unit (IMU) sensors of AVs. Based on the
predicted distance traveled between the current location and the immediate
future location of an autonomous vehicle, a threshold value is established
using the positioning error of the GNSS device and prediction error (i.e.,
maximum absolute error) related to distance traveled between the current
location and the immediate future location. Our analysis revealed that the
prediction-based spoofed attack detection strategy can successfully detect the
attack in real-time.",arxiv
http://arxiv.org/abs/2010.12598v1,2020-10-23T18:07:48Z,2020-10-23T18:07:48Z,"A Software Architecture for Autonomous Vehicles: Team LRM-B Entry in the
  First CARLA Autonomous Driving Challenge","The objective of the first CARLA autonomous driving challenge was to deploy
autonomous driving systems to lead with complex traffic scenarios where all
participants faced the same challenging traffic situations. According to the
organizers, this competition emerges as a way to democratize and to accelerate
the research and development of autonomous vehicles around the world using the
CARLA simulator contributing to the development of the autonomous vehicle area.
Therefore, this paper presents the architecture design for the navigation of an
autonomous vehicle in a simulated urban environment that attempts to commit the
least number of traffic infractions, which used as the baseline the original
architecture of the platform for autonomous navigation CaRINA 2. Our agent
traveled in simulated scenarios for several hours, demonstrating his
capabilities, winning three out of the four tracks of the challenge, and being
ranked second in the remaining track.
  Our architecture was made towards meeting the requirements of CARLA
Autonomous Driving Challenge and has components for obstacle detection using 3D
point clouds, traffic signs detection and classification which employs
Convolutional Neural Networks (CNN) and depth information, risk assessment with
collision detection using short-term motion prediction, decision-making with
Markov Decision Process (MDP), and control using Model Predictive Control
(MPC).",arxiv
http://arxiv.org/abs/2103.03150v1,2021-03-04T16:42:49Z,2021-03-04T16:42:49Z,"SSTN: Self-Supervised Domain Adaptation Thermal Object Detection for
  Autonomous Driving","The sensibility and sensitivity of the environment play a decisive role in
the safe and secure operation of autonomous vehicles. This perception of the
surrounding is way similar to human visual representation. The human's brain
perceives the environment by utilizing different sensory channels and develop a
view-invariant representation model. Keeping in this context, different
exteroceptive sensors are deployed on the autonomous vehicle for perceiving the
environment. The most common exteroceptive sensors are camera, Lidar and radar
for autonomous vehicle's perception. Despite being these sensors have
illustrated their benefit in the visible spectrum domain yet in the adverse
weather conditions, for instance, at night, they have limited operation
capability, which may lead to fatal accidents. In this work, we explore thermal
object detection to model a view-invariant model representation by employing
the self-supervised contrastive learning approach. For this purpose, we have
proposed a deep neural network Self Supervised Thermal Network (SSTN) for
learning the feature embedding to maximize the information between visible and
infrared spectrum domain by contrastive learning, and later employing these
learned feature representation for the thermal object detection using
multi-scale encoder-decoder transformer network. The proposed method is
extensively evaluated on the two publicly available datasets: the FLIR-ADAS
dataset and the KAIST Multi-Spectral dataset. The experimental results
illustrate the efficacy of the proposed method.",arxiv
http://arxiv.org/abs/2107.01784v1,2021-07-05T04:34:51Z,2021-07-05T04:34:51Z,"Learning a Model for Inferring a Spatial Road Lane Network Graph using
  Self-Supervision","Interconnected road lanes are a central concept for navigating urban roads.
Currently, most autonomous vehicles rely on preconstructed lane maps as
designing an algorithmic model is difficult. However, the generation and
maintenance of such maps is costly and hinders large-scale adoption of
autonomous vehicle technology. This paper presents the first self-supervised
learning method to train a model to infer a spatially grounded lane-level road
network graph based on a dense segmented representation of the road scene
generated from onboard sensors. A formal road lane network model is presented
and proves that any structured road scene can be represented by a directed
acyclic graph of at most depth three while retaining the notion of intersection
regions, and that this is the most compressed representation. The formal model
is implemented by a hybrid neural and search-based model, utilizing a novel
barrier function loss formulation for robust learning from partial labels.
Experiments are conducted for all common road intersection layouts. Results
show that the model can generalize to new road layouts, unlike previous
approaches, demonstrating its potential for real-world application as a
practical learning-based lane-level map generator.",arxiv
http://arxiv.org/abs/2108.04308v2,2021-09-16T23:00:49Z,2021-08-09T19:07:58Z,"Do Datasets Have Politics? Disciplinary Values in Computer Vision
  Dataset Development","Data is a crucial component of machine learning. The field is reliant on data
to train, validate, and test models. With increased technical capabilities,
machine learning research has boomed in both academic and industry settings,
and one major focus has been on computer vision. Computer vision is a popular
domain of machine learning increasingly pertinent to real-world applications,
from facial recognition in policing to object detection for autonomous
vehicles. Given computer vision's propensity to shape machine learning research
and impact human life, we seek to understand disciplinary practices around
dataset documentation - how data is collected, curated, annotated, and packaged
into datasets for computer vision researchers and practitioners to use for
model tuning and development. Specifically, we examine what dataset
documentation communicates about the underlying values of vision data and the
larger practices and goals of computer vision as a field. To conduct this
study, we collected a corpus of about 500 computer vision datasets, from which
we sampled 114 dataset publications across different vision tasks. Through both
a structured and thematic content analysis, we document a number of values
around accepted data practices, what makes desirable data, and the treatment of
humans in the dataset construction process. We discuss how computer vision
datasets authors value efficiency at the expense of care; universality at the
expense of contextuality; impartiality at the expense of positionality; and
model work at the expense of data work. Many of the silenced values we identify
sit in opposition with social computing practices. We conclude with suggestions
on how to better incorporate silenced values into the dataset creation and
curation process.",arxiv
http://arxiv.org/abs/2003.00790v1,2020-02-28T16:37:19Z,2020-02-28T16:37:19Z,"Towards Identifying and closing Gaps in Assurance of autonomous Road
  vehicleS -- a collection of Technical Notes Part 2","This report provides an introduction and overview of the Technical Topic
Notes (TTNs) produced in the Towards Identifying and closing Gaps in Assurance
of autonomous Road vehicleS (Tigars) project. These notes aim to support the
development and evaluation of autonomous vehicles. Part 1 addresses:
Assurance-overview and issues, Resilience and Safety Requirements, Open Systems
Perspective and Formal Verification and Static Analysis of ML Systems. This
report is Part 2 and discusses: Simulation and Dynamic Testing, Defence in
Depth and Diversity, Security-Informed Safety Analysis, Standards and
Guidelines.",arxiv
http://arxiv.org/abs/1912.11676v2,2020-07-23T15:52:45Z,2019-12-25T14:22:41Z,"Deep Learning-based Vehicle Behaviour Prediction For Autonomous Driving
  Applications: A Review","Behaviour prediction function of an autonomous vehicle predicts the future
states of the nearby vehicles based on the current and past observations of the
surrounding environment. This helps enhance their awareness of the imminent
hazards. However, conventional behaviour prediction solutions are applicable in
simple driving scenarios that require short prediction horizons. Most recently,
deep learning-based approaches have become popular due to their superior
performance in more complex environments compared to the conventional
approaches. Motivated by this increased popularity, we provide a comprehensive
review of the state-of-the-art of deep learning-based approaches for vehicle
behaviour prediction in this paper. We firstly give an overview of the generic
problem of vehicle behaviour prediction and discuss its challenges, followed by
classification and review of the most recent deep learning-based solutions
based on three criteria: input representation, output type, and prediction
method. The paper also discusses the performance of several well-known
solutions, identifies the research gaps in the literature and outlines
potential new research directions.",arxiv
http://arxiv.org/abs/1805.08986v1,2018-05-23T07:36:48Z,2018-05-23T07:36:48Z,Deep Object Tracking on Dynamic Occupancy Grid Maps Using RNNs,"The comprehensive representation and understanding of the driving environment
is crucial to improve the safety and reliability of autonomous vehicles. In
this paper, we present a new approach to establish an environment model
containing a segmentation between static and dynamic background and parametric
modeled objects with shape, position and orientation. Multiple laser scanners
are fused into a dynamic occupancy grid map resulting in a 360{\deg} perception
of the environment. A single-stage deep convolutional neural network is
combined with a recurrent neural network, which takes a time series of the
occupancy grid map as input and tracks cell states and its corresponding object
hypotheses. The labels for training are created unsupervised with an automatic
label generation algorithm.
  The proposed methods are evaluated in real-world experiments in complex inner
city scenarios using the aforementioned 360{\deg} laser perception. The results
show a better object detection accuracy in comparison with our old approach as
well as an AUC score of 0.946 for the dynamic and static segmentation.
Furthermore, we gain an improved detection for occluded objects and a more
consistent size estimation due to the usage of time series as input and the
memory about previous states introduced by the recurrent neural network.",arxiv
http://arxiv.org/abs/1605.07148v4,2017-10-01T00:57:20Z,2016-05-23T19:28:21Z,Backprop KF: Learning Discriminative Deterministic State Estimators,"Generative state estimators based on probabilistic filters and smoothers are
one of the most popular classes of state estimators for robots and autonomous
vehicles. However, generative models have limited capacity to handle rich
sensory observations, such as camera images, since they must model the entire
distribution over sensor readings. Discriminative models do not suffer from
this limitation, but are typically more complex to train as latent variable
models for state estimation. We present an alternative approach where the
parameters of the latent state distribution are directly optimized as a
deterministic computation graph, resulting in a simple and effective gradient
descent algorithm for training discriminative state estimators. We show that
this procedure can be used to train state estimators that use complex input,
such as raw camera images, which must be processed using expressive nonlinear
function approximators such as convolutional neural networks. Our model can be
viewed as a type of recurrent neural network, and the connection to
probabilistic filtering allows us to design a network architecture that is
particularly well suited for state estimation. We evaluate our approach on
synthetic tracking task with raw image inputs and on the visual odometry task
in the KITTI dataset. The results show significant improvement over both
standard generative approaches and regular recurrent neural networks.",arxiv
http://arxiv.org/abs/2006.03463v2,2021-05-12T14:17:37Z,2020-06-05T14:10:09Z,Sponge Examples: Energy-Latency Attacks on Neural Networks,"The high energy costs of neural network training and inference led to the use
of acceleration hardware such as GPUs and TPUs. While this enabled us to train
large-scale neural networks in datacenters and deploy them on edge devices, the
focus so far is on average-case performance. In this work, we introduce a novel
threat vector against neural networks whose energy consumption or decision
latency are critical. We show how adversaries can exploit carefully crafted
$\boldsymbol{sponge}~\boldsymbol{examples}$, which are inputs designed to
maximise energy consumption and latency.
  We mount two variants of this attack on established vision and language
models, increasing energy consumption by a factor of 10 to 200. Our attacks can
also be used to delay decisions where a network has critical real-time
performance, such as in perception for autonomous vehicles. We demonstrate the
portability of our malicious inputs across CPUs and a variety of hardware
accelerator chips including GPUs, and an ASIC simulator. We conclude by
proposing a defense strategy which mitigates our attack by shifting the
analysis of energy consumption in hardware from an average-case to a worst-case
perspective.",arxiv
http://arxiv.org/abs/2010.08844v2,2021-06-11T00:42:30Z,2020-10-17T18:35:32Z,"Finding Physical Adversarial Examples for Autonomous Driving with Fast
  and Differentiable Image Compositing","There is considerable evidence that deep neural networks are vulnerable to
adversarial perturbations applied directly to their digital inputs. However, it
remains an open question whether this translates to vulnerabilities in real
systems. For example, an attack on self-driving cars would in practice entail
modifying the driving environment, which then impacts the video inputs to the
car's controller, thereby indirectly leading to incorrect driving decisions.
Such attacks require accounting for system dynamics and tracking viewpoint
changes. We propose a scalable approach for finding adversarial modifications
of a simulated autonomous driving environment using a differentiable
approximation for the mapping from environmental modifications (rectangles on
the road) to the corresponding video inputs to the controller neural network.
Given the parameters of the rectangles, our proposed differentiable mapping
composites them onto pre-recorded video streams of the original environment,
accounting for geometric and color variations. Moreover, we propose a multiple
trajectory sampling approach that enables our attacks to be robust to a car's
self-correcting behavior. When combined with a neural network-based controller,
our approach allows the design of adversarial modifications through end-to-end
gradient-based optimization. Using the Carla autonomous driving simulator, we
show that our approach is significantly more scalable and far more effective at
identifying autonomous vehicle vulnerabilities in simulation experiments than a
state-of-the-art approach based on Bayesian Optimization.",arxiv
http://arxiv.org/abs/1401.5851v1,2014-01-23T02:43:47Z,2014-01-23T02:43:47Z,"A Market-Inspired Approach for Intersection Management in Urban Road
  Traffic Networks","Traffic congestion in urban road networks is a costly problem that affects
all major cities in developed countries. To tackle this problem, it is possible
(i) to act on the supply side, increasing the number of roads or lanes in a
network, (ii) to reduce the demand, restricting the access to urban areas at
specific hours or to specific vehicles, or (iii) to improve the efficiency of
the existing network, by means of a widespread use of so-called Intelligent
Transportation Systems (ITS). In line with the recent advances in smart
transportation management infrastructures, ITS has turned out to be a promising
field of application for artificial intelligence techniques. In particular,
multiagent systems seem to be the ideal candidates for the design and
implementation of ITS. In fact, drivers can be naturally modelled as autonomous
agents that interact with the transportation management infrastructure, thereby
generating a large-scale, open, agent-based system. To regulate such a system
and maintain a smooth and efficient flow of traffic, decentralised mechanisms
for the management of the transportation infrastructure are needed.
  In this article we propose a distributed, market-inspired, mechanism for the
management of a future urban road network, where intelligent autonomous
vehicles, operated by software agents on behalf of their human owners, interact
with the infrastructure in order to travel safely and efficiently through the
road network. Building on the reservation-based intersection control model
proposed by Dresner and Stone, we consider two different scenarios: one with a
single intersection and one with a network of intersections. In the former, we
analyse the performance of a novel policy based on combinatorial auctions for
the allocation of reservations. In the latter, we analyse the impact that a
traffic assignment strategy inspired by competitive markets has on the drivers
route choices. Finally we propose an adaptive management mechanism that
integrates the auction-based traffic control policy with the competitive
traffic assignment strategy.",arxiv
http://arxiv.org/abs/1810.09805v1,2018-10-23T12:07:32Z,2018-10-23T12:07:32Z,Action and intention recognition of pedestrians in urban traffic,"Action and intention recognition of pedestrians in urban settings are
challenging problems for Advanced Driver Assistance Systems as well as future
autonomous vehicles to maintain smooth and safe traffic. This work investigates
a number of feature extraction methods in combination with several machine
learning algorithms to build knowledge on how to automatically detect the
action and intention of pedestrians in urban traffic. We focus on the motion
and head orientation to predict whether the pedestrian is about to cross the
street or not. The work is based on the Joint Attention for Autonomous Driving
(JAAD) dataset, which contains 346 videoclips of various traffic scenarios
captured with cameras mounted in the windshield of a car. An accuracy of 72%
for head orientation estimation and 85% for motion detection is obtained in our
experiments.",arxiv
http://arxiv.org/abs/1812.01097v3,2019-12-09T20:02:37Z,2018-12-03T21:59:41Z,LEAF: A Benchmark for Federated Settings,"Modern federated networks, such as those comprised of wearable devices,
mobile phones, or autonomous vehicles, generate massive amounts of data each
day. This wealth of data can help to learn models that can improve the user
experience on each device. However, the scale and heterogeneity of federated
data presents new challenges in research areas such as federated learning,
meta-learning, and multi-task learning. As the machine learning community
begins to tackle these challenges, we are at a critical time to ensure that
developments made in these areas are grounded with realistic benchmarks. To
this end, we propose LEAF, a modular benchmarking framework for learning in
federated settings. LEAF includes a suite of open-source federated datasets, a
rigorous evaluation framework, and a set of reference implementations, all
geared towards capturing the obstacles and intricacies of practical federated
environments.",arxiv
http://arxiv.org/abs/1812.03823v2,2018-12-13T17:33:07Z,2018-12-10T14:31:58Z,Learning to Drive from Simulation without Real World Labels,"Simulation can be a powerful tool for understanding machine learning systems
and designing methods to solve real-world problems. Training and evaluating
methods purely in simulation is often ""doomed to succeed"" at the desired task
in a simulated environment, but the resulting models are incapable of operation
in the real world. Here we present and evaluate a method for transferring a
vision-based lane following driving policy from simulation to operation on a
rural road without any real-world labels. Our approach leverages recent
advances in image-to-image translation to achieve domain transfer while jointly
learning a single-camera control policy from simulation control labels. We
assess the driving performance of this method using both open-loop regression
metrics, and closed-loop performance operating an autonomous vehicle on rural
and urban roads.",arxiv
http://arxiv.org/abs/1910.08635v1,2019-10-18T21:35:33Z,2019-10-18T21:35:33Z,"Tree-based Intelligent Intrusion Detection System in Internet of
  Vehicles","The use of autonomous vehicles (AVs) is a promising technology in Intelligent
Transportation Systems (ITSs) to improve safety and driving efficiency.
Vehicle-to-everything (V2X) technology enables communication among vehicles and
other infrastructures. However, AVs and Internet of Vehicles (IoV) are
vulnerable to different types of cyber-attacks such as denial of service,
spoofing, and sniffing attacks. In this paper, an intelligent intrusion
detection system (IDS) is proposed based on tree-structure machine learning
models. The results from the implementation of the proposed intrusion detection
system on standard data sets indicate that the system has the ability to
identify various cyber-attacks in the AV networks. Furthermore, the proposed
ensemble learning and feature selection approaches enable the proposed system
to achieve high detection rate and low computational cost simultaneously.",arxiv
http://arxiv.org/abs/2004.14494v1,2020-04-29T21:51:21Z,2020-04-29T21:51:21Z,"Coordination and Communication of Autonomous Subsystems in Cyber
  Physical Systems: A Mechanism Learning Approach","In the control of many autonomous subsystems, such as autonomous vehicles or
UAV networks, a centralized control may be hindered by the prohibitive
complexity, limited communication bandwidth, or private information of
subsystems. Therefore, it is desirable for the control center to coordinate the
controls of subsystems by designing mechanisms such as pricing, which makes the
local optimizations of subsystem dynamics also maximize the reward of the total
system, namely the social welfare. The economics framework of mechanism design
is employed for the coordination of the autonomous subsystems. To address the
challenge of dynamics, which are not considered in conventional economics
mechanism design, and the complexity of private information, the approaches of
geometrization and machine learning are employed, by endowing different
geometric structures to the problem. The theoretical framework is applied in
the context of urban aerial mobility, where the numerical simulations show the
validity of the proposed framework.",arxiv
http://arxiv.org/abs/2005.12496v6,2021-03-15T02:30:18Z,2020-05-26T03:08:43Z,CRUDE: Calibrating Regression Uncertainty Distributions Empirically,"Calibrated uncertainty estimates in machine learning are crucial to many
fields such as autonomous vehicles, medicine, and weather and climate
forecasting. While there is extensive literature on uncertainty calibration for
classification, the classification findings do not always translate to
regression. As a result, modern models for predicting uncertainty in regression
settings typically produce uncalibrated and overconfident estimates. To address
these gaps, we present a calibration method for regression settings that does
not assume a particular uncertainty distribution over the error: Calibrating
Regression Uncertainty Distributions Empirically (CRUDE). CRUDE makes the
weaker assumption that error distributions have a constant arbitrary shape
across the output space, shifted by predicted mean and scaled by predicted
standard deviation. We detail a theoretical connection between CRUDE and
conformal inference. Across an extensive set of regression tasks, CRUDE
demonstrates consistently sharper, better calibrated, and more accurate
uncertainty estimates than state-of-the-art techniques.",arxiv
http://arxiv.org/abs/2009.14349v3,2020-12-07T20:08:44Z,2020-09-30T00:01:54Z,"Computing Systems for Autonomous Driving: State-of-the-Art and
  Challenges","The recent proliferation of computing technologies (e.g., sensors, computer
vision, machine learning, and hardware acceleration), and the broad deployment
of communication mechanisms (e.g., DSRC, C-V2X, 5G) have pushed the horizon of
autonomous driving, which automates the decision and control of vehicles by
leveraging the perception results based on multiple sensors. The key to the
success of these autonomous systems is making a reliable decision in real-time
fashion. However, accidents and fatalities caused by early deployed autonomous
vehicles arise from time to time. The real traffic environment is too
complicated for current autonomous driving computing systems to understand and
handle. In this paper, we present state-of-the-art computing systems for
autonomous driving, including seven performance metrics and nine key
technologies, followed by twelve challenges to realize autonomous driving. We
hope this paper will gain attention from both the computing and automotive
communities and inspire more research in this direction.",arxiv
http://arxiv.org/abs/2010.10426v1,2020-10-20T16:36:06Z,2020-10-20T16:36:06Z,A Lane Merge Coordination Model for a V2X Scenario,"Cooperative driving using connectivity services has been a promising avenue
for autonomous vehicles, with the low latency and further reliability support
provided by 5th Generation Mobile Network (5G). In this paper, we present an
application for lane merge coordination based on a centralised system, for
connected cars. This application delivers trajectory recommendations to the
connected vehicles on the road. The application comprises of a Traffic
Orchestrator as the main component. We apply machine learning and data analysis
to predict whether a connected vehicle can successfully complete the
cooperative manoeuvre of a lane merge. Furthermore, the acceleration and
heading parameters that are necessary for the completion of a safe merge are
elaborated. The results demonstrate the performance of several existing
algorithms and how their main parameters were selected to avoid over-fitting.",arxiv
http://arxiv.org/abs/2010.15441v1,2020-10-29T09:29:47Z,2020-10-29T09:29:47Z,"Self-awareness in intelligent vehicles: Feature based dynamic Bayesian
  models for abnormality detection","The evolution of Intelligent Transportation Systems in recent times
necessitates the development of self-awareness in agents. Before the intensive
use of Machine Learning, the detection of abnormalities was manually programmed
by checking every variable and creating huge nested conditions that are very
difficult to track. This paper aims to introduce a novel method to develop
self-awareness in autonomous vehicles that mainly focuses on detecting abnormal
situations around the considered agents. Multi-sensory time-series data from
the vehicles are used to develop the data-driven Dynamic Bayesian Network (DBN)
models used for future state prediction and the detection of dynamic
abnormalities. Moreover, an initial level collective awareness model that can
perform joint anomaly detection in co-operative tasks is proposed. The GNG
algorithm learns the DBN models' discrete node variables; probabilistic
transition links connect the node variables. A Markov Jump Particle Filter
(MJPF) is applied to predict future states and detect when the vehicle is
potentially misbehaving using learned DBNs as filter parameters. In this paper,
datasets from real experiments of autonomous vehicles performing various tasks
used to learn and test a set of switching DBN models.",arxiv
http://arxiv.org/abs/1806.04497v1,2018-06-12T13:26:56Z,2018-06-12T13:26:56Z,"A Virtual Environment with Multi-Robot Navigation, Analytics, and
  Decision Support for Critical Incident Investigation","Accidents and attacks that involve chemical, biological, radiological/nuclear
or explosive (CBRNE) substances are rare, but can be of high consequence. Since
the investigation of such events is not anybody's routine work, a range of AI
techniques can reduce investigators' cognitive load and support
decision-making, including: planning the assessment of the scene; ongoing
evaluation and updating of risks; control of autonomous vehicles for collecting
images and sensor data; reviewing images/videos for items of interest;
identification of anomalies; and retrieval of relevant documentation. Because
of the rare and high-risk nature of these events, realistic simulations can
support the development and evaluation of AI-based tools. We have developed
realistic models of CBRNE scenarios and implemented an initial set of tools.",arxiv
http://arxiv.org/abs/1811.00145v3,2019-01-12T19:27:45Z,2018-10-31T22:47:22Z,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,"While recent developments in autonomous vehicle (AV) technology highlight
substantial progress, we lack tools for rigorous and scalable testing.
Real-world testing, the $\textit{de facto}$ evaluation environment, places the
public in danger, and, due to the rare nature of accidents, will require
billions of miles in order to statistically validate performance claims. We
implement a simulation framework that can test an entire modern autonomous
driving system, including, in particular, systems that employ deep-learning
perception and control algorithms. Using adaptive importance-sampling methods
to accelerate rare-event probability evaluation, we estimate the probability of
an accident under a base distribution governing standard traffic behavior. We
demonstrate our framework on a highway scenario, accelerating system evaluation
by $2$-$20$ times over naive Monte Carlo sampling methods and $10$-$300
\mathsf{P}$ times (where $\mathsf{P}$ is the number of processors) over
real-world testing.",arxiv
http://arxiv.org/abs/1812.09670v1,2018-12-23T08:19:47Z,2018-12-23T08:19:47Z,"An Efficient L-Shape Fitting Method for Vehicle Pose Detection with 2D
  LiDAR","Detecting vehicles with strong robustness and high efficiency has become one
of the key capabilities of fully autonomous driving cars. This topic has
already been widely studied by GPU-accelerated deep learning approaches using
image sensors and 3D LiDAR, however, few studies seek to address it with a
horizontally mounted 2D laser scanner. 2D laser scanner is equipped on almost
every autonomous vehicle for its superiorities in the field of view, lighting
invariance, high accuracy and relatively low price. In this paper, we propose a
highly efficient search-based L-Shape fitting algorithm for detecting positions
and orientations of vehicles with a 2D laser scanner. Differing from the
approach to formulating LShape fitting as a complex optimization problem, our
method decomposes the L-Shape fitting into two steps: L-Shape vertexes
searching and L-Shape corner localization. Our approach is computationally
efficient due to its minimized complexity. In on-road experiments, our approach
is capable of adapting to various circumstances with high efficiency and
robustness.",arxiv
http://arxiv.org/abs/1909.05622v2,2020-04-24T17:06:36Z,2019-08-28T03:49:07Z,Inception-inspired LSTM for Next-frame Video Prediction,"The problem of video frame prediction has received much interest due to its
relevance to many computer vision applications such as autonomous vehicles or
robotics. Supervised methods for video frame prediction rely on labeled data,
which may not always be available. In this paper, we provide a novel
unsupervised deep-learning method called Inception-based LSTM for video frame
prediction. The general idea of inception networks is to implement wider
networks instead of deeper networks. This network design was shown to improve
the performance of image classification. The proposed method is evaluated on
both Inception-v1 and Inception-v2 structures. The proposed Inception LSTM
methods are compared with convolutional LSTM when applied using PredNet
predictive coding framework for both the KITTI and KTH data sets. We observed
that the Inception based LSTM outperforms the convolutional LSTM. Also,
Inception LSTM has better prediction performance compared to Inception v2 LSTM.
However, Inception v2 LSTM has a lower computational cost compared to Inception
LSTM.",arxiv
http://arxiv.org/abs/1910.04695v1,2019-10-02T03:55:45Z,2019-10-02T03:55:45Z,GLADAS: Gesture Learning for Advanced Driver Assistance Systems,"Human-computer interaction (HCI) is crucial for the safety of lives as
autonomous vehicles (AVs) become commonplace. Yet, little effort has been put
toward ensuring that AVs understand humans on the road. In this paper, we
present GLADAS, a simulator-based research platform designed to teach AVs to
understand pedestrian hand gestures. GLADAS supports the training, testing, and
validation of deep learning-based self-driving car gesture recognition systems.
We focus on gestures as they are a primordial (i.e, natural and common) way to
interact with cars. To the best of our knowledge, GLADAS is the first system of
its kind designed to provide an infrastructure for further research into
human-AV interaction. We also develop a hand gesture recognition algorithm for
self-driving cars, using GLADAS to evaluate its performance. Our results show
that an AV understands human gestures 85.91% of the time, reinforcing the need
for further research into human-AV interaction.",arxiv
http://arxiv.org/abs/2001.00236v1,2020-01-01T16:48:42Z,2020-01-01T16:48:42Z,Multi-lane Detection Using Instance Segmentation and Attentive Voting,"Autonomous driving is becoming one of the leading industrial research areas.
Therefore many automobile companies are coming up with semi to fully autonomous
driving solutions. Among these solutions, lane detection is one of the vital
driver-assist features that play a crucial role in the decision-making process
of the autonomous vehicle. A variety of solutions have been proposed to detect
lanes on the road, which ranges from using hand-crafted features to the
state-of-the-art end-to-end trainable deep learning architectures. Most of
these architectures are trained in a traffic constrained environment. In this
paper, we propose a novel solution to multi-lane detection, which outperforms
state of the art methods in terms of both accuracy and speed. To achieve this,
we also offer a dataset with a more intuitive labeling scheme as compared to
other benchmark datasets. Using our approach, we are able to obtain a lane
segmentation accuracy of 99.87% running at 54.53 fps (average).",arxiv
http://arxiv.org/abs/2003.06409v2,2020-07-17T10:07:40Z,2020-03-13T17:48:21Z,Probabilistic Future Prediction for Video Scene Understanding,"We present a novel deep learning architecture for probabilistic future
prediction from video. We predict the future semantics, geometry and motion of
complex real-world urban scenes and use this representation to control an
autonomous vehicle. This work is the first to jointly predict ego-motion,
static scene, and the motion of dynamic agents in a probabilistic manner, which
allows sampling consistent, highly probable futures from a compact latent
space. Our model learns a representation from RGB video with a spatio-temporal
convolutional module. The learned representation can be explicitly decoded to
future semantic segmentation, depth, and optical flow, in addition to being an
input to a learnt driving policy. To model the stochasticity of the future, we
introduce a conditional variational approach which minimises the divergence
between the present distribution (what could happen given what we have seen)
and the future distribution (what we observe actually happens). During
inference, diverse futures are generated by sampling from the present
distribution.",arxiv
http://arxiv.org/abs/2003.13402v1,2020-03-30T12:39:44Z,2020-03-30T12:39:44Z,"Predicting Semantic Map Representations from Images using Pyramid
  Occupancy Networks","Autonomous vehicles commonly rely on highly detailed birds-eye-view maps of
their environment, which capture both static elements of the scene such as road
layout as well as dynamic elements such as other cars and pedestrians.
Generating these map representations on the fly is a complex multi-stage
process which incorporates many important vision-based elements, including
ground plane estimation, road segmentation and 3D object detection. In this
work we present a simple, unified approach for estimating maps directly from
monocular images using a single end-to-end deep learning architecture. For the
maps themselves we adopt a semantic Bayesian occupancy grid framework, allowing
us to trivially accumulate information over multiple cameras and timesteps. We
demonstrate the effectiveness of our approach by evaluating against several
challenging baselines on the NuScenes and Argoverse datasets, and show that we
are able to achieve a relative improvement of 9.1% and 22.3% respectively
compared to the best-performing existing method.",arxiv
http://arxiv.org/abs/2006.00644v1,2020-06-01T00:02:45Z,2020-06-01T00:02:45Z,Automatic Building and Labeling of HD Maps with Deep Learning,"In a world where autonomous driving cars are becoming increasingly more
common, creating an adequate infrastructure for this new technology is
essential. This includes building and labeling high-definition (HD) maps
accurately and efficiently. Today, the process of creating HD maps requires a
lot of human input, which takes time and is prone to errors. In this paper, we
propose a novel method capable of generating labelled HD maps from raw sensor
data. We implemented and tested our methods on several urban scenarios using
data collected from our test vehicle. The results show that the pro-posed deep
learning based method can produce highly accurate HD maps. This approach speeds
up the process of building and labeling HD maps, which can make meaningful
contribution to the deployment of autonomous vehicle.",arxiv
http://arxiv.org/abs/2006.00962v1,2020-06-01T14:20:04Z,2020-06-01T14:20:04Z,"Off The Beaten Sidewalk: Pedestrian Prediction In Shared Spaces For
  Autonomous Vehicles","Pedestrians and drivers interact closely in a wide range of environments.
Autonomous vehicles (AVs) correspondingly face the need to predict pedestrians'
future trajectories in these same environments. Traditional model-based
prediction methods have been limited to making predictions in highly structured
scenes with signalized intersections, marked crosswalks, or curbs. Deep
learning methods have instead leveraged datasets to learn predictive features
that generalize across scenes, at the cost of model interpretability. This
paper aims to achieve both widely applicable and interpretable predictions by
proposing a risk-based attention mechanism to learn when pedestrians yield, and
a model of vehicle influence to learn how yielding affects motion. A novel
probabilistic method, Off the Sidewalk Predictions (OSP), uses these to achieve
accurate predictions in both shared spaces and traditional scenes. Experiments
on urban datasets demonstrate that the realtime method achieves
state-of-the-art performance.",arxiv
http://arxiv.org/abs/2007.14812v2,2021-03-24T18:11:37Z,2020-07-29T12:58:40Z,"What My Motion tells me about Your Pose: A Self-Supervised Monocular 3D
  Vehicle Detector","The estimation of the orientation of an observed vehicle relative to an
Autonomous Vehicle (AV) from monocular camera data is an important building
block in estimating its 6 DoF pose. Current Deep Learning based solutions for
placing a 3D bounding box around this observed vehicle are data hungry and do
not generalize well. In this paper, we demonstrate the use of monocular visual
odometry for the self-supervised fine-tuning of a model for orientation
estimation pre-trained on a reference domain. Specifically, while transitioning
from a virtual dataset (vKITTI) to nuScenes, we recover up to 70% of the
performance of a fully supervised method. We subsequently demonstrate an
optimization-based monocular 3D bounding box detector built on top of the
self-supervised vehicle orientation estimator without the requirement of
expensive labeled data. This allows 3D vehicle detection algorithms to be
self-trained from large amounts of monocular camera data from existing
commercial vehicle fleets.",arxiv
http://arxiv.org/abs/2007.16162v2,2020-08-26T02:06:33Z,2020-07-31T16:32:23Z,Imitative Planning using Conditional Normalizing Flow,"We explore the application of normalizing flows for improving the performance
of trajectory planning for autonomous vehicles (AVs). Normalizing flows provide
an invertible mapping from a known prior distribution to a potentially complex,
multi-modal target distribution and allow for fast sampling with exact PDF
inference. By modeling a trajectory planner's cost manifold as an energy
function we learn a scene conditioned mapping from the prior to a Boltzmann
distribution over the AV control space. This mapping allows for control samples
and their associated energy to be generated jointly and in parallel. We propose
using neural autoregressive flow (NAF) as part of an end-to-end deep learned
system that allows for utilizing sensors, map, and route information to
condition the flow mapping. Finally, we demonstrate the effectiveness of our
approach on real world datasets over IL and hand constructed trajectory
sampling techniques.",arxiv
http://arxiv.org/abs/2012.10870v1,2020-12-20T08:51:10Z,2020-12-20T08:51:10Z,Computer Vision based Accident Detection for Autonomous Vehicles,"Numerous Deep Learning and sensor-based models have been developed to detect
potential accidents with an autonomous vehicle. However, a self-driving car
needs to be able to detect accidents between other vehicles in its path and
take appropriate actions such as to slow down or stop and inform the concerned
authorities. In this paper, we propose a novel support system for self-driving
cars that detects vehicular accidents through a dashboard camera. The system
leverages the Mask R-CNN framework for vehicle detection and a centroid
tracking algorithm to track the detected vehicle. Additionally, the framework
calculates various parameters such as speed, acceleration, and trajectory to
determine whether an accident has occurred between any of the tracked vehicles.
The framework has been tested on a custom dataset of dashcam footage and
achieves a high accident detection rate while maintaining a low false alarm
rate.",arxiv
http://arxiv.org/abs/2103.14198v1,2021-03-26T01:18:11Z,2021-03-26T01:18:11Z,"Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object
  Detection","Self-driving cars must detect other vehicles and pedestrians in 3D to plan
safe routes and avoid collisions. State-of-the-art 3D object detectors, based
on deep learning, have shown promising accuracy but are prone to over-fit to
domain idiosyncrasies, making them fail in new environments -- a serious
problem if autonomous vehicles are meant to operate freely. In this paper, we
propose a novel learning approach that drastically reduces this gap by
fine-tuning the detector on pseudo-labels in the target domain, which our
method generates while the vehicle is parked, based on replays of previously
recorded driving sequences. In these replays, objects are tracked over time,
and detections are interpolated and extrapolated -- crucially, leveraging
future information to catch hard cases. We show, on five autonomous driving
datasets, that fine-tuning the object detector on these pseudo-labels
substantially reduces the domain gap to new driving environments, yielding
drastic improvements in accuracy and detection reliability.",arxiv
http://arxiv.org/abs/1808.10134v1,2018-08-30T06:29:10Z,2018-08-30T06:29:10Z,"Baidu Apollo Auto-Calibration System - An Industry-Level Data-Driven and
  Learning based Vehicle Longitude Dynamic Calibrating Algorithm","For any autonomous driving vehicle, control module determines its road
performance and safety, i.e. its precision and stability should stay within a
carefully-designed range. Nonetheless, control algorithms require vehicle
dynamics (such as longitudinal dynamics) as inputs, which, unfortunately, are
obscure to calibrate in real time. As a result, to achieve reasonable
performance, most, if not all, research-oriented autonomous vehicles do manual
calibrations in a one-by-one fashion. Since manual calibration is not
sustainable once entering into mass production stage for industrial purposes,
we here introduce a machine-learning based auto-calibration system for
autonomous driving vehicles. In this paper, we will show how we build a
data-driven longitudinal calibration procedure using machine learning
techniques. We first generated offline calibration tables from human driving
data. The offline table serves as an initial guess for later uses and it only
needs twenty-minutes data collection and process. We then used an
online-learning algorithm to appropriately update the initial table (the
offline table) based on real-time performance analysis. This longitudinal
auto-calibration system has been deployed to more than one hundred Baidu Apollo
self-driving vehicles (including hybrid family vehicles and electronic
delivery-only vehicles) since April 2018. By August 27, 2018, it had been
tested for more than two thousands hours, ten thousands kilometers (6,213
miles) and yet proven to be effective.",arxiv
http://arxiv.org/abs/1905.11026v2,2019-05-30T06:29:59Z,2019-05-27T07:55:05Z,"Fooling Detection Alone is Not Enough: First Adversarial Attack against
  Multiple Object Tracking","Recent work in adversarial machine learning started to focus on the visual
perception in autonomous driving and studied Adversarial Examples (AEs) for
object detection models. However, in such visual perception pipeline the
detected objects must also be tracked, in a process called Multiple Object
Tracking (MOT), to build the moving trajectories of surrounding obstacles.
Since MOT is designed to be robust against errors in object detection, it poses
a general challenge to existing attack techniques that blindly target objection
detection: we find that a success rate of over 98% is needed for them to
actually affect the tracking results, a requirement that no existing attack
technique can satisfy. In this paper, we are the first to study adversarial
machine learning attacks against the complete visual perception pipeline in
autonomous driving, and discover a novel attack technique, tracker hijacking,
that can effectively fool MOT using AEs on object detection. Using our
technique, successful AEs on as few as one single frame can move an existing
object in to or out of the headway of an autonomous vehicle to cause potential
safety hazards. We perform evaluation using the Berkeley Deep Drive dataset and
find that on average when 3 frames are attacked, our attack can have a nearly
100% success rate while attacks that blindly target object detection only have
up to 25%.",arxiv
http://arxiv.org/abs/2012.07753v1,2020-12-14T17:49:00Z,2020-12-14T17:49:00Z,"6G for Vehicle-to-Everything (V2X) Communications: Enabling
  Technologies, Challenges, and Opportunities","We are on the cusp of a new era of connected autonomous vehicles with
unprecedented user experiences, tremendously improved road safety and air
quality, highly diverse transportation environments and use cases, as well as a
plethora of advanced applications. Realizing this grand vision requires a
significantly enhanced vehicle-to-everything (V2X) communication network which
should be extremely intelligent and capable of concurrently supporting
hyper-fast, ultra-reliable, and low-latency massive information exchange. It is
anticipated that the sixth-generation (6G) communication systems will fulfill
these requirements of the next-generation V2X. In this article, we outline a
series of key enabling technologies from a range of domains, such as new
materials, algorithms, and system architectures. Aiming for truly intelligent
transportation systems, we envision that machine learning will play an
instrumental role for advanced vehicular communication and networking. To this
end, we provide an overview on the recent advances of machine learning in 6G
vehicular networks. To stimulate future research in this area, we discuss the
strength, open challenges, maturity, and enhancing areas of these technologies.",arxiv
http://arxiv.org/abs/2102.04241v1,2021-02-08T14:39:03Z,2021-02-08T14:39:03Z,"SceML - A Graphical Modeling Framework for Scenario-based Testing of
  Autonomous Vehicles","Ensuring the functional correctness and safety of autonomous vehicles is a
major challenge for the automotive industry. However, exhaustive physical test
drives are not feasible, as billions of driven kilometers would be required to
obtain reliable results. Scenariobased testing is an approach to tackle this
problem and reduce necessary test drives by replacing driven kilometers with
simulations of relevant or interesting scenarios. These scenarios can be
generated or extracted from recorded data with machine learning algorithms or
created by experts. In this paper, we propose a novel graphical scenario
modeling language. The graphical framework allows experts to create new
scenarios or review ones designed by other experts or generated by machine
learning algorithms. The scenario description is modeled as a graph and based
on behavior trees. It supports different abstraction levels of scenario
description during software and test development. Additionally, the graphbased
structure provides modularity and reusable sub-scenarios, an important use case
in scenario modeling. A graphical visualization of the scenario enhances
comprehensibility for different users. The presented approach eases the
scenario creation process and increases the usage of scenarios within
development and testing processes.",arxiv
http://arxiv.org/abs/2104.13983v1,2021-04-28T19:25:01Z,2021-04-28T19:25:01Z,Neuromorphic Computing is Turing-Complete,"Neuromorphic computing is a non-von Neumann computing paradigm that performs
computation by emulating the human brain. Neuromorphic systems are extremely
energy-efficient and known to consume thousands of times less power than CPUs
and GPUs. They have the potential to drive critical use cases such as
autonomous vehicles, edge computing and internet of things in the future. For
this reason, they are sought to be an indispensable part of the future
computing landscape. Neuromorphic systems are mainly used for spike-based
machine learning applications, although there are some non-machine learning
applications in graph theory, differential equations, and spike-based
simulations. These applications suggest that neuromorphic computing might be
capable of general-purpose computing. However, general-purpose computability of
neuromorphic computing has not been established yet. In this work, we prove
that neuromorphic computing is Turing-complete and therefore capable of
general-purpose computing. Specifically, we present a model of neuromorphic
computing, with just two neuron parameters (threshold and leak), and two
synaptic parameters (weight and delay). We devise neuromorphic circuits for
computing all the {\mu}-recursive functions (i.e., constant, successor and
projection functions) and all the {\mu}-recursive operators (i.e., composition,
primitive recursion and minimization operators). Given that the {\mu}-recursive
functions and operators are precisely the ones that can be computed using a
Turing machine, this work establishes the Turing-completeness of neuromorphic
computing.",arxiv
http://arxiv.org/abs/2109.11323v1,2021-09-23T12:16:50Z,2021-09-23T12:16:50Z,Federated Feature Selection for Cyber-Physical Systems of Systems,"Autonomous systems generate a huge amount of multimodal data that are
collected and processed on the Edge, in order to enable AI-based services. The
collected datasets are pre-processed in order to extract informative
attributes, called features, which are used to feed AI algorithms. Due to the
limited computational and communication resources of some CPS, like autonomous
vehicles, selecting the subset of relevant features from a dataset is of the
utmost importance, in order to improve the result achieved by learning methods
and to reduce computation and communication costs. Precisely, feature selection
is the candidate approach, which assumes that data contain a certain number of
redundant or irrelevant attributes that can be eliminated. The quality of our
methods is confirmed by the promising results achieved on two different data
sets. In this work, we propose, for the first time, a federated feature
selection method suitable for being executed in a distributed manner.
Precisely, our results show that a fleet of autonomous vehicles finds a
consensus on the optimal set of features that they exploit to reduce data
transmission up to 99% with negligible information loss.",arxiv
http://arxiv.org/abs/1805.01195v1,2018-05-03T09:59:45Z,2018-05-03T09:59:45Z,BirdNet: a 3D Object Detection Framework from LiDAR information,"Understanding driving situations regardless the conditions of the traffic
scene is a cornerstone on the path towards autonomous vehicles; however,
despite common sensor setups already include complementary devices such as
LiDAR or radar, most of the research on perception systems has traditionally
focused on computer vision. We present a LiDAR-based 3D object detection
pipeline entailing three stages. First, laser information is projected into a
novel cell encoding for bird's eye view projection. Later, both object location
on the plane and its heading are estimated through a convolutional neural
network originally designed for image processing. Finally, 3D oriented
detections are computed in a post-processing phase. Experiments on KITTI
dataset show that the proposed framework achieves state-of-the-art results
among comparable methods. Further tests with different LiDAR sensors in real
scenarios assess the multi-device capabilities of the approach.",arxiv
http://arxiv.org/abs/1607.00971v1,2016-07-04T17:44:13Z,2016-07-04T17:44:13Z,"Can we unify monocular detectors for autonomous driving by using the
  pixel-wise semantic segmentation of CNNs?","Autonomous driving is a challenging topic that requires complex solutions in
perception tasks such as recognition of road, lanes, traffic signs or lights,
vehicles and pedestrians. Through years of research, computer vision has grown
capable of tackling these tasks with monocular detectors that can provide
remarkable detection rates with relatively low processing times. However, the
recent appearance of Convolutional Neural Networks (CNNs) has revolutionized
the computer vision field and has made possible approaches to perform full
pixel-wise semantic segmentation in times close to real time (even on hardware
that can be carried on a vehicle). In this paper, we propose to use full image
segmentation as an approach to simplify and unify most of the detection tasks
required in the perception module of an autonomous vehicle, analyzing major
concerns such as computation time and detection performance.",arxiv
http://arxiv.org/abs/1609.09365v3,2017-04-19T14:31:32Z,2016-09-29T14:39:10Z,"Deep Tracking on the Move: Learning to Track the World from a Moving
  Vehicle using Recurrent Neural Networks","This paper presents an end-to-end approach for tracking static and dynamic
objects for an autonomous vehicle driving through crowded urban environments.
Unlike traditional approaches to tracking, this method is learned end-to-end,
and is able to directly predict a full unoccluded occupancy grid map from raw
laser input data. Inspired by the recently presented DeepTracking approach
[Ondruska, 2016], we employ a recurrent neural network (RNN) to capture the
temporal evolution of the state of the environment, and propose to use Spatial
Transformer modules to exploit estimates of the egomotion of the vehicle. Our
results demonstrate the ability to track a range of objects, including cars,
buses, pedestrians, and cyclists through occlusion, from both moving and
stationary platforms, using a single learned model. Experimental results
demonstrate that the model can also predict the future states of objects from
current inputs, with greater accuracy than previous work.",arxiv
http://arxiv.org/abs/1706.08211v1,2017-06-26T02:59:56Z,2017-06-26T02:59:56Z,End-to-end Learning of Image based Lane-Change Decision,"We propose an image based end-to-end learning framework that helps
lane-change decisions for human drivers and autonomous vehicles. The proposed
system, Safe Lane-Change Aid Network (SLCAN), trains a deep convolutional
neural network to classify the status of adjacent lanes from rear view images
acquired by cameras mounted on both sides of the vehicle. Rather than depending
on any explicit object detection or tracking scheme, SLCAN reads the whole
input image and directly decides whether initiation of the lane-change at the
moment is safe or not. We collected and annotated 77,273 rear side view images
to train and test SLCAN. Experimental results show that the proposed framework
achieves 96.98% classification accuracy although the test images are from
unseen roadways. We also visualize the saliency map to understand which part of
image SLCAN looks at for correct decisions.",arxiv
http://arxiv.org/abs/1712.02294v4,2018-07-12T14:11:40Z,2017-12-06T17:20:21Z,Joint 3D Proposal Generation and Object Detection from View Aggregation,"We present AVOD, an Aggregate View Object Detection network for autonomous
driving scenarios. The proposed neural network architecture uses LIDAR point
clouds and RGB images to generate features that are shared by two subnetworks:
a region proposal network (RPN) and a second stage detector network. The
proposed RPN uses a novel architecture capable of performing multimodal feature
fusion on high resolution feature maps to generate reliable 3D object proposals
for multiple object classes in road scenes. Using these proposals, the second
stage detection network performs accurate oriented 3D bounding box regression
and category classification to predict the extents, orientation, and
classification of objects in 3D space. Our proposed architecture is shown to
produce state of the art results on the KITTI 3D object detection benchmark
while running in real time with a low memory footprint, making it a suitable
candidate for deployment on autonomous vehicles. Code is at:
https://github.com/kujason/avod",arxiv
http://arxiv.org/abs/1801.01235v1,2018-01-04T03:03:45Z,2018-01-04T03:03:45Z,"Depth Not Needed - An Evaluation of RGB-D Feature Encodings for Off-Road
  Scene Understanding by Convolutional Neural Network","Scene understanding for autonomous vehicles is a challenging computer vision
task, with recent advances in convolutional neural networks (CNNs) achieving
results that notably surpass prior traditional feature driven approaches.
However, limited work investigates the application of such methods either
within the highly unstructured off-road environment or to RGBD input data. In
this work, we take an existing CNN architecture designed to perform semantic
segmentation of RGB images of urban road scenes, then adapt and retrain it to
perform the same task with multichannel RGBD images obtained under a range of
challenging off-road conditions. We compare two different stereo matching
algorithms and five different methods of encoding depth information, including
disparity, local normal orientation and HHA (horizontal disparity, height above
ground plane, angle with gravity), to create a total of ten experimental
variations of our dataset, each of which is used to train and test a CNN so
that classification performance can be evaluated against a CNN trained using
standard RGB input.",arxiv
http://arxiv.org/abs/1801.07962v1,2018-01-24T12:45:01Z,2018-01-24T12:45:01Z,An LSTM Network for Highway Trajectory Prediction,"In order to drive safely and efficiently on public roads, autonomous vehicles
will have to understand the intentions of surrounding vehicles, and adapt their
own behavior accordingly. If experienced human drivers are generally good at
inferring other vehicles' motion up to a few seconds in the future, most
current Advanced Driving Assistance Systems (ADAS) are unable to perform such
medium-term forecasts, and are usually limited to high-likelihood situations
such as emergency braking. In this article, we present a first step towards
consistent trajectory prediction by introducing a long short-term memory (LSTM)
neural network, which is capable of accurately predicting future longitudinal
and lateral trajectories for vehicles on highway. Unlike previous work focusing
on a low number of trajectories collected from a few drivers, our network was
trained and validated on the NGSIM US-101 dataset, which contains a total of
800 hours of recorded trajectories in various traffic densities, representing
more than 6000 individual drivers.",arxiv
http://arxiv.org/abs/1803.06077v2,2018-08-31T09:16:33Z,2018-03-16T05:29:12Z,"Real-time Detection, Tracking, and Classification of Moving and
  Stationary Objects using Multiple Fisheye Images","The ability to detect pedestrians and other moving objects is crucial for an
autonomous vehicle. This must be done in real-time with minimum system
overhead. This paper discusses the implementation of a surround view system to
identify moving as well as static objects that are close to the ego vehicle.
The algorithm works on 4 views captured by fisheye cameras which are merged
into a single frame. The moving object detection and tracking solution uses
minimal system overhead to isolate regions of interest (ROIs) containing moving
objects. These ROIs are then analyzed using a deep neural network (DNN) to
categorize the moving object. With deployment and testing on a real car in
urban environments, we have demonstrated the practical feasibility of the
solution. The video demos of our algorithm have been uploaded to Youtube:
https://youtu.be/vpoCfC724iA, https://youtu.be/2X4aqH2bMBs",arxiv
http://arxiv.org/abs/1807.09995v1,2018-07-26T07:57:13Z,2018-07-26T07:57:13Z,"Naturalistic Driver Intention and Path Prediction using Recurrent Neural
  Networks","Understanding the intentions of drivers at intersections is a critical
component for autonomous vehicles. Urban intersections that do not have traffic
signals are a common epicentre of highly variable vehicle movement and
interactions. We present a method for predicting driver intent at urban
intersections through multi-modal trajectory prediction with uncertainty. Our
method is based on recurrent neural networks combined with a mixture density
network output layer. To consolidate the multi-modal nature of the output
probability distribution, we introduce a clustering algorithm that extracts the
set of possible paths that exist in the prediction output, and ranks them
according to likelihood. To verify the method's performance and
generalizability, we present a real-world dataset that consists of over 23,000
vehicles traversing five different intersections, collected using a vehicle
mounted Lidar based tracking system. An array of metrics is used to demonstrate
the performance of the model against several baselines.",arxiv
http://arxiv.org/abs/1809.04730v1,2018-09-13T01:17:54Z,2018-09-13T01:17:54Z,"Adapting Semantic Segmentation Models for Changes in Illumination and
  Camera Perspective","Semantic segmentation using deep neural networks has been widely explored to
generate high-level contextual information for autonomous vehicles. To acquire
a complete $180^\circ$ semantic understanding of the forward surroundings, we
propose to stitch semantic images from multiple cameras with varying
orientations. However, previously trained semantic segmentation models showed
unacceptable performance after significant changes to the camera orientations
and the lighting conditions. To avoid time-consuming hand labeling, we explore
and evaluate the use of data augmentation techniques, specifically skew and
gamma correction, from a practical real-world standpoint to extend the existing
model and provide more robust performance. The presented experimental results
have shown significant improvements with varying illumination and camera
perspective changes.",arxiv
http://arxiv.org/abs/1809.05408v4,2019-06-26T14:06:42Z,2018-09-14T13:27:53Z,Socially Aware Kalman Neural Networks for Trajectory Prediction,"Trajectory prediction is a critical technique in the navigation of robots and
autonomous vehicles. However, the complex traffic and dynamic uncertainties
yield challenges in the effectiveness and robustness in modeling. We purpose a
data-driven approach socially aware Kalman neural networks (SAKNN) where the
interaction layer and the Kalman layer are embedded in the architecture,
resulting in a class of architectures with huge potential to directly learn
from high variance sensor input and robustly generate low variance outcomes.
The evaluation of our approach on NGSIM dataset demonstrates that SAKNN
performs state-of-the-art on prediction effectiveness in a relatively long-term
horizon and significantly improves the signal-to-noise ratio of the predicted
signal.",arxiv
http://arxiv.org/abs/1812.08273v1,2018-12-19T22:25:52Z,2018-12-19T22:25:52Z,Analog Signal Processing Using Stochastic Magnets,"We present a low barrier magnet based compact hardware unit for analog
stochastic neurons and demonstrate its use as a building-block for neuromorphic
hardware. By coupling circular magnetic tunnel junctions (MTJs) with a CMOS
based analog buffer, we show that these units can act as leaky-integrate-and
fire (LIF) neurons, a model of biological neural networks particularly suited
for temporal inferencing and pattern recognition. We demonstrate examples of
temporal sequence learning, processing, and prediction tasks in real time, as a
proof of concept demonstration of scalable and adaptive signal-processors.
Efficient non von-Neumann hardware implementation of such processors can open
up a pathway for integration of hardware based cognition in a wide variety of
emerging systems such as IoT, industrial controls, bio- and photo-sensors, and
Unmanned Autonomous Vehicles.",arxiv
http://arxiv.org/abs/1812.09395v3,2019-01-22T20:29:59Z,2018-12-21T22:27:10Z,"Multi-Step Prediction of Occupancy Grid Maps with Recurrent Neural
  Networks","We investigate the multi-step prediction of the drivable space, represented
by Occupancy Grid Maps (OGMs), for autonomous vehicles. Our motivation is that
accurate multi-step prediction of the drivable space can efficiently improve
path planning and navigation resulting in safe, comfortable and optimum paths
in autonomous driving. We train a variety of Recurrent Neural Network (RNN)
based architectures on the OGM sequences from the KITTI dataset. The results
demonstrate significant improvement of the prediction accuracy using our
proposed difference learning method, incorporating motion related features,
over the state of the art. We remove the egomotion from the OGM sequences by
transforming them into a common frame. Although in the transformed sequences
the KITTI dataset is heavily biased toward static objects, by learning the
difference between subsequent OGMs, our proposed method provides accurate
prediction over both the static and moving objects.",arxiv
http://arxiv.org/abs/1901.00466v1,2019-01-02T17:57:50Z,2019-01-02T17:57:50Z,Learning Generalizable Physical Dynamics of 3D Rigid Objects,"Humans have a remarkable ability to predict the effect of physical
interactions on the dynamics of objects. Endowing machines with this ability
would allow important applications in areas like robotics and autonomous
vehicles. In this work, we focus on predicting the dynamics of 3D rigid
objects, in particular an object's final resting position and total rotation
when subjected to an impulsive force. Different from previous work, our
approach is capable of generalizing to unseen object shapes - an important
requirement for real-world applications. To achieve this, we represent object
shape as a 3D point cloud that is used as input to a neural network, making our
approach agnostic to appearance variation. The design of our network is
informed by an understanding of physical laws. We train our model with data
from a physics engine that simulates the dynamics of a large number of shapes.
Experiments show that we can accurately predict the resting position and total
rotation for unseen object geometries.",arxiv
http://arxiv.org/abs/1901.04899v1,2018-12-14T00:43:58Z,2018-12-14T00:43:58Z,"Conversational Intent Understanding for Passengers in Autonomous
  Vehicles","Understanding passenger intents and extracting relevant slots are important
building blocks towards developing a contextual dialogue system responsible for
handling certain vehicle-passenger interactions in autonomous vehicles (AV).
When the passengers give instructions to AMIE (Automated-vehicle Multimodal
In-cabin Experience), the agent should parse such commands properly and trigger
the appropriate functionality of the AV system. In our AMIE scenarios, we
describe usages and support various natural commands for interacting with the
vehicle. We collected a multimodal in-cabin data-set with multi-turn dialogues
between the passengers and AMIE using a Wizard-of-Oz scheme. We explored
various recent Recurrent Neural Networks (RNN) based techniques and built our
own hierarchical models to recognize passenger intents along with relevant
slots associated with the action to be performed in AV scenarios. Our
experimental results achieved F1-score of 0.91 on utterance-level intent
recognition and 0.96 on slot extraction models.",arxiv
http://arxiv.org/abs/1902.05974v1,2019-02-15T19:42:45Z,2019-02-15T19:42:45Z,DeepFault: Fault Localization for Deep Neural Networks,"Deep Neural Networks (DNNs) are increasingly deployed in safety-critical
applications including autonomous vehicles and medical diagnostics. To reduce
the residual risk for unexpected DNN behaviour and provide evidence for their
trustworthy operation, DNNs should be thoroughly tested. The DeepFault whitebox
DNN testing approach presented in our paper addresses this challenge by
employing suspiciousness measures inspired by fault localization to establish
the hit spectrum of neurons and identify suspicious neurons whose weights have
not been calibrated correctly and thus are considered responsible for
inadequate DNN performance. DeepFault also uses a suspiciousness-guided
algorithm to synthesize new inputs, from correctly classified inputs, that
increase the activation values of suspicious neurons. Our empirical evaluation
on several DNN instances trained on MNIST and CIFAR-10 datasets shows that
DeepFault is effective in identifying suspicious neurons. Also, the inputs
synthesized by DeepFault closely resemble the original inputs, exercise the
identified suspicious neurons and are highly adversarial.",arxiv
http://arxiv.org/abs/1902.10928v4,2021-01-25T16:59:51Z,2019-02-28T07:10:30Z,Interaction-aware Kalman Neural Networks for Trajectory Prediction,"Forecasting the motion of surrounding obstacles (vehicles, bicycles,
pedestrians and etc.) benefits the on-road motion planning for intelligent and
autonomous vehicles. Complex scenes always yield great challenges in modeling
the patterns of surrounding traffic. For example, one main challenge comes from
the intractable interaction effects in a complex traffic system. In this paper,
we propose a multi-layer architecture Interaction-aware Kalman Neural Networks
(IaKNN) which involves an interaction layer for resolving high-dimensional
traffic environmental observations as interaction-aware accelerations, a motion
layer for transforming the accelerations to interaction aware trajectories, and
a filter layer for estimating future trajectories with a Kalman filter network.
Attributed to the multiple traffic data sources, our end-to-end trainable
approach technically fuses dynamic and interaction-aware trajectories boosting
the prediction performance. Experiments on the NGSIM dataset demonstrate that
IaKNN outperforms the state-of-the-art methods in terms of effectiveness for
traffic trajectory prediction.",arxiv
http://arxiv.org/abs/1904.10390v1,2019-04-23T15:42:00Z,2019-04-23T15:42:00Z,"Minimizing Perceived Image Quality Loss Through Adversarial Attack
  Scoping","Neural networks are now actively being used for computer vision tasks in
security critical areas such as robotics, face recognition, autonomous vehicles
yet their safety is under question after the discovery of adversarial attacks.
In this paper we develop simplified adversarial attack algorithms based on a
scoping idea, which enables execution of fast adversarial attacks that minimize
structural image quality (SSIM) loss, allows performing efficient transfer
attacks with low target inference network call count and opens a possibility of
an attack using pen-only drawings on a paper for the MNIST handwritten digit
dataset. The presented adversarial attack analysis and the idea of attack
scoping can be easily expanded to different datasets, thus making the paper's
results applicable to a wide range of practical tasks.",arxiv
http://arxiv.org/abs/1906.02277v1,2019-06-05T19:45:37Z,2019-06-05T19:45:37Z,"A Data Driven Method of Feedforward Compensator Optimization for
  Autonomous Vehicle Control","A reliable controller is critical for execution of safe and smooth maneuvers
of an autonomous vehicle. The controller must be robust to external
disturbances, such as road surface, weather, wind conditions, and so on. It
also needs to deal with internal variations of vehicle sub-systems, including
powertrain inefficiency, measurement errors, time delay, etc. These factors
introduce issues in controller performance. In this paper, a feed-forward
compensator is designed via a data-driven method to model and optimize the
controller performance. Principal Component Analysis (PCA) is applied for
extracting influential features, after which a Time Delay Neural Network is
adopted to predict control errors over a future time horizon. Based on the
predicted error, a feedforward compensator is then designed to improve control
performance. Simulation results in different scenarios show that, with the help
of with the proposed feedforward compensator, the maximum path tracking error
and the steering wheel angle oscillation are improved by 44.4% and 26.7%,
respectively.",arxiv
http://arxiv.org/abs/1906.11873v1,2019-06-12T16:22:41Z,2019-06-12T16:22:41Z,"VolMap: A Real-time Model for Semantic Segmentation of a LiDAR
  surrounding view","This paper introduces VolMap, a real-time approach for the semantic
segmentation of a 3D LiDAR surrounding view system in autonomous vehicles. We
designed an optimized deep convolution neural network that can accurately
segment the point cloud produced by a 360\degree{} LiDAR setup, where the input
consists of a volumetric bird-eye view with LiDAR height layers used as input
channels. We further investigated the usage of multi-LiDAR setup and its effect
on the performance of the semantic segmentation task. Our evaluations are
carried out on a large scale 3D object detection benchmark containing a LiDAR
cocoon setup, along with KITTI dataset, where the per-point segmentation labels
are derived from 3D bounding boxes. We show that VolMap achieved an excellent
balance between high accuracy and real-time running on CPU.",arxiv
http://arxiv.org/abs/1907.01038v1,2019-07-01T19:42:37Z,2019-07-01T19:42:37Z,AVFI: Fault Injection for Autonomous Vehicles,"Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S.
roads, offering the promise of improvements in traffic management, safety, and
the comfort and efficiency of vehicular travel. With this increasing popularity
and ubiquitous deployment, resilience has become a critical requirement for
public acceptance and adoption. Recent studies into the resilience of AVs have
shown that though the AV systems are improving over time, they have not reached
human levels of automation. Prior work in this area has studied the safety and
resilience of individual components of the AV system (e.g., testing of neural
networks powering the perception function). However, methods for holistic
end-to-end resilience assessment of AV systems are still non-existent.",arxiv
http://arxiv.org/abs/1907.04361v3,2019-09-16T14:44:20Z,2019-07-09T18:32:21Z,Estimating Pedestrian Moving State Based on Single 2D Body Pose,"The Crossing or Not-Crossing (C/NC) problem is important to autonomous
vehicles (AVs) for safe vehicle/pedestrian interactions. However, this problem
setup often ignores pedestrians walking along the direction of the vehicles'
movement (LONG). To enhance the AVs' awareness of pedestrians behavior, we make
the first step towards extending the C/NC to the C/NC/LONG problem and
recognize them based on single body pose. In contrast, previous C/NC state
classifiers depend on multiple poses or contextual information. Our proposed
shallow neural network classifier aims to recognize these three states swiftly.
We tested it on the JAAD dataset and reported an average 81.23% accuracy.
Furthermore, this model can be integrated with different sensors and algorithms
that provide 2D pedestrian body pose so that it is able to function across
multiple light and weather conditions.",arxiv
http://arxiv.org/abs/1907.07160v1,2019-07-16T17:35:53Z,2019-07-16T17:35:53Z,"EnforceNet: Monocular Camera Localization in Large Scale Indoor Sparse
  LiDAR Point Cloud","Pose estimation is a fundamental building block for robotic applications such
as autonomous vehicles, UAV, and large scale augmented reality. It is also a
prohibitive factor for those applications to be in mass production, since the
state-of-the-art, centimeter-level pose estimation often requires long mapping
procedures and expensive localization sensors, e.g. LiDAR and high precision
GPS/IMU, etc. To overcome the cost barrier, we propose a neural network based
solution to localize a consumer degree RGB camera within a prior sparse LiDAR
map with comparable centimeter-level precision. We achieved it by introducing a
novel network module, which we call resistor module, to enforce the network
generalize better, predicts more accurately, and converge faster. Such results
are benchmarked by several datasets we collected in the large scale indoor
parking garage scenes. We plan to open both the data and the code for the
community to join the effort to advance this field.",arxiv
http://arxiv.org/abs/1909.03854v1,2019-09-09T13:40:12Z,2019-09-09T13:40:12Z,A Convolutional Neural Network Approach Towards Self-Driving Cars,"A convolutional neural network (CNN) approach is used to implement a level 2
autonomous vehicle by mapping pixels from the camera input to the steering
commands. The network automatically learns the maximum variable features from
the camera input, hence requires minimal human intervention. Given realistic
frames as input, the driving policy trained on the dataset by NVIDIA and
Udacity can adapt to real-world driving in a controlled environment. The CNN is
tested on the CARLA open-source driving simulator. Details of a beta-testing
platform are also presented, which consists of an ultrasonic sensor for
obstacle detection and an RGBD camera for real-time position monitoring at
10Hz. Arduino Mega and Raspberry Pi are used for motor control and processing
respectively to output the steering angle, which is converted to angular
velocity for steering.",arxiv
http://arxiv.org/abs/1909.05665v2,2019-09-29T06:34:25Z,2019-09-09T18:01:36Z,"Cooperation-Aware Lane Change Maneuver in Dense Traffic based on Model
  Predictive Control with Recurrent Neural Network","This paper presents a real-time lane change control framework of autonomous
driving in dense traffic, which exploits cooperative behaviors of other
drivers. This paper focuses on heavy traffic where vehicles cannot change lanes
without cooperating with other drivers. In this case, classical robust controls
may not apply since there is no safe area to merge to without interacting with
the other drivers. That said, modeling complex and interactive human behaviors
is highly non-trivial from the perspective of control engineers. We propose a
mathematical control framework based on Model Predictive Control (MPC)
encompassing a state-of-the-art Recurrent Neural network (RNN) architecture. In
particular, RNN predicts interactive motions of other drivers in response to
potential actions of the autonomous vehicle, which are then systematically
evaluated in safety constraints. We also propose a real-time heuristic
algorithm to find locally optimal control inputs. Finally, quantitative and
qualitative analysis on simulation studies are presented to illustrate the
benefits of the proposed framework.",arxiv
http://arxiv.org/abs/1910.04862v1,2019-09-29T17:02:49Z,2019-09-29T17:02:49Z,"Vision-Based Autonomous Vehicle Control using the Two-Point Visual
  Driver Control Model","This work proposes a new self-driving framework that uses a human driver
control model, whose feature-input values are extracted from images using deep
convolutional neural networks (CNNs). The development of image processing
techniques using CNNs along with accelerated computing hardware has recently
enabled real-time detection of these feature-input values. The use of human
driver models can lead to more ""natural"" driving behavior of self-driving
vehicles. Specifically, we use the well-known two-point visual driver control
model as the controller, and we use a top-down lane cost map CNN and the YOLOv2
CNN to extract feature-input values. This framework relies exclusively on
inputs from low-cost sensors like a monocular camera and wheel speed sensors.
We experimentally validate the proposed framework on an outdoor track using a
1/5th-scale autonomous vehicle platform.",arxiv
http://arxiv.org/abs/2002.10570v2,2020-06-27T14:29:00Z,2020-02-24T22:17:25Z,"Real-time Fusion Network for RGB-D Semantic Segmentation Incorporating
  Unexpected Obstacle Detection for Road-driving Images","Semantic segmentation has made striking progress due to the success of deep
convolutional neural networks. Considering the demands of autonomous driving,
real-time semantic segmentation has become a research hotspot these years.
However, few real-time RGB-D fusion semantic segmentation studies are carried
out despite readily accessible depth information nowadays. In this paper, we
propose a real-time fusion semantic segmentation network termed RFNet that
effectively exploits complementary cross-modal information. Building on an
efficient network architecture, RFNet is capable of running swiftly, which
satisfies autonomous vehicles applications. Multi-dataset training is leveraged
to incorporate unexpected small obstacle detection, enriching the recognizable
classes required to face unforeseen hazards in the real world. A comprehensive
set of experiments demonstrates the effectiveness of our framework. On
Cityscapes, Our method outperforms previous state-of-the-art semantic
segmenters, with excellent accuracy and 22Hz inference speed at the full
2048x1024 resolution, outperforming most existing RGB-D networks.",arxiv
http://arxiv.org/abs/2005.08637v2,2020-05-19T14:42:30Z,2020-05-18T12:20:17Z,"Building BROOK: A Multi-modal and Facial Video Database for
  Human-Vehicle Interaction Research","With the growing popularity of Autonomous Vehicles, more opportunities have
bloomed in the context of Human-Vehicle Interactions. However, the lack of
comprehensive and concrete database support for such specific use case limits
relevant studies in the whole design spaces. In this paper, we present our
work-in-progress BROOK, a public multi-modal database with facial video
records, which could be used to characterize drivers' affective states and
driving styles. We first explain how we over-engineer such database in details,
and what we have gained through a ten-month study. Then we showcase a Neural
Network-based predictor, leveraging BROOK, which supports multi-modal
prediction (including physiological data of heart rate and skin conductance and
driving status data of speed)through facial videos. Finally, we discuss related
issues when building such a database and our future directions in the context
of BROOK. We believe BROOK is an essential building block for future
Human-Vehicle Interaction Research.",arxiv
http://arxiv.org/abs/2005.12469v3,2021-06-09T02:36:25Z,2020-05-26T01:10:01Z,"CARPe Posterum: A Convolutional Approach for Real-time Pedestrian Path
  Prediction","Pedestrian path prediction is an essential topic in computer vision and video
understanding. Having insight into the movement of pedestrians is crucial for
ensuring safe operation in a variety of applications including autonomous
vehicles, social robots, and environmental monitoring. Current works in this
area utilize complex generative or recurrent methods to capture many possible
futures. However, despite the inherent real-time nature of predicting future
paths, little work has been done to explore accurate and computationally
efficient approaches for this task. To this end, we propose a convolutional
approach for real-time pedestrian path prediction, CARPe. It utilizes a
variation of Graph Isomorphism Networks in combination with an agile
convolutional neural network design to form a fast and accurate path prediction
approach. Notable results in both inference speed and prediction accuracy are
achieved, improving FPS considerably in comparison to current state-of-the-art
methods while delivering competitive accuracy on well-known path prediction
datasets.",arxiv
http://arxiv.org/abs/2006.01250v6,2021-06-21T18:21:58Z,2020-05-09T09:41:46Z,RUHSNet: 3D Object Detection Using Lidar Data in Real Time,"In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects in
point cloud data. We compare the results with different backbone architectures
including the standard ones like VGG, ResNet, Inception with our backbone. Also
we present the optimization and ablation studies including designing an
efficient anchor. We use the Kitti 3D Birds Eye View dataset for benchmarking
and validating our results. Our work surpasses the state of the art in this
domain both in terms of average precision and speed running at > 30 FPS. This
makes it a feasible option to be deployed in real time applications including
self driving cars.",arxiv
http://arxiv.org/abs/2007.12036v1,2020-07-23T14:31:25Z,2020-07-23T14:31:25Z,Implicit Latent Variable Model for Scene-Consistent Motion Forecasting,"In order to plan a safe maneuver an autonomous vehicle must accurately
perceive its environment, and understand the interactions among traffic
participants. In this paper, we aim to learn scene-consistent motion forecasts
of complex urban traffic directly from sensor data. In particular, we propose
to characterize the joint distribution over future trajectories via an implicit
latent variable model. We model the scene as an interaction graph and employ
powerful graph neural networks to learn a distributed latent representation of
the scene. Coupled with a deterministic decoder, we obtain trajectory samples
that are consistent across traffic participants, achieving state-of-the-art
results in motion forecasting and interaction understanding. Last but not
least, we demonstrate that our motion forecasts result in safer and more
comfortable motion planning.",arxiv
http://arxiv.org/abs/2007.16072v1,2020-07-31T13:40:41Z,2020-07-31T13:40:41Z,Traffic Control Gesture Recognition for Autonomous Vehicles,"A car driver knows how to react on the gestures of the traffic officers.
Clearly, this is not the case for the autonomous vehicle, unless it has road
traffic control gesture recognition functionalities. In this work, we address
the limitation of the existing autonomous driving datasets to provide learning
data for traffic control gesture recognition. We introduce a dataset that is
based on 3D body skeleton input to perform traffic control gesture
classification on every time step. Our dataset consists of 250 sequences from
several actors, ranging from 16 to 90 seconds per sequence. To evaluate our
dataset, we propose eight sequential processing models based on deep neural
networks such as recurrent networks, attention mechanism, temporal
convolutional networks and graph convolutional networks. We present an
extensive evaluation and analysis of all approaches for our dataset, as well as
real-world quantitative evaluation. The code and dataset is publicly available.",arxiv
http://arxiv.org/abs/2009.12975v1,2020-09-27T22:39:00Z,2020-09-27T22:39:00Z,"VATLD: A Visual Analytics System to Assess, Understand and Improve
  Traffic Light Detection","Traffic light detection is crucial for environment perception and
decision-making in autonomous driving. State-of-the-art detectors are built
upon deep Convolutional Neural Networks (CNNs) and have exhibited promising
performance. However, one looming concern with CNN based detectors is how to
thoroughly evaluate the performance of accuracy and robustness before they can
be deployed to autonomous vehicles. In this work, we propose a visual analytics
system, VATLD, equipped with a disentangled representation learning and
semantic adversarial learning, to assess, understand, and improve the accuracy
and robustness of traffic light detectors in autonomous driving applications.
The disentangled representation learning extracts data semantics to augment
human cognition with human-friendly visual summarization, and the semantic
adversarial learning efficiently exposes interpretable robustness risks and
enables minimal human interaction for actionable insights. We also demonstrate
the effectiveness of various performance improvement strategies derived from
actionable insights with our visual analytics system, VATLD, and illustrate
some practical implications for safety-critical applications in autonomous
driving.",arxiv
http://arxiv.org/abs/2010.13294v2,2020-11-04T14:35:12Z,2020-10-26T02:51:00Z,"Global Image Segmentation Process using Machine Learning algorithm &
  Convolution Neural Network method for Self- Driving Vehicles","In autonomous Vehicles technology Image segmentation was a major problem in
visual perception. This image segmentation process is mainly used in medical
applications. Here we adopted an image segmentation process to visual
perception tasks for predicting the agents on the surrounding environment,
identifying the road boundaries and tracking the line markings. Main objective
of the paper is to divide the input images using the image segmentation process
and Convolution Neural Network method for efficient results of visual
perception. For Sampling assume a local city data-set samples and validation
process done in Jupyter Notebook using Python language. We proposed this image
segmentation method planning to standard and further the development of
state-of-the art methods for visual inspection system understanding. The
experimental results achieves 73% mean IOU. Our method also achieves 90 FPS
inference speed and using a NVDIA GeForce GTX 1050 GPU.",arxiv
http://arxiv.org/abs/2011.09045v2,2021-05-24T00:38:06Z,2020-11-18T02:34:26Z,"Double-Prong ConvLSTM for Spatiotemporal Occupancy Prediction in Dynamic
  Environments","Predicting the future occupancy state of an environment is important to
enable informed decisions for autonomous vehicles. Common challenges in
occupancy prediction include vanishing dynamic objects and blurred predictions,
especially for long prediction horizons. In this work, we propose a
double-prong neural network architecture to predict the spatiotemporal
evolution of the occupancy state. One prong is dedicated to predicting how the
static environment will be observed by the moving ego vehicle. The other prong
predicts how the dynamic objects in the environment will move. Experiments
conducted on the real-world Waymo Open Dataset indicate that the fused output
of the two prongs is capable of retaining dynamic objects and reducing
blurriness in the predictions for longer time horizons than baseline models.",arxiv
http://arxiv.org/abs/2101.02974v1,2021-01-08T11:56:12Z,2021-01-08T11:56:12Z,Approaching Neural Network Uncertainty Realism,"Statistical models are inherently uncertain. Quantifying or at least
upper-bounding their uncertainties is vital for safety-critical systems such as
autonomous vehicles. While standard neural networks do not report this
information, several approaches exist to integrate uncertainty estimates into
them. Assessing the quality of these uncertainty estimates is not
straightforward, as no direct ground truth labels are available. Instead,
implicit statistical assessments are required. For regression, we propose to
evaluate uncertainty realism -- a strict quality criterion -- with a
Mahalanobis distance-based statistical test. An empirical evaluation reveals
the need for uncertainty measures that are appropriate to upper-bound
heavy-tailed empirical errors. Alongside, we transfer the variational U-Net
classification architecture to standard supervised image-to-image tasks. We
adopt it to the automotive domain and show that it significantly improves
uncertainty realism compared to a plain encoder-decoder model.",arxiv
http://arxiv.org/abs/2102.06361v2,2021-05-29T14:00:58Z,2021-02-12T06:29:28Z,"SCOUT: Socially-COnsistent and UndersTandable Graph Attention Network
  for Trajectory Prediction of Vehicles and VRUs","Autonomous vehicles navigate in dynamically changing environments under a
wide variety of conditions, being continuously influenced by surrounding
objects. Modelling interactions among agents is essential for accurately
forecasting other agents' behaviour and achieving safe and comfortable motion
planning. In this work, we propose SCOUT, a novel Attention-based Graph Neural
Network that uses a flexible and generic representation of the scene as a graph
for modelling interactions, and predicts socially-consistent trajectories of
vehicles and Vulnerable Road Users (VRUs) under mixed traffic conditions. We
explore three different attention mechanisms and test our scheme with both
bird-eye-view and on-vehicle urban data, achieving superior performance than
existing state-of-the-art approaches on InD and ApolloScape Trajectory
benchmarks. Additionally, we evaluate our model's flexibility and
transferability by testing it under completely new scenarios on RounD dataset.
The importance and influence of each interaction in the final prediction is
explored by means of Integrated Gradients technique and the visualization of
the attention learned.",arxiv
http://arxiv.org/abs/2102.12967v1,2021-02-25T16:14:47Z,2021-02-25T16:14:47Z,"Statistical Testing for Efficient Out of Distribution Detection in Deep
  Neural Networks","Commonly, Deep Neural Networks (DNNs) generalize well on samples drawn from a
distribution similar to that of the training set. However, DNNs' predictions
are brittle and unreliable when the test samples are drawn from a dissimilar
distribution. This presents a major concern for deployment in real-world
applications, where such behavior may come at a great cost -- as in the case of
autonomous vehicles or healthcare applications.
  This paper frames the Out Of Distribution (OOD) detection problem in DNN as a
statistical hypothesis testing problem. Unlike previous OOD detection
heuristics, our framework is guaranteed to maintain the false positive rate
(detecting OOD as in-distribution) for test data. We build on this framework to
suggest a novel OOD procedure based on low-order statistics. Our method
achieves comparable or better than state-of-the-art results on well-accepted
OOD benchmarks without retraining the network parameters -- and at a fraction
of the computational cost.",arxiv
http://arxiv.org/abs/2103.15456v1,2021-03-29T09:40:37Z,2021-03-29T09:40:37Z,"Monitoring Object Detection Abnormalities via Data-Label and
  Post-Algorithm Abstractions","While object detection modules are essential functionalities for any
autonomous vehicle, the performance of such modules that are implemented using
deep neural networks can be, in many cases, unreliable. In this paper, we
develop abstraction-based monitoring as a logical framework for filtering
potentially erroneous detection results. Concretely, we consider two types of
abstraction, namely data-label abstraction and post-algorithm abstraction.
Operated on the training dataset, the construction of data-label abstraction
iterates each input, aggregates region-wise information over its associated
labels, and stores the vector under a finite history length. Post-algorithm
abstraction builds an abstract transformer for the tracking algorithm. Elements
being associated together by the abstract transformer can be checked against
consistency over their original values. We have implemented the overall
framework to a research prototype and validated it using publicly available
object detection datasets.",arxiv
http://arxiv.org/abs/2104.07182v1,2021-04-15T00:41:30Z,2021-04-15T00:41:30Z,Convolutions for Spatial Interaction Modeling,"In many different fields interactions between objects play a critical role in
determining their behavior. Graph neural networks (GNNs) have emerged as a
powerful tool for modeling interactions, although often at the cost of adding
considerable complexity and latency. In this paper, we consider the problem of
spatial interaction modeling in the context of predicting the motion of actors
around autonomous vehicles, and investigate alternative approaches to GNNs. We
revisit convolutions and show that they can demonstrate comparable performance
to graph networks in modeling spatial interactions with lower latency, thus
providing an effective and efficient alternative in time-critical systems.
Moreover, we propose a novel interaction loss to further improve the
interaction modeling of the considered methods.",arxiv
http://arxiv.org/abs/2104.12417v1,2021-04-26T09:15:28Z,2021-04-26T09:15:28Z,Model Guided Road Intersection Classification,"Understanding complex scenarios from in-vehicle cameras is essential for
safely operating autonomous driving systems in densely populated areas. Among
these, intersection areas are one of the most critical as they concentrate a
considerable number of traffic accidents and fatalities. Detecting and
understanding the scene configuration of these usually crowded areas is then of
extreme importance for both autonomous vehicles and modern ADAS aimed at
preventing road crashes and increasing the safety of vulnerable road users.
This work investigates inter-section classification from RGB images using
well-consolidate neural network approaches along with a method to enhance the
results based on the teacher/student training paradigm. An extensive
experimental activity aimed at identifying the best input configuration and
evaluating different network parameters on both the well-known KITTI dataset
and the new KITTI-360 sequences shows that our method outperforms current
state-of-the-art approaches on a per-frame basis and prove the effectiveness of
the proposed learning scheme.",arxiv
http://arxiv.org/abs/2109.12764v1,2021-09-27T02:20:38Z,2021-09-27T02:20:38Z,"Graph-Based Spatial-Temporal Convolutional Network for Vehicle
  Trajectory Prediction in Autonomous Driving","Forecasting the trajectories of neighbor vehicles is a crucial step for
decision making and motion planning of autonomous vehicles. This paper proposes
a graph-based spatial-temporal convolutional network (GSTCN) to predict future
trajectory distributions of all neighbor vehicles using past trajectories. This
network tackles the spatial interactions using a graph convolutional network
(GCN), and captures the temporal features with a convolutional neural network
(CNN). The spatial-temporal features are encoded and decoded by a gated
recurrent unit (GRU) network to generate future trajectory distributions.
Besides, we propose a weighted adjacency matrix to describe the intensities of
mutual influence between vehicles, and the ablation study demonstrates the
effectiveness of our proposed scheme. Our network is evaluated on two
real-world freeway trajectory datasets: I-80 and US-101 in the Next Generation
Simulation (NGSIM).Comparisons in three aspects, including prediction errors,
model sizes, and inference speeds, show that our network can achieve
state-of-the-art performance.",arxiv
http://arxiv.org/abs/2110.03968v1,2021-10-08T08:32:37Z,2021-10-08T08:32:37Z,How to Build a Curb Dataset with LiDAR Data for Autonomous Driving,"Curbs are one of the essential elements of urban and highway traffic
environments. Robust curb detection provides road structure information for
motion planning in an autonomous driving system. Commonly, video cameras and 3D
LiDARs are mounted on autonomous vehicles for curb detection. However,
camera-based methods suffer from challenging illumination conditions. During
the long period of time before wide application of Deep Neural Network (DNN)
with point clouds, LiDAR-based curb detection methods are based on hand-crafted
features, which suffer from poor detection in some complex scenes. Recently,
DNN-based dynamic object detection using LiDAR data has become prevalent, while
few works pay attention to curb detection with a DNN approach due to lack of
labeled data. A dataset with curb annotations or an efficient curb labeling
approach, hence, is of high demand...",arxiv
http://arxiv.org/abs/1811.10119v2,2019-06-11T20:51:25Z,2018-11-25T23:45:30Z,Variational End-to-End Navigation and Localization,"Deep learning has revolutionized the ability to learn ""end-to-end"" autonomous
vehicle control directly from raw sensory data. While there have been recent
extensions to handle forms of navigation instruction, these works are unable to
capture the full distribution of possible actions that could be taken and to
reason about localization of the robot within the environment. In this paper,
we extend end-to-end driving networks with the ability to perform
point-to-point navigation as well as probabilistic localization using only
noisy GPS data. We define a novel variational network capable of learning from
raw camera data of the environment as well as higher level roadmaps to predict
(1) a full probability distribution over the possible control commands; and (2)
a deterministic control command capable of navigating on the route specified
within the map. Additionally, we formulate how our model can be used to
localize the robot according to correspondences between the map and the
observed visual road topology, inspired by the rough localization that human
drivers can perform. We test our algorithms on real-world driving data that the
vehicle has never driven through before, and integrate our point-to-point
navigation algorithms onboard a full-scale autonomous vehicle for real-time
performance. Our localization algorithm is also evaluated over a new set of
roads and intersections to demonstrates rough pose localization even in
situations without any GPS prior.",arxiv
http://arxiv.org/abs/1904.04375v3,2019-05-12T02:38:13Z,2019-04-08T21:51:49Z,"Controlling Steering Angle for Cooperative Self-driving Vehicles
  utilizing CNN and LSTM-based Deep Networks","A fundamental challenge in autonomous vehicles is adjusting the steering
angle at different road conditions. Recent state-of-the-art solutions
addressing this challenge include deep learning techniques as they provide
end-to-end solution to predict steering angles directly from the raw input
images with higher accuracy. Most of these works ignore the temporal
dependencies between the image frames. In this paper, we tackle the problem of
utilizing multiple sets of images shared between two autonomous vehicles to
improve the accuracy of controlling the steering angle by considering the
temporal dependencies between the image frames. This problem has not been
studied in the literature widely. We present and study a new deep architecture
to predict the steering angle automatically by using Long-Short-Term-Memory
(LSTM) in our deep architecture. Our deep architecture is an end-to-end network
that utilizes CNN, LSTM and fully connected (FC) layers and it uses both
present and futures images (shared by a vehicle ahead via Vehicle-to-Vehicle
(V2V) communication) as input to control the steering angle. Our model
demonstrates the lowest error when compared to the other existing approaches in
the literature.",arxiv
http://arxiv.org/abs/2006.16471v4,2021-02-12T02:16:15Z,2020-06-30T02:05:10Z,"Object Detection Under Rainy Conditions for Autonomous Vehicles: A
  Review of State-of-the-Art and Emerging Techniques","Advanced automotive active-safety systems, in general, and autonomous
vehicles, in particular, rely heavily on visual data to classify and localize
objects such as pedestrians, traffic signs and lights, and other nearby cars,
to assist the corresponding vehicles maneuver safely in their environments.
However, the performance of object detection methods could degrade rather
significantly under challenging weather scenarios including rainy conditions.
Despite major advancements in the development of deraining approaches, the
impact of rain on object detection has largely been understudied, especially in
the context of autonomous driving. The main objective of this paper is to
present a tutorial on state-of-the-art and emerging techniques that represent
leading candidates for mitigating the influence of rainy conditions on an
autonomous vehicle's ability to detect objects. Our goal includes surveying and
analyzing the performance of object detection methods trained and tested using
visual data captured under clear and rainy conditions. Moreover, we survey and
evaluate the efficacy and limitations of leading deraining approaches,
deep-learning based domain adaptation, and image translation frameworks that
are being considered for addressing the problem of object detection under rainy
conditions. Experimental results of a variety of the surveyed techniques are
presented as part of this tutorial.",arxiv
http://arxiv.org/abs/2103.06113v3,2021-08-09T10:31:19Z,2021-03-10T15:06:11Z,"GRIT: Fast, Interpretable, and Verifiable Goal Recognition with Learned
  Decision Trees for Autonomous Driving","It is important for autonomous vehicles to have the ability to infer the
goals of other vehicles (goal recognition), in order to safely interact with
other vehicles and predict their future trajectories. This is a difficult
problem, especially in urban environments with interactions between many
vehicles. Goal recognition methods must be fast to run in real time and make
accurate inferences. As autonomous driving is safety-critical, it is important
to have methods which are human interpretable and for which safety can be
formally verified. Existing goal recognition methods for autonomous vehicles
fail to satisfy all four objectives of being fast, accurate, interpretable and
verifiable. We propose Goal Recognition with Interpretable Trees (GRIT), a goal
recognition system which achieves these objectives. GRIT makes use of decision
trees trained on vehicle trajectory data. We evaluate GRIT on two datasets,
showing that GRIT achieved fast inference speed and comparable accuracy to two
deep learning baselines, a planning-based goal recognition method, and an
ablation of GRIT. We show that the learned trees are human interpretable and
demonstrate how properties of GRIT can be formally verified using a
satisfiability modulo theories (SMT) solver.",arxiv
http://arxiv.org/abs/1907.11394v1,2019-07-26T06:36:18Z,2019-07-26T06:36:18Z,"A Comparative Study of High-Recall Real-Time Semantic Segmentation Based
  on Swift Factorized Network","Semantic Segmentation (SS) is the task to assign a semantic label to each
pixel of the observed images, which is of crucial significance for autonomous
vehicles, navigation assistance systems for the visually impaired, and
augmented reality devices. However, there is still a long way for SS to be put
into practice as there are two essential challenges that need to be addressed:
efficiency and evaluation criterions for practical application. For specific
application scenarios, different criterions need to be adopted. Recall rate is
an important criterion for many tasks like autonomous vehicles. For autonomous
vehicles, we need to focus on the detection of the traffic objects like cars,
buses, and pedestrians, which should be detected with high recall rates. In
other words, it is preferable to detect it wrongly than miss it, because the
other traffic objects will be dangerous if the algorithm miss them and segment
them as safe roadways. In this paper, our main goal is to explore possible
methods to attain high recall rate. Firstly, we propose a real-time SS network
named Swift Factorized Network (SFN). The proposed network is adapted from
SwiftNet, whose structure is a typical U-shape structure with lateral
connections. Inspired by ERFNet and Global convolution Networks (GCNet), we
propose two different blocks to enlarge valid receptive field. They do not take
up too much calculation resources, but significantly enhance the performance
compared with the baseline network. Secondly, we explore three ways to achieve
higher recall rate, i.e. loss function, classifier and decision rules. We
perform a comprehensive set of experiments on state-of-the-art datasets
including CamVid and Cityscapes. We demonstrate that our SS convolutional
neural networks reach excellent performance. Furthermore, we make a detailed
analysis and comparison of the three proposed methods on the promotion of
recall rate.",arxiv
http://arxiv.org/abs/1804.03629v1,2018-04-10T17:05:53Z,2018-04-10T17:05:53Z,Probabilistic Prediction of Vehicle Semantic Intention and Motion,"Accurately predicting the possible behaviors of traffic participants is an
essential capability for future autonomous vehicles. The majority of current
researches fix the number of driving intentions by considering only a specific
scenario. However, distinct driving environments usually contain various
possible driving maneuvers. Therefore, a intention prediction method that can
adapt to different traffic scenarios is needed. To further improve the overall
vehicle prediction performance, motion information is usually incorporated with
classified intentions. As suggested in some literature, the methods that
directly predict possible goal locations can achieve better performance for
long-term motion prediction than other approaches due to their automatic
incorporation of environment constraints. Moreover, by obtaining the temporal
information of the predicted destinations, the optimal trajectories for
predicted vehicles as well as the desirable path for ego autonomous vehicle
could be easily generated. In this paper, we propose a Semantic-based Intention
and Motion Prediction (SIMP) method, which can be adapted to any driving
scenarios by using semantic-defined vehicle behaviors. It utilizes a
probabilistic framework based on deep neural network to estimate the
intentions, final locations, and the corresponding time information for
surrounding vehicles. An exemplar real-world scenario was used to implement and
examine the proposed method.",arxiv
http://arxiv.org/abs/1710.06160v1,2017-10-17T08:40:16Z,2017-10-17T08:40:16Z,"Combining LiDAR Space Clustering and Convolutional Neural Networks for
  Pedestrian Detection","Pedestrian detection is an important component for safety of autonomous
vehicles, as well as for traffic and street surveillance. There are extensive
benchmarks on this topic and it has been shown to be a challenging problem when
applied on real use-case scenarios. In purely image-based pedestrian detection
approaches, the state-of-the-art results have been achieved with convolutional
neural networks (CNN) and surprisingly few detection frameworks have been built
upon multi-cue approaches. In this work, we develop a new pedestrian detector
for autonomous vehicles that exploits LiDAR data, in addition to visual
information. In the proposed approach, LiDAR data is utilized to generate
region proposals by processing the three dimensional point cloud that it
provides. These candidate regions are then further processed by a
state-of-the-art CNN classifier that we have fine-tuned for pedestrian
detection. We have extensively evaluated the proposed detection process on the
KITTI dataset. The experimental results show that the proposed LiDAR space
clustering approach provides a very efficient way of generating region
proposals leading to higher recall rates and fewer misses for pedestrian
detection. This indicates that LiDAR data can provide auxiliary information for
CNN-based approaches.",arxiv
http://arxiv.org/abs/1902.09094v1,2019-02-25T05:18:09Z,2019-02-25T05:18:09Z,"DRAMNet: Authentication based on Physical Unique Features of DRAM Using
  Deep Convolutional Neural Networks","Nowadays, there is an increasing interest in the development of Autonomous
Vehicles (AV). However, there are two types of attack challenges that can
affect AVs and are yet to be resolved, i.e., sensor attacks and vehicle access
attacks. This paper, to the best of our knowledge, is the first work that
proposes a novel authentication scheme involving DRAM power-up unique features
using deep Convolutional Neural Network (CNN), which can be used to implement
secure access control of autonomous vehicles. Our approach consists of two
parts. First, we convert raw power-up sequence data from DRAM cells into a
two-dimensional (2D) format to generate a DRAM image structure. Second, we
apply deep CNN to DRAM images, in order to extract unique features from each
memory to classify them for authentication. To evaluate our proposed approach,
we utilize data from three Commercial-Off-The-Shelf (COTS) DRAMs taken under
various environmental and other conditions (high/low temperature, high/low
supply voltage and aging effects). Based on our results, our proposed
authentication method ``DRAMNet'' achieves 98.63% accuracy and 98.49%
precision. In comparison to other state-of-the-art CNN architectures, such as
the AlexNet and VGGNet models, our DRAMNet approach fares equally well or
better than them.",arxiv
http://arxiv.org/abs/1909.05621v3,2019-09-17T11:06:37Z,2019-08-29T14:45:21Z,Automated Detecting and Placing Road Objects from Street-level Images,"Navigation services utilized by autonomous vehicles or ordinary users require
the availability of detailed information about road-related objects and their
geolocations, especially at road intersections. However, these road
intersections are mainly represented as point elements without detailed
information, or are even not available in current versions of crowdsourced
mapping databases including OpenStreetMap(OSM). This study develops an approach
to automatically detect road objects and place them to right location from
street-level images. Our processing pipeline relies on two convolutional neural
networks: the first segments the images, while the second detects and
classifies the specific objects. Moreover, to locate the detected objects, we
establish an attributed topological binary tree(ATBT) based on urban grammar
for each image to depict the coherent relations of topologies, attributes and
semantics of the road objects. Then the ATBT is further matched with map
features on OSM to determine the right placed location. The proposed method has
been applied to a case study in Berlin, Germany. We validate the effectiveness
of our method on two object classes: traffic signs and traffic lights.
Experimental results demonstrate that the proposed approach provides
near-precise localization results in terms of completeness and positional
accuracy. Among many potential applications, the output may be combined with
other sources of data to guide autonomous vehicles",arxiv
http://arxiv.org/abs/2006.03733v2,2020-07-14T16:34:23Z,2020-06-05T23:09:58Z,"Unsupervised Abnormality Detection Using Heterogeneous Autonomous
  Systems","Anomaly detection (AD) in a surveillance scenario is an emerging and
challenging field of research. For autonomous vehicles like drones or cars, it
is immensely important to distinguish between normal and abnormal states in
real-time. Additionally, we also need to detect any device malfunction. But the
nature and degree of abnormality may vary depending upon the actual environment
and adversary. As a result, it is impractical to model all cases a-priori and
use supervised methods to classify. Also, an autonomous vehicle provides
various data types like images and other analog or digital sensor data, all of
which can be useful in anomaly detection if leveraged fruitfully. To that
effect, in this paper, a heterogeneous system is proposed which estimates the
degree of abnormality of an unmanned surveillance drone, analyzing real-time
image and IMU (Inertial Measurement Unit) sensor data in an unsupervised
manner. Here, we have demonstrated a Convolutional Neural Network (CNN)
architecture, named AngleNet to estimate the angle between a normal image and
another image under consideration, which provides us with a measure of anomaly
of the device. Moreover, the IMU data are used in autoencoder to predict
abnormality. Finally, the results from these two algorithms are ensembled to
estimate the final degree of abnormality. The proposed method performs
satisfactorily on the IEEE SP Cup-2020 dataset with an accuracy of 97.3%.
Additionally, we have also tested this approach on an in-house dataset to
validate its robustness.",arxiv
http://arxiv.org/abs/2011.11190v1,2020-11-23T03:13:26Z,2020-11-23T03:13:26Z,"Attentional-GCNN: Adaptive Pedestrian Trajectory Prediction towards
  Generic Autonomous Vehicle Use Cases","Autonomous vehicle navigation in shared pedestrian environments requires the
ability to predict future crowd motion both accurately and with minimal delay.
Understanding the uncertainty of the prediction is also crucial. Most existing
approaches however can only estimate uncertainty through repeated sampling of
generative models. Additionally, most current predictive models are trained on
datasets that assume complete observability of the crowd using an aerial view.
These are generally not representative of real-world usage from a vehicle
perspective, and can lead to the underestimation of uncertainty bounds when the
on-board sensors are occluded. Inspired by prior work in motion prediction
using spatio-temporal graphs, we propose a novel Graph Convolutional Neural
Network (GCNN)-based approach, Attentional-GCNN, which aggregates information
of implicit interaction between pedestrians in a crowd by assigning attention
weight in edges of the graph. Our model can be trained to either output a
probabilistic distribution or faster deterministic prediction, demonstrating
applicability to autonomous vehicle use cases where either speed or accuracy
with uncertainty bounds are required. To further improve the training of
predictive models, we propose an automatically labelled pedestrian dataset
collected from an intelligent vehicle platform representative of real-world
use. Through experiments on a number of datasets, we show our proposed method
achieves an improvement over the state of art by 10% Average Displacement Error
(ADE) and 12% Final Displacement Error (FDE) with fast inference speeds.",arxiv
http://arxiv.org/abs/2101.06092v1,2021-01-15T13:18:18Z,2021-01-15T13:18:18Z,Black-box Adversarial Attacks in Autonomous Vehicle Technology,"Despite the high quality performance of the deep neural network in real-world
applications, they are susceptible to minor perturbations of adversarial
attacks. This is mostly undetectable to human vision. The impact of such
attacks has become extremely detrimental in autonomous vehicles with real-time
""safety"" concerns. The black-box adversarial attacks cause drastic
misclassification in critical scene elements such as road signs and traffic
lights leading the autonomous vehicle to crash into other vehicles or
pedestrians. In this paper, we propose a novel query-based attack method called
Modified Simple black-box attack (M-SimBA) to overcome the use of a white-box
source in transfer based attack method. Also, the issue of late convergence in
a Simple black-box attack (SimBA) is addressed by minimizing the loss of the
most confused class which is the incorrect class predicted by the model with
the highest probability, instead of trying to maximize the loss of the correct
class. We evaluate the performance of the proposed approach to the German
Traffic Sign Recognition Benchmark (GTSRB) dataset. We show that the proposed
model outperforms the existing models like Transfer-based projected gradient
descent (T-PGD), SimBA in terms of convergence time, flattening the
distribution of confused class probability, and producing adversarial samples
with least confidence on the true class.",arxiv
http://arxiv.org/abs/2102.03326v1,2021-02-05T18:14:36Z,2021-02-05T18:14:36Z,"Fusion of neural networks, for LIDAR-based evidential road mapping","LIDAR sensors are usually used to provide autonomous vehicles with 3D
representations of their environment. In ideal conditions, geometrical models
could detect the road in LIDAR scans, at the cost of a manual tuning of
numerical constraints, and a lack of flexibility. We instead propose an
evidential pipeline, to accumulate road detection results obtained from neural
networks. First, we introduce RoadSeg, a new convolutional architecture that is
optimized for road detection in LIDAR scans. RoadSeg is used to classify
individual LIDAR points as either belonging to the road, or not. Yet, such
point-level classification results need to be converted into a dense
representation, that can be used by an autonomous vehicle. We thus secondly
present an evidential road mapping algorithm, that fuses consecutive road
detection results. We benefitted from a reinterpretation of logistic
classifiers, which can be seen as generating a collection of simple evidential
mass functions. An evidential grid map that depicts the road can then be
obtained, by projecting the classification results from RoadSeg into grid
cells, and by handling moving objects via conflict analysis. The system was
trained and evaluated on real-life data. A python implementation maintains a 10
Hz framerate. Since road labels were needed for training, a soft labelling
procedure, relying lane-level HD maps, was used to generate coarse training and
validation sets. An additional test set was manually labelled for evaluation
purposes. So as to reach satisfactory results, the system fuses road detection
results obtained from three variants of RoadSeg, processing different LIDAR
features.",arxiv
http://arxiv.org/abs/1105.1749v2,2011-05-21T14:15:28Z,2011-05-09T18:17:20Z,"A Real-Time Model-Based Reinforcement Learning Architecture for Robot
  Control","Reinforcement Learning (RL) is a method for learning decision-making tasks
that could enable robots to learn and adapt to their situation on-line. For an
RL algorithm to be practical for robotic control tasks, it must learn in very
few actions, while continually taking those actions in real-time. Existing
model-based RL methods learn in relatively few actions, but typically take too
much time between each action for practical on-line learning. In this paper, we
present a novel parallel architecture for model-based RL that runs in real-time
by 1) taking advantage of sample-based approximate planning methods and 2)
parallelizing the acting, model learning, and planning processes such that the
acting process is sufficiently fast for typical robot control cycles. We
demonstrate that algorithms using this architecture perform nearly as well as
methods using the typical sequential architecture when both are given unlimited
time, and greatly out-perform these methods on tasks that require real-time
actions such as controlling an autonomous vehicle.",arxiv
http://arxiv.org/abs/1705.08926v2,2017-12-14T14:50:34Z,2017-05-24T18:52:17Z,Counterfactual Multi-Agent Policy Gradients,"Cooperative multi-agent systems can be naturally used to model many real
world problems, such as network packet routing and the coordination of
autonomous vehicles. There is a great need for new reinforcement learning
methods that can efficiently learn decentralised policies for such systems. To
this end, we propose a new multi-agent actor-critic method called
counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised
critic to estimate the Q-function and decentralised actors to optimise the
agents' policies. In addition, to address the challenges of multi-agent credit
assignment, it uses a counterfactual baseline that marginalises out a single
agent's action, while keeping the other agents' actions fixed. COMA also uses a
critic representation that allows the counterfactual baseline to be computed
efficiently in a single forward pass. We evaluate COMA in the testbed of
StarCraft unit micromanagement, using a decentralised variant with significant
partial observability. COMA significantly improves average performance over
other multi-agent actor-critic methods in this setting, and the best performing
agents are competitive with state-of-the-art centralised controllers that get
access to the full state.",arxiv
http://arxiv.org/abs/1809.02926v1,2018-09-09T05:44:16Z,2018-09-09T05:44:16Z,"Probabilistic Prediction of Interactive Driving Behavior via
  Hierarchical Inverse Reinforcement Learning","Autonomous vehicles (AVs) are on the road. To safely and efficiently interact
with other road participants, AVs have to accurately predict the behavior of
surrounding vehicles and plan accordingly. Such prediction should be
probabilistic, to address the uncertainties in human behavior. Such prediction
should also be interactive, since the distribution over all possible
trajectories of the predicted vehicle depends not only on historical
information, but also on future plans of other vehicles that interact with it.
To achieve such interaction-aware predictions, we propose a probabilistic
prediction approach based on hierarchical inverse reinforcement learning (IRL).
First, we explicitly consider the hierarchical trajectory-generation process of
human drivers involving both discrete and continuous driving decisions. Based
on this, the distribution over all future trajectories of the predicted vehicle
is formulated as a mixture of distributions partitioned by the discrete
decisions. Then we apply IRL hierarchically to learn the distributions from
real human demonstrations. A case study for the ramp-merging driving scenario
is provided. The quantitative results show that the proposed approach can
accurately predict both the discrete driving decisions such as yield or pass as
well as the continuous trajectories.",arxiv
http://arxiv.org/abs/1810.06519v2,2019-01-09T18:31:04Z,2018-10-15T17:06:38Z,Factorized Machine Self-Confidence for Decision-Making Agents,"Algorithmic assurances from advanced autonomous systems assist human users in
understanding, trusting, and using such systems appropriately. Designing these
systems with the capacity of assessing their own capabilities is one approach
to creating an algorithmic assurance. The idea of `machine self-confidence' is
introduced for autonomous systems. Using a factorization based framework for
self-confidence assessment, one component of self-confidence, called
`solver-quality', is discussed in the context of Markov decision processes for
autonomous systems. Markov decision processes underlie much of the theory of
reinforcement learning, and are commonly used for planning and decision making
under uncertainty in robotics and autonomous systems. A `solver quality' metric
is formally defined in the context of decision making algorithms based on
Markov decision processes. A method for assessing solver quality is then
derived, drawing inspiration from empirical hardness models. Finally, numerical
experiments for an unmanned autonomous vehicle navigation problem under
different solver, parameter, and environment conditions indicate that the
self-confidence metric exhibits the desired properties. Discussion of results,
and avenues for future investigation are included.",arxiv
http://arxiv.org/abs/1905.13428v1,2019-05-31T06:02:52Z,2019-05-31T06:02:52Z,"Attentional Policies for Cross-Context Multi-Agent Reinforcement
  Learning","Many potential applications of reinforcement learning in the real world
involve interacting with other agents whose numbers vary over time. We propose
new neural policy architectures for these multi-agent problems. In contrast to
other methods of training an individual, discrete policy for each agent and
then enforcing cooperation through some additional inter-policy mechanism, we
follow the spirit of recent work on the power of relational inductive biases in
deep networks by learning multi-agent relationships at the policy level via an
attentional architecture. In our method, all agents share the same policy, but
independently apply it in their own context to aggregate the other agents'
state information when selecting their next action. The structure of our
architectures allow them to be applied on environments with varying numbers of
agents. We demonstrate our architecture on a benchmark multi-agent autonomous
vehicle coordination problem, obtaining superior results to a full-knowledge,
fully-centralized reference solution, and significantly outperforming it when
scaling to large numbers of agents.",arxiv
http://arxiv.org/abs/1906.06588v1,2019-06-15T16:37:07Z,2019-06-15T16:37:07Z,"Reinforcement Learning with Non-uniform State Representations for
  Adaptive Search","Efficient spatial exploration is a key aspect of search and rescue. In this
paper, we present a search algorithm that generates efficient trajectories that
optimize the rate at which probability mass is covered by a searcher. This
should allow an autonomous vehicle find one or more lost targets as rapidly as
possible. We do this by performing non-uniform sampling of the search region.
The path generated minimizes the expected time to locate the missing target by
visiting high probability regions using non-myopic path generation based on
reinforcement learning. We model the target probability distribution using a
classic mixture of Gaussians model with means and mixture coefficients tuned
according to the location and time of sightings of the lost target. Key
features of our search algorithm are the ability to employ a very general
non-deterministic action model and the ability to generate action plans for any
new probability distribution using the parameters learned on other similar
looking distributions. One of the key contributions of this paper is the use of
non-uniform state aggregation for policy search in the context of robotics.",arxiv
http://arxiv.org/abs/1909.05004v4,2020-03-03T17:17:51Z,2019-09-11T12:26:42Z,"Predicting optimal value functions by interpolating reward functions in
  scalarized multi-objective reinforcement learning","A common approach for defining a reward function for Multi-objective
Reinforcement Learning (MORL) problems is the weighted sum of the multiple
objectives. The weights are then treated as design parameters dependent on the
expertise (and preference) of the person performing the learning, with the
typical result that a new solution is required for any change in these
settings. This paper investigates the relationship between the reward function
and the optimal value function for MORL; specifically addressing the question
of how to approximate the optimal value function well beyond the set of weights
for which the optimization problem was actually solved, thereby avoiding the
need to recompute for any particular choice. We prove that the value function
transforms smoothly given a transformation of weights of the reward function
(and thus a smooth interpolation in the policy space). A Gaussian process is
used to obtain a smooth interpolation over the reward function weights of the
optimal value function for three well-known examples: GridWorld, Objectworld
and Pendulum. The results show that the interpolation can provide very robust
values for sample states and action space in discrete and continuous domain
problems. Significant advantages arise from utilizing this interpolation
technique in the domain of autonomous vehicles: easy, instant adaptation of
user preferences while driving and true randomization of obstacle vehicle
behavior preferences during training.",arxiv
http://arxiv.org/abs/1909.12217v4,2021-01-25T21:19:51Z,2019-09-26T16:15:37Z,"Visual Exploration and Energy-aware Path Planning via Reinforcement
  Learning","Visual exploration and smart data collection via autonomous vehicles is an
attractive topic in various disciplines. Disturbances like wind significantly
influence both the power consumption of the flying robots and the performance
of the camera. We propose a reinforcement learning approach which combines the
effects of the power consumption and the object detection modules to develop a
policy for object detection in large areas with limited battery life. The
learning model enables dynamic learning of the negative rewards of each action
based on the drag forces that is resulted by the motion of the flying robot
with respect to the wind field. The algorithm is implemented in a near-real
world simulation environment both for the planar motion and flight in different
altitudes. The trained agent often performed a trade-off between detecting the
objects with high accuracy and increasing the area coverage within its battery
life. The developed exploration policy outperformed the complete coverage
algorithm by minimizing the traveled path while finding the target objects. The
performance of the algorithms under various wind fields was evaluated in planar
and 3D motion. During an exploration task with sparsely distributed goals and
within a UAV's battery life, the proposed architecture could detect more than
twice the amount of goal objects compared to the coverage path planning
algorithm in moderate wind field. In high wind intensities, the energy-aware
algorithm could detect 4 times the amount of goal objects when compared to its
complete coverage counterpart.",arxiv
http://arxiv.org/abs/2002.05502v2,2020-09-30T07:59:32Z,2020-02-13T14:09:22Z,"Improving Generalization of Reinforcement Learning with Minimax
  Distributional Soft Actor-Critic","Reinforcement learning (RL) has achieved remarkable performance in numerous
sequential decision making and control tasks. However, a common problem is that
learned nearly optimal policy always overfits to the training environment and
may not be extended to situations never encountered during training. For
practical applications, the randomness of environment usually leads to some
devastating events, which should be the focus of safety-critical systems such
as autonomous driving. In this paper, we introduce the minimax formulation and
distributional framework to improve the generalization ability of RL algorithms
and develop the Minimax Distributional Soft Actor-Critic (Minimax DSAC)
algorithm. Minimax formulation aims to seek optimal policy considering the most
severe variations from environment, in which the protagonist policy maximizes
action-value function while the adversary policy tries to minimize it.
Distributional framework aims to learn a state-action return distribution, from
which we can model the risk of different returns explicitly, thereby
formulating a risk-averse protagonist policy and a risk-seeking adversarial
policy. We implement our method on the decision-making tasks of autonomous
vehicles at intersections and test the trained policy in distinct environments.
Results demonstrate that our method can greatly improve the generalization
ability of the protagonist agent to different environmental variations.",arxiv
http://arxiv.org/abs/2003.01005v3,2020-06-17T06:01:46Z,2020-03-02T16:34:14Z,"Eco-Vehicular Edge Networks for Connected Transportation: A Distributed
  Multi-Agent Reinforcement Learning Approach","This paper introduces an energy-efficient, software-defined vehicular edge
network for the growing intelligent connected transportation system. A joint
user-centric virtual cell formation and resource allocation problem is
investigated to bring eco-solutions at the edge. This joint problem aims to
combat against the power-hungry edge nodes while maintaining assured
reliability and data rate. More specifically, by prioritizing the downlink
communication of dynamic eco-routing, highly mobile autonomous vehicles are
served with multiple low-powered access points (APs) simultaneously for
ubiquitous connectivity and guaranteed reliability of the network. The
formulated optimization is exceptionally troublesome to solve within a
polynomial time, due to its complicated combinatorial structure. Hence, a
distributed multi-agent reinforcement learning (D-MARL) algorithm is proposed
for eco-vehicular edges, where multiple agents cooperatively learn to receive
the best reward. First, the algorithm segments the centralized action space
into multiple smaller groups. Based on the model-free distributed Q learner,
each edge agent takes its actions from the respective group. Also, in each
learning state, a software-defined controller chooses the global best action
from individual bests of the distributed agents. Numerical results validate
that our learning solution achieves near-optimal performances within a small
number of training episodes as compared with existing baselines.",arxiv
http://arxiv.org/abs/2003.02604v2,2020-09-29T16:13:54Z,2020-03-05T13:32:43Z,BARK: Open Behavior Benchmarking in Multi-Agent Environments,"Predicting and planning interactive behaviors in complex traffic situations
presents a challenging task. Especially in scenarios involving multiple traffic
participants that interact densely, autonomous vehicles still struggle to
interpret situations and to eventually achieve their own mission goal. As
driving tests are costly and challenging scenarios are hard to find and
reproduce, simulation is widely used to develop, test, and benchmark behavior
models. However, most simulations rely on datasets and simplistic behavior
models for traffic participants and do not cover the full variety of
real-world, interactive human behaviors. In this work, we introduce BARK, an
open-source behavior benchmarking environment designed to mitigate the
shortcomings stated above. In BARK, behavior models are (re-)used for planning,
prediction, and simulation. A range of models is currently available, such as
Monte-Carlo Tree Search and Reinforcement Learning-based behavior models. We
use a public dataset and sampling-based scenario generation to show the
inter-exchangeability of behavior models in BARK. We evaluate how well the
models used cope with interactions and how robust they are towards exchanging
behavior models. Our evaluation shows that BARK provides a suitable framework
for a systematic development of behavior models.",arxiv
http://arxiv.org/abs/2004.04292v2,2020-06-18T20:49:28Z,2020-04-08T22:56:59Z,Adaptive Stress Testing without Domain Heuristics using Go-Explore,"Recently, reinforcement learning (RL) has been used as a tool for finding
failures in autonomous systems. During execution, the RL agents often rely on
some domain-specific heuristic reward to guide them towards finding failures,
but constructing such a heuristic may be difficult or infeasible. Without a
heuristic, the agent may only receive rewards at the time of failure, or even
rewards that guide it away from failures. For example, some approaches give
rewards for taking more-likely actions, because we want to find more-likely
failures. However, the agent may then learn to only take likely actions, and
may not be able to find a failure at all. Consequently, the problem becomes a
hard-exploration problem, where rewards do not aid exploration. A new
algorithm, go-explore (GE), has recently set new records on benchmarks from the
hard-exploration field. We apply GE to adaptive stress testing (AST), one
example of an RL-based falsification approach that provides a way to search for
the most-likely failure scenario. We simulate a scenario where an autonomous
vehicle drives while a pedestrian is crossing the road. We demonstrate that GE
is able to find failures without domain-specific heuristics, such as the
distance between the car and the pedestrian, on scenarios that other RL
techniques are unable to solve. Furthermore, inspired by the robustification
phase of GE, we demonstrate that the backwards algorithm (BA) improves the
failures found by other RL techniques.",arxiv
http://arxiv.org/abs/2005.03076v2,2020-05-11T01:36:35Z,2020-05-06T19:03:51Z,"Guided Policy Search Model-based Reinforcement Learning for Urban
  Autonomous Driving","In this paper, we continue our prior work on using imitation learning (IL)
and model free reinforcement learning (RL) to learn driving policies for
autonomous driving in urban scenarios, by introducing a model based RL method
to drive the autonomous vehicle in the Carla urban driving simulator. Although
IL and model free RL methods have been proved to be capable of solving lots of
challenging tasks, including playing video games, robots, and, in our prior
work, urban driving, the low sample efficiency of such methods greatly limits
their applications on actual autonomous driving. In this work, we developed a
model based RL algorithm of guided policy search (GPS) for urban driving tasks.
The algorithm iteratively learns a parameterized dynamic model to approximate
the complex and interactive driving task, and optimizes the driving policy
under the nonlinear approximate dynamic model. As a model based RL approach,
when applied in urban autonomous driving, the GPS has the advantages of higher
sample efficiency, better interpretability, and greater stability. We provide
extensive experiments validating the effectiveness of the proposed method to
learn robust driving policy for urban driving in Carla. We also compare the
proposed method with other policy search and model free RL baselines, showing
100x better sample efficiency of the GPS based RL method, and also that the GPS
based method can learn policies for harder tasks that the baseline methods can
hardly learn.",arxiv
http://arxiv.org/abs/2005.14419v2,2020-06-13T05:19:26Z,2020-05-29T06:53:29Z,Reinforcement Learning,"Reinforcement learning (RL) is a general framework for adaptive control,
which has proven to be efficient in many domains, e.g., board games, video
games or autonomous vehicles. In such problems, an agent faces a sequential
decision-making problem where, at every time step, it observes its state,
performs an action, receives a reward and moves to a new state. An RL agent
learns by trial and error a good policy (or controller) based on observations
and numeric reward feedback on the previously performed action. In this
chapter, we present the basic framework of RL and recall the two main families
of approaches that have been developed to learn a good policy. The first one,
which is value-based, consists in estimating the value of an optimal policy,
value from which a policy can be recovered, while the other, called policy
search, directly works in a policy space. Actor-critic methods can be seen as a
policy search technique where the policy value that is learned guides the
policy improvement. Besides, we give an overview of some extensions of the
standard RL framework, notably when risk-averse behavior needs to be taken into
account or when rewards are not available or not known.",arxiv
http://arxiv.org/abs/2006.04218v2,2020-06-19T16:12:04Z,2020-06-07T18:20:33Z,"Deep Reinforcement Learning for Human-Like Driving Policies in Collision
  Avoidance Tasks of Self-Driving Cars","The technological and scientific challenges involved in the development of
autonomous vehicles (AVs) are currently of primary interest for many automobile
companies and research labs. However, human-controlled vehicles are likely to
remain on the roads for several decades to come and may share with AVs the
traffic environments of the future. In such mixed environments, AVs should
deploy human-like driving policies and negotiation skills to enable smooth
traffic flow. To generate automated human-like driving policies, we introduce a
model-free, deep reinforcement learning approach to imitate an experienced
human driver's behavior. We study a static obstacle avoidance task on a
two-lane highway road in simulation (Unity). Our control algorithm receives a
stochastic feedback signal from two sources: a model-driven part, encoding
simple driving rules, such as lane-keeping and speed control, and a stochastic,
data-driven part, incorporating human expert knowledge from driving data. To
assess the similarity between machine and human driving, we model distributions
of track position and speed as Gaussian processes. We demonstrate that our
approach leads to human-like driving policies.",arxiv
http://arxiv.org/abs/2007.05673v1,2020-07-11T03:28:07Z,2020-07-11T03:28:07Z,"iRDRC: An Intelligent Real-time Dual-functional Radar-Communication
  System for Automotive Vehicles","This letter introduces an intelligent Real-time Dual-functional
Radar-Communication (iRDRC) system for autonomous vehicles (AVs). This system
enables an AV to perform both radar and data communications functions to
maximize bandwidth utilization as well as significantly enhance safety. In
particular, the data communications function allows the AV to transmit data,
e.g., of current traffic, to edge computing systems and the radar function is
used to enhance the reliability and reduce the collision risks of the AV, e.g.,
under bad weather conditions. The problem of the iRDRC is to decide when to use
the communication mode or the radar mode to maximize the data throughput while
minimizing the miss detection probability of unexpected events given the
uncertainty of surrounding environment. To solve the problem, we develop a deep
reinforcement learning algorithm that allows the AV to quickly obtain the
optimal policy without requiring any prior information about the environment.
Simulation results show that the proposed scheme outperforms baseline schemes
in terms of data throughput, miss detection probability, and convergence rate.",arxiv
http://arxiv.org/abs/2008.06696v1,2020-08-15T10:37:07Z,2020-08-15T10:37:07Z,"Autonomous Braking and Throttle System: A Deep Reinforcement Learning
  Approach for Naturalistic Driving","Autonomous Braking and Throttle control is key in developing safe driving
systems for the future. There exists a need for autonomous vehicles to
negotiate a multi-agent environment while ensuring safety and comfort. A Deep
Reinforcement Learning based autonomous throttle and braking system is
presented. For each time step, the proposed system makes a decision to apply
the brake or throttle. The throttle and brake are modelled as continuous action
space values. We demonstrate 2 scenarios where there is a need for a
sophisticated braking and throttle system, i.e when there is a static obstacle
in front of our agent like a car, stop sign. The second scenario consists of 2
vehicles approaching an intersection. The policies for brake and throttle
control are learned through computer simulation using Deep deterministic policy
gradients. The experiment shows that the system not only avoids a collision,
but also it ensures that there is smooth change in the values of throttle/brake
as it gets out of the emergency situation and abides by the speed regulations,
i.e the system resembles human driving.",arxiv
http://arxiv.org/abs/2010.15372v1,2020-10-29T06:21:23Z,2020-10-29T06:21:23Z,"Learning Personalized Discretionary Lane-Change Initiation for Fully
  Autonomous Driving Based on Reinforcement Learning","In this article, the authors present a novel method to learn the personalized
tactic of discretionary lane-change initiation for fully autonomous vehicles
through human-computer interactions. Instead of learning from human-driving
demonstrations, a reinforcement learning technique is employed to learn how to
initiate lane changes from traffic context, the action of a self-driving
vehicle, and in-vehicle user feedback. The proposed offline algorithm rewards
the action-selection strategy when the user gives positive feedback and
penalizes it when negative feedback. Also, a multi-dimensional driving scenario
is considered to represent a more realistic lane-change trade-off. The results
show that the lane-change initiation model obtained by this method can
reproduce the personal lane-change tactic, and the performance of the
customized models (average accuracy 86.1%) is much better than that of the
non-customized models (average accuracy 75.7%). This method allows continuous
improvement of customization for users during fully autonomous driving even
without human-driving experience, which will significantly enhance the user
acceptance of high-level autonomy of self-driving vehicles.",arxiv
http://arxiv.org/abs/2011.00120v1,2020-10-30T22:06:05Z,2020-10-30T22:06:05Z,"Optimizing Mixed Autonomy Traffic Flow With Decentralized Autonomous
  Vehicles and Multi-Agent RL","We study the ability of autonomous vehicles to improve the throughput of a
bottleneck using a fully decentralized control scheme in a mixed autonomy
setting. We consider the problem of improving the throughput of a scaled model
of the San Francisco-Oakland Bay Bridge: a two-stage bottleneck where four
lanes reduce to two and then reduce to one. Although there is extensive work
examining variants of bottleneck control in a centralized setting, there is
less study of the challenging multi-agent setting where the large number of
interacting AVs leads to significant optimization difficulties for
reinforcement learning methods. We apply multi-agent reinforcement algorithms
to this problem and demonstrate that significant improvements in bottleneck
throughput, from 20\% at a 5\% penetration rate to 33\% at a 40\% penetration
rate, can be achieved. We compare our results to a hand-designed feedback
controller and demonstrate that our results sharply outperform the feedback
controller despite extensive tuning. Additionally, we demonstrate that the
RL-based controllers adopt a robust strategy that works across penetration
rates whereas the feedback controllers degrade immediately upon penetration
rate variation. We investigate the feasibility of both action and observation
decentralization and demonstrate that effective strategies are possible using
purely local sensing. Finally, we open-source our code at
https://github.com/eugenevinitsky/decentralized_bottlenecks.",arxiv
http://arxiv.org/abs/2011.04555v1,2020-11-09T16:55:09Z,2020-11-09T16:55:09Z,"Multi-Agent Reinforcement Learning for Joint Channel Assignment and
  Power Allocation in Platoon-Based C-V2X Systems","We consider the problem of joint channel assignment and power allocation in
underlaid cellular vehicular-to-everything (C-V2X) systems where multiple
vehicle-to-infrastructure (V2I) uplinks share the time-frequency resources with
multiple vehicle-to-vehicle (V2V) platoons that enable groups of connected and
autonomous vehicles to travel closely together. Due to the nature of fast
channel variant in vehicular environment, traditional centralized optimization
approach relying on global channel information might not be viable in C-V2X
systems with large number of users. Utilizing a reinforcement learning (RL)
approach, we propose a distributed resource allocation (RA) algorithm to
overcome this challenge. Specifically, we model the RA problem as a multi-agent
system. Based solely on the local channel information, each platoon leader, who
acts as an agent, collectively interacts with each other and accordingly
selects the optimal combination of sub-band and power level to transmit its
signals. Toward this end, we utilize the double deep Q-learning algorithm to
jointly train the agents under the objectives of simultaneously maximizing the
V2I sum-rate and satisfying the packet delivery probability of each V2V link in
a desired latency limitation. Simulation results show that our proposed
RL-based algorithm achieves a close performance compared to that of the
well-known exhaustive search algorithm.",arxiv
http://arxiv.org/abs/2011.11191v1,2020-11-23T03:15:04Z,2020-11-23T03:15:04Z,"Socially Aware Crowd Navigation with Multimodal Pedestrian Trajectory
  Prediction for Autonomous Vehicles","Seamlessly operating an autonomous vehicle in a crowded pedestrian
environment is a very challenging task. This is because human movement and
interactions are very hard to predict in such environments. Recent work has
demonstrated that reinforcement learning-based methods have the ability to
learn to drive in crowds. However, these methods can have very poor performance
due to inaccurate predictions of the pedestrians' future state as human motion
prediction has a large variance. To overcome this problem, we propose a new
method, SARL-SGAN-KCE, that combines a deep socially aware attentive value
network with a human multimodal trajectory prediction model to help identify
the optimal driving policy. We also introduce a novel technique to extend the
discrete action space with minimal additional computational requirements. The
kinematic constraints of the vehicle are also considered to ensure smooth and
safe trajectories. We evaluate our method against the state of art methods for
crowd navigation and provide an ablation study to show that our method is safer
and closer to human behaviour.",arxiv
http://arxiv.org/abs/2102.08317v1,2021-02-16T17:56:23Z,2021-02-16T17:56:23Z,Resource allocation in dynamic multiagent systems,"Resource allocation and task prioritisation are key problem domains in the
fields of autonomous vehicles, networking, and cloud computing. The challenge
in developing efficient and robust algorithms comes from the dynamic nature of
these systems, with many components communicating and interacting in complex
ways. The multi-group resource allocation optimisation (MG-RAO) algorithm we
present uses multiple function approximations of resource demand over time,
alongside reinforcement learning techniques, to develop a novel method of
optimising resource allocation in these multi-agent systems. This method is
applicable where there are competing demands for shared resources, or in task
prioritisation problems. Evaluation is carried out in a simulated environment
containing multiple competing agents. We compare the new algorithm to an
approach where child agents distribute their resources uniformly across all the
tasks they can be allocated. We also contrast the performance of the algorithm
where resource allocation is modelled separately for groups of agents, as to
being modelled jointly over all agents. The MG-RAO algorithm shows a 23 - 28%
improvement over fixed resource allocation in the simulated environments.
Results also show that, in a volatile system, using the MG-RAO algorithm
configured so that child agents model resource allocation for all agents as a
whole has 46.5% of the performance of when it is set to model multiple groups
of agents. These results demonstrate the ability of the algorithm to solve
resource allocation problems in multi-agent systems and to perform well in
dynamic environments.",arxiv
http://arxiv.org/abs/2103.14705v1,2021-03-26T19:40:36Z,2021-03-26T19:40:36Z,Personalized Adaptive Cruise Control and Impacts on Mixed Traffic,"This paper presents a personalized adaptive cruise control (PACC) design that
can learn driver behavior and adaptively control the semi-autonomous vehicle
(SAV) in the car-following scenario, and investigates its impacts on mixed
traffic. In mixed traffic where the SAV and human-driven vehicles share the
road, the SAV's driver can choose a PACC tuning that better fits the driver's
preferred driving behaviors. The individual driver's preferences are learned
through the inverse reinforcement learning (IRL) approach by recovering a
unique cost function from the driver's demonstrated driving data that best
explains the observed driving style. The proposed PACC design plans the motion
of the SAV by minimizing the learned unique cost function considering the short
preview information of the preceding human-driven vehicle. The results reveal
that the learned driver model can identify and replicate the personalized
driving behaviors accurately and consistently when following the preceding
vehicle in a variety of traffic conditions. Furthermore, we investigated the
impacts of the PACC with different drivers on mixed traffic by considering time
headway, gap distance, and fuel economy assessments. A statistical
investigation shows that the impacts of the PACC on mixed traffic vary among
tested drivers due to their intrinsic driving preferences.",arxiv
http://arxiv.org/abs/2105.05701v1,2021-05-12T14:37:43Z,2021-05-12T14:37:43Z,"Deep Multi-agent Reinforcement Learning for Highway On-Ramp Merging in
  Mixed Traffic","On-ramp merging is a challenging task for autonomous vehicles (AVs),
especially in mixed traffic where AVs coexist with human-driven vehicles
(HDVs). In this paper, we formulate the mixed-traffic highway on-ramp merging
problem as a multi-agent reinforcement learning (MARL) problem, where the AVs
(on both merge lane and through lane) collaboratively learn a policy to adapt
to HDVs to maximize the traffic throughput. We develop an efficient and
scalable MARL framework that can be used in dynamic traffic where the
communication topology could be time-varying. Parameter sharing and local
rewards are exploited to foster inter-agent cooperation while achieving great
scalability. An action masking scheme is employed to improve learning
efficiency by filtering out invalid/unsafe actions at each step. In addition, a
novel priority-based safety supervisor is developed to significantly reduce
collision rate and greatly expedite the training process. A gym-like simulation
environment is developed and open-sourced with three different levels of
traffic densities. We exploit curriculum learning to efficiently learn harder
tasks from trained models under simpler settings. Comprehensive experimental
results show the proposed MARL framework consistently outperforms several
state-of-the-art benchmarks.",arxiv
http://arxiv.org/abs/2106.12194v2,2021-07-05T03:05:21Z,2021-06-23T06:55:14Z,"Uncertainty-Aware Model-Based Reinforcement Learning with Application to
  Autonomous Driving","To further improve the learning efficiency and performance of reinforcement
learning (RL), in this paper we propose a novel uncertainty-aware model-based
RL (UA-MBRL) framework, and then implement and validate it in autonomous
driving under various task scenarios. First, an action-conditioned ensemble
model with the ability of uncertainty assessment is established as the virtual
environment model. Then, a novel uncertainty-aware model-based RL framework is
developed based on the adaptive truncation approach, providing virtual
interactions between the agent and environment model, and improving RL's
training efficiency and performance. The developed algorithms are then
implemented in end-to-end autonomous vehicle control tasks, validated and
compared with state-of-the-art methods under various driving scenarios. The
validation results suggest that the proposed UA-MBRL method surpasses the
existing model-based and model-free RL approaches, in terms of learning
efficiency and achieved performance. The results also demonstrate the good
ability of the proposed method with respect to the adaptiveness and robustness,
under various autonomous driving scenarios.",arxiv
http://arxiv.org/abs/2107.00200v3,2021-07-20T20:13:48Z,2021-07-01T03:37:05Z,Social Coordination and Altruism in Autonomous Driving,"Despite the advances in the autonomous driving domain, autonomous vehicles
(AVs) are still inefficient and limited in terms of cooperating with each other
or coordinating with vehicles operated by humans. A group of autonomous and
human-driven vehicles (HVs) which work together to optimize an altruistic
social utility -- as opposed to the egoistic individual utility -- can co-exist
seamlessly and assure safety and efficiency on the road. Achieving this mission
without explicit coordination among agents is challenging, mainly due to the
difficulty of predicting the behavior of humans with heterogeneous preferences
in mixed-autonomy environments. Formally, we model an AV's maneuver planning in
mixed-autonomy traffic as a partially-observable stochastic game and attempt to
derive optimal policies that lead to socially-desirable outcomes using a
multi-agent reinforcement learning framework. We introduce a quantitative
representation of the AVs' social preferences and design a distributed reward
structure that induces altruism into their decision making process. Our
altruistic AVs are able to form alliances, guide the traffic, and affect the
behavior of the HVs to handle competitive driving scenarios. As a case study,
we compare egoistic AVs to our altruistic autonomous agents in a highway
merging setting and demonstrate the emerging behaviors that lead to a
noticeable improvement in the number of successful merges as well as the
overall traffic flow and safety.",arxiv
http://arxiv.org/abs/2107.04538v1,2021-07-09T16:43:12Z,2021-07-09T16:43:12Z,"Learning Interaction-aware Guidance Policies for Motion Planning in
  Dense Traffic Scenarios","Autonomous navigation in dense traffic scenarios remains challenging for
autonomous vehicles (AVs) because the intentions of other drivers are not
directly observable and AVs have to deal with a wide range of driving
behaviors. To maneuver through dense traffic, AVs must be able to reason how
their actions affect others (interaction model) and exploit this reasoning to
navigate through dense traffic safely. This paper presents a novel framework
for interaction-aware motion planning in dense traffic scenarios. We explore
the connection between human driving behavior and their velocity changes when
interacting. Hence, we propose to learn, via deep Reinforcement Learning (RL),
an interaction-aware policy providing global guidance about the cooperativeness
of other vehicles to an optimization-based planner ensuring safety and
kinematic feasibility through constraint satisfaction. The learned policy can
reason and guide the local optimization-based planner with interactive behavior
to pro-actively merge in dense traffic while remaining safe in case the other
vehicles do not yield. We present qualitative and quantitative results in
highly interactive simulation environments (highway merging and unprotected
left turns) against two baseline approaches, a learning-based and an
optimization-based method. The presented results demonstrate that our method
significantly reduces the number of collisions and increases the success rate
with respect to both learning-based and optimization-based baselines.",arxiv
http://arxiv.org/abs/2107.07316v1,2021-07-15T13:36:55Z,2021-07-15T13:36:55Z,"Minimizing Safety Interference for Safe and Comfortable Automated
  Driving with Distributional Reinforcement Learning","Despite recent advances in reinforcement learning (RL), its application in
safety critical domains like autonomous vehicles is still challenging. Although
punishing RL agents for risky situations can help to learn safe policies, it
may also lead to highly conservative behavior. In this paper, we propose a
distributional RL framework in order to learn adaptive policies that can tune
their level of conservativity at run-time based on the desired comfort and
utility. Using a proactive safety verification approach, the proposed framework
can guarantee that actions generated from RL are fail-safe according to the
worst-case assumptions. Concurrently, the policy is encouraged to minimize
safety interference and generate more comfortable behavior. We trained and
evaluated the proposed approach and baseline policies using a high level
simulator with a variety of randomized scenarios including several corner cases
which rarely happen in reality but are very crucial. In light of our
experiments, the behavior of policies learned using distributional RL can be
adaptive at run-time and robust to the environment uncertainty. Quantitatively,
the learned distributional RL agent drives in average 8 seconds faster than the
normal DQN policy and requires 83\% less safety interference compared to the
rule-based policy with slightly increasing the average crossing time. We also
study sensitivity of the learned policy in environments with higher perception
noise and show that our algorithm learns policies that can still drive reliable
when the perception noise is two times higher than the training configuration
for automated merging and crossing at occluded intersections.",arxiv
http://arxiv.org/abs/2108.08448v1,2021-08-19T02:33:43Z,2021-08-19T02:33:43Z,"Prior Is All You Need to Improve the Robustness and Safety for the First
  Time Deployment of Meta RL","The field of Meta Reinforcement Learning (Meta-RL) has seen substantial
advancements recently. In particular, off-policy methods were developed to
improve the data efficiency of Meta-RL techniques. \textit{Probabilistic
embeddings for actor-critic RL} (PEARL) is currently one of the leading
approaches for multi-MDP adaptation problems. A major drawback of many existing
Meta-RL methods, including PEARL, is that they do not explicitly consider the
safety of the prior policy when it is exposed to a new task for the very first
time. This is very important for some real-world applications, including field
robots and Autonomous Vehicles (AVs). In this paper, we develop the PEARL PLUS
(PEARL$^+$) algorithm, which optimizes the policy for both prior safety and
posterior adaptation. Building on top of PEARL, our proposed PEARL$^+$
algorithm introduces a prior regularization term in the reward function and a
new Q-network for recovering the state-action value with prior context
assumption, to improve the robustness and safety of the trained network
exposing to a new task for the first time. The performance of the PEARL$^+$
method is demonstrated by solving three safety-critical decision-making
problems related to robots and AVs, including two MuJoCo benchmark problems.
From the simulation experiments, we show that the safety of the prior policy is
significantly improved compared to that of the original PEARL method.",arxiv
http://arxiv.org/abs/2109.11661v1,2021-09-23T21:55:12Z,2021-09-23T21:55:12Z,Learning-Based Path Planning for Long-Range Autonomous Valet Parking,"In this paper, to reduce the congestion rate at the city center and increase
the quality of experience (QoE) of each user, the framework of long-range
autonomous valet parking (LAVP) is presented, where an Electric Autonomous
Vehicle (EAV) is deployed in the city, which can pick up, drop off users at
their required spots, and then drive to the car park out of city center
autonomously. In this framework, we aim to minimize the overall distance of the
EAV, while guarantee all users are served, i.e., picking up, and dropping off
users at their required spots through optimizing the path planning of the EAV
and number of serving time slots. To this end, we first propose a learning
based algorithm, which is named as Double-Layer Ant Colony Optimization
(DL-ACO) algorithm to solve the above problem in an iterative way. Then, to
make the real-time decision, while consider the dynamic environment (i.e., the
EAV may pick up and drop off users from different locations), we further
present a deep reinforcement learning (DRL) based algorithm, which is known as
deep Q network (DQN). The experimental results show that the DL-ACO and
DQN-based algorithms both achieve the considerable performance.",arxiv
http://arxiv.org/abs/1905.03681v1,2019-05-09T15:13:36Z,2019-05-09T15:13:36Z,Forecasting Pedestrian Trajectory with Machine-Annotated Training Data,"Reliable anticipation of pedestrian trajectory is imperative for the
operation of autonomous vehicles and can significantly enhance the
functionality of advanced driver assistance systems. While significant progress
has been made in the field of pedestrian detection, forecasting pedestrian
trajectories remains a challenging problem due to the unpredictable nature of
pedestrians and the huge space of potentially useful features. In this work, we
present a deep learning approach for pedestrian trajectory forecasting using a
single vehicle-mounted camera. Deep learning models that have revolutionized
other areas in computer vision have seen limited application to trajectory
forecasting, in part due to the lack of richly annotated training data. We
address the lack of training data by introducing a scalable machine annotation
scheme that enables our model to be trained using a large dataset without human
annotation. In addition, we propose Dynamic Trajectory Predictor (DTP), a model
for forecasting pedestrian trajectory up to one second into the future. DTP is
trained using both human and machine-annotated data, and anticipates dynamic
motion that is not captured by linear models. Experimental evaluation confirms
the benefits of the proposed model.",arxiv
http://arxiv.org/abs/2009.12942v1,2020-09-27T20:30:10Z,2020-09-27T20:30:10Z,"A Survey on Deep Learning Methods for Semantic Image Segmentation in
  Real-Time","Semantic image segmentation is one of fastest growing areas in computer
vision with a variety of applications. In many areas, such as robotics and
autonomous vehicles, semantic image segmentation is crucial, since it provides
the necessary context for actions to be taken based on a scene understanding at
the pixel level. Moreover, the success of medical diagnosis and treatment
relies on the extremely accurate understanding of the data under consideration
and semantic image segmentation is one of the important tools in many cases.
Recent developments in deep learning have provided a host of tools to tackle
this problem efficiently and with increased accuracy. This work provides a
comprehensive analysis of state-of-the-art deep learning architectures in image
segmentation and, more importantly, an extensive list of techniques to achieve
fast inference and computational efficiency. The origins of these techniques as
well as their strengths and trade-offs are discussed with an in-depth analysis
of their impact in the area. The best-performing architectures are summarized
with a list of methods used to achieve these state-of-the-art results.",arxiv
http://arxiv.org/abs/2012.14618v4,2021-08-06T11:04:09Z,2020-12-29T05:58:35Z,FPCC: Fast Point Cloud Clustering for Instance Segmentation,"Instance segmentation is an important pre-processing task in numerous
real-world applications, such as robotics, autonomous vehicles, and
human-computer interaction. Compared with the rapid development of deep
learning for two-dimensional (2D) image tasks, deep learning-based instance
segmentation of 3D point cloud still has a lot of room for development. In
particular, distinguishing a large number of occluded objects of the same class
is a highly challenging problem, which is seen in a robotic bin-picking. In a
usual bin-picking scene, many indentical objects are stacked together and the
model of the objects is known. Thus, the semantic information can be ignored;
instead, the focus in the bin-picking is put on the segmentation of instances.
Based on this task requirement, we propose a Fast Point Cloud Clustering (FPCC)
for instance segmentation of bin-picking scene. FPCC includes a network named
FPCC-Net and a fast clustering algorithm. FPCC-net has two subnets, one for
inferring the geometric centers for clustering and the other for describing
features of each point. FPCC-Net extracts features of each point and infers
geometric center points of each instance simultaneously. After that, the
proposed clustering algorithm clusters the remaining points to the closest
geometric center in feature embedding space. Experiments show that FPCC also
surpasses the existing works in bin-picking scenes and is more computationally
efficient. Our code and data are available at https://github.com/xyjbaal/FPCC.",arxiv
http://arxiv.org/abs/2106.10458v2,2021-06-22T10:31:04Z,2021-06-19T09:17:15Z,Place recognition survey: An update on deep learning approaches,"Autonomous Vehicles (AV) are becoming more capable of navigating in complex
environments with dynamic and changing conditions. A key component that enables
these intelligent vehicles to overcome such conditions and become more
autonomous is the sophistication of the perception and localization systems. As
part of the localization system, place recognition has benefited from recent
developments in other perception tasks such as place categorization or object
recognition, namely with the emergence of deep learning (DL) frameworks. This
paper surveys recent approaches and methods used in place recognition,
particularly those based on deep learning. The contributions of this work are
twofold: surveying recent sensors such as 3D LiDARs and RADARs, applied in
place recognition; and categorizing the various DL-based place recognition
works into supervised, unsupervised, semi-supervised, parallel, and
hierarchical categories. First, this survey introduces key place recognition
concepts to contextualize the reader. Then, sensor characteristics are
addressed. This survey proceeds by elaborating on the various DL-based works,
presenting summaries for each framework. Some lessons learned from this survey
include: the importance of NetVLAD for supervised end-to-end learning; the
advantages of unsupervised approaches in place recognition, namely for
cross-domain applications; or the increasing tendency of recent works to seek,
not only for higher performance but also for higher efficiency.",arxiv
http://arxiv.org/abs/1808.03506v4,2019-03-05T23:50:01Z,2018-08-10T12:30:03Z,"ChipNet: Real-Time LiDAR Processing for Drivable Region Segmentation on
  an FPGA","This paper presents a field-programmable gate array (FPGA) design of a
segmentation algorithm based on convolutional neural network (CNN) that can
process light detection and ranging (LiDAR) data in real-time. For autonomous
vehicles, drivable region segmentation is an essential step that sets up the
static constraints for planning tasks. Traditional drivable region segmentation
algorithms are mostly developed on camera data, so their performance is
susceptible to the light conditions and the qualities of road markings. LiDAR
sensors can obtain the 3D geometry information of the vehicle surroundings with
high precision. However, it is a computational challenge to process a large
amount of LiDAR data in real-time. In this paper, a convolutional neural
network model is proposed and trained to perform semantic segmentation using
data from the LiDAR sensor. An efficient hardware architecture is proposed and
implemented on an FPGA that can process each LiDAR scan in 17.59 ms, which is
much faster than the previous works. Evaluated using Ford and KITTI road
detection benchmarks, the proposed solution achieves both high accuracy in
performance and real-time processing in speed.",arxiv
http://arxiv.org/abs/1711.02757v1,2017-11-07T22:42:09Z,2017-11-07T22:42:09Z,Real-Time Road Segmentation Using LiDAR Data Processing on an FPGA,"This paper presents the FPGA design of a convolutional neural network (CNN)
based road segmentation algorithm for real-time processing of LiDAR data. For
autonomous vehicles, it is important to perform road segmentation and obstacle
detection such that the drivable region can be identified for path planning.
Traditional road segmentation algorithms are mainly based on image data from
cameras, which is subjected to the light condition as well as the quality of
road markings. LiDAR sensor can obtain the 3D geometry information of the
vehicle surroundings with very high accuracy. However, it is a computational
challenge to process a large amount of LiDAR data at real-time. In this work, a
convolutional neural network model is proposed and trained to perform semantic
segmentation using the LiDAR sensor data. Furthermore, an efficient hardware
design is implemented on the FPGA that can process each LiDAR scan in 16.9ms,
which is much faster than the previous works. Evaluated using KITTI road
benchmarks, the proposed solution achieves high accuracy of road segmentation.",arxiv
http://arxiv.org/abs/1811.07070v2,2018-11-27T02:45:13Z,2018-11-17T01:03:37Z,DSCnet: Replicating Lidar Point Clouds with Deep Sensor Cloning,"Convolutional neural networks (CNNs) have become increasingly popular for
solving a variety of computer vision tasks, ranging from image classification
to image segmentation. Recently, autonomous vehicles have created a demand for
depth information, which is often obtained using hardware sensors such as Light
detection and ranging (LIDAR). Although it can provide precise distance
measurements, most LIDARs are still far too expensive to sell in mass-produced
consumer vehicles, which has motivated methods to generate depth information
from commodity automotive sensors like cameras.
  In this paper, we propose an approach called Deep Sensor Cloning (DSC). The
idea is to use Convolutional Neural Networks in conjunction with inexpensive
sensors to replicate the 3D point-clouds that are created by expensive LIDARs.
To accomplish this, we develop a new dataset (DSDepth) and a new family of CNN
architectures (DSCnets). While previous tasks such as KITTI depth prediction
use an interpolated RGB-D images as ground-truth for training, we instead use
DSCnets to directly predict LIDAR point-clouds. When we compare the output of
our models to a $75,000 LIDAR, we find that our most accurate DSCnet achieves a
relative error of 5.77% using a single camera and 4.69% using stereo cameras.",arxiv
http://arxiv.org/abs/1903.02193v2,2020-04-29T16:00:39Z,2019-03-06T06:29:18Z,"Robust Lane Detection from Continuous Driving Scenes Using Deep Neural
  Networks","Lane detection in driving scenes is an important module for autonomous
vehicles and advanced driver assistance systems. In recent years, many
sophisticated lane detection methods have been proposed. However, most methods
focus on detecting the lane from one single image, and often lead to
unsatisfactory performance in handling some extremely-bad situations such as
heavy shadow, severe mark degradation, serious vehicle occlusion, and so on. In
fact, lanes are continuous line structures on the road. Consequently, the lane
that cannot be accurately detected in one current frame may potentially be
inferred out by incorporating information of previous frames. To this end, we
investigate lane detection by using multiple frames of a continuous driving
scene, and propose a hybrid deep architecture by combining the convolutional
neural network (CNN) and the recurrent neural network (RNN). Specifically,
information of each frame is abstracted by a CNN block, and the CNN features of
multiple continuous frames, holding the property of time-series, are then fed
into the RNN block for feature learning and lane prediction. Extensive
experiments on two large-scale datasets demonstrate that, the proposed method
outperforms the competing methods in lane detection, especially in handling
difficult situations.",arxiv
http://arxiv.org/abs/1906.04117v1,2019-06-10T16:49:40Z,2019-06-10T16:49:40Z,Fast Hierarchical Neural Network for Feature Learning on Point Cloud,"The analyses relying on 3D point clouds are an utterly complex task, often
involving million of points, but also requiring computationally efficient
algorithms because of many real-time applications; e.g. autonomous vehicle.
However, point clouds are intrinsically irregular and the points are sparsely
distributed in a non-Euclidean space, which normally requires point-wise
processing to achieve high performances. Although shared filter matrices and
pooling layers in convolutional neural networks (CNNs) are capable of reducing
the dimensionality of the problem and extracting high-level information
simultaneously, grids and highly regular data format are required as input. In
order to balance model performance and complexity, we introduce a novel neural
network architecture exploiting local features from a manually subsampled point
set. In our network, a recursive farthest point sampling method is firstly
applied to efficiently cover the entire point set. Successively, we employ the
k-nearest neighbours (knn) algorithm to gather local neighbourhood for each
group of the subsampled points. Finally, a multiple layer perceptron (MLP) is
applied on the subsampled points and edges that connect corresponding point and
neighbours to extract local features. The architecture has been tested for both
shape classification and segmentation using the ModelNet40 and ShapeNet part
datasets, in order to show that the network achieves the best trade-off in
terms of competitive performance when compared to other state-of-the-art
algorithms.",arxiv
http://arxiv.org/abs/1910.08102v1,2019-10-17T18:26:31Z,2019-10-17T18:26:31Z,"Probabilistic Trajectory Prediction for Autonomous Vehicles with
  Attentive Recurrent Neural Process","Predicting surrounding vehicle behaviors are critical to autonomous vehicles
when negotiating in multi-vehicle interaction scenarios. Most existing
approaches require tedious training process with large amounts of data and may
fail to capture the propagating uncertainty in interaction behaviors. The
multi-vehicle behaviors are assumed to be generated from a stochastic process.
This paper proposes an attentive recurrent neural process (ARNP) approach to
overcome the above limitations, which uses a neural process (NP) to learn a
distribution of multi-vehicle interaction behavior. Our proposed model inherits
the flexibility of neural networks while maintaining Bayesian probabilistic
characteristics. Constructed by incorporating NPs with recurrent neural
networks (RNNs), the ARNP model predicts the distribution of a target vehicle
trajectory conditioned on the observed long-term sequential data of all
surrounding vehicles. This approach is verified by learning and predicting
lane-changing trajectories in complex traffic scenarios. Experimental results
demonstrate that our proposed method outperforms previous counterparts in terms
of accuracy and uncertainty expressiveness. Moreover, the meta-learning
instinct of NPs enables our proposed ARNP model to capture global information
of all observations, thereby being able to adapt to new targets efficiently.",arxiv
http://arxiv.org/abs/2002.10439v1,2020-02-24T18:38:17Z,2020-02-24T18:38:17Z,Improvements of Motion Estimation and Coding using Neural Networks,"Inter-Prediction is used effectively in multiple standards, including H.264
and HEVC (also known as H.265). It leverages correlation between blocks of
consecutive video frames in order to perform motion compensation and thus
predict block pixel values and reduce transmission bandwidth. In order to
reduce the magnitude of the transmitted Motion Vector (MV) and thus reduce
bandwidth, the encoder utilizes Predicted Motion Vector (PMV), which is derived
by taking the median vector of the corresponding MVs of the neighboring blocks.
In this research, we propose innovative methods, based on neural networks
prediction, for improving the accuracy of the calculated PMV. We begin by
showing a straightforward approach of calculating the best matching PMV and
signaling its neighbor block index value to the decoder while reducing the
number of bits required to represent the result without adding any computation
complexity. Then we use a classification Fully Connected Neural Networks (FCNN)
to estimate from neighbors the PMV without requiring signaling and show the
advantage of the approach when employed for high motion movies. We demonstrate
the advantages using fast forward movies. However, the same improvements apply
to camera streams of autonomous vehicles, drone cameras, Pan-Tilt-Zoom (PTZ)
cameras, and similar applications whereas the MVs magnitudes are expected to be
large. We also introduce a regression FCNN to predict the PMV. We calculate
Huffman coded streams and demonstrate an order of ~34% reduction in number of
bits required to transmit the best matching calculated PMV without reducing the
quality, for fast forward movies with high motion.",arxiv
http://arxiv.org/abs/2004.11824v1,2020-04-24T16:02:17Z,2020-04-24T16:02:17Z,Detecting Unsigned Physical Road Incidents from Driver-View Images,"Safety on roads is of uttermost importance, especially in the context of
autonomous vehicles. A critical need is to detect and communicate disruptive
incidents early and effectively. In this paper we propose a system based on an
off-the-shelf deep neural network architecture that is able to detect and
recognize types of unsigned (non-placarded, such as traffic signs), physical
(visible in images) road incidents. We develop a taxonomy for unsigned physical
incidents to provide a means of organizing and grouping related incidents.
After selecting eight target types of incidents, we collect a dataset of twelve
thousand images gathered from publicly-available web sources. We subsequently
fine-tune a convolutional neural network to recognize the eight types of road
incidents. The proposed model is able to recognize incidents with a high level
of accuracy (higher than 90%). We further show that while our system
generalizes well across spatial context by training a classifier on
geostratified data in the United Kingdom (with an accuracy of over 90%), the
translation to visually less similar environments requires spatially
distributed data collection.
  Note: this is a pre-print version of work accepted in IEEE Transactions on
Intelligent Vehicles (T-IV;in press). The paper is currently in production, and
the DOI link will be added soon.",arxiv
http://arxiv.org/abs/2006.03340v2,2021-06-03T22:52:06Z,2020-06-05T09:49:59Z,MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction,"Autonomous vehicles are expected to drive in complex scenarios with several
independent non cooperating agents. Path planning for safely navigating in such
environments can not just rely on perceiving present location and motion of
other agents. It requires instead to predict such variables in a far enough
future. In this paper we address the problem of multimodal trajectory
prediction exploiting a Memory Augmented Neural Network. Our method learns past
and future trajectory embeddings using recurrent neural networks and exploits
an associative external memory to store and retrieve such embeddings.
Trajectory prediction is then performed by decoding in-memory future encodings
conditioned with the observed past. We incorporate scene knowledge in the
decoding state by learning a CNN on top of semantic scene maps. Memory growth
is limited by learning a writing controller based on the predictive capability
of existing embeddings. We show that our method is able to natively perform
multi-modal trajectory prediction obtaining state-of-the art results on three
datasets. Moreover, thanks to the non-parametric nature of the memory module,
we show how once trained our system can continuously improve by ingesting novel
patterns.",arxiv
http://arxiv.org/abs/2007.13834v2,2021-10-05T14:37:19Z,2020-07-27T19:54:42Z,Adaptive LiDAR Sampling and Depth Completion using Ensemble Variance,"This work considers the problem of depth completion, with or without image
data, where an algorithm may measure the depth of a prescribed limited number
of pixels. The algorithmic challenge is to choose pixel positions strategically
and dynamically to maximally reduce overall depth estimation error. This
setting is realized in daytime or nighttime depth completion for autonomous
vehicles with a programmable LiDAR. Our method uses an ensemble of predictors
to define a sampling probability over pixels. This probability is proportional
to the variance of the predictions of ensemble members, thus highlighting
pixels that are difficult to predict. By additionally proceeding in several
prediction phases, we effectively reduce redundant sampling of similar pixels.
Our ensemble-based method may be implemented using any depth-completion
learning algorithm, such as a state-of-the-art neural network, treated as a
black box. In particular, we also present a simple and effective Random
Forest-based algorithm, and similarly use its internal ensemble in our design.
We conduct experiments on the KITTI dataset, using the neural network algorithm
of Ma et al. and our Random Forest based learner for implementing our method.
The accuracy of both implementations exceeds the state of the art. Compared
with a random or grid sampling pattern, our method allows a reduction by a
factor of 4-10 in the number of measurements required to attain the same
accuracy.",arxiv
http://arxiv.org/abs/2105.09163v2,2021-06-10T20:01:12Z,2021-05-12T06:20:44Z,High-Performance FPGA-based Accelerator for Bayesian Neural Networks,"Neural networks (NNs) have demonstrated their potential in a wide range of
applications such as image recognition, decision making or recommendation
systems. However, standard NNs are unable to capture their model uncertainty
which is crucial for many safety-critical applications including healthcare and
autonomous vehicles. In comparison, Bayesian neural networks (BNNs) are able to
express uncertainty in their prediction via a mathematical grounding.
Nevertheless, BNNs have not been as widely used in industrial practice, mainly
because of their expensive computational cost and limited hardware performance.
This work proposes a novel FPGA-based hardware architecture to accelerate BNNs
inferred through Monte Carlo Dropout. Compared with other state-of-the-art BNN
accelerators, the proposed accelerator can achieve up to 4 times higher energy
efficiency and 9 times better compute efficiency. Considering partial Bayesian
inference, an automatic framework is proposed, which explores the trade-off
between hardware and algorithmic performance. Extensive experiments are
conducted to demonstrate that our proposed framework can effectively find the
optimal points in the design space.",arxiv
http://arxiv.org/abs/2105.13038v1,2021-05-27T10:15:31Z,2021-05-27T10:15:31Z,"LVD-NMPC: A Learning-based Vision Dynamics Approach to Nonlinear Model
  Predictive Control for Autonomous Vehicles","In this paper, we introduce a learning-based vision dynamics approach to
nonlinear model predictive control for autonomous vehicles, coined LVD-NMPC.
LVD-NMPC uses an a-priori process model and a learned vision dynamics model
used to calculate the dynamics of the driving scene, the controlled system's
desired state trajectory and the weighting gains of the quadratic cost function
optimized by a constrained predictive controller. The vision system is defined
as a deep neural network designed to estimate the dynamics of the images scene.
The input is based on historic sequences of sensory observations and vehicle
states, integrated by an Augmented Memory component. Deep Q-Learning is used to
train the deep network, which once trained can be used to also calculate the
desired trajectory of the vehicle. We evaluate LVD-NMPC against a baseline
Dynamic Window Approach (DWA) path planning executed using standard NMPC, as
well as against the PilotNet neural network. Performance is measured in our
simulation environment GridSim, on a real-world 1:8 scaled model car, as well
as on a real size autonomous test vehicle and the nuScenes computer vision
dataset.",arxiv
http://arxiv.org/abs/2110.07742v1,2021-10-14T21:53:03Z,2021-10-14T21:53:03Z,"Beyond Classification: Directly Training Spiking Neural Networks for
  Semantic Segmentation","Spiking Neural Networks (SNNs) have recently emerged as the low-power
alternative to Artificial Neural Networks (ANNs) because of their sparse,
asynchronous, and binary event-driven processing. Due to their energy
efficiency, SNNs have a high possibility of being deployed for real-world,
resource-constrained systems such as autonomous vehicles and drones. However,
owing to their non-differentiable and complex neuronal dynamics, most previous
SNN optimization methods have been limited to image recognition. In this paper,
we explore the SNN applications beyond classification and present semantic
segmentation networks configured with spiking neurons. Specifically, we first
investigate two representative SNN optimization techniques for recognition
tasks (i.e., ANN-SNN conversion and surrogate gradient learning) on semantic
segmentation datasets. We observe that, when converted from ANNs, SNNs suffer
from high latency and low performance due to the spatial variance of features.
Therefore, we directly train networks with surrogate gradient learning,
resulting in lower latency and higher performance than ANN-SNN conversion.
Moreover, we redesign two fundamental ANN segmentation architectures (i.e.,
Fully Convolutional Networks and DeepLab) for the SNN domain. We conduct
experiments on two public semantic segmentation benchmarks including the PASCAL
VOC2012 dataset and the DDD17 event-based dataset. In addition to showing the
feasibility of SNNs for semantic segmentation, we show that SNNs can be more
robust and energy-efficient compared to their ANN counterparts in this domain.",arxiv
http://arxiv.org/abs/1904.02390v1,2019-04-04T07:41:07Z,2019-04-04T07:41:07Z,"Interaction-aware Multi-agent Tracking and Probabilistic Behavior
  Prediction via Adversarial Learning","In order to enable high-quality decision making and motion planning of
intelligent systems such as robotics and autonomous vehicles, accurate
probabilistic predictions for surrounding interactive objects is a crucial
prerequisite. Although many research studies have been devoted to making
predictions on a single entity, it remains an open challenge to forecast future
behaviors for multiple interactive agents simultaneously. In this work, we take
advantage of the Generative Adversarial Network (GAN) due to its capability of
distribution learning and propose a generic multi-agent probabilistic
prediction and tracking framework which takes the interactions among multiple
entities into account, in which all the entities are treated as a whole.
However, since GAN is very hard to train, we make an empirical research and
present the relationship between training performance and hyperparameter values
with a numerical case study. The results imply that the proposed model can
capture both the mean, variance and multi-modalities of the groundtruth
distribution. Moreover, we apply the proposed approach to a real-world task of
vehicle behavior prediction to demonstrate its effectiveness and accuracy. The
results illustrate that the proposed model trained by adversarial learning can
achieve a better prediction performance than other state-of-the-art models
trained by traditional supervised learning which maximizes the data likelihood.
The well-trained model can also be utilized as an implicit proposal
distribution for particle filtered based Bayesian state estimation.",arxiv
http://arxiv.org/abs/2109.12155v1,2021-09-24T19:20:00Z,2021-09-24T19:20:00Z,"Learning-based Initialization Strategy for Safety of Multi-Vehicle
  Systems","Multi-vehicle collision avoidance is a highly crucial problem due to the
soaring interests of introducing autonomous vehicles into the real world in
recent years. The safety of these vehicles while they complete their objectives
is of paramount importance. Hamilton-Jacobi (HJ) reachability is a promising
tool for guaranteeing safety for low-dimensional systems. However, due to its
exponential complexity in computation time, no reachability-based methods have
been able to guarantee safety for more than three vehicles successfully in
unstructured scenarios. For systems with four or more vehicles,we can only
empirically validate their safety performance.While reachability-based safety
methods enjoy a flexible least-restrictive control strategy, it is challenging
to reason about long-horizon trajectories online because safety at any given
state is determined by looking up its safety value in a pre-computed table that
does not exhibit favorable properties that continuous functions have. This
motivates the problem of improving the safety performance of unstructured
multi-vehicle systems when safety cannot be guaranteed given any
least-restrictive safety-aware collision avoidance algorithm while avoiding
online trajectory optimization. In this paper, we propose a novel approach
using supervised learning to enhance the safety of vehicles by proposing new
initial states in very close neighborhood of the original initial states of
vehicles. Our experiments demonstrate the effectiveness of our proposed
approach and show that vehicles are able to get to their goals with better
safety performance with our approach compared to a baseline approach in
wide-ranging scenarios.",arxiv
http://arxiv.org/abs/2104.06826v1,2021-04-14T12:57:40Z,2021-04-14T12:57:40Z,Towards Unsupervised Fine-Tuning for Edge Video Analytics,"Judging by popular and generic computer vision challenges, such as the
ImageNet or PASCAL VOC, neural networks have proven to be exceptionally
accurate in recognition tasks. However, state-of-the-art accuracy often comes
at a high computational price, requiring equally state-of-the-art and high-end
hardware acceleration to achieve anything near real-time performance. At the
same time, use cases such as smart cities or autonomous vehicles require an
automated analysis of images from fixed cameras in real-time. Due to the huge
and constant amount of network bandwidth these streams would generate, we
cannot rely on offloading compute to the omnipresent and omnipotent cloud.
Therefore, a distributed Edge Cloud must be in charge to process images
locally. However, the Edge Cloud is, by nature, resource-constrained, which
puts a limit on the computational complexity of the models executed in the
edge. Nonetheless, there is a need for a meeting point between the Edge Cloud
and accurate real-time video analytics. In this paper, we propose a method for
improving accuracy of edge models without any extra compute cost by means of
automatic model specialization. First, we show how the sole assumption of
static cameras allows us to make a series of considerations that greatly
simplify the scope of the problem. Then, we present Edge AutoTuner, a framework
that implements and brings these considerations together to automate the
end-to-end fine-tuning of models. Finally, we show that complex neural networks
- able to generalize better - can be effectively used as teachers to annotate
datasets for the fine-tuning of lightweight neural networks and tailor them to
the specific edge context, which boosts accuracy at constant computational
cost, and do so without any human interaction. Results show that our method can
automatically improve accuracy of pre-trained models by an average of 21%.",arxiv
http://arxiv.org/abs/1908.01924v1,2019-08-06T01:34:51Z,2019-08-06T01:34:51Z,"Edge AIBench: Towards Comprehensive End-to-end Edge Computing
  Benchmarking","In edge computing scenarios, the distribution of data and collaboration of
workloads on different layers are serious concerns for performance, privacy,
and security issues. So for edge computing benchmarking, we must take an
end-to-end view, considering all three layers: client-side devices, edge
computing layer, and cloud servers. Unfortunately, the previous work ignores
this most important point. This paper presents the BenchCouncil's coordinated e
ort on edge AI benchmarks, named Edge AIBench. In total, Edge AIBench models
four typical application scenarios: ICU Patient Monitor, Surveillance Camera,
Smart Home, and Autonomous Vehicle with the focus on data distribution and
workload collaboration on three layers. Edge AIBench is a part of the
open-source AIBench project, publicly available from
http://www.benchcouncil.org/AIBench/index.html. We also build an edge computing
testbed with a federated learning framework to resolve performance, privacy,
and security issues.",arxiv
http://arxiv.org/abs/2109.02529v2,2021-09-07T04:46:01Z,2021-09-06T15:12:17Z,"ViSTA: a Framework for Virtual Scenario-based Testing of Autonomous
  Vehicles","In this paper, we present ViSTA, a framework for Virtual Scenario-based
Testing of Autonomous Vehicles (AV), developed as part of the 2021 IEEE
Autonomous Test Driving AI Test Challenge. Scenario-based virtual testing aims
to construct specific challenges posed for the AV to overcome, albeit in
virtual test environments that may not necessarily resemble the real world.
This approach is aimed at identifying specific issues that arise safety
concerns before an actual deployment of the AV on the road. In this paper, we
describe a comprehensive test case generation approach that facilitates the
design of special-purpose scenarios with meaningful parameters to form test
cases, both in automated and manual ways, leveraging the strength and
weaknesses of either. Furthermore, we describe how to automate the execution of
test cases, and analyze the performance of the AV under these test cases.",arxiv
http://arxiv.org/abs/1801.02197v1,2018-01-07T15:04:52Z,2018-01-07T15:04:52Z,Realistic Image Degradation with Measured PSF,"Training autonomous vehicles requires lots of driving sequences in all
situations\cite{zhao2016}. Typically a simulation environment
(software-in-the-loop, SiL) accompanies real-world test drives to
systematically vary environmental parameters. A missing piece in the optical
model of those SiL simulations is the sharpness, given in linear system theory
by the point-spread function (PSF) of the optical system. We present a novel
numerical model for the PSF of an optical system that can efficiently model
both experimental measurements and lens design simulations of the PSF. The
numerical basis for this model is a non-linear regression of the PSF with an
artificial neural network (ANN). The novelty lies in the portability and the
parameterization of this model, which allows to apply this model in basically
any conceivable optical simulation scenario, e.g. inserting a measured lens
into a computer game to train autonomous vehicles. We present a lens
measurement series, yielding a numerical function for the PSF that depends only
on the parameters defocus, field and azimuth. By convolving existing images and
videos with this PSF model we apply the measured lens as a transfer function,
therefore generating an image as if it were seen with the measured lens itself.
Applications of this method are in any optical scenario, but we focus on the
context of autonomous driving, where quality of the detection algorithms
depends directly on the optical quality of the used camera system. With the
parameterization of the optical model we present a method to validate the
functional and safety limits of camera-based ADAS based on the real, measured
lens actually used in the product.",arxiv
http://arxiv.org/abs/2001.00048v1,2019-12-31T19:41:59Z,2019-12-31T19:41:59Z,"MIR-Vehicle: Cost-Effective Research Platform for Autonomous Vehicle
  Applications","This paper illustrates the MIR (Mobile Intelligent Robotics) Vehicle: a
feasible option of transforming an electric ride-on-car into a modular Graphics
Processing Unit (GPU) powered autonomous platform equipped with the capability
that supports test and deployment of various intelligent autonomous vehicles
algorithms. To use a platform for research, two components must be provided:
perception and control. The sensors such as incremental encoders, an Inertial
Measurement Unit (IMU), a camera, and a LIght Detection And Ranging (LIDAR)
must be able to be installed on the platform to add the capability of
environmental perception. A microcontroller-powered control box is designed to
properly respond to the environmental changes by regulating drive and steering
motors. This drive-by-wire capability is controlled by a GPU powered laptop
computer where high-level perception algorithms are processed and complex
actions are generated by various methods including behavior cloning using deep
neural networks. The main goal of this paper is to provide an adequate and
comprehensive approach for fabricating a cost-effective platform that would
contribute to the research quality from the wider community. The proposed
platform is to use a modular and hierarchical software architecture where the
lower and simpler motor controls are taken care of by microcontroller programs,
and the higher and complex algorithms are processed by a GPU powered laptop
computer. The platform uses the Robot Operating System (ROS) as middleware to
maintain the modularity of the perceptions and decision-making modules. It is
expected that the level three and above autonomous vehicle systems and Advanced
Driver Assistance Systems (ADAS) can be tested on and deployed to the platform
with a decent real-time system behavior due to the capabilities and
affordability of the proposed platform.",arxiv
http://arxiv.org/abs/2011.07948v4,2021-04-28T18:43:50Z,2020-11-04T16:04:42Z,"A Follow-the-Leader Strategy using Hierarchical Deep Neural Networks
  with Grouped Convolutions","The task of following-the-leader is implemented using a hierarchical Deep
Neural Network (DNN) end-to-end driving model to match the direction and speed
of a target pedestrian. The model uses a classifier DNN to determine if the
pedestrian is within the field of view of the camera sensor. If the pedestrian
is present, the image stream from the camera is fed to a regression DNN which
simultaneously adjusts the autonomous vehicle's steering and throttle to keep
cadence with the pedestrian. If the pedestrian is not visible, the vehicle uses
a straightforward exploratory search strategy to reacquire the tracking
objective. The classifier and regression DNNs incorporate grouped convolutions
to boost model performance as well as to significantly reduce parameter count
and compute latency. The models are trained on the Intelligence Processing Unit
(IPU) to leverage its fine-grain compute capabilities in order to minimize
time-to-train. The results indicate very robust tracking behavior on the part
of the autonomous vehicle in terms of its steering and throttle profiles, while
requiring minimal data collection to produce. The throughput in terms of
processing training samples has been boosted by the use of the IPU in
conjunction with grouped convolutions by a factor ~3.5 for training of the
classifier and a factor of ~7 for the regression network. A recording of the
vehicle tracking a pedestrian has been produced and is available on the web.
This is a preprint of an article published in SN Computer Science. The final
authenticated version is available online at:
https://doi.org/https://doi.org/10.1007/s42979-021-00572-1.",arxiv
http://arxiv.org/abs/2106.01730v1,2021-06-03T10:07:55Z,2021-06-03T10:07:55Z,Drivers' Manoeuvre Modelling and Prediction for Safe HRI,"As autonomous machines such as robots and vehicles start performing tasks
involving human users, ensuring a safe interaction between them becomes an
important issue. Translating methods from human-robot interaction (HRI) studies
to the interaction between humans and other highly complex machines (e.g.
semi-autonomous vehicles) could help advance the use of those machines in
scenarios requiring human interaction. One method involves understanding human
intentions and decision-making to estimate the human's present and near-future
actions whilst interacting with a robot. This idea originates from the
psychological concept of Theory of Mind, which has been broadly explored for
robotics and recently for autonomous and semi-autonomous vehicles. In this
work, we explored how to predict human intentions before an action is performed
by combining data from human-motion, vehicle-state and human inputs (e.g.
steering wheel, pedals). A data-driven approach based on Recurrent Neural
Network models was used to classify the current driving manoeuvre and to
predict the future manoeuvre to be performed. A state-transition model was used
with a fixed set of manoeuvres to label data recorded during the trials for
real-time applications. Models were trained and tested using drivers of
different seat preferences, driving expertise and arm-length; precision and
recall metrics over 95% for manoeuvre identification and 86% for manoeuvre
prediction were achieved, with prediction time-windows of up to 1 second for
both known and unknown test subjects. Compared to our previous results,
performance improved and manoeuvre prediction was possible for unknown test
subjects without knowing the current manoeuvre.",arxiv
http://arxiv.org/abs/2005.01976v1,2020-05-05T07:28:46Z,2020-05-05T07:28:46Z,"Distributed Adaptive Reinforcement Learning: A Method for Optimal
  Routing","In this paper, a learning-based optimal transportation algorithm for
autonomous taxis and ridesharing vehicles is presented. The goal is to design a
mechanism to solve the routing problem for multiple autonomous vehicles and
multiple customers in order to maximize the transportation company's profit. As
a result, each vehicle selects the customer whose request maximizes the
company's profit in the long run. To solve this problem, the system is modeled
as a Markov Decision Process (MDP) using past customers data. By solving the
defined MDP, a centralized high-level planning recommendation is obtained,
where this offline solution is used as an initial value for the real-time
learning. Then, a distributed SARSA reinforcement learning algorithm is
proposed to capture the model errors and the environment changes, such as
variations in customer distributions in each area, traffic, and fares, thereby
providing optimal routing policies in real-time. Vehicles, or agents, use only
their local information and interaction, such as current passenger requests and
estimates of neighbors' tasks and their optimal actions, to obtain the optimal
policies in a distributed fashion. An optimal adaptive rate is introduced to
make the distributed SARSA algorithm capable of adapting to changes in the
environment and tracking the time-varying optimal policies. Furthermore, a
game-theory-based task assignment algorithm is proposed, where each agent uses
the optimal policies and their values from distributed SARSA to select its
customer from the set of local available requests in a distributed manner.
Finally, the customers data provided by the city of Chicago is used to validate
the proposed algorithms.",arxiv
http://arxiv.org/abs/2007.13699v2,2020-09-20T19:09:34Z,2020-07-27T17:25:58Z,"FlexPool: A Distributed Model-Free Deep Reinforcement Learning Algorithm
  for Joint Passengers & Goods Transportation","The growth in online goods delivery is causing a dramatic surge in urban
vehicle traffic from last-mile deliveries. On the other hand, ride-sharing has
been on the rise with the success of ride-sharing platforms and increased
research on using autonomous vehicle technologies for routing and matching. The
future of urban mobility for passengers and goods relies on leveraging new
methods that minimize operational costs and environmental footprints of
transportation systems.
  This paper considers combining passenger transportation with goods delivery
to improve vehicle-based transportation. Even though the problem has been
studied with a defined dynamics model of the transportation system environment,
this paper considers a model-free approach that has been demonstrated to be
adaptable to new or erratic environment dynamics. We propose FlexPool, a
distributed model-free deep reinforcement learning algorithm that jointly
serves passengers & goods workloads by learning optimal dispatch policies from
its interaction with the environment. The proposed algorithm pools passengers
for a ride-sharing service and delivers goods using a multi-hop transit method.
These flexibilities decrease the fleet's operational cost and environmental
footprint while maintaining service levels for passengers and goods. Through
simulations on a realistic multi-agent urban mobility platform, we demonstrate
that FlexPool outperforms other model-free settings in serving the demands from
passengers & goods. FlexPool achieves 30% higher fleet utilization and 35%
higher fuel efficiency in comparison to (i) model-free approaches where
vehicles transport a combination of passengers & goods without the use of
multi-hop transit, and (ii) model-free approaches where vehicles exclusively
transport either passengers or goods.",arxiv
http://arxiv.org/abs/1607.08289v4,2019-01-21T19:29:30Z,2016-07-28T01:22:26Z,Mammalian Value Systems,"Characterizing human values is a topic deeply interwoven with the sciences,
humanities, art, and many other human endeavors. In recent years, a number of
thinkers have argued that accelerating trends in computer science, cognitive
science, and related disciplines foreshadow the creation of intelligent
machines which meet and ultimately surpass the cognitive abilities of human
beings, thereby entangling an understanding of human values with future
technological development. Contemporary research accomplishments suggest
sophisticated AI systems becoming widespread and responsible for managing many
aspects of the modern world, from preemptively planning users' travel schedules
and logistics, to fully autonomous vehicles, to domestic robots assisting in
daily living. The extrapolation of these trends has been most forcefully
described in the context of a hypothetical ""intelligence explosion,"" in which
the capabilities of an intelligent software agent would rapidly increase due to
the presence of feedback loops unavailable to biological organisms. The
possibility of superintelligent agents, or simply the widespread deployment of
sophisticated, autonomous AI systems, highlights an important theoretical
problem: the need to separate the cognitive and rational capacities of an agent
from the fundamental goal structure, or value system, which constrains and
guides the agent's actions. The ""value alignment problem"" is to specify a goal
structure for autonomous agents compatible with human values. In this brief
article, we suggest that recent ideas from affective neuroscience and related
disciplines aimed at characterizing neurological and behavioral universals in
the mammalian class provide important conceptual foundations relevant to
describing human values. We argue that the notion of ""mammalian value systems""
points to a potential avenue for fundamental research in AI safety and AI
ethics.",arxiv
http://arxiv.org/abs/1808.06352v1,2018-08-20T09:06:21Z,2018-08-20T09:06:21Z,"Navigating the Landscape for Real-time Localisation and Mapping for
  Robotics and Virtual and Augmented Reality","Visual understanding of 3D environments in real-time, at low power, is a huge
computational challenge. Often referred to as SLAM (Simultaneous Localisation
and Mapping), it is central to applications spanning domestic and industrial
robotics, autonomous vehicles, virtual and augmented reality. This paper
describes the results of a major research effort to assemble the algorithms,
architectures, tools, and systems software needed to enable delivery of SLAM,
by supporting applications specialists in selecting and configuring the
appropriate algorithm and the appropriate hardware, and compilation pathway, to
meet their performance, accuracy, and energy consumption goals. The major
contributions we present are (1) tools and methodology for systematic
quantitative evaluation of SLAM algorithms, (2) automated,
machine-learning-guided exploration of the algorithmic and implementation
design space with respect to multiple objectives, (3) end-to-end simulation
tools to enable optimisation of heterogeneous, accelerated architectures for
the specific algorithmic requirements of the various SLAM algorithmic
approaches, and (4) tools for delivering, where appropriate, accelerated,
adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",arxiv
http://arxiv.org/abs/1510.07313v1,2015-10-25T22:02:48Z,2015-10-25T22:02:48Z,Safe Control under Uncertainty,"Controller synthesis for hybrid systems that satisfy temporal specifications
expressing various system properties is a challenging problem that has drawn
the attention of many researchers. However, making the assumption that such
temporal properties are deterministic is far from the reality. For example,
many of the properties the controller has to satisfy are learned through
machine learning techniques based on sensor input data. In this paper, we
propose a new logic, Probabilistic Signal Temporal Logic (PrSTL), as an
expressive language to define the stochastic properties, and enforce
probabilistic guarantees on them. We further show how to synthesize safe
controllers using this logic for cyber-physical systems under the assumption
that the stochastic properties are based on a set of Gaussian random variables.
One of the key distinguishing features of PrSTL is that the encoded logic is
adaptive and changes as the system encounters additional data and updates its
beliefs about the latent random variables that define the safety properties. We
demonstrate our approach by synthesizing safe controllers under the PrSTL
specifications for multiple case studies including control of quadrotors and
autonomous vehicles in dynamic environments.",arxiv
http://arxiv.org/abs/1705.09785v1,2017-05-27T07:57:50Z,2017-05-27T07:57:50Z,LiDAR-Camera Calibration using 3D-3D Point correspondences,"With the advent of autonomous vehicles, LiDAR and cameras have become an
indispensable combination of sensors. They both provide rich and complementary
data which can be used by various algorithms and machine learning to sense and
make vital inferences about the surroundings. We propose a novel pipeline and
experimental setup to find accurate rigid-body transformation for extrinsically
calibrating a LiDAR and a camera. The pipeling uses 3D-3D point correspondences
in LiDAR and camera frame and gives a closed form solution. We further show the
accuracy of the estimate by fusing point clouds from two stereo cameras which
align perfectly with the rotation and translation estimated by our method,
confirming the accuracy of our method's estimates both mathematically and
visually. Taking our idea of extrinsic LiDAR-camera calibration forward, we
demonstrate how two cameras with no overlapping field-of-view can also be
calibrated extrinsically using 3D point correspondences. The code has been made
available as open-source software in the form of a ROS package, more
information about which can be sought here:
https://github.com/ankitdhall/lidar_camera_calibration .",arxiv
http://arxiv.org/abs/1803.07913v1,2018-03-21T13:37:24Z,2018-03-21T13:37:24Z,"HATS: Histograms of Averaged Time Surfaces for Robust Event-based Object
  Classification","Event-based cameras have recently drawn the attention of the Computer Vision
community thanks to their advantages in terms of high temporal resolution, low
power consumption and high dynamic range, compared to traditional frame-based
cameras. These properties make event-based cameras an ideal choice for
autonomous vehicles, robot navigation or UAV vision, among others. However, the
accuracy of event-based object classification algorithms, which is of crucial
importance for any reliable system working in real-world conditions, is still
far behind their frame-based counterparts. Two main reasons for this
performance gap are: 1. The lack of effective low-level representations and
architectures for event-based object classification and 2. The absence of large
real-world event-based datasets. In this paper we address both problems. First,
we introduce a novel event-based feature representation together with a new
machine learning architecture. Compared to previous approaches, we use local
memory units to efficiently leverage past temporal information and build a
robust event-based representation. Second, we release the first large
real-world event-based dataset for object classification. We compare our method
to the state-of-the-art with extensive experiments, showing better
classification performance and real-time computation.",arxiv
http://arxiv.org/abs/1903.07738v1,2019-03-18T21:50:12Z,2019-03-18T21:50:12Z,"Predicting Stochastic Human Forward Reachable Sets Based on Learned
  Human Behavior","With the recent surge of interest in introducing autonomous vehicles to the
everyday lives of people, developing accurate and generalizable algorithms for
predicting human behavior becomes highly crucial. Moreover, many of these
emerging applications occur in a safety-critical context, making it even more
urgent to develop good prediction models for human-operated vehicles. This is
fundamentally a challenging task as humans are often noisy in their decision
processes. Hamilton-Jacobi (HJ) reachability is a useful tool in control theory
that provides safety guarantees for collision avoidance. In this paper, we
first demonstrate how to incorporate information derived from HJ reachability
into a machine learning problem which predicts human behavior in a simulated
collision avoidance context, and show that this yields a higher prediction
accuracy than learning without this information. Then we propose a framework to
generate stochastic forward reachable sets that flexibly provides different
safety probabilities and generalizes to novel scenarios. We demonstrate that we
can construct stochastic reachable sets that can capture the trajectories with
probability from 0.75 to 1.",arxiv
http://arxiv.org/abs/1907.09454v1,2019-07-16T18:06:03Z,2019-07-16T18:06:03Z,"A Fog Computing Framework for Autonomous Driving Assist: Architecture,
  Experiments, and Challenges","Autonomous driving is expected to provide a range of far-reaching economic,
environmental and safety benefits. In this study, we propose a fog computing
based framework to assist autonomous driving. Our framework relies on overhead
views from cameras and data streams from vehicle sensors to create a network of
distributed digital twins, called an edge twin, on fog machines. The edge twin
will be continuously updated with the locations of both autonomous and
human-piloted vehicles on the road segments. The vehicle locations will be
harvested from overhead cameras as well as location feeds from the vehicles
themselves. Although the edge twin can make fair road space allocations from a
global viewpoint, there is a communication cost (delay) in reaching it from the
cameras and vehicular sensors. To address this, we introduce a machine learning
forecaster as a part of the edge twin which is responsible for predicting the
future location of vehicles. Lastly, we introduce a box algorithm that will use
the forecasted values to create a hazard map for the road segment which would
be used by the framework to suggest safe manoeuvres for the autonomous vehicles
such as lane changes and accelerations. We present the complete fog computing
framework for autonomous driving assist and evaluate key portions of the
proposed framework using simulations based on a real-world dataset of vehicle
position traces on a highway",arxiv
http://arxiv.org/abs/1907.10265v1,2019-07-24T06:54:04Z,2019-07-24T06:54:04Z,"Interpretable Classification of Time-Series Data using Efficient
  Enumerative Techniques","Cyber-physical system applications such as autonomous vehicles, wearable
devices, and avionic systems generate a large volume of time-series data.
Designers often look for tools to help classify and categorize the data.
Traditional machine learning techniques for time-series data offer several
solutions to solve these problems; however, the artifacts trained by these
algorithms often lack interpretability. On the other hand, temporal logics,
such as Signal Temporal Logic (STL) have been successfully used in the formal
methods community as specifications of time-series behaviors. In this work, we
propose a new technique to automatically learn temporal logic formulae that are
able to cluster and classify real-valued time-series data. Previous work on
learning STL formulas from data either assumes a formula-template to be given
by the user, or assumes some special fragment of STL that enables exploring the
formula structure in a systematic fashion. In our technique, we relax these
assumptions, and provide a way to systematically explore the space of all STL
formulas. As the space of all STL formulas is very large, and contains many
semantically equivalent formulas, we suggest a technique to heuristically prune
the space of formulas considered. Finally, we illustrate our technique on
various case studies from the automotive, transportation and healthcare domain.",arxiv
http://arxiv.org/abs/1911.09592v1,2019-11-21T16:37:18Z,2019-11-21T16:37:18Z,"mm-Pose: Real-Time Human Skeletal Posture Estimation using mmWave Radars
  and CNNs","In this paper, mm-Pose, a novel approach to detect and track human skeletons
in real-time using an mmWave radar, is proposed. To the best of the authors'
knowledge, this is the first method to detect >15 distinct skeletal joints
using mmWave radar reflection signals. The proposed method would find several
applications in traffic monitoring systems, autonomous vehicles, patient
monitoring systems and defense forces to detect and track human skeleton for
effective and preventive decision making in real-time. The use of radar makes
the system operationally robust to scene lighting and adverse weather
conditions. The reflected radar point cloud in range, azimuth and elevation are
first resolved and projected in Range-Azimuth and Range-Elevation planes. A
novel low-size high-resolution radar-to-image representation is also presented,
that overcomes the sparsity in traditional point cloud data and offers
significant reduction in the subsequent machine learning architecture. The RGB
channels were assigned with the normalized values of range, elevation/azimuth
and the power level of the reflection signals for each of the points. A forked
CNN architecture was used to predict the real-world position of the skeletal
joints in 3-D space, using the radar-to-image representation. The proposed
method was tested for a single human scenario for four primary motions, (i)
Walking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging
both arms to validate accurate predictions for motion in range, azimuth and
elevation. The detailed methodology, implementation, challenges, and validation
results are presented.",arxiv
http://arxiv.org/abs/2003.10931v1,2020-03-24T15:44:07Z,2020-03-24T15:44:07Z,"PointNetKL: Deep Inference for GICP Covariance Estimation in Bathymetric
  SLAM","Registration methods for point clouds have become a key component of many
SLAM systems on autonomous vehicles. However, an accurate estimate of the
uncertainty of such registration is a key requirement to a consistent fusion of
this kind of measurements in a SLAM filter. This estimate, which is normally
given as a covariance in the transformation computed between point cloud
reference frames, has been modelled following different approaches, among which
the most accurate is considered to be the Monte Carlo method. However, a Monte
Carlo approximation is cumbersome to use inside a time-critical application
such as online SLAM. Efforts have been made to estimate this covariance via
machine learning using carefully designed features to abstract the raw point
clouds. However, the performance of this approach is sensitive to the features
chosen. We argue that it is possible to learn the features along with the
covariance by working with the raw data and thus we propose a new approach
based on PointNet. In this work, we train this network using the KL divergence
between the learned uncertainty distribution and one computed by the Monte
Carlo method as the loss. We test the performance of the general model
presented applying it to our target use-case of SLAM with an autonomous
underwater vehicle (AUV) restricted to the 2-dimensional registration of 3D
bathymetric point clouds.",arxiv
http://arxiv.org/abs/2004.10049v1,2020-04-18T10:13:40Z,2020-04-18T10:13:40Z,"Learning Self-Awareness for Autonomous Vehicles: Exploring Multisensory
  Incremental Models","The technology for autonomous vehicles is close to replacing human drivers by
artificial systems endowed with high-level decision-making capabilities. In
this regard, systems must learn about the usual vehicle's behavior to predict
imminent difficulties before they happen. An autonomous agent should be capable
of continuously interacting with multi-modal dynamic environments while
learning unseen novel concepts. Such environments are not often available to
train the agent on it, so the agent should have an understanding of its own
capacities and limitations. This understanding is usually called
self-awareness. This paper proposes a multi-modal self-awareness modeling of
signals coming from different sources. This paper shows how different machine
learning techniques can be used under a generic framework to learn single
modality models by using Dynamic Bayesian Networks. In the presented case, a
probabilistic switching model and a bank of generative adversarial networks are
employed to model a vehicle's positional and visual information respectively.
Our results include experiments performed on a real vehicle, highlighting the
potentiality of the proposed approach at detecting abnormalities in real
scenarios.",arxiv
http://arxiv.org/abs/2006.04345v1,2020-06-08T04:07:57Z,2020-06-08T04:07:57Z,"Fast Synthetic LiDAR Rendering via Spherical UV Unwrapping of
  Equirectangular Z-Buffer Images","LiDAR data is becoming increasingly essential with the rise of autonomous
vehicles. Its ability to provide 360deg horizontal field of view of point
cloud, equips self-driving vehicles with enhanced situational awareness
capabilities. While synthetic LiDAR data generation pipelines provide a good
solution to advance the machine learning research on LiDAR, they do suffer from
a major shortcoming, which is rendering time. Physically accurate LiDAR
simulators (e.g. Blensor) are computationally expensive with an average
rendering time of 14-60 seconds per frame for urban scenes. This is often
compensated for via using 3D models with simplified polygon topology (low poly
assets) as is the case of CARLA (Dosovitskiy et al., 2017). However, this comes
at the price of having coarse grained unrealistic LiDAR point clouds. In this
paper, we present a novel method to simulate LiDAR point cloud with faster
rendering time of 1 sec per frame. The proposed method relies on spherical UV
unwrapping of Equirectangular Z-Buffer images. We chose Blensor (Gschwandtner
et al., 2011) as the baseline method to compare the point clouds generated
using the proposed method. The reported error for complex urban landscapes is
4.28cm for a scanning range between 2-120 meters with Velodyne HDL64-E2
parameters. The proposed method reported a total time per frame to 3.2 +/- 0.31
seconds per frame. In contrast, the BlenSor baseline method reported 16.2 +/-
1.82 seconds.",arxiv
http://arxiv.org/abs/2007.02203v6,2021-10-02T22:01:32Z,2020-07-04T23:00:52Z,"Accuracy-Efficiency Trade-Offs and Accountability in Distributed ML
  Systems","Trade-offs between accuracy and efficiency pervade law, public health, and
other non-computing domains, which have developed policies to guide how to
balance the two in conditions of uncertainty. While computer science also
commonly studies accuracy-efficiency trade-offs, their policy implications
remain poorly examined. Drawing on risk assessment practices in the US, we
argue that, since examining these trade-offs has been useful for guiding
governance in other domains, we need to similarly reckon with these trade-offs
in governing computer systems. We focus our analysis on distributed machine
learning systems. Understanding the policy implications in this area is
particularly urgent because such systems, which include autonomous vehicles,
tend to be high-stakes and safety-critical. We 1) describe how the trade-off
takes shape for these systems, 2) highlight gaps between existing US risk
assessment standards and what these systems require to be properly assessed,
and 3) make specific calls to action to facilitate accountability when
hypothetical risks concerning the accuracy-efficiency trade-off become realized
as accidents in the real world. We close by discussing how such accountability
mechanisms encourage more just, transparent governance aligned with public
values.",arxiv
http://arxiv.org/abs/2103.00644v1,2021-02-28T22:12:27Z,2021-02-28T22:12:27Z,DMPC: A Data-and Model-Driven Approach to Predictive Control,"This work presents DMPC (Data-and Model-Driven Predictive Control) to solve
control problems in which some of the constraints or parts of the objective
function are known, while others are entirely unknown to the controller. It is
assumed that there is an exogenous ``black box'' system, e.g. a machine
learning technique, that predicts the value of the unknown functions for a
given trajectory. DMPC (1) provides an approach to merge both the model-based
and black-box systems; (2) can cope with very little data and is sample
efficient, building its solutions based on recently generated trajectories; and
(3) improves its cost in each iteration until converging to an optimal
trajectory, typically needing only a few trials even for nonlinear dynamics and
objectives. Theoretical analysis of the algorithm is presented, proving that
the quality of the trajectory does not worsen with each new iteration, as well
as providing bounds on the complexity. We apply the DMPC algorithm to the
motion planning of an autonomous vehicle with nonlinear dynamics.",arxiv
http://arxiv.org/abs/2104.13889v1,2021-04-28T17:21:30Z,2021-04-28T17:21:30Z,Driver State and Behavior Detection Through Smart Wearables,"Integrating driver, in-cabin, and outside environment's contextual cues into
the vehicle's decision making is the centerpiece of semi-automated vehicle
safety. Multiple systems have been developed for providing context to the
vehicle, which often rely on video streams capturing drivers' physical and
environmental states. While video streams are a rich source of information,
their ability in providing context can be challenging in certain situations,
such as low illuminance environments (e.g., night driving), and they are highly
privacy-intrusive. In this study, we leverage passive sensing through
smartwatches for classifying elements of driving context. Specifically, through
using the data collected from 15 participants in a naturalistic driving study,
and by using multiple machine learning algorithms such as random forest, we
classify driver's activities (e.g., using phone and eating), outside events
(e.g., passing intersection and changing lane), and outside road attributes
(e.g., driving in a city versus a highway) with an average F1 score of 94.55,
98.27, and 97.86 % respectively, through 10-fold cross-validation. Our results
show the applicability of multimodal data retrieved through smart wearable
devices in providing context in real-world driving scenarios and pave the way
for a better shared autonomy and privacy-aware driving data-collection,
analysis, and feedback for future autonomous vehicles.",arxiv
http://arxiv.org/abs/2105.13289v1,2021-05-26T17:36:35Z,2021-05-26T17:36:35Z,"MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet
  of Vehicles","Modern vehicles, including connected vehicles and autonomous vehicles,
nowadays involve many electronic control units connected through intra-vehicle
networks to implement various functionalities and perform actions. Modern
vehicles are also connected to external networks through vehicle-to-everything
technologies, enabling their communications with other vehicles,
infrastructures, and smart devices. However, the improving functionality and
connectivity of modern vehicles also increase their vulnerabilities to
cyber-attacks targeting both intra-vehicle and external networks due to the
large attack surfaces. To secure vehicular networks, many researchers have
focused on developing intrusion detection systems (IDSs) that capitalize on
machine learning methods to detect malicious cyber-attacks. In this paper, the
vulnerabilities of intra-vehicle and external networks are discussed, and a
multi-tiered hybrid IDS that incorporates a signature-based IDS and an
anomaly-based IDS is proposed to detect both known and unknown attacks on
vehicular networks. Experimental results illustrate that the proposed system
can detect various types of known attacks with 99.99% accuracy on the
CAN-intrusion-dataset representing the intra-vehicle network data and 99.88%
accuracy on the CICIDS2017 dataset illustrating the external vehicular network
data. For the zero-day attack detection, the proposed system achieves high
F1-scores of 0.963 and 0.800 on the above two datasets, respectively. The
average processing time of each data packet on a vehicle-level machine is less
than 0.6 ms, which shows the feasibility of implementing the proposed system in
real-time vehicle systems. This emphasizes the effectiveness and efficiency of
the proposed IDS.",arxiv
http://arxiv.org/abs/2107.07557v1,2021-07-15T18:37:19Z,2021-07-15T18:37:19Z,OdoViz: A 3D Odometry Visualization and Processing Tool,"OdoViz is a reactive web-based tool for 3D visualization and processing of
autonomous vehicle datasets designed to support common tasks in visual place
recognition research. The system includes functionality for loading,
inspecting, visualizing, and processing GPS/INS poses, point clouds and camera
images. It supports a number of commonly used driving datasets and can be
adapted to load custom datasets with minimal effort. OdoViz's design consists
of a slim server to serve the datasets coupled with a rich client frontend.
This design supports multiple deployment configurations including single user
stand-alone installations, research group installations serving datasets
internally across a lab, or publicly accessible web-frontends for providing
online interfaces for exploring and interacting with datasets. The tool allows
viewing complete vehicle trajectories traversed at multiple different time
periods simultaneously, facilitating tasks such as sub-sampling, comparing and
finding pose correspondences both across and within sequences. This
significantly reduces the effort required in creating subsets of data from
existing datasets for machine learning tasks. Further to the above, the system
also supports adding custom extensions and plugins to extend the capabilities
of the software for other potential data management, visualization and
processing tasks. The platform has been open-sourced to promote its use and
encourage further contributions from the research community.",arxiv
http://arxiv.org/abs/2107.13507v1,2021-07-28T17:26:31Z,2021-07-28T17:26:31Z,"The Reasonable Crowd: Towards evidence-based and interpretable models of
  driving behavior","Autonomous vehicles must balance a complex set of objectives. There is no
consensus on how they should do so, nor on a model for specifying a desired
driving behavior. We created a dataset to help address some of these questions
in a limited operating domain. The data consists of 92 traffic scenarios, with
multiple ways of traversing each scenario. Multiple annotators expressed their
preference between pairs of scenario traversals. We used the data to compare an
instance of a rulebook, carefully hand-crafted independently of the dataset,
with several interpretable machine learning models such as Bayesian networks,
decision trees, and logistic regression trained on the dataset. To compare
driving behavior, these models use scores indicating by how much different
scenario traversals violate each of 14 driving rules. The rules are
interpretable and designed by subject-matter experts. First, we found that
these rules were enough for these models to achieve a high classification
accuracy on the dataset. Second, we found that the rulebook provides high
interpretability without excessively sacrificing performance. Third, the data
pointed to possible improvements in the rulebook and the rules, and to
potential new rules. Fourth, we explored the interpretability vs performance
trade-off by also training non-interpretable models such as a random forest.
Finally, we make the dataset publicly available to encourage a discussion from
the wider community on behavior specification for AVs. Please find it at
github.com/bassam-motional/Reasonable-Crowd.",arxiv
http://arxiv.org/abs/2108.01021v1,2021-08-02T16:27:59Z,2021-08-02T16:27:59Z,Learning off-road maneuver plans for autonomous vehicles,"This thesis explores the benefits machine learning algorithms can bring to
online planning and scheduling for autonomous vehicles in off-road situations.
Mainly, we focus on typical problems of interest which include computing
itineraries that meet certain objectives, as well as computing scheduling
strategies to execute synchronized maneuvers with other vehicles. We present a
range of learning-based heuristics to assist different itinerary planners. We
show that these heuristics allow a significant increase in performance for
optimal planners. Furthermore, in the case of approximate planning, we show
that not only does the running time decrease, the quality of the itinerary
found also becomes almost always better. Finally, in order to synthesize
strategies to execute synchronized maneuvers, we propose a novel type of
scheduling controllability and a learning-assisted algorithm. The proposed
framework achieves significant improvement on known benchmarks in this
controllability type over the performance of state-of-the-art works in a
related controllability type. Moreover, it is able to find strategies on
complex scheduling problems for which previous works fail to do so.",arxiv
http://arxiv.org/abs/1904.09085v1,2019-04-19T05:53:14Z,2019-04-19T05:53:14Z,"LATTE: Accelerating LiDAR Point Cloud Annotation via Sensor Fusion,
  One-Click Annotation, and Tracking","LiDAR (Light Detection And Ranging) is an essential and widely adopted sensor
for autonomous vehicles, particularly for those vehicles operating at higher
levels (L4-L5) of autonomy. Recent work has demonstrated the promise of
deep-learning approaches for LiDAR-based detection. However, deep-learning
algorithms are extremely data hungry, requiring large amounts of labeled
point-cloud data for training and evaluation. Annotating LiDAR point cloud data
is challenging due to the following issues: 1) A LiDAR point cloud is usually
sparse and has low resolution, making it difficult for human annotators to
recognize objects. 2) Compared to annotation on 2D images, the operation of
drawing 3D bounding boxes or even point-wise labels on LiDAR point clouds is
more complex and time-consuming. 3) LiDAR data are usually collected in
sequences, so consecutive frames are highly correlated, leading to repeated
annotations. To tackle these challenges, we propose LATTE, an open-sourced
annotation tool for LiDAR point clouds. LATTE features the following
innovations: 1) Sensor fusion: We utilize image-based detection algorithms to
automatically pre-label a calibrated image, and transfer the labels to the
point cloud. 2) One-click annotation: Instead of drawing 3D bounding boxes or
point-wise labels, we simplify the annotation to just one click on the target
object, and automatically generate the bounding box for the target. 3)
Tracking: we integrate tracking into sequence annotation such that we can
transfer labels from one frame to subsequent ones and therefore significantly
reduce repeated labeling. Experiments show the proposed features accelerate the
annotation speed by 6.2x and significantly improve label quality with 23.6% and
2.2% higher instance-level precision and recall, and 2.0% higher bounding box
IoU. LATTE is open-sourced at https://github.com/bernwang/latte.",arxiv
http://arxiv.org/abs/2005.01701v1,2020-05-04T17:57:37Z,2020-05-04T17:57:37Z,"IO-VNBD: Inertial and Odometry Benchmark Dataset for Ground Vehicle
  Positioning","Low-cost inertial navigation sensors (INS) can be exploited for a reliable
tracking solution for autonomous vehicles. However, position errors grow
exponentially due to noises in the measurements. Several deep learning
techniques have been investigated to mitigate the errors for a better
navigation solution [1-10]. However, these studies have involved the use of
different datasets not made publicly available. The lack of a robust benchmark
dataset has thus hindered the advancement in the research, comparison and
adoption of deep learning techniques for vehicle positioning based on inertial
navigation. In order to facilitate the benchmarking, fast development and
evaluation of positioning algorithms, we therefore present the first of its
kind large-scale and information-rich inertial and odometry focused public
dataset called IO-VNBD (Inertial Odometry Vehicle Navigation Benchmark
Dataset).The vehicle tracking dataset was recorded using a research vehicle
equipped with ego-motion sensors on public roads in the United Kingdom,
Nigeria, and France. The sensors include a GPS receiver, inertial navigation
sensors, wheel-speed sensors amongst other sensors found on the car as well as
the inertial navigation sensors and GPS receiver in an android smart phone
sampling at 10HZ. A diverse number of scenarios and vehicle dynamics are
captured such as traffic, round-abouts, hard-braking etc. on different road
types (country roads, motorways etc.) with varying driving patterns. The
dataset consists of a total driving time of about 40 hours over 1,300km for the
vehicle extracted data and about 58 hours over 4,400 km for the smartphone
recorded data. We hope that this dataset will prove valuable in furthering
research on the correlation between vehicle dynamics and its displacement as
well as other related studies",arxiv
http://arxiv.org/abs/2104.14089v1,2021-04-29T03:21:31Z,2021-04-29T03:21:31Z,Collaborative Human-Agent Planning for Resilience,"Intelligent agents powered by AI planning assist people in complex scenarios,
such as managing teams of semi-autonomous vehicles. However, AI planning models
may be incomplete, leading to plans that do not adequately meet the stated
objectives, especially in unpredicted situations. Humans, who are apt at
identifying and adapting to unusual situations, may be able to assist planning
agents in these situations by encoding their knowledge into a planner at
run-time. We investigate whether people can collaborate with agents by
providing their knowledge to an agent using linear temporal logic (LTL) at
run-time without changing the agent's domain model. We presented 24
participants with baseline plans for situations in which a planner had
limitations, and asked the participants for workarounds for these limitations.
We encoded these workarounds as LTL constraints. Results show that
participants' constraints improved the expected return of the plans by 10% ($p
< 0.05$) relative to baseline plans, demonstrating that human insight can be
used in collaborative planning for resilience. However, participants used more
declarative than control constraints over time, but declarative constraints
produced plans less similar to the expectation of the participants, which could
lead to potential trust issues.",arxiv
http://arxiv.org/abs/1806.05620v2,2018-08-15T08:09:22Z,2018-06-14T15:52:07Z,"DynaSLAM: Tracking, Mapping and Inpainting in Dynamic Scenes","The assumption of scene rigidity is typical in SLAM algorithms. Such a strong
assumption limits the use of most visual SLAM systems in populated real-world
environments, which are the target of several relevant applications like
service robotics or autonomous vehicles. In this paper we present DynaSLAM, a
visual SLAM system that, building over ORB-SLAM2 [1], adds the capabilities of
dynamic object detection and background inpainting. DynaSLAM is robust in
dynamic scenarios for monocular, stereo and RGB-D configurations. We are
capable of detecting the moving objects either by multi-view geometry, deep
learning or both. Having a static map of the scene allows inpainting the frame
background that has been occluded by such dynamic objects. We evaluate our
system in public monocular, stereo and RGB-D datasets. We study the impact of
several accuracy/speed trade-offs to assess the limits of the proposed
methodology. DynaSLAM outperforms the accuracy of standard visual SLAM
baselines in highly dynamic scenarios. And it also estimates a map of the
static parts of the scene, which is a must for long-term applications in
real-world environments.",arxiv
http://arxiv.org/abs/1812.02765v1,2018-12-06T19:34:30Z,2018-12-06T19:34:30Z,"Improving Reconstruction Autoencoder Out-of-distribution Detection with
  Mahalanobis Distance","There is an increasingly apparent need for validating the classifications
made by deep learning systems in safety-critical applications like autonomous
vehicle systems. A number of recent papers have proposed methods for detecting
anomalous image data that appear different from known inlier data samples,
including reconstruction-based autoencoders. Autoencoders optimize the
compression of input data to a latent space of a dimensionality smaller than
the original input and attempt to accurately reconstruct the input using that
compressed representation. Since the latent vector is optimized to capture the
salient features from the inlier class only, it is commonly assumed that images
of objects from outside of the training class cannot effectively be compressed
and reconstructed. Some thus consider reconstruction error as a kind of novelty
measure. Here we suggest that reconstruction-based approaches fail to capture
particular anomalies that lie far from known inlier samples in latent space but
near the latent dimension manifold defined by the parameters of the model. We
propose incorporating the Mahalanobis distance in latent space to better
capture these out-of-distribution samples and our results show that this method
often improves performance over the baseline approach.",arxiv
http://arxiv.org/abs/1902.07830v4,2020-02-08T11:15:55Z,2019-02-21T01:11:51Z,"Deep Multi-modal Object Detection and Semantic Segmentation for
  Autonomous Driving: Datasets, Methods, and Challenges","Recent advancements in perception for autonomous driving are driven by deep
learning. In order to achieve robust and accurate scene understanding,
autonomous vehicles are usually equipped with different sensors (e.g. cameras,
LiDARs, Radars), and multiple sensing modalities can be fused to exploit their
complementary properties. In this context, many methods have been proposed for
deep multi-modal perception problems. However, there is no general guideline
for network architecture design, and questions of ""what to fuse"", ""when to
fuse"", and ""how to fuse"" remain open. This review paper attempts to
systematically summarize methodologies and discuss challenges for deep
multi-modal object detection and semantic segmentation in autonomous driving.
To this end, we first provide an overview of on-board sensors on test vehicles,
open datasets, and background information for object detection and semantic
segmentation in autonomous driving research. We then summarize the fusion
methodologies and discuss challenges and open questions. In the appendix, we
provide tables that summarize topics and methods. We also provide an
interactive online platform to navigate each reference:
https://boschresearch.github.io/multimodalperception/.",arxiv
http://arxiv.org/abs/1903.01450v1,2019-03-04T04:56:08Z,2019-03-04T04:56:08Z,"The Smart Black Box: A Value-Driven High-Bandwidth Automotive Event Data
  Recorder","Autonomous vehicles require reliable and resilient sensor suites and ongoing
validation through fleet-wide data collection. This paper proposes a Smart
Black Box (SBB) to augment traditional low-bandwidth data logging with
value-driven high-bandwidth data capture. The SBB caches short-term histories
of data as buffers through a deterministic Mealy machine based on data value
and similarity. Compression quality for each frame is determined by optimizing
the trade-off between value and storage cost. With finite storage, prioritized
data recording discards low-value buffers to make room for new data. This paper
formulates SBB compression decision making as a constrained multi-objective
optimization problem with novel value metrics and filtering. The SBB has been
evaluated on a traffic simulator which generates trajectories containing events
of interest (EOIs) and corresponding first-person view videos. SBB compression
efficiency is assessed by comparing storage requirements with different
compression quality levels and event capture ratios. Performance is evaluated
by comparing results with a traditional first-in-first-out (FIFO) recording
scheme. Deep learning performance on images recorded at different compression
levels is evaluated to illustrate the reproducibility of SBB recorded data.",arxiv
http://arxiv.org/abs/1904.00415v2,2019-09-02T18:35:09Z,2019-03-31T14:04:16Z,"Road Scene Understanding by Occupancy Grid Learning from Sparse Radar
  Clusters using Semantic Segmentation","Occupancy grid mapping is an important component in road scene understanding
for autonomous driving. It encapsulates information of the drivable area, road
obstacles and enables safe autonomous driving. Radars are an emerging sensor in
autonomous vehicle vision, becoming more widely used due to their long range
sensing, low cost, and robustness to severe weather conditions. Despite recent
advances in deep learning technology, occupancy grid mapping from radar data is
still mostly done using classical filtering approaches.In this work, we propose
learning the inverse sensor model used for occupancy grid mapping from
clustered radar data. This is done in a data driven approach that leverages
computer vision techniques. This task is very challenging due to data sparsity
and noise characteristics of the radar sensor. The problem is formulated as a
semantic segmentation task and we show how it can be learned using lidar data
for generating ground truth. We show both qualitatively and quantitatively that
our learned occupancy net outperforms classic methods by a large margin using
the recently released NuScenes real-world driving data.",arxiv
http://arxiv.org/abs/1907.08719v1,2019-07-19T22:37:28Z,2019-07-19T22:37:28Z,"Cross-Domain Car Detection Using Unsupervised Image-to-Image
  Translation: From Day to Night","Deep learning techniques have enabled the emergence of state-of-the-art
models to address object detection tasks. However, these techniques are
data-driven, delegating the accuracy to the training dataset which must
resemble the images in the target task. The acquisition of a dataset involves
annotating images, an arduous and expensive process, generally requiring time
and manual effort. Thus, a challenging scenario arises when the target domain
of application has no annotated dataset available, making tasks in such
situation to lean on a training dataset of a different domain. Sharing this
issue, object detection is a vital task for autonomous vehicles where the large
amount of driving scenarios yields several domains of application requiring
annotated data for the training process. In this work, a method for training a
car detection system with annotated data from a source domain (day images)
without requiring the image annotations of the target domain (night images) is
presented. For that, a model based on Generative Adversarial Networks (GANs) is
explored to enable the generation of an artificial dataset with its respective
annotations. The artificial dataset (fake dataset) is created translating
images from day-time domain to night-time domain. The fake dataset, which
comprises annotated images of only the target domain (night images), is then
used to train the car detector model. Experimental results showed that the
proposed method achieved significant and consistent improvements, including the
increasing by more than 10% of the detection performance when compared to the
training with only the available annotated data (i.e., day images).",arxiv
http://arxiv.org/abs/1909.02563v1,2019-09-05T13:42:08Z,2019-09-05T13:42:08Z,DeepEvolution: A Search-Based Testing Approach for Deep Neural Networks,"The increasing inclusion of Deep Learning (DL) models in safety-critical
systems such as autonomous vehicles have led to the development of multiple
model-based DL testing techniques. One common denominator of these testing
techniques is the automated generation of test cases, e.g., new inputs
transformed from the original training data with the aim to optimize some test
adequacy criteria. So far, the effectiveness of these approaches has been
hindered by their reliance on random fuzzing or transformations that do not
always produce test cases with a good diversity. To overcome these limitations,
we propose, DeepEvolution, a novel search-based approach for testing DL models
that relies on metaheuristics to ensure a maximum diversity in generated test
cases. We assess the effectiveness of DeepEvolution in testing computer-vision
DL models and found that it significantly increases the neuronal coverage of
generated test cases. Moreover, using DeepEvolution, we could successfully find
several corner-case behaviors. Finally, DeepEvolution outperformed Tensorfuzz
(a coverage-guided fuzzing tool developed at Google Brain) in detecting latent
defects introduced during the quantization of the models. These results suggest
that search-based approaches can help build effective testing tools for DL
systems.",arxiv
http://arxiv.org/abs/1910.03336v1,2019-10-08T11:11:27Z,2019-10-08T11:11:27Z,"Improving Map Re-localization with Deep 'Movable' Objects Segmentation
  on 3D LiDAR Point Clouds","Localization and Mapping is an essential component to enable Autonomous
Vehicles navigation, and requires an accuracy exceeding that of commercial
GPS-based systems. Current odometry and mapping algorithms are able to provide
this accurate information. However, the lack of robustness of these algorithms
against dynamic obstacles and environmental changes, even for short time
periods, forces the generation of new maps on every session without taking
advantage of previously obtained ones. In this paper we propose the use of a
deep learning architecture to segment movable objects from 3D LiDAR point
clouds in order to obtain longer-lasting 3D maps. This will in turn allow for
better, faster and more accurate re-localization and trajectoy estimation on
subsequent days. We show the effectiveness of our approach in a very dynamic
and cluttered scenario, a supermarket parking lot. For that, we record several
sequences on different days and compare localization errors with and without
our movable objects segmentation method. Results show that we are able to
accurately re-locate over a filtered map, consistently reducing trajectory
errors between an average of 35.1% with respect to a non-filtered map version
and of 47.9% with respect to a standalone map created on the current session.",arxiv
http://arxiv.org/abs/1911.03565v1,2019-11-08T22:28:53Z,2019-11-08T22:28:53Z,"Vision-Based Lane-Changing Behavior Detection Using Deep Residual Neural
  Network","Accurate lane localization and lane change detection are crucial in advanced
driver assistance systems and autonomous driving systems for safer and more
efficient trajectory planning. Conventional localization devices such as Global
Positioning System only provide road-level resolution for car navigation, which
is incompetent to assist in lane-level decision making. The state of art
technique for lane localization is to use Light Detection and Ranging sensors
to correct the global localization error and achieve centimeter-level accuracy,
but the real-time implementation and popularization for LiDAR is still limited
by its computational burden and current cost. As a cost-effective alternative,
vision-based lane change detection has been highly regarded for affordable
autonomous vehicles to support lane-level localization. A deep learning-based
computer vision system is developed to detect the lane change behavior using
the images captured by a front-view camera mounted on the vehicle and data from
the inertial measurement unit for highway driving. Testing results on
real-world driving data have shown that the proposed method is robust with
real-time working ability and could achieve around 87% lane change detection
accuracy. Compared to the average human reaction to visual stimuli, the
proposed computer vision system works 9 times faster, which makes it capable of
helping make life-saving decisions in time.",arxiv
http://arxiv.org/abs/1911.08030v1,2019-11-19T01:15:20Z,2019-11-19T01:15:20Z,"Driver Identification Based on Vehicle Telematics Data using
  LSTM-Recurrent Neural Network","Despite advancements in vehicle security systems, over the last decade,
auto-theft rates have increased, and cyber-security attacks on
internet-connected and autonomous vehicles are becoming a new threat. In this
paper, a deep learning model is proposed, which can identify drivers from their
driving behaviors based on vehicle telematics data. The proposed
Long-Short-Term-Memory (LSTM) model predicts the identity of the driver based
on the individual's unique driving patterns learned from the vehicle telematics
data. Given the telematics is time-series data, the problem is formulated as a
time series prediction task to exploit the embedded sequential information. The
performance of the proposed approach is evaluated on three naturalistic driving
datasets, which gives high accuracy prediction results. The robustness of the
model on noisy and anomalous data that is usually caused by sensor defects or
environmental factors is also investigated. Results show that the proposed
model prediction accuracy remains satisfactory and outperforms the other
approaches despite the extent of anomalies and noise-induced in the data.",arxiv
http://arxiv.org/abs/1912.13077v1,2019-12-30T20:25:16Z,2019-12-30T20:25:16Z,"SelectFusion: A Generic Framework to Selectively Learn Multisensory
  Fusion","Autonomous vehicles and mobile robotic systems are typically equipped with
multiple sensors to provide redundancy. By integrating the observations from
different sensors, these mobile agents are able to perceive the environment and
estimate system states, e.g. locations and orientations. Although deep learning
approaches for multimodal odometry estimation and localization have gained
traction, they rarely focus on the issue of robust sensor fusion - a necessary
consideration to deal with noisy or incomplete sensor observations in the real
world. Moreover, current deep odometry models also suffer from a lack of
interpretability. To this extent, we propose SelectFusion, an end-to-end
selective sensor fusion module which can be applied to useful pairs of sensor
modalities such as monocular images and inertial measurements, depth images and
LIDAR point clouds. During prediction, the network is able to assess the
reliability of the latent features from different sensor modalities and
estimate both trajectory at scale and global pose. In particular, we propose
two fusion modules based on different attention strategies: deterministic soft
fusion and stochastic hard fusion, and we offer a comprehensive study of the
new strategies compared to trivial direct fusion. We evaluate all fusion
strategies in both ideal conditions and on progressively degraded datasets that
present occlusions, noisy and missing data and time misalignment between
sensors, and we investigate the effectiveness of the different fusion
strategies in attending the most reliable features, which in itself, provides
insights into the operation of the various models.",arxiv
http://arxiv.org/abs/2003.04447v1,2020-03-09T23:07:23Z,2020-03-09T23:07:23Z,"SDVTracker: Real-Time Multi-Sensor Association and Tracking for
  Self-Driving Vehicles","Accurate motion state estimation of Vulnerable Road Users (VRUs), is a
critical requirement for autonomous vehicles that navigate in urban
environments. Due to their computational efficiency, many traditional autonomy
systems perform multi-object tracking using Kalman Filters which frequently
rely on hand-engineered association. However, such methods fail to generalize
to crowded scenes and multi-sensor modalities, often resulting in poor state
estimates which cascade to inaccurate predictions. We present a practical and
lightweight tracking system, SDVTracker, that uses a deep learned model for
association and state estimation in conjunction with an Interacting Multiple
Model (IMM) filter. The proposed tracking method is fast, robust and
generalizes across multiple sensor modalities and different VRU classes. In
this paper, we detail a model that jointly optimizes both association and state
estimation with a novel loss, an algorithm for determining ground-truth
supervision, and a training procedure. We show this system significantly
outperforms hand-engineered methods on a real-world urban driving dataset while
running in less than 2.5 ms on CPU for a scene with 100 actors, making it
suitable for self-driving applications where low latency and high accuracy is
critical.",arxiv
http://arxiv.org/abs/2005.01935v1,2020-05-05T03:48:10Z,2020-05-05T03:48:10Z,"Probabilistic End-to-End Vehicle Navigation in Complex Dynamic
  Environments with Multimodal Sensor Fusion","All-day and all-weather navigation is a critical capability for autonomous
driving, which requires proper reaction to varied environmental conditions and
complex agent behaviors. Recently, with the rise of deep learning, end-to-end
control for autonomous vehicles has been well studied. However, most works are
solely based on visual information, which can be degraded by challenging
illumination conditions such as dim light or total darkness. In addition, they
usually generate and apply deterministic control commands without considering
the uncertainties in the future. In this paper, based on imitation learning, we
propose a probabilistic driving model with ultiperception capability utilizing
the information from the camera, lidar and radar. We further evaluate its
driving performance online on our new driving benchmark, which includes various
environmental conditions (e.g., urban and rural areas, traffic densities,
weather and times of the day) and dynamic obstacles (e.g., vehicles,
pedestrians, motorcyclists and bicyclists). The results suggest that our
proposed model outperforms baselines and achieves excellent generalization
performance in unseen environments with heavy traffic and extreme weather.",arxiv
http://arxiv.org/abs/2008.10592v1,2020-08-24T17:54:51Z,2020-08-24T17:54:51Z,3D for Free: Crossmodal Transfer Learning using HD Maps,"3D object detection is a core perceptual challenge for robotics and
autonomous driving. However, the class-taxonomies in modern autonomous driving
datasets are significantly smaller than many influential 2D detection datasets.
In this work, we address the long-tail problem by leveraging both the large
class-taxonomies of modern 2D datasets and the robustness of state-of-the-art
2D detection methods. We proceed to mine a large, unlabeled dataset of images
and LiDAR, and estimate 3D object bounding cuboids, seeded from an
off-the-shelf 2D instance segmentation model. Critically, we constrain this
ill-posed 2D-to-3D mapping by using high-definition maps and object size
priors. The result of the mining process is 3D cuboids with varying confidence.
This mining process is itself a 3D object detector, although not especially
accurate when evaluated as such. However, we then train a 3D object detection
model on these cuboids, consistent with other recent observations in the deep
learning literature, we find that the resulting model is fairly robust to the
noisy supervision that our mining process provides. We mine a collection of
1151 unlabeled, multimodal driving logs from an autonomous vehicle and use the
discovered objects to train a LiDAR-based object detector. We show that
detector performance increases as we mine more unlabeled data. With our full,
unlabeled dataset, our method performs competitively with fully supervised
methods, even exceeding the performance for certain object categories, without
any human 3D annotations.",arxiv
http://arxiv.org/abs/2011.06679v2,2021-01-28T18:47:34Z,2020-11-12T22:51:25Z,"Trajectory Prediction in Autonomous Driving with a Lane Heading
  Auxiliary Loss","Predicting a vehicle's trajectory is an essential ability for autonomous
vehicles navigating through complex urban traffic scenes. Bird's-eye-view
roadmap information provides valuable information for making trajectory
predictions, and while state-of-the-art models extract this information via
image convolution, auxiliary loss functions can augment patterns inferred from
deep learning by further encoding common knowledge of social and legal driving
behaviors. Since human driving behavior is inherently multimodal, models which
allow for multimodal output tend to outperform single-prediction models on
standard metrics. We propose a loss function which enhances such models by
enforcing expected driving rules on all predicted modes. Our contribution to
trajectory prediction is twofold; we propose a new metric which addresses
failure cases of the off-road rate metric by penalizing trajectories that
oppose the ascribed heading (flow direction) of a driving lane, and we show
this metric to be differentiable and therefore suitable as an auxiliary loss
function. We then use this auxiliary loss to extend the the standard multiple
trajectory prediction (MTP) and MultiPath models, achieving improved results on
the nuScenes prediction benchmark by predicting trajectories which better
conform to the lane-following rules of the road.",arxiv
http://arxiv.org/abs/2101.01158v1,2021-01-04T18:41:09Z,2021-01-04T18:41:09Z,A Hybrid Learner for Simultaneous Localization and Mapping,"Simultaneous localization and mapping (SLAM) is used to predict the dynamic
motion path of a moving platform based on the location coordinates and the
precise mapping of the physical environment. SLAM has great potential in
augmented reality (AR), autonomous vehicles, viz. self-driving cars, drones,
Autonomous navigation robots (ANR). This work introduces a hybrid learning
model that explores beyond feature fusion and conducts a multimodal weight
sewing strategy towards improving the performance of a baseline SLAM algorithm.
It carries out weight enhancement of the front end feature extractor of the
SLAM via mutation of different deep networks' top layers. At the same time, the
trajectory predictions from independently trained models are amalgamated to
refine the location detail. Thus, the integration of the aforesaid early and
late fusion techniques under a hybrid learning framework minimizes the
translation and rotation errors of the SLAM model. This study exploits some
well-known deep learning (DL) architectures, including ResNet18, ResNet34,
ResNet50, ResNet101, VGG16, VGG19, and AlexNet for experimental analysis. An
extensive experimental analysis proves that hybrid learner (HL) achieves
significantly better results than the unimodal approaches and multimodal
approaches with early or late fusion strategies. Hence, it is found that the
Apolloscape dataset taken in this work has never been used in the literature
under SLAM with fusion techniques, which makes this work unique and insightful.",arxiv
http://arxiv.org/abs/2102.07037v3,2021-10-26T04:48:53Z,2021-02-14T00:29:55Z,Robust Lane Detection via Expanded Self Attention,"The image-based lane detection algorithm is one of the key technologies in
autonomous vehicles. Modern deep learning methods achieve high performance in
lane detection, but it is still difficult to accurately detect lanes in
challenging situations such as congested roads and extreme lighting conditions.
To be robust on these challenging situations, it is important to extract global
contextual information even from limited visual cues. In this paper, we propose
a simple but powerful self-attention mechanism optimized for lane detection
called the Expanded Self Attention (ESA) module. Inspired by the simple
geometric structure of lanes, the proposed method predicts the confidence of a
lane along the vertical and horizontal directions in an image. The prediction
of the confidence enables estimating occluded locations by extracting global
contextual information. ESA module can be easily implemented and applied to any
encoder-decoder-based model without increasing the inference time. The
performance of our method is evaluated on three popular lane detection
benchmarks (TuSimple, CULane and BDD100K). We achieve state-of-the-art
performance in CULane and BDD100K and distinct improvement on TuSimple dataset.
The experimental results show that our approach is robust to occlusion and
extreme lighting conditions.",arxiv
http://arxiv.org/abs/2103.07783v1,2021-03-13T20:24:18Z,2021-03-13T20:24:18Z,"Multi-Object Tracking using Poisson Multi-Bernoulli Mixture Filtering
  for Autonomous Vehicles","The ability of an autonomous vehicle to perform 3D tracking is essential for
safe planing and navigation in cluttered environments. The main challenges for
multi-object tracking (MOT) in autonomous driving applications reside in the
inherent uncertainties regarding the number of objects, when and where the
objects may appear and disappear, and uncertainties regarding objects' states.
Random finite set (RFS) based approaches can naturally model these
uncertainties accurately and elegantly, and they have been widely used in
radar-based tracking applications. In this work, we developed an RFS-based MOT
framework for 3D LiDAR data. In partiuclar, we propose a Poisson
multi-Bernoulli mixture (PMBM) filter to solve the amodal MOT problem for
autonomous driving applications. To the best of our knowledge, this represents
a first attempt for employing an RFS-based approach in conjunction with 3D
LiDAR data for MOT applications with comprehensive validation using challenging
datasets made available by industry leaders. The superior experimental results
of our PMBM tracker on public Waymo and Argoverse datasets clearly illustrate
that an RFS-based tracker outperforms many state-of-the-art deep learning-based
and Kalman filter-based methods, and consequently, these results indicate a
great potential for further exploration of RFS-based frameworks for 3D MOT
applications.",arxiv
http://arxiv.org/abs/2103.15326v2,2021-07-30T10:27:00Z,2021-03-29T04:34:31Z,Fooling LiDAR Perception via Adversarial Trajectory Perturbation,"LiDAR point clouds collected from a moving vehicle are functions of its
trajectories, because the sensor motion needs to be compensated to avoid
distortions. When autonomous vehicles are sending LiDAR point clouds to deep
networks for perception and planning, could the motion compensation
consequently become a wide-open backdoor in those networks, due to both the
adversarial vulnerability of deep learning and GPS-based vehicle trajectory
estimation that is susceptible to wireless spoofing? We demonstrate such
possibilities for the first time: instead of directly attacking point cloud
coordinates which requires tampering with the raw LiDAR readings, only
adversarial spoofing of a self-driving car's trajectory with small
perturbations is enough to make safety-critical objects undetectable or
detected with incorrect positions. Moreover, polynomial trajectory perturbation
is developed to achieve a temporally-smooth and highly-imperceptible attack.
Extensive experiments on 3D object detection have shown that such attacks not
only lower the performance of the state-of-the-art detectors effectively, but
also transfer to other detectors, raising a red flag for the community. The
code is available on https://ai4ce.github.io/FLAT/.",arxiv
http://arxiv.org/abs/2103.17119v2,2021-07-02T08:46:54Z,2021-03-31T14:42:00Z,"Topo-boundary: A Benchmark Dataset on Topological Road-boundary
  Detection Using Aerial Images for Autonomous Driving","Road-boundary detection is important for autonomous driving. It can be used
to constrain autonomous vehicles running on road areas to ensure driving
safety. Compared with online road-boundary detection using on-vehicle
cameras/Lidars, offline detection using aerial images could alleviate the
severe occlusion issue. Moreover, the offline detection results can be directly
employed to annotate high-definition (HD) maps. In recent years, deep-learning
technologies have been used in offline detection. But there still lacks a
publicly available dataset for this task, which hinders the research progress
in this area. So in this paper, we propose a new benchmark dataset, named
\textit{Topo-boundary}, for offline topological road-boundary detection. The
dataset contains 25,295 $1000\times1000$-sized 4-channel aerial images. Each
image is provided with 8 training labels for different sub-tasks. We also
design a new entropy-based metric for connectivity evaluation, which could
better handle noises or outliers. We implement and evaluate 3
segmentation-based baselines and 5 graph-based baselines using the dataset. We
also propose a new imitation-learning-based baseline which is enhanced from our
previous work. The superiority of our enhancement is demonstrated from the
comparison. The dataset and our-implemented code for the baselines are
available at \texttt{\url{https://tonyxuqaq.github.io/Topo-boundary/}}.",arxiv
http://arxiv.org/abs/2105.00113v2,2021-06-02T15:21:53Z,2021-04-30T22:34:32Z,IPatch: A Remote Adversarial Patch,"Applications such as autonomous vehicles and medical screening use deep
learning models to localize and identify hundreds of objects in a single frame.
In the past, it has been shown how an attacker can fool these models by placing
an adversarial patch within a scene. However, these patches must be placed in
the target location and do not explicitly alter the semantics elsewhere in the
image.
  In this paper, we introduce a new type of adversarial patch which alters a
model's perception of an image's semantics. These patches can be placed
anywhere within an image to change the classification or semantics of locations
far from the patch. We call this new class of adversarial examples `remote
adversarial patches' (RAP).
  We implement our own RAP called IPatch and perform an in-depth analysis on
image segmentation RAP attacks using five state-of-the-art architectures with
eight different encoders on the CamVid street view dataset. Moreover, we
demonstrate that the attack can be extended to object recognition models with
preliminary results on the popular YOLOv3 model. We found that the patch can
change the classification of a remote target region with a success rate of up
to 93% on average.",arxiv
http://arxiv.org/abs/2106.02268v1,2021-06-04T05:27:09Z,2021-06-04T05:27:09Z,"A C-V2X Platform Using Transportation Data and Spectrum-Aware Sidelink
  Access","Intelligent transportation systems and autonomous vehicles are expected to
bring new experiences with enhanced efficiency and safety to road users in the
near future. However, an efficient and robust vehicular communication system
should act as a strong backbone to offer the needed infrastructure
connectivity. Deep learning (DL)-based algorithms are widely adopted recently
in various vehicular communication applications due to their achieved low
latency and fast reconfiguration properties. Yet, collecting actual and
sufficient transportation data to train DL-based vehicular communication models
is costly and complex. This paper introduces a cellular vehicle-to-everything
(C-V2X) verification platform based on an actual traffic simulator and
spectrum-aware access. This integrated platform can generate realistic
transportation and communication data, benefiting the development and
adaptivity of DL-based solutions. Accordingly, vehicular spectrum recognition
and management are further investigated to demonstrate the potentials of
dynamic slidelink access. Numerical results show that our platform can
effectively train and realize DL-based C-V2X algorithms. The developed
slidelink communication can adopt different operating bands with remarkable
spectrum detection performance, validating its practicality in real-world
vehicular environments.",arxiv
http://arxiv.org/abs/2106.05870v1,2021-06-01T09:50:19Z,2021-06-01T09:50:19Z,"Investigation of Uncertainty of Deep Learning-based Object
  Classification on Radar Spectra","Deep learning (DL) has recently attracted increasing interest to improve
object type classification for automotive radar.In addition to high accuracy,
it is crucial for decision making in autonomous vehicles to evaluate the
reliability of the predictions; however, decisions of DL networks are
non-transparent. Current DL research has investigated how uncertainties of
predictions can be quantified, and in this article, we evaluate the potential
of these methods for safe, automotive radar perception. In particular we
evaluate how uncertainty quantification can support radar perception under (1)
domain shift, (2) corruptions of input signals, and (3) in the presence of
unknown objects. We find that in agreement with phenomena observed in the
literature,deep radar classifiers are overly confident, even in their wrong
predictions. This raises concerns about the use of the confidence values for
decision making under uncertainty, as the model fails to notify when it cannot
handle an unknown situation. Accurate confidence values would allow optimal
integration of multiple information sources, e.g. via sensor fusion. We show
that by applying state-of-the-art post-hoc uncertainty calibration, the quality
of confidence measures can be significantly improved,thereby partially
resolving the over-confidence problem. Our investigation shows that further
research into training and calibrating DL networks is necessary and offers
great potential for safe automotive object classification with radar sensors.",arxiv
http://arxiv.org/abs/2106.09637v1,2021-06-17T16:34:37Z,2021-06-17T16:34:37Z,AttDLNet: Attention-based DL Network for 3D LiDAR Place Recognition,"Deep networks have been progressively adapted to new sensor modalities,
namely to 3D LiDAR, which led to unprecedented achievements in autonomous
vehicle-related applications such as place recognition. One of the main
challenges of deep models in place recognition is to extract efficient and
descriptive feature representations that relate places based on their
similarity. To address the problem of place recognition using LiDAR data, this
paper proposes a novel 3D LiDAR-based deep learning network (named AttDLNet)
that comprises an encoder network and exploits an attention mechanism to
selectively focus on long-range context and interfeature relationships. The
proposed network is trained and validated on the KITTI dataset, using the
cosine loss for training and a retrieval-based place recognition pipeline for
validation. Additionally, an ablation study is presented to assess the best
network configuration. Results show that the encoder network features are
already very descriptive, but adding attention to the network further improves
performance. From the ablation study, results indicate that the middle encoder
layers have the highest mean performance, while deeper layers are more robust
to orientation change. The code is publicly available on the project website:
https://github.com/Cybonic/ AttDLNet",arxiv
http://arxiv.org/abs/2107.10895v1,2021-07-22T19:40:52Z,2021-07-22T19:40:52Z,"SAGE: A Split-Architecture Methodology for Efficient End-to-End
  Autonomous Vehicle Control","Autonomous vehicles (AV) are expected to revolutionize transportation and
improve road safety significantly. However, these benefits do not come without
cost; AVs require large Deep-Learning (DL) models and powerful hardware
platforms to operate reliably in real-time, requiring between several hundred
watts to one kilowatt of power. This power consumption can dramatically reduce
vehicles' driving range and affect emissions. To address this problem, we
propose SAGE: a methodology for selectively offloading the key energy-consuming
modules of DL architectures to the cloud to optimize edge energy usage while
meeting real-time latency constraints. Furthermore, we leverage Head Network
Distillation (HND) to introduce efficient bottlenecks within the DL
architecture in order to minimize the network overhead costs of offloading with
almost no degradation in the model's performance. We evaluate SAGE using an
Nvidia Jetson TX2 and an industry-standard Nvidia Drive PX2 as the AV edge
devices and demonstrate that our offloading strategy is practical for a wide
range of DL models and internet connection bandwidths on 3G, 4G LTE, and WiFi
technologies. Compared to edge-only computation, SAGE reduces energy
consumption by an average of 36.13%, 47.07%, and 55.66% for an AV with one
low-resolution camera, one high-resolution camera, and three high-resolution
cameras, respectively. SAGE also reduces upload data size by up to 98.40%
compared to direct camera offloading.",arxiv
http://arxiv.org/abs/2109.07288v1,2021-09-15T13:31:49Z,2021-09-15T13:31:49Z,Two algorithms for vehicular obstacle detection in sparse pointcloud,"One of the main components of an autonomous vehicle is the obstacle detection
pipeline. Most prototypes, both from research and industry, rely on lidars for
this task. Pointcloud information from lidar is usually combined with data from
cameras and radars, but the backbone of the architecture is mainly based on 3D
bounding boxes computed from lidar data. To retrieve an accurate
representation, sensors with many planes, e.g., greater than 32 planes, are
usually employed. The returned pointcloud is indeed dense and well defined, but
high-resolution sensors are still expensive and often require powerful GPUs to
be processed. Lidars with fewer planes are cheaper, but the returned data are
not dense enough to be processed with state of the art deep learning approaches
to retrieve 3D bounding boxes. In this paper, we propose two solutions based on
occupancy grid and geometric refinement to retrieve a list of 3D bounding boxes
employing lidar with a low number of planes (i.e., 16 and 8 planes). Our
solutions have been validated on a custom acquired dataset with accurate ground
truth to prove its feasibility and accuracy.",arxiv
http://arxiv.org/abs/2109.15286v1,2021-09-30T17:30:43Z,2021-09-30T17:30:43Z,Unsupervised Domain Adaptation for LiDAR Panoptic Segmentation,"Scene understanding is a pivotal task for autonomous vehicles to safely
navigate in the environment. Recent advances in deep learning enable accurate
semantic reconstruction of the surroundings from LiDAR data. However, these
models encounter a large domain gap while deploying them on vehicles equipped
with different LiDAR setups which drastically decreases their performance.
Fine-tuning the model for every new setup is infeasible due to the expensive
and cumbersome process of recording and manually labeling new data.
Unsupervised Domain Adaptation (UDA) techniques are thus essential to fill this
domain gap and retain the performance of models on new sensor setups without
the need for additional data labeling. In this paper, we propose AdaptLPS, a
novel UDA approach for LiDAR panoptic segmentation that leverages task-specific
knowledge and accounts for variation in the number of scan lines, mounting
position, intensity distribution, and environmental conditions. We tackle the
UDA task by employing two complementary domain adaptation strategies,
data-based and model-based. While data-based adaptations reduce the domain gap
by processing the raw LiDAR scans to resemble the scans in the target domain,
model-based techniques guide the network in extracting features that are
representative for both domains. Extensive evaluations on three pairs of
real-world autonomous driving datasets demonstrate that AdaptLPS outperforms
existing UDA approaches by up to 6.41 pp in terms of the PQ score.",arxiv
http://arxiv.org/abs/1804.05810v3,2019-05-01T03:41:44Z,2018-04-16T17:29:43Z,"ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object
  Detector","Given the ability to directly manipulate image pixels in the digital input
space, an adversary can easily generate imperceptible perturbations to fool a
Deep Neural Network (DNN) image classifier, as demonstrated in prior work. In
this work, we propose ShapeShifter, an attack that tackles the more challenging
problem of crafting physical adversarial perturbations to fool image-based
object detectors like Faster R-CNN. Attacking an object detector is more
difficult than attacking an image classifier, as it needs to mislead the
classification results in multiple bounding boxes with different scales.
Extending the digital attack to the physical world adds another layer of
difficulty, because it requires the perturbation to be robust enough to survive
real-world distortions due to different viewing distances and angles, lighting
conditions, and camera limitations. We show that the Expectation over
Transformation technique, which was originally proposed to enhance the
robustness of adversarial perturbations in image classification, can be
successfully adapted to the object detection setting. ShapeShifter can generate
adversarially perturbed stop signs that are consistently mis-detected by Faster
R-CNN as other objects, posing a potential threat to autonomous vehicles and
other safety-critical computer vision systems.",arxiv
http://arxiv.org/abs/1804.07834v2,2019-01-30T20:21:15Z,2018-04-20T21:38:32Z,"HandyNet: A One-stop Solution to Detect, Segment, Localize & Analyze
  Driver Hands","Tasks related to human hands have long been part of the computer vision
community. Hands being the primary actuators for humans, convey a lot about
activities and intents, in addition to being an alternative form of
communication/interaction with other humans and machines. In this study, we
focus on training a single feedforward convolutional neural network (CNN)
capable of executing many hand related tasks that may be of use in autonomous
and semi-autonomous vehicles of the future. The resulting network, which we
refer to as HandyNet, is capable of detecting, segmenting and localizing (in
3D) driver hands inside a vehicle cabin. The network is additionally trained to
identify handheld objects that the driver may be interacting with. To meet the
data requirements to train such a network, we propose a method for cheap
annotation based on chroma-keying, thereby bypassing weeks of human effort
required to label such data. This process can generate thousands of labeled
training samples in an efficient manner, and may be replicated in new
environments with relative ease.",arxiv
http://arxiv.org/abs/1804.09915v1,2018-04-26T07:18:30Z,2018-04-26T07:18:30Z,"Boosting LiDAR-based Semantic Labeling by Cross-Modal Training Data
  Generation","Mobile robots and autonomous vehicles rely on multi-modal sensor setups to
perceive and understand their surroundings. Aside from cameras, LiDAR sensors
represent a central component of state-of-the-art perception systems. In
addition to accurate spatial perception, a comprehensive semantic understanding
of the environment is essential for efficient and safe operation. In this paper
we present a novel deep neural network architecture called LiLaNet for
point-wise, multi-class semantic labeling of semi-dense LiDAR data. The network
utilizes virtual image projections of the 3D point clouds for efficient
inference. Further, we propose an automated process for large-scale cross-modal
training data generation called Autolabeling, in order to boost semantic
labeling performance while keeping the manual annotation effort low. The
effectiveness of the proposed network architecture as well as the automated
data generation process is demonstrated on a manually annotated ground truth
dataset. LiLaNet is shown to significantly outperform current state-of-the-art
CNN architectures for LiDAR data. Applying our automatically generated
large-scale training data yields a boost of up to 14 percentage points compared
to networks trained on manually annotated data only.",arxiv
http://arxiv.org/abs/1804.10829v3,2018-07-01T17:33:53Z,2018-04-28T16:37:01Z,Formal Security Analysis of Neural Networks using Symbolic Intervals,"Due to the increasing deployment of Deep Neural Networks (DNNs) in real-world
security-critical domains including autonomous vehicles and collision avoidance
systems, formally checking security properties of DNNs, especially under
different attacker capabilities, is becoming crucial. Most existing security
testing techniques for DNNs try to find adversarial examples without providing
any formal security guarantees about the non-existence of such adversarial
examples. Recently, several projects have used different types of
Satisfiability Modulo Theory (SMT) solvers to formally check security
properties of DNNs. However, all of these approaches are limited by the high
overhead caused by the solver.
  In this paper, we present a new direction for formally checking security
properties of DNNs without using SMT solvers. Instead, we leverage interval
arithmetic to compute rigorous bounds on the DNN outputs. Our approach, unlike
existing solver-based approaches, is easily parallelizable. We further present
symbolic interval analysis along with several other optimizations to minimize
overestimations of output bounds.
  We design, implement, and evaluate our approach as part of ReluVal, a system
for formally checking security properties of Relu-based DNNs. Our extensive
empirical results show that ReluVal outperforms Reluplex, a state-of-the-art
solver-based system, by 200 times on average. On a single 8-core machine
without GPUs, within 4 hours, ReluVal is able to verify a security property
that Reluplex deemed inconclusive due to timeout after running for more than 5
days. Our experiments demonstrate that symbolic interval analysis is a
promising new direction towards rigorously analyzing different security
properties of DNNs.",arxiv
http://arxiv.org/abs/1805.04333v1,2018-05-11T11:31:47Z,2018-05-11T11:31:47Z,"Quantitative Projection Coverage for Testing ML-enabled Autonomous
  Systems","Systematically testing models learned from neural networks remains a crucial
unsolved barrier to successfully justify safety for autonomous vehicles
engineered using data-driven approach. We propose quantitative k-projection
coverage as a metric to mediate combinatorial explosion while guiding the data
sampling process. By assuming that domain experts propose largely independent
environment conditions and by associating elements in each condition with
weights, the product of these conditions forms scenarios, and one may interpret
weights associated with each equivalence class as relative importance.
Achieving full k-projection coverage requires that the data set, when being
projected to the hyperplane formed by arbitrarily selected k-conditions, covers
each class with number of data points no less than the associated weight. For
the general case where scenario composition is constrained by rules, precisely
computing k-projection coverage remains in NP. In terms of finding minimum test
cases to achieve full coverage, we present theoretical complexity for important
sub-cases and an encoding to 0-1 integer programming. We have implemented a
research prototype that generates test cases for a visual object defection unit
in automated driving, demonstrating the technological feasibility of our
proposed coverage criterion.",arxiv
http://arxiv.org/abs/1711.09561v1,2017-11-27T07:07:11Z,2017-11-27T07:07:11Z,HP-GAN: Probabilistic 3D human motion prediction via GAN,"Predicting and understanding human motion dynamics has many applications,
such as motion synthesis, augmented reality, security, and autonomous vehicles.
Due to the recent success of generative adversarial networks (GAN), there has
been much interest in probabilistic estimation and synthetic data generation
using deep neural network architectures and learning algorithms.
  We propose a novel sequence-to-sequence model for probabilistic human motion
prediction, trained with a modified version of improved Wasserstein generative
adversarial networks (WGAN-GP), in which we use a custom loss function designed
for human motion prediction. Our model, which we call HP-GAN, learns a
probability density function of future human poses conditioned on previous
poses. It predicts multiple sequences of possible future human poses, each from
the same input sequence but a different vector z drawn from a random
distribution. Furthermore, to quantify the quality of the non-deterministic
predictions, we simultaneously train a motion-quality-assessment model that
learns the probability that a given skeleton sequence is a real human motion.
  We test our algorithm on two of the largest skeleton datasets: NTURGB-D and
Human3.6M. We train our model on both single and multiple action types. Its
predictive power for long-term motion estimation is demonstrated by generating
multiple plausible futures of more than 30 frames from just 10 frames of input.
We show that most sequences generated from the same input have more than 50\%
probabilities of being judged as a real human sequence. We will release all the
code used in this paper to Github.",arxiv
http://arxiv.org/abs/1802.02690v2,2018-04-25T00:45:58Z,2018-02-08T02:13:50Z,"Driver Gaze Zone Estimation using Convolutional Neural Networks: A
  General Framework and Ablative Analysis","Driver gaze has been shown to be an excellent surrogate for driver attention
in intelligent vehicles. With the recent surge of highly autonomous vehicles,
driver gaze can be useful for determining the handoff time to a human driver.
While there has been significant improvement in personalized driver gaze zone
estimation systems, a generalized system which is invariant to different
subjects, perspectives and scales is still lacking. We take a step towards this
generalized system using Convolutional Neural Networks (CNNs). We finetune 4
popular CNN architectures for this task, and provide extensive comparisons of
their outputs. We additionally experiment with different input image patches,
and also examine how image size affects performance. For training and testing
the networks, we collect a large naturalistic driving dataset comprising of 11
long drives, driven by 10 subjects in two different cars. Our best performing
model achieves an accuracy of 95.18% during cross-subject testing,
outperforming current state of the art techniques for this task. Finally, we
evaluate our best performing model on the publicly available Columbia Gaze
Dataset comprising of images from 56 subjects with varying head pose and gaze
directions. Without any training, our model successfully encodes the different
gaze directions on this diverse dataset, demonstrating good generalization
capabilities.",arxiv
http://arxiv.org/abs/1802.09975v1,2018-02-27T15:46:15Z,2018-02-27T15:46:15Z,"Mono-Camera 3D Multi-Object Tracking Using Deep Learning Detections and
  PMBM Filtering","Monocular cameras are one of the most commonly used sensors in the automotive
industry for autonomous vehicles. One major drawback using a monocular camera
is that it only makes observations in the two dimensional image plane and can
not directly measure the distance to objects. In this paper, we aim at filling
this gap by developing a multi-object tracking algorithm that takes an image as
input and produces trajectories of detected objects in a world coordinate
system. We solve this by using a deep neural network trained to detect and
estimate the distance to objects from a single input image. The detections from
a sequence of images are fed in to a state-of-the art Poisson multi-Bernoulli
mixture tracking filter. The combination of the learned detector and the PMBM
filter results in an algorithm that achieves 3D tracking using only mono-camera
images as input. The performance of the algorithm is evaluated both in 3D world
coordinates, and 2D image coordinates, using the publicly available KITTI
object tracking dataset. The algorithm shows the ability to accurately track
objects, correctly handle data associations, even when there is a big overlap
of the objects in the image, and is one of the top performing algorithms on the
KITTI object tracking benchmark. Furthermore, the algorithm is efficient,
running on average close to 20 frames per second.",arxiv
http://arxiv.org/abs/1806.00678v1,2018-06-02T17:46:33Z,2018-06-02T17:46:33Z,AutoRally An open platform for aggressive autonomous driving,"This article presents AutoRally, a 1$:$5 scale robotics testbed for
autonomous vehicle research. AutoRally is designed for robustness, ease of use,
and reproducibility, so that a team of two people with limited knowledge of
mechanical engineering, electrical engineering, and computer science can
construct and then operate the testbed to collect real world autonomous driving
data in whatever domain they wish to study. Complete documentation to construct
and operate the platform is available online along with tutorials, example
controllers, and a driving dataset collected at the Georgia Tech Autonomous
Racing Facility. Offline estimation algorithms are used to determine parameters
for physics-based dynamics models using an adaptive limited memory joint state
unscented Kalman filter. Online vehicle state estimation using a factor graph
optimization scheme and a convolutional neural network for semantic
segmentation of drivable surface are presented. All algorithms are tested with
real world data from the fleet of six AutoRally robots at the Georgia Tech
Autonomous Racing Facility tracks, and serve as a demonstration of the
robot$'$s capabilities.",arxiv
http://arxiv.org/abs/1807.01866v3,2021-08-26T09:51:33Z,2018-07-05T06:58:13Z,Multi-Task Trust Transfer for Human-Robot Interaction,"Trust is essential in shaping human interactions with one another and with
robots. This paper discusses how human trust in robot capabilities transfers
across multiple tasks. We first present a human-subject study of two distinct
task domains: a Fetch robot performing household tasks and a virtual reality
simulation of an autonomous vehicle performing driving and parking maneuvers.
The findings expand our understanding of trust and inspire new differentiable
models of trust evolution and transfer via latent task representations: (i) a
rational Bayes model, (ii) a data-driven neural network model, and (iii) a
hybrid model that combines the two. Experiments show that the proposed models
outperform prevailing models when predicting trust over unseen tasks and users.
These results suggest that (i) task-dependent functional trust models capture
human trust in robot capabilities more accurately, and (ii) trust transfer
across tasks can be inferred to a good degree. The latter enables
trust-mediated robot decision-making for fluent human-robot interaction in
multi-task settings.",arxiv
http://arxiv.org/abs/1810.08151v2,2019-05-10T13:35:25Z,2018-10-18T16:42:27Z,Probably Unknown: Deep Inverse Sensor Modelling In Radar,"Radar presents a promising alternative to lidar and vision in autonomous
vehicle applications, able to detect objects at long range under a variety of
weather conditions. However, distinguishing between occupied and free space
from raw radar power returns is challenging due to complex interactions between
sensor noise and occlusion.
  To counter this we propose to learn an Inverse Sensor Model (ISM) converting
a raw radar scan to a grid map of occupancy probabilities using a deep neural
network. Our network is self-supervised using partial occupancy labels
generated by lidar, allowing a robot to learn about world occupancy from past
experience without human supervision. We evaluate our approach on five hours of
data recorded in a dynamic urban environment. By accounting for the scene
context of each grid cell our model is able to successfully segment the world
into occupied and free space, outperforming standard CFAR filtering approaches.
Additionally by incorporating heteroscedastic uncertainty into our model
formulation, we are able to quantify the variance in the uncertainty throughout
the sensor observation. Through this mechanism we are able to successfully
identify regions of space that are likely to be occluded.",arxiv
http://arxiv.org/abs/1812.10812v1,2018-12-27T19:55:54Z,2018-12-27T19:55:54Z,"DeepBillboard: Systematic Physical-World Testing of Autonomous Driving
  Systems","Deep Neural Networks (DNNs) have been widely applied in many autonomous
systems such as autonomous driving. Recently, DNN testing has been intensively
studied to automatically generate adversarial examples, which inject
small-magnitude perturbations into inputs to test DNNs under extreme
situations. While existing testing techniques prove to be effective, they
mostly focus on generating digital adversarial perturbations (particularly for
autonomous driving), e.g., changing image pixels, which may never happen in
physical world. There is a critical missing piece in the literature on
autonomous driving testing: understanding and exploiting both digital and
physical adversarial perturbation generation for impacting steering decisions.
In this paper, we present DeepBillboard, a systematic physical-world testing
approach targeting at a common and practical driving scenario: drive-by
billboards. DeepBillboard is capable of generating a robust and resilient
printable adversarial billboard, which works under dynamic changing driving
conditions including viewing angle, distance, and lighting. The objective is to
maximize the possibility, degree, and duration of the steering-angle errors of
an autonomous vehicle driving by the generated adversarial billboard. We have
extensively evaluated the efficacy and robustness of DeepBillboard through
conducting both digital and physical-world experiments. Results show that
DeepBillboard is effective for various steering models and scenes. Furthermore,
DeepBillboard is sufficiently robust and resilient for generating
physical-world adversarial billboard tests for real-world driving under various
weather conditions. To the best of our knowledge, this is the first study
demonstrating the possibility of generating realistic and continuous
physical-world tests for practical autonomous driving systems.",arxiv
http://arxiv.org/abs/1901.00227v2,2019-08-22T22:26:08Z,2019-01-02T01:02:00Z,"Multitask Learning Deep Neural Networks to Combine Revealed and Stated
  Preference Data","It is an enduring question how to combine revealed preference (RP) and stated
preference (SP) data to analyze travel behavior. This study presents a
framework of multitask learning deep neural networks (MTLDNNs) for this
question, and demonstrates that MTLDNNs are more generic than the traditional
nested logit (NL) method, due to its capacity of automatic feature learning and
soft constraints. About 1,500 MTLDNN models are designed and applied to the
survey data that was collected in Singapore and focused on the RP of four
current travel modes and the SP with autonomous vehicles (AV) as the one new
travel mode in addition to those in RP. We found that MTLDNNs consistently
outperform six benchmark models and particularly the classical NL models by
about 5% prediction accuracy in both RP and SP datasets. This performance
improvement can be mainly attributed to the soft constraints specific to
MTLDNNs, including its innovative architectural design and regularization
methods, but not much to the generic capacity of automatic feature learning
endowed by a standard feedforward DNN architecture. Besides prediction, MTLDNNs
are also interpretable. The empirical results show that AV is mainly the
substitute of driving and AV alternative-specific variables are more important
than the socio-economic variables in determining AV adoption. Overall, this
study introduces a new MTLDNN framework to combine RP and SP, and demonstrates
its theoretical flexibility and empirical power for prediction and
interpretation. Future studies can design new MTLDNN architectures to reflect
the speciality of RP and SP and extend this work to other behavioral analysis.",arxiv
http://arxiv.org/abs/1901.10258v2,2019-01-30T21:30:18Z,2019-01-29T12:59:37Z,"RED-Attack: Resource Efficient Decision based Attack for Machine
  Learning","Due to data dependency and model leakage properties, Deep Neural Networks
(DNNs) exhibit several security vulnerabilities. Several security attacks
exploited them but most of them require the output probability vector. These
attacks can be mitigated by concealing the output probability vector. To
address this limitation, decision-based attacks have been proposed which can
estimate the model but they require several thousand queries to generate a
single untargeted attack image. However, in real-time attacks, resources and
attack time are very crucial parameters. Therefore, in resource-constrained
systems, e.g., autonomous vehicles where an untargeted attack can have a
catastrophic effect, these attacks may not work efficiently. To address this
limitation, we propose a resource efficient decision-based methodology which
generates the imperceptible attack, i.e., the RED-Attack, for a given black-box
model. The proposed methodology follows two main steps to generate the
imperceptible attack, i.e., classification boundary estimation and adversarial
noise optimization. Firstly, we propose a half-interval search-based algorithm
for estimating a sample on the classification boundary using a target image and
a randomly selected image from another class. Secondly, we propose an
optimization algorithm which first, introduces a small perturbation in some
randomly selected pixels of the estimated sample. Then to ensure
imperceptibility, it optimizes the distance between the perturbed and target
samples. For illustration, we evaluate it for CFAR-10 and German Traffic Sign
Recognition (GTSR) using state-of-the-art networks.",arxiv
http://arxiv.org/abs/1902.01084v2,2021-01-15T20:47:41Z,2019-02-04T08:51:50Z,Paracosm: A Language and Tool for Testing Autonomous Driving Systems,"Systematic testing of autonomous vehicles operating in complex real-world
scenarios is a difficult and expensive problem. We present Paracosm, a reactive
language for writing test scenarios for autonomous driving systems. Paracosm
allows users to programmatically describe complex driving situations with
specific visual features, e.g., road layout in an urban environment, as well as
reactive temporal behaviors of cars and pedestrians. Paracosm programs are
executed on top of a game engine that provides realistic physics simulation and
visual rendering. The infrastructure allows systematic exploration of the state
space, both for visual features (lighting, shadows, fog) and for reactive
interactions with the environment (pedestrians, other traffic). We define a
notion of test coverage for Paracosm configurations based on combinatorial
testing and low dispersion sequences. Paracosm comes with an automatic test
case generator that uses random sampling for discrete parameters and
deterministic quasi-Monte Carlo generation for continuous parameters. Through
an empirical evaluation, we demonstrate the modeling and testing capabilities
of Paracosm on a suite of autonomous driving systems implemented using deep
neural networks developed in research and education. We show how Paracosm can
expose incorrect behaviors or degraded performance.",arxiv
http://arxiv.org/abs/1903.00848v2,2019-06-03T07:41:18Z,2019-03-03T06:54:33Z,"Predicting Vehicle Behaviors Over An Extended Horizon Using Behavior
  Interaction Network","Anticipating possible behaviors of traffic participants is an essential
capability of autonomous vehicles. Many behavior detection and maneuver
recognition methods only have a very limited prediction horizon that leaves
inadequate time and space for planning. To avoid unsatisfactory reactive
decisions, it is essential to count long-term future rewards in planning, which
requires extending the prediction horizon. In this paper, we uncover that clues
to vehicle behaviors over an extended horizon can be found in vehicle
interaction, which makes it possible to anticipate the likelihood of a certain
behavior, even in the absence of any clear maneuver pattern. We adopt a
recurrent neural network (RNN) for observation encoding, and based on that, we
propose a novel vehicle behavior interaction network (VBIN) to capture the
vehicle interaction from the hidden states and connection feature of each
interaction pair. The output of our method is a probabilistic likelihood of
multiple behavior classes, which matches the multimodal and uncertain nature of
the distant future. A systematic comparison of our method against two
state-of-the-art methods and another two baseline methods on a publicly
available real highway dataset is provided, showing that our method has
superior accuracy and advanced capability for interaction modeling.",arxiv
http://arxiv.org/abs/1903.04939v1,2019-03-08T16:39:28Z,2019-03-08T16:39:28Z,Fast Deep Stereo with 2D Convolutional Processing of Cost Signatures,"Modern neural network-based algorithms are able to produce highly accurate
depth estimates from stereo image pairs, nearly matching the reliability of
measurements from more expensive depth sensors. However, this accuracy comes
with a higher computational cost since these methods use network architectures
designed to compute and process matching scores across all candidate matches at
all locations, with floating point computations repeated across a match volume
with dimensions corresponding to both space and disparity. This leads to longer
running times to process each image pair, making them impractical for real-time
use in robots and autonomous vehicles. We propose a new stereo algorithm that
employs a significantly more efficient network architecture. Our method builds
an initial match cost volume using traditional matching costs that are fast to
compute, and trains a network to estimate disparity from this volume.
Crucially, our network only employs per-pixel and two-dimensional convolution
operations: to summarize the match information at each location as a
low-dimensional feature vector, and to spatially process these `cost-signature'
features to produce a dense disparity map. Experimental results on the KITTI
benchmark show that our method delivers competitive accuracy at significantly
higher speeds---running at 48 frames per second on a modern GPU.",arxiv
http://arxiv.org/abs/1903.08746v1,2019-03-20T21:15:08Z,2019-03-20T21:15:08Z,Affordance Learning In Direct Perception for Autonomous Driving,"Recent development in autonomous driving involves high-level computer vision
and detailed road scene understanding. Today, most autonomous vehicles are
using mediated perception approach for path planning and control, which highly
rely on high-definition 3D maps and real time sensors. Recent research efforts
aim to substitute the massive HD maps with coarse road attributes. In this
paper, we follow the direct perception based method to train a deep neural
network for affordance learning in autonomous driving. Our goal in this work is
to develop the affordance learning model based on freely available Google
Street View panoramas and Open Street Map road vector attributes. Driving scene
understanding can be achieved by learning affordances from the images captured
by car-mounted cameras. Such scene understanding by learning affordances may be
useful for corroborating base maps such as HD maps so that the required data
storage space is minimized and available for processing in real time. We
compare capability in road attribute identification between human volunteers
and our model by experimental evaluation. Our results indicate that this method
could act as a cheaper way for training data collection in autonomous driving.
The cross validation results also indicate the effectiveness of our model.",arxiv
http://arxiv.org/abs/1904.09007v2,2019-07-19T09:24:45Z,2019-04-18T20:41:10Z,"DeepLocalization: Landmark-based Self-Localization with Deep Neural
  Networks","We address the problem of vehicle self-localization from multi-modal sensor
information and a reference map. The map is generated off-line by extracting
landmarks from the vehicle's field of view, while the measurements are
collected similarly on the fly. Our goal is to determine the autonomous
vehicle's pose from the landmark measurements and map landmarks. To learn this
mapping, we propose DeepLocalization, a deep neural network that regresses the
vehicle's translation and rotation parameters from unordered and dynamic input
landmarks. The proposed network architecture is robust to changes of the
dynamic environment and can cope with a small number of extracted landmarks.
During the training process we rely on synthetically generated ground-truth. In
our experiments, we evaluate two inference approaches in real-world scenarios.
We show that DeepLocalization can be combined with regular GPS signals and
filtering algorithms such as the extended Kalman filter. Our approach achieves
state-of-the-art accuracy and is about ten times faster than the related work.",arxiv
http://arxiv.org/abs/1904.10500v1,2019-04-23T19:13:51Z,2019-04-23T19:13:51Z,"Natural Language Interactions in Autonomous Vehicles: Intent Detection
  and Slot Filling from Passenger Utterances","Understanding passenger intents and extracting relevant slots are important
building blocks towards developing contextual dialogue systems for natural
interactions in autonomous vehicles (AV). In this work, we explored AMIE
(Automated-vehicle Multi-modal In-cabin Experience), the in-cabin agent
responsible for handling certain passenger-vehicle interactions. When the
passengers give instructions to AMIE, the agent should parse such commands
properly and trigger the appropriate functionality of the AV system. In our
current explorations, we focused on AMIE scenarios describing usages around
setting or changing the destination and route, updating driving behavior or
speed, finishing the trip and other use-cases to support various natural
commands. We collected a multi-modal in-cabin dataset with multi-turn dialogues
between the passengers and AMIE using a Wizard-of-Oz scheme via a realistic
scavenger hunt game activity. After exploring various recent Recurrent Neural
Networks (RNN) based techniques, we introduced our own hierarchical joint
models to recognize passenger intents along with relevant slots associated with
the action to be performed in AV scenarios. Our experimental results
outperformed certain competitive baselines and achieved overall F1 scores of
0.91 for utterance-level intent detection and 0.96 for slot filling tasks. In
addition, we conducted initial speech-to-text explorations by comparing
intent/slot models trained and tested on human transcriptions versus noisy
Automatic Speech Recognition (ASR) outputs. Finally, we compared the results
with single passenger rides versus the rides with multiple passengers.",arxiv
http://arxiv.org/abs/1905.01631v2,2019-07-28T08:26:20Z,2019-05-05T08:19:50Z,"Conditional Generative Neural System for Probabilistic Trajectory
  Prediction","Effective understanding of the environment and accurate trajectory prediction
of surrounding dynamic obstacles are critical for intelligent systems such as
autonomous vehicles and wheeled mobile robotics navigating in complex scenarios
to achieve safe and high-quality decision making, motion planning and control.
Due to the uncertain nature of the future, it is desired to make inference from
a probability perspective instead of deterministic prediction. In this paper,
we propose a conditional generative neural system (CGNS) for probabilistic
trajectory prediction to approximate the data distribution, with which
realistic, feasible and diverse future trajectory hypotheses can be sampled.
The system combines the strengths of conditional latent space learning and
variational divergence minimization, and leverages both static context and
interaction information with soft attention mechanisms. We also propose a
regularization method for incorporating soft constraints into deep neural
networks with differentiable barrier functions, which can regulate and push the
generated samples into the feasible regions. The proposed system is evaluated
on several public benchmark datasets for pedestrian trajectory prediction and a
roundabout naturalistic driving dataset collected by ourselves. The
experimental results demonstrate that our model achieves better performance
than various baseline approaches in terms of prediction accuracy.",arxiv
http://arxiv.org/abs/1905.04354v2,2019-05-14T12:59:26Z,2019-05-10T19:39:32Z,"FastDraw: Addressing the Long Tail of Lane Detection by Adapting a
  Sequential Prediction Network","The search for predictive models that generalize to the long tail of sensor
inputs is the central difficulty when developing data-driven models for
autonomous vehicles. In this paper, we use lane detection to study modeling and
training techniques that yield better performance on real world test drives. On
the modeling side, we introduce a novel fully convolutional model of lane
detection that learns to decode lane structures instead of delegating structure
inference to post-processing. In contrast to previous works, our convolutional
decoder is able to represent an arbitrary number of lanes per image, preserves
the polyline representation of lanes without reducing lanes to polynomials, and
draws lanes iteratively without requiring the computational and temporal
complexity of recurrent neural networks. Because our model includes an estimate
of the joint distribution of neighboring pixels belonging to the same lane, our
formulation includes a natural and computationally cheap definition of
uncertainty. On the training side, we demonstrate a simple yet effective
approach to adapt the model to new environments using unsupervised style
transfer. By training FastDraw to make predictions of lane structure that are
invariant to low-level stylistic differences between images, we achieve strong
performance at test time in weather and lighting conditions that deviate
substantially from those of the annotated datasets that are publicly available.
We quantitatively evaluate our approach on the CVPR 2017 Tusimple lane marking
challenge, difficult CULane datasets, and a small labeled dataset of our own
and achieve competitive accuracy while running at 90 FPS.",arxiv
http://arxiv.org/abs/1907.05418v1,2019-07-11T17:59:13Z,2019-07-11T17:59:13Z,Adversarial Objects Against LiDAR-Based Autonomous Driving Systems,"Deep neural networks (DNNs) are found to be vulnerable against adversarial
examples, which are carefully crafted inputs with a small magnitude of
perturbation aiming to induce arbitrarily incorrect predictions. Recent studies
show that adversarial examples can pose a threat to real-world
security-critical applications: a ""physical adversarial Stop Sign"" can be
synthesized such that the autonomous driving cars will misrecognize it as
others (e.g., a speed limit sign). However, these image-space adversarial
examples cannot easily alter 3D scans of widely equipped LiDAR or radar on
autonomous vehicles. In this paper, we reveal the potential vulnerabilities of
LiDAR-based autonomous driving detection systems, by proposing an optimization
based approach LiDAR-Adv to generate adversarial objects that can evade the
LiDAR-based detection system under various conditions. We first show the
vulnerabilities using a blackbox evolution-based algorithm, and then explore
how much a strong adversary can do, using our gradient-based approach
LiDAR-Adv. We test the generated adversarial objects on the Baidu Apollo
autonomous driving platform and show that such physical systems are indeed
vulnerable to the proposed attacks. We also 3D-print our adversarial objects
and perform physical experiments to illustrate that such vulnerability exists
in the real world. Please find more visualizations and results on the anonymous
website: https://sites.google.com/view/lidar-adv.",arxiv
http://arxiv.org/abs/1907.08009v1,2019-07-18T12:03:12Z,2019-07-18T12:03:12Z,"Real-Time Driver State Monitoring Using a CNN Based Spatio-Temporal
  Approach","Many road accidents occur due to distracted drivers. Today, driver monitoring
is essential even for the latest autonomous vehicles to alert distracted
drivers in order to take over control of the vehicle in case of emergency. In
this paper, a spatio-temporal approach is applied to classify drivers'
distraction level and movement decisions using convolutional neural networks
(CNNs). We approach this problem as action recognition to benefit from temporal
information in addition to spatial information. Our approach relies on features
extracted from sparsely selected frames of an action using a pre-trained
BN-Inception network. Experiments show that our approach outperforms the
state-of-the art results on the Distracted Driver Dataset (96.31%), with an
accuracy of 99.10% for 10-class classification while providing real-time
performance. We also analyzed the impact of fusion using RGB and optical flow
modalities with a very recent data level fusion strategy. The results on the
Distracted Driver and Brain4Cars datasets show that fusion of these modalities
further increases the accuracy.",arxiv
http://arxiv.org/abs/1907.08707v1,2019-07-19T21:56:38Z,2019-07-19T21:56:38Z,"Interpretable Modelling of Driving Behaviors in Interactive Driving
  Scenarios based on Cumulative Prospect Theory","Understanding human driving behavior is important for autonomous vehicles. In
this paper, we propose an interpretable human behavior model in interactive
driving scenarios based on the cumulative prospect theory (CPT). As a
non-expected utility theory, CPT can well explain some systematically biased or
``irrational'' behavior/decisions of human that cannot be explained by the
expected utility theory. Hence, the goal of this work is to formulate the human
drivers' behavior generation model with CPT so that some ``irrational''
behavior or decisions of human can be better captured and predicted. Towards
such a goal, we first develop a CPT-driven decision-making model focusing on
driving scenarios with two interacting agents. A hierarchical learning
algorithm is proposed afterward to learn the utility function, the value
function, and the decision weighting function in the CPT model. A case study
for roundabout merging is also provided as verification. With real driving
data, the prediction performances of three different models are compared: a
predefined model based on time-to-collision (TTC), a learning-based model based
on neural networks, and the proposed CPT-based model. The results show that the
proposed model outperforms the TTC model and achieves similar performance as
the learning-based model with much less training data and better
interpretability.",arxiv
http://arxiv.org/abs/1907.10014v2,2020-01-09T14:09:20Z,2019-07-23T17:18:04Z,Temporally Consistent Horizon Lines,"The horizon line is an important geometric feature for many image processing
and scene understanding tasks in computer vision. For instance, in navigation
of autonomous vehicles or driver assistance, it can be used to improve 3D
reconstruction as well as for semantic interpretation of dynamic environments.
While both algorithms and datasets exist for single images, the problem of
horizon line estimation from video sequences has not gained attention. In this
paper, we show how convolutional neural networks are able to utilise the
temporal consistency imposed by video sequences in order to increase the
accuracy and reduce the variance of horizon line estimates. A novel CNN
architecture with an improved residual convolutional LSTM is presented for
temporally consistent horizon line estimation. We propose an adaptive loss
function that ensures stable training as well as accurate results. Furthermore,
we introduce an extension of the KITTI dataset which contains precise horizon
line labels for 43699 images across 72 video sequences. A comprehensive
evaluation shows that the proposed approach consistently achieves superior
performance compared with existing methods.",arxiv
http://arxiv.org/abs/1907.11111v1,2019-07-25T14:43:31Z,2019-07-25T14:43:31Z,"MultiDepth: Single-Image Depth Estimation via Multi-Task Regression and
  Classification","We introduce MultiDepth, a novel training strategy and convolutional neural
network (CNN) architecture that allows approaching single-image depth
estimation (SIDE) as a multi-task problem. SIDE is an important part of road
scene understanding. It, thus, plays a vital role in advanced driver assistance
systems and autonomous vehicles. Best results for the SIDE task so far have
been achieved using deep CNNs. However, optimization of regression problems,
such as estimating depth, is still a challenging task. For the related tasks of
image classification and semantic segmentation, numerous CNN-based methods with
robust training behavior have been proposed. Hence, in order to overcome the
notorious instability and slow convergence of depth value regression during
training, MultiDepth makes use of depth interval classification as an auxiliary
task. The auxiliary task can be disabled at test-time to predict continuous
depth values using the main regression branch more efficiently. We applied
MultiDepth to road scenes and present results on the KITTI depth prediction
dataset. In experiments, we were able to show that end-to-end multi-task
learning with both, regression and classification, is able to considerably
improve training and yield more accurate results.",arxiv
http://arxiv.org/abs/1909.01867v1,2019-09-01T11:50:17Z,2019-09-01T11:50:17Z,"3D Bounding Box Estimation for Autonomous Vehicles by Cascaded Geometric
  Constraints and Depurated 2D Detections Using 3D Results","3D object detection is one of the most important tasks in 3D vision
perceptual system of autonomous vehicles. In this paper, we propose a novel two
stage 3D object detection method aimed at get the optimal solution of object
location in 3D space based on regressing two additional 3D object properties by
a deep convolutional neural network and combined with cascaded geometric
constraints between the 2D and 3D boxes. First, we modify the existing 3D
properties regressing network by adding two additional components, viewpoints
classification and the center projection of the 3D bounding box s bottom face.
Second, we use the predicted center projection combined with similar triangle
constraint to acquire an initial 3D bounding box by a closed-form solution.
Then, the location predicted by previous step is used as the initial value of
the over-determined equations constructed by 2D and 3D boxes fitting constraint
with the configuration determined with the classified viewpoint. Finally, we
use the recovered physical world information by the 3D detections to filter out
the false detection and false alarm in 2D detections. We compare our method
with the state-of-the-arts on the KITTI dataset show that although conceptually
simple, our method outperforms more complex and computational expensive methods
not only by improving the overall precision of 3D detections, but also
increasing the orientation estimation precision. Furthermore our method can
deal with the truncated objects to some extent and remove the false alarm and
false detections in both 2D and 3D detections.",arxiv
http://arxiv.org/abs/1909.05227v2,2020-03-02T21:31:17Z,2019-09-11T17:34:25Z,On-Demand Trajectory Predictions for Interaction Aware Highway Driving,"Highway driving places significant demands on human drivers and autonomous
vehicles (AVs) alike due to high speeds and the complex interactions in dense
traffic. Merging onto the highway poses additional challenges by limiting the
amount of time available for decision-making. Predicting others' trajectories
accurately and quickly is crucial to safely executing maneuvers. Many existing
prediction methods based on neural networks have focused on modeling
interactions to achieve better accuracy while assuming the existence of
observation windows over 3s long. This paper proposes a novel probabilistic
model for trajectory prediction that performs competitively with as little as
400ms of observations. The proposed model extends a deterministic car-following
model to the probabilistic setting by treating model parameters as unknown
random variables and introducing regularization terms. A realtime inference
procedure is derived to estimate the parameters from observations in this new
model. Experiments on dense traffic in the NGSIM dataset demonstrate that the
proposed method achieves state-of-the-art performance with both highly
constrained and more traditional observation windows.",arxiv
http://arxiv.org/abs/1909.08792v1,2019-09-19T03:51:57Z,2019-09-19T03:51:57Z,Agent Prioritization for Autonomous Navigation,"In autonomous navigation, a planning system reasons about other agents to
plan a safe and plausible trajectory. Before planning starts, agents are
typically processed with computationally intensive models for recognition,
tracking, motion estimation and prediction. With limited computational
resources and a large number of agents to process in real time, it becomes
important to efficiently rank agents according to their impact on the decision
making process. This allows spending more time processing the most important
agents. We propose a system to rank agents around an autonomous vehicle (AV) in
real time. We automatically generate a ranking data set by running the planner
in simulation on real-world logged data, where we can afford to run more
accurate and expensive models on all the agents. The causes of various planner
actions are logged and used for assigning ground truth importance scores. The
generated data set can be used to learn ranking models. In particular, we show
the utility of combining learned features, via a convolutional neural network,
with engineered features designed to capture domain knowledge. We show the
benefits of various design choices experimentally. When tested on real AVs, our
system demonstrates the capability of understanding complex driving situations.",arxiv
http://arxiv.org/abs/1909.12205v3,2021-09-13T18:28:56Z,2019-09-26T15:49:08Z,Adaptive Binary-Ternary Quantization,"Neural network models are resource hungry. It is difficult to deploy such
deep networks on devices with limited resources, like smart wearables,
cellphones, drones, and autonomous vehicles. Low bit quantization such as
binary and ternary quantization is a common approach to alleviate this resource
requirements. Ternary quantization provides a more flexible model and
outperforms binary quantization in terms of accuracy, however doubles the
memory footprint and increases the computational cost. Contrary to these
approaches, mixed quantized models allow a trade-off between accuracy and
memory footprint. In such models, quantization depth is often chosen manually,
or is tuned using a separate optimization routine. The latter requires training
a quantized network multiple times. Here, we propose an adaptive combination of
binary and ternary quantization, namely Smart Quantization (SQ), in which the
quantization depth is modified directly via a regularization function, so that
the model is trained only once. Our experimental results show that the proposed
method adapts quantization depth successfully while keeping the model accuracy
high on MNIST and CIFAR10 benchmarks.",arxiv
http://arxiv.org/abs/1909.13844v1,2019-09-30T17:08:22Z,2019-09-30T17:08:22Z,"Automated design of error-resilient and hardware-efficient deep neural
  networks","Applying deep neural networks (DNNs) in mobile and safety-critical systems,
such as autonomous vehicles, demands a reliable and efficient execution on
hardware. Optimized dedicated hardware accelerators are being developed to
achieve this. However, the design of efficient and reliable hardware has become
increasingly difficult, due to the increased complexity of modern integrated
circuit technology and its sensitivity against hardware faults, such as random
bit-flips. It is thus desirable to exploit optimization potential for error
resilience and efficiency also at the algorithmic side, e.g., by optimizing the
architecture of the DNN. Since there are numerous design choices for the
architecture of DNNs, with partially opposing effects on the preferred
characteristics (such as small error rates at low latency), multi-objective
optimization strategies are necessary. In this paper, we develop an
evolutionary optimization technique for the automated design of
hardware-optimized DNN architectures. For this purpose, we derive a set of
easily computable objective functions, which enable the fast evaluation of DNN
architectures with respect to their hardware efficiency and error resilience
solely based on the network topology. We observe a strong correlation between
predicted error resilience and actual measurements obtained from fault
injection simulations. Furthermore, we analyze two different quantization
schemes for efficient DNN computation and find significant differences
regarding their effect on error resilience.",arxiv
http://arxiv.org/abs/1910.03858v1,2019-10-09T09:06:49Z,2019-10-09T09:06:49Z,Intention Recognition of Pedestrians and Cyclists by 2D Pose Estimation,"Anticipating the intentions of vulnerable road users (VRUs) such as
pedestrians and cyclists is critical for performing safe and comfortable
driving maneuvers. This is the case for human driving and, thus, should be
taken into account by systems providing any level of driving assistance, from
advanced driver assistant systems (ADAS) to fully autonomous vehicles (AVs). In
this paper, we show how the latest advances on monocular vision-based human
pose estimation, i.e. those relying on deep Convolutional Neural Networks
(CNNs), enable to recognize the intentions of such VRUs. In the case of
cyclists, we assume that they follow traffic rules to indicate future maneuvers
with arm signals. In the case of pedestrians, no indications can be assumed.
Instead, we hypothesize that the walking pattern of a pedestrian allows to
determine if he/she has the intention of crossing the road in the path of the
ego-vehicle, so that the ego-vehicle must maneuver accordingly (e.g. slowing
down or stopping). In this paper, we show how the same methodology can be used
for recognizing pedestrians and cyclists' intentions. For pedestrians, we
perform experiments on the JAAD dataset. For cyclists, we did not found an
analogous dataset, thus, we created our own one by acquiring and annotating
videos which we share with the research community. Overall, the proposed
pipeline provides new state-of-the-art results on the intention recognition of
VRUs.",arxiv
http://arxiv.org/abs/1911.01523v3,2021-05-14T02:25:24Z,2019-11-04T23:03:32Z,Counterexample-Guided Synthesis of Perception Models and Control,"Recent advances in learning-based perception systems have led to drastic
improvements in the performance of robotic systems like autonomous vehicles and
surgical robots. These perception systems, however, are hard to analyze and
errors in them can propagate to cause catastrophic failures. In this paper, we
consider the problem of synthesizing safe and robust controllers for robotic
systems which rely on complex perception modules for feedback. We propose a
counterexample-guided synthesis framework that iteratively builds simple
surrogate models of the complex perception module and enables us to find safe
control policies. The framework uses a falsifier to find counterexamples, or
traces of the systems that violate a safety property, to extract information
that enables efficient modeling of the perception modules and errors in it.
These models are then used to synthesize controllers that are robust to errors
in perception. If the resulting policy is not safe, we gather new
counterexamples. By repeating the process, we eventually find a controller
which can keep the system safe even when there is a perception failure. We
demonstrate our framework on two scenarios in simulation, namely lane keeping
and automatic braking, and show that it generates controllers that are safe, as
well as a simpler model of a deep neural network-based perception system that
can provide meaningful insight into operations of the perception system.",arxiv
http://arxiv.org/abs/2001.02152v3,2020-03-25T11:17:37Z,2020-01-07T16:21:49Z,PaRoT: A Practical Framework for Robust Deep Neural Network Training,"Deep Neural Networks (DNNs) are finding important applications in
safety-critical systems such as Autonomous Vehicles (AVs), where perceiving the
environment correctly and robustly is necessary for safe operation. Raising
unique challenges for assurance due to their black-box nature, DNNs pose a
fundamental problem for regulatory acceptance of these types of systems. Robust
training --- training to minimize excessive sensitivity to small changes in
input --- has emerged as one promising technique to address this challenge.
However, existing robust training tools are inconvenient to use or apply to
existing codebases and models: they typically only support a small subset of
model elements and require users to extensively rewrite the training code. In
this paper we introduce a novel framework, PaRoT, developed on the popular
TensorFlow platform, that greatly reduces the barrier to entry. Our framework
enables robust training to be performed on arbitrary DNNs without any rewrites
to the model. We demonstrate that our framework's performance is comparable to
prior art, and exemplify its ease of use on off-the-shelf, trained models and
its testing capabilities on a real-world industrial application: a traffic
light detection network.",arxiv
http://arxiv.org/abs/2002.08440v1,2020-02-19T20:47:09Z,2020-02-19T20:47:09Z,Cooperative LIDAR Object Detection via Feature Sharing in Deep Networks,"The recent advancements in communication and computational systems has led to
significant improvement of situational awareness in connected and autonomous
vehicles. Computationally efficient neural networks and high speed wireless
vehicular networks have been some of the main contributors to this improvement.
However, scalability and reliability issues caused by inherent limitations of
sensory and communication systems are still challenging problems. In this
paper, we aim to mitigate the effects of these limitations by introducing the
concept of feature sharing for cooperative object detection (FS-COD). In our
proposed approach, a better understanding of the environment is achieved by
sharing partially processed data between cooperative vehicles while maintaining
a balance between computation and communication load. This approach is
different from current methods of map sharing, or sharing of raw data which are
not scalable. The performance of the proposed approach is verified through
experiments on Volony dataset. It is shown that the proposed approach has
significant performance superiority over the conventional single-vehicle object
detection approaches.",arxiv
http://arxiv.org/abs/2002.11927v3,2020-03-24T06:07:03Z,2020-02-27T05:40:23Z,"Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural
  Network for Human Trajectory Prediction","Better machine understanding of pedestrian behaviors enables faster progress
in modeling interactions between agents such as autonomous vehicles and humans.
Pedestrian trajectories are not only influenced by the pedestrian itself but
also by interaction with surrounding objects. Previous methods modeled these
interactions by using a variety of aggregation methods that integrate different
learned pedestrians states. We propose the Social Spatio-Temporal Graph
Convolutional Neural Network (Social-STGCNN), which substitutes the need of
aggregation methods by modeling the interactions as a graph. Our results show
an improvement over the state of art by 20% on the Final Displacement Error
(FDE) and an improvement on the Average Displacement Error (ADE) with 8.5 times
less parameters and up to 48 times faster inference speed than previously
reported methods. In addition, our model is data efficient, and exceeds
previous state of the art on the ADE metric with only 20% of the training data.
We propose a kernel function to embed the social interactions between
pedestrians within the adjacency matrix. Through qualitative analysis, we show
that our model inherited social behaviors that can be expected between
pedestrians trajectories. Code is available at
https://github.com/abduallahmohamed/Social-STGCNN.",arxiv
http://arxiv.org/abs/2002.12609v1,2020-02-28T09:25:01Z,2020-02-28T09:25:01Z,"SCALE-Net: Scalable Vehicle Trajectory Prediction Network under Random
  Number of Interacting Vehicles via Edge-enhanced Graph Convolutional Neural
  Network","Predicting the future trajectory of surrounding vehicles in a randomly
varying traffic level is one of the most challenging problems in developing an
autonomous vehicle. Since there is no pre-defined number of interacting
vehicles participate in, the prediction network has to be scalable with respect
to the vehicle number in order to guarantee the consistency in terms of both
accuracy and computational load. In this paper, the first fully scalable
trajectory prediction network, SCALE-Net, is proposed that can ensure both
higher prediction performance and consistent computational load regardless of
the number of surrounding vehicles. The SCALE-Net employs the Edge-enhance
Graph Convolutional Neural Network (EGCN) for the inter-vehicular interaction
embedding network. Since the proposed EGCN is inherently scalable with respect
to the graph node (an agent in this study), the model can be operated
independently from the total number of vehicles considered. We evaluated the
scalability of the SCALE-Net on the publically available NGSIM datasets by
comparing variations on computation time and prediction accuracy per single
driving scene with respect to the varying vehicle number. The experimental test
shows that both computation time and prediction performance of the SCALE-Net
consistently outperform those of previous models regardless of the level of
traffic complexities.",arxiv
http://arxiv.org/abs/2003.00856v2,2021-08-24T02:07:06Z,2020-02-27T20:42:32Z,Triangle-Net: Towards Robustness in Point Cloud Learning,"Three dimensional (3D) object recognition is becoming a key desired
capability for many computer vision systems such as autonomous vehicles,
service robots and surveillance drones to operate more effectively in
unstructured environments. These real-time systems require effective
classification methods that are robust to various sampling resolutions, noisy
measurements, and unconstrained pose configurations. Previous research has
shown that points' sparsity, rotation and positional inherent variance can lead
to a significant drop in the performance of point cloud based classification
techniques. However, neither of them is sufficiently robust to multifactorial
variance and significant sparsity. In this regard, we propose a novel approach
for 3D classification that can simultaneously achieve invariance towards
rotation, positional shift, scaling, and is robust to point sparsity. To this
end, we introduce a new feature that utilizes graph structure of point clouds,
which can be learned end-to-end with our proposed neural network to acquire a
robust latent representation of the 3D object. We show that such latent
representations can significantly improve the performance of object
classification and retrieval tasks when points are sparse. Further, we show
that our approach outperforms PointNet and 3DmFV by 35.0% and 28.1%
respectively in ModelNet 40 classification tasks using sparse point clouds of
only 16 points under arbitrary SO(3) rotation.",arxiv
http://arxiv.org/abs/2004.11803v3,2021-09-24T07:28:13Z,2020-04-06T11:08:12Z,"Scan-based Semantic Segmentation of LiDAR Point Clouds: An Experimental
  Study","Autonomous vehicles need to have a semantic understanding of the
three-dimensional world around them in order to reason about their environment.
State of the art methods use deep neural networks to predict semantic classes
for each point in a LiDAR scan. A powerful and efficient way to process LiDAR
measurements is to use two-dimensional, image-like projections. In this work,
we perform a comprehensive experimental study of image-based semantic
segmentation architectures for LiDAR point clouds. We demonstrate various
techniques to boost the performance and to improve runtime as well as memory
constraints.
  First, we examine the effect of network size and suggest that much faster
inference times can be achieved at a very low cost to accuracy. Next, we
introduce an improved point cloud projection technique that does not suffer
from systematic occlusions. We use a cyclic padding mechanism that provides
context at the horizontal field-of-view boundaries. In a third part, we perform
experiments with a soft Dice loss function that directly optimizes for the
intersection-over-union metric. Finally, we propose a new kind of convolution
layer with a reduced amount of weight-sharing along one of the two spatial
dimensions, addressing the large difference in appearance along the vertical
axis of a LiDAR scan. We propose a final set of the above methods with which
the model achieves an increase of 3.2% in mIoU segmentation performance over
the baseline while requiring only 42% of the original inference time.",arxiv
http://arxiv.org/abs/2005.13458v2,2020-06-03T23:56:09Z,2020-05-27T16:16:36Z,"Fast Risk Assessment for Autonomous Vehicles Using Learned Models of
  Agent Futures","This paper presents fast non-sampling based methods to assess the risk of
trajectories for autonomous vehicles when probabilistic predictions of other
agents' futures are generated by deep neural networks (DNNs). The presented
methods address a wide range of representations for uncertain predictions
including both Gaussian and non-Gaussian mixture models for predictions of both
agent positions and controls. We show that the problem of risk assessment when
Gaussian mixture models (GMMs) of agent positions are learned can be solved
rapidly to arbitrary levels of accuracy with existing numerical methods. To
address the problem of risk assessment for non-Gaussian mixture models of agent
position, we propose finding upper bounds on risk using Chebyshev's Inequality
and sums-of-squares (SOS) programming; they are both of interest as the former
is much faster while the latter can be arbitrarily tight. These approaches only
require statistical moments of agent positions to determine upper bounds on
risk. To perform risk assessment when models are learned for agent controls as
opposed to positions, we develop TreeRing, an algorithm analogous to tree
search over the ring of polynomials that can be used to exactly propagate
moments of control distributions into position distributions through nonlinear
dynamics. The presented methods are demonstrated on realistic predictions from
DNNs trained on the Argoverse and CARLA datasets and are shown to be effective
for rapidly assessing the probability of low probability events.",arxiv
http://arxiv.org/abs/2006.02578v1,2020-06-03T23:12:26Z,2020-06-03T23:12:26Z,"DFR-TSD: A Deep Learning Based Framework for Robust Traffic Sign
  Detection Under Challenging Weather Conditions","Robust traffic sign detection and recognition (TSDR) is of paramount
importance for the successful realization of autonomous vehicle technology. The
importance of this task has led to a vast amount of research efforts and many
promising methods have been proposed in the existing literature. However, the
SOTA (SOTA) methods have been evaluated on clean and challenge-free datasets
and overlooked the performance deterioration associated with different
challenging conditions (CCs) that obscure the traffic images captured in the
wild. In this paper, we look at the TSDR problem under CCs and focus on the
performance degradation associated with them. To overcome this, we propose a
Convolutional Neural Network (CNN) based TSDR framework with prior enhancement.
Our modular approach consists of a CNN-based challenge classifier, Enhance-Net,
an encoder-decoder CNN architecture for image enhancement, and two separate CNN
architectures for sign-detection and classification. We propose a novel
training pipeline for Enhance-Net that focuses on the enhancement of the
traffic sign regions (instead of the whole image) in the challenging images
subject to their accurate detection. We used CURE-TSD dataset consisting of
traffic videos captured under different CCs to evaluate the efficacy of our
approach. We experimentally show that our method obtains an overall precision
and recall of 91.1% and 70.71% that is 7.58% and 35.90% improvement in
precision and recall, respectively, compared to the current benchmark.
Furthermore, we compare our approach with SOTA object detection networks,
Faster-RCNN and R-FCN, and show that our approach outperforms them by a large
margin.",arxiv
http://arxiv.org/abs/2006.12706v1,2020-06-23T02:54:55Z,2020-06-23T02:54:55Z,"Deep Learning of Unified Region, Edge, and Contour Models for Automated
  Image Segmentation","Image segmentation is a fundamental and challenging problem in computer
vision with applications spanning multiple areas, such as medical imaging,
remote sensing, and autonomous vehicles. Recently, convolutional neural
networks (CNNs) have gained traction in the design of automated segmentation
pipelines. Although CNN-based models are adept at learning abstract features
from raw image data, their performance is dependent on the availability and
size of suitable training datasets. Additionally, these models are often unable
to capture the details of object boundaries and generalize poorly to unseen
classes. In this thesis, we devise novel methodologies that address these
issues and establish robust representation learning frameworks for
fully-automatic semantic segmentation in medical imaging and mainstream
computer vision. In particular, our contributions include (1) state-of-the-art
2D and 3D image segmentation networks for computer vision and medical image
analysis, (2) an end-to-end trainable image segmentation framework that unifies
CNNs and active contour models with learnable parameters for fast and robust
object delineation, (3) a novel approach for disentangling edge and texture
processing in segmentation networks, and (4) a novel few-shot learning model in
both supervised settings and semi-supervised settings where synergies between
latent and image spaces are leveraged to learn to segment images given limited
training data.",arxiv
http://arxiv.org/abs/2006.12906v2,2020-07-12T23:33:28Z,2020-06-23T11:25:16Z,"Probabilistic Crowd GAN: Multimodal Pedestrian Trajectory Prediction
  using a Graph Vehicle-Pedestrian Attention Network","Understanding and predicting the intention of pedestrians is essential to
enable autonomous vehicles and mobile robots to navigate crowds. This problem
becomes increasingly complex when we consider the uncertainty and multimodality
of pedestrian motion, as well as the implicit interactions between members of a
crowd, including any response to a vehicle. Our approach, Probabilistic Crowd
GAN, extends recent work in trajectory prediction, combining Recurrent Neural
Networks (RNNs) with Mixture Density Networks (MDNs) to output probabilistic
multimodal predictions, from which likely modal paths are found and used for
adversarial training. We also propose the use of Graph Vehicle-Pedestrian
Attention Network (GVAT), which models social interactions and allows input of
a shared vehicle feature, showing that inclusion of this module leads to
improved trajectory prediction both with and without the presence of a vehicle.
Through evaluation on various datasets, we demonstrate improvements on the
existing state of the art methods for trajectory prediction and illustrate how
the true multimodal and uncertain nature of crowd interactions can be directly
modelled.",arxiv
http://arxiv.org/abs/2007.02438v1,2020-07-05T20:12:56Z,2020-07-05T20:12:56Z,"DepthNet: Real-Time LiDAR Point Cloud Depth Completion for Autonomous
  Vehicles","Autonomous vehicles rely heavily on sensors such as camera and LiDAR, which
provide real-time information about their surroundings for the tasks of
perception, planning and control. Typically a LiDAR can only provide sparse
point cloud owing to a limited number of scanning lines. By employing depth
completion, a dense depth map can be generated by assigning each camera pixel a
corresponding depth value. However, the existing depth completion convolutional
neural networks are very complex that requires high-end GPUs for processing,
and thus they are not applicable to real-time autonomous driving. In this
paper, a light-weight network is proposed for the task of LiDAR point cloud
depth completion. With an astonishing 96.2% reduction in the number of
parameters, it still achieves comparable performance (9.3% better in MAE but
3.9% worse in RMSE) to the state-of-the-art network. For real-time embedded
platforms, depthwise separable technique is applied to both convolution and
deconvolution operations and the number of parameters decreases further by a
factor of 7.3, with only a small percentage increase in RMSE and MAE
performance. Moreover, a system-on-chip architecture for depth completion is
developed on a PYNQ-based FPGA platform that achieves real-time processing for
HDL-64E LiDAR at the speed 11.1 frame per second.",arxiv
http://arxiv.org/abs/2007.03877v2,2021-03-02T22:54:23Z,2020-07-08T03:31:58Z,"PathGAN: Local Path Planning with Attentive Generative Adversarial
  Networks","To achieve autonomous driving without high-definition maps, we present a
model capable of generating multiple plausible paths from egocentric images for
autonomous vehicles. Our generative model comprises two neural networks: the
feature extraction network (FEN) and path generation network (PGN). The FEN
extracts meaningful features from an egocentric image, whereas the PGN
generates multiple paths from the features, given a driving intention and
speed. To ensure that the paths generated are plausible and consistent with the
intention, we introduce an attentive discriminator and train it with the PGN
under generative adversarial networks framework. We also devise an interaction
model between the positions in the paths and the intentions hidden in the
positions and design a novel PGN architecture that reflects the interaction
model, resulting in the improvement of the accuracy and diversity of the
generated paths. Finally, we introduce ETRIDriving, a dataset for autonomous
driving in which the recorded sensor data are labeled with discrete high-level
driving actions, and demonstrate the state-of-the-art performance of the
proposed model on ETRIDriving in terms of accuracy and diversity.",arxiv
http://arxiv.org/abs/2007.05096v2,2020-08-14T18:08:25Z,2020-07-09T22:16:45Z,Multi-Agent Routing Value Iteration Network,"In this paper we tackle the problem of routing multiple agents in a
coordinated manner. This is a complex problem that has a wide range of
applications in fleet management to achieve a common goal, such as mapping from
a swarm of robots and ride sharing. Traditional methods are typically not
designed for realistic environments hich contain sparsely connected graphs and
unknown traffic, and are often too slow in runtime to be practical. In
contrast, we propose a graph neural network based model that is able to perform
multi-agent routing based on learned value iteration in a sparsely connected
graph with dynamically changing traffic conditions. Moreover, our learned
communication module enables the agents to coordinate online and adapt to
changes more effectively. We created a simulated environment to mimic realistic
mapping performed by autonomous vehicles with unknown minimum edge coverage and
traffic conditions; our approach significantly outperforms traditional solvers
both in terms of total cost and runtime. We also show that our model trained
with only two agents on graphs with a maximum of 25 nodes can easily generalize
to situations with more agents and/or nodes.",arxiv
http://arxiv.org/abs/2007.05828v1,2020-07-11T18:41:47Z,2020-07-11T18:41:47Z,Understanding Object Detection Through An Adversarial Lens,"Deep neural networks based object detection models have revolutionized
computer vision and fueled the development of a wide range of visual
recognition applications. However, recent studies have revealed that deep
object detectors can be compromised under adversarial attacks, causing a victim
detector to detect no object, fake objects, or mislabeled objects. With object
detection being used pervasively in many security-critical applications, such
as autonomous vehicles and smart cities, we argue that a holistic approach for
an in-depth understanding of adversarial attacks and vulnerabilities of deep
object detection systems is of utmost importance for the research community to
develop robust defense mechanisms. This paper presents a framework for
analyzing and evaluating vulnerabilities of the state-of-the-art object
detectors under an adversarial lens, aiming to analyze and demystify the attack
strategies, adverse effects, and costs, as well as the cross-model and
cross-resolution transferability of attacks. Using a set of quantitative
metrics, extensive experiments are performed on six representative deep object
detectors from three popular families (YOLOv3, SSD, and Faster R-CNN) with two
benchmark datasets (PASCAL VOC and MS COCO). We demonstrate that the proposed
framework can serve as a methodical benchmark for analyzing adversarial
behaviors and risks in real-time object detection systems. We conjecture that
this framework can also serve as a tool to assess the security risks and the
adversarial robustness of deep object detectors to be deployed in real-world
applications.",arxiv
http://arxiv.org/abs/2009.08253v1,2020-09-17T12:56:17Z,2020-09-17T12:56:17Z,Dynamic Edge Weights in Graph Neural Networks for 3D Object Detection,"A robust and accurate 3D detection system is an integral part of autonomous
vehicles. Traditionally, a majority of 3D object detection algorithms focus on
processing 3D point clouds using voxel grids or bird's eye view (BEV). Recent
works, however, demonstrate the utilization of the graph neural network (GNN)
as a promising approach to 3D object detection. In this work, we propose an
attention based feature aggregation technique in GNN for detecting objects in
LiDAR scan. We first employ a distance-aware down-sampling scheme that not only
enhances the algorithmic performance but also retains maximum geometric
features of objects even if they lie far from the sensor. In each layer of the
GNN, apart from the linear transformation which maps the per node input
features to the corresponding higher level features, a per node masked
attention by specifying different weights to different nodes in its first ring
neighborhood is also performed. The masked attention implicitly accounts for
the underlying neighborhood graph structure of every node and also eliminates
the need of costly matrix operations thereby improving the detection accuracy
without compromising the performance. The experiments on KITTI dataset show
that our method yields comparable results for 3D object detection.",arxiv
http://arxiv.org/abs/2010.13355v3,2021-03-25T04:01:17Z,2020-10-26T05:48:26Z,PSF-LO: Parameterized Semantic Features Based Lidar Odometry,"Lidar odometry (LO) is a key technology in numerous reliable and accurate
localization and mapping systems of autonomous driving. The state-of-the-art LO
methods generally leverage geometric information to perform point cloud
registration. Furthermore, obtaining point cloud semantic information which can
describe the environment more abundantly will help for the registration. We
present a novel semantic lidar odometry method based on self-designed
parameterized semantic features (PSFs) to achieve low-drift ego-motion
estimation for autonomous vehicle in realtime. We first use a convolutional
neural network-based algorithm to obtain point-wise semantics from the input
laser point cloud, and then use semantic labels to separate the road, building,
traffic sign and pole-like point cloud and fit them separately to obtain
corresponding PSFs. A fast PSF-based matching enable us to refine geometric
features (GeFs) registration, reducing the impact of blurred submap surface on
the accuracy of GeFs matching. Besides, we design an efficient method to
accurately recognize and remove the dynamic objects while retaining static ones
in the semantic point cloud, which are beneficial to further improve the
accuracy of LO. We evaluated our method, namely PSF-LO, on the public dataset
KITTI Odometry Benchmark and ranked #1 among semantic lidar methods with an
average translation error of 0.82% in the test dataset at the time of writing.",arxiv
http://arxiv.org/abs/2011.12706v2,2020-12-01T08:48:47Z,2020-11-25T13:18:06Z,Quantized Neural Networks for Radar Interference Mitigation,"Radar sensors are crucial for environment perception of driver assistance
systems as well as autonomous vehicles. Key performance factors are weather
resistance and the possibility to directly measure velocity. With a rising
number of radar sensors and the so far unregulated automotive radar frequency
band, mutual interference is inevitable and must be dealt with. Algorithms and
models operating on radar data in early processing stages are required to run
directly on specialized hardware, i.e. the radar sensor. This specialized
hardware typically has strict resource-constraints, i.e. a low memory capacity
and low computational power. Convolutional Neural Network (CNN)-based
approaches for denoising and interference mitigation yield promising results
for radar processing in terms of performance. However, these models typically
contain millions of parameters, stored in hundreds of megabytes of memory, and
require additional memory during execution. In this paper we investigate
quantization techniques for CNN-based denoising and interference mitigation of
radar signals. We analyze the quantization potential of different CNN-based
model architectures and sizes by considering (i) quantized weights and (ii)
piecewise constant activation functions, which results in reduced memory
requirements for model storage and during the inference step respectively.",arxiv
http://arxiv.org/abs/2012.01757v2,2021-08-08T15:16:14Z,2020-12-03T08:43:12Z,"Pedestrian Trajectory Prediction using Context-Augmented Transformer
  Networks","Forecasting the trajectory of pedestrians in shared urban traffic
environments is still considered one of the challenging problems facing the
development of autonomous vehicles (AVs). In the literature, this problem is
often tackled using recurrent neural networks (RNNs). Despite the powerful
capabilities of RNNs in capturing the temporal dependency in the pedestrians'
motion trajectories, they were argued to be challenged when dealing with longer
sequential data. Thus, in this work, we are introducing a framework based on
the transformer networks that were shown recently to be more efficient and
outperformed RNNs in many sequential-based tasks. We relied on a fusion of the
past positional information, agent interactions information and scene physical
semantics information as an input to our framework in order to provide a robust
trajectory prediction of pedestrians. We have evaluated our framework on two
real-life datasets of pedestrians in shared urban traffic environments and it
has outperformed the compared baseline approaches in both short-term and
long-term prediction horizons.",arxiv
http://arxiv.org/abs/2012.05228v2,2021-03-06T07:22:22Z,2020-12-09T18:49:24Z,Video Deblurring by Fitting to Test Data,"Motion blur in videos captured by autonomous vehicles and robots can degrade
their perception capability. In this work, we present a novel approach to video
deblurring by fitting a deep network to the test video. Our key observation is
that some frames in a video with motion blur are much sharper than others, and
thus we can transfer the texture information in those sharp frames to blurry
frames. Our approach heuristically selects sharp frames from a video and then
trains a convolutional neural network on these sharp frames. The trained
network often absorbs enough details in the scene to perform deblurring on all
the video frames. As an internal learning method, our approach has no domain
gap between training and test data, which is a problematic issue for existing
video deblurring approaches. The conducted experiments on real-world video data
show that our model can reconstruct clearer and sharper videos than
state-of-the-art video deblurring approaches. Code and data are available at
https://github.com/xrenaa/Deblur-by-Fitting.",arxiv
http://arxiv.org/abs/2012.07721v3,2021-05-08T12:06:03Z,2020-12-14T17:14:46Z,"Non-linear State-space Model Identification from Video Data using Deep
  Encoders","Identifying systems with high-dimensional inputs and outputs, such as systems
measured by video streams, is a challenging problem with numerous applications
in robotics, autonomous vehicles and medical imaging. In this paper, we propose
a novel non-linear state-space identification method starting from
high-dimensional input and output data. Multiple computational and conceptual
advances are combined to handle the high-dimensional nature of the data. An
encoder function, represented by a neural network, is introduced to learn a
reconstructability map to estimate the model states from past inputs and
outputs. This encoder function is jointly learned with the dynamics.
Furthermore, multiple computational improvements, such as an improved
reformulation of multiple shooting and batch optimization, are proposed to keep
the computational time under control when dealing with high-dimensional and
large datasets. We apply the proposed method to a video stream of a simulated
environment of a controllable ball in a unit box. The study shows low
simulation error with excellent long term prediction capability of the model
obtained using the proposed method.",arxiv
http://arxiv.org/abs/2101.04319v1,2021-01-12T06:42:45Z,2021-01-12T06:42:45Z,"DeepiSign: Invisible Fragile Watermark to Protect the Integrityand
  Authenticity of CNN","Convolutional Neural Networks (CNNs) deployed in real-life applications such
as autonomous vehicles have shown to be vulnerable to manipulation attacks,
such as poisoning attacks and fine-tuning. Hence, it is essential to ensure the
integrity and authenticity of CNNs because compromised models can produce
incorrect outputs and behave maliciously. In this paper, we propose a
self-contained tamper-proofing method, called DeepiSign, to ensure the
integrity and authenticity of CNN models against such manipulation attacks.
DeepiSign applies the idea of fragile invisible watermarking to securely embed
a secret and its hash value into a CNN model. To verify the integrity and
authenticity of the model, we retrieve the secret from the model, compute the
hash value of the secret, and compare it with the embedded hash value. To
minimize the effects of the embedded secret on the CNN model, we use a
wavelet-based technique to transform weights into the frequency domain and
embed the secret into less significant coefficients. Our theoretical analysis
shows that DeepiSign can hide up to 1KB secret in each layer with minimal loss
of the model's accuracy. To evaluate the security and performance of DeepiSign,
we performed experiments on four pre-trained models (ResNet18, VGG16, AlexNet,
and MobileNet) using three datasets (MNIST, CIFAR-10, and Imagenet) against
three types of manipulation attacks (targeted input poisoning, output
poisoning, and fine-tuning). The results demonstrate that DeepiSign is
verifiable without degrading the classification accuracy, and robust against
representative CNN manipulation attacks.",arxiv
http://arxiv.org/abs/2101.06409v1,2021-01-16T09:00:34Z,2021-01-16T09:00:34Z,Shape Back-Projection In 3D Scenes,"In this work, we propose a novel framework shape back-projection for
computationally efficient point cloud processing in a probabilistic manner. The
primary component of the technique is shape histogram and a back-projection
procedure. The technique measures similarity between 3D surfaces, by analyzing
their geometrical properties. It is analogous to color back-projection which
measures similarity between images, simply by looking at their color
distributions. In the overall process, first, shape histogram of a sample
surface (e.g. planar) is computed, which captures the profile of surface
normals around a point in form of a probability distribution. Later, the
histogram is back-projected onto a test surface and a likelihood score is
obtained. The score depicts that how likely a point in the test surface behaves
similar to the sample surface, geometrically. Shape back-projection finds its
application in binary surface classification, high curvature edge detection in
unorganized point cloud, automated point cloud labeling for 3D-CNNs
(convolutional neural network) etc. The algorithm can also be used for
real-time robotic operations such as autonomous object picking in warehouse
automation, ground plane extraction for autonomous vehicles and can be deployed
easily on computationally limited platforms (UAVs).",arxiv
http://arxiv.org/abs/2102.03546v1,2021-02-06T09:37:09Z,2021-02-06T09:37:09Z,"Convolutional Neural Network-based Intrusion Detection System for AVTP
  Streams in Automotive Ethernet-based Networks","Connected and autonomous vehicles (CAVs) are an innovative form of
traditional vehicles. Automotive Ethernet replaces the controller area network
and FlexRay to support the large throughput required by high-definition
applications. As CAVs have numerous functions, they exhibit a large attack
surface and an increased vulnerability to attacks. However, no previous studies
have focused on intrusion detection in automotive Ethernet-based networks. In
this paper, we present an intrusion detection method for detecting audio-video
transport protocol (AVTP) stream injection attacks in automotive Ethernet-based
networks. To the best of our knowledge, this is the first such method developed
for automotive Ethernet. The proposed intrusion detection model is based on
feature generation and a convolutional neural network (CNN). To evaluate our
intrusion detection system, we built a physical BroadR-Reach-based testbed and
captured real AVTP packets. The experimental results show that the model
exhibits outstanding performance: the F1-score and recall are greater than
0.9704 and 0.9949, respectively. In terms of the inference time per input and
the generation intervals of AVTP traffic, our CNN model can readily be employed
for real-time detection.",arxiv
http://arxiv.org/abs/2102.10191v1,2021-02-19T22:47:44Z,2021-02-19T22:47:44Z,"Adaptable Deformable Convolutions for Semantic Segmentation of Fisheye
  Images in Autonomous Driving Systems","Advanced Driver-Assistance Systems rely heavily on perception tasks such as
semantic segmentation where images are captured from large field of view (FoV)
cameras. State-of-the-art works have made considerable progress toward applying
Convolutional Neural Network (CNN) to standard (rectilinear) images. However,
the large FoV cameras used in autonomous vehicles produce fisheye images
characterized by strong geometric distortion. This work demonstrates that a CNN
trained on standard images can be readily adapted to fisheye images, which is
crucial in real-world applications where time-consuming real-time data
transformation must be avoided. Our adaptation protocol mainly relies on
modifying the support of the convolutions by using their deformable equivalents
on top of pre-existing layers. We prove that tuning an optimal support only
requires a limited amount of labeled fisheye images, as a small number of
training samples is sufficient to significantly improve an existing model's
performance on wide-angle images. Furthermore, we show that finetuning the
weights of the network is not necessary to achieve high performance once the
deformable components are learned. Finally, we provide an in-depth analysis of
the effect of the deformable convolutions, bringing elements of discussion on
the behavior of CNN models.",arxiv
http://arxiv.org/abs/2103.01644v3,2021-03-25T20:40:24Z,2021-03-02T11:13:43Z,"Exploiting latent representation of sparse semantic layers for improved
  short-term motion prediction with Capsule Networks","As urban environments manifest high levels of complexity it is of vital
importance that safety systems embedded within autonomous vehicles (AVs) are
able to accurately anticipate short-term future motion of nearby agents. This
problem can be further understood as generating a sequence of coordinates
describing the future motion of the tracked agent. Various proposed approaches
demonstrate significant benefits of using a rasterised top-down image of the
road, with a combination of Convolutional Neural Networks (CNNs), for
extraction of relevant features that define the road structure (eg. driveable
areas, lanes, walkways). In contrast, this paper explores use of Capsule
Networks (CapsNets) in the context of learning a hierarchical representation of
sparse semantic layers corresponding to small regions of the High-Definition
(HD) map. Each region of the map is dismantled into separate geometrical layers
that are extracted with respect to the agent's current position. By using an
architecture based on CapsNets the model is able to retain hierarchical
relationships between detected features within images whilst also preventing
loss of spatial data often caused by the pooling operation. We train and
evaluate our model on publicly available dataset nuTonomy scenes and compare it
to recently published methods. We show that our model achieves significant
improvement over recently published works on deterministic prediction, whilst
drastically reducing the overall size of the network.",arxiv
http://arxiv.org/abs/2103.04505v2,2021-09-11T02:53:50Z,2021-03-08T01:47:20Z,"Split Computing and Early Exiting for Deep Learning Applications: Survey
  and Research Challenges","Mobile devices such as smartphones and autonomous vehicles increasingly rely
on deep neural networks (DNNs) to execute complex inference tasks such as image
classification and speech recognition, among others. However, continuously
executing the entire DNN on the mobile device can quickly deplete its battery.
Although task offloading to edge servers may decrease the mobile device's
computational burden, erratic patterns in channel quality, network and edge
server load can lead to a significant delay in task execution.
Recently,approaches based on split computing (SC) have been proposed, where the
DNN is split into a head and a tail model, executed respectively on the mobile
device and on the edge server. Ultimately, this may reduce bandwidth usage as
well as energy consumption. Another approach, called early exiting (EE), trains
models to present multiple ""exits"" earlier in the architecture, each providing
increasingly higher target accuracy. Therefore, the trade-off between accuracy
and delay can be tuned according to the current conditions or application
demands. In this paper, we provide a comprehensive survey of the state of the
art in SC and EE strategies, by presenting a comparison of the most relevant
approaches. We conclude the paper by providing a set of compelling research
challenges.",arxiv
http://arxiv.org/abs/2103.10796v2,2021-10-07T07:59:55Z,2021-03-19T13:32:40Z,"CoordiNet: uncertainty-aware pose regressor for reliable vehicle
  localization","In this paper, we investigate visual-based camera re-localization with neural
networks for robotics and autonomous vehicles applications. Our solution is a
CNN-based algorithm which predicts camera pose (3D translation and 3D rotation)
directly from a single image. It also provides an uncertainty estimate of the
pose. Pose and uncertainty are learned together with a single loss function and
are fused at test time with an EKF. Furthermore, we propose a new fully
convolutional architecture, named CoordiNet, designed to embed some of the
scene geometry. Our framework outperforms comparable methods on the largest
available benchmark, the Oxford RobotCar dataset, with an average error of 8
meters where previous best was 19 meters. We have also investigated the
performance of our method on large scenes for real time (18 fps) vehicle
localization. In this setup, structure-based methods require a large database,
and we show that our proposal is a reliable alternative, achieving 29cm median
error in a 1.9km loop in a busy urban area",arxiv
http://arxiv.org/abs/2104.05327v2,2021-04-14T10:02:05Z,2021-04-12T10:16:08Z,MinkLoc++: Lidar and Monocular Image Fusion for Place Recognition,"We introduce a discriminative multimodal descriptor based on a pair of sensor
readings: a point cloud from a LiDAR and an image from an RGB camera. Our
descriptor, named MinkLoc++, can be used for place recognition, re-localization
and loop closure purposes in robotics or autonomous vehicles applications. We
use late fusion approach, where each modality is processed separately and fused
in the final part of the processing pipeline. The proposed method achieves
state-of-the-art performance on standard place recognition benchmarks. We also
identify dominating modality problem when training a multimodal descriptor. The
problem manifests itself when the network focuses on a modality with a larger
overfit to the training data. This drives the loss down during the training but
leads to suboptimal performance on the evaluation set. In this work we describe
how to detect and mitigate such risk when using a deep metric learning approach
to train a multimodal neural network. Our code is publicly available on the
project website: https://github.com/jac99/MinkLocMultimodal.",arxiv
http://arxiv.org/abs/2105.09847v2,2021-05-21T09:13:23Z,2021-05-20T15:46:02Z,"M4Depth: A motion-based approach for monocular depth estimation on video
  sequences","Getting the distance to objects is crucial for autonomous vehicles. In
instances where depth sensors cannot be used, this distance has to be estimated
from RGB cameras. As opposed to cars, the task of estimating depth from
on-board mounted cameras is made complex on drones because of the lack of
constrains on motion during flights. In this paper, we present a method to
estimate the distance of objects seen by an on-board mounted camera by using
its RGB video stream and drone motion information. Our method is built upon a
pyramidal convolutional neural network architecture and uses time recurrence in
pair with geometric constraints imposed by motion to produce pixel-wise depth
maps. In our architecture, each level of the pyramid is designed to produce its
own depth estimate based on past observations and information provided by the
previous level in the pyramid. We introduce a spatial reprojection layer to
maintain the spatio-temporal consistency of the data between the levels. We
analyse the performance of our approach on Mid-Air, a public drone dataset
featuring synthetic drone trajectories recorded in a wide variety of
unstructured outdoor environments. Our experiments show that our network
outperforms state-of-the-art depth estimation methods and that the use of
motion information is the main contributing factor for this improvement. The
code of our method is publicly available on GitHub; see
https://github.com/michael-fonder/M4Depth",arxiv
http://arxiv.org/abs/2105.12882v1,2021-05-27T00:03:27Z,2021-05-27T00:03:27Z,"MAVFI: An End-to-End Fault Analysis Framework with Anomaly Detection and
  Recovery for Micro Aerial Vehicles","Reliability and safety are critical in autonomous machine services, such as
autonomous vehicles and aerial drones. In this paper, we first present an
open-source Micro Aerial Vehicles (MAVs) reliability analysis framework, MAVFI,
to characterize transient fault's impacts on the end-to-end flight metrics,
e.g., flight time, success rate. Based on our framework, it is observed that
the end-to-end fault tolerance analysis is essential for characterizing system
reliability. We demonstrate the planning and control stages are more vulnerable
to transient faults than the visual perception stage in the common
""Perception-Planning-Control (PPC)"" compute pipeline. Furthermore, to improve
the reliability of the MAV system, we propose two low overhead anomaly-based
transient fault detection and recovery schemes based on Gaussian statistical
models and autoencoder neural networks. We validate our anomaly fault
protection schemes with a variety of simulated photo-realistic environments on
both Intel i9 CPU and ARM Cortex-A57 on Nvidia TX2 platform. It is demonstrated
that the autoencoder-based scheme can improve the system reliability by 100%
recovering failure cases with less than 0.0062% computational overhead in
best-case scenarios. In addition, MAVFI framework can be used for other
ROS-based cyber-physical applications and is open-sourced at
https://github.com/harvard-edge/MAVBench/tree/mavfi",arxiv
http://arxiv.org/abs/2106.02930v1,2021-06-05T16:51:54Z,2021-06-05T16:51:54Z,Spectral Temporal Graph Neural Network for Trajectory Prediction,"An effective understanding of the contextual environment and accurate motion
forecasting of surrounding agents is crucial for the development of autonomous
vehicles and social mobile robots. This task is challenging since the behavior
of an autonomous agent is not only affected by its own intention, but also by
the static environment and surrounding dynamically interacting agents. Previous
works focused on utilizing the spatial and temporal information in time domain
while not sufficiently taking advantage of the cues in frequency domain. To
this end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which
can capture inter-agent correlations and temporal dependency simultaneously in
frequency domain in addition to time domain. SpecTGNN operates on both an agent
graph with dynamic state information and an environment graph with the features
extracted from context images in two streams. The model integrates graph
Fourier transform, spectral graph convolution and temporal gated convolution to
encode history information and forecast future trajectories. Moreover, we
incorporate a multi-head spatio-temporal attention mechanism to mitigate the
effect of error propagation in a long time horizon. We demonstrate the
performance of SpecTGNN on two public trajectory prediction benchmark datasets,
which achieves state-of-the-art performance in terms of prediction accuracy.",arxiv
http://arxiv.org/abs/2106.02982v1,2021-06-05T23:02:55Z,2021-06-05T23:02:55Z,"Sensor Fusion-based GNSS Spoofing Attack Detection Framework for
  Autonomous Vehicles","In this study, a sensor fusion based GNSS spoofing attack detection framework
is presented that consists of three concurrent strategies for an autonomous
vehicle (AV): (i) prediction of location shift, (ii) detection of turns (left
or right), and (iii) recognition of motion state (including standstill state).
Data from multiple low-cost in-vehicle sensors (i.e., accelerometer, steering
angle sensor, speed sensor, and GNSS) are fused and fed into a recurrent neural
network model, which is a long short-term memory (LSTM) network for predicting
the location shift, i.e., the distance that an AV travels between two
consecutive timestamps. We have then combined k-Nearest Neighbors (k-NN) and
Dynamic Time Warping (DTW) algorithms to detect turns using data from the
steering angle sensor. In addition, data from an AV's speed sensor is used to
recognize the AV's motion state including the standstill state. To prove the
efficacy of the sensor fusion-based attack detection framework, attack datasets
are created for three unique and sophisticated spoofing attacks turn by turn,
overshoot, and stop using the publicly available real-world Honda Research
Institute Driving Dataset (HDD). Our analysis reveals that the sensor
fusion-based detection framework successfully detects all three types of
spoofing attacks within the required computational latency threshold.",arxiv
http://arxiv.org/abs/2106.11277v1,2021-06-21T17:27:11Z,2021-06-21T17:27:11Z,"Attention-based Neural Network for Driving Environment Complexity
  Perception","Environment perception is crucial for autonomous vehicle (AV) safety. Most
existing AV perception algorithms have not studied the surrounding environment
complexity and failed to include the environment complexity parameter. This
paper proposes a novel attention-based neural network model to predict the
complexity level of the surrounding driving environment. The proposed model
takes naturalistic driving videos and corresponding vehicle dynamics parameters
as input. It consists of a Yolo-v3 object detection algorithm, a heat map
generation algorithm, CNN-based feature extractors, and attention-based feature
extractors for both video and time-series vehicle dynamics data inputs to
extract features. The output from the proposed algorithm is a surrounding
environment complexity parameter. The Berkeley DeepDrive dataset (BDD Dataset)
and subjectively labeled surrounding environment complexity levels are used for
model training and validation to evaluate the algorithm. The proposed
attention-based network achieves 91.22% average classification accuracy to
classify the surrounding environment complexity. It proves that the environment
complexity level can be accurately predicted and applied for future AVs'
environment perception studies.",arxiv
http://arxiv.org/abs/2106.13085v1,2021-06-21T16:59:55Z,2021-06-21T16:59:55Z,"Coherent, super resolved radar beamforming using self-supervised
  learning","High resolution automotive radar sensors are required in order to meet the
high bar of autonomous vehicles needs and regulations. However, current radar
systems are limited in their angular resolution causing a technological gap. An
industry and academic trend to improve angular resolution by increasing the
number of physical channels, also increases system complexity, requires
sensitive calibration processes, lowers robustness to hardware malfunctions and
drives higher costs. We offer an alternative approach, named Radar signal
Reconstruction using Self Supervision (R2-S2), which significantly improves the
angular resolution of a given radar array without increasing the number of
physical channels. R2-S2 is a family of algorithms which use a Deep Neural
Network (DNN) with complex range-Doppler radar data as input and trained in a
self-supervised method using a loss function which operates in multiple data
representation spaces. Improvement of 4x in angular resolution was demonstrated
using a real-world dataset collected in urban and highway environments during
clear and rainy weather conditions.",arxiv
http://arxiv.org/abs/2107.04749v1,2021-07-10T03:40:25Z,2021-07-10T03:40:25Z,"Resilience of Autonomous Vehicle Object Category Detection to Universal
  Adversarial Perturbations","Due to the vulnerability of deep neural networks to adversarial examples,
numerous works on adversarial attacks and defenses have been burgeoning over
the past several years. However, there seem to be some conventional views
regarding adversarial attacks and object detection approaches that most
researchers take for granted. In this work, we bring a fresh perspective on
those procedures by evaluating the impact of universal perturbations on object
detection at a class-level. We apply it to a carefully curated data set related
to autonomous driving. We use Faster-RCNN object detector on images of five
different categories: person, car, truck, stop sign and traffic light from the
COCO data set, while carefully perturbing the images using Universal Dense
Object Suppression algorithm. Our results indicate that person, car, traffic
light, truck and stop sign are resilient in that order (most to least) to
universal perturbations. To the best of our knowledge, this is the first time
such a ranking has been established which is significant for the security of
the data sets pertaining to autonomous vehicles and object detection in
general.",arxiv
http://arxiv.org/abs/2107.08690v1,2021-07-19T08:53:35Z,2021-07-19T08:53:35Z,"ObserveNet Control: A Vision-Dynamics Learning Approach to Predictive
  Control in Autonomous Vehicles","A key component in autonomous driving is the ability of the self-driving car
to understand, track and predict the dynamics of the surrounding environment.
Although there is significant work in the area of object detection, tracking
and observations prediction, there is no prior work demonstrating that raw
observations prediction can be used for motion planning and control. In this
paper, we propose ObserveNet Control, which is a vision-dynamics approach to
the predictive control problem of autonomous vehicles. Our method is composed
of a: i) deep neural network able to confidently predict future sensory data on
a time horizon of up to 10s and ii) a temporal planner designed to compute a
safe vehicle state trajectory based on the predicted sensory data. Given the
vehicle's historical state and sensing data in the form of Lidar point clouds,
the method aims to learn the dynamics of the observed driving environment in a
self-supervised manner, without the need to manually specify training labels.
The experiments are performed both in simulation and real-life, using CARLA and
RovisLab's AMTU mobile platform as a 1:4 scaled model of a car. We evaluate the
capabilities of ObserveNet Control in aggressive driving contexts, such as
overtaking maneuvers or side cut-off situations, while comparing the results
with a baseline Dynamic Window Approach (DWA) and two state-of-the-art
imitation learning systems, that is, Learning by Cheating (LBC) and World on
Rails (WOR).",arxiv
http://arxiv.org/abs/2107.09804v2,2021-08-06T18:18:32Z,2021-07-20T23:21:04Z,"Using Undervolting as an On-Device Defense Against Adversarial Machine
  Learning Attacks","Deep neural network (DNN) classifiers are powerful tools that drive a broad
spectrum of important applications, from image recognition to autonomous
vehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks
that affect virtually all state-of-the-art models. These attacks make small
imperceptible modifications to inputs that are sufficient to induce the DNNs to
produce the wrong classification.
  In this paper we propose a novel, lightweight adversarial correction and/or
detection mechanism for image classifiers that relies on undervolting (running
a chip at a voltage that is slightly below its safe margin). We propose using
controlled undervolting of the chip running the inference process in order to
introduce a limited number of compute errors. We show that these errors disrupt
the adversarial input in a way that can be used either to correct the
classification or detect the input as adversarial. We evaluate the proposed
solution in an FPGA design and through software simulation. We evaluate 10
attacks and show average detection rates of 77% and 90% on two popular DNNs.",arxiv
http://arxiv.org/abs/2107.12137v2,2021-08-11T06:54:54Z,2021-07-26T12:18:23Z,AA3DNet: Attention Augmented Real Time 3D Object Detection,"In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects using
point cloud data. We present anchor design along with custom loss functions
used in this work. A combination of spatial and channel wise attention module
is used in this work. We use the Kitti 3D Birds Eye View dataset for
benchmarking and validating our results. Our method surpasses previous state of
the art in this domain both in terms of average precision and speed running at
> 30 FPS. Finally, we present the ablation study to demonstrate that the
performance of our network is generalizable. This makes it a feasible option to
be deployed in real time applications like self driving cars.",arxiv
http://arxiv.org/abs/2108.02712v1,2021-08-05T16:25:48Z,2021-08-05T16:25:48Z,"On Addressing Heterogeneity in Federated Learning for Autonomous
  Vehicles Connected to a Drone Orchestrator","In this paper we envision a federated learning (FL) scenario in service of
amending the performance of autonomous road vehicles, through a drone traffic
monitor (DTM), that also acts as an orchestrator. Expecting non-IID data
distribution, we focus on the issue of accelerating the learning of a
particular class of critical object (CO), that may harm the nominal operation
of an autonomous vehicle. This can be done through proper allocation of the
wireless resources for addressing learner and data heterogeneity. Thus, we
propose a reactive method for the allocation of wireless resources, that
happens dynamically each FL round, and is based on each learner's contribution
to the general model. In addition to this, we explore the use of static methods
that remain constant across all rounds. Since we expect partial work from each
learner, we use the FedProx FL algorithm, in the task of computer vision. For
testing, we construct a non-IID data distribution of the MNIST and FMNIST
datasets among four types of learners, in scenarios that represent the quickly
changing environment. The results show that proactive measures are effective
and versatile at improving system accuracy, and quickly learning the CO class
when underrepresented in the network. Furthermore, the experiments show a
tradeoff between FedProx intensity and resource allocation efforts.
Nonetheless, a well adjusted FedProx local optimizer allows for an even better
overall accuracy, particularly when using deeper neural network (NN)
implementations.",arxiv
http://arxiv.org/abs/2108.07399v1,2021-08-17T01:55:54Z,2021-08-17T01:55:54Z,"Network Generalization Prediction for Safety Critical Tasks in Novel
  Operating Domains","It is well known that Neural Network (network) performance often degrades
when a network is used in novel operating domains that differ from its training
and testing domains. This is a major limitation, as networks are being
integrated into safety critical, cyber-physical systems that must work in
unconstrained environments, e.g., perception for autonomous vehicles. Training
networks that generalize to novel operating domains and that extract robust
features is an active area of research, but previous work fails to predict what
the network performance will be in novel operating domains. We propose the task
Network Generalization Prediction: predicting the expected network performance
in novel operating domains. We describe the network performance in terms of an
interpretable Context Subspace, and we propose a methodology for selecting the
features of the Context Subspace that provide the most information about the
network performance. We identify the Context Subspace for a pretrained Faster
RCNN network performing pedestrian detection on the Berkeley Deep Drive (BDD)
Dataset, and demonstrate Network Generalization Prediction accuracy within 5%
or less of observed performance. We also demonstrate that the Context Subspace
from the BDD Dataset is informative for completely unseen datasets, JAAD and
Cityscapes, where predictions have a bias of 10% or less.",arxiv
http://arxiv.org/abs/2108.08635v1,2021-08-19T11:59:51Z,2021-08-19T11:59:51Z,"A Sensor Fusion-based GNSS Spoofing Attack Detection Framework for
  Autonomous Vehicles","This paper presents a sensor fusion based Global Navigation Satellite System
(GNSS) spoofing attack detection framework for autonomous vehicles (AV) that
consists of two concurrent strategies: (i) detection of vehicle state using
predicted location shift -- i.e., distance traveled between two consecutive
timestamps -- and monitoring of vehicle motion state -- i.e., standstill/ in
motion; and (ii) detection and classification of turns (i.e., left or right).
Data from multiple low-cost in-vehicle sensors (i.e., accelerometer, steering
angle sensor, speed sensor, and GNSS) are fused and fed into a recurrent neural
network model, which is a long short-term memory (LSTM) network for predicting
the location shift, i.e., the distance that an AV travels between two
consecutive timestamps. This location shift is then compared with the
GNSS-based location shift to detect an attack. We have then combined k-Nearest
Neighbors (k-NN) and Dynamic Time Warping (DTW) algorithms to detect and
classify left and right turns using data from the steering angle sensor. To
prove the efficacy of the sensor fusion-based attack detection framework,
attack datasets are created for four unique and sophisticated spoofing
attacks-turn-by-turn, overshoot, wrong turn, and stop, using the publicly
available real-world Honda Research Institute Driving Dataset (HDD). Our
analysis reveals that the sensor fusion-based detection framework successfully
detects all four types of spoofing attacks within the required computational
latency threshold.",arxiv
http://arxiv.org/abs/2109.07561v1,2021-09-15T20:20:04Z,2021-09-15T20:20:04Z,A Framework for Multisensory Foresight for Embodied Agents,"Predicting future sensory states is crucial for learning agents such as
robots, drones, and autonomous vehicles. In this paper, we couple multiple
sensory modalities with exploratory actions and propose a predictive neural
network architecture to address this problem. Most existing approaches rely on
large, manually annotated datasets, or only use visual data as a single
modality. In contrast, the unsupervised method presented here uses multi-modal
perceptions for predicting future visual frames. As a result, the proposed
model is more comprehensive and can better capture the spatio-temporal dynamics
of the environment, leading to more accurate visual frame prediction. The other
novelty of our framework is the use of sub-networks dedicated to anticipating
future haptic, audio, and tactile signals. The framework was tested and
validated with a dataset containing 4 sensory modalities (vision, haptic,
audio, and tactile) on a humanoid robot performing 9 behaviors multiple times
on a large set of objects. While the visual information is the dominant
modality, utilizing the additional non-visual modalities improves the accuracy
of predictions.",arxiv
http://arxiv.org/abs/2109.10083v1,2021-09-21T10:39:46Z,2021-09-21T10:39:46Z,PDFNet: Pointwise Dense Flow Network for Urban-Scene Segmentation,"In recent years, using a deep convolutional neural network (CNN) as a feature
encoder (or backbone) is the most commonly observed architectural pattern in
several computer vision methods, and semantic segmentation is no exception. The
two major drawbacks of this architectural pattern are: (i) the networks often
fail to capture small classes such as wall, fence, pole, traffic light, traffic
sign, and bicycle, which are crucial for autonomous vehicles to make accurate
decisions. (ii) due to the arbitrarily increasing depth, the networks require
massive labeled data and additional regularization techniques to converge and
to prevent the risk of over-fitting, respectively. While regularization
techniques come at minimal cost, the collection of labeled data is an expensive
and laborious process. In this work, we address these two drawbacks by
proposing a novel lightweight architecture named point-wise dense flow network
(PDFNet). In PDFNet, we employ dense, residual, and multiple shortcut
connections to allow a smooth gradient flow to all parts of the network. The
extensive experiments on Cityscapes and CamVid benchmarks demonstrate that our
method significantly outperforms baselines in capturing small classes and in
few-data regimes. Moreover, our method achieves considerable performance in
classifying out-of-the training distribution samples, evaluated on Cityscapes
to KITTI dataset.",arxiv
http://arxiv.org/abs/2109.13751v1,2021-09-28T14:11:36Z,2021-09-28T14:11:36Z,StereoSpike: Depth Learning with a Spiking Neural Network,"Depth estimation is an important computer vision task, useful in particular
for navigation in autonomous vehicles, or for object manipulation in robotics.
Here we solved it using an end-to-end neuromorphic approach, combining two
event-based cameras and a Spiking Neural Network (SNN) with a slightly modified
U-Net-like encoder-decoder architecture, that we named StereoSpike. More
specifically, we used the Multi Vehicle Stereo Event Camera Dataset (MVSEC). It
provides a depth ground-truth, which was used to train StereoSpike in a
supervised manner, using surrogate gradient descent. We propose a novel readout
paradigm to obtain a dense analog prediction -- the depth of each pixel -- from
the spikes of the decoder. We demonstrate that this architecture generalizes
very well, even better than its non-spiking counterparts, leading to
state-of-the-art test accuracy. To the best of our knowledge, it is the first
time that such a large-scale regression problem is solved by a fully spiking
network. Finally, we show that low firing rates (<10%) can be obtained via
regularization, with a minimal cost in accuracy. This means that StereoSpike
could be efficiently implemented on neuromorphic chips, opening the door for
low power and real time embedded systems.",arxiv
http://arxiv.org/abs/2110.01974v1,2021-09-24T01:08:25Z,2021-09-24T01:08:25Z,"Runtime Interchange for Adaptive Re-use of Intelligent Cyber-Physical
  System Controllers","Cyber-Physical Systems (CPSs) such as those found within autonomous vehicles
are increasingly adopting Artificial Neural Network (ANN)-based controllers. To
ensure the safety of these controllers, there is a spate of recent activity to
formally verify the ANN-based designs. There are two challenges with these
approaches: (1) The verification of such systems is difficult and time
consuming. (2) These verified controllers are not able to adapt to frequent
requirements changes, which are typical in situations like autonomous driving.
This raises the question: how can trained and verified controllers, which have
gone through expensive training and verification processes, be re-used to deal
with requirement changes? This paper addresses this challenge for the first
time by proposing a new framework that is capable of dealing with requirement
changes at runtime through a mechanism we term runtime interchange. Our
approach functions via a continual exchange and selection process of multiple
pre-verified controllers. It represents a key step on the way to
component-oriented engineering for intelligent designs, as it preserves the
behaviours of the original controllers while introducing additional
functionality. To demonstrate the efficacy of our approach we utilise an
existing autonomous driving case study as well as a set of smaller benchmarks.
These show that introduced overheads are extremely minimal and that the
approach is very scalable.",arxiv
http://arxiv.org/abs/1808.08617v2,2018-10-31T18:07:40Z,2018-08-26T20:20:37Z,"Autonomous Driving without a Burden: View from Outside with Elevated
  LiDAR","The current autonomous driving architecture places a heavy burden in signal
processing for the graphics processing units (GPUs) in the car. This directly
translates into battery drain and lower energy efficiency, crucial factors in
electric vehicles. This is due to the high bit rate of the captured video and
other sensing inputs, mainly due to Light Detection and Ranging (LiDAR) sensor
at the top of the car which is an essential feature in autonomous vehicles.
LiDAR is needed to obtain a high precision map for the vehicle AI to make
relevant decisions. However, this is still a quite restricted view from the
car. This is the same even in the case of cars without a LiDAR such as Tesla.
The existing LiDARs and the cameras have limited horizontal and vertical fields
of visions. In all cases it can be argued that precision is lower, given the
smaller map generated. This also results in the accumulation of a large amount
of data in the order of several TBs in a day, the storage of which becomes
challenging. If we are to reduce the effort for the processing units inside the
car, we need to uplink the data to edge or an appropriately placed cloud.
However, the required data rates in the order of several Gbps are difficult to
be met even with the advent of 5G. Therefore, we propose to have a coordinated
set of LiDAR's outside at an elevation which can provide an integrated view
with a much larger field of vision (FoV) to a centralized decision making body
which then sends the required control actions to the vehicles with a lower bit
rate in the downlink and with the required latency. The calculations we have
based on industry standard equipment from several manufacturers show that this
is not just a concept but a feasible system which can be implemented.The
proposed system can play a supportive role with existing autonomous vehicle
architecture and it is easily applicable in an urban area.",arxiv
http://arxiv.org/abs/1607.00667v1,2016-07-03T18:43:55Z,2016-07-03T18:43:55Z,"Reducing the Energy Cost of Inference via In-sensor Information
  Processing","There is much interest in incorporating inference capabilities into
sensor-rich embedded platforms such as autonomous vehicles, wearables, and
others. A central problem in the design of such systems is the need to extract
information locally from sensed data on a severely limited energy budget. This
necessitates the design of energy-efficient sensory embedded system. A typical
sensory embedded system enforces a physical separation between sensing and
computational subsystems - a separation mandated by the differing requirements
of the sensing and computational functions. As a consequence, the energy
consumption in such systems tends to be dominated by the energy consumed in
transferring data over the sensor-processor interface (communication energy)
and the energy consumed in processing the data in digital processor
(computational energy). In this article, we propose an in-sensor computing
architecture which (mostly) eliminates the sensor-processor interface by
embedding inference computations in the noisy sensor fabric in analog and
retraining the hyperparameters in order to compensate for non-ideal
computations. The resulting architecture referred to as the Compute Sensor - a
sensor that computes in addition to sensing - represents a radical departure
from the conventional. We show that a Compute Sensor for image data can be
designed by embedding both feature extraction and classification functions in
the analog domain in close proximity to the CMOS active pixel sensor (APS)
array. Significant gains in energy-efficiency are demonstrated using behavioral
and energy models in a commercial semiconductor process technology. In the
process, the Compute Sensor creates a unique opportunity to develop machine
learning algorithms for information extraction from data on a noisy underlying
computational fabric.",arxiv
http://arxiv.org/abs/1901.08221v1,2019-01-24T03:51:10Z,2019-01-24T03:51:10Z,"When is it right and good for an intelligent autonomous vehicle to take
  over control (and hand it back)?","There is much debate in machine ethics about the most appropriate way to
introduce ethical reasoning capabilities into intelligent autonomous machines.
Recent incidents involving autonomous vehicles in which humans have been killed
or injured have raised questions about how we ensure that such vehicles have an
ethical dimension to their behaviour and are therefore trustworthy. The main
problem is that hardwiring such machines with rules not to cause harm or damage
is not consistent with the notion of autonomy and intelligence. Also, such
ethical hardwiring does not leave intelligent autonomous machines with any
course of action if they encounter situations or dilemmas for which they are
not programmed or where some harm is caused no matter what course of action is
taken. Teaching machines so that they learn ethics may also be problematic
given recent findings in machine learning that machines pick up the prejudices
and biases embedded in their learning algorithms or data. This paper describes
a fuzzy reasoning approach to machine ethics. The paper shows how it is
possible for an ethics architecture to reason when taking over from a human
driver is morally justified. The design behind such an ethical reasoner is also
applied to an ethical dilemma resolution case. One major advantage of the
approach is that the ethical reasoner can generate its own data for learning
moral rules (hence, autometric) and thereby reduce the possibility of picking
up human biases and prejudices. The results show that a new type of
metric-based ethics appropriate for autonomous intelligent machines is feasible
and that our current concept of ethical reasoning being largely qualitative in
nature may need revising if want to construct future autonomous machines that
have an ethical dimension to their reasoning so that they become moral
machines.",arxiv
http://arxiv.org/abs/2008.09510v1,2020-08-19T19:50:56Z,2020-08-19T19:50:56Z,"Assessing Safety-Critical Systems from Operational Testing: A Study on
  Autonomous Vehicles","Context: Demonstrating high reliability and safety for safety-critical
systems (SCSs) remains a hard problem. Diverse evidence needs to be combined in
a rigorous way: in particular, results of operational testing with other
evidence from design and verification. Growing use of machine learning in SCSs,
by precluding most established methods for gaining assurance, makes operational
testing even more important for supporting safety and reliability claims.
Objective: We use Autonomous Vehicles (AVs) as a current example to revisit the
problem of demonstrating high reliability. AVs are making their debut on public
roads: methods for assessing whether an AV is safe enough are urgently needed.
We demonstrate how to answer 5 questions that would arise in assessing an AV
type, starting with those proposed by a highly-cited study. Method: We apply
new theorems extending Conservative Bayesian Inference (CBI), which exploit the
rigour of Bayesian methods while reducing the risk of involuntary misuse
associated with now-common applications of Bayesian inference; we define
additional conditions needed for applying these methods to AVs. Results: Prior
knowledge can bring substantial advantages if the AV design allows strong
expectations of safety before road testing. We also show how naive attempts at
conservative assessment may lead to over-optimism instead; why extrapolating
the trend of disengagements is not suitable for safety claims; use of knowledge
that an AV has moved to a less stressful environment. Conclusion: While some
reliability targets will remain too high to be practically verifiable, CBI
removes a major source of doubt: it allows use of prior knowledge without
inducing dangerously optimistic biases. For certain ranges of required
reliability and prior beliefs, CBI thus supports feasible, sound arguments.
Useful conservative claims can be derived from limited prior knowledge.",arxiv
http://arxiv.org/abs/2103.01986v1,2021-03-02T19:12:06Z,2021-03-02T19:12:06Z,Technical Report on Data Integration and Preparation,"AI application developers typically begin with a dataset of interest and a
vision of the end analytic or insight they wish to gain from the data at hand.
Although these are two very important components of an AI workflow, one often
spends the first few weeks (sometimes months) in the phase we refer to as data
conditioning. This step typically includes tasks such as figuring out how to
prepare data for analytics, dealing with inconsistencies in the dataset, and
determining which algorithm (or set of algorithms) will be best suited for the
application. Larger, faster, and messier datasets such as those from Internet
of Things sensors, medical devices or autonomous vehicles only amplify these
issues. These challenges, often referred to as the three Vs (volume, velocity,
variety) of Big Data, require low-level tools for data management, preparation
and integration. In most applications, data can come from structured and/or
unstructured sources and often includes inconsistencies, formatting
differences, and a lack of ground-truth labels.
  In this report, we highlight a number of tools that can be used to simplify
data integration and preparation steps. Specifically, we focus on data
integration tools and techniques, a deep dive into an exemplar data integration
tool, and a deep-dive in the evolving field of knowledge graphs. Finally, we
provide readers with a list of practical steps and considerations that they can
use to simplify the data integration challenge. The goal of this report is to
provide readers with a view of state-of-the-art as well as practical tips that
can be used by data creators that make data integration more seamless.",arxiv
http://arxiv.org/abs/1707.00051v4,2018-07-26T19:41:39Z,2017-06-30T21:42:47Z,"Failing to Learn: Autonomously Identifying Perception Failures for
  Self-driving Cars","One of the major open challenges in self-driving cars is the ability to
detect cars and pedestrians to safely navigate in the world. Deep
learning-based object detector approaches have enabled great advances in using
camera imagery to detect and classify objects. But for a safety critical
application, such as autonomous driving, the error rates of the current state
of the art are still too high to enable safe operation. Moreover, the
characterization of object detector performance is primarily limited to testing
on prerecorded datasets. Errors that occur on novel data go undetected without
additional human labels. In this letter, we propose an automated method to
identify mistakes made by object detectors without ground truth labels. We show
that inconsistencies in the object detector output between a pair of similar
images can be used as hypotheses for false negatives (e.g., missed detections)
and using a novel set of features for each hypothesis, an off-the-shelf binary
classifier can be used to find valid errors. In particular, we study two
distinct cues - temporal and stereo inconsistencies - using data that are
readily available on most autonomous vehicles. Our method can be used with any
camera-based object detector and we illustrate the technique on several sets of
real world data. We show that a state-of-the-art detector, tracker, and our
classifier trained only on synthetic data can identify valid errors on KITTI
tracking dataset with an average precision of 0.94. We also release a new
tracking dataset with 104 sequences totaling 80,655 labeled pairs of stereo
images along with ground truth disparity from a game engine to facilitate
further research. The dataset and code are available at
https://fcav.engin.umich.edu/research/failing-to-learn",arxiv
http://arxiv.org/abs/1805.04258v2,2018-08-28T03:33:24Z,2018-05-11T07:23:20Z,"PALM: An Incremental Construction of Hyperplanes for Data Stream
  Regression","Data stream has been the underlying challenge in the age of big data because
it calls for real-time data processing with the absence of a retraining process
and/or an iterative learning approach. In realm of fuzzy system community, data
stream is handled by algorithmic development of self-adaptive neurofuzzy
systems (SANFS) characterized by the single-pass learning mode and the open
structure property which enables effective handling of fast and rapidly
changing natures of data streams. The underlying bottleneck of SANFSs lies in
its design principle which involves a high number of free parameters (rule
premise and rule consequent) to be adapted in the training process. This figure
can even double in the case of type-2 fuzzy system. In this work, a novel
SANFS, namely parsimonious learning machine (PALM), is proposed. PALM features
utilization of a new type of fuzzy rule based on the concept of hyperplane
clustering which significantly reduces the number of network parameters because
it has no rule premise parameters. PALM is proposed in both type-1 and type-2
fuzzy systems where all of which characterize a fully dynamic rule-based
system. That is, it is capable of automatically generating, merging and tuning
the hyperplane-based fuzzy rule in the single pass manner. Moreover, an
extension of PALM, namely recurrent PALM (rPALM), is proposed and adopts the
concept of teacher-forcing mechanism in the deep learning literature. The
efficacy of PALM has been evaluated through numerical study with six real-world
and synthetic data streams from public database and our own real-world project
of autonomous vehicles. The proposed model showcases significant improvements
in terms of computational complexity and number of required parameters against
several renowned SANFSs, while attaining comparable and often better predictive
accuracy.",arxiv
http://arxiv.org/abs/2005.08135v2,2021-10-01T18:09:13Z,2020-05-17T00:27:53Z,"VPR-Bench: An Open-Source Visual Place Recognition Evaluation Framework
  with Quantifiable Viewpoint and Appearance Change","Visual Place Recognition (VPR) is the process of recognising a previously
visited place using visual information, often under varying appearance
conditions and viewpoint changes and with computational constraints. VPR is
related to the concepts of localisation, loop closure, image retrieval and is a
critical component of many autonomous navigation systems ranging from
autonomous vehicles to drones and computer vision systems. While the concept of
place recognition has been around for many years, VPR research has grown
rapidly as a field over the past decade due to improving camera hardware and
its potential for deep learning-based techniques, and has become a widely
studied topic in both the computer vision and robotics communities. This growth
however has led to fragmentation and a lack of standardisation in the field,
especially concerning performance evaluation. Moreover, the notion of viewpoint
and illumination invariance of VPR techniques has largely been assessed
qualitatively and hence ambiguously in the past. In this paper, we address
these gaps through a new comprehensive open-source framework for assessing the
performance of VPR techniques, dubbed ""VPR-Bench"". VPR-Bench (Open-sourced at:
https://github.com/MubarizZaffar/VPR-Bench) introduces two much-needed
capabilities for VPR researchers: firstly, it contains a benchmark of 12
fully-integrated datasets and 10 VPR techniques, and secondly, it integrates a
comprehensive variation-quantified dataset for quantifying viewpoint and
illumination invariance. We apply and analyse popular evaluation metrics for
VPR from both the computer vision and robotics communities, and discuss how
these different metrics complement and/or replace each other, depending upon
the underlying applications and system requirements.",arxiv
http://arxiv.org/abs/2011.02403v1,2020-11-04T16:56:12Z,2020-11-04T16:56:12Z,"IDE-Net: Interactive Driving Event and Pattern Extraction from Human
  Data","Autonomous vehicles (AVs) need to share the road with multiple, heterogeneous
road users in a variety of driving scenarios. It is overwhelming and
unnecessary to carefully interact with all observed agents, and AVs need to
determine whether and when to interact with each surrounding agent. In order to
facilitate the design and testing of prediction and planning modules of AVs,
in-depth understanding of interactive behavior is expected with proper
representation, and events in behavior data need to be extracted and
categorized automatically. Answers to what are the essential patterns of
interactions are also crucial for these motivations in addition to answering
whether and when. Thus, learning to extract interactive driving events and
patterns from human data for tackling the whether-when-what tasks is of
critical importance for AVs. There is, however, no clear definition and
taxonomy of interactive behavior, and most of the existing works are based on
either manual labelling or hand-crafted rules and features. In this paper, we
propose the Interactive Driving event and pattern Extraction Network (IDE-Net),
which is a deep learning framework to automatically extract interaction events
and patterns directly from vehicle trajectories. In IDE-Net, we leverage the
power of multi-task learning and proposed three auxiliary tasks to assist the
pattern extraction in an unsupervised fashion. We also design a unique
spatial-temporal block to encode the trajectory data. Experimental results on
the INTERACTION dataset verified the effectiveness of such designs in terms of
better generalizability and effective pattern extraction. We find three
interpretable patterns of interactions, bringing insights for driver behavior
representation, modeling and comprehension. Both objective and subjective
evaluation metrics are adopted in our analysis of the learned patterns.",arxiv
http://arxiv.org/abs/1812.02575v1,2018-12-06T14:59:29Z,2018-12-06T14:59:29Z,Prior Networks for Detection of Adversarial Attacks,"Adversarial examples are considered a serious issue for safety critical
applications of AI, such as finance, autonomous vehicle control and medicinal
applications. Though significant work has resulted in increased robustness of
systems to these attacks, systems are still vulnerable to well-crafted attacks.
To address this problem, several adversarial attack detection methods have been
proposed. However, a system can still be vulnerable to adversarial samples that
are designed to specifically evade these detection methods. One recent
detection scheme that has shown good performance is based on uncertainty
estimates derived from Monte-Carlo dropout ensembles. Prior Networks, a new
method of estimating predictive uncertainty, has been shown to outperform
Monte-Carlo dropout on a range of tasks. One of the advantages of this approach
is that the behaviour of a Prior Network can be explicitly tuned to, for
example, predict high uncertainty in regions where there are no training data
samples. In this work, Prior Networks are applied to adversarial attack
detection using measures of uncertainty in a similar fashion to Monte-Carlo
Dropout. Detection based on measures of uncertainty derived from DNNs and
Monte-Carlo dropout ensembles are used as a baseline. Prior Networks are shown
to significantly out-perform these baseline approaches over a range of
adversarial attacks in both detection of whitebox and blackbox configurations.
Even when the adversarial attacks are constructed with full knowledge of the
detection mechanism, it is shown to be highly challenging to successfully
generate an adversarial sample.",arxiv
http://arxiv.org/abs/1906.00400v1,2019-06-02T13:23:11Z,2019-06-02T13:23:11Z,Mobile Edge Intelligence and Computing for the Internet of Vehicles,"The Internet of Vehicles (IoV) is an emerging paradigm, driven by recent
advancements in vehicular communications and networking. Advances in research
can now provide reliable communication links between vehicles, via
vehicle-to-vehicle communications, and between vehicles and roadside
infrastructures, via vehicle-to-infrastructure communications. Meanwhile, the
capability and intelligence of vehicles are being rapidly enhanced, and this
will have the potential of supporting a plethora of new exciting applications,
which will integrate fully autonomous vehicles, the Internet of Things (IoT),
and the environment. These trends will bring about an era of intelligent IoV,
which will heavily depend upon communications, computing, and data analytics
technologies. To store and process the massive amount of data generated by
intelligent IoV, onboard processing and Cloud computing will not be sufficient,
due to resource/power constraints and communication overhead/latency,
respectively. By deploying storage and computing resources at the wireless
network edge, e.g., radio access points, the edge information system (EIS),
including edge caching, edge computing, and edge AI, will play a key role in
the future intelligent IoV. Such system will provide not only low-latency
content delivery and computation services, but also localized data acquisition,
aggregation and processing. This article surveys the latest development in EIS
for intelligent IoV. Key design issues, methodologies and hardware platforms
are introduced. In particular, typical use cases for intelligent vehicles are
illustrated, including edge-assisted perception, mapping, and localization. In
addition, various open research problems are identified.",arxiv
http://arxiv.org/abs/1912.03618v2,2020-06-06T03:56:29Z,2019-12-08T05:12:17Z,Efficient Black-box Assessment of Autonomous Vehicle Safety,"While autonomous vehicle (AV) technology has shown substantial progress, we
still lack tools for rigorous and scalable testing. Real-world testing, the
$\textit{de-facto}$ evaluation method, is dangerous to the public. Moreover,
due to the rare nature of failures, billions of miles of driving are needed to
statistically validate performance claims. Thus, the industry has largely
turned to simulation to evaluate AV systems. However, having a simulation stack
alone is not a solution. A simulation testing framework needs to prioritize
which scenarios to run, learn how the chosen scenarios provide coverage of
failure modes, and rank failure scenarios in order of importance. We implement
a simulation testing framework that evaluates an entire modern AV system as a
black box. This framework estimates the probability of accidents under a base
distribution governing standard traffic behavior. In order to accelerate
rare-event probability evaluation, we efficiently learn to identify and rank
failure scenarios via adaptive importance-sampling methods. Using this
framework, we conduct the first independent evaluation of a full-stack
commercial AV system, Comma AI's OpenPilot.",arxiv
http://arxiv.org/abs/2005.04439v1,2020-05-09T13:16:29Z,2020-05-09T13:16:29Z,"Automated Failure-Mode Clustering and Labeling for Informed
  Car-To-Driver Handover in Autonomous Vehicles","The car-to-driver handover is a critically important component of safe
autonomous vehicle operation when the vehicle is unable to safely proceed on
its own. Current implementations of this handover in automobiles take the form
of a generic alarm indicating an imminent transfer of control back to the human
driver. However, certain levels of vehicle autonomy may allow the driver to
engage in other, non-driving related tasks prior to a handover, leading to
substantial difficulty in quickly regaining situational awareness. This delay
in re-orientation could potentially lead to life-threatening failures unless
mitigating steps are taken. Explainable AI has been shown to improve fluency
and teamwork in human-robot collaboration scenarios. Therefore, we hypothesize
that by utilizing autonomous explanation, these car-to-driver handovers can be
performed more safely and reliably. The rationale is, by providing the driver
with additional situational knowledge, they will more rapidly focus on the
relevant parts of the driving environment. Towards this end, we propose an
algorithmic failure-mode identification and explanation approach to enable
informed handovers from vehicle to driver. Furthermore, we propose a set of
human-subjects driving-simulator studies to determine the appropriate form of
explanation during handovers, as well as validate our framework.",arxiv
http://arxiv.org/abs/2006.11684v1,2020-06-21T00:38:24Z,2020-06-21T00:38:24Z,"To Explain or Not to Explain: A Study on the Necessity of Explanations
  for Autonomous Vehicles","Explainable AI, in the context of autonomous systems, like self driving cars,
has drawn broad interests from researchers. Recent studies have found that
providing explanations for an autonomous vehicle actions has many benefits,
e.g., increase trust and acceptance, but put little emphasis on when an
explanation is needed and how the content of explanation changes with context.
In this work, we investigate which scenarios people need explanations and how
the critical degree of explanation shifts with situations and driver types.
Through a user experiment, we ask participants to evaluate how necessary an
explanation is and measure the impact on their trust in the self driving cars
in different contexts. We also present a self driving explanation dataset with
first person explanations and associated measure of the necessity for 1103
video clips, augmenting the Berkeley Deep Drive Attention dataset.
Additionally, we propose a learning based model that predicts how necessary an
explanation for a given situation in real time, using camera data inputs. Our
research reveals that driver types and context dictates whether or not an
explanation is necessary and what is helpful for improved interaction and
understanding.",arxiv
http://arxiv.org/abs/2008.04379v1,2020-08-10T19:35:51Z,2020-08-10T19:35:51Z,"A Survey and Insights on Deployments of the Connected and Autonomous
  Vehicles in US","CV/ITS (Connected Vehicle, Intelligent Transportation System) and AV/ADS
(Autonomous Vehicle, Automated Driving System) have been emerging for the sake
of saving people lives, improving traffic efficiency and helping the
environment for decades. There are separate efforts led respectively by USDOT
with state DOTs for CV, and private sectors through market driven approach from
start-ups and technology companies for AV. By CV/ITS effort there are 97
deployments of V2X communications utilizing the 5.9 GHz band, 18,877 vehicles
with aftermarket V2X communications devices, and 8,098 infrastructure V2X
devices installed at the roadsides. However, CV/ITS still cannot be massively
deployed in US markets due to lack of regulations, dedicated wireless spectrum
bands, sustainable financial & business models with mature supply chain, etc.
In the other side, technology-driven AV market has been much slower than
expected mainly because of immaturity of AI technology to handle different
complex driving scenarios in a cost effective way. In this paper, we first
present these two parallel journeys focusing on the deployments including
operating models, scenarios and applications, evaluations and lessons learning.
Then, come up with recommendations to a cooperative CAV approach driving a more
feasible, safer, affordable and cost effective transportation, but require a
great industry collaboration from Automotive, Transportation. ICT and Cloud.",arxiv
http://arxiv.org/abs/2012.15717v1,2020-12-31T17:15:09Z,2020-12-31T17:15:09Z,"FDMT: A Benchmark Dataset for Fine-grained Domain Adaptation in Machine
  Translation","Previous domain adaptation research usually neglect the diversity in
translation within a same domain, which is a core problem for adapting a
general neural machine translation (NMT) model into a specific domain in
real-world scenarios. One representative of such challenging scenarios is to
deploy a translation system for a conference with a specific topic, e.g.
computer networks or natural language processing, where there is usually
extremely less resources due to the limited time schedule. To motivate a wide
investigation in such settings, we present a real-world fine-grained domain
adaptation task in machine translation (FDMT). The FDMT dataset (Zh-En)
consists of four sub-domains of information technology: autonomous vehicles, AI
education, real-time networks and smart phone. To be closer to reality, FDMT
does not employ any in-domain bilingual training data. Instead, each sub-domain
is equipped with monolingual data, bilingual dictionary and knowledge base, to
encourage in-depth exploration of these available resources. Corresponding
development set and test set are provided for evaluation purpose. We make
quantitative experiments and deep analyses in this new setting, which
benchmarks the fine-grained domain adaptation task and reveals several
challenging problems that need to be addressed.",arxiv
http://arxiv.org/abs/2101.11775v2,2021-01-29T14:15:15Z,2021-01-28T01:46:52Z,Moral and Social Ramifications of Autonomous Vehicles,"Autonomous Vehicles (AVs) raise important social and ethical concerns,
especially about accountability, dignity, and justice. We focus on the specific
concerns arising from how AV technology will affect the lives and livelihoods
of professional and semi-professional drivers. Whereas previous studies of such
concerns have focused on the opinions of experts, we seek to understand these
ethical and societal challenges from the perspectives of the drivers
themselves.
  To this end, we adopted a qualitative research methodology based on
semi-structured interviews. This is an established social science methodology
that helps understand the core concerns of stakeholders in depth by avoiding
the biases of superficial methods such as surveys.
  We find that whereas drivers agree with the experts that AVs will
significantly impact transportation systems, they are apprehensive about the
prospects for their livelihoods and dismiss the suggestions that driving jobs
are unsatisfying and their profession does not merit protection.
  By showing how drivers differ from the experts, our study has ramifications
beyond AVs to AI and other advanced technologies. Our findings suggest that
qualitative research applied to the relevant, especially disempowered,
stakeholders is essential to ensuring that new technologies are introduced
ethically.",arxiv
http://arxiv.org/abs/2102.00145v1,2021-01-30T03:46:00Z,2021-01-30T03:46:00Z,"Actor-Critic Learning Based QoS-Aware Scheduler for Reconfigurable
  Wireless Networks","The flexibility offered by reconfigurable wireless networks, provide new
opportunities for various applications such as online AR/VR gaming,
high-quality video streaming and autonomous vehicles, that desire
high-bandwidth, reliable and low-latency communications. These applications
come with very stringent Quality of Service (QoS) requirements and increase the
burden over mobile networks. Currently, there is a huge spectrum scarcity due
to the massive data explosion and this problem can be solved by helps of
Reconfigurable Wireless Networks (RWNs) where nodes have reconfiguration and
perception capabilities. Therefore, a necessity of AI-assisted algorithms for
resource block allocation is observed. To tackle this challenge, in this paper,
we propose an actor-critic learning-based scheduler for allocating resource
blocks in a RWN. Various traffic types with different QoS levels are assigned
to our agents to provide more realistic results. We also include mobility in
our simulations to increase the dynamicity of networks. The proposed model is
compared with another actor-critic model and with other traditional schedulers;
proportional fair (PF) and Channel and QoS Aware (CQA) techniques. The proposed
models are evaluated by considering the delay experienced by user equipment
(UEs), successful transmissions and head-of-the-line delays. The results show
that the proposed model noticeably outperforms other techniques in different
aspects.",arxiv
http://arxiv.org/abs/2110.00761v1,2021-10-02T09:05:49Z,2021-10-02T09:05:49Z,"ComOpT: Combination and Optimization for Testing Autonomous Driving
  Systems","ComOpT is an open-source research tool for coverage-driven testing of
autonomous driving systems, focusing on planning and control. Starting with (i)
a meta-model characterizing discrete conditions to be considered and (ii)
constraints specifying the impossibility of certain combinations, ComOpT first
generates constraint-feasible abstract scenarios while maximally increasing the
coverage of k-way combinatorial testing. Each abstract scenario can be viewed
as a conceptual equivalence class, which is then instantiated into multiple
concrete scenarios by (1) randomly picking one local map that fulfills the
specified geographical condition, and (2) assigning all actors accordingly with
parameters within the range. Finally, ComOpT evaluates each concrete scenario
against a set of KPIs and performs local scenario variation via spawning a new
agent that might lead to a collision at designated points. We use ComOpT to
test the Apollo~6 autonomous driving software stack. ComOpT can generate highly
diversified scenarios with limited test budgets while uncovering problematic
situations such as inabilities to make simple right turns, uncomfortable
accelerations, and dangerous driving patterns. ComOpT participated in the 2021
IEEE AI Autonomous Vehicle Testing Challenge and won first place among more
than 110 contending teams.",arxiv
http://arxiv.org/abs/2001.11137v3,2021-02-08T07:43:45Z,2020-01-30T00:25:05Z,"Adversarial Attacks on Convolutional Neural Networks in Facial
  Recognition Domain","Numerous recent studies have demonstrated how Deep Neural Network (DNN)
classifiers can be fooled by adversarial examples, in which an attacker adds
perturbations to an original sample, causing the classifier to misclassify the
sample. Adversarial attacks that render DNNs vulnerable in real life represent
a serious threat in autonomous vehicles, malware filters, or biometric
authentication systems. In this paper, we apply Fast Gradient Sign Method to
introduce perturbations to a facial image dataset and then test the output on a
different classifier that we trained ourselves, to analyze transferability of
this method. Next, we craft a variety of different black-box attack algorithms
on a facial image dataset assuming minimal adversarial knowledge, to further
assess the robustness of DNNs in facial recognition. While experimenting with
different image distortion techniques, we focus on modifying single optimal
pixels by a large amount, or modifying all pixels by a smaller amount, or
combining these two attack approaches. While our single-pixel attacks achieved
about a 15% average decrease in classifier confidence level for the actual
class, the all-pixel attacks were more successful and achieved up to an 84%
average decrease in confidence, along with an 81.6% misclassification rate, in
the case of the attack that we tested with the highest levels of perturbation.
Even with these high levels of perturbation, the face images remained
identifiable to a human. Understanding how these noised and perturbed images
baffle the classification algorithms can yield valuable advances in the
training of DNNs against defense-aware adversarial attacks, as well as adaptive
noise reduction techniques. We hope our research may help to advance the study
of adversarial attacks on DNNs and defensive mechanisms to counteract them,
particularly in the facial recognition domain.",arxiv
http://arxiv.org/abs/2005.06892v1,2020-05-14T11:54:04Z,2020-05-14T11:54:04Z,ZynqNet: An FPGA-Accelerated Embedded Convolutional Neural Network,"Image Understanding is becoming a vital feature in ever more applications
ranging from medical diagnostics to autonomous vehicles. Many applications
demand for embedded solutions that integrate into existing systems with tight
real-time and power constraints. Convolutional Neural Networks (CNNs) presently
achieve record-breaking accuracies in all image understanding benchmarks, but
have a very high computational complexity. Embedded CNNs thus call for small
and efficient, yet very powerful computing platforms. This master thesis
explores the potential of FPGA-based CNN acceleration and demonstrates a fully
functional proof-of-concept CNN implementation on a Zynq System-on-Chip. The
ZynqNet Embedded CNN is designed for image classification on ImageNet and
consists of ZynqNet CNN, an optimized and customized CNN topology, and the
ZynqNet FPGA Accelerator, an FPGA-based architecture for its evaluation.
ZynqNet CNN is a highly efficient CNN topology. Detailed analysis and
optimization of prior topologies using the custom-designed Netscope CNN
Analyzer have enabled a CNN with 84.5% top-5 accuracy at a computational
complexity of only 530 million multiplyaccumulate operations. The topology is
highly regular and consists exclusively of convolutional layers, ReLU
nonlinearities and one global pooling layer. The CNN fits ideally onto the FPGA
accelerator. The ZynqNet FPGA Accelerator allows an efficient evaluation of
ZynqNet CNN. It accelerates the full network based on a nested-loop algorithm
which minimizes the number of arithmetic operations and memory accesses. The
FPGA accelerator has been synthesized using High-Level Synthesis for the Xilinx
Zynq XC-7Z045, and reaches a clock frequency of 200MHz with a device
utilization of 80% to 90 %.",arxiv
http://arxiv.org/abs/2008.11672v3,2020-11-28T13:46:27Z,2020-08-26T16:56:57Z,"DeepSOCIAL: Social Distancing Monitoring and Infection Risk Assessment
  in COVID-19 Pandemic","Social distancing is a recommended solution by the World Health Organisation
(WHO) to minimise the spread of COVID-19 in public places. The majority of
governments and national health authorities have set the 2-meter physical
distancing as a mandatory safety measure in shopping centres, schools and other
covered areas. In this research, we develop a hybrid Computer Vision and
YOLOv4-based Deep Neural Network model for automated people detection in the
crowd in indoor and outdoor environments using common CCTV security cameras.
The proposed DNN model in combination with an adapted inverse perspective
mapping (IPM) technique and SORT tracking algorithm leads to a robust people
detection and social distancing monitoring. The model has been trained against
two most comprehensive datasets by the time of the research the Microsoft
Common Objects in Context (MS COCO) and Google Open Image datasets. The system
has been evaluated against the Oxford Town Centre dataset with superior
performance compared to three state-of-the-art methods. The evaluation has been
conducted in challenging conditions, including occlusion, partial visibility,
and under lighting variations with the mean average precision of 99.8% and the
real-time speed of 24.1 fps. We also provide an online infection risk
assessment scheme by statistical analysis of the Spatio-temporal data from
people's moving trajectories and the rate of social distancing violations. The
developed model is a generic and accurate people detection and tracking
solution that can be applied in many other fields such as autonomous vehicles,
human action recognition, anomaly detection, sports, crowd analysis, or any
other research areas where the human detection is in the centre of attention.",arxiv
http://arxiv.org/abs/2010.04331v3,2021-08-13T01:29:14Z,2020-10-09T02:31:34Z,"Targeted Physical-World Attention Attack on Deep Learning Models in Road
  Sign Recognition","Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.",arxiv
http://arxiv.org/abs/2012.10672v2,2020-12-23T00:17:56Z,2020-12-19T12:26:06Z,RMT: Rule-based Metamorphic Testing for Autonomous Driving Models,"Deep neural network models are widely used for perception and control in
autonomous driving. Recent work uses metamorphic testing but is limited to
using equality-based metamorphic relations and does not provide expressiveness
for defining inequality-based metamorphic relations. To encode real world
traffic rules, domain experts must be able to express higher order relations
e.g., a vehicle should decrease speed in certain ratio, when there is a vehicle
x meters ahead and compositionality e.g., a vehicle must have a larger
deceleration, when there is a vehicle ahead and when the weather is rainy and
proportional compounding effect to the test outcome. We design RMT, a
declarative rule-based metamorphic testing framework. It provides three
components that work in concert:(1) a domain specific language that enables an
expert to express higher-order, compositional metamorphic relations, (2)
pluggable transformation engines built on a variety of image and graphics
processing techniques, and (3) automated test generation that translates a
human-written rule to a corresponding executable, metamorphic relation and
synthesizes meaningful inputs.Our evaluation using three driving models shows
that RMT can generate meaningful test cases on which 89% of erroneous
predictions are found by enabling higher-order metamorphic relations.
Compositionality provides further aids for generating meaningful, synthesized
inputs-3012 new images are generated by compositional rules. These detected
erroneous predictions are manually examined and confirmed by six human judges
as meaningful traffic rule violations. RMT is the first to expand automated
testing capability for autonomous vehicles by enabling easy mapping of traffic
regulations to executable metamorphic relations and to demonstrate the benefits
of expressivity, customization, and pluggability.",arxiv
http://arxiv.org/abs/2102.08417v1,2021-02-16T19:19:23Z,2021-02-16T19:19:23Z,Finding the Gap: Neuromorphic Motion Vision in Cluttered Environments,"Many animals meander in environments and avoid collisions. How the underlying
neuronal machinery can yield robust behaviour in a variety of environments
remains unclear. In the fly brain, motion-sensitive neurons indicate the
presence of nearby objects and directional cues are integrated within an area
known as the central complex. Such neuronal machinery, in contrast with the
traditional stream-based approach to signal processing, uses an event-based
approach, with events occurring when changes are sensed by the animal. Contrary
to von Neumann computing architectures, event-based neuromorphic hardware is
designed to process information in an asynchronous and distributed manner.
Inspired by the fly brain, we model, for the first time, a neuromorphic
closed-loop system mimicking essential behaviours observed in flying insects,
such as meandering in clutter and gap crossing, which are highly relevant for
autonomous vehicles. We implemented our system both in software and on
neuromorphic hardware. While moving through an environment, our agent perceives
changes in its surroundings and uses this information for collision avoidance.
The agent's manoeuvres result from a closed action-perception loop implementing
probabilistic decision-making processes. This loop-closure is thought to have
driven the development of neural circuitry in biological agents since the
Cambrian explosion. In the fundamental quest to understand neural computation
in artificial agents, we come closer to understanding and modelling biological
intelligence by closing the loop also in neuromorphic systems. As a closed-loop
system, our system deepens our understanding of processing in neural networks
and computations in biological and artificial systems. With these
investigations, we aim to set the foundations for neuromorphic intelligence in
the future, moving towards leveraging the full potential of neuromorphic
systems.",arxiv
http://arxiv.org/abs/2108.11800v1,2021-08-26T14:03:56Z,2021-08-26T14:03:56Z,"Efficient Out-of-Distribution Detection Using Latent Space of
  $$-VAE for Cyber-Physical Systems","Deep Neural Networks are actively being used in the design of autonomous
Cyber-Physical Systems (CPSs). The advantage of these models is their ability
to handle high-dimensional state-space and learn compact surrogate
representations of the operational state spaces. However, the problem is that
the sampled observations used for training the model may never cover the entire
state space of the physical environment, and as a result, the system will
likely operate in conditions that do not belong to the training distribution.
These conditions that do not belong to training distribution are referred to as
Out-of-Distribution (OOD). Detecting OOD conditions at runtime is critical for
the safety of CPS. In addition, it is also desirable to identify the context or
the feature(s) that are the source of OOD to select an appropriate control
action to mitigate the consequences that may arise because of the OOD
condition. In this paper, we study this problem as a multi-labeled time series
OOD detection problem over images, where the OOD is defined both sequentially
across short time windows (change points) as well as across the training data
distribution. A common approach to solving this problem is the use of
multi-chained one-class classifiers. However, this approach is expensive for
CPSs that have limited computational resources and require short inference
times. Our contribution is an approach to design and train a single
$\beta$-Variational Autoencoder detector with a partially disentangled latent
space sensitive to variations in image features. We use the feature sensitive
latent variables in the latent space to detect OOD images and identify the most
likely feature(s) responsible for the OOD. We demonstrate our approach using an
Autonomous Vehicle in the CARLA simulator and a real-world automotive dataset
called nuImages.",arxiv
http://arxiv.org/abs/2109.09975v2,2021-09-22T23:22:19Z,2021-09-21T05:55:39Z,"Fast nonlinear risk assessment for autonomous vehicles using learned
  conditional probabilistic models of agent futures","This paper presents fast non-sampling based methods to assess the risk for
trajectories of autonomous vehicles when probabilistic predictions of other
agents' futures are generated by deep neural networks (DNNs). The presented
methods address a wide range of representations for uncertain predictions
including both Gaussian and non-Gaussian mixture models to predict both agent
positions and control inputs conditioned on the scene contexts. We show that
the problem of risk assessment when Gaussian mixture models (GMMs) of agent
positions are learned can be solved rapidly to arbitrary levels of accuracy
with existing numerical methods. To address the problem of risk assessment for
non-Gaussian mixture models of agent position, we propose finding upper bounds
on risk using nonlinear Chebyshev's Inequality and sums-of-squares (SOS)
programming; they are both of interest as the former is much faster while the
latter can be arbitrarily tight. These approaches only require higher order
statistical moments of agent positions to determine upper bounds on risk. To
perform risk assessment when models are learned for agent control inputs as
opposed to positions, we propagate the moments of uncertain control inputs
through the nonlinear motion dynamics to obtain the exact moments of uncertain
position over the planning horizon. To this end, we construct deterministic
linear dynamical systems that govern the exact time evolution of the moments of
uncertain position in the presence of uncertain control inputs. The presented
methods are demonstrated on realistic predictions from DNNs trained on the
Argoverse and CARLA datasets and are shown to be effective for rapidly
assessing the probability of low probability events.",arxiv
http://arxiv.org/abs/1806.03243v1,2018-05-28T17:46:54Z,2018-05-28T17:46:54Z,"In-vehicle data recording, storage and access management in autonomous
  vehicles","Transport sector is in the process of being rapidly and fundamentally
reshaped by autonomous and collaborative driving technologies. This reshaping
promises huge economic and social benefits as well as challenges in terms of
developing and deploying secure and safe transportations systems, their smooth
integration to social fabric. We have employed Policy Scan and Technology
Strategy Design methodology in order to identify concrete societal expectations
and problems and map them with mitigating technological availabilities in the
domain of autonomous driving and smart mobility.
  Event Data Recorder for Autonomous Driving (EDR/AD) is an envisioned
subsystem of a vehicular Controller Area Network which ensures the
confidentiality, integrity and availability of data related to operation of a
vehicle in order to permit recovery of exact situation following the occurrence
of an event or on demand. The exact technical and regulatory requirements for
the device are still in the development internationally, but it is clear that
it will be included into vehicle type-approval requirements at UNECE level. We
present an analysis of the context of the usage of the EDR/AD in collaborative
intelligent transport systems, related security, data provenance and privacy,
other regulatory and technical issues considering many interest groups and
stakeholders involved. We present a concrete proposal for developing a EDR/AD
proof of the concept prototype with clear market deployment potential and urge
security researchers, vehicle manufacturers, and component suppliers to form a
collaboration towards implementing important technology for making future
autonomous vehicles more socially acceptable and legally compliant.
Furthermore, EDR/AD technology, apart from its immediate use in autonomous
driving and smart mobility domain has a potential to be extended to general
autonomous robot and AI applications.",arxiv
