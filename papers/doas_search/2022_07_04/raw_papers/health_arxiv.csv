id,updated,published,title,summary,database,query_name,query_value
http://arxiv.org/abs/2207.03366v1,2022-07-07T15:14:37Z,2022-07-07T15:14:37Z,"A simple normalization technique using window statistics to improve the
  out-of-distribution generalization in medical images","Since data scarcity and data heterogeneity are prevailing for medical images,
well-trained Convolutional Neural Networks (CNNs) using previous normalization
methods may perform poorly when deployed to a new site. However, a reliable
model for real-world applications should be able to generalize well both on
in-distribution (IND) and out-of-distribution (OOD) data (e.g., the new site
data). In this study, we present a novel normalization technique called window
normalization (WIN), which is a simple yet effective alternative to existing
normalization methods. Specifically, WIN perturbs the normalizing statistics
with the local statistics computed on a window of features. This feature-level
augmentation technique regularizes the models well and improves their OOD
generalization significantly. Taking its advantage, we propose a novel
self-distillation method called WIN-WIN to further improve the OOD
generalization in classification. WIN-WIN is easily implemented with twice
forward passes and a consistency constraint, which can be a simple extension
for existing methods. Extensive experimental results on various tasks (such as
glaucoma detection, breast cancer detection, chromosome classification, optic
disc and cup segmentation, etc.) and datasets (26 datasets) demonstrate the
generality and effectiveness of our methods. The code is available at
https://github.com/joe1chief/windowNormalizaion.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.13034v1,2022-06-27T03:55:23Z,2022-06-27T03:55:23Z,Monitoring Shortcut Learning using Mutual Information,"The failure of deep neural networks to generalize to out-of-distribution data
is a well-known problem and raises concerns about the deployment of trained
networks in safety-critical domains such as healthcare, finance and autonomous
vehicles. We study a particular kind of distribution shift $\unicode{x2013}$
shortcuts or spurious correlations in the training data. Shortcut learning is
often only exposed when models are evaluated on real-world data that does not
contain the same spurious correlations, posing a serious dilemma for AI
practitioners to properly assess the effectiveness of a trained model for
real-world applications. In this work, we propose to use the mutual information
(MI) between the learned representation and the input as a metric to find where
in training, the network latches onto shortcuts. Experiments demonstrate that
MI can be used as a domain-agnostic metric for monitoring shortcut learning.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.11981v1,2022-06-23T21:13:10Z,2022-06-23T21:13:10Z,"Never trust, always verify : a roadmap for Trustworthy AI?","Artificial Intelligence (AI) is becoming the corner stone of many systems
used in our daily lives such as autonomous vehicles, healthcare systems, and
unmanned aircraft systems. Machine Learning is a field of AI that enables
systems to learn from data and make decisions on new data based on models to
achieve a given goal. The stochastic nature of AI models makes verification and
validation tasks challenging. Moreover, there are intrinsic biaises in AI
models such as reproductibility bias, selection bias (e.g., races, genders,
color), and reporting bias (i.e., results that do not reflect the reality).
Increasingly, there is also a particular attention to the ethical, legal, and
societal impacts of AI. AI systems are difficult to audit and certify because
of their black-box nature. They also appear to be vulnerable to threats; AI
systems can misbehave when untrusted data are given, making them insecure and
unsafe. Governments, national and international organizations have proposed
several principles to overcome these challenges but their applications in
practice are limited and there are different interpretations in the principles
that can bias implementations. In this paper, we examine trust in the context
of AI-based systems to understand what it means for an AI system to be
trustworthy and identify actions that need to be undertaken to ensure that AI
systems are trustworthy. To achieve this goal, we first review existing
approaches proposed for ensuring the trustworthiness of AI systems, in order to
identify potential conceptual gaps in understanding what trustworthy AI is.
Then, we suggest a trust (resp. zero-trust) model for AI and suggest a set of
properties that should be satisfied to ensure the trustworthiness of AI
systems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.11804v4,2022-07-07T05:57:55Z,2022-06-23T16:22:56Z,"Rethinking Surgical Instrument Segmentation: A Background Image Can Be
  All You Need","Data diversity and volume are crucial to the success of training deep
learning models, while in the medical imaging field, the difficulty and cost of
data collection and annotation are especially huge. Specifically in robotic
surgery, data scarcity and imbalance have heavily affected the model accuracy
and limited the design and deployment of deep learning-based surgical
applications such as surgical instrument segmentation. Considering this, we
rethink the surgical instrument segmentation task and propose a one-to-many
data generation solution that gets rid of the complicated and expensive process
of data collection and annotation from robotic surgery. In our method, we only
utilize a single surgical background tissue image and a few open-source
instrument images as the seed images and apply multiple augmentations and
blending techniques to synthesize amounts of image variations. In addition, we
also introduce the chained augmentation mixing during training to further
enhance the data diversities. The proposed approach is evaluated on the real
datasets of the EndoVis-2018 and EndoVis-2017 surgical scene segmentation. Our
empirical analysis suggests that without the high cost of data collection and
annotation, we can achieve decent surgical instrument segmentation performance.
Moreover, we also observe that our method can deal with novel instrument
prediction in the deployment domain. We hope our inspiring results will
encourage researchers to emphasize data-centric methods to overcome demanding
deep learning limitations besides data shortage, such as class imbalance,
domain adaptation, and incremental learning. Our code is available at
https://github.com/lofrienger/Single_SurgicalScene_For_Segmentation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.08967v1,2022-06-17T18:47:40Z,2022-06-17T18:47:40Z,Random Forest of Epidemiological Models for Influenza Forecasting,"Forecasting the hospitalizations caused by the Influenza virus is vital for
public health planning so that hospitals can be better prepared for an influx
of patients. Many forecasting methods have been used in real-time during the
Influenza seasons and submitted to the CDC for public communication. The
forecasting models range from mechanistic models, and auto-regression models to
machine learning models. We hypothesize that we can improve forecasting by
using multiple mechanistic models to produce potential trajectories and use
machine learning to learn how to combine those trajectories into an improved
forecast. We propose a Tree Ensemble model design that utilizes the individual
predictors of our baseline model SIkJalpha to improve its performance. Each
predictor is generated by changing a set of hyper-parameters. We compare our
prospective forecasts deployed for the FluSight challenge (2022) to all the
other submitted approaches. Our approach is fully automated and does not
require any manual tuning. We demonstrate that our Random Forest-based approach
is able to improve upon the forecasts of the individual predictors in terms of
mean absolute error, coverage, and weighted interval score. Our method
outperforms all other models in terms of the mean absolute error and the
weighted interval score based on the mean across all weekly submissions in the
current season (2022). Explainability of the Random Forest (through analysis of
the trees) enables us to gain insights into how it improves upon the individual
predictors.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.06253v1,2022-06-13T15:35:59Z,2022-06-13T15:35:59Z,"RPLHR-CT Dataset and Transformer Baseline for Volumetric
  Super-Resolution from CT Scans","In clinical practice, anisotropic volumetric medical images with low
through-plane resolution are commonly used due to short acquisition time and
lower storage cost. Nevertheless, the coarse resolution may lead to
difficulties in medical diagnosis by either physicians or computer-aided
diagnosis algorithms. Deep learning-based volumetric super-resolution (SR)
methods are feasible ways to improve resolution, with convolutional neural
networks (CNN) at their core. Despite recent progress, these methods are
limited by inherent properties of convolution operators, which ignore content
relevance and cannot effectively model long-range dependencies. In addition,
most of the existing methods use pseudo-paired volumes for training and
evaluation, where pseudo low-resolution (LR) volumes are generated by a simple
degradation of their high-resolution (HR) counterparts. However, the domain gap
between pseudo- and real-LR volumes leads to the poor performance of these
methods in practice. In this paper, we build the first public real-paired
dataset RPLHR-CT as a benchmark for volumetric SR, and provide baseline results
by re-implementing four state-of-the-art CNN-based methods. Considering the
inherent shortcoming of CNN, we also propose a transformer volumetric
super-resolution network (TVSRN) based on attention mechanisms, dispensing with
convolutions entirely. This is the first research to use a pure transformer for
CT volumetric SR. The experimental results show that TVSRN significantly
outperforms all baselines on both PSNR and SSIM. Moreover, the TVSRN method
achieves a better trade-off between the image quality, the number of
parameters, and the running time. Data and code are available at
https://github.com/smilenaxx/RPLHR-CT.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.04336v1,2022-06-09T08:31:14Z,2022-06-09T08:31:14Z,"Joint Modeling of Image and Label Statistics for Enhancing Model
  Generalizability of Medical Image Segmentation","Although supervised deep-learning has achieved promising performance in
medical image segmentation, many methods cannot generalize well on unseen data,
limiting their real-world applicability. To address this problem, we propose a
deep learning-based Bayesian framework, which jointly models image and label
statistics, utilizing the domain-irrelevant contour of a medical image for
segmentation. Specifically, we first decompose an image into components of
contour and basis. Then, we model the expected label as a variable only related
to the contour. Finally, we develop a variational Bayesian framework to infer
the posterior distributions of these variables, including the contour, the
basis, and the label. The framework is implemented with neural networks, thus
is referred to as deep Bayesian segmentation. Results on the task of
cross-sequence cardiac MRI segmentation show that our method set a new state of
the art for model generalizability. Particularly, the BayeSeg model trained
with LGE MRI generalized well on T2 images and outperformed other models with
great margins, i.e., over 0.47 in terms of average Dice. Our code is available
at https://zmiclab.github.io/projects.html.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.03359v1,2022-06-07T14:53:35Z,2022-06-07T14:53:35Z,"An efficient semi-supervised quality control system trained using
  physics-based MRI-artefact generators and adversarial training","Large medical imaging data sets are becoming increasingly available. A common
challenge in these data sets is to ensure that each sample meets minimum
quality requirements devoid of significant artefacts. Despite a wide range of
existing automatic methods having been developed to identify imperfections and
artefacts in medical imaging, they mostly rely on data-hungry methods. In
particular, the lack of sufficient scans with artefacts available for training
has created a barrier in designing and deploying machine learning in clinical
research. To tackle this problem, we propose a novel framework having four main
components: (1) a set of artefact generators inspired by magnetic resonance
physics to corrupt brain MRI scans and augment a training dataset, (2) a set of
abstract and engineered features to represent images compactly, (3) a feature
selection process that depends on the class of artefact to improve
classification performance, and (4) a set of Support Vector Machine (SVM)
classifiers trained to identify artefacts. Our novel contributions are
threefold: first, we use the novel physics-based artefact generators to
generate synthetic brain MRI scans with controlled artefacts as a data
augmentation technique. This will avoid the labour-intensive collection and
labelling process of scans with rare artefacts. Second, we propose a large pool
of abstract and engineered image features developed to identify 9 different
artefacts for structural MRI. Finally, we use an artefact-based feature
selection block that, for each class of artefacts, finds the set of features
that provide the best classification performance. We performed validation
experiments on a large data set of scans with artificially-generated artefacts,
and in a multiple sclerosis clinical trial where real artefacts were identified
by experts, showing that the proposed pipeline outperforms traditional methods.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.02868v1,2022-06-06T19:47:29Z,2022-06-06T19:47:29Z,A Human-Centric Take on Model Monitoring,"Predictive models are increasingly used to make various consequential
decisions in high-stakes domains such as healthcare, finance, and policy. It
becomes critical to ensure that these models make accurate predictions, are
robust to shifts in the data, do not rely on spurious features, and do not
unduly discriminate against minority groups. To this end, several approaches
spanning various areas such as explainability, fairness, and robustness have
been proposed in recent literature. Such approaches need to be human-centered
as they cater to the understanding of the models to their users. However, there
is a research gap in understanding the human-centric needs and challenges of
monitoring machine learning (ML) models once they are deployed. To fill this
gap, we conducted an interview study with 13 practitioners who have experience
at the intersection of deploying ML models and engaging with customers spanning
domains such as financial services, healthcare, hiring, online retail,
computational advertising, and conversational assistants. We identified various
human-centric challenges and requirements for model monitoring in real-world
applications. Specifically, we found the need and the challenge for the model
monitoring systems to clarify the impact of the monitoring observations on
outcomes. Further, such insights must be actionable, robust, customizable for
domain-specific use cases, and cognitively considerate to avoid information
overload.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.02061v1,2022-06-04T22:09:34Z,2022-06-04T22:09:34Z,Low Power Neuromorphic EMG Gesture Classification,"EMG (Electromyograph) signal based gesture recognition can prove vital for
applications such as smart wearables and bio-medical neuro-prosthetic control.
Spiking Neural Networks (SNNs) are promising for low-power, real-time EMG
gesture recognition, owing to their inherent spike/event driven spatio-temporal
dynamics. In literature, there are limited demonstrations of neuromorphic
hardware implementation (at full chip/board/system scale) for EMG gesture
classification. Moreover, most literature attempts exploit primitive SNNs based
on LIF (Leaky Integrate and Fire) neurons. In this work, we address the
aforementioned gaps with following key contributions: (1) Low-power, high
accuracy demonstration of EMG-signal based gesture recognition using
neuromorphic Recurrent Spiking Neural Networks (RSNN). In particular, we
propose a multi-time scale recurrent neuromorphic system based on special
double-exponential adaptive threshold (DEXAT) neurons. Our network achieves
state-of-the-art classification accuracy (90%) while using ~53% lesser neurons
than best reported prior art on Roshambo EMG dataset. (2) A new multi-channel
spike encoder scheme for efficient processing of real-valued EMG data on
neuromorphic systems. (3) Unique multi-compartment methodology to implement
complex adaptive neurons on Intel's dedicated neuromorphic Loihi chip is shown.
(4) RSNN implementation on Loihi (Nahuku 32) achieves significant
energy/latency benefits of ~983X/19X compared to GPU for batch size as 50.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.00868v1,2022-06-02T04:34:57Z,2022-06-02T04:34:57Z,"6G Survey on Challenges, Requirements, Applications, Key Enabling
  Technologies, Use Cases, AI integration issues and Security aspects","The fifth-generation (5G) network is likely to bring in high data rates, more
reliability, and low delays for mobile, personal and local area networks.
Alongside the rapid growth of smart wireless sensing and communication
technologies, data traffic has significantly risen, and existing 5G networks
are not fully capable of supporting future massive data traffic in terms of
services, storage, and processing. To meet the forthcoming challenges, the
research community is investigating the Terahertz-based sixth-generation (6G)
wireless network which is supposed to be offered for industrial usage in around
10 years. This is the right time to explore and learn about various 6G aspects
that will play a key role in the successful execution and implementation of 6G
networks in the future. This survey provides a review of specifications,
requirements, applications, enabling technologies including disruptive and
innovative, integration of 6G with advanced architectures and networks like
software-defined networks (SDN), network functions virtualization (NFV),
cloud/fog computing, etc, artificial intelligence (AI) oriented technologies,
privacy and security issues and solutions, and potential futuristic use cases:
virtual reality, smart healthcare and Industry 5.0. Furthermore, based on the
conducted review, challenges and future research directions are highlighted to
aid the deployment of 6G networks.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.00105v1,2022-05-31T20:39:35Z,2022-05-31T20:39:35Z,Deep learning pipeline for image classification on mobile phones,"This article proposes and documents a machine-learning framework and tutorial
for classifying images using mobile phones. Compared to computers, the
performance of deep learning model performance degrades when deployed on a
mobile phone and requires a systematic approach to find a model that performs
optimally on both computers and mobile phones. By following the proposed
pipeline, which consists of various computational tools, simple procedural
recipes, and technical considerations, one can bring the power of deep learning
medical image classification to mobile devices, potentially unlocking new
domains of applications. The pipeline is demonstrated on four different
publicly available datasets: COVID X-rays, COVID CT scans, leaves, and
colorectal cancer. We used two application development frameworks: TensorFlow
Lite (real-time testing) and Flutter (digital image testing) to test the
proposed pipeline. We found that transferring deep learning models to a mobile
phone is limited by hardware and classification accuracy drops. To address this
issue, we proposed this pipeline to find an optimized model for mobile phones.
Finally, we discuss additional applications and computational concerns related
to deploying deep-learning models on phones, including real-time analysis and
image preprocessing. We believe the associated documentation and code can help
physicians and medical experts develop medical image classification
applications for distribution.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.14094v1,2022-05-27T16:50:48Z,2022-05-27T16:50:48Z,"Failure Detection in Medical Image Classification: A Reality Check and
  Benchmarking Testbed","Failure detection in automated image classification is a critical safeguard
for clinical deployment. Detected failure cases can be referred to human
assessment, ensuring patient safety in computer-aided clinical decision making.
Despite its paramount importance, there is insufficient evidence about the
ability of state-of-the-art confidence scoring methods to detect test-time
failures of classification models in the context of medical imaging. This paper
provides a reality check, establishing the performance of in-domain
misclassification detection methods, benchmarking 9 confidence scores on 6
medical imaging datasets with different imaging modalities, in multiclass and
binary classification settings. Our experiments show that the problem of
failure detection is far from being solved. We found that none of the
benchmarked advanced methods proposed in the computer vision and machine
learning literature can consistently outperform a simple softmax baseline. Our
developed testbed facilitates future work in this important area.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.13607v2,2022-06-02T18:27:47Z,2022-05-26T20:23:55Z,"Self-supervised Pretraining and Transfer Learning Enable Flu and
  COVID-19 Predictions in Small Mobile Sensing Datasets","Detailed mobile sensing data from phones, watches, and fitness trackers offer
an unparalleled opportunity to quantify and act upon previously unmeasurable
behavioral changes in order to improve individual health and accelerate
responses to emerging diseases. Unlike in natural language processing and
computer vision, deep representation learning has yet to broadly impact this
domain, in which the vast majority of research and clinical applications still
rely on manually defined features and boosted tree models or even forgo
predictive modeling altogether due to insufficient accuracy. This is due to
unique challenges in the behavioral health domain, including very small
datasets (~10^1 participants), which frequently contain missing data, consist
of long time series with critical long-range dependencies (length>10^4), and
extreme class imbalances (>10^3:1). Here, we introduce a neural architecture
for multivariate time series classification designed to address these unique
domain challenges. Our proposed behavioral representation learning approach
combines novel tasks for self-supervised pretraining and transfer learning to
address data scarcity, and captures long-range dependencies across long-history
time series through transformer self-attention following convolutional neural
network-based dimensionality reduction. We propose an evaluation framework
aimed at reflecting expected real-world performance in plausible deployment
scenarios. Concretely, we demonstrate (1) performance improvements over
baselines of up to 0.15 ROC AUC across five prediction tasks, (2) transfer
learning-induced performance improvements of 16% PR AUC in small data
scenarios, and (3) the potential of transfer learning in novel disease
scenarios through an exploratory case study of zero-shot COVID-19 prediction in
an independent data set. Finally, we discuss potential implications for medical
surveillance testing.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.12093v1,2022-05-24T14:17:26Z,2022-05-24T14:17:26Z,Bias Discovery in Machine Learning Models for Mental Health,"Fairness and bias are crucial concepts in artificial intelligence, yet they
are relatively ignored in machine learning applications in clinical psychiatry.
We computed fairness metrics and present bias mitigation strategies using a
model trained on clinical mental health data. We collected structured data
related to the admission, diagnosis, and treatment of patients in the
psychiatry department of the University Medical Center Utrecht. We trained a
machine learning model to predict future administrations of benzodiazepines on
the basis of past data. We found that gender plays an unexpected role in the
predictions-this constitutes bias. Using the AI Fairness 360 package, we
implemented reweighing and discrimination-aware regularization as bias
mitigation strategies, and we explored their implications for model
performance. This is the first application of bias exploration and mitigation
in a machine learning model trained on real clinical psychiatry data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.11090v1,2022-05-23T07:19:42Z,2022-05-23T07:19:42Z,FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders,"Face recognition, as one of the most successful applications in artificial
intelligence, has been widely used in security, administration, advertising,
and healthcare. However, the privacy issues of public face datasets have
attracted increasing attention in recent years. Previous works simply mask most
areas of faces or synthesize samples using generative models to construct
privacy-preserving face datasets, which overlooks the trade-off between privacy
protection and data utility. In this paper, we propose a novel framework
FaceMAE, where the face privacy and recognition performance are considered
simultaneously. Firstly, randomly masked face images are used to train the
reconstruction module in FaceMAE. We tailor the instance relation matching
(IRM) module to minimize the distribution gap between real faces and FaceMAE
reconstructed ones. During the deployment phase, we use trained FaceMAE to
reconstruct images from masked faces of unseen identities without extra
training. The risk of privacy leakage is measured based on face retrieval
between reconstructed and original datasets. Experiments prove that the
identities of reconstructed images are difficult to be retrieved. We also
perform sufficient privacy-preserving face recognition on several public face
datasets (i.e. CASIA-WebFace and WebFace260M). Compared to previous state of
the arts, FaceMAE consistently \textbf{reduces at least 50\% error rate} on
LFW, CFP-FP and AgeDB.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.10952v1,2022-05-22T23:14:27Z,2022-05-22T23:14:27Z,Analysis of functional neural codes of deep learning models,"Deep neural networks (DNNs), the agents of deep learning (DL), require a
massive number of parallel/sequential operations. This makes it extremely
challenging to comprehend DNNs' operations and hinders proper diagnosis.
Consequently, DNNs cannot be readily used in high-stakes domains, in which
incorrect decisions can lead to catastrophic failures. Therefore, to build more
reliable DNNs/DL to be deployed in high-stakes real-world problems, it is
imperative that we develop proper analysis tools that will allow us to better
understand DNNs' internal operations underlying their decision-making. Here, we
used the self-organizing map (SOM) to analyze internal codes of DL models
associated with their decision-making. Our analyses suggest that hidden layer
activation patterns can be mapped onto a finite number of patterns and are
correlated with DL predictions, raising the possibility that they could serve
as functional codes of DL models. Encouraged by this observation, we further
used SOM to estimate input features coded in hidden layers, analyzed the
effects of adversarial inputs to better understand characterized internal
representations' evolution and adversarial perturbations' propagation in DL
models.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.10635v1,2022-05-21T16:24:47Z,2022-05-21T16:24:47Z,"SplitPlace: AI Augmented Splitting and Placement of Large-Scale Neural
  Networks in Mobile Edge Environments","In recent years, deep learning models have become ubiquitous in industry and
academia alike. Deep neural networks can solve some of the most complex
pattern-recognition problems today, but come with the price of massive compute
and memory requirements. This makes the problem of deploying such large-scale
neural networks challenging in resource-constrained mobile edge computing
platforms, specifically in mission-critical domains like surveillance and
healthcare. To solve this, a promising solution is to split resource-hungry
neural networks into lightweight disjoint smaller components for pipelined
distributed processing. At present, there are two main approaches to do this:
semantic and layer-wise splitting. The former partitions a neural network into
parallel disjoint models that produce a part of the result, whereas the latter
partitions into sequential models that produce intermediate results. However,
there is no intelligent algorithm that decides which splitting strategy to use
and places such modular splits to edge nodes for optimal performance. To combat
this, this work proposes a novel AI-driven online policy, SplitPlace, that uses
Multi-Armed-Bandits to intelligently decide between layer and semantic
splitting strategies based on the input task's service deadline demands.
SplitPlace places such neural network split fragments on mobile edge devices
using decision-aware reinforcement learning for efficient and scalable
computing. Moreover, SplitPlace fine-tunes its placement engine to adapt to
volatile environments. Our experiments on physical mobile-edge environments
with real-world workloads show that SplitPlace can significantly improve the
state-of-the-art in terms of average response time, deadline violation rate,
inference accuracy, and total reward by up to 46, 69, 3 and 12 percent
respectively.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.09526v1,2022-05-19T12:49:37Z,2022-05-19T12:49:37Z,Simple Regularisation for Uncertainty-Aware Knowledge Distillation,"Considering uncertainty estimation of modern neural networks (NNs) is one of
the most important steps towards deploying machine learning systems to
meaningful real-world applications such as in medicine, finance or autonomous
systems. At the moment, ensembles of different NNs constitute the
state-of-the-art in both accuracy and uncertainty estimation in different
tasks. However, ensembles of NNs are unpractical under real-world constraints,
since their computation and memory consumption scale linearly with the size of
the ensemble, which increase their latency and deployment cost. In this work,
we examine a simple regularisation approach for distribution-free knowledge
distillation of ensemble of machine learning models into a single NN. The aim
of the regularisation is to preserve the diversity, accuracy and uncertainty
estimation characteristics of the original ensemble without any intricacies,
such as fine-tuning. We demonstrate the generality of the approach on
combinations of toy data, SVHN/CIFAR-10, simple to complex NN architectures and
different tasks.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.08404v1,2022-05-17T14:38:38Z,2022-05-17T14:38:38Z,"A Comprehensive Study on Artificial Intelligence Algorithms to Implement
  Safety Using Communication Technologies","The recent development of artificial intelligence (AI) has increased the
interest of researchers and practitioners towards applying its techniques into
multiple domains like automotive, health care and air space to achieve
automation. Combined to these applications, the attempt to use AI techniques
into carrying out safety issues is momentarily at a progressive state. As AI
problems are getting even more complex, large processing power is demanded for
safety-critical systems to fulfill real-time requirements. These challenges can
be solved through edge or cloud computing, which makes the communication an
integral part of the solution. This study aims at providing a comprehensive
picture of the state of the art AI based safety solutions that uses different
communication technologies in diverse application domains. To achieve this, a
systematic mapping study is conducted and 565 relevant papers are shortlisted
through a multistage selection process, which are then analyzed according to a
systematically defined classification framework. The results of the study are
based on these main objectives: to clarify current research gaps in the field,
to identify the possibility of increased usage of cellular communication in
multiple domains, to identify the mostly used AI algorithms and to summarize
the emerging future research trends on the topic. The results demonstrate that
automotive domain is the one applying AI and communication the most to
implement safety and the most used AI in this domain is neural networks,
clustering and computer vision; applying cellular communication to automotive
domain is highest; the use of non-cellular communication technologies is
dominant however a clear trend of a rapid increase in the use of cellular
communication is observed specially from 2020 with the roll-out of 5G
technology.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.08292v1,2022-05-17T12:44:54Z,2022-05-17T12:44:54Z,"Providing Location Information at Edge Networks: A Federated
  Learning-Based Approach","Recently, the development of mobile edge computing has enabled exhilarating
edge artificial intelligence (AI) with fast response and low communication
cost. The location information of edge devices is essential to support the edge
AI in many scenarios, like smart home, intelligent transportation systems and
integrated health care. Taking advantages of deep learning intelligence, the
centralized machine learning (ML)-based positioning technique has received
heated attention from both academia and industry. However, some potential
issues, such as location information leakage and huge data traffic, limit its
application. Fortunately, a newly emerging privacy-preserving distributed ML
mechanism, named federated learning (FL), is expected to alleviate these
concerns. In this article, we illustrate a framework of FL-based localization
system as well as the involved entities at edge networks. Moreover, the
advantages of such system are elaborated. On practical implementation of it, we
investigate the field-specific issues associated with system-level solutions,
which are further demonstrated over a real-word database. Moreover, future
challenging open problems in this field are outlined.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.06234v1,2022-05-12T17:23:24Z,2022-05-12T17:23:24Z,"SIBILA: High-performance computing and interpretable machine learning
  join efforts toward personalised medicine in a novel decision-making tool","Background and Objectives: Personalised medicine remains a major challenge
for scientists. The rapid growth of Machine learning and Deep learning has made
it a feasible alternative for predicting the most appropriate therapy for
individual patients. However, the lack of interpretation of their results and
high computational requirements make many reluctant to use these methods.
  Methods: Several Machine learning and Deep learning models have been
implemented into a single software tool, SIBILA. Once the models are trained,
SIBILA applies a range of interpretability methods to identify the input
features that each model considered the most important to predict. In addition,
all the features obtained are put in common to estimate the global attribution
of each variable to the predictions. To facilitate its use by non-experts,
SIBILA is also available to all users free of charge as a web server at
https://bio-hpc.ucam.edu/sibila/.
  Results: SIBILA has been applied to three case studies to show its accuracy
and efficiency in classification and regression problems. The first two cases
proved that SIBILA can make accurate predictions even on uncleaned datasets.
The last case demonstrates that SIBILA can be applied to medical contexts with
real data.
  Conclusion: With the aim of becoming a powerful decision-making tool for
clinicians, SIBILA has been developed. SIBILA is a novel software tool that
leverages interpretable machine learning to make accurate predictions and
explain how models made those decisions. SIBILA can be run on high-performance
computing platforms, drastically reducing computing times.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.13663v3,2022-07-05T15:49:29Z,2022-04-28T17:25:57Z,"ADVISER: AI-Driven Vaccination Intervention Optimiser for Increasing
  Vaccine Uptake in Nigeria","More than 5 million children under five years die from largely preventable or
treatable medical conditions every year, with an overwhelmingly large
proportion of deaths occurring in under-developed countries with low
vaccination uptake. One of the United Nations' sustainable development goals
(SDG 3) aims to end preventable deaths of newborns and children under five
years of age. We focus on Nigeria, where the rate of infant mortality is
appalling. We collaborate with HelpMum, a large non-profit organization in
Nigeria to design and optimize the allocation of heterogeneous health
interventions under uncertainty to increase vaccination uptake, the first such
collaboration in Nigeria. Our framework, ADVISER: AI-Driven Vaccination
Intervention Optimiser, is based on an integer linear program that seeks to
maximize the cumulative probability of successful vaccination. Our optimization
formulation is intractable in practice. We present a heuristic approach that
enables us to solve the problem for real-world use-cases. We also present
theoretical bounds for the heuristic method. Finally, we show that the proposed
approach outperforms baseline methods in terms of vaccination uptake through
experimental evaluation. HelpMum is currently planning a pilot program based on
our approach to be deployed in the largest city of Nigeria, which would be the
first deployment of an AI-driven vaccination uptake program in the country and
hopefully, pave the way for other data-driven programs to improve health
outcomes in Nigeria.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.12380v1,2022-04-26T15:25:55Z,2022-04-26T15:25:55Z,"Multi-task Learning for Concurrent Prediction of Thermal Comfort,
  Sensation, and Preference","Indoor thermal comfort immensely impacts the health and performance of
occupants. Therefore, researchers and engineers have proposed numerous
computational models to estimate thermal comfort (TC). Given the impetus toward
energy efficiency, the current focus is on data-driven TC prediction solutions
that leverage state-of-the-art machine learning (ML) algorithms. However, an
indoor occupant's perception of indoor thermal comfort (TC) is subjective and
multi-dimensional. Different aspects of TC are represented by various standard
metrics/scales viz., thermal sensation (TSV), thermal comfort (TCV), and
thermal preference (TPV). The current ML-based TC prediction solutions adopt
the Single-task Learning approach, i.e., one prediction model per metric.
Consequently, solutions often focus on only one TC metric. Moreover, when
several metrics are considered, multiple TC models for a single indoor space
lead to conflicting predictions, making real-world deployment infeasible. This
work addresses these problems. With the vision toward energy conservation and
real-world application, naturally ventilated primary school classrooms are
considered. First, month-long field experiments are conducted in 5 schools and
14 classrooms, including 512 unique student participants. Further,
""DeepComfort,"" a Multi-task Learning inspired deep-learning model is proposed.
DeepComfort predicts multiple TC output metrics viz., TSV, TPV, and TCV,
simultaneously, through a single model. It demonstrates high F1-scores,
Accuracy (>90%), and generalization capability when validated on the ASHRAE-II
database and the dataset created in this study. DeepComfort is also shown to
outperform 6 popular metric-specific single-task machine learning algorithms.
To the best of our knowledge, this work is the first application of Multi-task
Learning to thermal comfort prediction in classrooms.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.06701v1,2022-04-14T01:57:46Z,2022-04-14T01:57:46Z,"LSTM-Autoencoder based Anomaly Detection for Indoor Air Quality Time
  Series Data","Anomaly detection for indoor air quality (IAQ) data has become an important
area of research as the quality of air is closely related to human health and
well-being. However, traditional statistics and shallow machine learning-based
approaches in anomaly detection in the IAQ area could not detect anomalies
involving the observation of correlations across several data points (i.e.,
often referred to as long-term dependences). We propose a hybrid deep learning
model that combines LSTM with Autoencoder for anomaly detection tasks in IAQ to
address this issue. In our approach, the LSTM network is comprised of multiple
LSTM cells that work with each other to learn the long-term dependences of the
data in a time-series sequence. Autoencoder identifies the optimal threshold
based on the reconstruction loss rates evaluated on every data across all
time-series sequences. Our experimental results, based on the Dunedin CO2
time-series dataset obtained through a real-world deployment of the schools in
New Zealand, demonstrate a very high and robust accuracy rate (99.50%) that
outperforms other similar models.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.13989v1,2022-04-13T21:14:58Z,2022-04-13T21:14:58Z,"Dynamic Diagnosis of the Progress and Shortcomings of Student Learning
  using Machine Learning based on Cognitive, Social, and Emotional Features","Student diversity, like academic background, learning styles, career and life
goals, ethnicity, age, social and emotional characteristics, course load and
work schedule, offers unique opportunities in education, like learning new
skills, peer mentoring and example setting. But student diversity can be
challenging too as it adds variability in the way in which students learn and
progress over time. A single teaching approach is likely to be ineffective and
result in students not meeting their potential. Automated support could address
limitations of traditional teaching by continuously assessing student learning
and implementing needed interventions. This paper discusses a novel methodology
based on data analytics and Machine Learning to measure and causally diagnose
the progress and shortcomings of student learning, and then utilizes the
insight gained on individuals to optimize learning. Diagnosis pertains to
dynamic diagnostic formative assessment, which aims to uncover the causes of
learning shortcomings. The methodology groups learning difficulties into four
categories: recall from memory, concept adjustment, concept modification, and
problem decomposition into sub-goals (sub-problems) and concept combination.
Data models are predicting the occurrence of each of the four challenge types,
as well as a student's learning trajectory. The models can be used to
automatically create real-time, student-specific interventions (e.g., learning
cues) to address less understood concepts. We envision that the system will
enable new adaptive pedagogical approaches to unleash student learning
potential through customization of the course material to the background,
abilities, situation, and progress of each student; and leveraging
diversity-related learning experiences.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.08462v1,2022-04-13T18:47:04Z,2022-04-13T18:47:04Z,"CapillaryX: A Software Design Pattern for Analyzing Medical Images in
  Real-time using Deep Learning","Recent advances in digital imaging, e.g., increased number of pixels
captured, have meant that the volume of data to be processed and analyzed from
these images has also increased. Deep learning algorithms are state-of-the-art
for analyzing such images, given their high accuracy when trained with a large
data volume of data. Nevertheless, such analysis requires considerable
computational power, making such algorithms time- and resource-demanding. Such
high demands can be met by using third-party cloud service providers. However,
analyzing medical images using such services raises several legal and privacy
challenges and does not necessarily provide real-time results. This paper
provides a computing architecture that locally and in parallel can analyze
medical images in real-time using deep learning thus avoiding the legal and
privacy challenges stemming from uploading data to a third-party cloud
provider. To make local image processing efficient on modern multi-core
processors, we utilize parallel execution to offset the resource-intensive
demands of deep neural networks. We focus on a specific medical-industrial case
study, namely the quantifying of blood vessels in microcirculation images for
which we have developed a working system. It is currently used in an
industrial, clinical research setting as part of an e-health application. Our
results show that our system is approximately 78% faster than its serial system
counterpart and 12% faster than a master-slave parallel system architecture.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.06362v1,2022-04-13T13:16:21Z,2022-04-13T13:16:21Z,"A Review of Machine Learning Methods Applied to Structural Dynamics and
  Vibroacoustic","The use of Machine Learning (ML) has rapidly spread across several fields,
having encountered many applications in Structural Dynamics and Vibroacoustic
(SD\&V). The increasing capabilities of ML to unveil insights from data, driven
by unprecedented data availability, algorithms advances and computational
power, enhance decision making, uncertainty handling, patterns recognition and
real-time assessments. Three main applications in SD\&V have taken advantage of
these benefits. In Structural Health Monitoring, ML detection and prognosis
lead to safe operation and optimized maintenance schedules. System
identification and control design are leveraged by ML techniques in Active
Noise Control and Active Vibration Control. Finally, the so-called ML-based
surrogate models provide fast alternatives to costly simulations, enabling
robust and optimized product design. Despite the many works in the area, they
have not been reviewed and analyzed. Therefore, to keep track and understand
this ongoing integration of fields, this paper presents a survey of ML
applications in SD\&V analyses, shedding light on the current state of
implementation and emerging opportunities. The main methodologies, advantages,
limitations, and recommendations based on scientific knowledge were identified
for each of the three applications. Moreover, the paper considers the role of
Digital Twins and Physics Guided ML to overcome current challenges and power
future research progress. As a result, the survey provides a broad overview of
the present landscape of ML applied in SD\&V and guides the reader to an
advanced understanding of progress and prospects in the field.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.07038v1,2022-04-13T02:29:58Z,2022-04-13T02:29:58Z,"OMAD: On-device Mental Anomaly Detection for Substance and Non-Substance
  Users","Stay at home order during the COVID-19 helps flatten the curve but
ironically, instigate mental health problems among the people who have
Substance Use Disorders. Measuring the electrical activity signals in brain
using off-the-shelf consumer wearable devices such as smart wristwatch and
mapping them in real time to underlying mood, behavioral and emotional changes
play striking roles in postulating mental health anomalies. In this work, we
propose to implement a wearable, {\it On-device Mental Anomaly Detection
(OMAD)} system to detect anomalous behaviors and activities that render to
mental health problems and help clinicians to design effective intervention
strategies. We propose an intrinsic artifact removal model on
Electroencephalogram (EEG) signal to better correlate the fine-grained
behavioral changes. We design model compression technique on the artifact
removal and activity recognition (main) modules. We implement a magnitude-based
weight pruning technique both on convolutional neural network and Multilayer
Perceptron to employ the inference phase on Nvidia Jetson Nano; one of the
tightest resource-constrained devices for wearables. We experimented with three
different combinations of feature extractions and artifact removal approaches.
We evaluate the performance of {\it OMAD} in terms of accuracy, F1 score,
memory usage and running time for both unpruned and compressed models using EEG
data from both control and treatment (alcoholic) groups for different object
recognition tasks. Our artifact removal model and main activity detection model
achieved about $\approx$ 93\% and 90\% accuracy, respectively with significant
reduction in model size (70\%) and inference time (31\%).",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.05027v1,2022-04-11T11:55:06Z,2022-04-11T11:55:06Z,"Exploring the Pareto front of multi-objective COVID-19 mitigation
  policies using reinforcement learning","Infectious disease outbreaks can have a disruptive impact on public health
and societal processes. As decision making in the context of epidemic
mitigation is hard, reinforcement learning provides a methodology to
automatically learn prevention strategies in combination with complex epidemic
models. Current research focuses on optimizing policies w.r.t. a single
objective, such as the pathogen's attack rate. However, as the mitigation of
epidemics involves distinct, and possibly conflicting criteria (i.a.,
prevalence, mortality, morbidity, cost), a multi-objective approach is
warranted to learn balanced policies. To lift this decision-making process to
real-world epidemic models, we apply deep multi-objective reinforcement
learning and build upon a state-of-the-art algorithm, Pareto Conditioned
Networks (PCN), to learn a set of solutions that approximates the Pareto front
of the decision problem. We consider the first wave of the Belgian COVID-19
epidemic, which was mitigated by a lockdown, and study different deconfinement
strategies, aiming to minimize both COVID-19 cases (i.e., infections and
hospitalizations) and the societal burden that is induced by the applied
mitigation measures. We contribute a multi-objective Markov decision process
that encapsulates the stochastic compartment model that was used to inform
policy makers during the COVID-19 epidemic. As these social mitigation measures
are implemented in a continuous action space that modulates the contact matrix
of the age-structured epidemic model, we extend PCN to this setting. We
evaluate the solution returned by PCN, and observe that it correctly learns to
reduce the social burden whenever the hospitalization rates are sufficiently
low. In this work, we thus show that multi-objective reinforcement learning is
attainable in complex epidemiological models and provides essential insights to
balance complex mitigation policies.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.03323v1,2022-04-07T09:41:09Z,2022-04-07T09:41:09Z,"Multi-Sample $$-mixup: Richer, More Realistic Synthetic Samples
  from a $p$-Series Interpolant","Modern deep learning training procedures rely on model regularization
techniques such as data augmentation methods, which generate training samples
that increase the diversity of data and richness of label information. A
popular recent method, mixup, uses convex combinations of pairs of original
samples to generate new samples. However, as we show in our experiments, mixup
can produce undesirable synthetic samples, where the data is sampled off the
manifold and can contain incorrect labels. We propose $\zeta$-mixup, a
generalization of mixup with provably and demonstrably desirable properties
that allows convex combinations of $N \geq 2$ samples, leading to more
realistic and diverse outputs that incorporate information from $N$ original
samples by using a $p$-series interpolant. We show that, compared to mixup,
$\zeta$-mixup better preserves the intrinsic dimensionality of the original
datasets, which is a desirable property for training generalizable models.
Furthermore, we show that our implementation of $\zeta$-mixup is faster than
mixup, and extensive evaluation on controlled synthetic and 24 real-world
natural and medical image classification datasets shows that $\zeta$-mixup
outperforms mixup and traditional data augmentation techniques.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.02687v1,2022-04-06T09:23:12Z,2022-04-06T09:23:12Z,Learning to Adapt Clinical Sequences with Residual Mixture of Experts,"Clinical event sequences in Electronic Health Records (EHRs) record detailed
information about the patient condition and patient care as they occur in time.
Recent years have witnessed increased interest of machine learning community in
developing machine learning models solving different types of problems defined
upon information in EHRs. More recently, neural sequential models, such as RNN
and LSTM, became popular and widely applied models for representing patient
sequence data and for predicting future events or outcomes based on such data.
However, a single neural sequential model may not properly represent complex
dynamics of all patients and the differences in their behaviors. In this work,
we aim to alleviate this limitation by refining a one-fits-all model using a
Mixture-of-Experts (MoE) architecture. The architecture consists of multiple
(expert) RNN models covering patient sub-populations and refining the
predictions of the base model. That is, instead of training expert RNN models
from scratch we define them on the residual signal that attempts to model the
differences from the population-wide model. The heterogeneity of various
patient sequences is modeled through multiple experts that consist of RNN.
Particularly, instead of directly training MoE from scratch, we augment MoE
based on the prediction signal from pretrained base GRU model. With this way,
the mixture of experts can provide flexible adaptation to the (limited)
predictive power of the single base RNN model. We experiment with the newly
proposed model on real-world EHRs data and the multivariate clinical event
prediction task. We implement RNN using Gated Recurrent Units (GRU). We show
4.1% gain on AUPRC statistics compared to a single RNN prediction.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.01379v3,2022-04-11T12:46:57Z,2022-04-04T10:52:20Z,"Taking ROCKET on an Efficiency Mission: Multivariate Time Series
  Classification with LightWaveS","Nowadays, with the rising number of sensors in sectors such as healthcare and
industry, the problem of multivariate time series classification (MTSC) is
getting increasingly relevant and is a prime target for machine and deep
learning approaches. Their expanding adoption in real-world environments is
causing a shift in focus from the pursuit of ever-higher prediction accuracy
with complex models towards practical, deployable solutions that balance
accuracy and parameters such as prediction speed. An MTSC model that has
attracted attention recently is ROCKET, based on random convolutional kernels,
both because of its very fast training process and its state-of-the-art
accuracy. However, the large number of features it utilizes may be detrimental
to inference time. Examining its theoretical background and limitations enables
us to address potential drawbacks and present LightWaveS: a framework for
accurate MTSC, which is fast both during training and inference. Specifically,
utilizing wavelet scattering transformation and distributed feature selection,
we manage to create a solution that employs just 2.5% of the ROCKET features,
while achieving accuracy comparable to recent MTSC models. LightWaveS also
scales well across multiple compute nodes and with the number of input channels
during training. In addition, it can significantly reduce the input size and
provide insight to an MTSC problem by keeping only the most useful channels. We
present three versions of our algorithm and their results on distributed
training time and scalability, accuracy, and inference speedup. We show that we
achieve speedup ranging from 9x to 53x compared to ROCKET during inference on
an edge device, on datasets with comparable accuracy.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.17081v1,2022-03-31T14:54:35Z,2022-03-31T14:54:35Z,Interpretation of Black Box NLP Models: A Survey,"An increasing number of machine learning models have been deployed in domains
with high stakes such as finance and healthcare. Despite their superior
performances, many models are black boxes in nature which are hard to explain.
There are growing efforts for researchers to develop methods to interpret these
black-box models. Post hoc explanations based on perturbations, such as LIME,
are widely used approaches to interpret a machine learning model after it has
been built. This class of methods has been shown to exhibit large instability,
posing serious challenges to the effectiveness of the method itself and harming
user trust. In this paper, we propose S-LIME, which utilizes a hypothesis
testing framework based on central limit theorem for determining the number of
perturbation points needed to guarantee stability of the resulting explanation.
Experiments on both simulated and real world data sets are provided to
demonstrate the effectiveness of our method.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.15275v2,2022-04-15T23:17:54Z,2022-03-29T06:43:30Z,"A Multi-size Kernel based Adaptive Convolutional Neural Network for
  Bearing Fault Diagnosis","Bearing fault identification and analysis is an important research area in
the field of machinery fault diagnosis. Aiming at the common faults of rolling
bearings, we propose a data-driven diagnostic algorithm based on the
characteristics of bearing vibrations called multi-size kernel based adaptive
convolutional neural network (MSKACNN). Using raw bearing vibration signals as
the inputs, MSKACNN provides vibration feature learning and signal
classification capabilities to identify and analyze bearing faults. Ball mixing
is a ball bearing production quality problem that is difficult to identify
using traditional frequency domain analysis methods since it requires high
frequency resolutions of the measurement signals and results in a long
analyzing time. The proposed MSKACNN is shown to improve the efficiency and
accuracy of ball mixing diagnosis. To further demonstrate the effectiveness of
MSKACNN in bearing fault identification, a bearing vibration data acquisition
system was developed, and vibration signal acquisition was performed on rolling
bearings under five different fault conditions including ball mixing. The
resulting datasets were used to analyze the performance of our proposed model.
To validate the adaptive ability of MSKACNN, fault test data from the Case
Western Reserve University Bearing Data Center were also used. Test results
show that MSKACNN can identify the different bearing conditions with high
accuracy with high generalization ability. We presented an implementation of
the MSKACNN as a lightweight module for a real-time bearing fault diagnosis
system that is suitable for production.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.14031v1,2022-03-26T09:21:56Z,2022-03-26T09:21:56Z,"Medicinal Boxes Recognition on a Deep Transfer Learning Augmented
  Reality Mobile Application","Taking medicines is a fundamental aspect to cure illnesses. However, studies
have shown that it can be hard for patients to remember the correct posology.
More aggravating, a wrong dosage generally causes the disease to worsen.
Although, all relevant instructions for a medicine are summarized in the
corresponding patient information leaflet, the latter is generally difficult to
navigate and understand. To address this problem and help patients with their
medication, in this paper we introduce an augmented reality mobile application
that can present to the user important details on the framed medicine. In
particular, the app implements an inference engine based on a deep neural
network, i.e., a densenet, fine-tuned to recognize a medicinal from its
package. Subsequently, relevant information, such as posology or a simplified
leaflet, is overlaid on the camera feed to help a patient when taking a
medicine. Extensive experiments to select the best hyperparameters were
performed on a dataset specifically collected to address this task; ultimately
obtaining up to 91.30\% accuracy as well as real-time capabilities.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.12621v1,2022-03-23T10:35:06Z,2022-03-23T10:35:06Z,"MR Image Denoising and Super-Resolution Using Regularized Reverse
  Diffusion","Patient scans from MRI often suffer from noise, which hampers the diagnostic
capability of such images. As a method to mitigate such artifact, denoising is
largely studied both within the medical imaging community and beyond the
community as a general subject. However, recent deep neural network-based
approaches mostly rely on the minimum mean squared error (MMSE) estimates,
which tend to produce a blurred output. Moreover, such models suffer when
deployed in real-world sitautions: out-of-distribution data, and complex noise
distributions that deviate from the usual parametric noise models. In this
work, we propose a new denoising method based on score-based reverse diffusion
sampling, which overcomes all the aforementioned drawbacks. Our network,
trained only with coronal knee scans, excels even on out-of-distribution in
vivo liver MRI data, contaminated with complex mixture of noise. Even more, we
propose a method to enhance the resolution of the denoised image with the same
network. With extensive experiments, we show that our method establishes
state-of-the-art performance, while having desirable properties which prior
MMSE denoisers did not have: flexibly choosing the extent of denoising, and
quantifying uncertainty.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.11092v1,2022-03-21T16:17:38Z,2022-03-21T16:17:38Z,"Automated Clinical Coding: What, Why, and Where We Are?","Clinical coding is the task of transforming medical information in a
patient's health records into structured codes so that they can be used for
statistical analysis. This is a cognitive and time-consuming task that follows
a standard process in order to achieve a high level of consistency. Clinical
coding could potentially be supported by an automated system to improve the
efficiency and accuracy of the process. We introduce the idea of automated
clinical coding and summarise its challenges from the perspective of Artificial
Intelligence (AI) and Natural Language Processing (NLP), based on the
literature, our project experience over the past two and half years (late 2019
- early 2022), and discussions with clinical coding experts in Scotland and the
UK. Our research reveals the gaps between the current deep learning-based
approach applied to clinical coding and the need for explainability and
consistency in real-world practice. Knowledge-based methods that represent and
reason the standard, explainable process of a task may need to be incorporated
into deep learning-based methods for clinical coding. Automated clinical coding
is a promising task for AI, despite the technical and organisational
challenges. Coders are needed to be involved in the development process. There
is much to achieve to develop and deploy an AI-based automated system to
support coding in the next five years and beyond.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.06498v8,2022-06-02T16:26:22Z,2022-03-12T18:26:24Z,"The worst of both worlds: A comparative analysis of errors in learning
  from data in psychology and machine learning","Recent arguments that machine learning (ML) is facing a reproducibility and
replication crisis suggest that some published claims in ML research cannot be
taken at face value. These concerns inspire analogies to the replication crisis
affecting the social and medical sciences. They also inspire calls for the
integration of statistical approaches to causal inference and predictive
modeling. A deeper understanding of what reproducibility concerns in supervised
ML research have in common with the replication crisis in experimental science
puts the new concerns in perspective, and helps researchers avoid ""the worst of
both worlds,"" where ML researchers begin borrowing methodologies from
explanatory modeling without understanding their limitations and vice versa. We
contribute a comparative analysis of concerns about inductive learning that
arise in causal attribution as exemplified in psychology versus predictive
modeling as exemplified in ML. We identify themes that re-occur in reform
discussions, like overreliance on asymptotic theory and non-credible beliefs
about real-world data generating processes. We argue that in both fields,
claims from learning are implied to generalize outside the specific environment
studied (e.g., the input dataset or subject sample, modeling implementation,
etc.) but are often impossible to refute due to undisclosed sources of variance
in the learning pipeline. In particular, errors being acknowledged in ML expose
cracks in long-held beliefs that optimizing predictive accuracy using huge
datasets absolves one from having to consider a true data generating process or
formally represent uncertainty in performance claims. We conclude by discussing
risks that arise when sources of errors are misdiagnosed and the need to
acknowledge the role of human inductive biases in learning and reform.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.05574v1,2022-03-10T18:51:29Z,2022-03-10T18:51:29Z,On-the-Fly Test-time Adaptation for Medical Image Segmentation,"One major problem in deep learning-based solutions for medical imaging is the
drop in performance when a model is tested on a data distribution different
from the one that it is trained on. Adapting the source model to target data
distribution at test-time is an efficient solution for the data-shift problem.
Previous methods solve this by adapting the model to target distribution by
using techniques like entropy minimization or regularization. In these methods,
the models are still updated by back-propagation using an unsupervised loss on
complete test data distribution. In real-world clinical settings, it makes more
sense to adapt a model to a new test image on-the-fly and avoid model update
during inference due to privacy concerns and lack of computing resource at
deployment. To this end, we propose a new setting - On-the-Fly Adaptation which
is zero-shot and episodic (i.e., the model is adapted to a single image at a
time and also does not perform any back-propagation during test-time). To
achieve this, we propose a new framework called Adaptive UNet where each
convolutional block is equipped with an adaptive batch normalization layer to
adapt the features with respect to a domain code. The domain code is generated
using a pre-trained encoder trained on a large corpus of medical images. During
test-time, the model takes in just the new test image and generates a domain
code to adapt the features of source model according to the test data. We
validate the performance on both 2D and 3D data distribution shifts where we
get a better performance compared to previous test-time adaptation methods.
Code is available at https://github.com/jeya-maria-jose/On-The-Fly-Adaptation",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.05564v1,2022-03-09T23:22:56Z,2022-03-09T23:22:56Z,"HDL: Hybrid Deep Learning for the Synthesis of Myocardial Velocity Maps
  in Digital Twins for Cardiac Analysis","Synthetic digital twins based on medical data accelerate the acquisition,
labelling and decision making procedure in digital healthcare. A core part of
digital healthcare twins is model-based data synthesis, which permits the
generation of realistic medical signals without requiring to cope with the
modelling complexity of anatomical and biochemical phenomena producing them in
reality. Unfortunately, algorithms for cardiac data synthesis have been so far
scarcely studied in the literature. An important imaging modality in the
cardiac examination is three-directional CINE multi-slice myocardial velocity
mapping (3Dir MVM), which provides a quantitative assessment of cardiac motion
in three orthogonal directions of the left ventricle. The long acquisition time
and complex acquisition produce make it more urgent to produce synthetic
digital twins of this imaging modality. In this study, we propose a hybrid deep
learning (HDL) network, especially for synthetic 3Dir MVM data. Our algorithm
is featured by a hybrid UNet and a Generative Adversarial Network with a
foreground-background generation scheme. The experimental results show that
from temporally down-sampled magnitude CINE images (six times), our proposed
algorithm can still successfully synthesise high temporal resolution 3Dir MVM
CMR data (PSNR=42.32) with precise left ventricle segmentation (DICE=0.92).
These performance scores indicate that our proposed HDL algorithm can be
implemented in real-world digital twins for myocardial velocity mapping data
simulation. To the best of our knowledge, this work is the first one in the
literature investigating digital twins of the 3Dir MVM CMR, which has shown
great potential for improving the efficiency of clinical studies via
synthesised cardiac data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.06245v2,2022-03-17T02:33:13Z,2022-03-08T16:13:41Z,"Predatory Medicine: Exploring and Measuring the Vulnerability of Medical
  AI to Predatory Science","Medical Artificial Intelligence (MedAI) for diagnosis, treatment options, and
drug development represents the new age of healthcare. The security, integrity,
and credibility of MedAI tools are paramount issues because human lives are at
stake. MedAI solutions are often heavily dependent on scientific medical
research literature as a primary data source that draws the attacker's
attention as a potential target. We present a first study of how the output of
MedAI can be polluted with Predatory Publications Presence (PPP). We study two
MedAI systems: mediKanren (disease independent) and CancerMine
(Disease-specific), which use research literature as primary data input from
the research repository PubMed, PubMed derived database SemMedDB, and NIH
translational Knowledge Graphs (KGs). Our study has a three-pronged focus: (1)
identifying the PPP in PubMed; (2) verifying the PPP in SemMedDB and the KGs;
(3) demonstrating the existing vulnerability of PPP traversing to the MedAI
output. Our contribution lies in identifying the existing PPP in the MedAI
inputs and demonstrating how predatory science can jeopardize the credibility
of MedAI solutions, making their real-life deployment questionable.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.02446v1,2022-03-04T17:20:21Z,2022-03-04T17:20:21Z,"AutoMap: Automatic Medical Code Mapping for Clinical Prediction Model
  Deployment","Given a deep learning model trained on data from a source site, how to deploy
the model to a target hospital automatically? How to accommodate heterogeneous
medical coding systems across different hospitals? Standard approaches rely on
existing medical code mapping tools, which have significant practical
limitations.
  To tackle this problem, we propose AutoMap to automatically map the medical
codes across different EHR systems in a coarse-to-fine manner: (1)
Ontology-level Alignment: We leverage the ontology structure to learn a coarse
alignment between the source and target medical coding systems; (2) Code-level
Refinement: We refine the alignment at a fine-grained code level for the
downstream tasks using a teacher-student framework.
  We evaluate AutoMap using several deep learning models with two real-world
EHR datasets: eICU and MIMIC-III. Results show that AutoMap achieves relative
improvements up to 3.9% (AUC-ROC) and 8.7% (AUC-PR) for mortality prediction,
and up to 4.7% (AUC-ROC) and 3.7% (F1) for length-of-stay estimation. Further,
we show that AutoMap can provide accurate mapping across coding systems.
Lastly, we demonstrate that AutoMap can adapt to the two challenging scenarios:
(1) mapping between completely different coding systems and (2) between
completely different hospitals.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.02013v1,2022-03-03T20:52:47Z,2022-03-03T20:52:47Z,"DIME: Fine-grained Interpretations of Multimodal Models via Disentangled
  Local Explanations","The ability for a human to understand an Artificial Intelligence (AI) model's
decision-making process is critical in enabling stakeholders to visualize model
behavior, perform model debugging, promote trust in AI models, and assist in
collaborative human-AI decision-making. As a result, the research fields of
interpretable and explainable AI have gained traction within AI communities as
well as interdisciplinary scientists seeking to apply AI in their subject
areas. In this paper, we focus on advancing the state-of-the-art in
interpreting multimodal models - a class of machine learning methods that
tackle core challenges in representing and capturing interactions between
heterogeneous data sources such as images, text, audio, and time-series data.
Multimodal models have proliferated numerous real-world applications across
healthcare, robotics, multimedia, affective computing, and human-computer
interaction. By performing model disentanglement into unimodal contributions
(UC) and multimodal interactions (MI), our proposed approach, DIME, enables
accurate and fine-grained analysis of multimodal models while maintaining
generality across arbitrary modalities, model architectures, and tasks. Through
a comprehensive suite of experiments on both synthetic and real-world
multimodal tasks, we show that DIME generates accurate disentangled
explanations, helps users of multimodal models gain a deeper understanding of
model behavior, and presents a step towards debugging and improving these
models for real-world deployment. Code for our experiments can be found at
https://github.com/lvyiwei1/DIME.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.01707v1,2022-03-03T13:30:28Z,2022-03-03T13:30:28Z,Reinforcement Learning in Possibly Nonstationary Environments,"We consider reinforcement learning (RL) methods in offline nonstationary
environments. Many existing RL algorithms in the literature rely on the
stationarity assumption that requires the system transition and the reward
function to be constant over time. However, the stationarity assumption is
restrictive in practice and is likely to be violated in a number of
applications, including traffic signal control, robotics and mobile health. In
this paper, we develop a consistent procedure to test the nonstationarity of
the optimal policy based on pre-collected historical data, without additional
online data collection. Based on the proposed test, we further develop a
sequential change point detection method that can be naturally coupled with
existing state-of-the-art RL methods for policy optimisation in nonstationary
environments. The usefulness of our method is illustrated by theoretical
results, simulation studies, and a real data example from the 2018 Intern
Health Study. A Python implementation of the proposed procedure is available at
https://github.com/limengbinggz/CUSUM-RL",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.12943v1,2022-02-27T14:26:41Z,2022-02-27T14:26:41Z,"Arrhythmia Classifier Using Convolutional Neural Network with Adaptive
  Loss-aware Multi-bit Networks Quantization","Cardiovascular disease (CVDs) is one of the universal deadly diseases, and
the detection of it in the early stage is a challenging task to tackle.
Recently, deep learning and convolutional neural networks have been employed
widely for the classification of objects. Moreover, it is promising that lots
of networks can be deployed on wearable devices. An increasing number of
methods can be used to realize ECG signal classification for the sake of
arrhythmia detection. However, the existing neural networks proposed for
arrhythmia detection are not hardware-friendly enough due to a remarkable
quantity of parameters resulting in memory and power consumption.
  In this paper, we present a 1-D adaptive loss-aware quantization, achieving a
high compression rate that reduces memory consumption by 23.36 times. In order
to adapt to our compression method, we need a smaller and simpler network. We
propose a 17 layer end-to-end neural network classifier to classify 17
different rhythm classes trained on the MIT-BIH dataset, realizing a
classification accuracy of 93.5%, which is higher than most existing methods.
Due to the adaptive bitwidth method making important layers get more attention
and offered a chance to prune useless parameters, the proposed quantization
method avoids accuracy degradation. It even improves the accuracy rate, which
is 95.84%, 2.34% higher than before. Our study achieves a 1-D convolutional
neural network with high performance and low resources consumption, which is
hardware-friendly and illustrates the possibility of deployment on wearable
devices to realize a real-time arrhythmia diagnosis.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.00512v1,2022-02-26T01:13:32Z,2022-02-26T01:13:32Z,"A Deep Bayesian Neural Network for Cardiac Arrhythmia Classification
  with Rejection from ECG Recordings","With the development of deep learning-based methods, automated classification
of electrocardiograms (ECGs) has recently gained much attention. Although the
effectiveness of deep neural networks has been encouraging, the lack of
information given by the outputs restricts clinicians' reexamination. If the
uncertainty estimation comes along with the classification results,
cardiologists can pay more attention to ""uncertain"" cases. Our study aims to
classify ECGs with rejection based on data uncertainty and model uncertainty.
We perform experiments on a real-world 12-lead ECG dataset. First, we estimate
uncertainties using the Monte Carlo dropout for each classification prediction,
based on our Bayesian neural network. Then, we accept predictions with
uncertainty under a given threshold and provide ""uncertain"" cases for
clinicians. Furthermore, we perform a simulation experiment using varying
thresholds. Finally, with the help of a clinician, we conduct case studies to
explain the results of large uncertainties and incorrect predictions with small
uncertainties. The results show that correct predictions are more likely to
have smaller uncertainties, and the performance on accepted predictions
improves as the accepting ratio decreases (i.e. more rejections). Case studies
also help explain why rejection can improve the performance. Our study helps
neural networks produce more accurate results and provide information on
uncertainties to better assist clinicians in the diagnosis process. It can also
enable deep-learning-based ECG interpretation in clinical implementation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.10541v1,2022-02-21T21:41:29Z,2022-02-21T21:41:29Z,"Online Learning for Orchestration of Inference in Multi-User
  End-Edge-Cloud Networks","Deep-learning-based intelligent services have become prevalent in
cyber-physical applications including smart cities and health-care. Deploying
deep-learning-based intelligence near the end-user enhances privacy protection,
responsiveness, and reliability. Resource-constrained end-devices must be
carefully managed in order to meet the latency and energy requirements of
computationally-intensive deep learning services. Collaborative end-edge-cloud
computing for deep learning provides a range of performance and efficiency that
can address application requirements through computation offloading. The
decision to offload computation is a communication-computation co-optimization
problem that varies with both system parameters (e.g., network condition) and
workload characteristics (e.g., inputs). On the other hand, deep learning model
optimization provides another source of tradeoff between latency and model
accuracy. An end-to-end decision-making solution that considers such
computation-communication problem is required to synergistically find the
optimal offloading policy and model for deep learning services. To this end, we
propose a reinforcement-learning-based computation offloading solution that
learns optimal offloading policy considering deep learning model selection
techniques to minimize response time while providing sufficient accuracy. We
demonstrate the effectiveness of our solution for edge devices in an
end-edge-cloud system and evaluate with a real-setup implementation using
multiple AWS and ARM core configurations. Our solution provides 35% speedup in
the average response time compared to the state-of-the-art with less than 0.9%
accuracy reduction, demonstrating the promise of our online learning framework
for orchestrating DL inference in end-edge-cloud systems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.10336v1,2022-02-15T03:34:56Z,2022-02-15T03:34:56Z,Artificial Intelligence for the Metaverse: A Survey,"Along with the massive growth of the Internet from the 1990s until now,
various innovative technologies have been created to bring users breathtaking
experiences with more virtual interactions in cyberspace. Many virtual
environments with thousands of services and applications, from social networks
to virtual gaming worlds, have been developed with immersive experience and
digital transformation, but most are incoherent instead of being integrated
into a platform. In this context, metaverse, a term formed by combining meta
and universe, has been introduced as a shared virtual world that is fueled by
many emerging technologies, such as fifth-generation networks and beyond,
virtual reality, and artificial intelligence (AI). Among such technologies, AI
has shown the great importance of processing big data to enhance immersive
experience and enable human-like intelligence of virtual agents. In this
survey, we make a beneficial effort to explore the role of AI in the foundation
and development of the metaverse. We first deliver a preliminary of AI,
including machine learning algorithms and deep learning architectures, and its
role in the metaverse. We then convey a comprehensive investigation of AI-based
methods concerning six technical aspects that have potentials for the
metaverse: natural language processing, machine vision, blockchain, networking,
digital twin, and neural interface, and being potential for the metaverse.
Subsequently, several AI-aided applications, such as healthcare, manufacturing,
smart cities, and gaming, are studied to be deployed in the virtual worlds.
Finally, we conclude the key contribution of this survey and open some future
research directions in AI for the metaverse.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.04361v2,2022-02-20T04:18:20Z,2022-02-09T09:50:31Z,"Molecular-scale Integration of Multi-modal Sensing and Neuromorphic
  Computing with Organic Electrochemical Transistors","Abstract: Bionic learning with fused sensing, memory and processing functions
outperforms artificial neural networks running on silicon chips in terms of
efficiency and footprint. However, digital hardware implementation of bionic
learning suffers from device heterogeneity in sensors and processing cores,
which incurs large hardware, energy and time overheads. Here, we present a
universal solution to simultaneously perform multi-modal sensing, memory and
processing using organic electrochemical transistors with designed architecture
and tailored channel morphology, selective ion injection into the
crystalline/amorphous regions. The resultant device work as either a volatile
receptor that shows multi-modal sensing, or a non-volatile synapse that
features record-high 10-bit analog states, low switching stochasticity and good
retention without the integration of any extra devices. Homogeneous integration
of such devices enables bionic learning functions such as conditioned reflex
and real-time cardiac disease diagnose via reservoir computing, illustrating
the promise for future smart edge health informatics.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.02559v1,2022-02-05T14:12:01Z,2022-02-05T14:12:01Z,"Digital Twin of Wireless Systems: Overview, Taxonomy, Challenges, and
  Opportunities","Future wireless services must be focused on improving the quality of life by
enabling various applications, such as extended reality, brain-computer
interaction, and healthcare. These applications have diverse performance
requirements (e.g., user-defined quality of experience metrics, latency, and
reliability) that are challenging to be fulfilled by existing wireless systems.
To meet the diverse requirements of the emerging applications, the concept of a
digital twin has been recently proposed. A digital twin uses a virtual
representation along with security-related technologies (e.g., blockchain),
communication technologies (e.g., 6G), computing technologies (e.g., edge
computing), and machine learning, so as to enable the smart applications. In
this tutorial, we present a comprehensive overview on digital twins for
wireless systems. First, we present an overview of fundamental concepts (i.e.,
design aspects, high-level architecture, and frameworks) of digital twin of
wireless systems. Second, a comprehensive taxonomy is devised for both
different aspects. These aspects are twins for wireless and wireless for twins.
For the twins for wireless aspect, we consider parameters, such as twin objects
design, prototyping, deployment trends, physical devices design, interface
design, incentive mechanism, twins isolation, and decoupling. On the other
hand, for wireless for twins, parameters such as, twin objects access aspects,
security and privacy, and air interface design are considered. Finally, open
research challenges and opportunities are presented along with causes and
possible solutions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.01176v1,2022-02-02T18:09:06Z,2022-02-02T18:09:06Z,Epidemic Dreams: Dreaming about health during the COVID-19 pandemic,"The continuity hypothesis of dreams suggests that the content of dreams is
continuous with the dreamer's waking experiences. Given the unprecedented
nature of the experiences during COVID-19, we studied the continuity hypothesis
in the context of the pandemic. We implemented a deep-learning algorithm that
can extract mentions of medical conditions from text and applied it to two
datasets collected during the pandemic: 2,888 dream reports (dreaming life
experiences), and 57M tweets mentioning the pandemic (waking life experiences).
The health expressions common to both sets were typical COVID-19 symptoms
(e.g., cough, fever, and anxiety), suggesting that dreams reflected people's
real-world experiences. The health expressions that distinguished the two sets
reflected differences in thought processes: expressions in waking life
reflected a linear and logical thought process and, as such, described
realistic symptoms or related disorders (e.g., nasal pain, SARS, H1N1); those
in dreaming life reflected a thought process closer to the visual and emotional
spheres and, as such, described either conditions unrelated to the virus (e.g.,
maggots, deformities, snakebites), or conditions of surreal nature (e.g., teeth
falling out, body crumbling into sand). Our results confirm that dream reports
represent an understudied yet valuable source of people's health experiences in
the real world.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.01034v1,2022-02-02T13:59:23Z,2022-02-02T13:59:23Z,"Maintaining fairness across distribution shift: do we have viable
  solutions for real-world applications?","Fairness and robustness are often considered as orthogonal dimensions when
evaluating machine learning models. However, recent work has revealed
interactions between fairness and robustness, showing that fairness properties
are not necessarily maintained under distribution shift. In healthcare
settings, this can result in e.g. a model that performs fairly according to a
selected metric in ""hospital A"" showing unfairness when deployed in ""hospital
B"". While a nascent field has emerged to develop provable fair and robust
models, it typically relies on strong assumptions about the shift, limiting its
impact for real-world applications. In this work, we explore the settings in
which recently proposed mitigation strategies are applicable by referring to a
causal framing. Using examples of predictive models in dermatology and
electronic health records, we show that real-world applications are complex and
often invalidate the assumptions of such methods. Our work hence highlights
technical, practical, and engineering gaps that prevent the development of
robustly fair machine learning models for real-world applications. Finally, we
discuss potential remedies at each step of the machine learning pipeline.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.07711v1,2022-01-19T16:51:18Z,2022-01-19T16:51:18Z,Enhancing the Security & Privacy of Wearable Brain-Computer Interfaces,"Brain computing interfaces (BCI) are used in a plethora of
safety/privacy-critical applications, ranging from healthcare to smart
communication and control. Wearable BCI setups typically involve a head-mounted
sensor connected to a mobile device, combined with ML-based data processing.
Consequently, they are susceptible to a multiplicity of attacks across the
hardware, software, and networking stacks used that can leak users' brainwave
data or at worst relinquish control of BCI-assisted devices to remote
attackers. In this paper, we: (i) analyse the whole-system security and privacy
threats to existing wearable BCI products from an operating system and
adversarial machine learning perspective; and (ii) introduce Argus, the first
information flow control system for wearable BCI applications that mitigates
these attacks. Argus' domain-specific design leads to a lightweight
implementation on Linux ARM platforms suitable for existing BCI use-cases. Our
proof of concept attacks on real-world BCI devices (Muse, NeuroSky, and
OpenBCI) led us to discover more than 300 vulnerabilities across the stacks of
six major attack vectors. Our evaluation shows Argus is highly effective in
tracking sensitive dataflows and restricting these attacks with an acceptable
memory and performance overhead (<15%).",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.07888v1,2022-01-16T23:49:20Z,2022-01-16T23:49:20Z,"Adaptive Energy Management for Self-Sustainable Wearables in Mobile
  Health","Wearable devices that integrate multiple sensors, processors, and
communication technologies have the potential to transform mobile health for
remote monitoring of health parameters. However, the small form factor of the
wearable devices limits the battery size and operating lifetime. As a result,
the devices require frequent recharging, which has limited their widespread
adoption. Energy harvesting has emerged as an effective method towards
sustainable operation of wearable devices. Unfortunately, energy harvesting
alone is not sufficient to fulfill the energy requirements of wearable devices.
This paper studies the novel problem of adaptive energy management towards the
goal of self-sustainable wearables by using harvested energy to supplement the
battery energy and to reduce manual recharging by users. To solve this problem,
we propose a principled algorithm referred as AdaEM. There are two key ideas
behind AdaEM. First, it uses machine learning (ML) methods to learn predictive
models of user activity and energy usage patterns. These models allow us to
estimate the potential of energy harvesting in a day as a function of the user
activities. Second, it reasons about the uncertainty in predictions and
estimations from the ML models to optimize the energy management decisions
using a dynamic robust optimization (DyRO) formulation. We propose a
light-weight solution for DyRO to meet the practical needs of deployment. We
validate the AdaEM approach on a wearable device prototype consisting of solar
and motion energy harvesting using real-world data of user activities.
Experiments show that AdaEM achieves solutions that are within 5% of the
optimal with less than 0.005% execution time and energy overhead.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.05115v1,2022-01-13T18:20:32Z,2022-01-13T18:20:32Z,Functional Anomaly Detection: a Benchmark Study,"The increasing automation in many areas of the Industry expressly demands to
design efficient machine-learning solutions for the detection of abnormal
events. With the ubiquitous deployment of sensors monitoring nearly
continuously the health of complex infrastructures, anomaly detection can now
rely on measurements sampled at a very high frequency, providing a very rich
representation of the phenomenon under surveillance. In order to exploit fully
the information thus collected, the observations cannot be treated as
multivariate data anymore and a functional analysis approach is required. It is
the purpose of this paper to investigate the performance of recent techniques
for anomaly detection in the functional setup on real datasets. After an
overview of the state-of-the-art and a visual-descriptive study, a variety of
anomaly detection methods are compared. While taxonomies of abnormalities (e.g.
shape, location) in the functional setup are documented in the literature,
assigning a specific type to the identified anomalies appears to be a
challenging task. Thus, strengths and weaknesses of the existing approaches are
benchmarked in view of these highlighted types in a simulation study. Anomaly
detection methods are next evaluated on two datasets, related to the monitoring
of helicopters in flight and to the spectrometry of construction materials
namely. The benchmark analysis is concluded by recommendation guidance for
practitioners.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.04967v2,2022-05-13T21:27:21Z,2022-01-11T13:55:57Z,"Adherence Forecasting for Guided Internet-Delivered Cognitive Behavioral
  Therapy: A Minimally Data-Sensitive Approach","Internet-delivered psychological treatments (IDPT) are seen as an effective
and scalable pathway to improving the accessibility of mental healthcare.
Within this context, treatment adherence is an especially pertinent challenge
to address due to the reduced interaction between healthcare professionals and
patients, compared to more traditional interventions. In parallel, there are
increasing regulations when using peoples' personal data, especially in the
digital sphere. In such regulations, data minimization is often a core tenant
such as within the General Data Protection Regulation (GDPR). Consequently,
this work proposes a Self-Attention-based deep learning approach to perform
automatic adherence forecasting, while only relying on minimally sensitive
login/logout-timestamp data. This approach was tested on a dataset containing
342 patients undergoing Guided Internet-delivered Cognitive Behavioral Therapy
(G-ICBT) treatment. Of these 342 patients, 101 (~30%) were considered as
non-adherent (dropout) based on the adherence definition used in this work. The
proposed Self-Attention Network achieved over 70% average balanced accuracy,
after only 20 out of the 56 days (~1/3) of the treatment had elapsed. This
study demonstrates that automatic adherence forecasting for G-ICBT, is
achievable using only minimally sensitive data, thus facilitating the
implementation of such tools within real-world IDPT platforms.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.01943v1,2022-01-06T07:14:02Z,2022-01-06T07:14:02Z,"Machine Learning: Algorithms, Models, and Applications","Recent times are witnessing rapid development in machine learning algorithm
systems, especially in reinforcement learning, natural language processing,
computer and robot vision, image processing, speech, and emotional processing
and understanding. In tune with the increasing importance and relevance of
machine learning models, algorithms, and their applications, and with the
emergence of more innovative uses cases of deep learning and artificial
intelligence, the current volume presents a few innovative research works and
their applications in real world, such as stock trading, medical and healthcare
systems, and software automation. The chapters in the book illustrate how
machine learning and deep learning algorithms and models are designed,
optimized, and deployed. The volume will be useful for advanced graduate and
doctoral students, researchers, faculty members of universities, practicing
data scientists and data engineers, professionals, and consultants working on
the broad areas of machine learning, deep learning, and artificial
intelligence.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.15031v2,2022-07-04T09:07:46Z,2021-12-30T12:32:33Z,"Development of a face mask detection pipeline for mask-wearing
  monitoring in the era of the COVID-19 pandemic: A modular approach","During the SARS-Cov-2 pandemic, mask-wearing became an effective tool to
prevent spreading and contracting the virus. The ability to monitor the
mask-wearing rate in the population would be useful for determining public
health strategies against the virus. However, artificial intelligence
technologies for detecting face masks have not been deployed at a large scale
in real-life to measure the mask-wearing rate in public. In this paper, we
present a two-step face mask detection approach consisting of two separate
modules: 1) face detection and alignment and 2) face mask classification. This
approach allowed us to experiment with different combinations of face detection
and face mask classification modules. More specifically, we experimented with
PyramidKey and RetinaFace as face detectors while maintaining a lightweight
backbone for the face mask classification module. Moreover, we also provide a
relabeled annotation of the test set of the AIZOO dataset, where we rectified
the incorrect labels for some face images. The evaluation results on the AIZOO
and Moxa 3K datasets showed that the proposed face mask detection pipeline
surpassed the state-of-the-art methods. The proposed pipeline also yielded a
higher mAP on the relabeled test set of the AIZOO dataset than the original
test set. Since we trained the proposed model using in-the-wild face images, we
can successfully deploy our model to monitor the mask-wearing rate using public
CCTV images.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.13338v1,2021-12-26T09:25:32Z,2021-12-26T09:25:32Z,MPCLeague: Robust MPC Platform for Privacy-Preserving Machine Learning,"In the modern era of computing, machine learning tools have demonstrated
their potential in vital sectors, such as healthcare and finance, to derive
proper inferences. The sensitive and confidential nature of the data in such
sectors raises genuine concerns for data privacy. This motivated the area of
Privacy-preserving Machine Learning (PPML), where privacy of data is
guaranteed. In this thesis, we design an efficient platform, MPCLeague, for
PPML in the Secure Outsourced Computation (SOC) setting using Secure
Multi-party Computation (MPC) techniques.
  MPC, the holy-grail problem of secure distributed computing, enables a set of
n mutually distrusting parties to perform joint computation on their private
inputs in a way that no coalition of t parties can learn more information than
the output (privacy) or affect the true output of the computation
(correctness). While MPC, in general, has been a subject of extensive research,
the area of MPC with a small number of parties has drawn popularity of late
mainly due to its application to real-time scenarios, efficiency and
simplicity. This thesis focuses on designing efficient MPC frameworks for 2, 3
and 4 parties, with at most one corruption and supports ring structures.
  At the heart of this thesis are four frameworks - ASTRA, SWIFT, Tetrad,
ABY2.0 - catered to different settings. The practicality of our framework is
argued through improvements in the benchmarking of widely used ML algorithms --
Linear Regression, Logistic Regression, Neural Networks, and Support Vector
Machines. We propose two variants for each of our frameworks, with one variant
aiming to minimise the execution time while the other focuses on the monetary
cost. The concrete efficiency gains of our frameworks coupled with the stronger
security guarantee of robustness make our platform an ideal choice for a
real-time deployment of PPML techniques.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.13058v1,2021-12-24T13:27:05Z,2021-12-24T13:27:05Z,Tri-Transformer Hawkes Process: Three Heads are better than one,"Abstract. Most of the real world data we encounter are asynchronous event
sequence, so the last decades have been characterized by the implementation of
various point process into the field of social networks,electronic medical
records and financial transactions. At the beginning, Hawkes process and its
variants which can simulate simultaneously the self-triggering and mutual
triggering patterns between different events in complex sequences in a clear
and quantitative way are more popular.Later on, with the advances of neural
network, neural Hawkes process has been proposed one after another, and
gradually become a research hotspot. The proposal of the transformer Hawkes
process (THP) has gained a huge performance improvement, so a new upsurge of
the neural Hawkes process based on transformer is set off. However, THP does
not make full use of the information of occurrence time and type of event in
the asynchronous event sequence. It simply adds the encoding of event type
conversion and the location encoding of time conversion to the source encoding.
At the same time, the learner built from a single transformer will result in an
inescapable learning bias. In order to mitigate these problems, we propose a
tri-transformer Hawkes process (Tri-THP) model, in which the event and time
information are added to the dot-product attention as auxiliary information to
form a new multihead attention. The effectiveness of the Tri-THP is proved by a
series of well-designed experiments on both real world and synthetic data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.08421v1,2021-12-15T19:08:27Z,2021-12-15T19:08:27Z,"A White-Box SVM Framework and its Swarm-Based Optimization for
  Supervision of Toothed Milling Cutter through Characterization of Spindle
  Vibrations","In this paper, a white-Box support vector machine (SVM) framework and its
swarm-based optimization is presented for supervision of toothed milling cutter
through characterization of real-time spindle vibrations. The anomalous moments
of vibration evolved due to in-process tool failures (i.e., flank and nose
wear, crater and notch wear, edge fracture) have been investigated through
time-domain response of acceleration and statistical features. The Recursive
Feature Elimination with Cross-Validation (RFECV) with decision trees as the
estimator has been implemented for feature selection. Further, the competence
of standard SVM has been examined for tool health monitoring followed by its
optimization through application of swarm based algorithms. The comparative
analysis of performance of five meta-heuristic algorithms (Elephant Herding
Optimization, Monarch Butterfly Optimization, Harris Hawks Optimization, Slime
Mould Algorithm, and Moth Search Algorithm) has been carried out. The white-box
approach has been presented considering global and local representation that
provides insight into the performance of machine learning models in tool
condition monitoring.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.08211v1,2021-12-15T15:36:57Z,2021-12-15T15:36:57Z,"TrialGraph: Machine Intelligence Enabled Insight from Graph Modelling of
  Clinical Trials","A major impediment to successful drug development is the complexity, cost,
and scale of clinical trials. The detailed internal structure of clinical trial
data can make conventional optimization difficult to achieve. Recent advances
in machine learning, specifically graph-structured data analysis, have the
potential to enable significant progress in improving the clinical trial
design. TrialGraph seeks to apply these methodologies to produce a
proof-of-concept framework for developing models which can aid drug development
and benefit patients. In this work, we first introduce a curated clinical trial
data set compiled from the CT.gov, AACT and TrialTrove databases (n=1191
trials; representing one million patients) and describe the conversion of this
data to graph-structured formats. We then detail the mathematical basis and
implementation of a selection of graph machine learning algorithms, which
typically use standard machine classifiers on graph data embedded in a
low-dimensional feature space. We trained these models to predict side effect
information for a clinical trial given information on the disease, existing
medical conditions, and treatment. The MetaPath2Vec algorithm performed
exceptionally well, with standard Logistic Regression, Decision Tree, Random
Forest, Support Vector, and Neural Network classifiers exhibiting typical
ROC-AUC scores of 0.85, 0.68, 0.86, 0.80, and 0.77, respectively. Remarkably,
the best performing classifiers could only produce typical ROC-AUC scores of
0.70 when trained on equivalent array-structured data. Our work demonstrates
that graph modelling can significantly improve prediction accuracy on
appropriate datasets. Successive versions of the project that refine modelling
assumptions and incorporate more data types can produce excellent predictors
with real-world applications in drug development.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.07285v1,2021-12-14T10:41:04Z,2021-12-14T10:41:04Z,"Automatic COVID-19 disease diagnosis using 1D convolutional neural
  network and augmentation with human respiratory sound based on parameters:
  cough, breath, and voice","The issue in respiratory sound classification has attained good attention
from the clinical scientists and medical researcher's group in the last year to
diagnosing COVID-19 disease. To date, various models of Artificial Intelligence
(AI) entered into the real-world to detect the COVID-19 disease from
human-generated sounds such as voice/speech, cough, and breath. The
Convolutional Neural Network (CNN) model is implemented for solving a lot of
real-world problems on machines based on Artificial Intelligence (AI). In this
context, one dimension (1D) CNN is suggested and implemented to diagnose
respiratory diseases of COVID-19 from human respiratory sounds such as a voice,
cough, and breath. An augmentation-based mechanism is applied to improve the
preprocessing performance of the COVID-19 sounds dataset and to automate
COVID-19 disease diagnosis using the 1D convolutional network. Furthermore, a
DDAE (Data De-noising Auto Encoder) technique is used to generate deep sound
features such as the input function to the 1D CNN instead of adopting the
standard input of MFCC (Mel-frequency cepstral coefficient), and it is
performed better accuracy and performance than previous models.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.06247v1,2021-12-12T14:28:06Z,2021-12-12T14:28:06Z,DeepFIB: Self-Imputation for Time Series Anomaly Detection,"Time series (TS) anomaly detection (AD) plays an essential role in various
applications, e.g., fraud detection in finance and healthcare monitoring. Due
to the inherently unpredictable and highly varied nature of anomalies and the
lack of anomaly labels in historical data, the AD problem is typically
formulated as an unsupervised learning problem. The performance of existing
solutions is often not satisfactory, especially in data-scarce scenarios. To
tackle this problem, we propose a novel self-supervised learning technique for
AD in time series, namely \emph{DeepFIB}. We model the problem as a \emph{Fill
In the Blank} game by masking some elements in the TS and imputing them with
the rest. Considering the two common anomaly shapes (point- or
sequence-outliers) in TS data, we implement two masking strategies with many
self-generated training samples. The corresponding self-imputation networks can
extract more robust temporal relations than existing AD solutions and
effectively facilitate identifying the two types of anomalies. For continuous
outliers, we also propose an anomaly localization algorithm that dramatically
reduces AD errors. Experiments on various real-world TS datasets demonstrate
that DeepFIB outperforms state-of-the-art methods by a large margin, achieving
up to $65.2\%$ relative improvement in F1-score.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.05667v1,2021-12-10T17:01:44Z,2021-12-10T17:01:44Z,A Deep Learning Based Automated Hand Hygiene Training System,"Hand hygiene is crucial for preventing viruses and infections. Due to the
pervasive outbreak of COVID-19, wearing a mask and hand hygiene appear to be
the most effective ways for the public to curb the spread of these viruses. The
World Health Organization (WHO) recommends a guideline for alcohol-based hand
rub in eight steps to ensure that all surfaces of hands are entirely clean. As
these steps involve complex gestures, human assessment of them lacks enough
accuracy. However, Deep Neural Network (DNN) and machine vision have made it
possible to accurately evaluate hand rubbing quality for the purposes of
training and feedback. In this paper, an automated deep learning based hand rub
assessment system with real-time feedback is presented. The system evaluates
the compliance with the 8-step guideline using a DNN architecture trained on a
dataset of videos collected from volunteers with various skin tones and hand
characteristics following the hand rubbing guideline. Various DNN architectures
were tested, and an Inception-ResNet model led to the best results with 97%
test accuracy. In the proposed system, an NVIDIA Jetson AGX Xavier embedded
board runs the software. The efficacy of the system is evaluated in a concrete
situation of being used by various users, and challenging steps are identified.
In this experiment, the average time taken by the hand rubbing steps among
volunteers is 27.2 seconds, which conforms to the WHO guidelines.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.04461v1,2021-12-08T18:42:58Z,2021-12-08T18:42:58Z,Enhancing Counterfactual Classification via Self-Training,"Unlike traditional supervised learning, in many settings only partial
feedback is available. We may only observe outcomes for the chosen actions, but
not the counterfactual outcomes associated with other alternatives. Such
settings encompass a wide variety of applications including pricing, online
marketing and precision medicine. A key challenge is that observational data
are influenced by historical policies deployed in the system, yielding a biased
data distribution. We approach this task as a domain adaptation problem and
propose a self-training algorithm which imputes outcomes with categorical
values for finite unseen actions in the observational data to simulate a
randomized trial through pseudolabeling, which we refer to as Counterfactual
Self-Training (CST). CST iteratively imputes pseudolabels and retrains the
model. In addition, we show input consistency loss can further improve CST
performance which is shown in recent theoretical analysis of pseudolabeling. We
demonstrate the effectiveness of the proposed algorithms on both synthetic and
real datasets.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.03270v1,2021-12-05T21:21:19Z,2021-12-05T21:21:19Z,Toward a Taxonomy of Trust for Probabilistic Machine Learning,"Probabilistic machine learning increasingly informs critical decisions in
medicine, economics, politics, and beyond. We need evidence to support that the
resulting decisions are well-founded. To aid development of trust in these
decisions, we develop a taxonomy delineating where trust in an analysis can
break down: (1) in the translation of real-world goals to goals on a particular
set of available training data, (2) in the translation of abstract goals on the
training data to a concrete mathematical problem, (3) in the use of an
algorithm to solve the stated mathematical problem, and (4) in the use of a
particular code implementation of the chosen algorithm. We detail how trust can
fail at each step and illustrate our taxonomy with two case studies: an
analysis of the efficacy of microcredit and The Economist's predictions of the
2020 US presidential election. Finally, we describe a wide variety of methods
that can be used to increase trust at each step of our taxonomy. The use of our
taxonomy highlights steps where existing research work on trust tends to
concentrate and also steps where establishing trust is particularly
challenging.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.01134v1,2021-12-02T11:16:02Z,2021-12-02T11:16:02Z,"Data Stream Stabilization for Optical Coherence Tomography Volumetric
  Scanning","Optical Coherence Tomography (OCT) is an emerging medical imaging modality
for luminal organ diagnosis. The non-constant rotation speed of optical
components in the OCT catheter tip causes rotational distortion in OCT
volumetric scanning. By improving the scanning process, this instability can be
partially reduced. To further correct the rotational distortion in the OCT
image, a volumetric data stabilization algorithm is proposed. The algorithm
first estimates the Non-Uniform Rotational Distortion (NURD) for each B-scan by
using a Convolutional Neural Network (CNN). A correlation map between two
successive B-scans is computed and provided as input to the CNN. To solve the
problem of accumulative error in iterative frame stream processing, we deploy
an overall rotation estimation between reference orientation and actual OCT
image orientation. We train the network with synthetic OCT videos by
intentionally adding rotational distortion into real OCT images. As part of
this article we discuss the proposed method in two different scanning modes:
the first is a conventional pullback mode where the optical components move
along the protection sheath, and the second is a self-designed scanning mode
where the catheter is globally translated by using an external actuator. The
efficiency and robustness of the proposed method are evaluated with synthetic
scans as well as real scans under two scanning modes.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.11439v1,2021-11-29T22:11:23Z,2021-11-29T22:11:23Z,"Automated Drug-Related Information Extraction from French Clinical
  Documents: ReLyfe Approach","Structuring medical data in France remains a challenge mainly because of the
lack of medical data due to privacy concerns and the lack of methods and
approaches on processing the French language. One of these challenges is
structuring drug-related information in French clinical documents. To our
knowledge, over the last decade, there are less than five relevant papers that
study French prescriptions. This paper proposes a new approach for extracting
drug-related information from French clinical scanned documents while
preserving patients' privacy. In addition, we deployed our method in a health
data management platform where it is used to structure drug medical data and
help patients organize their drug schedules. It can be implemented on any web
or mobile platform. This work closes the gap between theoretical and practical
work by creating an application adapted to real production problems. It is a
combination of a rule-based phase and a Deep Learning approach. Finally,
numerical results show the outperformance and relevance of the proposed
methodology.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.14176v1,2021-11-28T15:28:31Z,2021-11-28T15:28:31Z,UAV-based Crowd Surveillance in Post COVID-19 Era,"To cope with the current pandemic situation and reinstate pseudo-normal daily
life, several measures have been deployed and maintained, such as mask wearing,
social distancing, hands sanitizing, etc. Since outdoor cultural events,
concerts, and picnics, are gradually allowed, a close monitoring of the crowd
activity is needed to avoid undesired contact and disease transmission. In this
context, intelligent unmanned aerial vehicles (UAVs) can be occasionally
deployed to ensure the surveillance of these activities, that health
restriction measures are applied, and to trigger alerts when the latter are not
respected. Consequently, we propose in this paper a complete UAV framework for
intelligent monitoring of post COVID-19 outdoor activities. Specifically, we
propose a three steps approach. In the first step, captured images by a UAV are
analyzed using machine learning to detect and locate individuals. The second
step consists of a novel coordinates mapping approach to evaluate distances
among individuals, then cluster them, while the third step provides an
energy-efficient and/or reliable UAV trajectory to inspect clusters for
restrictions violation such as mask wearing. Obtained results provide the
following insights: 1) Efficient detection of individuals depends on the angle
from which the image was captured, 2) coordinates mapping is very sensitive to
the estimation error in individuals' bounding boxes, and 3) UAV trajectory
design algorithm 2-Opt is recommended for practical real-time deployments due
to its low-complexity and near-optimal performance.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.14125v1,2021-11-28T12:13:30Z,2021-11-28T12:13:30Z,"AirSPEC: An IoT-empowered Air Quality Monitoring System integrated with
  a Machine Learning Framework to Detect and Predict defined Air Quality
  parameters","The air that surrounds us is the cardinal source of respiration of all
life-forms. Therefore, it is undoubtedly vital to highlight that balanced air
quality is utmost important to the respiratory health of all living beings,
environmental homeostasis, and even economical equilibrium. Nevertheless, a
gradual deterioration of air quality has been observed in the last few decades,
due to the continuous increment of polluted emissions from automobiles and
industries into the atmosphere. Even though many people have scarcely
acknowledged the depth of the problem, the persistent efforts of determined
parties, including the World Health Organization, have consistently pushed the
boundaries for a qualitatively better global air homeostasis, by facilitating
technology-driven initiatives to timely detect and predict air quality in
regional and global scales. However, the existing frameworks for air quality
monitoring lack the capability of real-time responsiveness and flexible
semantic distribution. In this paper, a novel Internet of Things framework is
proposed which is easily implementable, semantically distributive, and
empowered by a machine learning model. The proposed system is equipped with a
NodeRED dashboard which processes, visualizes, and stores the primary sensor
data that are acquired through a public air quality sensor network, and
further, the dashboard is integrated with a machine-learning model to obtain
temporal and geo-spatial air quality predictions. ESP8266 NodeMCU is
incorporated as a subscriber to the NodeRED dashboard via a message queuing
telemetry transport broker to communicate quantitative air quality data or
alarming emails to the end-users through the developed web and mobile
applications. Therefore, the proposed system could become highly beneficial in
empowering public engagement in air quality through an unoppressive,
data-driven, and semantic framework.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.11789v1,2021-11-23T11:06:27Z,2021-11-23T11:06:27Z,"End-to-End Optimized Arrhythmia Detection Pipeline using Machine
  Learning for Ultra-Edge Devices","Atrial fibrillation (AF) is the most prevalent cardiac arrhythmia worldwide,
with 2% of the population affected. It is associated with an increased risk of
strokes, heart failure and other heart-related complications. Monitoring
at-risk individuals and detecting asymptomatic AF could result in considerable
public health benefits, as individuals with asymptomatic AF could take
preventive measures with lifestyle changes. With increasing affordability to
wearables, personalized health care is becoming more accessible. These
personalized healthcare solutions require accurate classification of
bio-signals while being computationally inexpensive. By making inferences
on-device, we avoid issues inherent to cloud-based systems such as latency and
network connection dependency. We propose an efficient pipeline for real-time
Atrial Fibrillation Detection with high accuracy that can be deployed in
ultra-edge devices. The feature engineering employed in this research catered
to optimizing the resource-efficient classifier used in the proposed pipeline,
which was able to outperform the best performing standard ML model by
$10^5\times$ in terms of memory footprint with a mere trade-off of 2%
classification accuracy. We also obtain higher accuracy of approximately 6%
while consuming 403$\times$ lesser memory and being 5.2$\times$ faster compared
to the previous state-of-the-art (SoA) embedded implementation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.11108v1,2021-11-22T10:58:53Z,2021-11-22T10:58:53Z,"Unsupervised Time Series Outlier Detection with Diversity-Driven
  Convolutional Ensembles -- Extended Version","With the sweeping digitalization of societal, medical, industrial, and
scientific processes, sensing technologies are being deployed that produce
increasing volumes of time series data, thus fueling a plethora of new or
improved applications. In this setting, outlier detection is frequently
important, and while solutions based on neural networks exist, they leave room
for improvement in terms of both accuracy and efficiency. With the objective of
achieving such improvements, we propose a diversity-driven, convolutional
ensemble. To improve accuracy, the ensemble employs multiple basic outlier
detection models built on convolutional sequence-to-sequence autoencoders that
can capture temporal dependencies in time series. Further, a novel
diversity-driven training method maintains diversity among the basic models,
with the aim of improving the ensemble's accuracy. To improve efficiency, the
approach enables a high degree of parallelism during training. In addition, it
is able to transfer some model parameters from one basic model to another,
which reduces training time. We report on extensive experiments using
real-world multivariate time series that offer insight into the design choices
underlying the new approach and offer evidence that it is capable of improved
accuracy and efficiency. This is an extended version of ""Unsupervised Time
Series Outlier Detection with Diversity-Driven Convolutional Ensembles"", to
appear in PVLDB 2022.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.03890v1,2021-11-06T13:54:07Z,2021-11-06T13:54:07Z,"Demystifying Deep Learning Models for Retinal OCT Disease Classification
  using Explainable AI","In the world of medical diagnostics, the adoption of various deep learning
techniques is quite common as well as effective, and its statement is equally
true when it comes to implementing it into the retina Optical Coherence
Tomography (OCT) sector, but (i)These techniques have the black box
characteristics that prevent the medical professionals to completely trust the
results generated from them (ii)Lack of precision of these methods restricts
their implementation in clinical and complex cases (iii)The existing works and
models on the OCT classification are substantially large and complicated and
they require a considerable amount of memory and computational power, reducing
the quality of classifiers in real-time applications. To meet these problems,
in this paper a self-developed CNN model has been proposed which is
comparatively smaller and simpler along with the use of Lime that introduces
Explainable AI to the study and helps to increase the interpretability of the
model. This addition will be an asset to the medical experts for getting major
and detailed information and will help them in making final decisions and will
also reduce the opacity and vulnerability of the conventional deep learning
models.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.03731v1,2021-11-05T21:27:55Z,2021-11-05T21:27:55Z,Frugal Machine Learning,"Machine learning, already at the core of increasingly many systems and
applications, is set to become even more ubiquitous with the rapid rise of
wearable devices and the Internet of Things. In most machine learning
applications, the main focus is on the quality of the results achieved (e.g.,
prediction accuracy), and hence vast amounts of data are being collected,
requiring significant computational resources to build models. In many
scenarios, however, it is infeasible or impractical to set up large centralized
data repositories. In personal health, for instance, privacy issues may inhibit
the sharing of detailed personal data. In such cases, machine learning should
ideally be performed on wearable devices themselves, which raises major
computational limitations such as the battery capacity of smartwatches. This
paper thus investigates frugal learning, aimed to build the most accurate
possible models using the least amount of resources. A wide range of learning
algorithms is examined through a frugal lens, analyzing their accuracy/runtime
performance on a wide range of data sets. The most promising algorithms are
thereafter assessed in a real-world scenario by implementing them in a
smartwatch and letting them learn activity recognition models on the watch
itself.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.01999v1,2021-11-03T03:32:33Z,2021-11-03T03:32:33Z,"Automated, real-time hospital ICU emergency signaling: A field-level
  implementation","Contemporary patient surveillance systems have streamlined central
surveillance into the electronic health record interface. They are able to
process the sheer volume of patient data by adopting machine learning
approaches. However, these systems are not suitable for implementation in many
hospitals, mostly in developing countries, with limited human, financial, and
technological resources. Through conducting thorough research on intensive care
facilities, we designed a novel central patient monitoring system and in this
paper, we describe the working prototype of our system. The proposed prototype
comprises of inexpensive peripherals and simplistic user interface. Our central
patient monitoring system implements Kernel-based On-line Anomaly Detection
(KOAD) algorithm for emergency event signaling. By evaluating continuous
patient data, we show that the system is able to detect critical events in
real-time reliably and has low false alarm rate.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.01950v2,2021-11-10T10:08:13Z,2021-11-02T23:51:06Z,"Machine-Learning Identification of Hemodynamics in Coronary Arteries in
  the Presence of Stenosis","Prediction of the blood flow characteristics is of utmost importance for
understanding the behavior of the blood arterial network, especially in the
presence of vascular diseases such as stenosis. Computational fluid dynamics
(CFD) has provided a powerful and efficient tool to determine these
characteristics including the pressure and velocity fields within the network.
Despite numerous studies in the field, the extremely high computational cost of
CFD has led the researchers to develop new platforms including Machine Learning
approaches that instead provide faster analyses at a much lower cost. In this
study, we put forth a Deep Neural Network framework to predict flow behavior in
a coronary arterial network with different properties in the presence of any
abnormality like stenosis. To this end, an artificial neural network (ANN)
model is trained using synthetic data so that it can predict the pressure and
velocity within the arterial network. The data required to train the neural
network were obtained from the CFD analysis of several geometries of arteries
with specific features in ABAQUS software. Blood pressure drop caused by
stenosis, which is one of the most important factors in the diagnosis of heart
diseases, can be predicted using our proposed model knowing the geometrical and
flow boundary conditions of any section of the coronary arteries. The
efficiency of the model was verified using three real geometries of LAD's
vessels. The proposed approach precisely predicts the hemodynamic behavior of
the blood flow. The average accuracy of the pressure prediction was 98.7% and
the average velocity magnitude accuracy was 93.2%. According to the results of
testing the model on three patient-specific geometries, model can be considered
as an alternative to finite element methods as well as other hard-to-implement
and time-consuming numerical simulations.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.01338v2,2021-11-03T14:49:34Z,2021-11-02T02:54:30Z,"Federated Split Vision Transformer for COVID-19 CXR Diagnosis using
  Task-Agnostic Training","Federated learning, which shares the weights of the neural network across
clients, is gaining attention in the healthcare sector as it enables training
on a large corpus of decentralized data while maintaining data privacy. For
example, this enables neural network training for COVID-19 diagnosis on chest
X-ray (CXR) images without collecting patient CXR data across multiple
hospitals. Unfortunately, the exchange of the weights quickly consumes the
network bandwidth if highly expressive network architecture is employed.
So-called split learning partially solves this problem by dividing a neural
network into a client and a server part, so that the client part of the network
takes up less extensive computation resources and bandwidth. However, it is not
clear how to find the optimal split without sacrificing the overall network
performance. To amalgamate these methods and thereby maximize their distinct
strengths, here we show that the Vision Transformer, a recently developed deep
learning architecture with straightforward decomposable configuration, is
ideally suitable for split learning without sacrificing performance. Even under
the non-independent and identically distributed data distribution which
emulates a real collaboration between hospitals using CXR datasets from
multiple sources, the proposed framework was able to attain performance
comparable to data-centralized training. In addition, the proposed framework
along with heterogeneous multi-task clients also improves individual task
performances including the diagnosis of COVID-19, eliminating the need for
sharing large weights with innumerable parameters. Our results affirm the
suitability of Transformer for collaborative learning in medical imaging and
pave the way forward for future real-world implementations.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.15127v1,2021-10-28T14:02:16Z,2021-10-28T14:02:16Z,"Lightweight Mobile Automated Assistant-to-physician for Global
  Lower-resource Areas","Importance: Lower-resource areas in Africa and Asia face a unique set of
healthcare challenges: the dual high burden of communicable and
non-communicable diseases; a paucity of highly trained primary healthcare
providers in both rural and densely populated urban areas; and a lack of
reliable, inexpensive internet connections. Objective: To address these
challenges, we designed an artificial intelligence assistant to help primary
healthcare providers in lower-resource areas document demographic and medical
sign/symptom data and to record and share diagnostic data in real-time with a
centralized database. Design: We trained our system using multiple data sets,
including US-based electronic medical records (EMRs) and open-source medical
literature and developed an adaptive, general medical assistant system based on
machine learning algorithms. Main outcomes and Measure: The application
collects basic information from patients and provides primary care providers
with diagnoses and prescriptions suggestions. The application is unique from
existing systems in that it covers a wide range of common diseases, signs, and
medication typical in lower-resource countries; the application works with or
without an active internet connection. Results: We have built and implemented
an adaptive learning system that assists trained primary care professionals by
means of an Android smartphone application, which interacts with a central
database and collects real-time data. The application has been tested by dozens
of primary care providers. Conclusions and Relevance: Our application would
provide primary healthcare providers in lower-resource areas with a tool that
enables faster and more accurate documentation of medical encounters. This
application could be leveraged to automatically populate local or national EMR
systems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.12900v2,2022-03-06T17:55:30Z,2021-10-21T01:38:35Z,"Automated Scoring System of HER2 in Pathological Images under the
  Microscope","Breast cancer is the most common cancer among women worldwide. The human
epidermal growth factor receptor 2 (HER2) with immunohistochemical (IHC) is
widely used for pathological evaluation to provide the appropriate therapy for
patients with breast cancer. However, the deficiency of pathologists and
subjective and susceptible to inter-observer variation of visual diagnosis are
the main challenges. Recently, with the rapid development of artificial
intelligence (AI) in disease diagnosis, several automated HER2 scoring methods
using traditional computer vision or machine learning methods indicate the
improvement of the HER2 diagnostic accuracy, but the unreasonable
interpretation in pathology, as well as the expensive and ethical issues for
annotation, make these methods still have a long way to deploy in hospitals to
ease pathologists' burden in real. In this paper, we propose a HER2 automated
scoring system that strictly follows the HER2 scoring guidelines simulating the
real workflow of HER2 scores diagnosis by pathologists. Unlike the previous
work, our method considers the positive control of HER2 to make sure the assay
performance for each slide, eliminating work for repeated comparison between
the current field of view (FOV) and positive control FOV, especially for the
borderline cases. Besides, for each selected FOV under the microscope, our
system provides real-time HER2 scores analysis and visualizations of the
membrane staining intensity and completeness corresponding with the cell
classifications. Our rigorous workflow along with the flexible interactive
adjustion in demand substantially assists pathologists to finish the HER2
diagnosis faster and improves the robustness and accuracy. The proposed system
will be embedded in our Thorough Eye platform for deployment in hospitals.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.08820v2,2021-10-19T16:49:58Z,2021-10-17T13:42:37Z,On-board Fault Diagnosis of a Laboratory Mini SR-30 Gas Turbine Engine,"Inspired by recent progress in machine learning, a data-driven fault
diagnosis and isolation (FDI) scheme is explicitly developed for failure in the
fuel supply system and sensor measurements of the laboratory gas turbine
system. A passive approach of fault diagnosis is implemented where a model is
trained using machine learning classifiers to detect a given set of fault
scenarios in real-time on which it is trained. Towards the end, a comparative
study is presented for well-known classification techniques, namely Support
vector classifier, linear discriminant analysis, K-neighbor, and decision
trees. Several simulation studies were carried out to demonstrate and
illustrate the proposed fault diagnosis scheme's advantages, capabilities, and
performance.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.08732v1,2021-10-17T06:12:02Z,2021-10-17T06:12:02Z,A Deep Learning-based Approach for Real-time Facemask Detection,"The COVID-19 pandemic is causing a global health crisis. Public spaces need
to be safeguarded from the adverse effects of this pandemic. Wearing a facemask
becomes one of the effective protection solutions adopted by many governments.
Manual real-time monitoring of facemask wearing for a large group of people is
becoming a difficult task. The goal of this paper is to use deep learning (DL),
which has shown excellent results in many real-life applications, to ensure
efficient real-time facemask detection. The proposed approach is based on two
steps. An off-line step aiming to create a DL model that is able to detect and
locate facemasks and whether they are appropriately worn. An online step that
deploys the DL model at edge computing in order to detect masks in real-time.
In this study, we propose to use MobileNetV2 to detect facemask in real-time.
Several experiments are conducted and show good performances of the proposed
approach (99% for training and testing accuracy). In addition, several
comparisons with many state-of-the-art models namely ResNet50, DenseNet, and
VGG16 show good performance of the MobileNetV2 in terms of training time and
accuracy.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.06196v1,2021-10-12T17:49:46Z,2021-10-12T17:49:46Z,GraPE: fast and scalable Graph Processing and Embedding,"Graph Representation Learning methods have enabled a wide range of learning
problems to be addressed for data that can be represented in graph form.
Nevertheless, several real world problems in economy, biology, medicine and
other fields raised relevant scaling problems with existing methods and their
software implementation, due to the size of real world graphs characterized by
millions of nodes and billions of edges. We present GraPE, a software resource
for graph processing and random walk based embedding, that can scale with large
and high-degree graphs and significantly speed up-computation. GraPE comprises
specialized data structures, algorithms, and a fast parallel implementation
that displays everal orders of magnitude improvement in empirical space and
time complexity compared to state of the art software resources, with a
corresponding boost in the performance of machine learning methods for edge and
node label prediction and for the unsupervised analysis of graphs.GraPE is
designed to run on laptop and desktop computers, as well as on high performance
computing clusters",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.04563v1,2021-10-09T13:11:21Z,2021-10-09T13:11:21Z,"Automatic Recognition of Abdominal Organs in Ultrasound Images based on
  Deep Neural Networks and K-Nearest-Neighbor Classification","Abdominal ultrasound imaging has been widely used to assist in the diagnosis
and treatment of various abdominal organs. In order to shorten the examination
time and reduce the cognitive burden on the sonographers, we present a
classification method that combines the deep learning techniques and
k-Nearest-Neighbor (k-NN) classification to automatically recognize various
abdominal organs in the ultrasound images in real time. Fine-tuned deep neural
networks are used in combination with PCA dimension reduction to extract
high-level features from raw ultrasound images, and a k-NN classifier is
employed to predict the abdominal organ in the image. We demonstrate the
effectiveness of our method in the task of ultrasound image classification to
automatically recognize six abdominal organs. A comprehensive comparison of
different configurations is conducted to study the influence of different
feature extractors and classifiers on the classification accuracy. Both
quantitative and qualitative results show that with minimal training effort,
our method can ""lazily"" recognize the abdominal organs in the ultrasound images
in real time with an accuracy of 96.67%. Our implementation code is publicly
available at: https://github.com/LeeKeyu/abdominal_ultrasound_classification.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.04249v1,2021-10-08T16:58:57Z,2021-10-08T16:58:57Z,How Can AI Recognize Pain and Express Empathy,"Sensory and emotional experiences such as pain and empathy are relevant to
mental and physical health. The current drive for automated pain recognition is
motivated by a growing number of healthcare requirements and demands for social
interaction make it increasingly essential. Despite being a trending area, they
have not been explored in great detail. Over the past decades, behavioral
science and neuroscience have uncovered mechanisms that explain the
manifestations of pain. Recently, also artificial intelligence research has
allowed empathic machine learning methods to be approachable. Generally, the
purpose of this paper is to review the current developments for computational
pain recognition and artificial empathy implementation. Our discussion covers
the following topics: How can AI recognize pain from unimodality and
multimodality? Is it necessary for AI to be empathic? How can we create an AI
agent with proactive and reactive empathy? This article explores the challenges
and opportunities of real-world multimodal pain recognition from a
psychological, neuroscientific, and artificial intelligence perspective.
Finally, we identify possible future implementations of artificial empathy and
analyze how humans might benefit from an AI agent equipped with empathy.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.01863v2,2022-03-31T17:46:28Z,2021-10-05T07:55:19Z,"DeepEdge: A Deep Reinforcement Learning based Task Orchestrator for Edge
  Computing","The improvements in the edge computing technology pave the road for
diversified applications that demand real-time interaction. However, due to the
mobility of the end-users and the dynamic edge environment, it becomes
challenging to handle the task offloading with high performance. Moreover,
since each application in mobile devices has different characteristics, a task
orchestrator must be adaptive and have the ability to learn the dynamics of the
environment. For this purpose, we develop a deep reinforcement learning based
task orchestrator, DeepEdge, which learns to meet different task requirements
without needing human interaction even under the heavily-loaded stochastic
network conditions in terms of mobile users and applications. Given the dynamic
offloading requests and time-varying communication conditions, we successfully
model the problem as a Markov process and then apply the Double Deep Q-Network
(DDQN) algorithm to implement DeepEdge. To evaluate the robustness of DeepEdge,
we experiment with four different applications including image rendering,
infotainment, pervasive health, and augmented reality in the network under
various loads. Furthermore, we compare the performance of our agent with the
four different task offloading approaches in the literature. Our results show
that DeepEdge outperforms its competitors in terms of the percentage of
satisfactorily completed tasks.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.01293v1,2021-10-04T09:59:01Z,2021-10-04T09:59:01Z,"Light-weight Deformable Registration using Adversarial Learning with
  Distilling Knowledge","Deformable registration is a crucial step in many medical procedures such as
image-guided surgery and radiation therapy. Most recent learning-based methods
focus on improving the accuracy by optimizing the non-linear spatial
correspondence between the input images. Therefore, these methods are
computationally expensive and require modern graphic cards for real-time
deployment. In this paper, we introduce a new Light-weight Deformable
Registration network that significantly reduces the computational cost while
achieving competitive accuracy. In particular, we propose a new adversarial
learning with distilling knowledge algorithm that successfully leverages
meaningful information from the effective but expensive teacher network to the
student network. We design the student network such as it is light-weight and
well suitable for deployment on a typical CPU. The extensively experimental
results on different public datasets show that our proposed method achieves
state-of-the-art accuracy while significantly faster than recent methods. We
further show that the use of our adversarial learning algorithm is essential
for a time-efficiency deformable registration method. Finally, our source code
and trained models are available at: https://github.com/aioz-ai/LDR_ALDK.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.00086v1,2021-09-30T20:56:37Z,2021-09-30T20:56:37Z,On the Trustworthiness of Tree Ensemble Explainability Methods,"The recent increase in the deployment of machine learning models in critical
domains such as healthcare, criminal justice, and finance has highlighted the
need for trustworthy methods that can explain these models to stakeholders.
Feature importance methods (e.g. gain and SHAP) are among the most popular
explainability methods used to address this need. For any explainability
technique to be trustworthy and meaningful, it has to provide an explanation
that is accurate and stable. Although the stability of local feature importance
methods (explaining individual predictions) has been studied before, there is
yet a knowledge gap about the stability of global features importance methods
(explanations for the whole model). Additionally, there is no study that
evaluates and compares the accuracy of global feature importance methods with
respect to feature ordering. In this paper, we evaluate the accuracy and
stability of global feature importance methods through comprehensive
experiments done on simulations as well as four real-world datasets. We focus
on tree-based ensemble methods as they are used widely in industry and measure
the accuracy and stability of explanations under two scenarios: 1) when inputs
are perturbed 2) when models are perturbed. Our findings provide a comparison
of these methods under a variety of settings and shed light on the limitations
of global feature importance methods by indicating their lack of accuracy with
and without noisy inputs, as well as their lack of stability with respect to:
1) increase in input dimension or noise in the data; 2) perturbations in models
initialized by different random seeds or hyperparameter settings.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.14885v2,2022-05-05T19:11:45Z,2021-09-30T07:05:20Z,"Out-of-Distribution Detection for Medical Applications: Guidelines for
  Practical Evaluation","Detection of Out-of-Distribution (OOD) samples in real time is a crucial
safety check for deployment of machine learning models in the medical field.
Despite a growing number of uncertainty quantification techniques, there is a
lack of evaluation guidelines on how to select OOD detection methods in
practice. This gap impedes implementation of OOD detection methods for
real-world applications. Here, we propose a series of practical considerations
and tests to choose the best OOD detector for a specific medical dataset. These
guidelines are illustrated on a real-life use case of Electronic Health Records
(EHR). Our results can serve as a guide for implementation of OOD detection
methods in clinical practice, mitigating risks associated with the use of
machine learning models in healthcare.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.13521v2,2021-11-23T05:34:54Z,2021-09-28T06:49:40Z,"A multi-stage semi-supervised improved deep embedded clustering method
  for bearing fault diagnosis under the situation of insufficient labeled
  samples","Although data-driven fault diagnosis methods have been widely applied,
massive labeled data are required for model training. However, a difficulty of
implementing this in real industries hinders the application of these methods.
Hence, an effective diagnostic approach that can work well in such situation is
urgently needed.In this study, a multi-stage semi-supervised improved deep
embedded clustering (MS-SSIDEC) method, which combines semi-supervised learning
with improved deep embedded clustering (IDEC), is proposed to jointly explore
scarce labeled data and massive unlabeled data. In the first stage, a
skip-connection-based convolutional auto-encoder (SCCAE) that can automatically
map the unlabeled data into a low-dimensional feature space is proposed and
pre-trained to be a fault feature extractor. In the second stage, a
semi-supervised improved deep embedded clustering (SSIDEC) network is proposed
for clustering. It is first initialized with available labeled data and then
used to simultaneously optimize the clustering label assignment and make the
feature space to be more clustering-friendly. To tackle the phenomenon of
overfitting, virtual adversarial training (VAT) is introduced as a
regularization term in this stage. In the third stage, pseudo labels are
obtained by the high-quality results of SSIDEC. The labeled dataset can be
augmented by these pseudo-labeled data and then leveraged to train a bearing
fault diagnosis model. Two public datasets of vibration data from rolling
bearings are used to evaluate the performance of the proposed method.
Experimental results indicate that the proposed method achieves a promising
performance in both semi-supervised and unsupervised fault diagnosis tasks.
This method provides a new approach for fault diagnosis under the situation of
limited labeled samples by effectively exploring unsupervised data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.09435v1,2021-09-20T11:33:09Z,2021-09-20T11:33:09Z,Incremental Learning Techniques for Online Human Activity Recognition,"Unobtrusive and smart recognition of human activities using smartphones
inertial sensors is an interesting topic in the field of artificial
intelligence acquired tremendous popularity among researchers, especially in
recent years. A considerable challenge that needs more attention is the
real-time detection of physical activities, since for many real-world
applications such as health monitoring and elderly care, it is required to
recognize users' activities immediately to prevent severe damages to
individuals' wellness. In this paper, we propose a human activity recognition
(HAR) approach for the online prediction of physical movements, benefiting from
the capabilities of incremental learning algorithms. We develop a HAR system
containing monitoring software and a mobile application that collects
accelerometer and gyroscope data and send them to a remote server via the
Internet for classification and recognition operations. Six incremental
learning algorithms are employed and evaluated in this work and compared with
several batch learning algorithms commonly used for developing offline HAR
systems. The Final results indicated that considering all performance
evaluation metrics, Incremental K-Nearest Neighbors and Incremental Naive
Bayesian outperformed other algorithms, exceeding a recognition accuracy of 95%
in real-time.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.07846v1,2021-09-16T10:22:31Z,2021-09-16T10:22:31Z,"Telehealthcare and Covid-19: A Noninvasive & Low Cost Invasive, Scalable
  and Multimodal Real-Time Smartphone Application for Early Diagnosis of
  SARS-CoV-2 Infection","The global coronavirus pandemic overwhelmed many health care systems,
enforcing lockdown and encouraged work from home to control the spread of the
virus and prevent overrunning of hospitalized patients. This prompted a sharp
widespread use of telehealth to provide low-risk care for patients.
Nevertheless, a continuous mutation into new variants and widespread
unavailability of test kits, especially in developing countries, possess the
challenge to control future potential waves of infection. In this paper, we
propose a novel Smartphone application-based platform for early diagnosis of
possible Covid-19 infected patients. The application provides three modes of
diagnosis from possible symptoms, cough sound, and specific blood biomarkers.
When a user chooses a particular setting and provides the necessary
information, it sends the data to a trained machine learning (ML) model
deployed in a remote server using the internet. The ML algorithm then predicts
the possibility of contracting Covid-19 and sends the feedback to the user. The
entire procedure takes place in real-time. Our machine learning models can
identify Covid-19 patients with an accuracy of 100%, 95.65%, and 77.59% from
blood parameters, cough sound, and symptoms respectively. Moreover, the ML
sensitivity for blood and sound is 100%, which indicates correct identification
of Covid positive patients. This is significant in limiting the spread of the
virus. The multimodality offers multiplex diagnostic methods to better classify
possible infectees and together with the instantaneous nature of our technique,
demonstrates the power of telehealthcare as an easy and widespread low-cost
scalable diagnostic solution for future pandemics.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.07827v2,2022-04-27T16:38:20Z,2021-09-16T09:36:53Z,"Enabling risk-aware Reinforcement Learning for medical interventions
  through uncertainty decomposition","Reinforcement Learning (RL) is emerging as tool for tackling complex control
and decision-making problems. However, in high-risk environments such as
healthcare, manufacturing, automotive or aerospace, it is often challenging to
bridge the gap between an apparently optimal policy learnt by an agent and its
real-world deployment, due to the uncertainties and risk associated with it.
Broadly speaking RL agents face two kinds of uncertainty, 1. aleatoric
uncertainty, which reflects randomness or noise in the dynamics of the world,
and 2. epistemic uncertainty, which reflects the bounded knowledge of the agent
due to model limitations and finite amount of information/data the agent has
acquired about the world. These two types of uncertainty carry fundamentally
different implications for the evaluation of performance and the level of risk
or trust. Yet these aleatoric and epistemic uncertainties are generally
confounded as standard and even distributional RL is agnostic to this
difference. Here we propose how a distributional approach (UA-DQN) can be
recast to render uncertainties by decomposing the net effects of each
uncertainty. We demonstrate the operation of this method in grid world examples
to build intuition and then show a proof of concept application for an RL agent
operating as a clinical decision support system in critical care",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.06919v2,2022-01-12T22:08:58Z,2021-09-14T18:41:36Z,Deploying clinical machine learning? Consider the following...,"Despite the intense attention and considerable investment into clinical
machine learning research, relatively few applications have been deployed at a
large-scale in a real-world clinical environment. While research is important
in advancing the state-of-the-art, translation is equally important in bringing
these techniques and technologies into a position to ultimately impact
healthcare. We believe a lack of appreciation for several considerations are a
major cause for this discrepancy between expectation and reality. To better
characterize a holistic perspective among researchers and practitioners, we
survey several practitioners with commercial experience in developing CML for
clinical deployment. Using these insights, we identify several main categories
of challenges in order to better design and develop clinical machine learning
applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.05742v3,2022-06-28T03:11:58Z,2021-09-13T07:07:23Z,"Domain Generalization for Medical Image Segmentation via Hierarchical
  Consistency Regularization","Modern deep neural networks struggle to transfer knowledge and generalize
across diverse domains when deployed to real-world applications. Currently,
domain generalization (DG) is introduced to learn a universal representation
from multiple domains to improve the network generalization ability on unseen
domains. However, previous DG methods only focus on the data-level consistency
scheme without considering the synergistic regularization among different
consistency schemes. In this paper, we present a novel Hierarchical Consistency
framework for Domain Generalization (HCDG) by integrating Extrinsic Consistency
and Intrinsic Consistency synergistically. Particularly, for the Extrinsic
Consistency, we leverage the knowledge across multiple source domains to
enforce data-level consistency. To better enhance such consistency, we design a
novel Amplitude Gaussian-mixing strategy into Fourier-based data augmentation
called DomainUp. For the Intrinsic Consistency, we perform task-level
consistency for the same instance under the dual-task scenario. We evaluate the
proposed HCDG framework on two medical image segmentation tasks, i.e., optic
cup/disc segmentation on fundus images and prostate MRI segmentation. Extensive
experimental results manifest the effectiveness and versatility of our HCDG
framework.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.02915v1,2021-09-07T08:04:02Z,2021-09-07T08:04:02Z,"Few-shot Learning in Emotion Recognition of Spontaneous Speech Using a
  Siamese Neural Network with Adaptive Sample Pair Formation","Speech-based machine learning (ML) has been heralded as a promising solution
for tracking prosodic and spectrotemporal patterns in real-life that are
indicative of emotional changes, providing a valuable window into one's
cognitive and mental state. Yet, the scarcity of labelled data in ambulatory
studies prevents the reliable training of ML models, which usually rely on
""data-hungry"" distribution-based learning. Leveraging the abundance of labelled
speech data from acted emotions, this paper proposes a few-shot learning
approach for automatically recognizing emotion in spontaneous speech from a
small number of labelled samples. Few-shot learning is implemented via a metric
learning approach through a siamese neural network, which models the relative
distance between samples rather than relying on learning absolute patterns of
the corresponding distributions of each emotion. Results indicate the
feasibility of the proposed metric learning in recognizing emotions from
spontaneous speech in four datasets, even with a small amount of labelled
samples. They further demonstrate superior performance of the proposed metric
learning compared to commonly used adaptation methods, including network
fine-tuning and adversarial learning. Findings from this work provide a
foundation for the ambulatory tracking of human emotion in spontaneous speech
contributing to the real-life assessment of mental health degradation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.02418v2,2021-10-17T07:11:58Z,2021-09-06T12:58:25Z,Multitask Balanced and Recalibrated Network for Medical Code Prediction,"Human coders assign standardized medical codes to clinical documents
generated during patients' hospitalization, which is error-prone and
labor-intensive. Automated medical coding approaches have been developed using
machine learning methods such as deep neural networks. Nevertheless, automated
medical coding is still challenging because of the imbalanced class problem,
complex code association, and noise in lengthy documents. To solve these
issues, we propose a novel neural network called Multitask Balanced and
Recalibrated Neural Network. Significantly, the multitask learning scheme
shares the relationship knowledge between different code branches to capture
the code association. A recalibrated aggregation module is developed by
cascading convolutional blocks to extract high-level semantic features that
mitigate the impact of noise in documents. Also, the cascaded structure of the
recalibrated module can benefit the learning from lengthy notes. To solve the
class imbalanced problem, we deploy the focal loss to redistribute the
attention of low and high-frequency medical codes. Experimental results show
that our proposed model outperforms competitive baselines on a real-world
clinical dataset MIMIC-III.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.00582v3,2022-07-02T05:44:29Z,2021-09-01T19:20:28Z,"Information-theoretic Classification Accuracy: A Criterion that Guides
  Data-driven Combination of Ambiguous Outcome Labels in Multi-class
  Classification","Outcome labeling ambiguity and subjectivity are ubiquitous in real-world
datasets. While practitioners commonly combine ambiguous outcome labels for all
data points (instances) in an ad hoc way to improve the accuracy of multi-class
classification, there lacks a principled approach to guide the label
combination for all data points by any optimality criterion. To address this
problem, we propose the information-theoretic classification accuracy (ITCA), a
criterion that balances the trade-off between prediction accuracy (how well do
predicted labels agree with actual labels) and classification resolution (how
many labels are predictable), to guide practitioners on how to combine
ambiguous outcome labels. To find the optimal label combination indicated by
ITCA, we propose two search strategies: greedy search and breadth-first search.
Notably, ITCA and the two search strategies are adaptive to all
machine-learning classification algorithms. Coupled with a classification
algorithm and a search strategy, ITCA has two uses: improving prediction
accuracy and identifying ambiguous labels. We first verify that ITCA achieves
high accuracy with both search strategies in finding the correct label
combinations on synthetic and real data. Then we demonstrate the effectiveness
of ITCA in diverse applications including medical prognosis, cancer survival
prediction, user demographics prediction, and cell type classification. We also
provide theoretical insights into ITCA by studying the oracle and the linear
discriminant analysis classification algorithms. Python package itca (available
at https://github.com/JSB-UCLA/ITCA) implements ITCA and search strategies.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.00115v1,2021-08-31T23:38:17Z,2021-08-31T23:38:17Z,"Uncertainty Quantified Deep Learning for Predicting Dice Coefficient of
  Digital Histopathology Image Segmentation","Deep learning models (DLMs) can achieve state of the art performance in
medical image segmentation and classification tasks. However, DLMs that do not
provide feedback for their predictions such as Dice coefficients (Dice) have
limited deployment potential in real world clinical settings. Uncertainty
estimates can increase the trust of these automated systems by identifying
predictions that need further review but remain computationally prohibitive to
deploy. In this study, we use a DLM with randomly initialized weights and Monte
Carlo dropout (MCD) to segment tumors from microscopic Hematoxylin and Eosin
(H&E) dye stained prostate core biopsy RGB images. We devise a novel approach
that uses multiple clinical region based uncertainties from a single image
(instead of the entire image) to predict Dice of the DLM model output by linear
models. Image level uncertainty maps were generated and showed correspondence
between imperfect model segmentation and high levels of uncertainty associated
with specific prostate tissue regions with or without tumors. Results from this
study suggest that linear models can learn coefficients of uncertainty
quantified deep learning and correlations ((Spearman's correlation (p<0.05)) to
predict Dice scores of specific regions of medical images.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.00516v1,2021-08-31T17:51:15Z,2021-08-31T17:51:15Z,Multistage Pruning of CNN Based ECG Classifiers for Edge Devices,"Using smart wearable devices to monitor patients electrocardiogram (ECG) for
real-time detection of arrhythmias can significantly improve healthcare
outcomes. Convolutional neural network (CNN) based deep learning has been used
successfully to detect anomalous beats in ECG. However, the computational
complexity of existing CNN models prohibits them from being implemented in
low-powered edge devices. Usually, such models are complex with lots of model
parameters which results in large number of computations, memory, and power
usage in edge devices. Network pruning techniques can reduce model complexity
at the expense of performance in CNN models. This paper presents a novel
multistage pruning technique that reduces CNN model complexity with negligible
loss in performance compared to existing pruning techniques. An existing CNN
model for ECG classification is used as a baseline reference. At 60% sparsity,
the proposed technique achieves 97.7% accuracy and an F1 score of 93.59% for
ECG classification tasks. This is an improvement of 3.3% and 9% for accuracy
and F1 Score respectively, compared to traditional pruning with fine-tuning
approach. Compared to the baseline model, we also achieve a 60.4% decrease in
run-time complexity.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.13557v2,2022-03-04T19:37:30Z,2021-08-31T00:06:09Z,Towards Observability for Machine Learning Pipelines,"Software organizations are increasingly incorporating machine learning (ML)
into their product offerings, driving a need for new data management tools.
Many of these tools facilitate the initial development of ML applications, but
sustaining these applications post-deployment is difficult due to lack of
real-time feedback (i.e., labels) for predictions and silent failures that
could occur at any stage, or component, of the ML pipeline (e.g., data
distribution shift). We propose a new type of data management system that
offers end-to-end observability, or visibility into complex system behavior,
for ML pipelines through assisted (1) detection, (2) diagnosis, and (3)
reaction to ML-related bugs. We describe new research challenges and suggest
preliminary solution ideas in all three aspects. Finally, we introduce an
example architecture for a ""bolt-on"" ML observability system, or one that wraps
around existing tools in the stack.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.13381v1,2021-08-30T17:04:04Z,2021-08-30T17:04:04Z,"Trustworthy AI for Process Automation on a Chylla-Haase Polymerization
  Reactor","In this paper, genetic programming reinforcement learning (GPRL) is utilized
to generate human-interpretable control policies for a Chylla-Haase
polymerization reactor. Such continuously stirred tank reactors (CSTRs) with
jacket cooling are widely used in the chemical industry, in the production of
fine chemicals, pigments, polymers, and medical products. Despite appearing
rather simple, controlling CSTRs in real-world applications is quite a
challenging problem to tackle. GPRL utilizes already existing data from the
reactor and generates fully automatically a set of optimized simplistic control
strategies, so-called policies, the domain expert can choose from. Note that
these policies are white-box models of low complexity, which makes them easy to
validate and implement in the target control system, e.g., SIMATIC PCS 7.
However, despite its low complexity the automatically-generated policy yields a
high performance in terms of reactor temperature control deviation, which we
empirically evaluate on the original reactor template.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.13035v1,2021-08-30T07:43:47Z,2021-08-30T07:43:47Z,"SurRoL: An Open-source Reinforcement Learning Centered and dVRK
  Compatible Platform for Surgical Robot Learning","Autonomous surgical execution relieves tedious routines and surgeon's
fatigue. Recent learning-based methods, especially reinforcement learning (RL)
based methods, achieve promising performance for dexterous manipulation, which
usually requires the simulation to collect data efficiently and reduce the
hardware cost. The existing learning-based simulation platforms for medical
robots suffer from limited scenarios and simplified physical interactions,
which degrades the real-world performance of learned policies. In this work, we
designed SurRoL, an RL-centered simulation platform for surgical robot learning
compatible with the da Vinci Research Kit (dVRK). The designed SurRoL
integrates a user-friendly RL library for algorithm development and a real-time
physics engine, which is able to support more PSM/ECM scenarios and more
realistic physical interactions. Ten learning-based surgical tasks are built in
the platform, which are common in the real autonomous surgical execution. We
evaluate SurRoL using RL algorithms in simulation, provide in-depth analysis,
deploy the trained policies on the real dVRK, and show that our SurRoL achieves
better transferability in the real world.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.12242v1,2021-08-27T12:47:19Z,2021-08-27T12:47:19Z,Deep learning models are not robust against noise in clinical text,"Artificial Intelligence (AI) systems are attracting increasing interest in
the medical domain due to their ability to learn complicated tasks that require
human intelligence and expert knowledge. AI systems that utilize
high-performance Natural Language Processing (NLP) models have achieved
state-of-the-art results on a wide variety of clinical text processing
benchmarks. They have even outperformed human accuracy on some tasks. However,
performance evaluation of such AI systems have been limited to accuracy
measures on curated and clean benchmark datasets that may not properly reflect
how robustly these systems can operate in real-world situations. In order to
address this challenge, we introduce and implement a wide variety of
perturbation methods that simulate different types of noise and variability in
clinical text data. While noisy samples produced by these perturbation methods
can often be understood by humans, they may cause AI systems to make erroneous
decisions. Conducting extensive experiments on several clinical text processing
tasks, we evaluated the robustness of high-performance NLP models against
various types of character-level and word-level noise. The results revealed
that the NLP models performance degrades when the input contains small amounts
of noise. This study is a significant step towards exposing vulnerabilities of
AI models utilized in clinical text processing systems. The proposed
perturbation methods can be used in performance evaluation tests to assess how
robustly clinical NLP models can operate on noisy data, in real-world settings.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.08762v1,2021-08-19T16:06:16Z,2021-08-19T16:06:16Z,"Dynamic Difficulty Adjustment in Virtual Reality Exergames through
  Experience-driven Procedural Content Generation","Virtual Reality (VR) games that feature physical activities have been shown
to increase players' motivation to do physical exercise. However, for such
exercises to have a positive healthcare effect, they have to be repeated
several times a week. To maintain player motivation over longer periods of
time, games often employ Dynamic Difficulty Adjustment (DDA) to adapt the
game's challenge according to the player's capabilities. For exercise games,
this is mostly done by tuning specific in-game parameters like the speed of
objects. In this work, we propose to use experience-driven Procedural Content
Generation for DDA in VR exercise games by procedurally generating levels that
match the player's current capabilities. Not only finetuning specific
parameters but creating completely new levels has the potential to decrease
repetition over longer time periods and allows for the simultaneous adaptation
of the cognitive and physical challenge of the exergame. As a proof-of-concept,
we implement an initial prototype in which the player must traverse a maze that
includes several exercise rooms, whereby the generation of the maze is realized
by a neural network. Passing those exercise rooms requires the player to
perform physical activities. To match the player's capabilities, we use Deep
Reinforcement Learning to adjust the structure of the maze and to decide which
exercise rooms to include in the maze. We evaluate our prototype in an
exploratory user study utilizing both biodata and subjective questionnaires.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.07856v1,2021-08-17T20:01:33Z,2021-08-17T20:01:33Z,"OncoPetNet: A Deep Learning based AI system for mitotic figure counting
  on H&E stained whole slide digital images in a large veterinary diagnostic
  lab setting","Background: Histopathology is an important modality for the diagnosis and
management of many diseases in modern healthcare, and plays a critical role in
cancer care. Pathology samples can be large and require multi-site sampling,
leading to upwards of 20 slides for a single tumor, and the human-expert tasks
of site selection and and quantitative assessment of mitotic figures are time
consuming and subjective. Automating these tasks in the setting of a digital
pathology service presents significant opportunities to improve workflow
efficiency and augment human experts in practice. Approach: Multiple
state-of-the-art deep learning techniques for histopathology image
classification and mitotic figure detection were used in the development of
OncoPetNet. Additionally, model-free approaches were used to increase speed and
accuracy. The robust and scalable inference engine leverages Pytorch's
performance optimizations as well as specifically developed speed up techniques
in inference. Results: The proposed system, demonstrated significantly improved
mitotic counting performance for 41 cancer cases across 14 cancer types
compared to human expert baselines. In 21.9% of cases use of OncoPetNet led to
change in tumor grading compared to human expert evaluation. In deployment, an
effective 0.27 min/slide inference was achieved in a high throughput veterinary
diagnostic pathology service across 2 centers processing 3,323 digital whole
slide images daily. Conclusion: This work represents the first successful
automated deployment of deep learning systems for real-time expert-level
performance on important histopathology tasks at scale in a high volume
clinical practice. The resulting impact outlines important considerations for
model development, deployment, clinical decision making, and informs best
practices for implementation of deep learning systems in digital histopathology
practices.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.03660v1,2021-08-17T18:01:12Z,2021-08-17T18:01:12Z,"Developing Medical AI : a cloud-native audio-visual data collection
  study","Designing Artificial Intelligence (AI) solutions that can operate in
real-world situations is a highly complex task. Deploying such solutions in the
medical domain is even more challenging. The promise of using AI to improve
patient care and reduce cost has encouraged many companies to undertake such
endeavours. For our team, the goal has been to improve early identification of
deteriorating patients in the hospital. Identifying patient deterioration in
lower acuity wards relies, to a large degree on the attention and intuition of
clinicians, rather than on the presence of physiological monitoring devices. In
these care areas, an automated tool which could continuously observe patients
and notify the clinical staff of suspected deterioration, would be extremely
valuable. In order to develop such an AI-enabled tool, a large collection of
patient images and audio correlated with corresponding vital signs, past
medical history and clinical outcome would be indispensable. To the best of our
knowledge, no such public or for-pay data set currently exists. This lack of
audio-visual data led to the decision to conduct exactly such study. The main
contributions of this paper are, the description of a protocol for audio-visual
data collection study, a cloud-architecture for efficiently processing and
consuming such data, and the design of a specific data collection device.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.04815v1,2021-08-10T17:58:01Z,2021-08-10T17:58:01Z,"The Effect of the Loss on Generalization: Empirical Study on Synthetic
  Lung Nodule Data","Convolutional Neural Networks (CNNs) are widely used for image classification
in a variety of fields, including medical imaging. While most studies deploy
cross-entropy as the loss function in such tasks, a growing number of
approaches have turned to a family of contrastive learning-based losses. Even
though performance metrics such as accuracy, sensitivity and specificity are
regularly used for the evaluation of CNN classifiers, the features that these
classifiers actually learn are rarely identified and their effect on the
classification performance on out-of-distribution test samples is
insufficiently explored. In this paper, motivated by the real-world task of
lung nodule classification, we investigate the features that a CNN learns when
trained and tested on different distributions of a synthetic dataset with
controlled modes of variation. We show that different loss functions lead to
different features being learned and consequently affect the generalization
ability of the classifier on unseen data. This study provides some important
insights into the design of deep learning solutions for medical imaging tasks.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.04177v1,2021-08-09T17:00:52Z,2021-08-09T17:00:52Z,"Novel scorpion detection system combining computer vision and
  fluorescence","In this work, a fully automatic and real-time system for the detection of
scorpions was developed using computer vision and deep learning techniques.
This system is based on the implementation of a double validation process using
the shape features and the fluorescent characteristics of scorpions when
exposed to ultraviolet (UV) light. The Haar Cascade Classifier (HCC) and YOLO
(You Only Look Once) models have been used and compared as the first mechanism
for the scorpion shape detection. The detection of the fluorescence emitted by
the scorpions under UV light has been used as a second detection mechanism in
order to increase the accuracy and precision of the system. The results
obtained show that the system can accurately and reliably detect the presence
of scorpions. In addition, values obtained of recall of 100% is essential with
the purpose of providing a health security tool. Although the developed system
can only be used at night or in dark environment, where the fluorescence
emitted by the scorpions can be visualized, the nocturnal activity of scorpions
justifies the incorporation of this second validation mechanism.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.03823v7,2022-03-20T02:17:03Z,2021-08-09T05:58:49Z,Towards to Robust and Generalized Medical Image Segmentation Framework,"Deep learning-based computer-aided diagnosis is gradually deployed to review
and analyze medical images. However, this paradigm is restricted in real-world
clinical applications due to the poor robustness and generalization. The issue
is more sinister with a lack of training data. In this paper, we address the
challenge from the transfer learning point of view. Different from the common
setting that transferring knowledge from the natural image domain to the
medical image domain, we find the knowledge from the same domain further boosts
the model robustness and generalization. Therefore, we propose a novel
two-stage framework for robust generalized medical image segmentation. Firstly,
an unsupervised tile-wise autoencoder pretraining architecture is proposed to
learn local and global knowledge. Secondly, the downstream segmentation model
coupled with an auxiliary reconstruction network is designed. The
reconstruction branch encourages the model to capture more general semantic
features. Experiments of lung segmentation on multi chest X-ray datasets are
conducted. Comprehensive results demonstrate the superior robustness of the
proposed framework to corruption and high generalization performance on unseen
datasets, especially under the scenario of the limited training data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.00974v1,2021-08-02T15:22:05Z,2021-08-02T15:22:05Z,"Evaluating Federated Learning for Intrusion Detection in Internet of
  Things: Review and Challenges","The application of Machine Learning (ML) techniques to the well-known
intrusion detection systems (IDS) is key to cope with increasingly
sophisticated cybersecurity attacks through an effective and efficient
detection process. In the context of the Internet of Things (IoT), most
ML-enabled IDS approaches use centralized approaches where IoT devices share
their data with data centers for further analysis. To mitigate privacy concerns
associated with centralized approaches, in recent years the use of Federated
Learning (FL) has attracted a significant interest in different sectors,
including healthcare and transport systems. However, the development of
FL-enabled IDS for IoT is in its infancy, and still requires research efforts
from various areas, in order to identify the main challenges for the deployment
in real-world scenarios. In this direction, our work evaluates a FL-enabled IDS
approach based on a multiclass classifier considering different data
distributions for the detection of different attacks in an IoT scenario. In
particular, we use three different settings that are obtained by partitioning
the recent ToN\_IoT dataset according to IoT devices' IP address and types of
attack. Furthermore, we evaluate the impact of different aggregation functions
according to such setting by using the recent IBMFL framework as FL
implementation. Additionally, we identify a set of challenges and future
directions based on the existing literature and the analysis of our evaluation
results.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.10205v1,2021-08-02T13:09:53Z,2021-08-02T13:09:53Z,"Power transformer faults diagnosis using undestructive methods (Roger
  and IEC) and artificial neural network for dissolved gas analysis applied on
  the functional transformer in the Algerian north-eastern: a comparative study","Nowadays, power transformer aging and failures are viewed with great
attention in power transmission industry. Dissolved gas analysis (DGA) is
classified among the biggest widely used methods used within the context of
asset management policy to detect the incipient faults in their earlier stage
in power transformers. Up to now, several procedures have been employed for the
lecture of DGA results. Among these useful means, we find Key Gases, Rogers
Ratios, IEC Ratios, the historical technique less used today Doernenburg
Ratios, the two types of Duval Pentagons methods, several versions of the Duval
Triangles method and Logarithmic Nomograph. Problem. DGA data extracted from
different units in service served to verify the ability and reliability of
these methods in assessing the state of health of the power transformer. Aim.
An improving the quality of diagnostics of electrical power transformer by
artificial neural network tools based on two conventional methods in the case
of a functional power transformer at S\'etif province in East North of Algeria.
Methodology. Design an inelegant tool for power transformer diagnosis using
neural networks based on traditional methods IEC and Rogers, which allows to
early detection faults, to increase the reliability, of the entire electrical
energy system from transport to consumers and improve a continuity and quality
of service. Results. The solution of the problem was carried out by using
feed-forward back-propagation neural networks implemented in MATLAB-Simulink
environment. Four real power transformers working under different environment
and climate conditions such as: desert, humid, cold were taken into account.
The practical results of the diagnosis of these power transformers by the DGA
are presented. Practical value.....",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.04358v1,2021-07-31T01:54:20Z,2021-07-31T01:54:20Z,"Convolutional Nets for Diabetic Retinopathy Screening in Bangladeshi
  Patients","Diabetes is one of the most prevalent chronic diseases in Bangladesh, and as
a result, Diabetic Retinopathy (DR) is widespread in the population. DR, an eye
illness caused by diabetes, can lead to blindness if it is not identified and
treated in its early stages. Unfortunately, diagnosis of DR requires medically
trained professionals, but Bangladesh has limited specialists in comparison to
its population. Moreover, the screening process is often expensive, prohibiting
many from receiving timely and proper diagnosis. To address the problem, we
introduce a deep learning algorithm which screens for different stages of DR.
We use a state-of-the-art CNN architecture to diagnose patients based on
retinal fundus imagery. This paper is an experimental evaluation of the
algorithm we developed for DR diagnosis and screening specifically for
Bangladeshi patients. We perform this validation study using separate pools of
retinal image data of real patients from a hospital and field studies in
Bangladesh. Our results show that the algorithm is effective at screening
Bangladeshi eyes even when trained on a public dataset which is out of domain,
and can accurately determine the stage of DR as well, achieving an overall
accuracy of 92.27\% and 93.02\% on two validation sets of Bangladeshi eyes. The
results confirm the ability of the algorithm to be used in real clinical
settings and applications due to its high accuracy and classwise metrics. Our
algorithm is implemented in the application Drishti, which is used to screen
for DR in patients living in rural areas in Bangladesh, where access to
professional screening is limited.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.14293v2,2022-02-16T18:56:38Z,2021-07-29T19:39:39Z,"Self-Supervised Transformer for Sparse and Irregularly Sampled
  Multivariate Clinical Time-Series","Multivariate time-series data are frequently observed in critical care
settings and are typically characterized by sparsity (missing information) and
irregular time intervals. Existing approaches for learning representations in
this domain handle these challenges by either aggregation or imputation of
values, which in-turn suppresses the fine-grained information and adds
undesirable noise/overhead into the machine learning model. To tackle this
problem, we propose a Self-supervised Transformer for Time-Series (STraTS)
model which overcomes these pitfalls by treating time-series as a set of
observation triplets instead of using the standard dense matrix representation.
It employs a novel Continuous Value Embedding technique to encode continuous
time and variable values without the need for discretization. It is composed of
a Transformer component with multi-head attention layers which enable it to
learn contextual triplet embeddings while avoiding the problems of recurrence
and vanishing gradients that occur in recurrent architectures. In addition, to
tackle the problem of limited availability of labeled data (which is typically
observed in many healthcare applications), STraTS utilizes self-supervision by
leveraging unlabeled data to learn better representations by using time-series
forecasting as an auxiliary proxy task. Experiments on real-world multivariate
clinical time-series benchmark datasets demonstrate that STraTS has better
prediction performance than state-of-the-art methods for mortality prediction,
especially when labeled data is limited. Finally, we also present an
interpretable version of STraTS which can identify important measurements in
the time-series data. Our data preprocessing and model implementation codes are
available at https://github.com/sindhura97/STraTS.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.11696v1,2021-07-24T22:26:50Z,2021-07-24T22:26:50Z,"A Real Use Case of Semi-Supervised Learning for Mammogram Classification
  in a Local Clinic of Costa Rica","The implementation of deep learning based computer aided diagnosis systems
for the classification of mammogram images can help in improving the accuracy,
reliability, and cost of diagnosing patients. However, training a deep learning
model requires a considerable amount of labeled images, which can be expensive
to obtain as time and effort from clinical practitioners is required. A number
of publicly available datasets have been built with data from different
hospitals and clinics. However, using models trained on these datasets for
later work on images sampled from a different hospital or clinic might result
in lower performance. This is due to the distribution mismatch of the datasets,
which include different patient populations and image acquisition protocols.
The scarcity of labeled data can also bring a challenge towards the application
of transfer learning with models trained using these source datasets. In this
work, a real world scenario is evaluated where a novel target dataset sampled
from a private Costa Rican clinic is used, with few labels and heavily
imbalanced data. The use of two popular and publicly available datasets
(INbreast and CBIS-DDSM) as source data, to train and test the models on the
novel target dataset, is evaluated. The use of the semi-supervised deep
learning approach known as MixMatch, to leverage the usage of unlabeled data
from the target dataset, is proposed and evaluated. In the tests, the
performance of models is extensively measured, using different metrics to
assess the performance of a classifier under heavy data imbalance conditions.
It is shown that the use of semi-supervised deep learning combined with
fine-tuning can provide a meaningful advantage when using scarce labeled
observations. We make available the novel dataset for the benefit of the
community.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.11263v1,2021-07-23T14:22:26Z,2021-07-23T14:22:26Z,Compressed Ultrasound Imaging:from Sub-Nyquist Rates to Super-Resolution,"The multi-billion dollar, worldwide medical ultrasound (US) market continues
to grow annually. Its non-ionizing nature, real-time capabilities and
relatively low cost, compared to other imaging modalities, have led to
significant applications in many different fields, including cardiology,
angiology, obstetrics and emergency medicine. Facilitated by ongoing
innovations, US continues to change rules and norms regarding patient
screening, diagnosis and surgery. This huge and promising market is constantly
driven by new imaging and processing techniques. From 3D images to
sophisticated software, hardware and portability improvements, it is clear that
the status of US as one of the leading medical imaging technologies is ensured
for many years ahead. However, as imaging systems evolve, new engineering
challenges emerge. Acquisition, transmission and processing of huge amounts of
data are common for all ultrasound-based imaging modalities. Moreover,
achieving higher resolution is constantly on demand, as improved diagnosis
could be achieved by better visualization of organs and blood vessels deep
within tissues. In this article, our goal is to motivate further interest and
research in emerging processing techniques, as well as their applications in
medical ultrasound, enabled by recent advancements in signal processing
algorithms and deep learning. We address some of the primary challenges and
potential remedies from a signal processing perspective, by exploiting the
inherent structure of the received US signal.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.11003v1,2021-07-23T02:41:51Z,2021-07-23T02:41:51Z,"Model Selection for Offline Reinforcement Learning: Practical
  Considerations for Healthcare Settings","Reinforcement learning (RL) can be used to learn treatment policies and aid
decision making in healthcare. However, given the need for generalization over
complex state/action spaces, the incorporation of function approximators (e.g.,
deep neural networks) requires model selection to reduce overfitting and
improve policy performance at deployment. Yet a standard validation pipeline
for model selection requires running a learned policy in the actual
environment, which is often infeasible in a healthcare setting. In this work,
we investigate a model selection pipeline for offline RL that relies on
off-policy evaluation (OPE) as a proxy for validation performance. We present
an in-depth analysis of popular OPE methods, highlighting the additional
hyperparameters and computational requirements (fitting/inference of auxiliary
models) when used to rank a set of candidate policies. We compare the utility
of different OPE methods as part of the model selection pipeline in the context
of learning to treat patients with sepsis. Among all the OPE methods we
considered, fitted Q evaluation (FQE) consistently leads to the best validation
ranking, but at a high computational cost. To balance this trade-off between
accuracy of ranking and computational efficiency, we propose a simple two-stage
approach to accelerate model selection by avoiding potentially unnecessary
computation. Our work serves as a practical guide for offline RL model
selection and can help RL practitioners select policies using real-world
datasets. To facilitate reproducibility and future extensions, the code
accompanying this paper is available online at
https://github.com/MLD3/OfflineRL_ModelSelection.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.10230v4,2021-08-13T05:13:51Z,2021-07-21T17:28:46Z,"Multi-institution encrypted medical imaging AI validation without data
  sharing","Adoption of artificial intelligence medical imaging applications is often
impeded by barriers between healthcare systems and algorithm developers given
that access to both private patient data and commercial model IP is important
to perform pre-deployment evaluation. This work investigates a framework for
secure, privacy-preserving and AI-enabled medical imaging inference using
CrypTFlow2, a state-of-the-art end-to-end compiler allowing cryptographically
secure 2-party Computation (2PC) protocols between the machine learning model
vendor and target patient data owner. A common DenseNet-121 chest x-ray
diagnosis model was evaluated on multi-institutional chest radiographic imaging
datasets both with and without CrypTFlow2 on two test sets spanning seven sites
across the US and India, and comprising 1,149 chest x-ray images. We measure
comparative AUROC performance between secure and insecure inference in multiple
pathology classification tasks, and explore model output distributional shifts
and resource constraints introduced by secure model inference. Secure inference
with CrypTFlow2 demonstrated no significant difference in AUROC for all
diagnoses, and model outputs from secure and insecure inference methods were
distributionally equivalent. The use of CrypTFlow2 may allow off-the-shelf
secure 2PC between healthcare systems and AI model vendors for medical imaging,
without changes in performance, and can facilitate scalable pre-deployment
infrastructure for real-world secure model evaluation without exposure to
patient data or model IP.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.08574v1,2021-07-19T01:29:16Z,2021-07-19T01:29:16Z,"A Modulation Layer to Increase Neural Network Robustness Against Data
  Quality Issues","Data quality is a common problem in machine learning, especially in
high-stakes settings such as healthcare. Missing data affects accuracy,
calibration, and feature attribution in complex patterns. Developers often
train models on carefully curated datasets to minimize missing data bias;
however, this reduces the usability of such models in production environments,
such as real-time healthcare records. Making machine learning models robust to
missing data is therefore crucial for practical application. While some
classifiers naturally handle missing data, others, such as deep neural
networks, are not designed for unknown values. We propose a novel neural
network modification to mitigate the impacts of missing data. The approach is
inspired by neuromodulation that is performed by biological neural networks.
Our proposal replaces the fixed weights of a fully-connected layer with a
function of an additional input (reliability score) at each input, mimicking
the ability of cortex to up- and down-weight inputs based on the presence of
other data. The modulation function is jointly learned with the main task using
a multi-layer perceptron. We tested our modulating fully connected layer on
multiple classification, regression, and imputation problems, and it either
improved performance or generated comparable performance to conventional neural
network architectures concatenating reliability to the inputs. Models with
modulating layers were more robust against degradation of data quality by
introducing additional missingness at evaluation time. These results suggest
that explicitly accounting for reduced information quality with a modulating
fully connected layer can enable the deployment of artificial intelligence
systems in real-time settings.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.08189v1,2021-07-17T05:53:24Z,2021-07-17T05:53:24Z,"BEDS-Bench: Behavior of EHR-models under Distributional Shift--A
  Benchmark","Machine learning has recently demonstrated impressive progress in predictive
accuracy across a wide array of tasks. Most ML approaches focus on
generalization performance on unseen data that are similar to the training data
(In-Distribution, or IND). However, real world applications and deployments of
ML rarely enjoy the comfort of encountering examples that are always IND. In
such situations, most ML models commonly display erratic behavior on
Out-of-Distribution (OOD) examples, such as assigning high confidence to wrong
predictions, or vice-versa. Implications of such unusual model behavior are
further exacerbated in the healthcare setting, where patient health can
potentially be put at risk. It is crucial to study the behavior and robustness
properties of models under distributional shift, understand common failure
modes, and take mitigation steps before the model is deployed. Having a
benchmark that shines light upon these aspects of a model is a first and
necessary step in addressing the issue. Recent work and interest in increasing
model robustness in OOD settings have focused more on image modality, while the
Electronic Health Record (EHR) modality is still largely under-explored. We aim
to bridge this gap by releasing BEDS-Bench, a benchmark for quantifying the
behavior of ML models over EHR data under OOD settings. We use two open access,
de-identified EHR datasets to construct several OOD data settings to run tests
on, and measure relevant metrics that characterize crucial aspects of a model's
OOD behavior. We evaluate several learning algorithms under BEDS-Bench and find
that all of them show poor generalization performance under distributional
shift in general. Our results highlight the need and the potential to improve
robustness of EHR models under distributional shift, and BEDS-Bench provides
one way to measure progress towards that goal.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.07502v2,2021-11-10T07:31:56Z,2021-07-15T17:54:36Z,MultiBench: Multiscale Benchmarks for Multimodal Representation Learning,"Learning multimodal representations involves integrating information from
multiple heterogeneous sources of data. It is a challenging yet crucial area
with numerous real-world applications in multimedia, affective computing,
robotics, finance, human-computer interaction, and healthcare. Unfortunately,
multimodal research has seen limited resources to study (1) generalization
across domains and modalities, (2) complexity during training and inference,
and (3) robustness to noisy and missing modalities. In order to accelerate
progress towards understudied modalities and tasks while ensuring real-world
robustness, we release MultiBench, a systematic and unified large-scale
benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6
research areas. MultiBench provides an automated end-to-end machine learning
pipeline that simplifies and standardizes data loading, experimental setup, and
model evaluation. To enable holistic evaluation, MultiBench offers a
comprehensive methodology to assess (1) generalization, (2) time and space
complexity, and (3) modality robustness. MultiBench introduces impactful
challenges for future research, including scalability to large-scale multimodal
datasets and robustness to realistic imperfections. To accompany this
benchmark, we also provide a standardized implementation of 20 core approaches
in multimodal learning. Simply applying methods proposed in different research
areas can improve the state-of-the-art performance on 9/15 datasets. Therefore,
MultiBench presents a milestone in unifying disjoint efforts in multimodal
research and paves the way towards a better understanding of the capabilities
and limitations of multimodal models, all the while ensuring ease of use,
accessibility, and reproducibility. MultiBench, our standardized code, and
leaderboards are publicly available, will be regularly updated, and welcomes
inputs from the community.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.07191v2,2021-07-20T13:42:37Z,2021-07-15T08:36:54Z,Deep Learning based Food Instance Segmentation using Synthetic Data,"In the process of intelligently segmenting foods in images using deep neural
networks for diet management, data collection and labeling for network training
are very important but labor-intensive tasks. In order to solve the
difficulties of data collection and annotations, this paper proposes a food
segmentation method applicable to real-world through synthetic data. To perform
food segmentation on healthcare robot systems, such as meal assistance robot
arm, we generate synthetic data using the open-source 3D graphics software
Blender placing multiple objects on meal plate and train Mask R-CNN for
instance segmentation. Also, we build a data collection system and verify our
segmentation model on real-world food data. As a result, on our real-world
dataset, the model trained only synthetic data is available to segment food
instances that are not trained with 52.2% mask AP@all, and improve performance
by +6.4%p after fine-tuning comparing to the model trained from scratch. In
addition, we also confirm the possibility and performance improvement on the
public dataset for fair analysis. Our code and pre-trained weights are
avaliable online at: https://github.com/gist-ailab/Food-Instance-Segmentation",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.05989v1,2021-07-13T11:17:00Z,2021-07-13T11:17:00Z,"Emotion Recognition for Healthcare Surveillance Systems Using Neural
  Networks: A Survey","Recognizing the patient's emotions using deep learning techniques has
attracted significant attention recently due to technological advancements.
Automatically identifying the emotions can help build smart healthcare centers
that can detect depression and stress among the patients in order to start the
medication early. Using advanced technology to identify emotions is one of the
most exciting topics as it defines the relationships between humans and
machines. Machines learned how to predict emotions by adopting various methods.
In this survey, we present recent research in the field of using neural
networks to recognize emotions. We focus on studying emotions' recognition from
speech, facial expressions, and audio-visual input and show the different
techniques of deploying these algorithms in the real world. These three emotion
recognition techniques can be used as a surveillance system in healthcare
centers to monitor patients. We conclude the survey with a presentation of the
challenges and the related future work to provide an insight into the
applications of using emotion recognition.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.04882v1,2021-07-10T18:00:40Z,2021-07-10T18:00:40Z,"Out of Distribution Detection and Adversarial Attacks on Deep Neural
  Networks for Robust Medical Image Analysis","Deep learning models have become a popular choice for medical image analysis.
However, the poor generalization performance of deep learning models limits
them from being deployed in the real world as robustness is critical for
medical applications. For instance, the state-of-the-art Convolutional Neural
Networks (CNNs) fail to detect adversarial samples or samples drawn
statistically far away from the training distribution. In this work, we
experimentally evaluate the robustness of a Mahalanobis distance-based
confidence score, a simple yet effective method for detecting abnormal input
samples, in classifying malaria parasitized cells and uninfected cells. Results
indicated that the Mahalanobis confidence score detector exhibits improved
performance and robustness of deep learning models, and achieves
stateof-the-art performance on both out-of-distribution (OOD) and adversarial
samples.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.02359v3,2021-07-15T18:35:40Z,2021-07-06T02:44:40Z,"Leveraging Clinical Context for User-Centered Explainability: A Diabetes
  Use Case","Academic advances of AI models in high-precision domains, like healthcare,
need to be made explainable in order to enhance real-world adoption. Our past
studies and ongoing interactions indicate that medical experts can use AI
systems with greater trust if there are ways to connect the model inferences
about patients to explanations that are tied back to the context of use.
Specifically, risk prediction is a complex problem of diagnostic and
interventional importance to clinicians wherein they consult different sources
to make decisions. To enable the adoption of the ever improving AI risk
prediction models in practice, we have begun to explore techniques to
contextualize such models along three dimensions of interest: the patients'
clinical state, AI predictions about their risk of complications, and
algorithmic explanations supporting the predictions. We validate the importance
of these dimensions by implementing a proof-of-concept (POC) in type-2 diabetes
(T2DM) use case where we assess the risk of chronic kidney disease (CKD) - a
common T2DM comorbidity. Within the POC, we include risk prediction models for
CKD, post-hoc explainers of the predictions, and other natural-language modules
which operationalize domain knowledge and CPGs to provide context. With primary
care physicians (PCP) as our end-users, we present our initial results and
clinician feedback in this paper. Our POC approach covers multiple knowledge
sources and clinical scenarios, blends knowledge to explain data and
predictions to PCPs, and received an enthusiastic response from our medical
expert.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.02319v2,2021-08-03T17:12:51Z,2021-07-05T23:32:05Z,"Exploring Deep Learning Methods for Real-Time Surgical Instrument
  Segmentation in Laparoscopy","Minimally invasive surgery is a surgical intervention used to examine the
organs inside the abdomen and has been widely used due to its effectiveness
over open surgery. Due to the hardware improvements such as high definition
cameras, this procedure has significantly improved and new software methods
have demonstrated potential for computer-assisted procedures. However, there
exists challenges and requirements to improve detection and tracking of the
position of the instruments during these surgical procedures. To this end, we
evaluate and compare some popular deep learning methods that can be explored
for the automated segmentation of surgical instruments in laparoscopy, an
important step towards tool tracking. Our experimental results exhibit that the
Dual decoder attention network (DDANet) produces a superior result compared to
other recent deep learning methods. DDANet yields a Dice coefficient of 0.8739
and mean intersection-over-union of 0.8183 for the Robust Medical Instrument
Segmentation (ROBUST-MIS) Challenge 2019 dataset, at a real-time speed of
101.36 frames-per-second that is critical for such procedures.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.13219v1,2021-06-24T17:52:43Z,2021-06-24T17:52:43Z,Towards Understanding and Mitigating Social Biases in Language Models,"As machine learning methods are deployed in real-world settings such as
healthcare, legal systems, and social science, it is crucial to recognize how
they shape social biases and stereotypes in these sensitive decision-making
processes. Among such real-world deployments are large-scale pretrained
language models (LMs) that can be potentially dangerous in manifesting
undesirable representational biases - harmful biases resulting from
stereotyping that propagate negative generalizations involving gender, race,
religion, and other social constructs. As a step towards improving the fairness
of LMs, we carefully define several sources of representational biases before
proposing new benchmarks and metrics to measure them. With these tools, we
propose steps towards mitigating social biases during text generation. Our
empirical results and human evaluation demonstrate effectiveness in mitigating
bias while retaining crucial contextual information for high-fidelity text
generation, thereby pushing forward the performance-fairness Pareto frontier.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.12563v2,2021-06-25T18:08:39Z,2021-06-23T17:43:31Z,Feature Attributions and Counterfactual Explanations Can Be Manipulated,"As machine learning models are increasingly used in critical decision-making
settings (e.g., healthcare, finance), there has been a growing emphasis on
developing methods to explain model predictions. Such \textit{explanations} are
used to understand and establish trust in models and are vital components in
machine learning pipelines. Though explanations are a critical piece in these
systems, there is little understanding about how they are vulnerable to
manipulation by adversaries. In this paper, we discuss how two broad classes of
explanations are vulnerable to manipulation. We demonstrate how adversaries can
design biased models that manipulate model agnostic feature attribution methods
(e.g., LIME \& SHAP) and counterfactual explanations that hill-climb during the
counterfactual search (e.g., Wachter's Algorithm \& DiCE) into
\textit{concealing} the model's biases. These vulnerabilities allow an
adversary to deploy a biased model, yet explanations will not reveal this bias,
thereby deceiving stakeholders into trusting the model. We evaluate the
manipulations on real world data sets, including COMPAS and Communities \&
Crime, and find explanations can be manipulated in practice.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.10352v1,2021-06-18T20:54:18Z,2021-06-18T20:54:18Z,"Semi-supervised Optimal Transport with Self-paced Ensemble for
  Cross-hospital Sepsis Early Detection","The utilization of computer technology to solve problems in medical scenarios
has attracted considerable attention in recent years, which still has great
potential and space for exploration. Among them, machine learning has been
widely used in the prediction, diagnosis and even treatment of Sepsis. However,
state-of-the-art methods require large amounts of labeled medical data for
supervised learning. In real-world applications, the lack of labeled data will
cause enormous obstacles if one hospital wants to deploy a new Sepsis detection
system. Different from the supervised learning setting, we need to use known
information (e.g., from another hospital with rich labeled data) to help build
a model with acceptable performance, i.e., transfer learning. In this paper, we
propose a semi-supervised optimal transport with self-paced ensemble framework
for Sepsis early detection, called SPSSOT, to transfer knowledge from the other
that has rich labeled data. In SPSSOT, we first extract the same clinical
indicators from the source domain (e.g., hospital with rich labeled data) and
the target domain (e.g., hospital with little labeled data), then we combine
the semi-supervised domain adaptation based on optimal transport theory with
self-paced under-sampling to avoid a negative transfer possibly caused by
covariate shift and class imbalance. On the whole, SPSSOT is an end-to-end
transfer learning method for Sepsis early detection which can automatically
select suitable samples from two domains respectively according to the number
of iterations and align feature space of two domains. Extensive experiments on
two open clinical datasets demonstrate that comparing with other methods, our
proposed SPSSOT, can significantly improve the AUC values with only 1% labeled
data in the target domain in two transfer learning scenarios, MIMIC
$rightarrow$ Challenge and Challenge $rightarrow$ MIMIC.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.07875v1,2021-06-15T04:24:59Z,2021-06-15T04:24:59Z,S-LIME: Stabilized-LIME for Model Explanation,"An increasing number of machine learning models have been deployed in domains
with high stakes such as finance and healthcare. Despite their superior
performances, many models are black boxes in nature which are hard to explain.
There are growing efforts for researchers to develop methods to interpret these
black-box models. Post hoc explanations based on perturbations, such as LIME,
are widely used approaches to interpret a machine learning model after it has
been built. This class of methods has been shown to exhibit large instability,
posing serious challenges to the effectiveness of the method itself and harming
user trust. In this paper, we propose S-LIME, which utilizes a hypothesis
testing framework based on central limit theorem for determining the number of
perturbation points needed to guarantee stability of the resulting explanation.
Experiments on both simulated and real world data sets are provided to
demonstrate the effectiveness of our method.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.07708v1,2021-06-14T18:58:09Z,2021-06-14T18:58:09Z,"CathAI: Fully Automated Interpretation of Coronary Angiograms Using
  Neural Networks","Coronary heart disease (CHD) is the leading cause of adult death in the
United States and worldwide, and for which the coronary angiography procedure
is the primary gateway for diagnosis and clinical management decisions. The
standard-of-care for interpretation of coronary angiograms depends upon ad-hoc
visual assessment by the physician operator. However, ad-hoc visual
interpretation of angiograms is poorly reproducible, highly variable and bias
prone. Here we show for the first time that fully-automated angiogram
interpretation to estimate coronary artery stenosis is possible using a
sequence of deep neural network algorithms. The algorithmic pipeline we
developed--called CathAI--achieves state-of-the art performance across the
sequence of tasks required to accomplish automated interpretation of
unselected, real-world angiograms. CathAI (Algorithms 1-2) demonstrated
positive predictive value, sensitivity and F1 score of >=90% to identify the
projection angle overall and >=93% for left or right coronary artery angiogram
detection, the primary anatomic structures of interest. To predict obstructive
coronary artery stenosis (>=70% stenosis), CathAI (Algorithm 4) exhibited an
area under the receiver operating characteristic curve (AUC) of 0.862 (95% CI:
0.843-0.880). When externally validated in a healthcare system in another
country, CathAI AUC was 0.869 (95% CI: 0.830-0.907) to predict obstructive
coronary artery stenosis. Our results demonstrate that multiple purpose-built
neural networks can function in sequence to accomplish the complex series of
tasks required for automated analysis of real-world angiograms. Deployment of
CathAI may serve to increase standardization and reproducibility in coronary
stenosis assessment, while providing a robust foundation to accomplish future
tasks for algorithmic angiographic interpretation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.06908v1,2021-06-13T03:56:59Z,2021-06-13T03:56:59Z,"Domain Generalization on Medical Imaging Classification using Episodic
  Training with Task Augmentation","Medical imaging datasets usually exhibit domain shift due to the variations
of scanner vendors, imaging protocols, etc. This raises the concern about the
generalization capacity of machine learning models. Domain generalization (DG),
which aims to learn a model from multiple source domains such that it can be
directly generalized to unseen test domains, seems particularly promising to
medical imaging community. To address DG, recent model-agnostic meta-learning
(MAML) has been introduced, which transfers the knowledge from previous
training tasks to facilitate the learning of novel testing tasks. However, in
clinical practice, there are usually only a few annotated source domains
available, which decreases the capacity of training task generation and thus
increases the risk of overfitting to training tasks in the paradigm. In this
paper, we propose a novel DG scheme of episodic training with task augmentation
on medical imaging classification. Based on meta-learning, we develop the
paradigm of episodic training to construct the knowledge transfer from episodic
training-task simulation to the real testing task of DG. Motivated by the
limited number of source domains in real-world medical deployment, we consider
the unique task-level overfitting and we propose task augmentation to enhance
the variety during training task generation to alleviate it. With the
established learning framework, we further exploit a novel meta-objective to
regularize the deep embedding of training domains. To validate the
effectiveness of the proposed method, we perform experiments on
histopathological images and abdominal CT images.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.03211v2,2021-06-10T22:04:36Z,2021-06-06T18:57:30Z,Distributed Learning and its Application for Time-Series Prediction,"Extreme events are occurrences whose magnitude and potential cause extensive
damage on people, infrastructure, and the environment. Motivated by the extreme
nature of the current global health landscape, which is plagued by the
coronavirus pandemic, we seek to better understand and model extreme events.
Modeling extreme events is common in practice and plays an important role in
time-series prediction applications. Our goal is to (i) compare and investigate
the effect of some common extreme events modeling methods to explore which
method can be practical in reality and (ii) accelerate the deep learning
training process, which commonly uses deep recurrent neural network (RNN), by
implementing the asynchronous local Stochastic Gradient Descent (SGD) framework
among multiple compute nodes. In order to verify our distributed extreme events
modeling, we evaluate our proposed framework on a stock data set S\&P500, with
a standard recurrent neural network. Our intuition is to explore the (best)
extreme events modeling method which could work well under the distributed deep
learning setting. Moreover, by using asynchronous distributed learning, we aim
to significantly reduce the communication cost among the compute nodes and
central server, which is the main bottleneck of almost all distributed learning
frameworks.
  We implement our proposed work and evaluate its performance on representative
data sets, such as S&P500 stock in $5$-year period. The experimental results
validate the correctness of the design principle and show a significant
training duration reduction upto $8$x, compared to the baseline single compute
node. Our results also show that our proposed work can achieve the same level
of test accuracy, compared to the baseline setting.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.06048v3,2021-11-07T15:41:11Z,2021-06-04T14:30:39Z,"Optimizing Bayesian Recurrent Neural Networks on an FPGA-based
  Accelerator","Neural networks have demonstrated their outstanding performance in a wide
range of tasks. Specifically recurrent architectures based on long-short term
memory (LSTM) cells have manifested excellent capability to model time
dependencies in real-world data. However, standard recurrent architectures
cannot estimate their uncertainty which is essential for safety-critical
applications such as in medicine. In contrast, Bayesian recurrent neural
networks (RNNs) are able to provide uncertainty estimation with improved
accuracy. Nonetheless, Bayesian RNNs are computationally and memory demanding,
which limits their practicality despite their advantages. To address this
issue, we propose an FPGA-based hardware design to accelerate Bayesian
LSTM-based RNNs. To further improve the overall algorithmic-hardware
performance, a co-design framework is proposed to explore the most fitting
algorithmic-hardware configurations for Bayesian RNNs. We conduct extensive
experiments on healthcare applications to demonstrate the improvement of our
design and the effectiveness of our framework. Compared with GPU
implementation, our FPGA-based design can achieve up to 10 times speedup with
nearly 106 times higher energy efficiency. To the best of our knowledge, this
is the first work targeting acceleration of Bayesian RNNs on FPGAs.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.01613v3,2022-03-16T04:05:02Z,2021-06-03T06:20:18Z,"NODE-GAM: Neural Generalized Additive Model for Interpretable Deep
  Learning","Deployment of machine learning models in real high-risk settings (e.g.
healthcare) often depends not only on the model's accuracy but also on its
fairness, robustness, and interpretability. Generalized Additive Models (GAMs)
are a class of interpretable models with a long history of use in these
high-risk domains, but they lack desirable features of deep learning such as
differentiability and scalability. In this work, we propose a neural GAM
(NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that scale well and perform better
than other GAMs on large datasets, while remaining interpretable compared to
other ensemble and deep learning models. We demonstrate that our models find
interesting patterns in the data. Lastly, we show that we improve model
accuracy via self-supervised pre-training, an improvement that is not possible
for non-differentiable GAMs.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.15041v1,2021-05-31T15:26:09Z,2021-05-31T15:26:09Z,"Scorpion detection and classification systems based on computer vision
  and deep learning for health security purposes","In this paper, two novel automatic and real-time systems for the detection
and classification of two genera of scorpions found in La Plata city
(Argentina) were developed using computer vision and deep learning techniques.
The object detection technique was implemented with two different methods, YOLO
(You Only Look Once) and MobileNet, based on the shape features of the
scorpions. High accuracy values of 88% and 91%, and high recall values of 90%
and 97%, have been achieved for both models, respectively, which guarantees
that they can successfully detect scorpions. In addition, the MobileNet method
has been shown to have excellent performance to detect scorpions within an
uncontrolled environment and to perform multiple detections. The MobileNet
model was also used for image classification in order to successfully
distinguish between dangerous scorpion (Tityus) and non-dangerous scorpion
(Bothriurus) with the purpose of providing a health security tool. Applications
for smartphones were developed, with the advantage of the portability of the
systems, which can be used as a help tool for emergency services, or for
biological research purposes. The developed systems can be easily scalable to
other genera and species of scorpions to extend the region where these
applications can be used.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.14052v1,2021-05-28T18:37:12Z,2021-05-28T18:37:12Z,"Targeted Deep Learning: Framework, Methods, and Applications","Deep learning systems are typically designed to perform for a wide range of
test inputs. For example, deep learning systems in autonomous cars are supposed
to deal with traffic situations for which they were not specifically trained.
In general, the ability to cope with a broad spectrum of unseen test inputs is
called generalization. Generalization is definitely important in applications
where the possible test inputs are known but plentiful or simply unknown, but
there are also cases where the possible inputs are few and unlabeled but known
beforehand. For example, medicine is currently interested in targeting
treatments to individual patients; the number of patients at any given time is
usually small (typically one), their diagnoses/responses/... are still unknown,
but their general characteristics (such as genome information, protein levels
in the blood, and so forth) are known before the treatment. We propose to call
deep learning in such applications targeted deep learning. In this paper, we
introduce a framework for targeted deep learning, and we devise and test an
approach for adapting standard pipelines to the requirements of targeted deep
learning. The approach is very general yet easy to use: it can be implemented
as a simple data-preprocessing step. We demonstrate on a variety of real-world
data that our approach can indeed render standard deep learning faster and more
accurate when the test inputs are known beforehand.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.06791v2,2021-10-31T00:08:57Z,2021-05-14T12:16:47Z,"Agree to Disagree: When Deep Learning Models With Identical
  Architectures Produce Distinct Explanations","Deep Learning of neural networks has progressively become more prominent in
healthcare with models reaching, or even surpassing, expert accuracy levels.
However, these success stories are tainted by concerning reports on the lack of
model transparency and bias against some medical conditions or patients'
sub-groups. Explainable methods are considered the gateway to alleviate many of
these concerns. In this study we demonstrate that the generated explanations
are volatile to changes in model training that are perpendicular to the
classification task and model structure. This raises further questions about
trust in deep learning models for healthcare. Mainly, whether the models
capture underlying causal links in the data or just rely on spurious
correlations that are made visible via explanation methods. We demonstrate that
the output of explainability methods on deep neural networks can vary
significantly by changes of hyper-parameters, such as the random seed or how
the training set is shuffled. We introduce a measure of explanation consistency
which we use to highlight the identified problems on the MIMIC-CXR dataset. We
find explanations of identical models but with different training setups have a
low consistency: $\approx$ 33% on average. On the contrary, kernel methods are
robust against any orthogonal changes, with explanation consistency at 94%. We
conclude that current trends in model explanation are not sufficient to
mitigate the risks of deploying models in real life healthcare applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.06442v1,2021-05-13T17:33:28Z,2021-05-13T17:33:28Z,"An Empirical Comparison of Bias Reduction Methods on Real-World Problems
  in High-Stakes Policy Settings","Applications of machine learning (ML) to high-stakes policy settings -- such
as education, criminal justice, healthcare, and social service delivery -- have
grown rapidly in recent years, sparking important conversations about how to
ensure fair outcomes from these systems. The machine learning research
community has responded to this challenge with a wide array of proposed
fairness-enhancing strategies for ML models, but despite the large number of
methods that have been developed, little empirical work exists evaluating these
methods in real-world settings. Here, we seek to fill this research gap by
investigating the performance of several methods that operate at different
points in the ML pipeline across four real-world public policy and social good
problems. Across these problems, we find a wide degree of variability and
inconsistency in the ability of many of these methods to improve model
fairness, but post-processing by choosing group-specific score thresholds
consistently removes disparities, with important implications for both the ML
research community and practitioners deploying machine learning to inform
consequential policy decisions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.01852v2,2021-10-22T15:54:55Z,2021-05-05T03:28:57Z,Deep Learning for Needle Detection in a Cannulation Simulator,"Cannulation for hemodialysis is the act of inserting a needle into a
surgically created vascular access (e.g., an arteriovenous fistula) for the
purpose of dialysis. The main risk associated with cannulation is infiltration,
the puncture of the wall of the vascular access after entry, which can cause
medical complications. Simulator-based training allows clinicians to gain
cannulation experience without putting patients at risk. In this paper, we
propose to use deep-learning-based techniques for detecting, based on video,
whether the needle tip is in or has infiltrated the simulated fistula. Three
categories of deep neural networks are investigated in this work: modified
pre-trained models based on VGG-16 and ResNet-50, light convolutional neural
networks (light CNNs), and convolutional recurrent neural networks (CRNNs).
CRNNs consist of convolutional layers and a long short-term memory (LSTM)
layer. A data set of cannulation experiments was collected and analyzed. The
results show that both the light CNN and the CRNN achieve better performance
than the pre-trained baseline models. The CRNN was implemented in real time on
commodity hardware for use in the cannulation simulator, and the performance
was verified. Deep-learning video analysis is a viable method for detecting
needle state in a low cost cannulation simulator. Our data sets and code are
released at https://github.com/axin233/DL_for_Needle_Detection_Cannulation",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.01401v1,2021-05-04T10:27:20Z,2021-05-04T10:27:20Z,"A Review of Confidentiality Threats Against Embedded Neural Network
  Models","Utilization of Machine Learning (ML) algorithms, especially Deep Neural
Network (DNN) models, becomes a widely accepted standard in many domains more
particularly IoT-based systems. DNN models reach impressive performances in
several sensitive fields such as medical diagnosis, smart transport or security
threat detection, and represent a valuable piece of Intellectual Property. Over
the last few years, a major trend is the large-scale deployment of models in a
wide variety of devices. However, this migration to embedded systems is slowed
down because of the broad spectrum of attacks threatening the integrity,
confidentiality and availability of embedded models. In this review, we cover
the landscape of attacks targeting the confidentiality of embedded DNN models
that may have a major impact on critical IoT systems, with a particular focus
on model extraction and data leakage. We highlight the fact that Side-Channel
Analysis (SCA) is a relatively unexplored bias by which model's confidentiality
can be compromised. Input data, architecture or parameters of a model can be
extracted from power or electromagnetic observations, testifying a real need
from a security point of view.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.14870v1,2021-04-30T09:53:28Z,2021-04-30T09:53:28Z,"Action in Mind: A Neural Network Approach to Action Recognition and
  Segmentation","Recognizing and categorizing human actions is an important task with
applications in various fields such as human-robot interaction, video analysis,
surveillance, video retrieval, health care system and entertainment industry.
This thesis presents a novel computational approach for human action
recognition through different implementations of multi-layer architectures
based on artificial neural networks. Each system level development is designed
to solve different aspects of the action recognition problem including online
real-time processing, action segmentation and the involvement of objects. The
analysis of the experimental results are illustrated and described in six
articles. The proposed action recognition architecture of this thesis is
composed of several processing layers including a preprocessing layer, an
ordered vector representation layer and three layers of neural networks. It
utilizes self-organizing neural networks such as Kohonen feature maps and
growing grids as the main neural network layers. Thus the architecture presents
a biological plausible approach with certain features such as topographic
organization of the neurons, lateral interactions, semi-supervised learning and
the ability to represent high dimensional input space in lower dimensional
maps. For each level of development the system is trained with the input data
consisting of consecutive 3D body postures and tested with generalized input
data that the system has never met before. The experimental results of
different system level developments show that the system performs well with
quite high accuracy for recognizing human actions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.12844v1,2021-04-26T19:47:03Z,2021-04-26T19:47:03Z,"LCS-DIVE: An Automated Rule-based Machine Learning Visualization
  Pipeline for Characterizing Complex Associations in Classification","Machine learning (ML) research has yielded powerful tools for training
accurate prediction models despite complex multivariate associations (e.g.
interactions and heterogeneity). In fields such as medicine, improved
interpretability of ML modeling is required for knowledge discovery,
accountability, and fairness. Rule-based ML approaches such as Learning
Classifier Systems (LCSs) strike a balance between predictive performance and
interpretability in complex, noisy domains. This work introduces the LCS
Discovery and Visualization Environment (LCS-DIVE), an automated LCS model
interpretation pipeline for complex biomedical classification. LCS-DIVE
conducts modeling using a new scikit-learn implementation of ExSTraCS, an LCS
designed to overcome noise and scalability in biomedical data mining yielding
human readable IF:THEN rules as well as feature-tracking scores for each
training sample. LCS-DIVE leverages feature-tracking scores and/or rules to
automatically guide characterization of (1) feature importance (2) underlying
additive, epistatic, and/or heterogeneous patterns of association, and (3)
model-driven heterogeneous instance subgroups via clustering, visualization
generation, and cluster interrogation. LCS-DIVE was evaluated over a diverse
set of simulated genetic and benchmark datasets encoding a variety of complex
multivariate associations, demonstrating its ability to differentiate between
them and then applied to characterize associations within a real-world study of
pancreatic cancer.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.10715v1,2021-04-21T18:28:13Z,2021-04-21T18:28:13Z,Uncertainty-Aware Boosted Ensembling in Multi-Modal Settings,"Reliability of machine learning (ML) systems is crucial in safety-critical
applications such as healthcare, and uncertainty estimation is a widely
researched method to highlight the confidence of ML systems in deployment.
Sequential and parallel ensemble techniques have shown improved performance of
ML systems in multi-modal settings by leveraging the feature sets together. We
propose an uncertainty-aware boosting technique for multi-modal ensembling in
order to focus on the data points with higher associated uncertainty estimates,
rather than the ones with higher loss values. We evaluate this method on
healthcare tasks related to Dementia and Parkinson's disease which involve
real-world multi-modal speech and text data, wherein our method shows an
improved performance. Additional analysis suggests that introducing
uncertainty-awareness into the boosted ensembles decreases the overall entropy
of the system, making it more robust to heteroscedasticity in the data, as well
as better calibrating each of the modalities along with high quality prediction
intervals. We open-source our entire codebase at
https://github.com/usarawgi911/Uncertainty-aware-boosting",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.09876v1,2021-04-20T10:16:04Z,2021-04-20T10:16:04Z,"IIoT-Enabled Health Monitoring for Integrated Heat Pump System Using
  Mixture Slow Feature Analysis","The sustaining evolution of sensing and advancement in communications
technologies have revolutionized prognostics and health management for various
electrical equipment towards data-driven ways. This revolution delivers a
promising solution for the health monitoring problem of heat pump (HP) system,
a vital device widely deployed in modern buildings for heating use, to timely
evaluate its operation status to avoid unexpected downtime. Many HPs were
practically manufactured and installed many years ago, resulting in fewer
sensors available due to technology limitations and cost control at that time.
It raises a dilemma to safeguard HPs at an affordable cost. We propose a hybrid
scheme by integrating industrial Internet-of-Things (IIoT) and intelligent
health monitoring algorithms to handle this challenge. To start with, an IIoT
network is constructed to sense and store measurements. Specifically,
temperature sensors are properly chosen and deployed at the inlet and outlet of
the water tank to measure water temperature. Second, with temperature
information, we propose an unsupervised learning algorithm named mixture slow
feature analysis (MSFA) to timely evaluate the health status of the integrated
HP. Characterized by frequent operation switches of different HPs due to the
variable demand for hot water, various heating patterns with different heating
speeds are observed. Slowness, a kind of dynamics to measure the varying speed
of steady distribution, is properly considered in MSFA for both heating pattern
division and health evaluation. Finally, the efficacy of the proposed method is
verified through a real integrated HP with five connected HPs installed ten
years ago. The experimental results show that MSFA is capable of accurately
identifying health status of the system, especially failure at a preliminary
stage compared to its competing algorithms.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.09699v1,2021-04-20T00:45:01Z,2021-04-20T00:45:01Z,"Domain adaptation based self-correction model for COVID-19 infection
  segmentation in CT images","The capability of generalization to unseen domains is crucial for deep
learning models when considering real-world scenarios. However, current
available medical image datasets, such as those for COVID-19 CT images, have
large variations of infections and domain shift problems. To address this
issue, we propose a prior knowledge driven domain adaptation and a dual-domain
enhanced self-correction learning scheme. Based on the novel learning schemes,
a domain adaptation based self-correction model (DASC-Net) is proposed for
COVID-19 infection segmentation on CT images. DASC-Net consists of a novel
attention and feature domain enhanced domain adaptation model (AFD-DA) to solve
the domain shifts and a self-correction learning process to refine segmentation
results. The innovations in AFD-DA include an image-level activation feature
extractor with attention to lung abnormalities and a multi-level discrimination
module for hierarchical feature domain alignment. The proposed self-correction
learning process adaptively aggregates the learned model and corresponding
pseudo labels for the propagation of aligned source and target domain
information to alleviate the overfitting to noises caused by pseudo labels.
Extensive experiments over three publicly available COVID-19 CT datasets
demonstrate that DASC-Net consistently outperforms state-of-the-art
segmentation, domain shift, and coronavirus infection segmentation methods.
Ablation analysis further shows the effectiveness of the major components in
our model. The DASC-Net enriches the theory of domain adaptation and
self-correction learning in medical imaging and can be generalized to
multi-site COVID-19 infection segmentation on CT images for clinical
deployment.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.09164v1,2021-04-19T09:41:32Z,2021-04-19T09:41:32Z,"HEAR: Human Action Recognition via Neural Networks on Homomorphically
  Encrypted Data","Remote monitoring to support ""aging in place"" is an active area of research.
Advanced computer vision technology based on deep learning can provide near
real-time home monitoring to detect falling and symptoms related to seizure,
and stroke. Affordable webcams, together with cloud computing services (to run
machine learning algorithms), can potentially bring significant social and
health benefits. However, it has not been deployed in practice because of
privacy and security concerns. People may feel uncomfortable sending their
videos of daily activities (with potentially sensitive private information) to
a computing service provider (e.g., on a commercial cloud). In this paper, we
propose a novel strategy to resolve this dilemma by applying fully homomorphic
encryption (FHE) to an alternative representation of human actions (i.e.,
skeleton joints), which guarantees information confidentiality while retaining
high-performance action detection at a low cost. We design an FHE-friendly
neural network for action recognition and present a secure neural network
evaluation strategy to achieve near real-time action detection. Our framework
for private inference achieves an 87.99% recognition accuracy (86.21%
sensitivity and 99.14% specificity in detecting falls) with a latency of 3.1
seconds on real-world datasets. Our evaluation shows that our elaborated and
fine-tuned method reduces the inference latency by 23.81%~74.67% over a
straightforward implementation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.07820v2,2021-04-29T00:11:58Z,2021-04-15T23:38:39Z,"Machine Learning Approaches for Type 2 Diabetes Prediction and Care
  Management","Prediction of diabetes and its various complications has been studied in a
number of settings, but a comprehensive overview of problem setting for
diabetes prediction and care management has not been addressed in the
literature. In this document we seek to remedy this omission in literature with
an encompassing overview of diabetes complication prediction as well as
situating this problem in the context of real world healthcare management. We
illustrate various problems encountered in real world clinical scenarios via
our own experience with building and deploying such models. In this manuscript
we illustrate a Machine Learning (ML) framework for addressing the problem of
predicting Type 2 Diabetes Mellitus (T2DM) together with a solution for risk
stratification, intervention and management. These ML models align with how
physicians think about disease management and mitigation, which comprises these
four steps: Identify, Stratify, Engage, Measure.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.08178v1,2021-04-14T20:32:39Z,2021-04-14T20:32:39Z,"Design of an Efficient, Ease-of-use and Affordable Artificial
  Intelligence based Nucleic Acid Amplification Diagnosis Technology for
  Tuberculosis and Multi-drug Resistant Tuberculosis","Current technologies that facilitate diagnosis for simultaneous detection of
Mycobacterium tuberculosis and its resistance to first-line anti-tuberculosis
drugs (Isoniazid and Rifampicim) are designed for lab-based settings and are
unaffordable for large scale testing implementations. The suitability of a TB
diagnosis instrument, generally required in low-resource settings, to be
implementable in point-of-care last mile public health centres depends on
manufacturing cost, ease-of-use, automation and portability. This paper
discusses a portable, low-cost, machine learning automated Nucleic acid
amplification testing (NAAT) device that employs the use of a smartphone-based
fluorescence detection using novel image processing and chromaticity detection
algorithms. To test the instrument, real time polymerase chain reaction (qPCR)
experiment on cDNA dilution spanning over two concentrations (40 ng/uL and 200
ng/uL) was performed and sensitive detection of multiplexed positive control
assay was verified.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.06910v1,2021-04-14T15:00:39Z,2021-04-14T15:00:39Z,"Towards a framework for evaluating the safety, acceptability and
  efficacy of AI systems for health: an initial synthesis","The potential presented by Artificial Intelligence (AI) for healthcare has
long been recognised by the technical community. More recently, this potential
has been recognised by policymakers, resulting in considerable public and
private investment in the development of AI for healthcare across the globe.
Despite this, excepting limited success stories, real-world implementation of
AI systems into front-line healthcare has been limited. There are numerous
reasons for this, but a main contributory factor is the lack of internationally
accepted, or formalised, regulatory standards to assess AI safety and impact
and effectiveness. This is a well-recognised problem with numerous ongoing
research and policy projects to overcome it. Our intention here is to
contribute to this problem-solving effort by seeking to set out a minimally
viable framework for evaluating the safety, acceptability and efficacy of AI
systems for healthcare. We do this by conducting a systematic search across
Scopus, PubMed and Google Scholar to identify all the relevant literature
published between January 1970 and November 2020 related to the evaluation of:
output performance; efficacy; and real-world use of AI systems, and
synthesising the key themes according to the stages of evaluation: pre-clinical
(theoretical phase); exploratory phase; definitive phase; and post-market
surveillance phase (monitoring). The result is a framework to guide AI system
developers, policymakers, and regulators through a sufficient evaluation of an
AI system designed for use in healthcare.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.16898v1,2021-03-31T08:31:07Z,2021-03-31T08:31:07Z,"Perun: Secure Multi-Stakeholder Machine Learning Framework with GPU
  Support","Confidential multi-stakeholder machine learning (ML) allows multiple parties
to perform collaborative data analytics while not revealing their intellectual
property, such as ML source code, model, or datasets. State-of-the-art
solutions based on homomorphic encryption incur a large performance overhead.
Hardware-based solutions, such as trusted execution environments (TEEs),
significantly improve the performance in inference computations but still
suffer from low performance in training computations, e.g., deep neural
networks model training, because of limited availability of protected memory
and lack of GPU support.
  To address this problem, we designed and implemented Perun, a framework for
confidential multi-stakeholder machine learning that allows users to make a
trade-off between security and performance. Perun executes ML training on
hardware accelerators (e.g., GPU) while providing security guarantees using
trusted computing technologies, such as trusted platform module and integrity
measurement architecture. Less compute-intensive workloads, such as inference,
execute only inside TEE, thus at a lower trusted computing base. The evaluation
shows that during the ML training on CIFAR-10 and real-world medical datasets,
Perun achieved a 161x to 1560x speedup compared to a pure TEE-based approach.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.16223v3,2022-01-11T10:47:28Z,2021-03-30T10:11:09Z,"Towards Real-World Deployment of Reinforcement Learning for Traffic
  Signal Control","Sub-optimal control policies in intersection traffic signal controllers (TSC)
contribute to congestion and lead to negative effects on human health and the
environment. Reinforcement learning (RL) for traffic signal control is a
promising approach to design better control policies and has attracted
considerable research interest in recent years. However, most work done in this
area used simplified simulation environments of traffic scenarios to train
RL-based TSC. To deploy RL in real-world traffic systems, the gap between
simplified simulation environments and real-world applications has to be
closed. Therefore, we propose LemgoRL, a benchmark tool to train RL agents as
TSC in a realistic simulation environment of Lemgo, a medium-sized town in
Germany. In addition to the realistic simulation model, LemgoRL encompasses a
traffic signal logic unit that ensures compliance with all regulatory and
safety requirements. LemgoRL offers the same interface as the wellknown OpenAI
gym toolkit to enable easy deployment in existing research work. To demonstrate
the functionality and applicability of LemgoRL, we train a state-of-the-art
Deep RL algorithm on a CPU cluster utilizing a framework for distributed and
parallel RL and compare its performance with other methods. Our benchmark tool
drives the development of RL algorithms towards real-world applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.15933v1,2021-03-29T20:10:51Z,2021-03-29T20:10:51Z,Learning Under Adversarial and Interventional Shifts,"Machine learning models are often trained on data from one distribution and
deployed on others. So it becomes important to design models that are robust to
distribution shifts. Most of the existing work focuses on optimizing for either
adversarial shifts or interventional shifts. Adversarial methods lack
expressivity in representing plausible shifts as they consider shifts to joint
distributions in the data. Interventional methods allow more expressivity but
provide robustness to unbounded shifts, resulting in overly conservative
models. In this work, we combine the complementary strengths of the two
approaches and propose a new formulation, RISe, for designing robust models
against a set of distribution shifts that are at the intersection of
adversarial and interventional shifts. We employ the distributionally robust
optimization framework to optimize the resulting objective in both supervised
and reinforcement learning settings. Extensive experimentation with synthetic
and real world datasets from healthcare demonstrate the efficacy of the
proposed approach.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.15908v2,2021-03-31T00:46:39Z,2021-03-29T19:38:04Z,"pH-RL: A personalization architecture to bring reinforcement learning to
  health practice","While reinforcement learning (RL) has proven to be the approach of choice for
tackling many complex problems, it remains challenging to develop and deploy RL
agents in real-life scenarios successfully. This paper presents pH-RL
(personalization in e-Health with RL) a general RL architecture for
personalization to bring RL to health practice. pH-RL allows for various levels
of personalization in health applications and allows for online and batch
learning. Furthermore, we provide a general-purpose implementation framework
that can be integrated with various healthcare applications. We describe a
step-by-step guideline for the successful deployment of RL policies in a mobile
application. We implemented our open-source RL architecture and integrated it
with the MoodBuster mobile application for mental health to provide messages to
increase daily adherence to the online therapeutic modules. We then performed a
comprehensive study with human participants over a sustained period. Our
experimental results show that the developed policies learn to select
appropriate actions consistently using only a few days' worth of data.
Furthermore, we empirically demonstrate the stability of the learned policies
during the study.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.15245v3,2021-04-03T14:55:20Z,2021-03-28T23:36:56Z,"Game Theory Based Privacy Preserving Approach for Collaborative Deep
  Learning in IoT","The exponential growth of Internet of Things (IoT) has become a transcending
force in creating innovative smart devices and connected domains including
smart homes, healthcare, transportation and manufacturing. With billions of IoT
devices, there is a huge amount of data continuously being generated,
transmitted, and stored at various points in the IoT architecture. Deep
learning is widely being used in IoT applications to extract useful insights
from IoT data. However, IoT users have security and privacy concerns and prefer
not to share their personal data with third party applications or stakeholders.
In order to address user privacy concerns, Collaborative Deep Learning (CDL)
has been largely employed in data-driven applications which enables multiple
IoT devices to train their models locally on edge gateways. In this chapter, we
first discuss different types of deep learning approaches and how these
approaches can be employed in the IoT domain. We present a privacy-preserving
collaborative deep learning approach for IoT devices which can achieve benefits
from other devices in the system. This learning approach is analyzed from the
behavioral perspective of mobile edge devices using a game-theoretic model. We
analyze the Nash Equilibrium in N-player static game model. We further present
a novel fair collaboration strategy among edge IoT devices using cluster based
approach to solve the CDL game, which enforces mobile edge devices for
cooperation. We also present implementation details and evaluation analysis in
a real-world smart home deployment.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.14734v1,2021-03-26T21:03:33Z,2021-03-26T21:03:33Z,"Fully Automated 2D and 3D Convolutional Neural Networks Pipeline for
  Video Segmentation and Myocardial Infarction Detection in Echocardiography","Cardiac imaging known as echocardiography is a non-invasive tool utilized to
produce data including images and videos, which cardiologists use to diagnose
cardiac abnormalities in general and myocardial infarction (MI) in particular.
Echocardiography machines can deliver abundant amounts of data that need to be
quickly analyzed by cardiologists to help them make a diagnosis and treat
cardiac conditions. However, the acquired data quality varies depending on the
acquisition conditions and the patient's responsiveness to the setup
instructions. These constraints are challenging to doctors especially when
patients are facing MI and their lives are at stake. In this paper, we propose
an innovative real-time end-to-end fully automated model based on convolutional
neural networks (CNN) to detect MI depending on regional wall motion
abnormalities (RWMA) of the left ventricle (LV) from videos produced by
echocardiography. Our model is implemented as a pipeline consisting of a 2D CNN
that performs data preprocessing by segmenting the LV chamber from the apical
four-chamber (A4C) view, followed by a 3D CNN that performs a binary
classification to detect if the segmented echocardiography shows signs of MI.
We trained both CNNs on a dataset composed of 165 echocardiography videos each
acquired from a distinct patient. The 2D CNN achieved an accuracy of 97.18% on
data segmentation while the 3D CNN achieved 90.9% of accuracy, 100% of
precision and 95% of recall on MI detection. Our results demonstrate that
creating a fully automated system for MI detection is feasible and propitious.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.13511v1,2021-03-24T22:33:38Z,2021-03-24T22:33:38Z,Addressing catastrophic forgetting for medical domain expansion,"Model brittleness is a key concern when deploying deep learning models in
real-world medical settings. A model that has high performance at one
institution may suffer a significant decline in performance when tested at
other institutions. While pooling datasets from multiple institutions and
retraining may provide a straightforward solution, it is often infeasible and
may compromise patient privacy. An alternative approach is to fine-tune the
model on subsequent institutions after training on the original institution.
Notably, this approach degrades model performance at the original institution,
a phenomenon known as catastrophic forgetting. In this paper, we develop an
approach to address catastrophic forget-ting based on elastic weight
consolidation combined with modulation of batch normalization statistics under
two scenarios: first, for expanding the domain from one imaging system's data
to another imaging system's, and second, for expanding the domain from a large
multi-institutional dataset to another single institution dataset. We show that
our approach outperforms several other state-of-the-art approaches and provide
theoretical justification for the efficacy of batch normalization modulation.
The results of this study are generally applicable to the deployment of any
clinical deep learning model which requires domain expansion.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.13477v2,2021-03-26T02:49:43Z,2021-03-24T20:52:23Z,A Survey of Multimedia Technologies and Robust Algorithms,"Multimedia technologies are now more practical and deployable in real life,
and the algorithms are widely used in various researching areas such as deep
learning, signal processing, haptics, computer vision, robotics, and medical
multimedia processing. This survey provides an overview of multimedia
technologies and robust algorithms in multimedia data processing, medical
multimedia processing, human facial expression tracking and pose recognition,
and multimedia in education and training. This survey will also analyze and
propose a future research direction based on the overview of current robust
algorithms and multimedia technologies. We want to thank the research and
previous work done by the Multimedia Research Centre (MRC), the University of
Alberta, which is the inspiration and starting point for future research.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.15561v2,2021-04-21T00:13:57Z,2021-03-24T10:54:46Z,"Pyfectious: An individual-level simulator to discover optimal
  containment polices for epidemic diseases","Simulating the spread of infectious diseases in human communities is critical
for predicting the trajectory of an epidemic and verifying various policies to
control the devastating impacts of the outbreak. Many existing simulators are
based on compartment models that divide people into a few subsets and simulate
the dynamics among those subsets using hypothesized differential equations.
However, these models lack the requisite granularity to study the effect of
intelligent policies that influence every individual in a particular way. In
this work, we introduce a simulator software capable of modeling a population
structure and controlling the disease's propagation at an individualistic
level. In order to estimate the confidence of the conclusions drawn from the
simulator, we employ a comprehensive probabilistic approach where the entire
population is constructed as a hierarchical random variable. This approach
makes the inferred conclusions more robust against sampling artifacts and gives
confidence bounds for decisions based on the simulation results. To showcase
potential applications, the simulator parameters are set based on the formal
statistics of the COVID-19 pandemic, and the outcome of a wide range of control
measures is investigated. Furthermore, the simulator is used as the environment
of a reinforcement learning problem to find the optimal policies to control the
pandemic. The obtained experimental results indicate the simulator's
adaptability and capacity in making sound predictions and a successful policy
derivation example based on real-world data. As an exemplary application, our
results show that the proposed policy discovery method can lead to control
measures that produce significantly fewer infected individuals in the
population and protect the health system against saturation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.11381v1,2021-03-21T12:28:46Z,2021-03-21T12:28:46Z,"Quantum Machine Learning with HQC Architectures using non-Classically
  Simulable Feature Maps","Hybrid Quantum-Classical (HQC) Architectures are used in near-term NISQ
Quantum Computers for solving Quantum Machine Learning problems. The quantum
advantage comes into picture due to the exponential speedup offered over
classical computing. One of the major challenges in implementing such
algorithms is the choice of quantum embeddings and the use of a functionally
correct quantum variational circuit. In this paper, we present an application
of QSVM (Quantum Support Vector Machines) to predict if a person will require
mental health treatment in the tech world in the future using the dataset from
OSMI Mental Health Tech Surveys. We achieve this with non-classically simulable
feature maps and prove that NISQ HQC Architectures for Quantum Machine Learning
can be used alternatively to create good performance models in near-term
real-world applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.03472v1,2021-03-05T04:51:02Z,2021-03-05T04:51:02Z,"A Novel Framework for Threat Analysis of Machine Learning-based Smart
  Healthcare Systems","Smart healthcare systems (SHSs) are providing fast and efficient disease
treatment leveraging wireless body sensor networks (WBSNs) and implantable
medical devices (IMDs)-based internet of medical things (IoMT). In addition,
IoMT-based SHSs are enabling automated medication, allowing communication among
myriad healthcare sensor devices. However, adversaries can launch various
attacks on the communication network and the hardware/firmware to introduce
false data or cause data unavailability to the automatic medication system
endangering the patient's life. In this paper, we propose SHChecker, a novel
threat analysis framework that integrates machine learning and formal analysis
capabilities to identify potential attacks and corresponding effects on an
IoMT-based SHS. Our framework can provide us with all potential attack vectors,
each representing a set of sensor measurements to be altered, for an SHS given
a specific set of attack attributes, allowing us to realize the system's
resiliency, thus the insight to enhance the robustness of the model. We
implement SHChecker on a synthetic and a real dataset, which affirms that our
framework can reveal potential attack vectors in an IoMT system. This is a
novel effort to formally analyze supervised and unsupervised machine learning
models for black-box SHS threat analysis.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.12967v3,2022-03-31T09:29:13Z,2021-02-25T16:14:47Z,"A statistical framework for efficient out of distribution detection in
  deep neural networks","Background. Commonly, Deep Neural Networks (DNNs) generalize well on samples
drawn from a distribution similar to that of the training set. However, DNNs'
predictions are brittle and unreliable when the test samples are drawn from a
dissimilar distribution. This is a major concern for deployment in real-world
applications, where such behavior may come at a considerable cost, such as
industrial production lines, autonomous vehicles, or healthcare applications.
Contributions. We frame Out Of Distribution (OOD) detection in DNNs as a
statistical hypothesis testing problem. Tests generated within our proposed
framework combine evidence from the entire network. Unlike previous OOD
detection heuristics, this framework returns a $p$-value for each test sample.
It is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD
for an actual in-distribution sample) for test data. Moreover, this allows to
combine several detectors while maintaining the T1E. Building on this
framework, we suggest a novel OOD procedure based on low-order statistics. Our
method achieves comparable or better results than state-of-the-art methods on
well-accepted OOD benchmarks, without retraining the network parameters or
assuming prior knowledge on the test distribution -- and at a fraction of the
computational cost.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.10618v4,2021-07-19T15:27:17Z,2021-02-21T14:51:18Z,"Towards the Unification and Robustness of Perturbation and Gradient
  Based Explanations","As machine learning black boxes are increasingly being deployed in critical
domains such as healthcare and criminal justice, there has been a growing
emphasis on developing techniques for explaining these black boxes in a post
hoc manner. In this work, we analyze two popular post hoc interpretation
techniques: SmoothGrad which is a gradient based method, and a variant of LIME
which is a perturbation based method. More specifically, we derive explicit
closed form expressions for the explanations output by these two methods and
show that they both converge to the same explanation in expectation, i.e., when
the number of perturbed samples used by these methods is large. We then
leverage this connection to establish other desirable properties, such as
robustness, for these techniques. We also derive finite sample complexity
bounds for the number of perturbations required for these methods to converge
to their expected explanation. Finally, we empirically validate our theory
using extensive experimentation on both synthetic and real world datasets.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.10435v1,2021-02-20T20:17:07Z,2021-02-20T20:17:07Z,"MHDeep: Mental Health Disorder Detection System based on Body-Area and
  Deep Neural Networks","Mental health problems impact quality of life of millions of people around
the world. However, diagnosis of mental health disorders is a challenging
problem that often relies on self-reporting by patients about their behavioral
patterns. Therefore, there is a need for new strategies for diagnosis of mental
health problems. The recent introduction of body-area networks consisting of a
plethora of accurate sensors embedded in smartwatches and smartphones and deep
neural networks (DNNs) points towards a possible solution. However, disease
diagnosis based on WMSs and DNNs, and their deployment on edge devices, remains
a challenging problem. To this end, we propose a framework called MHDeep that
utilizes commercially available WMSs and efficient DNN models to diagnose three
important mental health disorders: schizoaffective, major depressive, and
bipolar. MHDeep uses eight different categories of data obtained from sensors
integrated in a smartwatch and smartphone. Due to limited available data,
MHDeep uses a synthetic data generation module to augment real data with
synthetic data drawn from the same probability distribution. We use the
synthetic dataset to pre-train the DNN models, thus imposing a prior on the
weights. We use a grow-and-prune DNN synthesis approach to learn both the
architecture and weights during the training process. We use three different
data partitions to evaluate the MHDeep models trained with data collected from
74 individuals. We conduct data instance level and patient level evaluations.
MHDeep achieves an average test accuracy of 90.4%, 87.3%, and 82.4%,
respectively, for classifications between healthy instances and schizoaffective
disorder instances, major depressive disorder instances, and bipolar disorder
instances. At the patient level, MHDeep DNNs achieve an accuracy of 100%, 100%,
and 90.0% for the three mental health disorders, respectively.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.09548v2,2021-08-28T19:59:03Z,2021-02-18T18:50:31Z,"Therapeutics Data Commons: Machine Learning Datasets and Tasks for Drug
  Discovery and Development","Therapeutics machine learning is an emerging field with incredible
opportunities for innovatiaon and impact. However, advancement in this field
requires formulation of meaningful learning tasks and careful curation of
datasets. Here, we introduce Therapeutics Data Commons (TDC), the first
unifying platform to systematically access and evaluate machine learning across
the entire range of therapeutics. To date, TDC includes 66 AI-ready datasets
spread across 22 learning tasks and spanning the discovery and development of
safe and effective medicines. TDC also provides an ecosystem of tools and
community resources, including 33 data functions and types of meaningful data
splits, 23 strategies for systematic model evaluation, 17 molecule generation
oracles, and 29 public leaderboards. All resources are integrated and
accessible via an open Python library. We carry out extensive experiments on
selected datasets, demonstrating that even the strongest algorithms fall short
of solving key therapeutics challenges, including real dataset distributional
shifts, multi-scale modeling of heterogeneous data, and robust generalization
to novel data points. We envision that TDC can facilitate algorithmic and
scientific advances and considerably accelerate machine-learning model
development, validation and transition into biomedical and clinical
implementation. TDC is an open-science initiative available at
https://tdcommons.ai.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.07510v2,2021-03-19T10:10:08Z,2021-02-15T12:19:28Z,Plug-and-Play gradient-based denoisers applied to CT image enhancement,"Blur and noise corrupting Computed Tomography (CT) images can hide or distort
small but important details, negatively affecting the diagnosis. In this paper,
we present a novel gradient-based Plug-and-Play algorithm, constructed on the
Half-Quadratic Splitting scheme, and we apply it to restore CT images. In
particular, we consider different schemes encompassing external and internal
denoisers as priors, defined on the image gradient domain. The internal prior
is based on the Total Variation functional. The external denoiser is
implemented by a deep Convolutional Neural Network (CNN) trained on the
gradient domain (and not on the image one, as in state-of-the-art works). We
also prove a general fixed-point convergence theorem under weak assumptions on
both internal and external denoisers. The experiments confirm the effectiveness
of the proposed framework in restoring blurred noisy CT images, both in
simulated and real medical settings. The achieved enhancements in the restored
images are really remarkable, if compared to the results of many
state-of-the-art methods.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.06320v1,2021-02-12T00:27:41Z,2021-02-12T00:27:41Z,On Automatic Parsing of Log Records,"Software log analysis helps to maintain the health of software solutions and
ensure compliance and security. Existing software systems consist of
heterogeneous components emitting logs in various formats. A typical solution
is to unify the logs using manually built parsers, which is laborious.
  Instead, we explore the possibility of automating the parsing task by
employing machine translation (MT). We create a tool that generates synthetic
Apache log records which we used to train recurrent-neural-network-based MT
models. Models' evaluation on real-world logs shows that the models can learn
Apache log format and parse individual log records. The median relative edit
distance between an actual real-world log record and the MT prediction is less
than or equal to 28%. Thus, we show that log parsing using an MT approach is
promising.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.06096v1,2021-02-11T16:21:06Z,2021-02-11T16:21:06Z,"Searching for Pneumothorax in X-Ray Images Using Autoencoded Deep
  Features","Fast diagnosis and treatment of pneumothorax, a collapsed or dropped lung, is
crucial to avoid fatalities. Pneumothorax is typically detected on a chest
X-ray image through visual inspection by experienced radiologists. However, the
detection rate is quite low. Therefore, there is a strong need for automated
detection systems to assist radiologists. Despite the high accuracy levels
generally reported for deep learning classifiers in many applications, they may
not be useful in clinical practice due to the lack of large number of
high-quality labelled images as well as a lack of interpretation possibility.
Alternatively, searching in the archive of past cases to find matching images
may serve as a 'virtual second opinion' through accessing the metadata of
matched evidently diagnosed cases. To use image search as a triaging/diagnosis
tool, all chest X-ray images must first be tagged with identifiers, i.e., deep
features. Then, given a query chest X-ray image, the majority vote among the
top k retrieved images can provide a more explainable output. While image
search can be clinically more viable, its detection performance needs to be
investigated at a scale closer to real-world practice. We combined 3 public
datasets to assemble a repository with more than 550,000 chest X-ray images. We
developed the Autoencoding Thorax Net (short AutoThorax-Net) for image search
in chest radiographs compressing three inputs: the left chest side, the flipped
right side, and the entire chest image. Experimental results show that image
search based on AutoThorax-Net features can achieve high identification rates
providing a path towards real-world deployment. We achieved 92% AUC accuracy
for a semi-automated search in 194,608 images (pneumothorax and normal) and 82%
AUC accuracy for fully automated search in 551,383 images (normal, pneumothorax
and many other chest diseases).",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.01998v1,2021-02-03T10:56:58Z,2021-02-03T10:56:58Z,"Unbox the Black-box for the Medical Explainable AI via Multi-modal and
  Multi-centre Data Fusion: A Mini-Review, Two Showcases and Beyond","Explainable Artificial Intelligence (XAI) is an emerging research topic of
machine learning aimed at unboxing how AI systems' black-box choices are made.
This research field inspects the measures and models involved in
decision-making and seeks solutions to explain them explicitly. Many of the
machine learning algorithms can not manifest how and why a decision has been
cast. This is particularly true of the most popular deep neural network
approaches currently in use. Consequently, our confidence in AI systems can be
hindered by the lack of explainability in these black-box models. The XAI
becomes more and more crucial for deep learning powered applications,
especially for medical and healthcare studies, although in general these deep
neural networks can return an arresting dividend in performance. The
insufficient explainability and transparency in most existing AI systems can be
one of the major reasons that successful implementation and integration of AI
tools into routine clinical practice are uncommon. In this study, we first
surveyed the current progress of XAI and in particular its advances in
healthcare applications. We then introduced our solutions for XAI leveraging
multi-modal and multi-centre data fusion, and subsequently validated in two
showcases following real clinical scenarios. Comprehensive quantitative and
qualitative analyses can prove the efficacy of our proposed XAI solutions, from
which we can envisage successful applications in a broader range of clinical
questions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.00837v1,2021-02-01T13:50:56Z,2021-02-01T13:50:56Z,Machine learning pipeline for battery state of health estimation,"Lithium-ion batteries are ubiquitous in modern day applications ranging from
portable electronics to electric vehicles. Irrespective of the application,
reliable real-time estimation of battery state of health (SOH) by on-board
computers is crucial to the safe operation of the battery, ultimately
safeguarding asset integrity. In this paper, we design and evaluate a machine
learning pipeline for estimation of battery capacity fade - a metric of battery
health - on 179 cells cycled under various conditions. The pipeline estimates
battery SOH with an associated confidence interval by using two parametric and
two non-parametric algorithms. Using segments of charge voltage and current
curves, the pipeline engineers 30 features, performs automatic feature
selection and calibrates the algorithms. When deployed on cells operated under
the fast-charging protocol, the best model achieves a root mean squared percent
error of 0.45\%. This work provides insights into the design of scalable
data-driven models for battery SOH estimation, emphasising the value of
confidence bounds around the prediction. The pipeline methodology combines
experimental data with machine learning modelling and can be generalized to
other critical components that require real-time estimation of SOH.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.10869v2,2021-01-29T06:26:14Z,2021-01-23T09:49:33Z,"A Raspberry Pi-based Traumatic Brain Injury Detection System for
  Single-Channel Electroencephalogram","Traumatic Brain Injury (TBI) is a common cause of death and disability.
However, existing tools for TBI diagnosis are either subjective or require
extensive clinical setup and expertise. The increasing affordability and
reduction in size of relatively high-performance computing systems combined
with promising results from TBI related machine learning research make it
possible to create compact and portable systems for early detection of TBI.
This work describes a Raspberry Pi based portable, real-time data acquisition,
and automated processing system that uses machine learning to efficiently
identify TBI and automatically score sleep stages from a single-channel
Electroen-cephalogram (EEG) signal. We discuss the design, implementation, and
verification of the system that can digitize EEG signal using an Analog to
Digital Converter (ADC) and perform real-time signal classification to detect
the presence of mild TBI (mTBI). We utilize Convolutional Neural Networks (CNN)
and XGBoost based predictive models to evaluate the performance and demonstrate
the versatility of the system to operate with multiple types of predictive
models. We achieve a peak classification accuracy of more than 90% with a
classification time of less than 1 s across 16 s - 64 s epochs for TBI vs
control conditions. This work can enable development of systems suitable for
field use without requiring specialized medical equipment for early TBI
detection applications and TBI research. Further, this work opens avenues to
implement connected, real-time TBI related health and wellness monitoring
systems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.07996v1,2021-01-20T06:47:41Z,2021-01-20T06:47:41Z,SplitSR: An End-to-End Approach to Super-Resolution on Mobile Devices,"Super-resolution (SR) is a coveted image processing technique for mobile apps
ranging from the basic camera apps to mobile health. Existing SR algorithms
rely on deep learning models with significant memory requirements, so they have
yet to be deployed on mobile devices and instead operate in the cloud to
achieve feasible inference time. This shortcoming prevents existing SR methods
from being used in applications that require near real-time latency. In this
work, we demonstrate state-of-the-art latency and accuracy for on-device
super-resolution using a novel hybrid architecture called SplitSR and a novel
lightweight residual block called SplitSRBlock. The SplitSRBlock supports
channel-splitting, allowing the residual blocks to retain spatial information
while reducing the computation in the channel dimension. SplitSR has a hybrid
design consisting of standard convolutional blocks and lightweight residual
blocks, allowing people to tune SplitSR for their computational budget. We
evaluate our system on a low-end ARM CPU, demonstrating both higher accuracy
and up to 5 times faster inference than previous approaches. We then deploy our
model onto a smartphone in an app called ZoomSR to demonstrate the first-ever
instance of on-device, deep learning-based SR. We conducted a user study with
15 participants to have them assess the perceived quality of images that were
post-processed by SplitSR. Relative to bilinear interpolation -- the existing
standard for on-device SR -- participants showed a statistically significant
preference when looking at both images (Z=-9.270, p<0.01) and text (Z=-6.486,
p<0.01).",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.11461v1,2021-01-18T17:10:39Z,2021-01-18T17:10:39Z,Machine learning with limited data,"Thanks to the availability of powerful computing resources, big data and deep
learning algorithms, we have made great progress on computer vision in the last
few years. Computer vision systems begin to surpass humans in some tasks, such
as object recognition, object detection, face recognition and pose estimation.
Lots of computer vision algorithms have been deployed to real world
applications and started to improve our life quality. However, big data and
labels are not always available. Sometimes we only have very limited labeled
data, such as medical images which requires experts to label them. In this
paper, we study few shot image classification, in which we only have very few
labeled data. Machine learning with little data is a big challenge. To tackle
this challenge, we propose two methods and test their effectiveness thoroughly.
One method is to augment image features by mixing the style of these images.
The second method is applying spatial attention to explore the relations
between patches of images. We also find that domain shift is a critical issue
in few shot learning when the training domain and testing domain are different.
So we propose a more realistic cross-domain few-shot learning with unlabeled
data setting, in which some unlabeled data is available in the target domain.
We propose two methods in this setting. Our first method transfers the style
information of the unlabeled target dataset to the samples in the source
dataset and trains a model with stylized images and original images. Our second
method proposes a unified framework to fully utilize all the data. Both of our
methods surpass the baseline method by a large margin.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.06175v1,2021-01-15T15:36:22Z,2021-01-15T15:36:22Z,PaddleSeg: A High-Efficient Development Toolkit for Image Segmentation,"Image Segmentation plays an essential role in computer vision and image
processing with various applications from medical diagnosis to autonomous car
driving. A lot of segmentation algorithms have been proposed for addressing
specific problems. In recent years, the success of deep learning techniques has
tremendously influenced a wide range of computer vision areas, and the modern
approaches of image segmentation based on deep learning are becoming prevalent.
In this article, we introduce a high-efficient development toolkit for image
segmentation, named PaddleSeg. The toolkit aims to help both developers and
researchers in the whole process of designing segmentation models, training
models, optimizing performance and inference speed, and deploying models.
Currently, PaddleSeg supports around 20 popular segmentation models and more
than 50 pre-trained models from real-time and high-accuracy levels. With
modular components and backbone networks, users can easily build over one
hundred models for different requirements. Furthermore, we provide
comprehensive benchmarks and evaluations to show that these segmentation
algorithms trained on our toolkit have more competitive accuracy. Also, we
provide various real industrial applications and practical cases based on
PaddleSeg. All codes and examples of PaddleSeg are available at
https://github.com/PaddlePaddle/PaddleSeg.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.05766v1,2021-01-14T18:17:11Z,2021-01-14T18:17:11Z,Ajalon: Simplifying the Authoring of Wearable Cognitive Assistants,"Wearable Cognitive Assistance (WCA) amplifies human cognition in real time
through a wearable device and low-latency wireless access to edge computing
infrastructure. It is inspired by, and broadens, the metaphor of GPS navigation
tools that provide real-time step-by-step guidance, with prompt error detection
and correction. WCA applications are likely to be transformative in education,
health care, industrial troubleshooting, manufacturing, and many other areas.
Today, WCA application development is difficult and slow, requiring skills in
areas such as machine learning and computer vision that are not widespread
among software developers. This paper describes Ajalon, an authoring toolchain
for WCA applications that reduces the skill and effort needed at each step of
the development pipeline. Our evaluation shows that Ajalon significantly
reduces the effort needed to create new WCA applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.04240v2,2021-01-15T22:46:36Z,2021-01-11T23:58:56Z,"Lesion2Vec: Deep Metric Learning for Few-Shot Multiple Lesions
  Recognition in Wireless Capsule Endoscopy Video","Effective and rapid detection of lesions in the Gastrointestinal tract is
critical to gastroenterologist's response to some life-threatening diseases.
Wireless Capsule Endoscopy (WCE) has revolutionized traditional endoscopy
procedure by allowing gastroenterologists visualize the entire GI tract
non-invasively. Once the tiny capsule is swallowed, it sequentially capture
images of the GI tract at about 2 to 6 frames per second (fps). A single video
can last up to 8 hours producing between 30,000 to 100,000 images. Automating
the detection of frames containing specific lesion in WCE video would relieve
gastroenterologists the arduous task of reviewing the entire video before
making diagnosis. While the WCE produces large volume of images, only about 5\%
of the frames contain lesions that aid the diagnosis process. Convolutional
Neural Network (CNN) based models have been very successful in various image
classification tasks. However, they suffer excessive parameters, are sample
inefficient and rely on very large amount of training data. Deploying a CNN
classifier for lesion detection task will require time-to-time fine-tuning to
generalize to any unforeseen category. In this paper, we propose a metric-based
learning framework followed by a few-shot lesion recognition in WCE data.
Metric-based learning is a meta-learning framework designed to establish
similarity or dissimilarity between concepts while few-shot learning (FSL) aims
to identify new concepts from only a small number of examples. We train a
feature extractor to learn a representation for different small bowel lesions
using metric-based learning. At the testing stage, the category of an unseen
sample is predicted from only a few support examples, thereby allowing the
model to generalize to a new category that has never been seen before. We
demonstrated the efficacy of this method on real patient capsule endoscopy
data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.04086v1,2021-01-11T18:29:50Z,2021-01-11T18:29:50Z,"System Design for a Data-driven and Explainable Customer Sentiment
  Monitor","The most important goal of customer services is to keep the customer
satisfied. However, service resources are always limited and must be
prioritized. Therefore, it is important to identify customers who potentially
become unsatisfied and might lead to escalations. Today this prioritization of
customers is often done manually. Data science on IoT data (esp. log data) for
machine health monitoring, as well as analytics on enterprise data for customer
relationship management (CRM) have mainly been researched and applied
independently. In this paper, we present a framework for a data-driven decision
support system which combines IoT and enterprise data to model customer
sentiment. Such decision support systems can help to prioritize customers and
service resources to effectively troubleshoot problems or even avoid them. The
framework is applied in a real-world case study with a major medical device
manufacturer. This includes a fully automated and interpretable machine
learning pipeline designed to meet the requirements defined with domain experts
and end users. The overall framework is currently deployed, learns and
evaluates predictive models from terabytes of IoT and enterprise data to
actively monitor the customer sentiment for a fleet of thousands of high-end
medical devices. Furthermore, we provide an anonymized industrial benchmark
dataset for the research community.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.03989v2,2021-11-29T17:41:07Z,2021-01-11T15:54:48Z,Technology Readiness Levels for Machine Learning Systems,"The development and deployment of machine learning (ML) systems can be
executed easily with modern tools, but the process is typically rushed and
means-to-an-end. The lack of diligence can lead to technical debt, scope creep
and misaligned objectives, model misuse and failures, and expensive
consequences. Engineering systems, on the other hand, follow well-defined
processes and testing standards to streamline development for high-quality,
reliable results. The extreme is spacecraft systems, where mission critical
measures and robustness are ingrained in the development process. Drawing on
experience in both spacecraft engineering and ML (from research through product
across domain areas), we have developed a proven systems engineering approach
for machine learning development and deployment. Our ""Machine Learning
Technology Readiness Levels"" (MLTRL) framework defines a principled process to
ensure robust, reliable, and responsible systems while being streamlined for ML
workflows, including key distinctions from traditional software engineering.
Even more, MLTRL defines a lingua franca for people across teams and
organizations to work collaboratively on artificial intelligence and machine
learning technologies. Here we describe the framework and elucidate it with
several real world use-cases of developing ML methods from basic research
through productization and deployment, in areas such as medical diagnostics,
consumer computer vision, satellite imagery, and particle physics.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.02780v1,2021-01-07T22:01:30Z,2021-01-07T22:01:30Z,"SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things
  and Cyber-Physical Systems based on Machine Learning","Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are
increasingly being deployed across multiple functionalities, ranging from
healthcare devices and wearables to critical infrastructures, e.g., nuclear
power plants, autonomous vehicles, smart cities, and smart homes. These devices
are inherently not secure across their comprehensive software, hardware, and
network stacks, thus presenting a large attack surface that can be exploited by
hackers. In this article, we present an innovative technique for detecting
unknown system vulnerabilities, managing these vulnerabilities, and improving
incident response when such vulnerabilities are exploited. The novelty of this
approach lies in extracting intelligence from known real-world CPS/IoT attacks,
representing them in the form of regular expressions, and employing machine
learning (ML) techniques on this ensemble of regular expressions to generate
new attack vectors and security vulnerabilities. Our results show that 10 new
attack vectors and 122 new vulnerability exploits can be successfully generated
that have the potential to exploit a CPS or an IoT ecosystem. The ML
methodology achieves an accuracy of 97.4% and enables us to predict these
attacks efficiently with an 87.2% reduction in the search space. We demonstrate
the application of our method to the hacking of the in-vehicle network of a
connected car. To defend against the known attacks and possible novel exploits,
we discuss a defense-in-depth mechanism for various classes of attacks and the
classification of data targeted by such attacks. This defense mechanism
optimizes the cost of security measures based on the sensitivity of the
protected resource, thus incentivizing its adoption in real-world CPS/IoT by
cybersecurity practitioners.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.03170v2,2021-09-17T17:17:45Z,2021-01-07T20:18:43Z,"BDNNSurv: Bayesian deep neural networks for survival analysis using
  pseudo values","There has been increasing interest in modeling survival data using deep
learning methods in medical research. In this paper, we proposed a Bayesian
hierarchical deep neural networks model for modeling and prediction of survival
data. Compared with previously studied methods, the new proposal can provide
not only point estimate of survival probability but also quantification of the
corresponding uncertainty, which can be of crucial importance in predictive
modeling and subsequent decision making. The favorable statistical properties
of point and uncertainty estimates were demonstrated by simulation studies and
real data analysis. The Python code implementing the proposed approach was
provided.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.14704v2,2021-12-02T13:58:01Z,2020-12-29T11:10:12Z,"Advances in deep learning methods for pavement surface crack detection
  and identification with visible light visual images","Compared to NDT and health monitoring method for cracks in engineering
structures, surface crack detection or identification based on visible light
images is non-contact, with the advantages of fast speed, low cost and high
precision. Firstly, typical pavement (concrete also) crack public data sets
were collected, and the characteristics of sample images as well as the random
variable factors, including environmental, noise and interference etc., were
summarized. Subsequently, the advantages and disadvantages of three main crack
identification methods (i.e., hand-crafted feature engineering, machine
learning, deep learning) were compared. Finally, from the aspects of model
architecture, testing performance and predicting effectiveness, the development
and progress of typical deep learning models, including self-built CNN,
transfer learning(TL) and encoder-decoder(ED), which can be easily deployed on
embedded platform, were reviewed. The benchmark test shows that: 1) It has been
able to realize real-time pixel-level crack identification on embedded
platform: the entire crack detection average time cost of an image sample is
less than 100ms, either using the ED method (i.e., FPCNet) or the TL method
based on InceptionV3. It can be reduced to less than 10ms with TL method based
on MobileNet (a lightweight backbone base network). 2) In terms of accuracy, it
can reach over 99.8% on CCIC which is easily identified by human eyes. On
SDNET2018, some samples of which are difficult to be identified, FPCNet can
reach 97.5%, while TL method is close to 96.1%.
  To the best of our knowledge, this paper for the first time comprehensively
summarizes the pavement crack public data sets, and the performance and
effectiveness of surface crack detection and identification deep learning
methods for embedded platform, are reviewed and evaluated.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.13968v1,2020-12-27T16:03:32Z,2020-12-27T16:03:32Z,"Detecting Medical Misinformation on Social Media Using Multimodal Deep
  Learning","In 2019, outbreaks of vaccine-preventable diseases reached the highest number
in the US since 1992. Medical misinformation, such as antivaccine content
propagating through social media, is associated with increases in vaccine delay
and refusal. Our overall goal is to develop an automatic detector for
antivaccine messages to counteract the negative impact that antivaccine
messages have on the public health. Very few extant detection systems have
considered multimodality of social media posts (images, texts, and hashtags),
and instead focus on textual components, despite the rapid growth of
photo-sharing applications (e.g., Instagram). As a result, existing systems are
not sufficient for detecting antivaccine messages with heavy visual components
(e.g., images) posted on these newer platforms. To solve this problem, we
propose a deep learning network that leverages both visual and textual
information. A new semantic- and task-level attention mechanism was created to
help our model to focus on the essential contents of a post that signal
antivaccine messages. The proposed model, which consists of three branches, can
generate comprehensive fused features for predictions. Moreover, an ensemble
method is proposed to further improve the final prediction accuracy. To
evaluate the proposed model's performance, a real-world social media dataset
that consists of more than 30,000 samples was collected from Instagram between
January 2016 and October 2019. Our 30 experiment results demonstrate that the
final network achieves above 97% testing accuracy and outperforms other
relevant models, demonstrating that it can detect a large amount of antivaccine
messages posted daily. The implementation code is available at
https://github.com/wzhings/antivaccine_detection.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.12794v1,2020-12-23T16:56:28Z,2020-12-23T16:56:28Z,"NeuXus: A Biosignal Processing and Classification Pipeline for Real-Time
  Brain-Computer Interaction","In the last few years,Brain-Computer Interfaces (BCIs) have progressed as an
emerging research area in the fields of human-computer interaction and
interactive systems.This is primarily due to the introduction of low-cost
electroencephalographic (EEG) systems that render BCI technology accessible for
non-medical research but also due to the advancements of signal processing and
machine learning methods.Consequently,BCIs could provide a wide new range of
possibilities in the way users interact with a computer system (e.g.,
neuroadaptive interfaces).However,major challenges must still be addressed for
BCI systems to mature into an established communication medium for effective
human-computer interaction. One of the major challenges involves the easy
integration of real-time processing pipelines with portable EEG systems for an
out-of-the-lab use. To date, despite the amount of options current open-source
tools provide, most toolboxes focus mainly in extending the processing and
classification methods but lack on the ability to provide an easy-to-design yet
extensible architecture for ubiquitous use.Here, we present NeuXus, a modular
toolbox in Python for real-time biosignal processing and pipeline design.NeuXus
is open-source and platform independent,providing high-level implementation of
processing pipelines for easy BCI design and deployment.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.11952v1,2020-12-22T12:11:42Z,2020-12-22T12:11:42Z,"A Feasibility study for Deep learning based automated brain tumor
  segmentation using Magnetic Resonance Images","Deep learning algorithms have accounted for the rapid acceleration of
research in artificial intelligence in medical image analysis, interpretation,
and segmentation with many potential applications across various sub
disciplines in medicine. However, only limited number of research which
investigates these application scenarios, are deployed into the clinical sector
for the evaluation of the real requirement and the practical challenges of the
model deployment. In this research, a deep convolutional neural network (CNN)
based classification network and Faster RCNN based localization network were
developed for brain tumor MR image classification and tumor localization. A
typical edge detection algorithm called Prewitt was used for tumor segmentation
task, based on the output of the tumor localization. Overall performance of the
proposed tumor segmentation architecture, was analyzed using objective quality
parameters including Accuracy, Boundary Displacement Error (BDE), Dice score
and confidence interval. A subjective quality assessment of the model was
conducted based on the Double Stimulus Impairment Scale (DSIS) protocol using
the input of medical expertise. It was observed that the confidence level of
our segmented output was in a similar range to that of experts. Also, the
Neurologists have rated the output of our model as highly accurate
segmentation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.03889v2,2021-02-16T13:44:56Z,2020-12-21T10:25:27Z,A Comprehensive Survey of 6G Wireless Communications,"While fifth-generation (5G) communications are being rolled out worldwide,
sixth-generation (6G) communications have attracted much attention from both
the industry and the academia. Compared with 5G, 6G will have a wider frequency
band, higher transmission rate, spectrum efficiency, greater connection
capacity, shorter delay, broader coverage, and more robust anti-interference
capability to satisfy various network requirements. This survey presents an
insightful understanding of 6G wireless communications by introducing
requirements, features, critical technologies, challenges, and applications.
First, we give an overview of 6G from perspectives of technologies, security
and privacy, and applications. Subsequently, we introduce various 6G
technologies and their existing challenges in detail, e.g., artificial
intelligence (AI), intelligent surfaces, THz, space-air-ground-sea integrated
network, cell-free massive MIMO, etc. Because of these technologies, 6G is
expected to outperform existing wireless communication systems regarding the
transmission rate, latency, global coverage, etc. Next, we discuss security and
privacy techniques that can be applied to protect data in 6G. Since edge
devices are expected to gain popularity soon, the vast amount of generated data
and frequent data exchange make the leakage of data easily. Finally, we predict
real-world applications built on the technologies and features of 6G; for
example, smart healthcare, smart city, and smart manufacturing will be
implemented by taking advantage of AI.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.10853v1,2020-12-20T06:06:08Z,2020-12-20T06:06:08Z,eTREE: Learning Tree-structured Embeddings,"Matrix factorization (MF) plays an important role in a wide range of machine
learning and data mining models. MF is commonly used to obtain item embeddings
and feature representations due to its ability to capture correlations and
higher-order statistical dependencies across dimensions. In many applications,
the categories of items exhibit a hierarchical tree structure. For instance,
human diseases can be divided into coarse categories, e.g., bacterial, and
viral. These categories can be further divided into finer categories, e.g.,
viral infections can be respiratory, gastrointestinal, and exanthematous viral
diseases. In e-commerce, products, movies, books, etc., are grouped into
hierarchical categories, e.g., clothing items are divided by gender, then by
type (formal, casual, etc.). While the tree structure and the categories of the
different items may be known in some applications, they have to be learned
together with the embeddings in many others. In this work, we propose eTREE, a
model that incorporates the (usually ignored) tree structure to enhance the
quality of the embeddings. We leverage the special uniqueness properties of
Nonnegative MF (NMF) to prove identifiability of eTREE. The proposed model not
only exploits the tree structure prior, but also learns the hierarchical
clustering in an unsupervised data-driven fashion. We derive an efficient
algorithmic solution and a scalable implementation of eTREE that exploits
parallel computing, computation caching, and warm start strategies. We showcase
the effectiveness of eTREE on real data from various application domains:
healthcare, recommender systems, and education. We also demonstrate the
meaningfulness of the tree obtained from eTREE by means of domain experts
interpretation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.10020v1,2020-12-18T02:37:49Z,2020-12-18T02:37:49Z,"EVA: Generating Longitudinal Electronic Health Records Using Conditional
  Variational Autoencoders","Researchers require timely access to real-world longitudinal electronic
health records (EHR) to develop, test, validate, and implement machine learning
solutions that improve the quality and efficiency of healthcare. In contrast,
health systems value deeply patient privacy and data security. De-identified
EHRs do not adequately address the needs of health systems, as de-identified
data are susceptible to re-identification and its volume is also limited.
Synthetic EHRs offer a potential solution. In this paper, we propose EHR
Variational Autoencoder (EVA) for synthesizing sequences of discrete EHR
encounters (e.g., clinical visits) and encounter features (e.g., diagnoses,
medications, procedures). We illustrate that EVA can produce realistic EHR
sequences, account for individual differences among patients, and can be
conditioned on specific disease conditions, thus enabling disease-specific
studies. We design efficient, accurate inference algorithms by combining
stochastic gradient Markov Chain Monte Carlo with amortized variational
inference. We assess the utility of the methods on large real-world EHR
repositories containing over 250, 000 patients. Our experiments, which include
user studies with knowledgeable clinicians, indicate the generated EHR
sequences are realistic. We confirmed the performance of predictive models
trained on the synthetic data are similar with those trained on real EHRs.
Additionally, our findings indicate that augmenting real data with synthetic
EHRs results in the best predictive performance - improving the best baseline
by as much as 8% in top-20 recall.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.07278v1,2020-12-14T05:54:55Z,2020-12-14T05:54:55Z,"Learning how to approve updates to machine learning algorithms in
  non-stationary settings","Machine learning algorithms in healthcare have the potential to continually
learn from real-world data generated during healthcare delivery and adapt to
dataset shifts. As such, the FDA is looking to design policies that can
autonomously approve modifications to machine learning algorithms while
maintaining or improving the safety and effectiveness of the deployed models.
However, selecting a fixed approval strategy, a priori, can be difficult
because its performance depends on the stationarity of the data and the quality
of the proposed modifications. To this end, we investigate a
learning-to-approve approach (L2A) that uses accumulating monitoring data to
learn how to approve modifications. L2A defines a family of strategies that
vary in their ""optimism''---where more optimistic policies have faster approval
rates---and searches over this family using an exponentially weighted average
forecaster. To control the cumulative risk of the deployed model, we give L2A
the option to abstain from making a prediction and incur some fixed abstention
cost instead. We derive bounds on the average risk of the model deployed by
L2A, assuming the distributional shifts are smooth. In simulation studies and
empirical analyses, L2A tailors the level of optimism for each problem-setting:
It learns to abstain when performance drops are common and approve beneficial
modifications quickly when the distribution is stable.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.06448v2,2020-12-19T10:02:04Z,2020-12-11T16:16:32Z,"An Unsupervised Reconstruction Method For Low-Dose CT Using Deep
  Generative Regularization Prior","Low-dose CT imaging requires reconstruction from noisy indirect measurements
which can be defined as an ill-posed linear inverse problem. In addition to
conventional FBP method in CT imaging, recent compressed sensing based methods
exploit handcrafted priors which are mostly simplistic and hard to determine.
More recently, deep learning (DL) based methods have become popular in medical
imaging field. In CT imaging, DL based methods try to learn a function that
maps low-dose images to normal-dose images. Although the results of these
methods are promising, their success mostly depends on the availability of
high-quality massive datasets. In this study, we proposed a method that does
not require any training data or a learning process. Our method exploits such
an approach that deep convolutional neural networks (CNNs) generate patterns
easier than the noise, therefore randomly initialized generative neural
networks can be suitable priors to be used in regularizing the reconstruction.
In the experiments, the proposed method is implemented with different loss
function variants. Both analytical CT phantoms and real-world CT images are
used with different views. Conventional FBP method, a popular iterative method
(SART), and TV regularized SART are used in the comparisons. We demonstrated
that our method with different loss function variants outperforms the other
methods both qualitatively and quantitatively.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.06354v1,2020-12-10T13:56:00Z,2020-12-10T13:56:00Z,Privacy-preserving medical image analysis,"The utilisation of artificial intelligence in medicine and healthcare has led
to successful clinical applications in several domains. The conflict between
data usage and privacy protection requirements in such systems must be resolved
for optimal results as well as ethical and legal compliance. This calls for
innovative solutions such as privacy-preserving machine learning (PPML). We
present PriMIA (Privacy-preserving Medical Image Analysis), a software
framework designed for PPML in medical imaging. In a real-life case study we
demonstrate significantly better classification performance of a securely
aggregated federated learning model compared to human experts on unseen
datasets. Furthermore, we show an inference-as-a-service scenario for
end-to-end encrypted diagnosis, where neither the data nor the model are
revealed. Lastly, we empirically evaluate the framework's security against a
gradient-based model inversion attack and demonstrate that no usable
information can be recovered from the model.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.05410v1,2020-12-10T02:08:47Z,2020-12-10T02:08:47Z,Artificial Intelligence at the Edge,"The Internet of Things (IoT) and edge computing applications aim to support a
variety of societal needs, including the global pandemic situation that the
entire world is currently experiencing and responses to natural disasters.
  The need for real-time interactive applications such as immersive video
conferencing, augmented/virtual reality, and autonomous vehicles, in education,
healthcare, disaster recovery and other domains, has never been higher. At the
same time, there have been recent technological breakthroughs in highly
relevant fields such as artificial intelligence (AI)/machine learning (ML),
advanced communication systems (5G and beyond), privacy-preserving
computations, and hardware accelerators. 5G mobile communication networks
increase communication capacity, reduce transmission latency and error, and
save energy -- capabilities that are essential for new applications. The
envisioned future 6G technology will integrate many more technologies,
including for example visible light communication, to support groundbreaking
applications, such as holographic communications and high precision
manufacturing. Many of these applications require computations and analytics
close to application end-points: that is, at the edge of the network, rather
than in a centralized cloud. AI techniques applied at the edge have tremendous
potential both to power new applications and to need more efficient operation
of edge infrastructure. However, it is critical to understand where to deploy
AI systems within complex ecosystems consisting of advanced applications and
the specific real-time requirements towards AI systems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.03426v2,2021-09-27T05:48:50Z,2020-12-07T02:47:36Z,"Deep Learning Based Signal Enhancement of Low-Resolution Accelerometer
  for Fall Detection Systems","In the last two decades, fall detection (FD) systems have been developed as a
popular assistive technology. Such systems automatically detect critical fall
events and immediately alert medical professionals or caregivers. To support
long-term FD services, various power-saving strategies have been implemented.
Among them, a reduced sampling rate is a common approach for an
energy-efficient system in the real-world. However, the performance of FD
systems is diminished owing to low-resolution (LR) accelerometer signals. To
improve the detection accuracy with LR accelerometer signals, several technical
challenges must be considered, including misalignment, mismatch of effective
features, and the degradation effects. In this work, a deep-learning-based
accelerometer signal enhancement (ASE) model is proposed to improve the
detection performance of LR-FD systems. This proposed model reconstructs
high-resolution (HR) signals from the LR signals by learning the relationship
between the LR and HR signals. The results show that the FD system using
support vector machine and the proposed ASE model at an extremely low sampling
rate (sampling rate < 2 Hz) achieved 97.34% and 90.52% accuracies in the
SisFall and FallAllD datasets, respectively, while those without ASE models
only achieved 95.92% and 87.47% accuracies in the SisFall and FallAllD
datasets, respectively. This study demonstrates that the ASE model helps the FD
systems tackle the technical challenges of LR signals and achieve better
detection performance.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.03173v2,2021-09-07T19:18:12Z,2020-12-06T03:41:51Z,"Large-scale Robust Deep AUC Maximization: A New Surrogate Loss and
  Empirical Studies on Medical Image Classification","Deep AUC Maximization (DAM) is a new paradigm for learning a deep neural
network by maximizing the AUC score of the model on a dataset. Most previous
works of AUC maximization focus on the perspective of optimization by designing
efficient stochastic algorithms, and studies on generalization performance of
large-scale DAM on difficult tasks are missing. In this work, we aim to make
DAM more practical for interesting real-world applications (e.g., medical image
classification). First, we propose a new margin-based min-max surrogate loss
function for the AUC score (named as AUC min-max-margin loss or simply AUC
margin loss for short). It is more robust than the commonly used AUC square
loss, while enjoying the same advantage in terms of large-scale stochastic
optimization. Second, we conduct extensive empirical studies of our DAM method
on four difficult medical image classification tasks, namely (i) classification
of chest x-ray images for identifying many threatening diseases, (ii)
classification of images of skin lesions for identifying melanoma, (iii)
classification of mammogram for breast cancer screening, and (iv)
classification of microscopic images for identifying tumor tissue. Our studies
demonstrate that the proposed DAM method improves the performance of optimizing
cross-entropy loss by a large margin, and also achieves better performance than
optimizing the existing AUC square loss on these medical image classification
tasks. Specifically, our DAM method has achieved the 1st place on Stanford
CheXpert competition on Aug. 31, 2020. To the best of our knowledge, this is
the first work that makes DAM succeed on large-scale medical image datasets. We
also conduct extensive ablation studies to demonstrate the advantages of the
new AUC margin loss over the AUC square loss on benchmark datasets. The
proposed method is implemented in our open-sourced library LibAUC
(www.libauc.org).",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.02308v2,2021-03-08T10:30:50Z,2020-12-03T22:18:24Z,Concept-based model explanations for Electronic Health Records,"Recurrent Neural Networks (RNNs) are often used for sequential modeling of
adverse outcomes in electronic health records (EHRs) due to their ability to
encode past clinical states. These deep, recurrent architectures have displayed
increased performance compared to other modeling approaches in a number of
tasks, fueling the interest in deploying deep models in clinical settings. One
of the key elements in ensuring safe model deployment and building user trust
is model explainability. Testing with Concept Activation Vectors (TCAV) has
recently been introduced as a way of providing human-understandable
explanations by comparing high-level concepts to the network's gradients. While
the technique has shown promising results in real-world imaging applications,
it has not been applied to structured temporal inputs. To enable an application
of TCAV to sequential predictions in the EHR, we propose an extension of the
method to time series data. We evaluate the proposed approach on an open EHR
benchmark from the intensive care unit, as well as synthetic data where we are
able to better isolate individual effects.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.02048v1,2020-12-03T16:28:45Z,2020-12-03T16:28:45Z,"Ethical Testing in the Real World: Evaluating Physical Testing of
  Adversarial Machine Learning","This paper critically assesses the adequacy and representativeness of
physical domain testing for various adversarial machine learning (ML) attacks
against computer vision systems involving human subjects. Many papers that
deploy such attacks characterize themselves as ""real world."" Despite this
framing, however, we found the physical or real-world testing conducted was
minimal, provided few details about testing subjects and was often conducted as
an afterthought or demonstration. Adversarial ML research without
representative trials or testing is an ethical, scientific, and health/safety
issue that can cause real harms. We introduce the problem and our methodology,
and then critique the physical domain testing methodologies employed by papers
in the field. We then explore various barriers to more inclusive physical
testing in adversarial ML and offer recommendations to improve such testing
notwithstanding these challenges.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.01153v1,2020-12-02T12:53:19Z,2020-12-02T12:53:19Z,Towards Intelligent Reconfigurable Wireless Physical Layer (PHY),"Next-generation wireless networks are getting significant attention because
they promise 10-factor enhancement in mobile broadband along with the potential
to enable new heterogeneous services. Services include massive machine type
communications desired for Industrial 4.0 along with ultra-reliable low latency
services for remote healthcare and vehicular communications. In this paper, we
present the design of an intelligent and reconfigurable physical layer (PHY) to
bring these services to reality. First, we design and implement the
reconfigurable PHY via a hardware-software co-design approach on system-on-chip
consisting of the ARM processor and field-programmable gate array (FPGA). The
reconfigurable PHY is then made intelligent by augmenting it with online
machine learning (OML) based decision-making algorithm. Such PHY can learn the
environment (for example, wireless channel) and dynamically adapt the
transceivers' configuration (i.e., modulation scheme, word-length) and select
the wireless channel on-the-fly. Since the environment is unknown and changes
with time, we make the OML architecture reconfigurable to enable dynamic switch
between various OML algorithms on-the-fly. We have demonstrated the functional
correctness of the proposed architecture for different environments and
word-lengths. The detailed throughput, latency, and complexity analysis
validate the feasibility and importance of the proposed intelligent and
reconfigurable PHY in next-generation networks.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.15100v1,2020-11-30T18:32:20Z,2020-11-30T18:32:20Z,"From the DESK (Dexterous Surgical Skill) to the Battlefield -- A
  Robotics Exploratory Study","Short response time is critical for future military medical operations in
austere settings or remote areas. Such effective patient care at the point of
injury can greatly benefit from the integration of semi-autonomous robotic
systems. To achieve autonomy, robots would require massive libraries of
maneuvers. While this is possible in controlled settings, obtaining surgical
data in austere settings can be difficult. Hence, in this paper, we present the
Dexterous Surgical Skill (DESK) database for knowledge transfer between robots.
The peg transfer task was selected as it is one of 6 main tasks of laparoscopic
training. Also, we provide a ML framework to evaluate novel transfer learning
methodologies on this database. The collected DESK dataset comprises a set of
surgical robotic skills using the four robotic platforms: Taurus II, simulated
Taurus II, YuMi, and the da Vinci Research Kit. Then, we explored two different
learning scenarios: no-transfer and domain-transfer. In the no-transfer
scenario, the training and testing data were obtained from the same domain;
whereas in the domain-transfer scenario, the training data is a blend of
simulated and real robot data that is tested on a real robot. Using simulation
data enhances the performance of the real robot where limited or no real data
is available. The transfer model showed an accuracy of 81% for the YuMi robot
when the ratio of real-to-simulated data was 22%-78%. For Taurus II and da
Vinci robots, the model showed an accuracy of 97.5% and 93% respectively,
training only with simulation data. Results indicate that simulation can be
used to augment training data to enhance the performance of models in real
scenarios. This shows the potential for future use of surgical data from the
operating room in deployable surgical robots in remote areas.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.14966v1,2020-11-30T16:38:18Z,2020-11-30T16:38:18Z,"Depression Status Estimation by Deep Learning based Hybrid Multi-Modal
  Fusion Model","Preliminary detection of mild depression could immensely help in effective
treatment of the common mental health disorder. Due to the lack of proper
awareness and the ample mix of stigmas and misconceptions present within the
society, mental health status estimation has become a truly difficult task. Due
to the immense variations in character level traits from person to person,
traditional deep learning methods fail to generalize in a real world setting.
In our study we aim to create a human allied AI workflow which could
efficiently adapt to specific users and effectively perform in real world
scenarios. We propose a Hybrid deep learning approach that combines the essence
of one shot learning, classical supervised deep learning methods and human
allied interactions for adaptation. In order to capture maximum information and
make efficient diagnosis video, audio, and text modalities are utilized. Our
Hybrid Fusion model achieved a high accuracy of 96.3% on the Dataset; and
attained an AUC of 0.9682 which proves its robustness in discriminating classes
in complex real-world scenarios making sure that no cases of mild depression
are missed during diagnosis. The proposed method is deployed in a cloud-based
smartphone application for robust testing. With user-specific adaptations and
state of the art methodologies, we present a state-of-the-art model with user
friendly experience.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.12945v2,2022-04-10T23:01:14Z,2020-11-25T18:50:32Z,"No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained
  Classification Problems","In real-world classification tasks, each class often comprises multiple
finer-grained ""subclasses."" As the subclass labels are frequently unavailable,
models trained using only the coarser-grained class labels often exhibit highly
variable performance across different subclasses. This phenomenon, known as
hidden stratification, has important consequences for models deployed in
safety-critical applications such as medicine. We propose GEORGE, a method to
both measure and mitigate hidden stratification even when subclass labels are
unknown. We first observe that unlabeled subclasses are often separable in the
feature space of deep neural networks, and exploit this fact to estimate
subclass labels for the training data via clustering techniques. We then use
these approximate subclass labels as a form of noisy supervision in a
distributionally robust optimization objective. We theoretically characterize
the performance of GEORGE in terms of the worst-case generalization error
across any subclass. We empirically validate GEORGE on a mix of real-world and
benchmark image classification datasets, and show that our approach boosts
worst-case subclass accuracy by up to 22 percentage points compared to standard
training techniques, without requiring any prior information about the
subclasses.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.11719v3,2021-09-02T10:10:08Z,2020-11-23T20:51:22Z,"Explainable-by-design Semi-Supervised Representation Learning for
  COVID-19 Diagnosis from CT Imaging","Our motivating application is a real-world problem: COVID-19 classification
from CT imaging, for which we present an explainable Deep Learning approach
based on a semi-supervised classification pipeline that employs variational
autoencoders to extract efficient feature embedding. We have optimized the
architecture of two different networks for CT images: (i) a novel conditional
variational autoencoder (CVAE) with a specific architecture that integrates the
class labels inside the encoder layers and uses side information with shared
attention layers for the encoder, which make the most of the contextual clues
for representation learning, and (ii) a downstream convolutional neural network
for supervised classification using the encoder structure of the CVAE. With the
explainable classification results, the proposed diagnosis system is very
effective for COVID-19 classification. Based on the promising results obtained
qualitatively and quantitatively, we envisage a wide deployment of our
developed technique in large-scale clinical studies.Code is available at
https://git.etrovub.be/AVSP/ct-based-covid-19-diagnostic-tool.git.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.11557v1,2020-11-23T17:11:50Z,2020-11-23T17:11:50Z,"Planar 3D Transfer Learning for End to End Unimodal MRI Unbalanced Data
  Segmentation","We present a novel approach of 2D to 3D transfer learning based on mapping
pre-trained 2D convolutional neural network weights into planar 3D kernels. The
method is validated by the proposed planar 3D res-u-net network with encoder
transferred from the 2D VGG-16, which is applied for a single-stage unbalanced
3D image data segmentation. In particular, we evaluate the method on the MICCAI
2016 MS lesion segmentation challenge dataset utilizing solely fluid-attenuated
inversion recovery (FLAIR) sequence without brain extraction for training and
inference to simulate real medical praxis. The planar 3D res-u-net network
performed the best both in sensitivity and Dice score amongst end to end
methods processing raw MRI scans and achieved comparable Dice score to a
state-of-the-art unimodal not end to end approach. Complete source code was
released under the open-source license, and this paper complies with the
Machine learning reproducibility checklist. By implementing practical transfer
learning for 3D data representation, we could segment heavily unbalanced data
without selective sampling and achieved more reliable results using less
training data in a single modality. From a medical perspective, the unimodal
approach gives an advantage in real praxis as it does not require
co-registration nor additional scanning time during an examination. Although
modern medical imaging methods capture high-resolution 3D anatomy scans
suitable for computer-aided detection system processing, deployment of
automatic systems for interpretation of radiology imaging is still rather
theoretical in many medical areas. Our work aims to bridge the gap by offering
a solution for partial research questions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.10839v1,2020-11-21T18:26:44Z,2020-11-21T18:26:44Z,"Deep Learning-Based Computer Vision for Real Time Intravenous Drip
  Infusion Monitoring","This paper explores the use of deep learning-based computer vision for
real-time monitoring of the flow in intravenous (IV) infusions. IV infusions
are among the most common therapies in hospitalized patients and, given that
both over-infusion and under-infusion can cause severe damages, monitoring the
flow rate of the fluid being administered to patients is very important for
their safety. The proposed system uses a camera to film the IV drip infusion
kit and a deep learning-based algorithm to classify acquired frames into two
different states: frames with a drop that has just begun to take shape and
frames with a well-formed drop. The alternation of these two states is used to
count drops and derive a measurement of the flow rate of the drip. The usage of
a camera as sensing element makes the proposed system safe in medical
environments and easier to be integrated into current health facilities.
Experimental results are reported in the paper that confirm the accuracy of the
system and its capability to produce real-time estimates. The proposed method
can be therefore effectively adopted to implement IV infusion monitoring and
control systems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.10823v2,2021-06-23T08:49:24Z,2020-11-21T16:45:02Z,"A System for Automatic Rice Disease Detection from Rice Paddy Images
  Serviced via a Chatbot","A LINE Bot System to diagnose rice diseases from actual paddy field images
was developed and presented in this paper. It was easy-to-use and automatic
system designed to help rice farmers improve the rice yield and quality. The
targeted images were taken from the actual paddy environment without special
sample preparation. We used a deep learning neural networks technique to detect
rice diseases from the images. We developed an object detection model training
and refinement process to improve the performance of our previous research on
rice leave diseases detection. The process was based on analyzing the model's
predictive results and could be repeatedly used to improve the quality of the
database in the next training of the model. The deployment model for our LINE
Bot system was created from the selected best performance technique in our
previous paper, YOLOv3, trained by refined training data set. The performance
of the deployment model was measured on 5 target classes and found that the
Average True Positive Point improved from 91.1% in the previous paper to 95.6%
in this study. Therefore, we used this deployment model for Rice Disease LINE
Bot system. Our system worked automatically real-time to suggest primary
diagnosis results to the users in the LINE group, which included rice farmers
and rice disease specialists. They could communicate freely via chat. In the
real LINE Bot deployment, the model's performance was measured by our own
defined measurement Average True Positive Point and was found to be an average
of 78.86%. The system was fast and took only 2-3 s for detection process in our
system server.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.07555v1,2020-11-15T15:27:51Z,2020-11-15T15:27:51Z,Towards Compliant Data Management Systems for Healthcare ML,"The increasing popularity of machine learning approaches and the rising
awareness of data protection and data privacy presents an opportunity to build
truly secure and trustworthy healthcare systems. Regulations such as GDPR and
HIPAA present broad guidelines and frameworks, but the implementation can
present technical challenges. Compliant data management systems require
enforcement of a number of technical and administrative safeguards. While
policies can be set for both safeguards there is limited availability to
understand compliance in real time. Increasingly, machine learning
practitioners are becoming aware of the importance of keeping track of
sensitive data. With sensitivity over personally identifiable, health or
commercially sensitive information there would be value in understanding
assessment of the flow of data in a more dynamic fashion. We review how data
flows within machine learning projects in healthcare from source to storage to
use in training algorithms and beyond. Based on this, we design engineering
specifications and solutions for versioning of data. Our objective is to design
tools to detect and track sensitive data across machines and users across the
life cycle of a project, prioritizing efficiency, consistency and ease of use.
We build a prototype of the solution that demonstrates the difficulties in this
domain. Together, these represent first efforts towards building a compliant
data management system for healthcare machine learning projects.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.04128v1,2020-11-09T01:17:58Z,2020-11-09T01:17:58Z,"Stable predictions for health related anticausal prediction tasks
  affected by selection biases: the need to deconfound the test set features","In health related machine learning applications, the training data often
corresponds to a non-representative sample from the target populations where
the learners will be deployed. In anticausal prediction tasks, selection biases
often make the associations between confounders and the outcome variable
unstable across different target environments. As a consequence, the
predictions from confounded learners are often unstable, and might fail to
generalize in shifted test environments. Stable prediction approaches aim to
solve this problem by producing predictions that are stable across unknown test
environments. These approaches, however, are sometimes applied to the training
data alone with the hope that training an unconfounded model will be enough to
generate stable predictions in shifted test sets. Here, we show that this is
insufficient, and that improved stability can be achieved by deconfounding the
test set features as well. We illustrate these observations using both
synthetic data and real world data from a mobile health study.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.03395v2,2020-11-24T19:16:02Z,2020-11-06T14:53:13Z,"Underspecification Presents Challenges for Credibility in Modern Machine
  Learning","ML models often exhibit unexpectedly poor behavior when they are deployed in
real-world domains. We identify underspecification as a key reason for these
failures. An ML pipeline is underspecified when it can return many predictors
with equivalently strong held-out performance in the training domain.
Underspecification is common in modern ML pipelines, such as those based on
deep learning. Predictors returned by underspecified pipelines are often
treated as equivalent based on their training domain performance, but we show
here that such predictors can behave very differently in deployment domains.
This ambiguity can lead to instability and poor model behavior in practice, and
is a distinct failure mode from previously identified issues arising from
structural mismatch between training and deployment domains. We show that this
problem appears in a wide variety of practical ML pipelines, using examples
from computer vision, medical imaging, natural language processing, clinical
risk prediction based on electronic health records, and medical genomics. Our
results show the need to explicitly account for underspecification in modeling
pipelines that are intended for real-world deployment in any domain.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.03274v1,2020-11-06T10:41:39Z,2020-11-06T10:41:39Z,"Trust Issues: Uncertainty Estimation Does Not Enable Reliable OOD
  Detection On Medical Tabular Data","When deploying machine learning models in high-stakes real-world environments
such as health care, it is crucial to accurately assess the uncertainty
concerning a model's prediction on abnormal inputs. However, there is a
scarcity of literature analyzing this problem on medical data, especially on
mixed-type tabular data such as Electronic Health Records. We close this gap by
presenting a series of tests including a large variety of contemporary
uncertainty estimation techniques, in order to determine whether they are able
to identify out-of-distribution (OOD) patients. In contrast to previous work,
we design tests on realistic and clinically relevant OOD groups, and run
experiments on real-world medical data. We find that almost all techniques fail
to achieve convincing results, partly disagreeing with earlier findings.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.02000v5,2021-05-05T21:17:45Z,2020-11-03T20:41:59Z,"Detection of Maternal and Fetal Stress from the Electrocardiogram with
  Self-Supervised Representation Learning","In the pregnant mother and her fetus, chronic prenatal stress results in
entrainment of the fetal heartbeat by the maternal heartbeat, quantified by the
fetal stress index (FSI). Deep learning (DL) is capable of pattern detection in
complex medical data with high accuracy in noisy real-life environments, but
little is known about DL's utility in non-invasive biometric monitoring during
pregnancy. A recently established self-supervised learning (SSL) approach to DL
provides emotional recognition from electrocardiogram (ECG). We hypothesized
that SSL will identify chronically stressed mother-fetus dyads from the raw
maternal abdominal electrocardiograms (aECG), containing fetal and maternal
ECG. Chronically stressed mothers and controls matched at enrolment at 32 weeks
of gestation were studied. We validated the chronic stress exposure by
psychological inventory, maternal hair cortisol and FSI. We tested two variants
of SSL architecture, one trained on the generic ECG features for emotional
recognition obtained from public datasets and another transfer-learned on a
subset of our data. Our DL models accurately detect the chronic stress exposure
group (AUROC=0.982+/-0.002), the individual psychological stress score
(R2=0.943+/-0.009) and FSI at 34 weeks of gestation (R2=0.946+/-0.013), as well
as the maternal hair cortisol at birth reflecting chronic stress exposure
(0.931+/-0.006). The best performance was achieved with the DL model trained on
the public dataset and using maternal ECG alone. The present DL approach
provides a novel source of physiological insights into complex multi-modal
relationships between different regulatory systems exposed to chronic stress.
The final DL model can be deployed in low-cost regular ECG biosensors as a
simple, ubiquitous early stress detection and monitoring tool during pregnancy.
This discovery should enable early behavioral interventions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.00739v2,2021-04-06T17:11:52Z,2020-10-30T17:32:18Z,"Mutual Information-based Disentangled Neural Networks for Classifying
  Unseen Categories in Different Domains: Application to Fetal Ultrasound
  Imaging","Deep neural networks exhibit limited generalizability across images with
different entangled domain features and categorical features. Learning
generalizable features that can form universal categorical decision boundaries
across domains is an interesting and difficult challenge. This problem occurs
frequently in medical imaging applications when attempts are made to deploy and
improve deep learning models across different image acquisition devices, across
acquisition parameters or if some classes are unavailable in new training
databases. To address this problem, we propose Mutual Information-based
Disentangled Neural Networks (MIDNet), which extract generalizable categorical
features to transfer knowledge to unseen categories in a target domain. The
proposed MIDNet adopts a semi-supervised learning paradigm to alleviate the
dependency on labeled data. This is important for real-world applications where
data annotation is time-consuming, costly and requires training and expertise.
We extensively evaluate the proposed method on fetal ultrasound datasets for
two different image classification tasks where domain features are respectively
defined by shadow artifacts and image acquisition devices. Experimental results
show that the proposed method outperforms the state-of-the-art on the
classification of unseen categories in a target domain with sparsely labeled
training data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.11008v1,2020-10-21T13:48:37Z,2020-10-21T13:48:37Z,What is Wrong with Continual Learning in Medical Image Segmentation?,"Continual learning protocols are attracting increasing attention from the
medical imaging community. In a continual setup, data from different sources
arrives sequentially and each batch is only available for a limited period.
Given the inherent privacy risks associated with medical data, this setup
reflects the reality of deployment for deep learning diagnostic radiology
systems. Many techniques exist to learn continuously for classification tasks,
and several have been adapted to semantic segmentation. Yet most have at least
one of the following flaws: a) they rely too heavily on domain identity
information during inference, or b) data as seen in early training stages does
not profit from training with later data. In this work, we propose an
evaluation framework that addresses both concerns, and introduce a fair
multi-model benchmark. We show that the benchmark outperforms two popular
continual learning methods for the task of T2-weighted MR prostate
segmentation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.10969v2,2021-01-06T10:07:56Z,2020-10-21T13:00:05Z,"Incorporating Interpretable Output Constraints in Bayesian Neural
  Networks","Domains where supervised models are deployed often come with task-specific
constraints, such as prior expert knowledge on the ground-truth function, or
desiderata like safety and fairness. We introduce a novel probabilistic
framework for reasoning with such constraints and formulate a prior that
enables us to effectively incorporate them into Bayesian neural networks
(BNNs), including a variant that can be amortized over tasks. The resulting
Output-Constrained BNN (OC-BNN) is fully consistent with the Bayesian framework
for uncertainty quantification and is amenable to black-box inference. Unlike
typical BNN inference in uninterpretable parameter space, OC-BNNs widen the
range of functional knowledge that can be incorporated, especially for model
users without expertise in machine learning. We demonstrate the efficacy of
OC-BNNs on real-world datasets, spanning multiple domains such as healthcare,
criminal justice, and credit scoring.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.09553v7,2022-06-07T17:38:12Z,2020-10-19T14:28:55Z,Survey on Causal-based Machine Learning Fairness Notions,"Addressing the problem of fairness is crucial to safely use machine learning
algorithms to support decisions with a critical impact on people's lives such
as job hiring, child maltreatment, disease diagnosis, loan granting, etc.
Several notions of fairness have been defined and examined in the past decade,
such as statistical parity and equalized odds. The most recent fairness
notions, however, are causal-based and reflect the now widely accepted idea
that using causality is necessary to appropriately address the problem of
fairness. This paper examines an exhaustive list of causal-based fairness
notions and study their applicability in real-world scenarios. As the majority
of causal-based fairness notions are defined in terms of non-observable
quantities (e.g., interventions and counterfactuals), their deployment in
practice requires to compute or estimate those quantities using observational
data. This paper offers a comprehensive report of the different approaches to
infer causal quantities from observational data including identifiability
(Pearl's SCM framework) and estimation (potential outcome framework). The main
contributions of this survey paper are (1) a guideline to help selecting a
suitable fairness notion given a specific real-world scenario, and (2) a
ranking of the fairness notions according to Pearl's causation ladder
indicating how difficult it is to deploy each notion in practice.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.02715v1,2020-10-03T23:18:05Z,2020-10-03T23:18:05Z,"Assessing Automated Machine Learning service to detect COVID-19 from
  X-Ray and CT images: A Real-time Smartphone Application case study","The recent outbreak of SARS COV-2 gave us a unique opportunity to study for a
non interventional and sustainable AI solution. Lung disease remains a major
healthcare challenge with high morbidity and mortality worldwide. The
predominant lung disease was lung cancer. Until recently, the world has
witnessed the global pandemic of COVID19, the Novel coronavirus outbreak. We
have experienced how viral infection of lung and heart claimed thousands of
lives worldwide. With the unprecedented advancement of Artificial Intelligence
in recent years, Machine learning can be used to easily detect and classify
medical imagery. It is much faster and most of the time more accurate than
human radiologists. Once implemented, it is more cost-effective and
time-saving. In our study, we evaluated the efficacy of Microsoft Cognitive
Service to detect and classify COVID19 induced pneumonia from other
Viral/Bacterial pneumonia based on X-Ray and CT images. We wanted to assess the
implication and accuracy of the Automated ML-based Rapid Application
Development (RAD) environment in the field of Medical Image diagnosis. This
study will better equip us to respond with an ML-based diagnostic Decision
Support System(DSS) for a Pandemic situation like COVID19. After optimization,
the trained network achieved 96.8% Average Precision which was implemented as a
Web Application for consumption. However, the same trained network did not
perform the same like Web Application when ported to Smartphone for Real-time
inference. Which was our main interest of study. The authors believe, there is
scope for further study on this issue. One of the main goal of this study was
to develop and evaluate the performance of AI-powered Smartphone-based
Real-time Application. Facilitating primary diagnostic services in less
equipped and understaffed rural healthcare centers of the world with unreliable
internet service.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.01165v2,2021-03-25T13:21:50Z,2020-10-02T19:01:02Z,"Multi-domain Clinical Natural Language Processing with MedCAT: the
  Medical Concept Annotation Toolkit","Electronic health records (EHR) contain large volumes of unstructured text,
requiring the application of Information Extraction (IE) technologies to enable
clinical analysis. We present the open-source Medical Concept Annotation
Toolkit (MedCAT) that provides: a) a novel self-supervised machine learning
algorithm for extracting concepts using any concept vocabulary including
UMLS/SNOMED-CT; b) a feature-rich annotation interface for customising and
training IE models; and c) integrations to the broader CogStack ecosystem for
vendor-agnostic health system deployment. We show improved performance in
extracting UMLS concepts from open datasets (F1:0.448-0.738 vs 0.429-0.650).
Further real-world validation demonstrates SNOMED-CT extraction at 3 large
London hospitals with self-supervised training over ~8.8B words from ~17M
clinical records and further fine-tuning with ~6K clinician annotated examples.
We show strong transferability (F1 > 0.94) between hospitals, datasets, and
concept types indicating cross-domain EHR-agnostic utility for accelerated
clinical and research use cases.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.07029v2,2021-02-27T19:06:48Z,2020-09-29T21:32:28Z,"Basic principles and concept design of a real-time clinical decision
  support system for managing medical emergencies on missions to Mars","Space agencies and private companies prepare the beginning of human space
exploration for the 2030s with missions to put the first human on the Mars
surface. The absence of gravity and radiation, along with distance, isolation
and hostile environments, are expected to increase medical events where
previously unseen manifestations may arise. The current healthcare strategy
based on telemedicine and the possibility to stabilize and transport the
injured crewmember to a terrestrial definitive medical facility is not
applicable in exploration class missions. Therefore, the need for deploying the
full autonomous capability to solve medical emergencies may guide the design of
future onboard healthcare systems. We present ten basic principles and concept
design of a software suite to bring onboard decision support to help the crew
dealing with medical emergencies taking into consideration physiological
disturbances in space and spaceflight restrictions. 1) give real-time support
for emergency medical decision making, 2) give patient-specific advice for
executive problem-solving, 3) take into account available information from life
support and monitoring of crewmembers, 4) be fully autonomous from remote
facilities, 5) continuously adapt predictions to physiological disturbance and
changing conditions, 6) optimize emergency medical decision making in terms of
mission fundamental priorities, 7) take into account medical supplies and
equipment on board, 8) apply health standards for the level of care V, 9)
implement ethics responsibilities for spaceflights, and 10) apply ethical
standards for artificial intelligence. Based on these principles, we propose an
autonomous clinical decision support system (CDSS) to provide real-time advice
for emergency medical interventions on board of space exploration missions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.12406v1,2020-09-25T19:15:26Z,2020-09-25T19:15:26Z,"Why have a Unified Predictive Uncertainty? Disentangling it using Deep
  Split Ensembles","Understanding and quantifying uncertainty in black box Neural Networks (NNs)
is critical when deployed in real-world settings such as healthcare. Recent
works using Bayesian and non-Bayesian methods have shown how a unified
predictive uncertainty can be modelled for NNs. Decomposing this uncertainty to
disentangle the granular sources of heteroscedasticity in data provides rich
information about its underlying causes. We propose a conceptually simple
non-Bayesian approach, deep split ensemble, to disentangle the predictive
uncertainties using a multivariate Gaussian mixture model. The NNs are trained
with clusters of input features, for uncertainty estimates per cluster. We
evaluate our approach on a series of benchmark regression datasets, while also
comparing with unified uncertainty methods. Extensive analyses using dataset
shits and empirical rule highlight our inherently well-calibrated models. Our
work further demonstrates its applicability in a multi-modal setting using a
benchmark Alzheimer's dataset and also shows how deep split ensembles can
highlight hidden modality-specific biases. The minimal changes required to NNs
and the training procedure, and the high flexibility to group features into
clusters makes it readily deployable and useful. The source code is available
at https://github.com/wazeerzulfikar/deep-split-ensembles",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.11433v1,2020-09-24T01:04:18Z,2020-09-24T01:04:18Z,Unifying data for fine-grained visual species classification,"Wildlife monitoring is crucial to nature conservation and has been done by
manual observations from motion-triggered camera traps deployed in the field.
Widespread adoption of such in-situ sensors has resulted in unprecedented data
volumes being collected over the last decade. A significant challenge exists to
process and reliably identify what is in these images efficiently. Advances in
computer vision are poised to provide effective solutions with custom AI models
built to automatically identify images of interest and label the species in
them. Here we outline the data unification effort for the Wildlife Insights
platform from various conservation partners, and the challenges involved. Then
we present an initial deep convolutional neural network model, trained on 2.9M
images across 465 fine-grained species, with a goal to reduce the load on human
experts to classify species in images manually. The long-term goal is to enable
scientists to make conservation recommendations from near real-time analysis of
species abundance and population health.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.11380v2,2021-03-24T18:29:36Z,2020-09-23T21:19:55Z,"Combining Weighted Total Variation and Deep Image Prior for natural and
  medical image restoration via ADMM","In the last decades, unsupervised deep learning based methods have caught
researchers attention, since in many real applications, such as medical
imaging, collecting a great amount of training examples is not always feasible.
Moreover, the construction of a good training set is time consuming and hard
because the selected data have to be enough representative for the task. In
this paper, we focus on the Deep Image Prior (DIP) framework and we propose to
combine it with a space-variant Total Variation regularizer with an automatic
estimation of the local regularization parameters. Differently from other
existing approaches, we solve the arising minimization problem via the flexible
Alternating Direction Method of Multipliers (ADMM). Furthermore, we provide a
specific implementation also for the standard isotropic Total Variation. The
promising performances of the proposed approach, in terms of PSNR and SSIM
values, are addressed through several experiments on simulated as well as real
natural and medical corrupted images.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.09231v1,2020-09-19T13:47:33Z,2020-09-19T13:47:33Z,Adversarial Exposure Attack on Diabetic Retinopathy Imagery,"Diabetic retinopathy (DR) is a leading cause of vision loss in the world and
numerous cutting-edge works have built powerful deep neural networks (DNNs) to
automatically classify the DR cases via the retinal fundus images (RFIs).
However, RFIs are usually affected by the widely existing camera exposure while
the robustness of DNNs to the exposure is rarely explored. In this paper, we
study this problem from the viewpoint of adversarial attack and identify a
totally new task, i.e., adversarial exposure attack generating adversarial
images by tuning image exposure to mislead the DNNs with significantly high
transferability. To this end, we first implement a straightforward method,
i.e., multiplicative-perturbation-based exposure attack, and reveal the big
challenges of this new task. Then, to make the adversarial image naturalness,
we propose the adversarial bracketed exposure fusion that regards the exposure
attack as an element-wise bracketed exposure fusion problem in the
Laplacian-pyramid space. Moreover, to realize high transferability, we further
propose the convolutional bracketed exposure fusion where the element-wise
multiplicative operation is extended to the convolution. We validate our method
on the real public DR dataset with the advanced DNNs, e.g., ResNet50,
MobileNet, and EfficientNet, showing our method can achieve high image quality
and success rate of the transfer attack. Our method reveals the potential
threats to the DNN-based DR automated diagnosis and can definitely benefit the
development of exposure-robust automated DR diagnosis method in the future.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.04607v3,2022-02-26T21:00:20Z,2020-09-09T23:55:27Z,"Multi-Objective Model-based Reinforcement Learning for Infectious
  Disease Control","Severe infectious diseases such as the novel coronavirus (COVID-19) pose a
huge threat to public health. Stringent control measures, such as school
closures and stay-at-home orders, while having significant effects, also bring
huge economic losses. In the face of an emerging infectious disease, a crucial
question for policymakers is how to make the trade-off and implement the
appropriate interventions timely given the huge uncertainty. In this work, we
propose a Multi-Objective Model-based Reinforcement Learning framework to
facilitate data-driven decision-making and minimize the overall long-term cost.
Specifically, at each decision point, a Bayesian epidemiological model is first
learned as the environment model, and then the proposed model-based
multi-objective planning algorithm is applied to find a set of Pareto-optimal
policies. This framework, combined with the prediction bands for each policy,
provides a real-time decision support tool for policymakers. The application is
demonstrated with the spread of COVID-19 in China.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.13369v1,2020-08-31T05:12:57Z,2020-08-31T05:12:57Z,"Introducing Representations of Facial Affect in Automated Multimodal
  Deception Detection","Automated deception detection systems can enhance health, justice, and
security in society by helping humans detect deceivers in high-stakes
situations across medical and legal domains, among others. This paper presents
a novel analysis of the discriminative power of dimensional representations of
facial affect for automated deception detection, along with interpretable
features from visual, vocal, and verbal modalities. We used a video dataset of
people communicating truthfully or deceptively in real-world, high-stakes
courtroom situations. We leveraged recent advances in automated emotion
recognition in-the-wild by implementing a state-of-the-art deep neural network
trained on the Aff-Wild database to extract continuous representations of
facial valence and facial arousal from speakers. We experimented with unimodal
Support Vector Machines (SVM) and SVM-based multimodal fusion methods to
identify effective features, modalities, and modeling approaches for detecting
deception. Unimodal models trained on facial affect achieved an AUC of 80%, and
facial affect contributed towards the highest-performing multimodal approach
(adaptive boosting) that achieved an AUC of 91% when tested on speakers who
were not part of training sets. This approach achieved a higher AUC than
existing automated machine learning approaches that used interpretable visual,
vocal, and verbal features to detect deception in this dataset, but did not use
facial affect. Across all videos, deceptive and truthful speakers exhibited
significant differences in facial valence and facial arousal, contributing
computational support to existing psychological theories on affect and
deception. The demonstrated importance of facial affect in our models informs
and motivates the future development of automated, affect-aware machine
learning approaches for modeling and detecting deception and other social
behaviors in-the-wild.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.12949v2,2021-01-14T12:55:11Z,2020-08-29T09:54:05Z,VR-Caps: A Virtual Environment for Capsule Endoscopy,"Current capsule endoscopes and next-generation robotic capsules for diagnosis
and treatment of gastrointestinal diseases are complex cyber-physical platforms
that must orchestrate complex software and hardware functions. The desired
tasks for these systems include visual localization, depth estimation, 3D
mapping, disease detection and segmentation, automated navigation, active
control, path realization and optional therapeutic modules such as targeted
drug delivery and biopsy sampling. Data-driven algorithms promise to enable
many advanced functionalities for capsule endoscopes, but real-world data is
challenging to obtain. Physically-realistic simulations providing synthetic
data have emerged as a solution to the development of data-driven algorithms.
In this work, we present a comprehensive simulation platform for capsule
endoscopy operations and introduce VR-Caps, a virtual active capsule
environment that simulates a range of normal and abnormal tissue conditions
(e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope
designs (e.g., mono, stereo, dual and 360{\deg}camera), and the type, number,
strength, and placement of internal and external magnetic sources that enable
active locomotion. VR-Caps makes it possible to both independently or jointly
develop, optimize, and test medical imaging and analysis software for the
current and next-generation endoscopic capsule systems. To validate this
approach, we train state-of-the-art deep neural networks to accomplish various
medical image analysis tasks using simulated data from VR-Caps and evaluate the
performance of these models on real medical data. Results demonstrate the
usefulness and effectiveness of the proposed virtual platform in developing
algorithms that quantify fractional coverage, camera trajectory, 3D map
reconstruction, and disease classification.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.01657v1,2020-08-27T20:53:26Z,2020-08-27T20:53:26Z,"A free web service for fast COVID-19 classification of chest X-Ray
  images","The coronavirus outbreak became a major concern for society worldwide.
Technological innovation and ingenuity are essential to fight COVID-19 pandemic
and bring us one step closer to overcome it. Researchers over the world are
working actively to find available alternatives in different fields, such as
the Healthcare System, pharmaceutic, health prevention, among others. With the
rise of artificial intelligence (AI) in the last 10 years, IA-based
applications have become the prevalent solution in different areas because of
its higher capability, being now adopted to help combat against COVID-19. This
work provides a fast detection system of COVID-19 characteristics in X-Ray
images based on deep learning (DL) techniques. This system is available as a
free web deployed service for fast patient classification, alleviating the high
demand for standards method for COVID-19 diagnosis. It is constituted of two
deep learning models, one to differentiate between X-Ray and non-X-Ray images
based on Mobile-Net architecture, and another one to identify chest X-Ray
images with characteristics of COVID-19 based on the DenseNet architecture. For
real-time inference, it is provided a pair of dedicated GPUs, which reduce the
computational time. The whole system can filter out non-chest X-Ray images, and
detect whether the X-Ray presents characteristics of COVID-19, highlighting the
most sensitive regions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.08525v1,2020-08-19T16:05:58Z,2020-08-19T16:05:58Z,"""Name that manufacturer"". Relating image acquisition bias with task
  complexity when training deep learning models: experiments on head CT","As interest in applying machine learning techniques for medical images
continues to grow at a rapid pace, models are starting to be developed and
deployed for clinical applications. In the clinical AI model development
lifecycle (described by Lu et al. [1]), a crucial phase for machine learning
scientists and clinicians is the proper design and collection of the data
cohort. The ability to recognize various forms of biases and distribution
shifts in the dataset is critical at this step. While it remains difficult to
account for all potential sources of bias, techniques can be developed to
identify specific types of bias in order to mitigate their impact. In this work
we analyze how the distribution of scanner manufacturers in a dataset can
contribute to the overall bias of deep learning models. We evaluate
convolutional neural networks (CNN) for both classification and segmentation
tasks, specifically two state-of-the-art models: ResNet [2] for classification
and U-Net [3] for segmentation. We demonstrate that CNNs can learn to
distinguish the imaging scanner manufacturer and that this bias can
substantially impact model performance for both classification and segmentation
tasks. By creating an original synthesis dataset of brain data mimicking the
presence of more or less subtle lesions we also show that this bias is related
to the difficulty of the task. Recognition of such bias is critical to develop
robust, generalizable models that will be crucial for clinical applications in
real-world data distributions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.07257v3,2021-03-12T02:22:31Z,2020-08-17T12:41:46Z,FLBench: A Benchmark Suite for Federated Learning,"Federated learning is a new machine learning paradigm. The goal is to build a
machine learning model from the data sets distributed on multiple devices
so-called an isolated data island, while keeping their data secure and private.
Most existing federated learning benchmarks work manually splits commonly used
public datasets into partitions to simulate real world isolated data island
scenarios. Still, this simulation fails to capture real world isolated data
island intrinsic characteristics. This paper presents a federated learning (FL)
benchmark suite named FLBench. FLBench contains three domains: medical,
financial, and AIoT. By configuring various domains, FLBench is qualified to
evaluate federated learning systems and algorithms essential aspects, like
communication, scenario transformation, privacy-preserving, data distribution
heterogeneity, and cooperation strategy. Hence, it becomes a promising platform
for developing novel federated learning algorithms. Currently, FLBench is open
sourced and in fast evolution. We package it as an automated deployment tool.
The benchmark suite is available from
https://www.benchcouncil.org/flbench.html.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.05381v1,2020-08-12T15:29:11Z,2020-08-12T15:29:11Z,"Improving the Performance of Fine-Grain Image Classifiers via Generative
  Data Augmentation","Recent advances in machine learning (ML) and computer vision tools have
enabled applications in a wide variety of arenas such as financial analytics,
medical diagnostics, and even within the Department of Defense. However, their
widespread implementation in real-world use cases poses several challenges: (1)
many applications are highly specialized, and hence operate in a \emph{sparse
data} domain; (2) ML tools are sensitive to their training sets and typically
require cumbersome, labor-intensive data collection and data labelling
processes; and (3) ML tools can be extremely ""black box,"" offering users little
to no insight into the decision-making process or how new data might affect
prediction performance. To address these challenges, we have designed and
developed Data Augmentation from Proficient Pre-Training of Robust Generative
Adversarial Networks (DAPPER GAN), an ML analytics support tool that
automatically generates novel views of training images in order to improve
downstream classifier performance. DAPPER GAN leverages high-fidelity
embeddings generated by a StyleGAN2 model (trained on the LSUN cars dataset) to
create novel imagery for previously unseen classes. We experimentally evaluate
this technique on the Stanford Cars dataset, demonstrating improved vehicle
make and model classification accuracy and reduced requirements for real data
using our GAN based data augmentation framework. The method's validity was
supported through an analysis of classifier performance on both augmented and
non-augmented datasets, achieving comparable or better accuracy with up to 30\%
less real data across visually similar classes. To support this method, we
developed a novel augmentation method that can manipulate semantically
meaningful dimensions (e.g., orientation) of the target object in the embedding
space.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.05232v2,2020-11-23T20:38:50Z,2020-08-12T11:03:57Z,Learning to Detect Anomalous Wireless Links in IoT Networks,"After decades of research, the Internet of Things (IoT) is finally permeating
real-life and helps improve the efficiency of infrastructures and processes as
well as our health. As a massive number of IoT devices are deployed, they
naturally incur great operational costs to ensure intended operations. To
effectively handle such intended operations in massive IoT networks, automatic
detection of malfunctioning, namely anomaly detection, becomes a critical but
challenging task. In this paper, motivated by a real-world experimental IoT
deployment, we introduce four types of wireless network anomalies that are
identified at the link layer. We study the performance of threshold- and
machine learning (ML)-based classifiers to automatically detect these
anomalies. We examine the relative performance of three supervised and three
unsupervised ML techniques on both non-encoded and encoded (autoencoder)
feature representations. Our results demonstrate that; i) selected supervised
approaches are able to detect anomalies with F1 scores of above 0.98, while
unsupervised ones are also capable of detecting the said anomalies with F1
scores of, on average, 0.90, and ii) OC-SVM outperforms all the other
unsupervised ML approaches reaching at F1 scores of 0.99 for SuddenD, 0.95 for
SuddenR, 0.93 for InstaD and 0.95 for SlowD.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.02567v1,2020-08-06T10:51:56Z,2020-08-06T10:51:56Z,"An Intelligent Non-Invasive Real Time Human Activity Recognition System
  for Next-Generation Healthcare","Human motion detection is getting considerable attention in the field of
Artificial Intelligence (AI) driven healthcare systems. Human motion can be
used to provide remote healthcare solutions for vulnerable people by
identifying particular movements such as falls, gait and breathing disorders.
This can allow people to live more independent lifestyles and still have the
safety of being monitored if more direct care is needed. At present wearable
devices can provide real time monitoring by deploying equipment on a person's
body. However, putting devices on a person's body all the time make it
uncomfortable and the elderly tends to forget it to wear as well in addition to
the insecurity of being tracked all the time. This paper demonstrates how human
motions can be detected in quasi-real-time scenario using a non-invasive
method. Patterns in the wireless signals presents particular human body motions
as each movement induces a unique change in the wireless medium. These changes
can be used to identify particular body motions. This work produces a dataset
that contains patterns of radio wave signals obtained using software defined
radios (SDRs) to establish if a subject is standing up or sitting down as a
test case. The dataset was used to create a machine learning model, which was
used in a developed application to provide a quasi-real-time classification of
standing or sitting state. The machine learning model was able to achieve 96.70
% accuracy using the Random Forest algorithm using 10 fold cross validation. A
benchmark dataset of wearable devices was compared to the proposed dataset and
results showed the proposed dataset to have similar accuracy of nearly 90 %.
The machine learning models developed in this paper are tested for two
activities but the developed system is designed and applicable for detecting
and differentiating x number of activities.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.01774v2,2020-11-04T02:36:36Z,2020-08-04T19:20:31Z,"An artificial intelligence system for predicting the deterioration of
  COVID-19 patients in the emergency department","During the coronavirus disease 2019 (COVID-19) pandemic, rapid and accurate
triage of patients at the emergency department is critical to inform
decision-making. We propose a data-driven approach for automatic prediction of
deterioration risk using a deep neural network that learns from chest X-ray
images and a gradient boosting model that learns from routine clinical
variables. Our AI prognosis system, trained using data from 3,661 patients,
achieves an area under the receiver operating characteristic curve (AUC) of
0.786 (95% CI: 0.745-0.830) when predicting deterioration within 96 hours. The
deep neural network extracts informative areas of chest X-ray images to assist
clinicians in interpreting the predictions and performs comparably to two
radiologists in a reader study. In order to verify performance in a real
clinical setting, we silently deployed a preliminary version of the deep neural
network at New York University Langone Health during the first wave of the
pandemic, which produced accurate predictions in real-time. In summary, our
findings demonstrate the potential of the proposed system for assisting
front-line physicians in the triage of COVID-19 patients.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.15215v1,2020-07-30T03:54:32Z,2020-07-30T03:54:32Z,"Learner's Dilemma: IoT Devices Training Strategies in Collaborative Deep
  Learning","With the growth of Internet of Things (IoT) and mo-bile edge computing,
billions of smart devices are interconnected to develop applications used in
various domains including smart homes, healthcare and smart manufacturing. Deep
learning has been extensively utilized in various IoT applications which
require huge amount of data for model training. Due to privacy requirements,
smart IoT devices do not release data to a remote third party for their use. To
overcome this problem, collaborative approach to deep learning, also known as
Collaborative DeepLearning (CDL) has been largely employed in data-driven
applications. This approach enables multiple edge IoT devices to train their
models locally on mobile edge devices. In this paper,we address IoT device
training problem in CDL by analyzing the behavior of mobile edge devices using
a game-theoretic model,where each mobile edge device aims at maximizing the
accuracy of its local model at the same time limiting the overhead of
participating in CDL. We analyze the Nash Equilibrium in anN-player static game
model. We further present a novel cluster-based fair strategy to approximately
solve the CDL game to enforce mobile edge devices for cooperation. Our
experimental results and evaluation analysis in a real-world smart home
deployment show that 80% mobile edge devices are ready to cooperate in CDL,
while 20% of them do not train their local models collaboratively.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.15153v1,2020-07-29T23:43:15Z,2020-07-29T23:43:15Z,"Fast, Structured Clinical Documentation via Contextual Autocomplete","We present a system that uses a learned autocompletion mechanism to
facilitate rapid creation of semi-structured clinical documentation. We
dynamically suggest relevant clinical concepts as a doctor drafts a note by
leveraging features from both unstructured and structured medical data. By
constraining our architecture to shallow neural networks, we are able to make
these suggestions in real time. Furthermore, as our algorithm is used to write
a note, we can automatically annotate the documentation with clean labels of
clinical concepts drawn from medical vocabularies, making notes more structured
and readable for physicians, patients, and future algorithms. To our knowledge,
this system is the only machine learning-based documentation utility for
clinical notes deployed in a live hospital setting, and it reduces keystroke
burden of clinical concepts by 67% in real environments.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.14432v1,2020-07-28T18:47:21Z,2020-07-28T18:47:21Z,"A Convolutional Neural Network for gaze preference detection: A
  potential tool for diagnostics of autism spectrum disorder in children","Early diagnosis of autism spectrum disorder (ASD) is known to improve the
quality of life of affected individuals. However, diagnosis is often delayed
even in wealthier countries including the US, largely due to the fact that gold
standard diagnostic tools such as the Autism Diagnostic Observation Schedule
(ADOS) and the Autism Diagnostic Interview-Revised (ADI-R) are time consuming
and require expertise to administer. This trend is even more pronounced lower
resources settings due to a lack of trained experts. As a result, alternative,
less technical methods that leverage the unique ways in which children with ASD
react to visual stimulation in a controlled environment have been developed to
help facilitate early diagnosis. Previous studies have shown that, when exposed
to a video that presents both social and abstract scenes side by side, a child
with ASD will focus their attention towards the abstract images on the screen
to a greater extent than a child without ASD. Such differential responses make
it possible to implement an algorithm for the rapid diagnosis of ASD based on
eye tracking against different visual stimuli. Here we propose a convolutional
neural network (CNN) algorithm for gaze prediction using images extracted from
a one-minute stimulus video. Our model achieved a high accuracy rate and
robustness for prediction of gaze direction with independent persons and
employing a different camera than the one used during testing. In addition to
this, the proposed algorithm achieves a fast response time, providing a near
real-time evaluation of ASD. Thereby, by applying the proposed method, we could
significantly reduce the diagnosis time and facilitate the diagnosis of ASD in
low resource regions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.13404v2,2020-10-29T16:23:12Z,2020-07-27T09:50:11Z,"YOLOpeds: Efficient Real-Time Single-Shot Pedestrian Detection for Smart
  Camera Applications","Deep Learning-based object detectors can enhance the capabilities of smart
camera systems in a wide spectrum of machine vision applications including
video surveillance, autonomous driving, robots and drones, smart factory, and
health monitoring. Pedestrian detection plays a key role in all these
applications and deep learning can be used to construct accurate
state-of-the-art detectors. However, such complex paradigms do not scale easily
and are not traditionally implemented in resource-constrained smart cameras for
on-device processing which offers significant advantages in situations when
real-time monitoring and robustness are vital. Efficient neural networks can
not only enable mobile applications and on-device experiences but can also be a
key enabler of privacy and security allowing a user to gain the benefits of
neural networks without needing to send their data to the server to be
evaluated. This work addresses the challenge of achieving a good trade-off
between accuracy and speed for efficient deployment of deep-learning-based
pedestrian detection in smart camera applications. A computationally efficient
architecture is introduced based on separable convolutions and proposes
integrating dense connections across layers and multi-scale feature fusion to
improve representational capacity while decreasing the number of parameters and
operations. In particular, the contributions of this work are the following: 1)
An efficient backbone combining multi-scale feature operations, 2) a more
elaborate loss function for improved localization, 3) an anchor-less approach
for detection, The proposed approach called YOLOpeds is evaluated using the
PETS2009 surveillance dataset on 320x320 images. Overall, YOLOpeds provides
real-time sustained operation of over 30 frames per second with detection rates
in the range of 86% outperforming existing deep learning models.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.11344v2,2020-10-27T07:35:51Z,2020-07-22T11:14:23Z,DEAL: Deep Evidential Active Learning for Image Classification,"Convolutional Neural Networks (CNNs) have proven to be state-of-the-art
models for supervised computer vision tasks, such as image classification.
However, large labeled data sets are generally needed for the training and
validation of such models. In many domains, unlabeled data is available but
labeling is expensive, for instance when specific expert knowledge is required.
Active Learning (AL) is one approach to mitigate the problem of limited labeled
data. Through selecting the most informative and representative data instances
for labeling, AL can contribute to more efficient learning of the model. Recent
AL methods for CNNs propose different solutions for the selection of instances
to be labeled. However, they do not perform consistently well and are often
computationally expensive. In this paper, we propose a novel AL algorithm that
efficiently learns from unlabeled data by capturing high prediction
uncertainty. By replacing the softmax standard output of a CNN with the
parameters of a Dirichlet density, the model learns to identify data instances
that contribute efficiently to improving model performance during training. We
demonstrate in several experiments with publicly available data that our method
consistently outperforms other state-of-the-art AL approaches. It can be easily
implemented and does not require extensive computational resources for
training. Additionally, we are able to show the benefits of the approach on a
real-world medical use case in the field of automated detection of visual
signals for pneumonia on chest radiographs.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.08146v1,2020-07-16T07:10:21Z,2020-07-16T07:10:21Z,"Enhanced detection of fetal pose in 3D MRI by Deep Reinforcement
  Learning with physical structure priors on anatomy","Fetal MRI is heavily constrained by unpredictable and substantial fetal
motion that causes image artifacts and limits the set of viable diagnostic
image contrasts. Current mitigation of motion artifacts is predominantly
performed by fast, single-shot MRI and retrospective motion correction.
Estimation of fetal pose in real time during MRI stands to benefit prospective
methods to detect and mitigate fetal motion artifacts where inferred fetal
motion is combined with online slice prescription with low-latency decision
making. Current developments of deep reinforcement learning (DRL), offer a
novel approach for fetal landmarks detection. In this task 15 agents are
deployed to detect 15 landmarks simultaneously by DRL. The optimization is
challenging, and here we propose an improved DRL that incorporates priors on
physical structure of the fetal body. First, we use graph communication layers
to improve the communication among agents based on a graph where each node
represents a fetal-body landmark. Further, additional reward based on the
distance between agents and physical structures such as the fetal limbs is used
to fully exploit physical structure. Evaluation of this method on a repository
of 3-mm resolution in vivo data demonstrates a mean accuracy of landmark
estimation within 10 mm of ground truth as 87.3%, and a mean error of 6.9 mm.
The proposed DRL for fetal pose landmark search demonstrates a potential
clinical utility for online detection of fetal motion that guides real-time
mitigation of motion artifacts as well as health diagnosis during MRI of the
pregnant mother.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.08653v1,2020-07-14T22:47:12Z,2020-07-14T22:47:12Z,Dementia Prediction Applying Variational Quantum Classifier,"Dementia is the fifth cause of death worldwide with 10 million new cases
every year. Healthcare applications using machine learning techniques have
almost reached the physical limits while more data is becoming available
resulting from the increasing rate of diagnosis. Recent research in Quantum
Machine Learning (QML) techniques have found different approaches that may be
useful to accelerate the training process of existing machine learning models
and provide an alternative to learn more complex patterns. This work aims to
report a real-world application of a Quantum Machine Learning Algorithm, in
particular, we found that using the implemented version for Variational Quantum
Classiffication (VQC) in IBM's framework Qiskit allows predicting dementia in
elderly patients, this approach proves to provide more consistent results when
compared with a classical Support Vector Machine (SVM) with a linear kernel
using different number of features.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.03226v1,2020-06-28T20:59:03Z,2020-06-28T20:59:03Z,"The Photoswitch Dataset: A Molecular Machine Learning Benchmark for the
  Advancement of Synthetic Chemistry","The space of synthesizable molecules is greater than $10^{60}$, meaning only
a vanishingly small fraction of these molecules have ever been realized in the
lab. In order to prioritize which regions of this space to explore next,
synthetic chemists need access to accurate molecular property predictions.
While great advances in molecular machine learning have been made, there is a
dearth of benchmarks featuring properties that are useful for the synthetic
chemist. Focussing directly on the needs of the synthetic chemist, we introduce
the Photoswitch Dataset, a new benchmark for molecular machine learning where
improvements in model performance can be immediately observed in the throughput
of promising molecules synthesized in the lab. Photoswitches are a versatile
class of molecule for medical and renewable energy applications where a
molecule's efficacy is governed by its electronic transition wavelengths. We
demonstrate superior performance in predicting these wavelengths compared to
both time-dependent density functional theory (TD-DFT), the incumbent first
principles quantum mechanical approach, as well as a panel of human experts.
Our baseline models are currently being deployed in the lab as part of the
decision process for candidate synthesis. It is our hope that this benchmark
can drive real discoveries in photoswitch chemistry and that future benchmarks
can be introduced to pivot learning algorithm development to benefit more
expansive areas of synthetic chemistry.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.13379v1,2020-06-23T23:15:54Z,2020-06-23T23:15:54Z,Deep Generative Model-based Quality Control for Cardiac MRI Segmentation,"In recent years, convolutional neural networks have demonstrated promising
performance in a variety of medical image segmentation tasks. However, when a
trained segmentation model is deployed into the real clinical world, the model
may not perform optimally. A major challenge is the potential poor-quality
segmentations generated due to degraded image quality or domain shift issues.
There is a timely need to develop an automated quality control method that can
detect poor segmentations and feedback to clinicians. Here we propose a novel
deep generative model-based framework for quality control of cardiac MRI
segmentation. It first learns a manifold of good-quality image-segmentation
pairs using a generative model. The quality of a given test segmentation is
then assessed by evaluating the difference from its projection onto the
good-quality manifold. In particular, the projection is refined through
iterative search in the latent space. The proposed method achieves high
prediction accuracy on two publicly available cardiac MRI datasets. Moreover,
it shows better generalisation ability than traditional regression-based
methods. Our approach provides a real-time and model-agnostic quality control
for cardiac MRI segmentation, which has the potential to be integrated into
clinical image analysis workflows.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.10748v1,2020-06-17T22:03:31Z,2020-06-17T22:03:31Z,"Genetic Programming visitation scheduling solution can deliver a less
  austere COVID-19 pandemic population lockdown","A computational methodology is introduced to minimize infection opportunities
for people suffering some degree of lockdown in response to a pandemic, as is
the 2020 COVID-19 pandemic. Persons use their mobile phone or computational
device to request trips to places of their need or interest indicating a rough
time of day: `morning', `afternoon', `night' or `any time' when they would like
to undertake these outings as well as the desired place to visit. An artificial
intelligence methodology which is a variant of Genetic Programming studies all
requests and responds with specific time allocations for such visits that
minimize the overall risks of infection, hospitalization and death of people. A
number of alternatives for this computation are presented and results of
numerical experiments involving over 230 people of various ages and background
health levels in over 1700 visits that take place over three consecutive days.
A novel partial infection model is introduced to discuss these proof of concept
solutions which are compared to round robin uninformed time scheduling for
visits to places. The computations indicate vast improvements with far fewer
dead and hospitalized. These auger well for a more realistic study using
accurate infection models with the view to test deployment in the real world.
The input that drives the infection model is the degree of infection by
taxonomic class, such as the information that may arise from population testing
for COVID-19 or, alternatively, any contamination model. The taxonomy class
assumed in the computations is the likely level of infection by age group.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.09519v1,2020-06-16T21:16:53Z,2020-06-16T21:16:53Z,Aligning with Heterogeneous Preferences for Kidney Exchange,"AI algorithms increasingly make decisions that impact entire groups of
humans. Since humans tend to hold varying and even conflicting preferences, AI
algorithms responsible for making decisions on behalf of such groups encounter
the problem of preference aggregation: combining inconsistent and sometimes
contradictory individual preferences into a representative aggregate. In this
paper, we address this problem in a real-world public health context: kidney
exchange. The algorithms that allocate kidneys from living donors to patients
needing transplants in kidney exchange matching markets should prioritize
patients in a way that aligns with the values of the community they serve, but
allocation preferences vary widely across individuals. In this paper, we
propose, implement and evaluate a methodology for prioritizing patients based
on such heterogeneous moral preferences. Instead of selecting a single static
set of patient weights, we learn a distribution over preference functions based
on human subject responses to allocation dilemmas, then sample from this
distribution to dynamically determine patient weights during matching. We find
that this methodology increases the average rank of matched patients in the
sampled preference ordering, indicating better satisfaction of group
preferences. We hope that this work will suggest a roadmap for future automated
moral decision making on behalf of heterogeneous groups.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.07900v1,2020-06-14T13:29:02Z,2020-06-14T13:29:02Z,ResOT: Resource-Efficient Oblique Trees for Neural Signal Classification,"Classifiers that can be implemented on chip with minimal computational and
memory resources are essential for edge computing in emerging applications such
as medical and IoT devices. This paper introduces a machine learning model
based on oblique decision trees to enable resource-efficient classification on
a neural implant. By integrating model compression with probabilistic routing
and implementing cost-aware learning, our proposed model could significantly
reduce the memory and hardware cost compared to state-of-the-art models, while
maintaining the classification accuracy. We trained the resource-efficient
oblique tree with power-efficient regularization (ResOT-PE) on three neural
classification tasks to evaluate the performance, memory, and hardware
requirements. On seizure detection task, we were able to reduce the model size
by 3.4X and the feature extraction cost by 14.6X compared to the ensemble of
boosted trees, using the intracranial EEG from 10 epilepsy patients. In a
second experiment, we tested the ResOT-PE model on tremor detection for
Parkinson's disease, using the local field potentials from 12 patients
implanted with a deep-brain stimulation (DBS) device. We achieved a comparable
classification performance as the state-of-the-art boosted tree ensemble, while
reducing the model size and feature extraction cost by 10.6X and 6.8X,
respectively. We also tested on a 6-class finger movement detection task using
ECoG recordings from 9 subjects, reducing the model size by 17.6X and feature
computation cost by 5.1X. The proposed model can enable a low-power and
memory-efficient implementation of classifiers for real-time neurological
disease detection and motor decoding.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.06385v1,2020-06-11T13:00:02Z,2020-06-11T13:00:02Z,"TensorFlow with user friendly Graphical Framework for object detection
  API","TensorFlow is an open-source framework for deep learning dataflow and
contains application programming interfaces (APIs) of voice analysis, natural
language process, and computer vision. Especially, TensorFlow object detection
API in computer vision field has been widely applied to technologies of
agriculture, engineering, and medicine but barriers to entry of the framework
usage is still high through command-line interface (CLI) and code for amateurs
and beginners of information technology (IT) field. Therefore, this is aim to
develop an user friendly Graphical Framework for object detection API on
TensorFlow which is called TensorFlow Graphical Framework (TF-GraF). The
TF-GraF provides independent virtual environments according to user accounts in
server-side, additionally, execution of data preprocessing, training, and
evaluation without CLI in client-side. Furthermore, hyperparameter setting,
real-time observation of training process, object visualization of test images,
and metrics evaluations of test data can also be operated via TF-GraF.
Especially, TF-GraF supports flexible model selection of SSD, Faster-RCNN,
RFCN, and Mask-RCNN including convolutional neural networks (inceptions and
ResNets) through GUI environment. Consequently, TF-GraF allows anyone, even
without any previous knowledge of deep learning frameworks, to design, train
and deploy machine intelligence models without coding. Since TF-GraF takes care
of setting and configuration, it allows anyone to use deep learning technology
for their project without spending time to install complex software and
environment.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.05301v3,2021-03-21T11:42:08Z,2020-06-09T14:40:00Z,VAEs in the Presence of Missing Data,"Real world datasets often contain entries with missing elements e.g. in a
medical dataset, a patient is unlikely to have taken all possible diagnostic
tests. Variational Autoencoders (VAEs) are popular generative models often used
for unsupervised learning. Despite their widespread use it is unclear how best
to apply VAEs to datasets with missing data. We develop a novel latent variable
model of a corruption process which generates missing data, and derive a
corresponding tractable evidence lower bound (ELBO). Our model is
straightforward to implement, can handle both missing completely at random
(MCAR) and missing not at random (MNAR) data, scales to high dimensional inputs
and gives both the VAE encoder and decoder principled access to indicator
variables for whether a data element is missing or not. On the MNIST and SVHN
datasets we demonstrate improved marginal log-likelihood of observed data and
better missing data imputation, compared to existing approaches.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.04920v3,2021-08-21T05:14:02Z,2020-06-08T20:34:20Z,Survival regression with accelerated failure time model in XGBoost,"Survival regression is used to estimate the relation between time-to-event
and feature variables, and is important in application domains such as
medicine, marketing, risk management and sales management. Nonlinear tree based
machine learning algorithms as implemented in libraries such as XGBoost,
scikit-learn, LightGBM, and CatBoost are often more accurate in practice than
linear models. However, existing state-of-the-art implementations of tree-based
models have offered limited support for survival regression. In this work, we
implement loss functions for learning accelerated failure time (AFT) models in
XGBoost, to increase the support for survival modeling for different kinds of
label censoring. We demonstrate with real and simulated experiments the
effectiveness of AFT in XGBoost with respect to a number of baselines, in two
respects: generalization performance and training speed. Furthermore, we take
advantage of the support for NVIDIA GPUs in XGBoost to achieve substantial
speedup over multi-core CPUs. To our knowledge, our work is the first
implementation of AFT that utilizes the processing power of NVIDIA GPUs.
Starting from the 1.2.0 release, the XGBoost package natively supports the AFT
model. The addition of AFT in XGBoost has had significant impact in the open
source community, and a few statistics packages now utilize the XGBoost AFT
model.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.03647v2,2020-06-23T16:54:09Z,2020-06-05T19:33:19Z,"Deployment-Efficient Reinforcement Learning via Model-Based Offline
  Optimization","Most reinforcement learning (RL) algorithms assume online access to the
environment, in which one may readily interleave updates to the policy with
experience collection using that policy. However, in many real-world
applications such as health, education, dialogue agents, and robotics, the cost
or potential risk of deploying a new data-collection policy is high, to the
point that it can become prohibitive to update the data-collection policy more
than a few times during learning. With this view, we propose a novel concept of
deployment efficiency, measuring the number of distinct data-collection
policies that are used during policy learning. We observe that na\""{i}vely
applying existing model-free offline RL algorithms recursively does not lead to
a practical deployment-efficient and sample-efficient algorithm. We propose a
novel model-based algorithm, Behavior-Regularized Model-ENsemble (BREMEN) that
can effectively optimize a policy offline using 10-20 times fewer data than
prior works. Furthermore, the recursive application of BREMEN is able to
achieve impressive deployment efficiency while maintaining the same or better
sample efficiency, learning successful policies from scratch on simulated
robotic environments with only 5-10 deployments, compared to typical values of
hundreds to millions in standard RL baselines. Codes and pre-trained models are
available at https://github.com/matsuolab/BREMEN .",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.13373v1,2020-05-27T14:08:46Z,2020-05-27T14:08:46Z,Deep Learning Assisted Data Inspection for Radio Astronomy,"Modern radio telescopes combine thousands of receivers, long-distance
networks, large-scale compute hardware, and intricate software. Due to this
complexity, failures occur relatively frequently. In this work we propose novel
use of unsupervised deep learning to diagnose system health for modern radio
telescopes. The model is a convolutional Variational Autoencoder (VAE) that
enables the projection of the high dimensional time-frequency data to a
low-dimensional prescriptive space. Using this projection, telescope operators
are able to visually inspect failures thereby maintaining system health. We
have trained and evaluated the performance of the VAE quantitatively in
controlled experiments on simulated data from HERA. Moreover, we present a
qualitative assessment of the the model trained and tested on real LOFAR data.
Through the use of a naive SVM classifier on the projected synthesised data, we
show that there is a trade-off between the dimensionality of the projection and
the number of compounded features in a given spectrogram. The VAE and SVM
combination scores between 65% and 90% accuracy depending on the number of
features in a given input. Finally, we show the prototype
system-health-diagnostic web framework that integrates the evaluated model. The
system is currently undergoing testing at the ASTRON observatory.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.12573v3,2021-05-08T11:45:24Z,2020-05-26T08:46:32Z,"Learning Global and Local Features of Normal Brain Anatomy for
  Unsupervised Abnormality Detection","In real-world clinical practice, overlooking unanticipated findings can
result in serious consequences. However, supervised learning, which is the
foundation for the current success of deep learning, only encourages models to
identify abnormalities that are defined in datasets in advance. Therefore,
abnormality detection must be implemented in medical images that are not
limited to a specific disease category. In this study, we demonstrate an
unsupervised learning framework for pixel-wise abnormality detection in brain
magnetic resonance imaging captured from a patient population with metastatic
brain tumor. Our concept is as follows: If an image reconstruction network can
faithfully reproduce the global features of normal anatomy, then the abnormal
lesions in unseen images can be identified based on the local difference from
those reconstructed as normal by a discriminative network. Both networks are
trained on a dataset comprising only normal images without labels. In addition,
we devise a metric to evaluate the anatomical fidelity of the reconstructed
images and confirm that the overall detection performance is improved when the
image reconstruction network achieves a higher score. For evaluation,
clinically significant abnormalities are comprehensively segmented. The results
show that the area under the receiver operating characteristics curve values
for metastatic brain tumors, extracranial metastatic tumors, postoperative
cavities, and structural changes are 0.78, 0.61, 0.91, and 0.60, respectively.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.11711v1,2020-05-24T10:32:49Z,2020-05-24T10:32:49Z,Learning Camera Miscalibration Detection,"Self-diagnosis and self-repair are some of the key challenges in deploying
robotic platforms for long-term real-world applications. One of the issues that
can occur to a robot is miscalibration of its sensors due to aging,
environmental transients, or external disturbances. Precise calibration lies at
the core of a variety of applications, due to the need to accurately perceive
the world. However, while a lot of work has focused on calibrating the sensors,
not much has been done towards identifying when a sensor needs to be
recalibrated. This paper focuses on a data-driven approach to learn the
detection of miscalibration in vision sensors, specifically RGB cameras. Our
contributions include a proposed miscalibration metric for RGB cameras and a
novel semi-synthetic dataset generation pipeline based on this metric.
Additionally, by training a deep convolutional neural network, we demonstrate
the effectiveness of our pipeline to identify whether a recalibration of the
camera's intrinsic parameters is required or not. The code is available at
http://github.com/ethz-asl/camera_miscalib_detection.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.08076v1,2020-05-16T19:42:16Z,2020-05-16T19:42:16Z,"A Deep Learning based Wearable Healthcare IoT Device for AI-enabled
  Hearing Assistance Automation","With the recent booming of artificial intelligence (AI), particularly deep
learning techniques, digital healthcare is one of the prevalent areas that
could gain benefits from AI-enabled functionality. This research presents a
novel AI-enabled Internet of Things (IoT) device operating from the ESP-8266
platform capable of assisting those who suffer from impairment of hearing or
deafness to communicate with others in conversations. In the proposed solution,
a server application is created that leverages Google's online speech
recognition service to convert the received conversations into texts, then
deployed to a micro-display attached to the glasses to display the conversation
contents to deaf people, to enable and assist conversation as normal with the
general population. Furthermore, in order to raise alert of traffic or
dangerous scenarios, an 'urban-emergency' classifier is developed using a deep
learning model, Inception-v4, with transfer learning to detect/recognize
alerting/alarming sounds, such as a horn sound or a fire alarm, with texts
generated to alert the prospective user. The training of Inception-v4 was
carried out on a consumer desktop PC and then implemented into the AI based IoT
application. The empirical results indicate that the developed prototype system
achieves an accuracy rate of 92% for sound recognition and classification with
real-time performance.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.07649v2,2021-09-23T01:42:58Z,2020-05-15T17:09:10Z,"Convolutional Neural Network for emotion recognition to assist
  psychiatrists and psychologists during the COVID-19 pandemic: experts opinion","A web application with real-time emotion recognition for psychologists and
psychiatrists is presented. Mental health effects during COVID-19 quarantine
need to be handled because society is being emotionally impacted. The human
micro-expressions can describe genuine emotions that can be captured by
Convolutional Neural Networks (CNN) models. But the challenge is to implement
it under the poor performance of a part of society computers and the low speed
of internet connection, i.e., improve the computational efficiency and reduce
the data transfer. To validate the computational efficiency premise, we compare
CNN architectures results, collecting the floating-point operations per second
(FLOPS), the Number of Parameters (NP) and accuracy from the MobileNet,
PeleeNet, Extended Deep Neural Network (EDNN), Inception- Based Deep Neural
Network (IDNN) and our proposed Residual mobile-based Network model (ResmoNet).
Also, we compare the trained models results in terms of Main Memory Utilization
(MMU) and Response Time to complete the Emotion (RTE) recognition. Besides, we
design a data transfer that includes the raw data of emotions and the basic
patient information. The web application was evaluated with the System
Usability Scale (SUS) and a utility questionnaire by psychologists and
psychiatrists. ResmoNet model generated the most reduced NP, FLOPS, and MMU
results, only EDNN overcomes ResmoNet in 0.01sec in RTE. The optimizations to
our model impacted the accuracy, therefore IDNN and EDNN are 0.02 and 0.05 more
accurate than our model respectively. Finally, according to psychologists and
psychiatrists, the web application has good usability (73.8 of 100) and utility
(3.94 of 5).",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.06892v1,2020-05-14T11:54:04Z,2020-05-14T11:54:04Z,ZynqNet: An FPGA-Accelerated Embedded Convolutional Neural Network,"Image Understanding is becoming a vital feature in ever more applications
ranging from medical diagnostics to autonomous vehicles. Many applications
demand for embedded solutions that integrate into existing systems with tight
real-time and power constraints. Convolutional Neural Networks (CNNs) presently
achieve record-breaking accuracies in all image understanding benchmarks, but
have a very high computational complexity. Embedded CNNs thus call for small
and efficient, yet very powerful computing platforms. This master thesis
explores the potential of FPGA-based CNN acceleration and demonstrates a fully
functional proof-of-concept CNN implementation on a Zynq System-on-Chip. The
ZynqNet Embedded CNN is designed for image classification on ImageNet and
consists of ZynqNet CNN, an optimized and customized CNN topology, and the
ZynqNet FPGA Accelerator, an FPGA-based architecture for its evaluation.
ZynqNet CNN is a highly efficient CNN topology. Detailed analysis and
optimization of prior topologies using the custom-designed Netscope CNN
Analyzer have enabled a CNN with 84.5% top-5 accuracy at a computational
complexity of only 530 million multiplyaccumulate operations. The topology is
highly regular and consists exclusively of convolutional layers, ReLU
nonlinearities and one global pooling layer. The CNN fits ideally onto the FPGA
accelerator. The ZynqNet FPGA Accelerator allows an efficient evaluation of
ZynqNet CNN. It accelerates the full network based on a nested-loop algorithm
which minimizes the number of arithmetic operations and memory accesses. The
FPGA accelerator has been synthesized using High-Level Synthesis for the Xilinx
Zynq XC-7Z045, and reaches a clock frequency of 200MHz with a device
utilization of 80% to 90 %.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.06342v1,2020-05-09T05:54:28Z,2020-05-09T05:54:28Z,"sCrop: A Internet-of-Agro-Things (IoAT) Enabled Solar Powered Smart
  Device for Automatic Plant Disease Prediction","Internet-of-Things (IoT) is omnipresent, ranging from home solutions to
turning wheels for the fourth industrial revolution. This article presents the
novel concept of Internet-of-Agro-Things (IoAT) with an example of automated
plant disease prediction. It consists of solar enabled sensor nodes which help
in continuous sensing and automating agriculture. The existing solutions have
implemented a battery powered sensor node. On the contrary, the proposed system
has adopted the use of an energy efficient way of powering using solar energy.
It is observed that around 80% of the crops are attacked with microbial
diseases in traditional agriculture. To prevent this, a health maintenance
system is integrated with the sensor node, which captures the image of the crop
and performs an analysis with the trained Convolutional Neural Network (CNN)
model. The deployment of the proposed system is demonstrated in a real-time
environment using a microcontroller, solar sensor nodes with a camera module,
and an mobile application for the farmers visualization of the farms. The
deployed prototype was deployed for two months and has achieved a robust
performance by sustaining in varied weather conditions and continued to remain
rust-free. The proposed deep learning framework for plant disease prediction
has achieved an accuracy of 99.2% testing accuracy.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.03077v1,2020-05-06T19:06:51Z,2020-05-06T19:06:51Z,"AVAC: A Machine Learning based Adaptive RRAM Variability-Aware
  Controller for Edge Devices","Recently, the Edge Computing paradigm has gained significant popularity both
in industry and academia. Researchers now increasingly target to improve
performance and reduce energy consumption of such devices. Some recent efforts
focus on using emerging RRAM technologies for improving energy efficiency,
thanks to their no leakage property and high integration density. As the
complexity and dynamism of applications supported by such devices escalate, it
has become difficult to maintain ideal performance by static RRAM controllers.
Machine Learning provides a promising solution for this, and hence, this work
focuses on extending such controllers to allow dynamic parameter updates. In
this work we propose an Adaptive RRAM Variability-Aware Controller, AVAC, which
periodically updates Wait Buffer and batch sizes using on-the-fly learning
models and gradient ascent. AVAC allows Edge devices to adapt to different
applications and their stages, to improve computation performance and reduce
energy consumption. Simulations demonstrate that the proposed model can provide
up to 29% increase in performance and 19% decrease in energy, compared to
static controllers, using traces of real-life healthcare applications on a
Raspberry-Pi based Edge deployment.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.02706v3,2020-09-30T08:14:54Z,2020-05-06T10:21:16Z,Knee Injury Detection using MRI with Efficiently-Layered Network (ELNet),"Magnetic Resonance Imaging (MRI) is a widely-accepted imaging technique for
knee injury analysis. Its advantage of capturing knee structure in three
dimensions makes it the ideal tool for radiologists to locate potential tears
in the knee. In order to better confront the ever growing workload of
musculoskeletal (MSK) radiologists, automated tools for patients' triage are
becoming a real need, reducing delays in the reading of pathological cases. In
this work, we present the Efficiently-Layered Network (ELNet), a convolutional
neural network (CNN) architecture optimized for the task of initial knee MRI
diagnosis for triage. Unlike past approaches, we train ELNet from scratch
instead of using a transfer-learning approach. The proposed method is validated
quantitatively and qualitatively, and compares favorably against
state-of-the-art MRNet while using a single imaging stack (axial or coronal) as
input. Additionally, we demonstrate our model's capability to locate tears in
the knee despite the absence of localization information during training.
Lastly, the proposed model is extremely lightweight ($<$ 1MB) and therefore
easy to train and deploy in real clinical settings. The code for our model is
provided at: https://github.com/mxtsai/ELNet.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.06612v1,2020-05-05T12:01:12Z,2020-05-05T12:01:12Z,"An Investigation of COVID-19 Spreading Factors with Explainable AI
  Techniques","Since COVID-19 was first identified in December 2019, various public health
interventions have been implemented across the world. As different measures are
implemented at different countries at different times, we conduct an assessment
of the relative effectiveness of the measures implemented in 18 countries and
regions using data from 22/01/2020 to 02/04/2020. We compute the top one and
two measures that are most effective for the countries and regions studied
during the period. Two Explainable AI techniques, SHAP and ECPI, are used in
our study; such that we construct (machine learning) models for predicting the
instantaneous reproduction number ($R_t$) and use the models as surrogates to
the real world and inputs that the greatest influence to our models are seen as
measures that are most effective. Across-the-board, city lockdown and contact
tracing are the two most effective measures. For ensuring $R_t<1$, public
wearing face masks is also important. Mass testing alone is not the most
effective measure although when paired with other measures, it can be
effective. Warm temperature helps for reducing the transmission.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.01180v2,2020-05-05T11:49:27Z,2020-05-03T20:27:10Z,MAGES 3.0: Tying the knot of medical VR,"In this work, we present MAGES 3.0, a novel Virtual Reality (VR)-based
authoring SDK platform for accelerated surgical training and assessment. The
MAGES Software Development Kit (SDK) allows code-free prototyping of any VR
psychomotor simulation of medical operations by medical professionals, who
urgently need a tool to solve the issue of outdated medical training. Our
platform encapsulates the following novel algorithmic techniques: a)
collaborative networking layer with Geometric Algebra (GA) interpolation engine
b) supervised machine learning analytics module for real-time recommendations
and user profiling c) GA deformable cutting and tearing algorithm d) on-the-go
configurable soft body simulation for deformable surfaces.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.11958v1,2020-04-24T19:36:37Z,2020-04-24T19:36:37Z,"The Plant Pathology 2020 challenge dataset to classify foliar disease of
  apples","Apple orchards in the U.S. are under constant threat from a large number of
pathogens and insects. Appropriate and timely deployment of disease management
depends on early disease detection. Incorrect and delayed diagnosis can result
in either excessive or inadequate use of chemicals, with increased production
costs, environmental, and health impacts. We have manually captured 3,651
high-quality, real-life symptom images of multiple apple foliar diseases, with
variable illumination, angles, surfaces, and noise. A subset, expert-annotated
to create a pilot dataset for apple scab, cedar apple rust, and healthy leaves,
was made available to the Kaggle community for 'Plant Pathology Challenge';
part of the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2020
(Computer Vision and Pattern Recognition). We also trained an off-the-shelf
convolutional neural network (CNN) on this data for disease classification and
achieved 97% accuracy on a held-out test set. This dataset will contribute
towards development and deployment of machine learning-based automated plant
disease classification algorithms to ultimately realize fast and accurate
disease detection. We will continue to add images to the pilot dataset for a
larger, more comprehensive expert-annotated dataset for future Kaggle
competitions and to explore more advanced methods for disease classification
and quantification.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.12881v1,2020-03-28T19:57:55Z,2020-03-28T19:57:55Z,"Streamlined Empirical Bayes Fitting of Linear Mixed Models in Mobile
  Health","To effect behavior change a successful algorithm must make high-quality
decisions in real-time. For example, a mobile health (mHealth) application
designed to increase physical activity must make contextually relevant
suggestions to motivate users. While machine learning offers solutions for
certain stylized settings, such as when batch data can be processed offline,
there is a dearth of approaches which can deliver high-quality solutions under
the specific constraints of mHealth. We propose an algorithm which provides
users with contextualized and personalized physical activity suggestions. This
algorithm is able to overcome a challenge critical to mHealth that complex
models be trained efficiently. We propose a tractable streamlined empirical
Bayes procedure which fits linear mixed effects models in large-data settings.
Our procedure takes advantage of sparsity introduced by hierarchical random
effects to efficiently learn the posterior distribution of a linear mixed
effects model. A key contribution of this work is that we provide explicit
updates in order to learn both fixed effects, random effects and
hyper-parameter values. We demonstrate the success of this approach in a mobile
health (mHealth) reinforcement learning application, a domain in which fast
computations are crucial for real time interventions. Not only is our approach
computationally efficient, it is also easily implemented with closed form
matrix algebraic updates and we show improvements over state of the art
approaches both in speed and accuracy of up to 99% and 56% respectively.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.12828v2,2020-06-24T16:39:37Z,2020-03-28T16:07:41Z,Learning medical triage from clinicians using Deep Q-Learning,"Medical Triage is of paramount importance to healthcare systems, allowing for
the correct orientation of patients and allocation of the necessary resources
to treat them adequately. While reliable decision-tree methods exist to triage
patients based on their presentation, those trees implicitly require human
inference and are not immediately applicable in a fully automated setting. On
the other hand, learning triage policies directly from experts may correct for
some of the limitations of hard-coded decision-trees. In this work, we present
a Deep Reinforcement Learning approach (a variant of DeepQ-Learning) to triage
patients using curated clinical vignettes. The dataset, consisting of 1374
clinical vignettes, was created by medical doctors to represent real-life
cases. Each vignette is associated with an average of 3.8 expert triage
decisions given by medical doctors relying solely on medical history. We show
that this approach is on a par with human performance, yielding safe triage
decisions in 94% of cases, and matching expert decisions in 85% of cases. The
trained agent learns when to stop asking questions, acquires optimized decision
policies requiring less evidence than supervised approaches, and adapts to the
novelty of a situation by asking for more information. Overall, we demonstrate
that a Deep Reinforcement Learning approach can learn effective medical triage
policies directly from expert decisions, without requiring expert knowledge
engineering. This approach is scalable and can be deployed in healthcare
settings or geographical regions with distinct triage specifications, or where
trained experts are scarce, to improve decision making in the early stage of
care.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.11117v1,2020-03-24T21:17:44Z,2020-03-24T21:17:44Z,"COVID-19 and Computer Audition: An Overview on What Speech & Sound
  Analysis Could Contribute in the SARS-CoV-2 Corona Crisis","At the time of writing, the world population is suffering from more than
10,000 registered COVID-19 disease epidemic induced deaths since the outbreak
of the Corona virus more than three months ago now officially known as
SARS-CoV-2. Since, tremendous efforts have been made worldwide to counter-steer
and control the epidemic by now labelled as pandemic. In this contribution, we
provide an overview on the potential for computer audition (CA), i.e., the
usage of speech and sound analysis by artificial intelligence to help in this
scenario. We first survey which types of related or contextually significant
phenomena can be automatically assessed from speech or sound. These include the
automatic recognition and monitoring of breathing, dry and wet coughing or
sneezing sounds, speech under cold, eating behaviour, sleepiness, or pain to
name but a few. Then, we consider potential use-cases for exploitation. These
include risk assessment and diagnosis based on symptom histograms and their
development over time, as well as monitoring of spread, social distancing and
its effects, treatment and recovery, and patient wellbeing. We quickly guide
further through challenges that need to be faced for real-life usage. We come
to the conclusion that CA appears ready for implementation of (pre-)diagnosis
and monitoring tools, and more generally provides rich and significant, yet so
far untapped potential in the fight against COVID-19 spread.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.10548v1,2020-03-23T21:04:43Z,2020-03-23T21:04:43Z,spsurv: An R package for semi-parametric survival analysis,"Software development innovations and advances in computing have enabled more
complex and less costly computations in medical research (survival analysis),
engineering studies (reliability analysis), and social sciences event analysis
(historical analysis). As a result, many semi-parametric modeling efforts
emerged when it comes to time-to-event data analysis. In this context, this
work presents a flexible Bernstein polynomial (BP) based framework for survival
data modeling. This innovative approach is applied to existing families of
models such as proportional hazards (PH), proportional odds (PO), and
accelerated failure time (AFT) models to estimate unknown baseline functions.
Along with this contribution, this work also presents new automated routines in
R, taking advantage of algorithms available in Stan. The proposed computation
routines are tested and explored through simulation studies based on artificial
datasets. The tools implemented to fit the proposed statistical models are
combined and organized in an R package. Also, the BP based proportional hazards
(BPPH), proportional odds (BPPO), and accelerated failure time (BPAFT) models
are illustrated in real applications related to cancer trial data using maximum
likelihood (ML) estimation and Markov chain Monte Carlo (MCMC) methods.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.09800v1,2020-03-22T03:58:05Z,2020-03-22T03:58:05Z,Forecasting and evaluating intervention of Covid-19 in the World,"When the Covid-19 pandemic enters dangerous new phase, whether and when to
take aggressive public health interventions to slow down the spread of
COVID-19. To develop the artificial intelligence (AI) inspired methods for
real-time forecasting and evaluating intervention strategies to curb the spread
of Covid-19 in the World. A modified auto-encoder for modeling the transmission
dynamics of the epidemics is developed and applied to the surveillance data of
cumulative and new Covid-19 cases and deaths from WHO, as of March 16, 2020.
The average errors of 5-step forecasting were 2.5%. The total peak number of
cumulative cases and new cases, and the maximum number of cumulative cases in
the world with later intervention (comprehensive public health intervention is
implemented 4 weeks later) could reach 75,249,909, 10,086,085, and 255,392,154,
respectively. The case ending time was January 10, 2021. However, the total
peak number of cumulative cases and new cases and the maximum number of
cumulative cases in the world with one week later intervention were reduced to
951,799, 108,853 and 1,530,276, respectively. Duration time of the Covid-19
spread would be reduced from 356 days to 232 days. The case ending time was
September 8, 2020. We observed that delaying intervention for one month caused
the maximum number of cumulative cases to increase 166.89 times, and the number
of deaths increase from 53,560 to 8,938,725. We will face disastrous
consequences if immediate action to intervene is not taken.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.07775v1,2020-03-11T10:15:06Z,2020-03-11T10:15:06Z,Deep generative models in DataSHIELD,"The best way to calculate statistics from medical data is to use the data of
individual patients. In some settings, this data is difficult to obtain due to
privacy restrictions. In Germany, for example, it is not possible to pool
routine data from different hospitals for research purposes without the consent
of the patients. The DataSHIELD software provides an infrastructure and a set
of statistical methods for joint analyses of distributed data. The contained
algorithms are reformulated to work with aggregated data from the participating
sites instead of the individual data. If a desired algorithm is not implemented
in DataSHIELD or cannot be reformulated in such a way, using artificial data is
an alternative. We present a methodology together with a software
implementation that builds on DataSHIELD to create artificial data that
preserve complex patterns from distributed individual patient data. Such data
sets of artificial patients, which are not linked to real patients, can then be
used for joint analyses. We use deep Boltzmann machines (DBMs) as generative
models for capturing the distribution of data. For the implementation, we
employ the package ""BoltzmannMachines"" from the Julia programming language and
wrap it for use with DataSHIELD, which is based on R. As an exemplary
application, we conduct a distributed analysis with DBMs on a synthetic data
set, which simulates genetic variant data. Patterns from the original data can
be recovered in the artificial data using hierarchical clustering of the
virtual patients, demonstrating the feasibility of the approach. Our
implementation adds to DataSHIELD the ability to generate artificial data that
can be used for various analyses, e. g. for pattern recognition with deep
learning. This also demonstrates more generally how DataSHIELD can be flexibly
extended with advanced algorithms from languages other than R.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.05731v4,2021-03-05T01:55:27Z,2020-03-11T00:22:50Z,"SUOD: Accelerating Large-Scale Unsupervised Heterogeneous Outlier
  Detection","Outlier detection (OD) is a key machine learning (ML) task for identifying
abnormal objects from general samples with numerous high-stake applications
including fraud detection and intrusion detection. Due to the lack of ground
truth labels, practitioners often have to build a large number of unsupervised,
heterogeneous models (i.e., different algorithms with varying hyperparameters)
for further combination and analysis, rather than relying on a single model.
How to accelerate the training and scoring on new-coming samples by
outlyingness (referred as prediction throughout the paper) with a large number
of unsupervised, heterogeneous OD models? In this study, we propose a modular
acceleration system, called SUOD, to address it. The proposed system focuses on
three complementary acceleration aspects (data reduction for high-dimensional
data, approximation for costly models, and taskload imbalance optimization for
distributed environment), while maintaining performance accuracy. Extensive
experiments on more than 20 benchmark datasets demonstrate SUOD's effectiveness
in heterogeneous OD acceleration, along with a real-world deployment case on
fraudulent claim analysis at IQVIA, a leading healthcare firm. We open-source
SUOD for reproducibility and accessibility.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.01719v1,2020-03-03T15:38:43Z,2020-03-03T15:38:43Z,"Image-based OoD-Detector Principles on Graph-based Input Data in Human
  Action Recognition","Living in a complex world like ours makes it unacceptable that a practical
implementation of a machine learning system assumes a closed world. Therefore,
it is necessary for such a learning-based system in a real world environment,
to be aware of its own capabilities and limits and to be able to distinguish
between confident and unconfident results of the inference, especially if the
sample cannot be explained by the underlying distribution. This knowledge is
particularly essential in safety-critical environments and tasks e.g.
self-driving cars or medical applications. Towards this end, we transfer
image-based Out-of-Distribution (OoD)-methods to graph-based data and show the
applicability in action recognition. The contribution of this work is (i) the
examination of the portability of recent image-based OoD-detectors for
graph-based input data, (ii) a Metric Learning-based approach to detect
OoD-samples, and (iii) the introduction of a novel semi-synthetic action
recognition dataset. The evaluation shows that image-based OoD-methods can be
applied to graph-based data. Additionally, there is a gap between the
performance on intraclass and intradataset results. First methods as the
examined baseline or ODIN provide reasonable results. More sophisticated
network architectures - in contrast to their image-based application - were
surpassed in the intradataset comparison and even lead to less classification
accuracy.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.05229v1,2020-02-12T20:35:31Z,2020-02-12T20:35:31Z,"Data Efficient Training for Reinforcement Learning with Adaptive
  Behavior Policy Sharing","Deep Reinforcement Learning (RL) is proven powerful for decision making in
simulated environments. However, training deep RL model is challenging in real
world applications such as production-scale health-care or recommender systems
because of the expensiveness of interaction and limitation of budget at
deployment. One aspect of the data inefficiency comes from the expensive
hyper-parameter tuning when optimizing deep neural networks. We propose
Adaptive Behavior Policy Sharing (ABPS), a data-efficient training algorithm
that allows sharing of experience collected by behavior policy that is
adaptively selected from a pool of agents trained with an ensemble of
hyper-parameters. We further extend ABPS to evolve hyper-parameters during
training by hybridizing ABPS with an adapted version of Population Based
Training (ABPS-PBT). We conduct experiments with multiple Atari games with up
to 16 hyper-parameter/architecture setups. ABPS achieves superior overall
performance, reduced variance on top 25% agents, and equivalent performance on
the best agent compared to conventional hyper-parameter tuning with independent
training, even though ABPS only requires the same number of environmental
interactions as training a single agent. We also show that ABPS-PBT further
improves the convergence speed and reduces the variance.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.04700v4,2020-03-15T03:27:52Z,2020-02-11T21:42:22Z,"A Single RGB Camera Based Gait Analysis with a Mobile Tele-Robot for
  Healthcare","With the increasing awareness of high-quality life, there is a growing need
for health monitoring devices running robust algorithms in home environment.
Health monitoring technologies enable real-time analysis of users' health
status, offering long-term healthcare support and reducing hospitalization
time. The purpose of this work is twofold, the software focuses on the analysis
of gait, which is widely adopted for joint correction and assessing any lower
limb or spinal problem. On the hardware side, we design a novel marker-less
gait analysis device using a low-cost RGB camera mounted on a mobile
tele-robot. As gait analysis with a single camera is much more challenging
compared to previous works utilizing multi-cameras, a RGB-D camera or wearable
sensors, we propose using vision-based human pose estimation approaches. More
specifically, based on the output of two state-of-the-art human pose estimation
models (Openpose and VNect), we devise measurements for four bespoke gait
parameters: inversion/eversion, dorsiflexion/plantarflexion, ankle and foot
progression angles. We thereby classify walking patterns into normal,
supination, pronation and limp. We also illustrate how to run the purposed
machine learning models in low-resource environments such as a single
entry-level CPU. Experiments show that our single RGB camera method achieves
competitive performance compared to state-of-the-art methods based on depth
cameras or multi-camera motion capture system, at smaller hardware costs.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.03478v3,2020-08-11T06:51:45Z,2020-02-10T00:26:43Z,"Interpretable Off-Policy Evaluation in Reinforcement Learning by
  Highlighting Influential Transitions","Off-policy evaluation in reinforcement learning offers the chance of using
observational data to improve future outcomes in domains such as healthcare and
education, but safe deployment in high stakes settings requires ways of
assessing its validity. Traditional measures such as confidence intervals may
be insufficient due to noise, limited data and confounding. In this paper we
develop a method that could serve as a hybrid human-AI system, to enable human
experts to analyze the validity of policy evaluation estimates. This is
accomplished by highlighting observations in the data whose removal will have a
large effect on the OPE estimate, and formulating a set of rules for choosing
which ones to present to domain experts for validation. We develop methods to
compute exactly the influence functions for fitted Q-evaluation with two
different function classes: kernel-based and linear least squares, as well as
importance sampling methods. Experiments on medical simulations and real-world
intensive care unit data demonstrate that our method can be used to identify
limitations in the evaluation process and make evaluation more robust.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.02897v2,2020-02-15T14:34:48Z,2020-02-07T16:55:21Z,"MDLdroid: a ChainSGD-reduce Approach to Mobile Deep Learning for
  Personal Mobile Sensing","Personal mobile sensing is fast permeating our daily lives to enable activity
monitoring, healthcare and rehabilitation. Combined with deep learning, these
applications have achieved significant success in recent years. Different from
conventional cloud-based paradigms, running deep learning on devices offers
several advantages including data privacy preservation and low-latency response
for both model inference and update. Since data collection is costly in
reality, Google's Federated Learning offers not only complete data privacy but
also better model robustness based on multiple user data. However, personal
mobile sensing applications are mostly user-specific and highly affected by
environment. As a result, continuous local changes may seriously affect the
performance of a global model generated by Federated Learning. In addition,
deploying Federated Learning on a local server, e.g., edge server, may quickly
reach the bottleneck due to resource constraint and serious failure by attacks.
Towards pushing deep learning on devices, we present MDLdroid, a novel
decentralized mobile deep learning framework to enable resource-aware on-device
collaborative learning for personal mobile sensing applications. To address
resource limitation, we propose a ChainSGD-reduce approach which includes a
novel chain-directed Synchronous Stochastic Gradient Descent algorithm to
effectively reduce overhead among multiple devices. We also design an
agent-based multi-goal reinforcement learning mechanism to balance resources in
a fair and efficient manner. Our evaluations show that our model training on
off-the-shelf mobile devices achieves 2x to 3.5x faster than single-device
training, and 1.5x faster than the master-slave approach.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.03763v2,2020-02-22T16:56:25Z,2020-02-03T22:58:28Z,Learning Numerical Observers using Unsupervised Domain Adaptation,"Medical imaging systems are commonly assessed by use of objective image
quality measures. Supervised deep learning methods have been investigated to
implement numerical observers for task-based image quality assessment. However,
labeling large amounts of experimental data to train deep neural networks is
tedious, expensive, and prone to subjective errors. Computer-simulated image
data can potentially be employed to circumvent these issues; however, it is
often difficult to computationally model complicated anatomical structures,
noise sources, and the response of real world imaging systems. Hence, simulated
image data will generally possess physical and statistical differences from the
experimental image data they seek to emulate. Within the context of machine
learning, these differences between the sets of two images is referred to as
domain shift. In this study, we propose and investigate the use of an
adversarial domain adaptation method to mitigate the deleterious effects of
domain shift between simulated and experimental image data for deep
learning-based numerical observers (DL-NOs) that are trained on simulated
images but applied to experimental ones. In the proposed method, a DL-NO will
initially be trained on computer-simulated image data and subsequently adapted
for use with experimental image data, without the need for any labeled
experimental images. As a proof of concept, a binary signal detection task is
considered. The success of this strategy as a function of the degree of domain
shift present between the simulated and experimental image data is
investigated.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.11363v1,2020-01-29T17:23:16Z,2020-01-29T17:23:16Z,"REST: Robust and Efficient Neural Networks for Sleep Monitoring in the
  Wild","In recent years, significant attention has been devoted towards integrating
deep learning technologies in the healthcare domain. However, to safely and
practically deploy deep learning models for home health monitoring, two
significant challenges must be addressed: the models should be (1) robust
against noise; and (2) compact and energy-efficient. We propose REST, a new
method that simultaneously tackles both issues via 1) adversarial training and
controlling the Lipschitz constant of the neural network through spectral
regularization while 2) enabling neural network compression through sparsity
regularization. We demonstrate that REST produces highly-robust and efficient
models that substantially outperform the original full-sized models in the
presence of noise. For the sleep staging task over single-channel
electroencephalogram (EEG), the REST model achieves a macro-F1 score of 0.67
vs. 0.39 achieved by a state-of-the-art model in the presence of Gaussian noise
while obtaining 19x parameter reduction and 15x MFLOPS reduction on two large,
real-world EEG datasets. By deploying these models to an Android application on
a smartphone, we quantitatively observe that REST allows models to achieve up
to 17x energy reduction and 9x faster inference. We open-source the code
repository with this paper: https://github.com/duggalrahul/REST.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.09346v2,2020-03-04T19:22:37Z,2020-01-25T18:43:47Z,"CorGAN: Correlation-Capturing Convolutional Generative Adversarial
  Networks for Generating Synthetic Healthcare Records","Deep learning models have demonstrated high-quality performance in areas such
as image classification and speech processing. However, creating a deep
learning model using electronic health record (EHR) data, requires addressing
particular privacy challenges that are unique to researchers in this domain.
This matter focuses attention on generating realistic synthetic data while
ensuring privacy. In this paper, we propose a novel framework called
correlation-capturing Generative Adversarial Network (CorGAN), to generate
synthetic healthcare records. In CorGAN we utilize Convolutional Neural
Networks to capture the correlations between adjacent medical features in the
data representation space by combining Convolutional Generative Adversarial
Networks and Convolutional Autoencoders. To demonstrate the model fidelity, we
show that CorGAN generates synthetic data with performance similar to that of
real data in various Machine Learning settings such as classification and
prediction. We also give a privacy assessment and report on statistical
analysis regarding realistic characteristics of the synthetic data. The
software of this work is open-source and is available at:
https://github.com/astorfi/cor-gan.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.09282v2,2020-04-08T08:52:44Z,2020-01-25T09:13:39Z,"Limited Angle Tomography reconstruction for non-standard MBI system by
  means of parallel-hole and pinhole optics","The purpose of the present work is the study of reconstruction properties of
a new Molecular Breast Imaging (MBI) device for the early diagnosis of breast
cancer, in Limited Angle Tomography (LAT), by using two asymmetric detector
heads with different collimators. The detectors face each other in
anti-parallel viewing direction and, mild-compressing the breast phantom, they
are able to reconstruct the inner tumour of the phantoms with only a limited
number of projections using a dedicated maximum-likelihood expectation
maximization (ML-EM) algorithm. Phantoms, MBI system, as well as Monte Carlo
simulator using Geant 4 Application for Tomographic Emission (GATE) software,
are briefly described. MBI system's model has been implemented in IDL
(Interactive Data Visualization), in order to evaluate the best LAT
configuration of the system and its reconstruction ability by varying tumour's
size, depth and uptake. LAT setup in real and simulated configurations, as well
as the ML-EM method and the preliminary reconstruction results, are discussed.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.09778v2,2020-02-06T14:46:51Z,2020-01-22T15:39:42Z,"Artificial intelligence in medicine and healthcare: a review and
  classification of current and near-future applications and their ethical and
  social Impact","This paper provides an overview of the current and near-future applications
of Artificial Intelligence (AI) in Medicine and Health Care and presents a
classification according to their ethical and societal aspects, potential
benefits and pitfalls, and issues that can be considered controversial and are
not deeply discussed in the literature.
  This work is based on an analysis of the state of the art of research and
technology, including existing software, personal monitoring devices, genetic
tests and editing tools, personalized digital models, online platforms,
augmented reality devices, and surgical and companion robotics. Motivated by
our review, we present and describe the notion of 'extended personalized
medicine', we then review existing applications of AI in medicine and
healthcare and explore the public perception of medical AI systems, and how
they show, simultaneously, extraordinary opportunities and drawbacks that even
question fundamental medical concepts. Many of these topics coincide with
urgent priorities recently defined by the World Health Organization for the
coming decade. In addition, we study the transformations of the roles of
doctors and patients in an age of ubiquitous information, identify the risk of
a division of Medicine into 'fake-based', 'patient-generated', and
'scientifically tailored', and draw the attention of some aspects that need
further thorough analysis and public debate.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.07769v3,2020-02-16T22:19:32Z,2020-01-21T20:41:27Z,"Massif: Interactive Interpretation of Adversarial Attacks on Deep
  Learning","Deep neural networks (DNNs) are increasingly powering high-stakes
applications such as autonomous cars and healthcare; however, DNNs are often
treated as ""black boxes"" in such applications. Recent research has also
revealed that DNNs are highly vulnerable to adversarial attacks, raising
serious concerns over deploying DNNs in the real world. To overcome these
deficiencies, we are developing Massif, an interactive tool for deciphering
adversarial attacks. Massif identifies and interactively visualizes neurons and
their connections inside a DNN that are strongly activated or suppressed by an
adversarial attack. Massif provides both a high-level, interpretable overview
of the effect of an attack on a DNN, and a low-level, detailed description of
the affected neurons. These tightly coupled views in Massif help people better
understand which input features are most vulnerable or important for correct
predictions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.05375v1,2020-01-15T15:30:29Z,2020-01-15T15:30:29Z,"AAAI FSS-19: Human-Centered AI: Trustworthiness of AI Models and Data
  Proceedings","To facilitate the widespread acceptance of AI systems guiding decision-making
in real-world applications, it is key that solutions comprise trustworthy,
integrated human-AI systems. Not only in safety-critical applications such as
autonomous driving or medicine, but also in dynamic open world systems in
industry and government it is crucial for predictive models to be
uncertainty-aware and yield trustworthy predictions. Another key requirement
for deployment of AI at enterprise scale is to realize the importance of
integrating human-centered design into AI systems such that humans are able to
use systems effectively, understand results and output, and explain findings to
oversight committees.
  While the focus of this symposium was on AI systems to improve data quality
and technical robustness and safety, we welcomed submissions from broadly
defined areas also discussing approaches addressing requirements such as
explainable models, human trust and ethical aspects of AI.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.01215v2,2020-01-07T08:57:16Z,2020-01-05T11:33:31Z,A System for Real-Time Interactive Analysis of Deep Learning Training,"Performing diagnosis or exploratory analysis during the training of deep
learning models is challenging but often necessary for making a sequence of
decisions guided by the incremental observations. Currently available systems
for this purpose are limited to monitoring only the logged data that must be
specified before the training process starts. Each time a new information is
desired, a cycle of stop-change-restart is required in the training process.
These limitations make interactive exploration and diagnosis tasks difficult,
imposing long tedious iterations during the model development. We present a new
system that enables users to perform interactive queries on live processes
generating real-time information that can be rendered in multiple formats on
multiple surfaces in the form of several desired visualizations simultaneously.
To achieve this, we model various exploratory inspection and diagnostic tasks
for deep learning training processes as specifications for streams using a
map-reduce paradigm with which many data scientists are already familiar. Our
design achieves generality and extensibility by defining composable primitives
which is a fundamentally different approach than is used by currently available
systems. The open source implementation of our system is available as
TensorWatch project at https://github.com/microsoft/tensorwatch.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.00660v1,2020-01-02T22:56:15Z,2020-01-02T22:56:15Z,A Parallel Sparse Tensor Benchmark Suite on CPUs and GPUs,"Tensor computations present significant performance challenges that impact a
wide spectrum of applications ranging from machine learning, healthcare
analytics, social network analysis, data mining to quantum chemistry and signal
processing. Efforts to improve the performance of tensor computations include
exploring data layout, execution scheduling, and parallelism in common tensor
kernels. This work presents a benchmark suite for arbitrary-order sparse tensor
kernels using state-of-the-art tensor formats: coordinate (COO) and
hierarchical coordinate (HiCOO) on CPUs and GPUs. It presents a set of
reference tensor kernel implementations that are compatible with real-world
tensors and power law tensors extended from synthetic graph generation
techniques. We also propose Roofline performance models for these kernels to
provide insights of computer platforms from sparse tensor view.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.12397v1,2019-12-28T04:05:15Z,2019-12-28T04:05:15Z,"Natural language processing of MIMIC-III clinical notes for identifying
  diagnosis and procedures with neural networks","Coding diagnosis and procedures in medical records is a crucial process in
the healthcare industry, which includes the creation of accurate billings,
receiving reimbursements from payers, and creating standardized patient care
records. In the United States, Billing and Insurance related activities cost
around $471 billion in 2012 which constitutes about 25% of all the U.S hospital
spending. In this paper, we report the performance of a natural language
processing model that can map clinical notes to medical codes, and predict
final diagnosis from unstructured entries of history of present illness,
symptoms at the time of admission, etc. Previous studies have demonstrated that
deep learning models perform better at such mapping when compared to
conventional machine learning models. Therefore, we employed state-of-the-art
deep learning method, ULMFiT on the largest emergency department clinical notes
dataset MIMIC III which has 1.2M clinical notes to select for the top-10 and
top-50 diagnosis and procedure codes. Our models were able to predict the
top-10 diagnoses and procedures with 80.3% and 80.5% accuracy, whereas the
top-50 ICD-9 codes of diagnosis and procedures are predicted with 70.7% and
63.9% accuracy. Prediction of diagnosis and procedures from unstructured
clinical notes benefit human coders to save time, eliminate errors and minimize
costs. With promising scores from our present model, the next step would be to
deploy this on a small-scale real-world scenario and compare it with human
coders as the gold standard. We believe that further research of this approach
can create highly accurate predictions that can ease the workflow in a clinical
setting.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.12115v1,2019-12-27T14:39:58Z,2019-12-27T14:39:58Z,Split Learning for collaborative deep learning in healthcare,"Shortage of labeled data has been holding the surge of deep learning in
healthcare back, as sample sizes are often small, patient information cannot be
shared openly, and multi-center collaborative studies are a burden to set up.
Distributed machine learning methods promise to mitigate these problems. We
argue for a split learning based approach and apply this distributed learning
method for the first time in the medical field to compare performance against
(1) centrally hosted and (2) non collaborative configurations for a range of
participants. Two medical deep learning tasks are used to compare split
learning to conventional single and multi center approaches: a binary
classification problem of a data set of 9000 fundus photos, and multi-label
classification problem of a data set of 156,535 chest X-rays. The several
distributed learning setups are compared for a range of 1-50 distributed
participants. Performance of the split learning configuration remained constant
for any number of clients compared to a single center study, showing a marked
difference compared to the non collaborative configuration after 2 clients (p <
0.001) for both sets. Our results affirm the benefits of collaborative training
of deep neural networks in health care. Our work proves the significant benefit
of distributed learning in healthcare, and paves the way for future real-world
implementations.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.11119v3,2022-03-01T17:26:21Z,2019-12-23T21:40:08Z,MM for Penalized Estimation,"Penalized estimation can conduct variable selection and parameter estimation
simultaneously. The general framework is to minimize a loss function subject to
a penalty designed to generate sparse variable selection. The
majorization-minimization (MM) algorithm is a computational scheme for
stability and simplicity, and the MM algorithm has been widely applied in
penalized estimation. Much of the previous work have focused on convex loss
functions such as generalized linear models. When data are contaminated with
outliers, robust loss functions can generate more reliable estimates. Recent
literature has witnessed a growing impact of nonconvex loss-based methods,
which can generate robust estimation for data contaminated with outliers. This
article investigates MM algorithm for penalized estimation, provide innovative
optimality conditions and establish convergence theory with both convex and
nonconvex loss functions. With respect to applications, we focus on several
nonconvex loss functions, which were formerly studied in machine learning for
regression and classification problems. Performance of the proposed algorithms
are evaluated on simulated and real data including healthcare costs and cancer
clinical status. Efficient implementations of the algorithms are available in
the R package mpath in CRAN.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.09848v1,2019-12-20T14:35:49Z,2019-12-20T14:35:49Z,"Prediction of Physical Load Level by Machine Learning Analysis of Heart
  Activity after Exercises","The assessment of energy expenditure in real life is of great importance for
monitoring the current physical state of people, especially in work, sport,
elderly care, health care, and everyday life even. This work reports about
application of some machine learning methods (linear regression, linear
discriminant analysis, k-nearest neighbors, decision tree, random forest,
Gaussian naive Bayes, support-vector machine) for monitoring energy
expenditures in athletes. The classification problem was to predict the known
level of the in-exercise loads (in three categories by calories) by the heart
rate activity features measured during the short period of time (1 minute only)
after training, i.e by features of the post-exercise load. The results obtained
shown that the post-exercise heart activity features preserve the information
of the in-exercise training loads and allow us to predict their actual
in-exercise levels. The best performance can be obtained by the random forest
classifier with all 8 heart rate features (micro-averaged area under curve
value AUCmicro = 0.87 and macro-averaged one AUCmacro = 0.88) and the k-nearest
neighbors classifier with 4 most important heart rate features (AUCmicro = 0.91
and AUCmacro = 0.89). The limitations and perspectives of the ML methods used
are outlined, and some practical advices are proposed as to their improvement
and implementation for the better prediction of in-exercise energy
expenditures.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.09621v1,2019-12-20T02:57:05Z,2019-12-20T02:57:05Z,"Understanding Deep Neural Network Predictions for Medical Imaging
  Applications","Computer-aided detection has been a research area attracting great interest
in the past decade. Machine learning algorithms have been utilized extensively
for this application as they provide a valuable second opinion to the doctors.
Despite several machine learning models being available for medical imaging
applications, not many have been implemented in the real-world due to the
uninterpretable nature of the decisions made by the network. In this paper, we
investigate the results provided by deep neural networks for the detection of
malaria, diabetic retinopathy, brain tumor, and tuberculosis in different
imaging modalities. We visualize the class activation mappings for all the
applications in order to enhance the understanding of these networks. This type
of visualization, along with the corresponding network performance metrics,
would aid the data science experts in better understanding of their models as
well as assisting doctors in their decision-making process.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.01274v2,2020-04-06T19:00:35Z,2019-12-03T10:01:51Z,The Knowledge Within: Methods for Data-Free Model Compression,"Recently, an extensive amount of research has been focused on compressing and
accelerating Deep Neural Networks (DNN). So far, high compression rate
algorithms require part of the training dataset for a low precision
calibration, or a fine-tuning process. However, this requirement is
unacceptable when the data is unavailable or contains sensitive information, as
in medical and biometric use-cases. We present three methods for generating
synthetic samples from trained models. Then, we demonstrate how these samples
can be used to calibrate and fine-tune quantized models without using any real
data in the process. Our best performing method has a negligible accuracy
degradation compared to the original training set. This method, which leverages
intrinsic batch normalization layers' statistics of the trained model, can be
used to evaluate data similarity. Our approach opens a path towards genuine
data-free model compression, alleviating the need for training data during
model deployment.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.02102v1,2019-12-03T02:11:50Z,2019-12-03T02:11:50Z,"Artificial Intelligence for Low-Resource Communities: Influence
  Maximization in an Uncertain World","The potential of Artificial Intelligence (AI) to tackle challenging problems
that afflict society is enormous, particularly in the areas of healthcare,
conservation and public safety and security. Many problems in these domains
involve harnessing social networks of under-served communities to enable
positive change, e.g., using social networks of homeless youth to raise
awareness about Human Immunodeficiency Virus (HIV) and other STDs.
Unfortunately, most of these real-world problems are characterized by
uncertainties about social network structure and influence models, and previous
research in AI fails to sufficiently address these uncertainties. This thesis
addresses these shortcomings by advancing the state-of-the-art to a new
generation of algorithms for interventions in social networks. In particular,
this thesis describes the design and development of new influence maximization
algorithms which can handle various uncertainties that commonly exist in
real-world social networks. These algorithms utilize techniques from sequential
planning problems and social network theory to develop new kinds of AI
algorithms. Further, this thesis also demonstrates the real-world impact of
these algorithms by describing their deployment in three pilot studies to
spread awareness about HIV among actual homeless youth in Los Angeles. This
represents one of the first-ever deployments of computer science based
influence maximization algorithms in this domain. Our results show that our AI
algorithms improved upon the state-of-the-art by 160% in the real-world. We
discuss research and implementation challenges faced in deploying these
algorithms, and lessons that can be gleaned for future deployment of such
algorithms. The positive results from these deployments illustrate the enormous
potential of AI in addressing societally relevant problems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.08090v1,2019-11-19T04:33:05Z,2019-11-19T04:33:05Z,Deep Detector Health Management under Adversarial Campaigns,"Machine learning models are vulnerable to adversarial inputs that induce
seemingly unjustifiable errors. As automated classifiers are increasingly used
in industrial control systems and machinery, these adversarial errors could
grow to be a serious problem. Despite numerous studies over the past few years,
the field of adversarial ML is still considered alchemy, with no practical
unbroken defenses demonstrated to date, leaving PHM practitioners with few
meaningful ways of addressing the problem. We introduce turbidity detection as
a practical superset of the adversarial input detection problem, coping with
adversarial campaigns rather than statistically invisible one-offs. This
perspective is coupled with ROC-theoretic design guidance that prescribes an
inexpensive domain adaptation layer at the output of a deep learning model
during an attack campaign. The result aims to approximate the Bayes optimal
mitigation that ameliorates the detection model's degraded health. A
proactively reactive type of prognostics is achieved via Monte Carlo simulation
of various adversarial campaign scenarios, by sampling from the model's own
turbidity distribution to quickly deploy the correct mitigation during a
real-world campaign.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.08089v2,2019-12-07T03:42:06Z,2019-11-19T04:28:47Z,"""The Human Body is a Black Box"": Supporting Clinical Decision-Making
  with Deep Learning","Machine learning technologies are increasingly developed for use in
healthcare. While research communities have focused on creating
state-of-the-art models, there has been less focus on real world implementation
and the associated challenges to accuracy, fairness, accountability, and
transparency that come from actual, situated use. Serious questions remain
under examined regarding how to ethically build models, interpret and explain
model output, recognize and account for biases, and minimize disruptions to
professional expertise and work cultures. We address this gap in the literature
and provide a detailed case study covering the development, implementation, and
evaluation of Sepsis Watch, a machine learning-driven tool that assists
hospital clinicians in the early diagnosis and treatment of sepsis. We, the
team that developed and evaluated the tool, discuss our conceptualization of
the tool not as a model deployed in the world but instead as a socio-technical
system requiring integration into existing social and professional contexts.
Rather than focusing on model interpretability to ensure a fair and accountable
machine learning, we point toward four key values and practices that should be
considered when developing machine learning to support clinical
decision-making: rigorously define the problem in context, build relationships
with stakeholders, respect professional discretion, and create ongoing feedback
loops with stakeholders. Our work has significant implications for future
research regarding mechanisms of institutional accountability and
considerations for designing machine learning systems. Our work underscores the
limits of model interpretability as a solution to ensure transparency,
accuracy, and accountability in practice. Instead, our work demonstrates other
means and goals to achieve FATML values in design and in practice.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.06633v1,2019-11-15T13:50:27Z,2019-11-15T13:50:27Z,"HealthFog: An Ensemble Deep Learning based Smart Healthcare System for
  Automatic Diagnosis of Heart Diseases in Integrated IoT and Fog Computing
  Environments","Cloud computing provides resources over the Internet and allows a plethora of
applications to be deployed to provide services for different industries. The
major bottleneck being faced currently in these cloud frameworks is their
limited scalability and hence inability to cater to the requirements of
centralized Internet of Things (IoT) based compute environments. The main
reason for this is that latency-sensitive applications like health monitoring
and surveillance systems now require computation over large amounts of data
(Big Data) transferred to centralized database and from database to cloud data
centers which leads to drop in performance of such systems. The new paradigms
of fog and edge computing provide innovative solutions by bringing resources
closer to the user and provide low latency and energy-efficient solutions for
data processing compared to cloud domains. Still, the current fog models have
many limitations and focus from a limited perspective on either accuracy of
results or reduced response time but not both. We proposed a novel framework
called HealthFog for integrating ensemble deep learning in Edge computing
devices and deployed it for a real-life application of automatic Heart Disease
analysis. HealthFog delivers healthcare as a fog service using IoT devices and
efficiently manages the data of heart patients, which comes as user requests.
Fog-enabled cloud framework, FogBus is used to deploy and test the performance
of the proposed model in terms of power consumption, network bandwidth,
latency, jitter, accuracy and execution time. HealthFog is configurable to
various operation modes that provide the best Quality of Service or prediction
accuracy, as required, in diverse fog computation scenarios and for different
user requirements.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.05521v1,2019-11-13T14:56:36Z,2019-11-13T14:56:36Z,"Real-time ultra-low power ECG anomaly detection using an event-driven
  neuromorphic processor","Accurate detection of pathological conditions in human subjects can be
achieved through off-line analysis of recorded biological signals such as
electrocardiograms (ECGs). However, human diagnosis is time-consuming and
expensive, as it requires the time of medical professionals. This is especially
inefficient when indicative patterns in the biological signals are infrequent.
Moreover, patients with suspected pathologies are often monitored for extended
periods, requiring the storage and examination of large amounts of
non-pathological data, and entailing a difficult visual search task for
diagnosing professionals.
  In this work we propose a compact and sub-mW low power neural processing
system that can be used to perform on-line and real-time preliminary diagnosis
of pathological conditions, to raise warnings for the existence of possible
pathological conditions, or to trigger an off-line data recording system for
further analysis by a medical professional. We apply the system to real-time
classification of ECG data for distinguishing between healthy heartbeats and
pathological rhythms.
  Multi-channel analog ECG traces are encoded as asynchronous streams of binary
events and processed using a spiking recurrent neural network operated in a
reservoir computing paradigm. An event-driven neuron output layer is then
trained to recognize one of several pathologies. Finally, the filtered activity
of this output layer is used to generate a binary trigger signal indicating the
presence or absence of a pathological pattern.
  We validate the approach proposed using a Dynamic Neuromorphic Asynchronous
Processor (DYNAP) chip, implemented using a standard 180 nm CMOS VLSI process,
and present experimental results measured from the chip.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.02508v2,2020-02-03T18:53:50Z,2019-11-06T17:52:20Z,"Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation
  Methods","As machine learning black boxes are increasingly being deployed in domains
such as healthcare and criminal justice, there is growing emphasis on building
tools and techniques for explaining these black boxes in an interpretable
manner. Such explanations are being leveraged by domain experts to diagnose
systematic errors and underlying biases of black boxes. In this paper, we
demonstrate that post hoc explanations techniques that rely on input
perturbations, such as LIME and SHAP, are not reliable. Specifically, we
propose a novel scaffolding technique that effectively hides the biases of any
given classifier by allowing an adversarial entity to craft an arbitrary
desired explanation. Our approach can be used to scaffold any biased classifier
in such a way that its predictions on the input data distribution still remain
biased, but the post hoc explanations of the scaffolded classifier look
innocuous. Using extensive evaluation with multiple real-world datasets
(including COMPAS), we demonstrate how extremely biased (racist) classifiers
crafted by our framework can easily fool popular explanation techniques such as
LIME and SHAP into generating innocuous explanations which do not reflect the
underlying biases.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.13580v1,2019-10-29T23:43:01Z,2019-10-29T23:43:01Z,Domain Generalization via Model-Agnostic Learning of Semantic Features,"Generalization capability to unseen domains is crucial for machine learning
models when deploying to real-world conditions. We investigate the challenging
problem of domain generalization, i.e., training a model on multi-domain source
data such that it can directly generalize to target domains with unknown
statistics. We adopt a model-agnostic learning paradigm with gradient-based
meta-train and meta-test procedures to expose the optimization to domain shift.
Further, we introduce two complementary losses which explicitly regularize the
semantic structure of the feature space. Globally, we align a derived soft
confusion matrix to preserve general knowledge about inter-class relationships.
Locally, we promote domain-independent class-specific cohesion and separation
of sample features with a metric-learning component. The effectiveness of our
method is demonstrated with new state-of-the-art results on two common object
recognition benchmarks. Our method also shows consistent improvement on a
medical image segmentation task.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.03060v1,2019-10-07T20:06:38Z,2019-10-07T20:06:38Z,Impact of Inference Accelerators on hardware selection,"As opportunities for AI-assisted healthcare grow steadily, model deployment
faces challenges due to the specific characteristics of the industry. The
configuration choice for a production device can impact model performance while
influencing operational costs. Moreover, in healthcare some situations might
require fast, but not real time, inference. We study different configurations
and conduct a cost-performance analysis to determine the optimized hardware for
the deployment of a model subject to healthcare domain constraints. We observe
that a naive performance comparison may not lead to an optimal configuration
selection. In fact, given realistic domain constraints, CPU execution might be
preferable to GPU accelerators. Hence, defining beforehand precise expectations
for model deployment is crucial.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.01177v1,2019-10-02T19:24:31Z,2019-10-02T19:24:31Z,Improving Differentially Private Models with Active Learning,"Broad adoption of machine learning techniques has increased privacy concerns
for models trained on sensitive data such as medical records. Existing
techniques for training differentially private (DP) models give rigorous
privacy guarantees, but applying these techniques to neural networks can
severely degrade model performance. This performance reduction is an obstacle
to deploying private models in the real world. In this work, we improve the
performance of DP models by fine-tuning them through active learning on public
data. We introduce two new techniques - DIVERSEPUBLIC and NEARPRIVATE - for
doing this fine-tuning in a privacy-aware way. For the MNIST and SVHN datasets,
these techniques improve state-of-the-art accuracy for DP models while
retaining privacy guarantees.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.13343v2,2019-10-01T16:06:39Z,2019-09-29T19:15:08Z,"ISTHMUS: Secure, Scalable, Real-time and Robust Machine Learning
  Platform for Healthcare","In recent times, machine learning (ML) and artificial intelligence (AI) based
systems have evolved and scaled across different industries such as finance,
retail, insurance, energy utilities, etc. Among other things, they have been
used to predict patterns of customer behavior, to generate pricing models, and
to predict the return on investments. But the successes in deploying machine
learning models at scale in those industries have not translated into the
healthcare setting. There are multiple reasons why integrating ML models into
healthcare has not been widely successful, but from a technical perspective,
general-purpose commercial machine learning platforms are not a good fit for
healthcare due to complexities in handling data quality issues, mandates to
demonstrate clinical relevance, and a lack of ability to monitor performance in
a highly regulated environment with stringent security and privacy needs. In
this paper, we describe Isthmus, a turnkey, cloud-based platform which
addresses the challenges above and reduces time to market for operationalizing
ML/AI in healthcare. Towards the end, we describe three case studies which shed
light on Isthmus capabilities. These include (1) supporting an end-to-end
lifecycle of a model which predicts trauma survivability at hospital trauma
centers, (2) bringing in and harmonizing data from disparate sources to create
a community data platform for inferring population as well as patient level
insights for Social Determinants of Health (SDoH), and (3) ingesting
live-streaming data from various IoT sensors to build models, which can
leverage real-time and longitudinal information to make advanced time-sensitive
predictions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.10868v2,2020-02-01T02:19:29Z,2019-09-18T04:45:53Z,"Adversarial Representation Learning for Robust Patient-Independent
  Epileptic Seizure Detection","Objective: Epilepsy is a chronic neurological disorder characterized by the
occurrence of spontaneous seizures, which affects about one percent of the
world's population. Most of the current seizure detection approaches strongly
rely on patient history records and thus fail in the patient-independent
situation of detecting the new patients. To overcome such limitation, we
propose a robust and explainable epileptic seizure detection model that
effectively learns from seizure states while eliminates the inter-patient
noises. Methods: A complex deep neural network model is proposed to learn the
pure seizure-specific representation from the raw non-invasive
electroencephalography (EEG) signals through adversarial training. Furthermore,
to enhance the explainability, we develop an attention mechanism to
automatically learn the importance of each EEG channels in the seizure
diagnosis procedure. Results: The proposed approach is evaluated over the
Temple University Hospital EEG (TUH EEG) database. The experimental results
illustrate that our model outperforms the competitive state-of-the-art
baselines with low latency. Moreover, the designed attention mechanism is
demonstrated ables to provide fine-grained information for pathological
analysis. Conclusion and significance: We propose an effective and efficient
patient-independent diagnosis approach of epileptic seizure based on raw EEG
signals without manually feature engineering, which is a step toward the
development of large-scale deployment for real-life use.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.02511v2,2019-09-27T21:48:31Z,2019-09-05T16:31:40Z,"CT Data Curation for Liver Patients: Phase Recognition in Dynamic
  Contrast-Enhanced CT","As the demand for more descriptive machine learning models grows within
medical imaging, bottlenecks due to data paucity will exacerbate. Thus,
collecting enough large-scale data will require automated tools to harvest
data/label pairs from messy and real-world datasets, such as hospital PACS.
This is the focus of our work, where we present a principled data curation tool
to extract multi-phase CT liver studies and identify each scan's phase from a
real-world and heterogenous hospital PACS dataset. Emulating a typical
deployment scenario, we first obtain a set of noisy labels from our
institutional partners that are text mined using simple rules from DICOM tags.
We train a deep learning system, using a customized and streamlined 3D SE
architecture, to identify non-contrast, arterial, venous, and delay phase
dynamic CT liver scans, filtering out anything else, including other types of
liver contrast studies. To exploit as much training data as possible, we also
introduce an aggregated cross entropy loss that can learn from scans only
identified as ""contrast"". Extensive experiments on a dataset of 43K scans of
7680 patient imaging studies demonstrate that our 3DSE architecture, armed with
our aggregated loss, can achieve a mean F1 of 0.977 and can correctly harvest
up to 92.7% of studies, which significantly outperforms the text-mined and
standard-loss approach, and also outperforms other, and more complex, model
architectures.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.11863v1,2019-08-30T17:48:05Z,2019-08-30T17:48:05Z,Systematic Analysis of Image Generation using GANs,"Generative Adversarial Networks have been crucial in the developments made in
unsupervised learning in recent times. Exemplars of image synthesis from text
or other images, these networks have shown remarkable improvements over
conventional methods in terms of performance. Trained on the adversarial
training philosophy, these networks aim to estimate the potential distribution
from the real data and then use this as input to generate the synthetic data.
Based on this fundamental principle, several frameworks can be generated that
are paragon implementations in several real-life applications such as art
synthesis, generation of high resolution outputs and synthesis of images from
human drawn sketches, to name a few. While theoretically GANs present better
results and prove to be an improvement over conventional methods in many
factors, the implementation of these frameworks for dedicated applications
remains a challenge. This study explores and presents a taxonomy of these
frameworks and their use in various image to image synthesis and text to image
synthesis applications. The basic GANs, as well as a variety of different niche
frameworks, are critically analyzed. The advantages of GANs for image
generation over conventional methods as well their disadvantages amongst other
frameworks are presented. The future applications of GANs in industries such as
healthcare, art and entertainment are also discussed.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.08733v3,2020-03-03T15:27:57Z,2019-08-23T09:38:13Z,Neural Cognitive Diagnosis for Intelligent Education Systems,"Cognitive diagnosis is a fundamental issue in intelligent education, which
aims to discover the proficiency level of students on specific knowledge
concepts. Existing approaches usually mine linear interactions of student
exercising process by manual-designed function (e.g., logistic function), which
is not sufficient for capturing complex relations between students and
exercises. In this paper, we propose a general Neural Cognitive Diagnosis
(NeuralCD) framework, which incorporates neural networks to learn the complex
exercising interactions, for getting both accurate and interpretable diagnosis
results. Specifically, we project students and exercises to factor vectors and
leverage multi neural layers for modeling their interactions, where the
monotonicity assumption is applied to ensure the interpretability of both
factors. Furthermore, we propose two implementations of NeuralCD by
specializing the required concepts of each exercise, i.e., the NeuralCDM with
traditional Q-matrix and the improved NeuralCDM+ exploring the rich text
content. Extensive experimental results on real-world datasets show the
effectiveness of NeuralCD framework with both accuracy and interpretability.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.05764v5,2020-10-23T10:45:37Z,2019-08-15T21:03:42Z,"Learning Sub-Sampling and Signal Recovery with Applications in
  Ultrasound Imaging","Limitations on bandwidth and power consumption impose strict bounds on data
rates of diagnostic imaging systems. Consequently, the design of suitable (i.e.
task- and data-aware) compression and reconstruction techniques has attracted
considerable attention in recent years. Compressed sensing emerged as a popular
framework for sparse signal reconstruction from a small set of compressed
measurements. However, typical compressed sensing designs measure a
(non)linearly weighted combination of all input signal elements, which poses
practical challenges. These designs are also not necessarily task-optimal. In
addition, real-time recovery is hampered by the iterative and time-consuming
nature of sparse recovery algorithms. Recently, deep learning methods have
shown promise for fast recovery from compressed measurements, but the design of
adequate and practical sensing strategies remains a challenge. Here, we propose
a deep learning solution termed Deep Probabilistic Sub-sampling (DPS), that
learns a task-driven sub-sampling pattern, while jointly training a subsequent
task model. Once learned, the task-based sub-sampling patterns are fixed and
straightforwardly implementable, e.g. by non-uniform analog-to-digital
conversion, sparse array design, or slow-time ultrasound pulsing schemes. The
effectiveness of our framework is demonstrated in-silico for sparse signal
recovery from partial Fourier measurements, and in-vivo for both anatomical
image and tissue-motion (Doppler) reconstruction from sub-sampled medical
ultrasound imaging data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.06943v2,2020-04-24T15:13:00Z,2019-08-15T15:46:40Z,"Resolving challenges in deep learning-based analyses of
  histopathological images using explanation methods","Deep learning has recently gained popularity in digital pathology due to its
high prediction quality. However, the medical domain requires explanation and
insight for a better understanding beyond standard quantitative performance
evaluation. Recently, explanation methods have emerged, which are so far still
rarely used in medicine. This work shows their application to generate heatmaps
that allow to resolve common challenges encountered in deep learning-based
digital histopathology analyses. These challenges comprise biases typically
inherent to histopathology data. We study binary classification tasks of tumor
tissue discrimination in publicly available haematoxylin and eosin slides of
various tumor entities and investigate three types of biases: (1) biases which
affect the entire dataset, (2) biases which are by chance correlated with class
labels and (3) sampling biases. While standard analyses focus on patch-level
evaluation, we advocate pixel-wise heatmaps, which offer a more precise and
versatile diagnostic instrument and furthermore help to reveal biases in the
data. This insight is shown to not only detect but also to be helpful to remove
the effects of common hidden biases, which improves generalization within and
across datasets. For example, we could see a trend of improved area under the
receiver operating characteristic curve by 5% when reducing a labeling bias.
Explanation techniques are thus demonstrated to be a helpful and highly
relevant tool for the development and the deployment phases within the life
cycle of real-world applications in digital pathology.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.05376v1,2019-08-15T00:06:23Z,2019-08-15T00:06:23Z,"Maximum Relevance and Minimum Redundancy Feature Selection Methods for a
  Marketing Machine Learning Platform","In machine learning applications for online product offerings and marketing
strategies, there are often hundreds or thousands of features available to
build such models. Feature selection is one essential method in such
applications for multiple objectives: improving the prediction accuracy by
eliminating irrelevant features, accelerating the model training and prediction
speed, reducing the monitoring and maintenance workload for feature data
pipeline, and providing better model interpretation and diagnosis capability.
However, selecting an optimal feature subset from a large feature space is
considered as an NP-complete problem. The mRMR (Minimum Redundancy and Maximum
Relevance) feature selection framework solves this problem by selecting the
relevant features while controlling for the redundancy within the selected
features. This paper describes the approach to extend, evaluate, and implement
the mRMR feature selection methods for classification problem in a marketing
machine learning platform at Uber that automates creation and deployment of
targeting and personalization models at scale. This study first extends the
existing mRMR methods by introducing a non-linear feature redundancy measure
and a model-based feature relevance measure. Then an extensive empirical
evaluation is performed for eight different feature selection methods, using
one synthetic dataset and three real-world marketing datasets at Uber to cover
different use cases. Based on the empirical results, the selected mRMR method
is implemented in production for the marketing machine learning platform. A
description of the production implementation is provided and an online
experiment deployed through the platform is discussed.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.04537v2,2019-08-14T09:20:57Z,2019-08-13T08:49:33Z,"Icebreaker: Element-wise Active Information Acquisition with Bayesian
  Deep Latent Gaussian Model","In this paper we introduce the ice-start problem, i.e., the challenge of
deploying machine learning models when only little or no training data is
initially available, and acquiring each feature element of data is associated
with costs. This setting is representative for the real-world machine learning
applications. For instance, in the health-care domain, when training an AI
system for predicting patient metrics from lab tests, obtaining every single
measurement comes with a high cost. Active learning, where only the label is
associated with a cost does not apply to such problem, because performing all
possible lab tests to acquire a new training datum would be costly, as well as
unnecessary due to redundancy. We propose Icebreaker, a principled framework to
approach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent
Gaussian Model (BELGAM) with a novel inference method. Our proposed method
combines recent advances in amortized inference and stochastic gradient MCMC to
enable fast and accurate posterior inference. By utilizing BELGAM's ability to
fully quantify model uncertainty, we also propose two information acquisition
functions for imputation and active prediction problems. We demonstrate that
BELGAM performs significantly better than the previous VAE (Variational
autoencoder) based models, when the data set size is small, using both machine
learning benchmarks and real-world recommender systems and health-care
applications. Moreover, based on BELGAM, Icebreaker further improves the
performance and demonstrate the ability to use minimum amount of the training
data to obtain the highest test time performance.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.00149v1,2019-07-31T23:53:50Z,2019-07-31T23:53:50Z,"Response time optimization for drone-delivered automated external
  defibrillators","Out-of-hospital cardiac arrest (OHCA) claims over 400,000 lives each year in
North America and is one of the most time-sensitive medical emergencies.
Drone-delivered automated external defibrillators (AEDs) have the potential to
be a transformative innovation in the provision of emergency care for OHCA. In
this paper, we propose a simulation-optimization framework to minimize the
total number of drones required to meet a pre-specified response time goal,
while guaranteeing a sufficient number of drones are located at each base. To
do this, we develop a location-queuing model that is based on the p-median
architecture, where each base constitutes an explicit M/M/d queue, and that
incorporates estimated baseline response times to the demand points. We then
develop a reformulation technique that exploits the baseline response times,
allowing us to solve real-world instances to optimality using an off-the-shelf
solver. To test our model, we develop a two-stage machine learning approach to
simulate both the locations and baseline response times for future OHCAs. We
demonstrate the application of our framework using eight years of real data
from an area covering 26,000 square kilometres around Toronto, Canada. A modest
number of drones are required to significantly reduce response times in all
regions. Furthermore, an objective function focused on improving the 90th
percentile is well-suited for use in practice because the model reduces the
entire response time distribution, while providing equitable coverage in both
cities and rural areas. Overall, this paper provides a realistic framework that
can be leveraged by healthcare providers seeking to implement a drone network.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.10554v2,2020-03-26T16:11:35Z,2019-07-24T16:47:47Z,"Development of a Real-time Indoor Location System using Bluetooth Low
  Energy Technology and Deep Learning to Facilitate Clinical Applications","An indoor, real-time location system (RTLS) can benefit both hospitals and
patients by improving clinical efficiency through data-driven optimization of
procedures. Bluetooth-based RTLS systems are cost-effective but lack accuracy
and robustness because Bluetooth signal strength is subject to fluctuation. We
developed a machine learning-based solution using a Long Short-Term Memory
(LSTM) network followed by a Multilayer Perceptron classifier and a posterior
constraint algorithm to improve RTLS performance. Training and validation
datasets showed that most machine learning models perform well in classifying
individual location zones, although LSTM was most reliable. However, when faced
with data indicating cross-zone trajectories, all models showed erratic zone
switching. Thus, we implemented a history-based posterior constraint algorithm
to reduce the variability in exchange for a slight decrease in responsiveness.
This network increases robustness at the expense of latency. When latency is
less of a concern, we computed the latency-corrected accuracy which is 100% for
our testing data, significantly improved from LSTM without constraint which is
96.2%. The balance between robustness and responsiveness can be considered and
adjusted on a case-by-case basis, according to the specific needs of downstream
clinical applications. This system was deployed and validated in an academic
medical center. Industry best practices enabled system scaling without
substantial compromises to performance or cost.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.07296v4,2019-10-03T19:38:48Z,2019-07-17T00:50:37Z,"Explaining Vulnerabilities to Adversarial Machine Learning through
  Visual Analytics","Machine learning models are currently being deployed in a variety of
real-world applications where model predictions are used to make decisions
about healthcare, bank loans, and numerous other critical tasks. As the
deployment of artificial intelligence technologies becomes ubiquitous, it is
unsurprising that adversaries have begun developing methods to manipulate
machine learning models to their advantage. While the visual analytics
community has developed methods for opening the black box of machine learning
models, little work has focused on helping the user understand their model
vulnerabilities in the context of adversarial attacks. In this paper, we
present a visual analytics framework for explaining and exploring model
vulnerabilities to adversarial attacks. Our framework employs a multi-faceted
visualization scheme designed to support the analysis of data poisoning attacks
from the perspective of models, data instances, features, and local structures.
We demonstrate our framework through two case studies on binary classifiers and
illustrate model vulnerabilities with respect to varying attack strategies.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.01734v1,2019-07-03T04:37:31Z,2019-07-03T04:37:31Z,"AMI-Net+: A Novel Multi-Instance Neural Network for Medical Diagnosis
  from Incomplete and Imbalanced Data","In medical real-world study (RWS), how to fully utilize the fragmentary and
scarce information in model training to generate the solid diagnosis results is
a challenging task. In this work, we introduce a novel multi-instance neural
network, AMI-Net+, to train and predict from the incomplete and extremely
imbalanced data. It is more effective than the state-of-art method, AMI-Net.
First, we also implement embedding, multi-head attention and gated
attention-based multi-instance pooling to capture the relations of symptoms
themselves and with the given disease. Besides, we propose var-ious
improvements to AMI-Net, that the cross-entropy loss is replaced by focal loss
and we propose a novel self-adaptive multi-instance pooling method on
instance-level to obtain the bag representation. We validate the performance of
AMI-Net+ on two real-world datasets, from two different medical domains.
Results show that our approach outperforms other base-line models by a
considerable margin.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.11976v1,2019-06-27T21:36:13Z,2019-06-27T21:36:13Z,"Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the
  haystack to the needle","The research literature on cybersecurity incident detection & response is
very rich in automatic detection methodologies, in particular those based on
the anomaly detection paradigm. However, very little attention has been devoted
to the diagnosis ability of the methods, aimed to provide useful information on
the causes of a given detected anomaly. This information is of utmost
importance for the security team to reduce the time from detection to response.
In this paper, we present Multivariate Big Data Analysis (MBDA), a complete
intrusion detection approach based on 5 steps to effectively handle massive
amounts of disparate data sources. The approach has been designed to deal with
the main characteristics of Big Data, that is, the high volume, velocity and
variety. The core of the approach is the Multivariate Statistical Network
Monitoring (MSNM) technique proposed in a recent paper. Unlike in state of the
art machine learning methodologies applied to the intrusion detection problem,
when an anomaly is identified in MBDA the output of the system includes the
detail of the logs of raw information associated to this anomaly, so that the
security team can use this information to elucidate its root causes. MBDA is
based in two open software packages available in Github: the MEDA Toolbox and
the FCParser. We illustrate our approach with two case studies. The first one
demonstrates the application of MBDA to semistructured sources of information,
using the data from the VAST 2012 mini challenge 2. This complete case study is
supplied in a virtual machine available for download. In the second case study
we show the Big Data capabilities of the approach in data collected from a real
network with labeled attacks.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.10670v2,2020-11-11T05:26:52Z,2019-06-25T17:09:34Z,"Improving performance of deep learning models with axiomatic attribution
  priors and expected gradients","Recent research has demonstrated that feature attribution methods for deep
networks can themselves be incorporated into training; these attribution priors
optimize for a model whose attributions have certain desirable properties --
most frequently, that particular features are important or unimportant. These
attribution priors are often based on attribution methods that are not
guaranteed to satisfy desirable interpretability axioms, such as completeness
and implementation invariance. Here, we introduce attribution priors to
optimize for higher-level properties of explanations, such as smoothness and
sparsity, enabled by a fast new attribution method formulation called expected
gradients that satisfies many important interpretability axioms. This improves
model performance on many real-world tasks where previous attribution priors
fail. Our experiments show that the gains from combining higher-level
attribution priors with expected gradients attributions are consistent across
image, gene expression, and health care data sets. We believe this work
motivates and provides the necessary tools to support the widespread adoption
of axiomatic attribution priors in many areas of applied machine learning. The
implementations and our results have been made freely available to academic
communities.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.09908v1,2019-06-17T18:19:18Z,2019-06-17T18:19:18Z,Brain Network Construction and Classification Toolbox (BrainNetClass),"Brain functional network has become an increasingly used approach in
understanding brain functions and diseases. Many network construction methods
have been developed, whereas the majority of the studies still used static
pairwise Pearson's correlation-based functional connectivity. The goal of this
work is to introduce a toolbox namely ""Brain Network Construction and
Classification"" (BrainNetClass) to the field to promote more advanced brain
network construction methods. It comprises various brain network construction
methods, including some state-of-the-art methods that were recently developed
to capture more complex interactions among brain regions along with connectome
feature extraction, reduction, parameter optimization towards network-based
individualized classification. BrainNetClass is a MATLAB-based, open-source,
cross-platform toolbox with graphical user-friendly interfaces for cognitive
and clinical neuroscientists to perform rigorous computer-aided diagnosis with
interpretable result presentations even though they do not possess neuroimage
computing and machine learning knowledge. We demonstrate the implementations of
this toolbox on real resting-state functional MRI datasets. BrainNetClass
(v1.0) can be downloaded from https://github.com/zzstefan/BrainNetClass.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.06357v1,2019-06-14T18:16:21Z,2019-06-14T18:16:21Z,"Data-Driven Machine Learning Techniques for Self-healing in Cellular
  Wireless Networks: Challenges and Solutions","For enabling automatic deployment and management of cellular networks, the
concept of self-organizing network (SON) was introduced. SON capabilities can
enhance network performance, improve service quality, and reduce operational
and capital expenditure (OPEX/CAPEX). As an important component in SON,
self-healing is defined as a network paradigm where the faults of target
networks are mitigated or recovered by automatically triggering a series of
actions such as detection, diagnosis and compensation. Data-driven machine
learning has been recognized as a powerful tool to bring intelligence into
network and to realize self-healing. However, there are major challenges for
practical applications of machine learning techniques for self-healing. In this
article, we first classify these challenges into five categories: 1) data
imbalance, 2) data insufficiency, 3) cost insensitivity, 4) non-real-time
response, and 5) multi-source data fusion. Then we provide potential technical
solutions to address these challenges. Furthermore, a case study of
cost-sensitive fault detection with imbalanced data is provided to illustrate
the feasibility and effectiveness of the suggested solutions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.04450v2,2019-08-14T17:52:37Z,2019-06-11T09:02:35Z,"Quantifying Intrinsic Uncertainty in Classification via Deep Dirichlet
  Mixture Networks","With the widespread success of deep neural networks in science and
technology, it is becoming increasingly important to quantify the uncertainty
of the predictions produced by deep learning. In this paper, we introduce a new
method that attaches an explicit uncertainty statement to the probabilities of
classification using deep neural networks. Precisely, we view that the
classification probabilities are sampled from an unknown distribution, and we
propose to learn this distribution through the Dirichlet mixture that is
flexible enough for approximating any continuous distribution on the simplex.
We then construct credible intervals from the learned distribution to assess
the uncertainty of the classification probabilities. Our approach is easy to
implement, computationally efficient, and can be coupled with any deep neural
network architecture. Our method leverages the crucial observation that, in
many classification applications such as medical diagnosis, more than one class
labels are available for each observational unit. We demonstrate the usefulness
of our approach through simulations and a real data example.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.00442v1,2019-06-02T16:36:45Z,2019-06-02T16:36:45Z,"An Evaluation Toolkit to Guide Model Selection and Cohort Definition in
  Causal Inference","Real world observational data, together with causal inference, allow the
estimation of causal effects when randomized controlled trials are not
available. To be accepted into practice, such predictive models must be
validated for the dataset at hand, and thus require a comprehensive evaluation
toolkit, as introduced here. Since effect estimation cannot be evaluated
directly, we turn to evaluating the various observable properties of causal
inference, namely the observed outcome and treatment assignment. We developed a
toolkit that expands established machine learning evaluation methods and adds
several causal-specific ones. Evaluations can be applied in cross-validation,
in a train-test scheme, or on the training data. Multiple causal inference
methods are implemented within the toolkit in a way that allows modular use of
the underlying machine learning models. Thus, the toolkit is agnostic to the
machine learning model that is used. We showcase our approach using a
rheumatoid arthritis cohort (consisting of about 120K patients) extracted from
the IBM MarketScan(R) Research Database. We introduce an iterative pipeline of
data definition, model definition, and model evaluation. Using this pipeline,
we demonstrate how each of the evaluation components helps drive model
selection and refinement of data extraction criteria in a way that provides
more reproducible results and ensures that the causal question is answerable
with available data. Furthermore, we show how the evaluation toolkit can be
used to ensure that performance is maintained when applied to subsets of the
data, thus allowing exploration of questions that move towards personalized
medicine.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.00108v1,2019-05-31T22:28:40Z,2019-05-31T22:28:40Z,"ActiveHARNet: Towards On-Device Deep Bayesian Active Learning for Human
  Activity Recognition","Various health-care applications such as assisted living, fall detection
etc., require modeling of user behavior through Human Activity Recognition
(HAR). HAR using mobile- and wearable-based deep learning algorithms have been
on the rise owing to the advancements in pervasive computing. However, there
are two other challenges that need to be addressed: first, the deep learning
model should support on-device incremental training (model updation) from
real-time incoming data points to learn user behavior over time, while also
being resource-friendly; second, a suitable ground truthing technique (like
Active Learning) should help establish labels on-the-fly while also selecting
only the most informative data points to query from an oracle. Hence, in this
paper, we propose ActiveHARNet, a resource-efficient deep ensembled model which
supports on-device Incremental Learning and inference, with capabilities to
represent model uncertainties through approximations in Bayesian Neural
Networks using dropout. This is combined with suitable acquisition functions
for active learning. Empirical results on two publicly available wrist-worn HAR
and fall detection datasets indicate that ActiveHARNet achieves considerable
efficiency boost during inference across different users, with a substantially
low number of acquired pool points (at least 60% reduction) during incremental
learning on both datasets experimented with various acquisition functions, thus
demonstrating deployment and Incremental Learning feasibility.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.13658v1,2019-05-31T14:58:29Z,2019-05-31T14:58:29Z,Ordinal Regression as Structured Classification,"This paper extends the class of ordinal regression models with a structured
interpretation of the problem by applying a novel treatment of encoded labels.
The net effect of this is to transform the underlying problem from an ordinal
regression task to a (structured) classification task which we solve with
conditional random fields, thereby achieving a coherent and probabilistic model
in which all model parameters are jointly learnt. Importantly, we show that
although we have cast ordinal regression to classification, our method still
fall within the class of decomposition methods in the ordinal regression
ontology. This is an important link since our experience is that many
applications of machine learning to healthcare ignores completely the important
nature of the label ordering, and hence these approaches should considered
naive in this ontology. We also show that our model is flexible both in how it
adapts to data manifolds and in terms of the operations that are available for
practitioner to execute. Our empirical evaluation demonstrates that the
proposed approach overwhelmingly produces superior and often statistically
significant results over baseline approaches on forty popular ordinal
regression models, and demonstrate that the proposed model significantly
out-performs baselines on synthetic and real datasets. Our implementation,
together with scripts to reproduce the results of this work, will be available
on a public GitHub repository.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.10364v1,2019-05-24T09:19:42Z,2019-05-24T09:19:42Z,"Deep learning based high-resolution incoherent x-ray imaging with a
  single-pixel detector","X-ray ""ghost"" imaging has drawn great attention for its potential to lower
radiation dose in medical diagnosis. For practical implementation, however, the
efficiency and image quality have to be greatly improved. Here we demonstrate a
computational ghost imaging scheme where a bucket detector and specially
designed modulation masks are used, together with a new robust deep learning
algorithm in which a compressed set of Hadamard matrices is incorporated into a
multi-level wavelet convolutional neural network. By this means we have
obtained an image of a real object from only 18.75% of the Nyquist sampling
rate, using a portable tabletop incoherent x-ray source of ~37 {\mu}m diameter.
A high imaging resolution of ~10 {\mu}m is achieved, which represents a
concrete step towards the realization of a practical low cost x-ray ghost
imaging camera for applications in biomedicine, archeology, material science,
and so forth.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.06004v1,2019-05-15T07:48:21Z,2019-05-15T07:48:21Z,Domain Adaptive Transfer Learning for Fault Diagnosis,"Thanks to digitization of industrial assets in fleets, the ambitious goal of
transferring fault diagnosis models fromone machine to the other has raised
great interest. Solving these domain adaptive transfer learning tasks has the
potential to save large efforts on manually labeling data and modifying models
for new machines in the same fleet. Although data-driven methods have shown
great potential in fault diagnosis applications, their ability to generalize on
new machines and new working conditions are limited because of their tendency
to overfit to the training set in reality. One promising solution to this
problem is to use domain adaptation techniques. It aims to improve model
performance on the target new machine. Inspired by its successful
implementation in computer vision, we introduced Domain-Adversarial Neural
Networks (DANN) to our context, along with two other popular methods existing
in previous fault diagnosis research. We then carefully justify the
applicability of these methods in realistic fault diagnosis settings, and offer
a unified experimental protocol for a fair comparison between domain adaptation
methods for fault diagnosis problems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.03554v1,2019-05-09T11:52:10Z,2019-05-09T11:52:10Z,1D Convolutional Neural Networks and Applications: A Survey,"During the last decade, Convolutional Neural Networks (CNNs) have become the
de facto standard for various Computer Vision and Machine Learning operations.
CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating
convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and
millions of parameters have the ability to learn complex objects and patterns
providing that they can be trained on a massive size visual database with
ground-truth labels. With a proper training, this unique ability makes them the
primary tool for various engineering applications for 2D signals such as images
and video frames. Yet, this may not be a viable option in numerous applications
over 1D signals especially when the training data is scarce or
application-specific. To address this issue, 1D CNNs have recently been
proposed and immediately achieved the state-of-the-art performance levels in
several applications such as personalized biomedical data classification and
early diagnosis, structural health monitoring, anomaly detection and
identification in power electronics and motor-fault detection. Another major
advantage is that a real-time and low-cost hardware implementation is feasible
due to the simple and compact configuration of 1D CNNs that perform only 1D
convolutions (scalar multiplications and additions). This paper presents a
comprehensive review of the general architecture and principals of 1D CNNs
along with their major engineering applications, especially focused on the
recent progress in this field. Their state-of-the-art performance is
highlighted concluding with their unique properties. The benchmark datasets and
the principal 1D CNN software used in those applications are also publically
shared in a dedicated website.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.02940v1,2019-05-08T07:26:27Z,2019-05-08T07:26:27Z,"A new direction to promote the implementation of artificial intelligence
  in natural clinical settings","Artificial intelligence (AI) researchers claim that they have made great
`achievements' in clinical realms. However, clinicians point out the so-called
`achievements' have no ability to implement into natural clinical settings. The
root cause for this huge gap is that many essential features of natural
clinical tasks are overlooked by AI system developers without medical
background. In this paper, we propose that the clinical benchmark suite is a
novel and promising direction to capture the essential features of the
real-world clinical tasks, hence qualifies itself for guiding the development
of AI systems, promoting the implementation of AI in real-world clinical
practice.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.00288v3,2020-07-23T18:16:09Z,2019-05-01T12:50:26Z,Beyond Mobile Apps: A Survey of Technologies for Mental Well-being,"Mental health problems are on the rise globally and strain national health
systems worldwide. Mental disorders are closely associated with fear of stigma,
structural barriers such as financial burden, and lack of available services
and resources which often prohibit the delivery of frequent clinical advice and
monitoring. Technologies for mental well-being exhibit a range of attractive
properties, which facilitate the delivery of state-of-the-art clinical
monitoring. This review article provides an overview of traditional techniques
followed by their technological alternatives, sensing devices, behaviour
changing tools, and feedback interfaces. The challenges presented by these
technologies are then discussed with data collection, privacy, and battery life
being some of the key issues which need to be carefully considered for the
successful deployment of mental health toolkits. Finally, the opportunities
this growing research area presents are discussed including the use of portable
tangible interfaces combining sensing and feedback technologies. Capitalising
on the data these ubiquitous devices can record, state of the art machine
learning algorithms can lead to the development of robust clinical decision
support tools towards diagnosis and improvement of mental well-being delivery
in real-time.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.13342v1,2019-04-30T16:12:55Z,2019-04-30T16:12:55Z,PYRO-NN: Python Reconstruction Operators in Neural Networks,"Purpose: Recently, several attempts were conducted to transfer deep learning
to medical image reconstruction. An increasingly number of publications follow
the concept of embedding the CT reconstruction as a known operator into a
neural network. However, most of the approaches presented lack an efficient CT
reconstruction framework fully integrated into deep learning environments. As a
result, many approaches are forced to use workarounds for mathematically
unambiguously solvable problems. Methods: PYRO-NN is a generalized framework to
embed known operators into the prevalent deep learning framework Tensorflow.
The current status includes state-of-the-art parallel-, fan- and cone-beam
projectors and back-projectors accelerated with CUDA provided as Tensorflow
layers. On top, the framework provides a high level Python API to conduct FBP
and iterative reconstruction experiments with data from real CT systems.
Results: The framework provides all necessary algorithms and tools to design
end-to-end neural network pipelines with integrated CT reconstruction
algorithms. The high level Python API allows a simple use of the layers as
known from Tensorflow. To demonstrate the capabilities of the layers, the
framework comes with three baseline experiments showing a cone-beam short scan
FDK reconstruction, a CT reconstruction filter learning setup, and a TV
regularized iterative reconstruction. All algorithms and tools are referenced
to a scientific publication and are compared to existing non deep learning
reconstruction frameworks. The framework is available as open-source software
at \url{https://github.com/csyben/PYRO-NN}. Conclusions: PYRO-NN comes with the
prevalent deep learning framework Tensorflow and allows to setup end-to-end
trainable neural networks in the medical image reconstruction context. We
believe that the framework will be a step towards reproducible research",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.04475v4,2021-10-01T05:35:11Z,2019-04-09T05:58:28Z,Private Hierarchical Clustering and Efficient Approximation,"In collaborative learning, multiple parties contribute their datasets to
jointly deduce global machine learning models for numerous predictive tasks.
Despite its efficacy, this learning paradigm fails to encompass critical
application domains that involve highly sensitive data, such as healthcare and
security analytics, where privacy risks limit entities to individually train
models using only their own datasets. In this work, we target
privacy-preserving collaborative hierarchical clustering. We introduce a formal
security definition that aims to achieve the balance between utility and
privacy and present a two-party protocol that provably satisfies it. We then
extend our protocol with: (i) an optimized version for the single-linkage
clustering, and (ii) scalable approximation variants. We implement all our
schemes and experimentally evaluate their performance and accuracy on synthetic
and real datasets, obtaining very encouraging results. For example, end-to-end
execution of our secure approximate protocol for over 1M 10-dimensional data
samples requires 35sec of computation and achieves 97.09% accuracy.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1902.02808v1,2019-02-07T19:15:51Z,2019-02-07T19:15:51Z,ML Health: Fitness Tracking for Production Models,"Deployment of machine learning (ML) algorithms in production for extended
periods of time has uncovered new challenges such as monitoring and management
of real-time prediction quality of a model in the absence of labels. However,
such tracking is imperative to prevent catastrophic business outcomes resulting
from incorrect predictions. The scale of these deployments makes manual
monitoring prohibitive, making automated techniques to track and raise alerts
imperative. We present a framework, ML Health, for tracking potential drops in
the predictive performance of ML models in the absence of labels. The framework
employs diagnostic methods to generate alerts for further investigation. We
develop one such method to monitor potential problems when production data
patterns do not match training data distributions. We demonstrate that our
method performs better than standard ""distance metrics"", such as RMSE,
KL-Divergence, and Wasserstein at detecting issues with mismatched data sets.
Finally, we present a working system that incorporates the ML Health approach
to monitor and manage ML deployments within a realistic full production ML
lifecycle.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1902.01506v3,2019-06-24T07:19:55Z,2019-02-05T00:59:44Z,"Learning to Prescribe Interventions for Tuberculosis Patients Using
  Digital Adherence Data","Digital Adherence Technologies (DATs) are an increasingly popular method for
verifying patient adherence to many medications. We analyze data from one city
served by 99DOTS, a phone-call-based DAT deployed for Tuberculosis (TB)
treatment in India where nearly 3 million people are afflicted with the disease
each year. The data contains nearly 17,000 patients and 2.1M dose records. We
lay the groundwork for learning from this real-world data, including a method
for avoiding the effects of unobserved interventions in training data used for
machine learning. We then construct a deep learning model, demonstrate its
interpretability, and show how it can be adapted and trained in different
clinical scenarios to better target and improve patient care. In the real-time
risk prediction setting our model could be used to proactively intervene with
21% more patients and before 76% more missed doses than current heuristic
baselines. For outcome prediction, our model performs 40% better than baseline
methods, allowing cities to target more resources to clinics with a heavier
burden of patients at risk of failure. Finally, we present a case study
demonstrating how our model can be trained in an end-to-end decision focused
learning setting to achieve 15% better solution quality in an example decision
problem faced by health workers.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1901.01377v2,2021-01-25T22:10:53Z,2019-01-05T07:46:38Z,"Population-Guided Large Margin Classifier for High-Dimension Low
  -Sample-Size Problems","Various applications in different fields, such as gene expression analysis or
computer vision, suffer from data sets with high-dimensional low-sample-size
(HDLSS), which has posed significant challenges for standard statistical and
modern machine learning methods. In this paper, we propose a novel linear
binary classifier, denoted by population-guided large margin classifier
(PGLMC), which is applicable to any sorts of data, including HDLSS. PGLMC is
conceived with a projecting direction w given by the comprehensive
consideration of local structural information of the hyperplane and the
statistics of the training samples. Our proposed model has several advantages
compared to those widely used approaches. First, it is not sensitive to the
intercept term b. Second, it operates well with imbalanced data. Third, it is
relatively simple to be implemented based on Quadratic Programming. Fourth, it
is robust to the model specification for various real applications. The
theoretical properties of PGLMC are proven. We conduct a series of evaluations
on two simulated and six real-world benchmark data sets, including DNA
classification, digit recognition, medical image analysis, and face
recognition. PGLMC outperforms the state-of-the-art classification methods in
most cases, or at least obtains comparable results.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1812.01885v1,2018-12-05T10:02:59Z,2018-12-05T10:02:59Z,"Improving Medical Short Text Classification with Semantic Expansion
  Using Word-Cluster Embedding","Automatic text classification (TC) research can be used for real-world
problems such as the classification of in-patient discharge summaries and
medical text reports, which is beneficial to make medical documents more
understandable to doctors. However, in electronic medical records (EMR), the
texts containing sentences are shorter than that in general domain, which leads
to the lack of semantic features and the ambiguity of semantic. To tackle this
challenge, we propose to add word-cluster embedding to deep neural network for
improving short text classification. Concretely, we first use hierarchical
agglomerative clustering to cluster the word vectors in the semantic space.
Then we calculate the cluster center vector which represents the implicit topic
information of words in the cluster. Finally, we expand word vector with
cluster center vector, and implement classifiers using CNN and LSTM
respectively. To evaluate the performance of our proposed method, we conduct
experiments on public data sets TREC and the medical short sentences data sets
which is constructed and released by us. The experimental results demonstrate
that our proposed method outperforms state-of-the-art baselines in short
sentence classification on both medical domain and general domain.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1812.01813v1,2018-12-05T04:41:10Z,2018-12-05T04:41:10Z,"Machine-learned epidemiology: real-time detection of foodborne illness
  at scale","Machine learning has become an increasingly powerful tool for solving complex
problems, and its application in public health has been underutilized. The
objective of this study is to test the efficacy of a machine-learned model of
foodborne illness detection in a real-world setting. To this end, we built
FINDER, a machine-learned model for real-time detection of foodborne illness
using anonymous and aggregated web search and location data. We computed the
fraction of people who visited a particular restaurant and later searched for
terms indicative of food poisoning to identify potentially unsafe restaurants.
We used this information to focus restaurant inspections in two cities and
demonstrated that FINDER improves the accuracy of health inspections;
restaurants identified by FINDER are 3.1 times as likely to be deemed unsafe
during the inspection as restaurants identified by existing methods.
Additionally, FINDER enables us to ascertain previously intractable
epidemiological information, for example, in 38% of cases the restaurant
potentially causing food poisoning was not the last one visited, which may
explain the lower precision of complaint-based inspections. We found that
FINDER is able to reliably identify restaurants that have an active lapse in
food safety, allowing for implementation of corrective actions that would
prevent the potential spread of foodborne illness.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1901.06242v1,2018-12-01T13:40:03Z,2018-12-01T13:40:03Z,"Data-driven Air Quality Characterisation for Urban Environments: a Case
  Study","The economic and social impact of poor air quality in towns and cities is
increasingly being recognised, together with the need for effective ways of
creating awareness of real-time air quality levels and their impact on human
health. With local authority maintained monitoring stations being
geographically sparse and the resultant datasets also featuring missing labels,
computational data-driven mechanisms are needed to address the data sparsity
challenge. In this paper, we propose a machine learning-based method to
accurately predict the Air Quality Index (AQI), using environmental monitoring
data together with meteorological measurements. To do so, we develop an air
quality estimation framework that implements a neural network that is enhanced
with a novel Non-linear Autoregressive neural network with exogenous input
(NARX), especially designed for time series prediction. The framework is
applied to a case study featuring different monitoring sites in London, with
comparisons against other standard machine-learning based predictive algorithms
showing the feasibility and robust performance of the proposed method for
different kinds of areas within an urban region.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1812.00825v2,2018-12-04T05:36:36Z,2018-11-21T21:02:50Z,"Microscope 2.0: An Augmented Reality Microscope with Real-time
  Artificial Intelligence Integration","The brightfield microscope is instrumental in the visual examination of both
biological and physical samples at sub-millimeter scales. One key clinical
application has been in cancer histopathology, where the microscopic assessment
of the tissue samples is used for the diagnosis and staging of cancer and thus
guides clinical therapy. However, the interpretation of these samples is
inherently subjective, resulting in significant diagnostic variability.
Moreover, in many regions of the world, access to pathologists is severely
limited due to lack of trained personnel. In this regard, Artificial
Intelligence (AI) based tools promise to improve the access and quality of
healthcare. However, despite significant advances in AI research, integration
of these tools into real-world cancer diagnosis workflows remains challenging
because of the costs of image digitization and difficulties in deploying AI
solutions. Here we propose a cost-effective solution to the integration of AI:
the Augmented Reality Microscope (ARM). The ARM overlays AI-based information
onto the current view of the sample through the optical pathway in real-time,
enabling seamless integration of AI into the regular microscopy workflow. We
demonstrate the utility of ARM in the detection of lymph node metastases in
breast cancer and the identification of prostate cancer with a latency that
supports real-time workflows. We anticipate that ARM will remove barriers
towards the use of AI in microscopic analysis and thus improve the accuracy and
efficiency of cancer diagnosis. This approach is applicable to other microscopy
tasks and AI algorithms in the life sciences and beyond.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.07738v3,2019-04-23T07:51:28Z,2018-11-19T14:51:56Z,"M2U-Net: Effective and Efficient Retinal Vessel Segmentation for
  Resource-Constrained Environments","In this paper, we present a novel neural network architecture for retinal
vessel segmentation that improves over the state of the art on two benchmark
datasets, is the first to run in real time on high resolution images, and its
small memory and processing requirements make it deployable in mobile and
embedded systems. The M2U-Net has a new encoder-decoder architecture that is
inspired by the U-Net. It adds pretrained components of MobileNetV2 in the
encoder part and novel contractive bottleneck blocks in the decoder part that,
combined with bilinear upsampling, drastically reduce the parameter count to
0.55M compared to 31.03M in the original U-Net. We have evaluated its
performance against a wide body of previously published results on three public
datasets. On two of them, the M2U-Net achieves new state-of-the-art performance
by a considerable margin. When implemented on a GPU, our method is the first to
achieve real-time inference speeds on high-resolution fundus images. We also
implemented our proposed network on an ARM-based embedded system where it
segments images in between 0.6 and 15 sec, depending on the resolution. Thus,
the M2U-Net enables a number of applications of retinal vessel structure
extraction, such as early diagnosis of eye diseases, retinal biometric
authentication systems, and robot assisted microsurgery.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.06672v1,2018-11-16T03:59:22Z,2018-11-16T03:59:22Z,Detecting Irregular Patterns in IoT Streaming Data for Fall Detection,"Detecting patterns in real time streaming data has been an interesting and
challenging data analytics problem. With the proliferation of a variety of
sensor devices, real-time analytics of data from the Internet of Things (IoT)
to learn regular and irregular patterns has become an important machine
learning problem to enable predictive analytics for automated notification and
decision support. In this work, we address the problem of learning an irregular
human activity pattern, fall, from streaming IoT data from wearable sensors. We
present a deep neural network model for detecting fall based on accelerometer
data giving 98.75 percent accuracy using an online physical activity monitoring
dataset called ""MobiAct"", which was published by Vavoulas et al. The initial
model was developed using IBM Watson studio and then later transferred and
deployed on IBM Cloud with the streaming analytics service supported by IBM
Streams for monitoring real-time IoT data. We also present the systems
architecture of the real-time fall detection framework that we intend to use
with mbientlabs wearable health monitoring sensors for real time patient
monitoring at retirement homes or rehabilitation clinics.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.01627v1,2018-11-05T11:49:26Z,2018-11-05T11:49:26Z,"Real-time Driver Drowsiness Detection for Android Application Using Deep
  Neural Networks Techniques","Road crashes and related forms of accidents are a common cause of injury and
death among the human population. According to 2015 data from the World Health
Organization, road traffic injuries resulted in approximately 1.25 million
deaths worldwide, i.e. approximately every 25 seconds an individual will
experience a fatal crash. While the cost of traffic accidents in Europe is
estimated at around 160 billion Euros, driver drowsiness accounts for
approximately 100,000 accidents per year in the United States alone as reported
by The American National Highway Traffic Safety Administration (NHTSA). In this
paper, a novel approach towards real-time drowsiness detection is proposed.
This approach is based on a deep learning method that can be implemented on
Android applications with high accuracy. The main contribution of this work is
the compression of heavy baseline model to a lightweight model. Moreover,
minimal network structure is designed based on facial landmark key point
detection to recognize whether the driver is drowsy. The proposed model is able
to achieve an accuracy of more than 80%. Keywords: Driver Monitoring System;
Drowsiness Detection; Deep Learning; Real-time Deep Neural Network; Android.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.04793v3,2018-10-25T13:38:34Z,2018-10-10T16:41:05Z,"Patient2Vec: A Personalized Interpretable Deep Representation of the
  Longitudinal Electronic Health Record","The wide implementation of electronic health record (EHR) systems facilitates
the collection of large-scale health data from real clinical settings. Despite
the significant increase in adoption of EHR systems, this data remains largely
unexplored, but presents a rich data source for knowledge discovery from
patient health histories in tasks such as understanding disease correlations
and predicting health outcomes. However, the heterogeneity, sparsity, noise,
and bias in this data present many complex challenges. This complexity makes it
difficult to translate potentially relevant information into machine learning
algorithms. In this paper, we propose a computational framework, Patient2Vec,
to learn an interpretable deep representation of longitudinal EHR data which is
personalized for each patient. To evaluate this approach, we apply it to the
prediction of future hospitalizations using real EHR data and compare its
predictive performance with baseline methods. Patient2Vec produces a vector
space with meaningful structure and it achieves an AUC around 0.799
outperforming baseline methods. In the end, the learned feature importance can
be visualized and interpreted at both the individual and population levels to
bring clinical insights.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.04538v1,2018-10-10T14:04:08Z,2018-10-10T14:04:08Z,"Secure Deep Learning Engineering: A Software Quality Assurance
  Perspective","Over the past decades, deep learning (DL) systems have achieved tremendous
success and gained great popularity in various applications, such as
intelligent machines, image processing, speech processing, and medical
diagnostics. Deep neural networks are the key driving force behind its recent
success, but still seem to be a magic black box lacking interpretability and
understanding. This brings up many open safety and security issues with
enormous and urgent demands on rigorous methodologies and engineering practice
for quality enhancement. A plethora of studies have shown that the
state-of-the-art DL systems suffer from defects and vulnerabilities that can
lead to severe loss and tragedies, especially when applied to real-world
safety-critical applications. In this paper, we perform a large-scale study and
construct a paper repository of 223 relevant works to the quality assurance,
security, and interpretation of deep learning. We, from a software quality
assurance perspective, pinpoint challenges and future opportunities towards
universal secure deep learning engineering. We hope this work and the
accompanied paper repository can pave the path for the software engineering
community towards addressing the pressing industrial demand of secure
intelligent applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.10804v1,2018-09-28T00:14:10Z,2018-09-28T00:14:10Z,"Patient Risk Assessment and Warning Symptom Detection Using Deep
  Attention-Based Neural Networks","We present an operational component of a real-world patient triage system.
Given a specific patient presentation, the system is able to assess the level
of medical urgency and issue the most appropriate recommendation in terms of
best point of care and time to treat. We use an attention-based convolutional
neural network architecture trained on 600,000 doctor notes in German. We
compare two approaches, one that uses the full text of the medical notes and
one that uses only a selected list of medical entities extracted from the text.
These approaches achieve 79% and 66% precision, respectively, but on a
confidence threshold of 0.6, precision increases to 85% and 75%, respectively.
In addition, a method to detect warning symptoms is implemented to render the
classification task transparent from a medical perspective. The method is based
on the learning of attention scores and a method of automatic validation using
the same data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.07914v1,2018-09-21T02:04:16Z,2018-09-21T02:04:16Z,"Secure Phrase Search for Intelligent Processing of Encrypted Data in
  Cloud-Based IoT","Phrase search allows retrieval of documents containing an exact phrase, which
plays an important role in many machine learning applications for cloud-based
IoT, such as intelligent medical data analytics. In order to protect sensitive
information from being leaked by service providers, documents (e.g., clinic
records) are usually encrypted by data owners before being outsourced to the
cloud. This, however, makes the search operation an extremely challenging task.
Existing searchable encryption schemes for multi-keyword search operations fail
to perform phrase search, as they are unable to determine the location
relationship of multiple keywords in a queried phrase over encrypted data on
the cloud server side. In this paper, we propose P3, an efficient
privacy-preserving phrase search scheme for intelligent encrypted data
processing in cloud-based IoT. Our scheme exploits the homomorphic encryption
and bilinear map to determine the location relationship of multiple queried
keywords over encrypted data. It also utilizes a probabilistic trapdoor
generation algorithm to protect users search patterns. Thorough security
analysis demonstrates the security guarantees achieved by P3. We implement a
prototype and conduct extensive experiments on real-world datasets. The
evaluation results show that compared with existing multikeyword search
schemes, P3 can greatly improve the search accuracy with moderate overheads.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.07806v2,2019-06-14T01:39:12Z,2018-09-20T19:03:14Z,Understanding Behavior of Clinical Models under Domain Shifts,"The hypothesis that computational models can be reliable enough to be adopted
in prognosis and patient care is revolutionizing healthcare. Deep learning, in
particular, has been a game changer in building predictive models, thus leading
to community-wide data curation efforts. However, due to inherent variabilities
in population characteristics and biological systems, these models are often
biased to the training datasets. This can be limiting when models are deployed
in new environments, when there are systematic domain shifts not known a
priori. In this paper, we propose to emulate a large class of domain shifts,
that can occur in clinical settings, with a given dataset, and argue that
evaluating the behavior of predictive models in light of those shifts is an
effective way to quantify their reliability. More specifically, we develop an
approach for building realistic scenarios, based on analysis of \textit{disease
landscapes} in multi-label classification. Using the openly available MIMIC-III
EHR dataset for phenotyping, for the first time, our work sheds light into data
regimes where deep clinical models can fail to generalize. This work emphasizes
the need for novel validation mechanisms driven by real-world domain shifts in
AI for healthcare.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.07763v4,2020-05-26T15:15:19Z,2018-09-19T19:14:46Z,"auditor: an R Package for Model-Agnostic Visual Validation and
  Diagnostics","Machine learning models have spread to almost every area of life. They are
successfully applied in biology, medicine, finance, physics, and other fields.
With modern software it is easy to train even a~complex model that fits the
training data and results in high accuracy on the test set. The problem arises
when models fail confronted with real-world data.
  This paper describes methodology and tools for model-agnostic audit.
Introduced techniques facilitate assessing and comparing the goodness of fit
and performance of models. In~addition, they may be used for the analysis of
the similarity of residuals and for identification of~outliers and influential
observations. The examination is carried out by diagnostic scores and visual
verification.
  Presented methods were implemented in the auditor package for R. Due to
flexible and~consistent grammar, it is simple to validate models of any
classes.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.01852v3,2019-03-07T04:27:19Z,2018-09-06T07:30:13Z,"GAMENet: Graph Augmented MEmory Networks for Recommending Medication
  Combination","Recent progress in deep learning is revolutionizing the healthcare domain
including providing solutions to medication recommendations, especially
recommending medication combination for patients with complex health
conditions. Existing approaches either do not customize based on patient health
history, or ignore existing knowledge on drug-drug interactions (DDI) that
might lead to adverse outcomes. To fill this gap, we propose the Graph
Augmented Memory Networks (GAMENet), which integrates the drug-drug
interactions knowledge graph by a memory module implemented as a graph
convolutional networks, and models longitudinal patient records as the query.
It is trained end-to-end to provide safe and personalized recommendation of
medication combination. We demonstrate the effectiveness and safety of GAMENet
by comparing with several state-of-the-art methods on real EHR data. GAMENet
outperformed all baselines in all effectiveness measures, and also achieved
3.60% DDI rate reduction from existing EHR data.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.06428v2,2018-08-21T13:31:15Z,2018-08-20T12:50:41Z,"CapsDeMM: Capsule network for Detection of Munro's Microabscess in skin
  biopsy images","This paper presents an approach for automatic detection of Munro's
Microabscess in stratum corneum (SC) of human skin biopsy in order to realize a
machine assisted diagnosis of Psoriasis. The challenge of detecting neutrophils
in presence of nucleated cells is solved using the recent advances of deep
learning algorithms. Separation of SC layer, extraction of patches from the
layer followed by classification of patches with respect to presence or absence
of neutrophils form the basis of the overall approach which is effected through
an integration of a U-Net based segmentation network and a capsule network for
classification. The novel design of the present capsule net leads to a drastic
reduction in the number of parameters without any noticeable compromise in the
overall performance. The research further addresses the challenge of dealing
with Mega-pixel images (in 10X) vis-a-vis Giga-pixel ones (in 40X). The
promising result coming out of an experiment on a dataset consisting of 273
real-life images shows that a practical system is possible based on the present
research. The implementation of our system is available at
https://github.com/Anabik/CapsDeMM.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.03941v2,2019-05-05T03:42:19Z,2018-08-12T13:30:27Z,"Denoising of 3-D Magnetic Resonance Images Using a Residual
  Encoder-Decoder Wasserstein Generative Adversarial Network","Structure-preserved denoising of 3D magnetic resonance imaging (MRI) images
is a critical step in medical image analysis. Over the past few years, many
algorithms with impressive performances have been proposed. In this paper,
inspired by the idea of deep learning, we introduce an MRI denoising method
based on the residual encoder-decoder Wasserstein generative adversarial
network (RED-WGAN). Specifically, to explore the structure similarity between
neighboring slices, a 3D configuration is utilized as the basic processing
unit. Residual autoencoders combined with deconvolution operations are
introduced into the generator network. Furthermore, to alleviate the
oversmoothing shortcoming of the traditional mean squared error (MSE) loss
function, the perceptual similarity, which is implemented by calculating the
distances in the feature space extracted by a pretrained VGG-19 network, is
incorporated with the MSE and adversarial losses to form the new loss function.
Extensive experiments are implemented to assess the performance of the proposed
method. The experimental results show that the proposed RED-WGAN achieves
performance superior to several state-of-the-art methods in both simulated and
real clinical data. In particular, our method demonstrates powerful abilities
in both noise suppression and structure preservation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.11718v2,2019-04-22T16:48:16Z,2018-07-31T09:33:58Z,"Feature Grouping as a Stochastic Regularizer for High-Dimensional
  Structured Data","In many applications where collecting data is expensive, for example
neuroscience or medical imaging, the sample size is typically small compared to
the feature dimension. It is challenging in this setting to train expressive,
non-linear models without overfitting. These datasets call for intelligent
regularization that exploits known structure, such as correlations between the
features arising from the measurement device. However, existing structured
regularizers need specially crafted solvers, which are difficult to apply to
complex models. We propose a new regularizer specifically designed to leverage
structure in the data in a way that can be applied efficiently to complex
models. Our approach relies on feature grouping, using a fast clustering
algorithm inside a stochastic gradient descent loop: given a family of feature
groupings that capture feature covariations, we randomly select these groups at
each iteration. We show that this approach amounts to enforcing a denoising
regularizer on the solution. The method is easy to implement in many model
architectures, such as fully connected neural networks, and has a linear
computational cost. We apply this regularizer to a real-world fMRI dataset and
the Olivetti Faces datasets. Experiments on both datasets demonstrate that the
proposed approach produces models that generalize better than those trained
with conventional regularizers, and also improves convergence speed.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.08942v1,2018-07-24T07:50:18Z,2018-07-24T07:50:18Z,Example Mining for Incremental Learning in Medical Imaging,"Incremental Learning is well known machine learning approach wherein the
weights of the learned model are dynamically and gradually updated to
generalize on new unseen data without forgetting the existing knowledge.
Incremental learning proves to be time as well as resource-efficient solution
for deployment of deep learning algorithms in real world as the model can
automatically and dynamically adapt to new data as and when annotated data
becomes available. The development and deployment of Computer Aided Diagnosis
(CAD) tools in medical domain is another scenario, where incremental learning
becomes very crucial as collection and annotation of a comprehensive dataset
spanning over multiple pathologies and imaging machines might take years.
However, not much has so far been explored in this direction. In the current
work, we propose a robust and efficient method for incremental learning in
medical imaging domain. Our approach makes use of Hard Example Mining technique
(which is commonly used as a solution to heavy class imbalance) to
automatically select a subset of dataset to fine-tune the existing network
weights such that it adapts to new data while retaining existing knowledge. We
develop our approach for incremental learning of our already under test model
for detecting dental caries. Further, we apply our approach to one publicly
available dataset and demonstrate that our approach reaches the accuracy of
training on entire dataset at once, while availing the benefits of incremental
learning scenario.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.05331v1,2018-07-14T04:38:47Z,2018-07-14T04:38:47Z,"Improving Photoplethysmographic Measurements under Motion Artifacts
  using Artificial Neural Network for Personal Healthcare","Photoplethysmographic (PPG) measurements are susceptible to motion artifacts
(MA) due to movement of the peripheral body parts. In this paper, we present a
new approach to identify the MA corrupted PPG beats and then rectify the beat
morphology using artificial neural network (ANN). Initially, beat quality
assessment was done to identify the clean PPG beats by a pre-trained feedback
ANN to generate a reference beat template for each person. The PPG data was
decomposed using principal component analysis (PCA) and reconstructed using
fixed energy retention. A weight coefficient was assigned for each PPG samples
in such a way that when they are multiplied , the modified beat morphology
matches the reference template. A particle swarm optimization (PSO) based
technique was utilized to select the best weight weight vector coefficients to
tune another feedback ANN, fed with a set of significant features generated by
an auto encoder from PCA reconstructed data. For real time implementation, this
pre-trained ANN was operated in feed-forward mode to directly generate the
weight vectors for any subsequent measurements of PPG. The method was validated
with PPG data collected from 55 human subjects. An average RMSE of 0.28 and SNR
improvement of 14.54 dB was obtained, with an average improvement of 36% and
47% measurement accuracy on crest time and systolic to diastolic peak height
ratio respectively. With IEEE Signal Processing Cup 2015 Challenge database,
Pearson's correlation coefficient between PPG estimated and ECG derived heart
rate was 0.990. The proposed method can be useful for personal health
monitoring applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.06419v1,2018-07-13T17:23:54Z,2018-07-13T17:23:54Z,On Ternary Coding and Three-Valued Logic,"Mathematically, ternary coding is more efficient than binary coding. It is
little used in computation because technology for binary processing is already
established and the implementation of ternary coding is more complicated, but
remains relevant in algorithms that use decision trees and in communications.
In this paper we present a new comparison of binary and ternary coding and
their relative efficiencies are computed both for number representation and
decision trees. The implications of our inability to use optimal representation
through mathematics or logic are examined. Apart from considerations of
representation efficiency, ternary coding appears preferable to binary coding
in classification of many real-world problems of artificial intelligence (AI)
and medicine. We examine the problem of identifying appropriate three classes
for domain-specific applications.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.03043v5,2019-02-25T21:06:08Z,2018-07-09T11:12:16Z,Convolutional Recurrent Neural Networks for Glucose Prediction,"Control of blood glucose is essential for diabetes management. Current
digital therapeutic approaches for subjects with Type 1 diabetes mellitus
(T1DM) such as the artificial pancreas and insulin bolus calculators leverage
machine learning techniques for predicting subcutaneous glucose for improved
control. Deep learning has recently been applied in healthcare and medical
research to achieve state-of-the-art results in a range of tasks including
disease diagnosis, and patient state prediction among others. In this work, we
present a deep learning model that is capable of forecasting glucose levels
with leading accuracy for simulated patient cases (RMSE = 9.38$\pm$0.71 [mg/dL]
over a 30-minute horizon, RMSE = 18.87$\pm$2.25 [mg/dL] over a 60-minute
horizon) and real patient cases (RMSE = 21.07$\pm$2.35 [mg/dL] for 30-minute,
RMSE = 33.27$\pm$4.79\% for 60-minute). In addition, the model provides
competitive performance in providing effective prediction horizon ($PH_{eff}$)
with minimal time lag both in a simulated patient dataset ($PH_{eff}$ =
29.0$\pm$0.7 for 30-min and $PH_{eff}$ = 49.8$\pm$2.9 for 60-min) and in a real
patient dataset ($PH_{eff}$ = 19.3$\pm$3.1 for 30-min and $PH_{eff}$ =
29.3$\pm$9.4 for 60-min). This approach is evaluated on a dataset of 10
simulated cases generated from the UVa/Padova simulator and a clinical dataset
of 10 real cases each containing glucose readings, insulin bolus, and meal
(carbohydrate) data. Performance of the recurrent convolutional neural network
is benchmarked against four algorithms. The proposed algorithm is implemented
on an Android mobile phone, with an execution time of $6$ms on a phone compared
to an execution time of $780$ms on a laptop.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1806.07777v1,2018-06-20T14:56:10Z,2018-06-20T14:56:10Z,"Generative Adversarial Networks for Image-to-Image Translation on
  Multi-Contrast MR Images - A Comparison of CycleGAN and UNIT","In medical imaging, a general problem is that it is costly and time consuming
to collect high quality data from healthy and diseased subjects. Generative
adversarial networks (GANs) is a deep learning method that has been developed
for synthesizing data. GANs can thereby be used to generate more realistic
training data, to improve classification performance of machine learning
algorithms. Another application of GANs is image-to-image translations, e.g.
generating magnetic resonance (MR) images from computed tomography (CT) images,
which can be used to obtain multimodal datasets from a single modality. Here,
we evaluate two unsupervised GAN models (CycleGAN and UNIT) for image-to-image
translation of T1- and T2-weighted MR images, by comparing generated synthetic
MR images to ground truth images. We also evaluate two supervised models; a
modification of CycleGAN and a pure generator model. A small perceptual study
was also performed to evaluate how visually realistic the synthesized images
are. It is shown that the implemented GAN models can synthesize visually
realistic MR images (incorrectly labeled as real by a human). It is also shown
that models producing more visually realistic synthetic images not necessarily
have better quantitative error measurements, when compared to ground truth
data. Code is available at https://github.com/simontomaskarlsson/GAN-MRI",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1805.08960v1,2018-05-23T04:52:06Z,2018-05-23T04:52:06Z,ICADx: Interpretable computer aided diagnosis of breast masses,"In this study, a novel computer aided diagnosis (CADx) framework is devised
to investigate interpretability for classifying breast masses. Recently, a deep
learning technology has been successfully applied to medical image analysis
including CADx. Existing deep learning based CADx approaches, however, have a
limitation in explaining the diagnostic decision. In real clinical practice,
clinical decisions could be made with reasonable explanation. So current deep
learning approaches in CADx are limited in real world deployment. In this
paper, we investigate interpretability in CADx with the proposed interpretable
CADx (ICADx) framework. The proposed framework is devised with a generative
adversarial network, which consists of interpretable diagnosis network and
synthetic lesion generative network to learn the relationship between
malignancy and a standardized description (BI-RADS). The lesion generative
network and the interpretable diagnosis network compete in an adversarial
learning so that the two networks are improved. The effectiveness of the
proposed method was validated on public mammogram database. Experimental
results showed that the proposed ICADx framework could provide the
interpretability of mass as well as mass classification. It was mainly
attributed to the fact that the proposed method was effectively trained to find
the relationship between malignancy and interpretations via the adversarial
learning. These results imply that the proposed ICADx framework could be a
promising approach to develop the CADx system.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1805.05491v1,2018-05-14T22:59:56Z,2018-05-14T22:59:56Z,"Crowdbreaks: Tracking Health Trends using Public Social Media Data and
  Crowdsourcing","In the past decade, tracking health trends using social media data has shown
great promise, due to a powerful combination of massive adoption of social
media around the world, and increasingly potent hardware and software that
enables us to work with these new big data streams. At the same time, many
challenging problems have been identified. First, there is often a mismatch
between how rapidly online data can change, and how rapidly algorithms are
updated, which means that there is limited reusability for algorithms trained
on past data as their performance decreases over time. Second, much of the work
is focusing on specific issues during a specific past period in time, even
though public health institutions would need flexible tools to assess multiple
evolving situations in real time. Third, most tools providing such capabilities
are proprietary systems with little algorithmic or data transparency, and thus
little buy-in from the global public health and research community. Here, we
introduce Crowdbreaks, an open platform which allows tracking of health trends
by making use of continuous crowdsourced labelling of public social media
content. The system is built in a way which automatizes the typical workflow
from data collection, filtering, labelling and training of machine learning
classifiers and therefore can greatly accelerate the research process in the
public health domain. This work introduces the technical aspects of the
platform and explores its future use cases.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1805.00917v3,2018-11-19T22:57:54Z,2018-05-02T17:26:09Z,A Scalable Discrete-Time Survival Model for Neural Networks,"There is currently great interest in applying neural networks to prediction
tasks in medicine. It is important for predictive models to be able to use
survival data, where each patient has a known follow-up time and
event/censoring indicator. This avoids information loss when training the model
and enables generation of predicted survival curves. In this paper, we describe
a discrete-time survival model that is designed to be used with neural
networks, which we refer to as Nnet-survival. The model is trained with the
maximum likelihood method using minibatch stochastic gradient descent (SGD).
The use of SGD enables rapid convergence and application to large datasets that
do not fit in memory. The model is flexible, so that the baseline hazard rate
and the effect of the input data on hazard probability can vary with follow-up
time. It has been implemented in the Keras deep learning framework, and source
code for the model and several examples is available online. We demonstrate the
performance of the model on both simulated and real data and compare it to
existing models Cox-nnet and Deepsurv.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.10801v2,2018-05-05T04:19:23Z,2018-04-28T13:31:45Z,A Cost-Sensitive Deep Belief Network for Imbalanced Classification,"Imbalanced data with a skewed class distribution are common in many
real-world applications. Deep Belief Network (DBN) is a machine learning
technique that is effective in classification tasks. However, conventional DBN
does not work well for imbalanced data classification because it assumes equal
costs for each class. To deal with this problem, cost-sensitive approaches
assign different misclassification costs for different classes without
disrupting the true data sample distributions. However, due to lack of prior
knowledge, the misclassification costs are usually unknown and hard to choose
in practice. Moreover, it has not been well studied as to how cost-sensitive
learning could improve DBN performance on imbalanced data problems. This paper
proposes an evolutionary cost-sensitive deep belief network (ECS-DBN) for
imbalanced classification. ECS-DBN uses adaptive differential evolution to
optimize the misclassification costs based on training data, that presents an
effective approach to incorporating the evaluation measure (i.e. G-mean) into
the objective function. We first optimize the misclassification costs, then
apply them to deep belief network. Adaptive differential evolution optimization
is implemented as the optimization algorithm that automatically updates its
corresponding parameters without the need of prior domain knowledge. The
experiments have shown that the proposed approach consistently outperforms the
state-of-the-art on both benchmark datasets and real-world dataset for fault
diagnosis in tool condition monitoring.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.09997v1,2018-04-26T11:37:03Z,2018-04-26T11:37:03Z,PANDA: Facilitating Usable AI Development,"Recent advances in artificial intelligence (AI) and machine learning have
created a general perception that AI could be used to solve complex problems,
and in some situations over-hyped as a tool that can be so easily used.
Unfortunately, the barrier to realization of mass adoption of AI on various
business domains is too high because most domain experts have no background in
AI. Developing AI applications involves multiple phases, namely data
preparation, application modeling, and product deployment. The effort of AI
research has been spent mostly on new AI models (in the model training stage)
to improve the performance of benchmark tasks such as image recognition. Many
other factors such as usability, efficiency and security of AI have not been
well addressed, and therefore form a barrier to democratizing AI. Further, for
many real world applications such as healthcare and autonomous driving,
learning via huge amounts of possibility exploration is not feasible since
humans are involved. In many complex applications such as healthcare, subject
matter experts (e.g. Clinicians) are the ones who appreciate the importance of
features that affect health, and their knowledge together with existing
knowledge bases are critical to the end results. In this paper, we take a new
perspective on developing AI solutions, and present a solution for making AI
usable. We hope that this resolution will enable all subject matter experts
(eg. Clinicians) to exploit AI like data scientists.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.07886v1,2018-04-21T04:16:46Z,2018-04-21T04:16:46Z,Social Bots for Online Public Health Interventions,"According to the Center for Disease Control and Prevention, in the United
States hundreds of thousands initiate smoking each year, and millions live with
smoking-related dis- eases. Many tobacco users discuss their habits and
preferences on social media. This work conceptualizes a framework for targeted
health interventions to inform tobacco users about the consequences of tobacco
use. We designed a Twitter bot named Notobot (short for No-Tobacco Bot) that
leverages machine learning to identify users posting pro-tobacco tweets and
select individualized interventions to address their interest in tobacco use.
We searched the Twitter feed for tobacco-related keywords and phrases, and
trained a convolutional neural network using over 4,000 tweets dichotomously
manually labeled as either pro- tobacco or not pro-tobacco. This model achieves
a 90% recall rate on the training set and 74% on test data. Users posting pro-
tobacco tweets are matched with former smokers with similar interests who
posted anti-tobacco tweets. Algorithmic matching, based on the power of peer
influence, allows for the systematic delivery of personalized interventions
based on real anti-tobacco tweets from former smokers. Experimental evaluation
suggests that our system would perform well if deployed. This research offers
opportunities for public health researchers to increase health awareness at
scale. Future work entails deploying the fully operational Notobot system in a
controlled experiment within a public health campaign.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.05296v3,2019-02-04T06:03:22Z,2018-04-15T02:33:08Z,Adversarial Attacks Against Medical Deep Learning Systems,"The discovery of adversarial examples has raised concerns about the practical
deployment of deep learning systems. In this paper, we demonstrate that
adversarial examples are capable of manipulating deep learning systems across
three clinical domains. For each of our representative medical deep learning
classifiers, both white and black box attacks were highly successful. Our
models are representative of the current state of the art in medical computer
vision and, in some cases, directly reflect architectures already seeing
deployment in real world clinical settings. In addition to the technical
contribution of our paper, we synthesize a large body of knowledge about the
healthcare system to argue that medicine may be uniquely susceptible to
adversarial attacks, both in terms of monetary incentives and technical
vulnerability. To this end, we outline the healthcare economy and the
incentives it creates for fraud and provide concrete examples of how and why
such attacks could be realistically carried out. We urge practitioners to be
aware of current vulnerabilities when deploying deep learning systems in
clinical settings, and encourage the machine learning community to further
investigate the domain-specific characteristics of medical learning systems.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.00308v3,2021-09-28T14:55:41Z,2018-04-01T15:56:43Z,"Manipulating Machine Learning: Poisoning Attacks and Countermeasures for
  Regression Learning","As machine learning becomes widely used for automated decisions, attackers
have strong incentives to manipulate the results and models generated by
machine learning algorithms. In this paper, we perform the first systematic
study of poisoning attacks and their countermeasures for linear regression
models. In poisoning attacks, attackers deliberately influence the training
data to manipulate the results of a predictive model. We propose a
theoretically-grounded optimization framework specifically designed for linear
regression and demonstrate its effectiveness on a range of datasets and models.
We also introduce a fast statistical attack that requires limited knowledge of
the training process. Finally, we design a new principled defense method that
is highly resilient against all poisoning attacks. We provide formal guarantees
about its convergence and an upper bound on the effect of poisoning attacks
when the defense is deployed. We evaluate extensively our attacks and defenses
on three realistic datasets from health care, loan assessment, and real estate
domains.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.00064v1,2018-03-30T21:56:38Z,2018-03-30T21:56:38Z,"Learning Beyond Human Expertise with Generative Models for Dental
  Restorations","Computer vision has advanced significantly that many discriminative
approaches such as object recognition are now widely used in real applications.
We present another exciting development that utilizes generative models for the
mass customization of medical products such as dental crowns. In the dental
industry, it takes a technician years of training to design synthetic crowns
that restore the function and integrity of missing teeth. Each crown must be
customized to individual patients, and it requires human expertise in a
time-consuming and labor-intensive process, even with computer-assisted design
software. We develop a fully automatic approach that learns not only from human
designs of dental crowns, but also from natural spatial profiles between
opposing teeth. The latter is hard to account for by technicians but important
for proper biting and chewing functions. Built upon a Generative Adversar-ial
Network architecture (GAN), our deep learning model predicts the customized
crown-filled depth scan from the crown-missing depth scan and opposing depth
scan. We propose to incorporate additional space constraints and statistical
compatibility into learning. Our automatic designs exceed human technicians'
standards for good morphology and functionality, and our algorithm is being
tested for production use.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1803.04873v2,2018-03-14T15:30:00Z,2018-03-13T15:17:30Z,"Using Convolutional Neural Networks for Determining Reticulocyte
  Percentage in Cats","Recent advances in artificial intelligence (AI), specifically in computer
vision (CV) and deep learning (DL), have created opportunities for novel
systems in many fields. In the last few years, deep learning applications have
demonstrated impressive results not only in fields such as autonomous driving
and robotics, but also in the field of medicine, where they have, in some
cases, even exceeded human-level performance. However, despite the huge
potential, adoption of deep learning-based methods is still slow in many areas,
especially in veterinary medicine, where we haven't been able to find any
research papers using modern convolutional neural networks (CNNs) in medical
image processing. We believe that using deep learning-based medical imaging can
enable more accurate, faster and less expensive diagnoses in veterinary
medicine. In order to do so, however, these methods have to be accessible to
everyone in this field, not just to computer scientists. To show the potential
of this technology, we present results on a real-world task in veterinary
medicine that is usually done manually: feline reticulocyte percentage. Using
an open source Keras implementation of the Single-Shot MultiBox Detector (SSD)
model architecture and training it on only 800 labeled images, we achieve an
accuracy of 98.7% at predicting the correct number of aggregate reticulocytes
in microscope images of cat blood smears. The main motivation behind this paper
is to show not only that deep learning can approach or even exceed human-level
performance on a task like this, but also that anyone in the field can
implement it, even without a background in computer science.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.10458v2,2018-11-01T12:43:02Z,2018-02-27T02:24:06Z,"A High GOPs/Slice Time Series Classifier for Portable and Embedded
  Biomedical Applications","Nowadays a diverse range of physiological data can be captured continuously
for various applications in particular wellbeing and healthcare. Such data
require efficient methods for classification and analysis. Deep learning
algorithms have shown remarkable potential regarding such analyses, however,
the use of these algorithms on low-power wearable devices is challenged by
resource constraints such as area and power consumption. Most of the available
on-chip deep learning processors contain complex and dense hardware
architectures in order to achieve the highest possible throughput. Such a trend
in hardware design may not be efficient in applications where on-node
computation is required and the focus is more on the area and power efficiency
as in the case of portable and embedded biomedical devices. This paper presents
an efficient time-series classifier capable of automatically detecting
effective features and classifying the input signals in real-time. In the
proposed classifier, throughput is traded off with hardware complexity and cost
using resource sharing techniques. A Convolutional Neural Network (CNN) is
employed to extract input features and then a Long-Short-Term-Memory (LSTM)
architecture with ternary weight precision classifies the input signals
according to the extracted features. Hardware implementation on a Xilinx FPGA
confirm that the proposed hardware can accurately classify multiple complex
biomedical time series data with low area and power consumption and outperform
all previously presented state-of-the-art records. Most notably, our classifier
reaches 1.3$\times$ higher GOPs/Slice than similar state of the art FPGA-based
accelerators.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.06403v2,2018-06-07T23:14:31Z,2018-02-18T16:55:15Z,"RadialGAN: Leveraging multiple datasets to improve target-specific
  predictive models using Generative Adversarial Networks","Training complex machine learning models for prediction often requires a
large amount of data that is not always readily available. Leveraging these
external datasets from related but different sources is therefore an important
task if good predictive models are to be built for deployment in settings where
data can be rare. In this paper we propose a novel approach to the problem in
which we use multiple GAN architectures to learn to translate from one dataset
to another, thereby allowing us to effectively enlarge the target dataset, and
therefore learn better predictive models than if we simply used the target
dataset. We show the utility of such an approach, demonstrating that our method
improves the prediction performance on the target domain over using just the
target dataset and also show that our framework outperforms several other
benchmarks on a collection of real-world medical datasets.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.06259v2,2019-09-12T17:21:14Z,2018-02-17T16:47:32Z,"Exact and Consistent Interpretation for Piecewise Linear Neural
  Networks: A Closed Form Solution","Strong intelligent machines powered by deep neural networks are increasingly
deployed as black boxes to make decisions in risk-sensitive domains, such as
finance and medical. To reduce potential risk and build trust with users, it is
critical to interpret how such machines make their decisions. Existing works
interpret a pre-trained neural network by analyzing hidden neurons, mimicking
pre-trained models or approximating local predictions. However, these methods
do not provide a guarantee on the exactness and consistency of their
interpretation. In this paper, we propose an elegant closed form solution named
$OpenBox$ to compute exact and consistent interpretations for the family of
Piecewise Linear Neural Networks (PLNN). The major idea is to first transform a
PLNN into a mathematically equivalent set of linear classifiers, then interpret
each linear classifier by the features that dominate its prediction. We further
apply $OpenBox$ to demonstrate the effectiveness of non-negative and sparse
constraints on improving the interpretability of PLNNs. The extensive
experiments on both synthetic and real world data sets clearly demonstrate the
exactness and consistency of our interpretation.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.09271v1,2018-01-28T19:29:50Z,2018-01-28T19:29:50Z,"Deep Reinforcement Learning for Dynamic Treatment Regimes on Medical
  Registry Data","This paper presents the first deep reinforcement learning (DRL) framework to
estimate the optimal Dynamic Treatment Regimes from observational medical data.
This framework is more flexible and adaptive for high dimensional action and
state spaces than existing reinforcement learning methods to model real-life
complexity in heterogeneous disease progression and treatment choices, with the
goal of providing doctor and patients the data-driven personalized decision
recommendations. The proposed DRL framework comprises (i) a supervised learning
step to predict the most possible expert actions, and (ii) a deep reinforcement
learning step to estimate the long-term value function of Dynamic Treatment
Regimes. Both steps depend on deep neural networks.
  As a key motivational example, we have implemented the proposed framework on
a data set from the Center for International Bone Marrow Transplant Research
(CIBMTR) registry database, focusing on the sequence of prevention and
treatments for acute and chronic graft versus host disease after
transplantation. In the experimental results, we have demonstrated promising
accuracy in predicting human experts' decisions, as well as the high expected
reward function in the DRL-based dynamic treatment regimes.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1712.09347v1,2017-12-25T02:08:39Z,2017-12-25T02:08:39Z,"Smart Fog: Fog Computing Framework for Unsupervised Clustering Analytics
  in Wearable Internet of Things","The increasing use of wearables in smart telehealth generates heterogeneous
medical big data. Cloud and fog services process these data for assisting
clinical procedures. IoT based ehealthcare have greatly benefited from
efficient data processing. This paper proposed and evaluated use of low
resource machine learning on Fog devices kept close to the wearables for smart
healthcare. In state of the art telecare systems, the signal processing and
machine learning modules are deployed in the cloud for processing physiological
data. We developed a prototype of Fog-based unsupervised machine learning big
data analysis for discovering patterns in physiological data. We employed Intel
Edison and Raspberry Pi as Fog computer in proposed architecture. We performed
validation studies on real-world pathological speech data from in home
monitoring of patients with Parkinson's disease (PD). Proposed architecture
employed machine learning for analysis of pathological speech data obtained
from smartwatches worn by the patients with PD. Results showed that proposed
architecture is promising for low-resource clinical machine learning. It could
be useful for other applications within wearable IoT for smart telehealth
scenarios by translating machine learning approaches from the cloud backend to
edge computing devices such as Fog.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1712.01785v3,2017-12-16T00:30:53Z,2017-12-05T17:49:18Z,"Towards Practical Verification of Machine Learning: The Case of Computer
  Vision Systems","Due to the increasing usage of machine learning (ML) techniques in security-
and safety-critical domains, such as autonomous systems and medical diagnosis,
ensuring correct behavior of ML systems, especially for different corner cases,
is of growing importance. In this paper, we propose a generic framework for
evaluating security and robustness of ML systems using different real-world
safety properties. We further design, implement and evaluate VeriVis, a
scalable methodology that can verify a diverse set of safety properties for
state-of-the-art computer vision systems with only blackbox access. VeriVis
leverage different input space reduction techniques for efficient verification
of different safety properties. VeriVis is able to find thousands of safety
violations in fifteen state-of-the-art computer vision systems including ten
Deep Neural Networks (DNNs) such as Inception-v3 and Nvidia's Dave self-driving
system with thousands of neurons as well as five commercial third-party vision
APIs including Google vision and Clarifai for twelve different safety
properties. Furthermore, VeriVis can successfully verify local safety
properties, on average, for around 31.7% of the test images. VeriVis finds up
to 64.8x more violations than existing gradient-based methods that, unlike
VeriVis, cannot ensure non-existence of any violations. Finally, we show that
retraining using the safety violations detected by VeriVis can reduce the
average number of violations up to 60.2%.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1711.08149v3,2018-10-15T15:26:47Z,2017-11-22T06:32:13Z,"Accurate Real Time Localization Tracking in A Clinical Environment using
  Bluetooth Low Energy and Deep Learning","Deep learning has started to revolutionize several different industries, and
the applications of these methods in medicine are now becoming more
commonplace. This study focuses on investigating the feasibility of tracking
patients and clinical staff wearing Bluetooth Low Energy (BLE) tags in a
radiation oncology clinic using artificial neural networks (ANNs) and
convolutional neural networks (CNNs). The performance of these networks was
compared to relative received signal strength indicator (RSSI) thresholding and
triangulation. By utilizing temporal information, a combined CNN+ANN network
was capable of correctly identifying the location of the BLE tag with an
accuracy of 99.9%. It outperformed a CNN model (accuracy = 94%), a thresholding
model employing majority voting (accuracy = 95%), and a triangulation
classifier utilizing majority voting (accuracy = 95%). Future studies will seek
to deploy this affordable real time location system in hospitals to improve
clinical workflow, efficiency, and patient safety.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1711.06517v2,2018-05-22T05:54:17Z,2017-11-17T12:59:22Z,Wikipedia for Smart Machines and Double Deep Machine Learning,"Very important breakthroughs in data centric deep learning algorithms led to
impressive performance in transactional point applications of Artificial
Intelligence (AI) such as Face Recognition, or EKG classification. With all due
appreciation, however, knowledge blind data only machine learning algorithms
have severe limitations for non-transactional AI applications, such as medical
diagnosis beyond the EKG results. Such applications require deeper and broader
knowledge in their problem solving capabilities, e.g. integrating anatomy and
physiology knowledge with EKG results and other patient findings. Following a
review and illustrations of such limitations for several real life AI
applications, we point at ways to overcome them. The proposed Wikipedia for
Smart Machines initiative aims at building repositories of software structures
that represent humanity science & technology knowledge in various parts of
life; knowledge that we all learn in schools, universities and during our
professional life. Target readers for these repositories are smart machines;
not human. AI software developers will have these Reusable Knowledge structures
readily available, hence, the proposed name ReKopedia. Big Data is by now a
mature technology, it is time to focus on Big Knowledge. Some will be derived
from data, some will be obtained from mankind gigantic repository of knowledge.
Wikipedia for smart machines along with the new Double Deep Learning approach
offer a paradigm for integrating datacentric deep learning algorithms with
algorithms that leverage deep knowledge, e.g. evidential reasoning and
causality reasoning. For illustration, a project is described to produce
ReKopedia knowledge modules for medical diagnosis of about 1,000 disorders.
Data is important, but knowledge deep, basic, and commonsense is equally
important.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1711.06195v2,2017-11-22T01:11:52Z,2017-11-16T16:58:53Z,Neurology-as-a-Service for the Developing World,"Electroencephalography (EEG) is an extensively-used and well-studied
technique in the field of medical diagnostics and treatment for brain
disorders, including epilepsy, migraines, and tumors. The analysis and
interpretation of EEGs require physicians to have specialized training, which
is not common even among most doctors in the developed world, let alone the
developing world where physician shortages plague society. This problem can be
addressed by teleEEG that uses remote EEG analysis by experts or by local
computer processing of EEGs. However, both of these options are prohibitively
expensive and the second option requires abundant computing resources and
infrastructure, which is another concern in developing countries where there
are resource constraints on capital and computing infrastructure. In this work,
we present a cloud-based deep neural network approach to provide decision
support for non-specialist physicians in EEG analysis and interpretation. Named
`neurology-as-a-service,' the approach requires almost no manual intervention
in feature engineering and in the selection of an optimal architecture and
hyperparameters of the neural network. In this study, we deploy a pipeline that
includes moving EEG data to the cloud and getting optimal models for various
classification tasks. Our initial prototype has been tested only in developed
world environments to-date, but our intention is to test it in developing world
environments in future work. We demonstrate the performance of our proposed
approach using the BCI2000 EEG MMI dataset, on which our service attains 63.4%
accuracy for the task of classifying real vs. imaginary activity performed by
the subject, which is significantly higher than what is obtained with a shallow
approach such as support vector machines.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1712.01636v2,2018-02-12T18:25:28Z,2017-11-08T14:26:01Z,"Generalization of Deep Neural Networks for Chest Pathology
  Classification in X-Rays Using Generative Adversarial Networks","Medical datasets are often highly imbalanced with over-representation of
common medical problems and a paucity of data from rare conditions. We propose
simulation of pathology in images to overcome the above limitations. Using
chest X-rays as a model medical image, we implement a generative adversarial
network (GAN) to create artificial images based upon a modest sized labeled
dataset. We employ a combination of real and artificial images to train a deep
convolutional neural network (DCNN) to detect pathology across five classes of
chest X-rays. Furthermore, we demonstrate that augmenting the original
imbalanced dataset with GAN generated images improves performance of chest
pathology classification using the proposed DCNN in comparison to the same DCNN
trained with the original dataset alone. This improved performance is largely
attributed to balancing of the dataset using GAN generated images, where image
classes that are lacking in example images are preferentially augmented.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.04749v2,2018-02-12T05:16:08Z,2017-10-12T23:42:00Z,"Explaining Aviation Safety Incidents Using Deep Temporal Multiple
  Instance Learning","Although aviation accidents are rare, safety incidents occur more frequently
and require a careful analysis to detect and mitigate risks in a timely manner.
Analyzing safety incidents using operational data and producing event-based
explanations is invaluable to airline companies as well as to governing
organizations such as the Federal Aviation Administration (FAA) in the United
States. However, this task is challenging because of the complexity involved in
mining multi-dimensional heterogeneous time series data, the lack of
time-step-wise annotation of events in a flight, and the lack of scalable tools
to perform analysis over a large number of events. In this work, we propose a
precursor mining algorithm that identifies events in the multidimensional time
series that are correlated with the safety incident. Precursors are valuable to
systems health and safety monitoring and in explaining and forecasting safety
incidents. Current methods suffer from poor scalability to high dimensional
time series data and are inefficient in capturing temporal behavior. We propose
an approach by combining multiple-instance learning (MIL) and deep recurrent
neural networks (DRNN) to take advantage of MIL's ability to learn using weakly
supervised data and DRNN's ability to model temporal behavior. We describe the
algorithm, the data, the intuition behind taking a MIL approach, and a
comparative analysis of the proposed algorithm with baseline models. We also
discuss the application to a real-world aviation safety problem using data from
a commercial airline company and discuss the model's abilities and
shortcomings, with some final remarks about possible deployment directions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.08299v1,2017-09-26T05:20:12Z,2017-09-26T05:20:12Z,An In-field Automatic Wheat Disease Diagnosis System,"Crop diseases are responsible for the major production reduction and economic
losses in agricultural industry world- wide. Monitoring for health status of
crops is critical to control the spread of diseases and implement effective
management. This paper presents an in-field automatic wheat disease diagnosis
system based on a weakly super- vised deep learning framework, i.e. deep
multiple instance learning, which achieves an integration of identification for
wheat diseases and localization for disease areas with only image-level
annotation for training images in wild conditions. Furthermore, a new in-field
image dataset for wheat disease, Wheat Disease Database 2017 (WDD2017), is
collected to verify the effectiveness of our system. Under two different
architectures, i.e. VGG-FCN-VD16 and VGG-FCN-S, our system achieves the mean
recognition accuracies of 97.95% and 95.12% respectively over 5-fold
cross-validation on WDD2017, exceeding the results of 93.27% and 73.00% by two
conventional CNN frameworks, i.e. VGG-CNN-VD16 and VGG-CNN-S. Experimental
results demonstrate that the proposed system outperforms conventional CNN
architectures on recognition accuracy under the same amount of parameters,
meanwhile main- taining accurate localization for corresponding disease areas.
Moreover, the proposed system has been packed into a real-time mobile app to
provide support for agricultural disease diagnosis.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1708.09099v1,2017-08-30T03:32:56Z,2017-08-30T03:32:56Z,"Watch Me, but Don't Touch Me! Contactless Control Flow Monitoring via
  Electromagnetic Emanations","Trustworthy operation of industrial control systems depends on secure and
real-time code execution on the embedded programmable logic controllers (PLCs).
The controllers monitor and control the critical infrastructures, such as
electric power grids and healthcare platforms, and continuously report back the
system status to human operators. We present Zeus, a contactless embedded
controller security monitor to ensure its execution control flow integrity.
Zeus leverages the electromagnetic emission by the PLC circuitry during the
execution of the controller programs. Zeus's contactless execution tracking
enables non-intrusive monitoring of security-critical controllers with tight
real-time constraints. Those devices often cannot tolerate the cost and
performance overhead that comes with additional traditional hardware or
software monitoring modules. Furthermore, Zeus provides an air-gap between the
monitor (trusted computing base) and the target (potentially compromised) PLC.
This eliminates the possibility of the monitor infection by the same attack
vectors. Zeus monitors for control flow integrity of the PLC program execution.
Zeus monitors the communications between the human-machine interface and the
PLC, and captures the control logic binary uploads to the PLC. Zeus exercises
its feasible execution paths, and fingerprints their emissions using an
external electromagnetic sensor. Zeus trains a neural network for legitimate
PLC executions, and uses it at runtime to identify the control flow based on
PLC's electromagnetic emissions. We implemented Zeus on a commercial Allen
Bradley PLC, which is widely used in industry, and evaluated it on real-world
control program executions. Zeus was able to distinguish between different
legitimate and malicious executions with 98.9% accuracy and with zero overhead
on PLC execution by design.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1706.02501v1,2017-06-08T10:10:44Z,2017-06-08T10:10:44Z,Unlocking the Potential of Simulators: Design with RL in Mind,"Using Reinforcement Learning (RL) in simulation to construct policies useful
in real life is challenging. This is often attributed to the sequential
decision making aspect: inaccuracies in simulation accumulate over multiple
steps, hence the simulated trajectories diverge from what would happen in
reality.
  In our work we show the need to consider another important aspect: the
mismatch in simulating control. We bring attention to the need for modeling
control as well as dynamics, since oversimplifying assumptions about applying
actions of RL policies could make the policies fail on real-world systems.
  We design a simulator for solving a pivoting task (of interest in Robotics)
and demonstrate that even a simple simulator designed with RL in mind
outperforms high-fidelity simulators when it comes to learning a policy that is
to be deployed on a real robotic system. We show that a phenomenon that is hard
to model - friction - could be exploited successfully, even when RL is
performed using a simulator with a simple dynamics and noise model. Hence, we
demonstrate that as long as the main sources of uncertainty are identified, it
could be possible to learn policies applicable to real systems even using a
simple simulator.
  RL-compatible simulators could open the possibilities for applying a wide
range of RL algorithms in various fields. This is important, since currently
data sparsity in fields like healthcare and education frequently forces
researchers and engineers to only consider sample-efficient RL approaches.
Successful simulator-aided RL could increase flexibility of experimenting with
RL algorithms and help applying RL policies to real-world settings in fields
where data is scarce. We believe that lessons learned in Robotics could help
other fields design RL-compatible simulators, so we summarize our experience
and conclude with suggestions.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1705.09874v2,2018-12-14T21:53:24Z,2017-05-27T22:43:08Z,Targeted Learning with Daily EHR Data,"Electronic health records (EHR) data provide a cost and time-effective
opportunity to conduct cohort studies of the effects of multiple time-point
interventions in the diverse patient population found in real-world clinical
settings. Because the computational cost of analyzing EHR data at daily (or
more granular) scale can be quite high, a pragmatic approach has been to
partition the follow-up into coarser intervals of pre-specified length. Current
guidelines suggest employing a 'small' interval, but the feasibility and
practical impact of this recommendation has not been evaluated and no formal
methodology to inform this choice has been developed. We start filling these
gaps by leveraging large-scale EHR data from a diabetes study to develop and
illustrate a fast and scalable targeted learning approach that allows to follow
the current recommendation and study its practical impact on inference. More
specifically, we map daily EHR data into four analytic datasets using 90, 30,
15 and 5-day intervals. We apply a semi-parametric and doubly robust estimation
approach, the longitudinal TMLE, to estimate the causal effects of four dynamic
treatment rules with each dataset, and compare the resulting inferences. To
overcome the computational challenges presented by the size of these data, we
propose a novel TMLE implementation, the 'long-format TMLE', and rely on the
latest advances in scalable data-adaptive machine-learning software, xgboost
and h2o, for estimation of the TMLE nuisance parameters.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1703.02914v1,2017-03-08T17:00:21Z,2017-03-08T17:00:21Z,Dropout Inference in Bayesian Neural Networks with Alpha-divergences,"To obtain uncertainty estimates with real-world Bayesian deep learning
models, practical inference approximations are needed. Dropout variational
inference (VI) for example has been used for machine vision and medical
applications, but VI can severely underestimates model uncertainty.
Alpha-divergences are alternative divergences to VI's KL objective, which are
able to avoid VI's uncertainty underestimation. But these are hard to use in
practice: existing techniques can only use Gaussian approximating
distributions, and require existing models to be changed radically, thus are of
limited use for practitioners. We propose a re-parametrisation of the
alpha-divergence objectives, deriving a simple inference technique which,
together with dropout, can be easily implemented with existing models by simply
changing the loss of the model. We demonstrate improved uncertainty estimates
and accuracy compared to VI in dropout networks. We study our model's epistemic
uncertainty far away from the data using adversarial images, showing that these
can be distinguished from non-adversarial images by examining our model's
uncertainty.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1702.08623v3,2017-07-14T20:01:31Z,2017-02-28T03:11:33Z,Progress Estimation and Phase Detection for Sequential Processes,"Process modeling and understanding are fundamental for advanced
human-computer interfaces and automation systems. Most recent research has
focused on activity recognition, but little has been done on sensor-based
detection of process progress. We introduce a real-time, sensor-based system
for modeling, recognizing and estimating the progress of a work process. We
implemented a multimodal deep learning structure to extract the relevant
spatio-temporal features from multiple sensory inputs and used a novel deep
regression structure for overall completeness estimation. Using process
completeness estimation with a Gaussian mixture model, our system can predict
the phase for sequential processes. The performance speed, calculated using
completeness estimation, allows online estimation of the remaining time. To
train our system, we introduced a novel rectified hyperbolic tangent (rtanh)
activation function and conditional loss. Our system was tested on data
obtained from the medical process (trauma resuscitation) and sports events
(Olympic swimming competition). Our system outperformed the existing
trauma-resuscitation phase detectors with a phase detection accuracy of over
86%, an F1-score of 0.67, a completeness estimation error of under 12.6%, and a
remaining-time estimation error of less than 7.5 minutes. For the Olympic
swimming dataset, our system achieved an accuracy of 88%, an F1-score of 0.58,
a completeness estimation error of 6.3% and a remaining-time estimation error
of 2.9 minutes.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1702.01780v1,2017-02-06T20:10:10Z,2017-02-06T20:10:10Z,"Toward the automated analysis of complex diseases in genome-wide
  association studies using genetic programming","Machine learning has been gaining traction in recent years to meet the demand
for tools that can efficiently analyze and make sense of the ever-growing
databases of biomedical data in health care systems around the world. However,
effectively using machine learning methods requires considerable domain
expertise, which can be a barrier of entry for bioinformaticians new to
computational data science methods. Therefore, off-the-shelf tools that make
machine learning more accessible can prove invaluable for bioinformaticians. To
this end, we have developed an open source pipeline optimization tool
(TPOT-MDR) that uses genetic programming to automatically design machine
learning pipelines for bioinformatics studies. In TPOT-MDR, we implement
Multifactor Dimensionality Reduction (MDR) as a feature construction method for
modeling higher-order feature interactions, and combine it with a new expert
knowledge-guided feature selector for large biomedical data sets. We
demonstrate TPOT-MDR's capabilities using a combination of simulated and real
world data sets from human genetics and find that TPOT-MDR significantly
outperforms modern machine learning methods such as logistic regression and
eXtreme Gradient Boosting (XGBoost). We further analyze the best pipeline
discovered by TPOT-MDR for a real world problem and highlight TPOT-MDR's
ability to produce a high-accuracy solution that is also easily interpretable.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1701.05130v1,2017-01-18T16:17:35Z,2017-01-18T16:17:35Z,"On the Performance of Network Parallel Training in Artificial Neural
  Networks","Artificial Neural Networks (ANNs) have received increasing attention in
recent years with applications that span a wide range of disciplines including
vital domains such as medicine, network security and autonomous transportation.
However, neural network architectures are becoming increasingly complex and
with an increasing need to obtain real-time results from such models, it has
become pivotal to use parallelization as a mechanism for speeding up network
training and deployment. In this work we propose an implementation of Network
Parallel Training through Cannon's Algorithm for matrix multiplication. We show
that increasing the number of processes speeds up training until the point
where process communication costs become prohibitive; this point varies by
network complexity. We also show through empirical efficiency calculations that
the speedup obtained is superlinear.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1611.04049v1,2016-11-12T22:08:15Z,2016-11-12T22:08:15Z,Prognostics of Surgical Site Infections using Dynamic Health Data,"Surgical Site Infection (SSI) is a national priority in healthcare research.
Much research attention has been attracted to develop better SSI risk
prediction models. However, most of the existing SSI risk prediction models are
built on static risk factors such as comorbidities and operative factors. In
this paper, we investigate the use of the dynamic wound data for SSI risk
prediction. There have been emerging mobile health (mHealth) tools that can
closely monitor the patients and generate continuous measurements of many
wound-related variables and other evolving clinical variables. Since existing
prediction models of SSI have quite limited capacity to utilize the evolving
clinical data, we develop the corresponding solution to equip these mHealth
tools with decision-making capabilities for SSI prediction with a seamless
assembly of several machine learning models to tackle the analytic challenges
arising from the spatial-temporal data. The basic idea is to exploit the
low-rank property of the spatial-temporal data via the bilinear formulation,
and further enhance it with automatic missing data imputation by the matrix
completion technique. We derive efficient optimization algorithms to implement
these models and demonstrate the superior performances of our new predictive
model on a real-world dataset of SSI, compared to a range of state-of-the-art
methods.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1610.09704v1,2016-10-30T20:09:46Z,2016-10-30T20:09:46Z,Feature-Augmented Neural Networks for Patient Note De-identification,"Patient notes contain a wealth of information of potentially great interest
to medical investigators. However, to protect patients' privacy, Protected
Health Information (PHI) must be removed from the patient notes before they can
be legally released, a process known as patient note de-identification. The
main objective for a de-identification system is to have the highest possible
recall. Recently, the first neural-network-based de-identification system has
been proposed, yielding state-of-the-art results. Unlike other systems, it does
not rely on human-engineered features, which allows it to be quickly deployed,
but does not leverage knowledge from human experts or from electronic health
records (EHRs). In this work, we explore a method to incorporate
human-engineered features as well as features derived from EHRs to a
neural-network-based de-identification system. Our results show that the
addition of features, especially the EHR-derived features, further improves the
state-of-the-art in patient note de-identification, including for some of the
most sensitive PHI types such as patient names. Since in a real-life setting
patient notes typically come with EHRs, we recommend developers of
de-identification systems to leverage the information EHRs contain.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1509.08644v1,2015-09-29T08:54:48Z,2015-09-29T08:54:48Z,"Neural-based machine translation for medical text domain. Based on
  European Medicines Agency leaflet texts","The quality of machine translation is rapidly evolving. Today one can find
several machine translation systems on the web that provide reasonable
translations, although the systems are not perfect. In some specific domains,
the quality may decrease. A recently proposed approach to this domain is neural
machine translation. It aims at building a jointly-tuned single neural network
that maximizes translation performance, a very different approach from
traditional statistical machine translation. Recently proposed neural machine
translation models often belong to the encoder-decoder family in which a source
sentence is encoded into a fixed length vector that is, in turn, decoded to
generate a translation. The present research examines the effects of different
training methods on a Polish-English Machine Translation system used for
medical data. The European Medicines Agency parallel text corpus was used as
the basis for training of neural and statistical network-based translation
systems. The main machine translation evaluation metrics have also been used in
analysis of the systems. A comparison and implementation of a real-time medical
translator is the main focus of our experiments.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1205.6910v1,2012-05-31T08:22:19Z,2012-05-31T08:22:19Z,"A New Architecture of a Ubiquitous Health Monitoring System: A Prototype
  Of Cloud Mobile Health Monitoring System","Wireless Body Area Sensor Networks (WBASN) is an emerging technology which
uses wireless sensors to implement real-time wearable health monitoring of
patients to enhance independent living. In this paper we propose a prototype of
cloud mobile health monitoring system. The system uses WBASN and Smartphone
application that uses cloud computing, location data and a neural network to
determine the state of patients.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1204.1653v1,2012-04-07T16:34:20Z,2012-04-07T16:34:20Z,Machine Cognition Models: EPAM and GPS,"Through history, the human being tried to relay its daily tasks to other
creatures, which was the main reason behind the rise of civilizations. It
started with deploying animals to automate tasks in the field of
agriculture(bulls), transportation (e.g. horses and donkeys), and even
communication (pigeons). Millenniums after, come the Golden age with
""Al-jazari"" and other Muslim inventors, which were the pioneers of automation,
this has given birth to industrial revolution in Europe, centuries after. At
the end of the nineteenth century, a new era was to begin, the computational
era, the most advanced technological and scientific development that is driving
the mankind and the reason behind all the evolutions of science; such as
medicine, communication, education, and physics. At this edge of technology
engineers and scientists are trying to model a machine that behaves the same as
they do, which pushed us to think about designing and implementing ""Things
that-Thinks"", then artificial intelligence was. In this work we will cover each
of the major discoveries and studies in the field of machine cognition, which
are the ""Elementary Perceiver and Memorizer""(EPAM) and ""The General Problem
Solver""(GPS). The First one focus mainly on implementing the human-verbal
learning behavior, while the second one tries to model an architecture that is
able to solve problems generally (e.g. theorem proving, chess playing, and
arithmetic). We will cover the major goals and the main ideas of each model, as
well as comparing their strengths and weaknesses, and finally giving their
fields of applications. And Finally, we will suggest a real life implementation
of a cognitive machine.",arxiv,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
