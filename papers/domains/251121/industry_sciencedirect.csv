id,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1016/j.rcim.2021.102283,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2022-04-01,sciencedirect,Real-time data-driven dynamic scheduling for flexible job shop with insufficient transportation resources using hybrid deep Q network,https://api.elsevier.com/content/abstract/scopus_id/85118113364,"With the extensive application of automated guided vehicles in manufacturing system, production scheduling considering limited transportation resources becomes a difficult problem. At the same time, the real manufacturing system is prone to various disturbance events, which increase the complexity and uncertainty of shop floor. To this end, this paper addresses the dynamic flexible job shop scheduling problem with insufficient transportation resources (DFJSP-ITR) to minimize the makespan and total energy consumption. As a sequential decision-making problem, DFJSP-ITR can be modeled as a Markov decision process where the agent should determine the scheduling object and allocation of resources at each decision point. So this paper adopts deep reinforcement learning to solve DFJSP-ITR. In this paper, the multiobjective optimization model of DFJSP-ITR is established. Then, in order to make agent learn to choose the appropriate rule based on the production state at each decision point, a hybrid deep Q network (HDQN) is developed for this problem, which combines deep Q network with three extensions. Moreover, the shop floor state model is established at first, and then the decision point, generic state features, genetic-programming-based action space and reward function are designed. Based on these contents, the training method using HDQN and the strategy for facing new job insertions and machine breakdowns are proposed. Finally, comprehensive experiments are conducted, and the results show that HDQN has superiority and generality compared with current optimization-based approaches, and can effectively deal with disturbance events and unseen situations through learning.",industry
10.1016/j.ymssp.2021.108372,Journal,Mechanical Systems and Signal Processing,scopus,2022-02-15,sciencedirect,Robotic seam tracking system combining convolution filter and deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85113754502,"To perform automatic, real-time seam tracking tasks effectively, a robust and accurate seam tracking system must be designed. In this paper, we solve the seam tracking issue using a six-axis welding robot, a line laser sensor and an industrial computer. The processing of welding images is the core of the seam tracking system, which aims to determine the weld feature point in each image. We propose a two-stage weld feature point localization method that combines convolution filter and deep reinforcement learning (CF-DRL) to localize the weld feature point in each welding image robustly and accurately. In the first stage, the weld feature point is roughly tracked using a convolution filter tracker. But the position given by the convolution tracker is sometimes not accurate enough due to the natural gap between visual tracking and seam tracking. Consequently, in the second stage, the weld feature point should be further refined using our trained policy network. Using our two-stage weld feature point localization method, the weld feature points can be determined from noisy images in real time during the welding process. The 3D coordinate values of these points are obtained according to the structured light measurement principle to control the movement of the robot and the torch in real time. A robotic seam tracking system is established based on the equipment and methods mentioned above. Experimental results show that the welding torch runs smoothly with a strong arc light and splash interference. The mean tracking error of our experiments reaches 0.189 mm, which can fulfill actual welding requirements. Several comparison tests have been performed to illustrate the robustness and accuracy of our seam tracking system using our welding image dataset.",industry
10.1016/j.ssci.2021.105529,Journal,Safety Science,scopus,2022-02-01,sciencedirect,A novel decision support system for managing predictive maintenance strategies based on machine learning approaches,https://api.elsevier.com/content/abstract/scopus_id/85118705579,"Nowadays, the industrial environment is characterised by growing competitiveness, short response times, cost reduction and reliability of production to meet customer needs. Thus, the new industrial paradigm of Industry 4.0 has gained interest worldwide, leading many manufacturers to a significant digital transformation. Digital technologies have enabled a novel approach to decision-making processes based on data-driven strategies, where knowledge extraction relies on the analysis of a large amount of data from sensor-equipped factories. In this context, Predictive Maintenance (PdM) based on Machine Learning (ML) is one of the most prominent data-driven analytical approaches for monitoring industrial systems aiming to maximise reliability and efficiency. In fact, PdM aims not only to reduce equipment failure rates but also to minimise operating costs by maximising equipment life. When considering industrial applications, industries deal with different issues and constraints relating to process digitalisation. The main purpose of this study is to develop a new decision support system based on decision trees (DTs) that guides the decision-making process of PdM implementation, considering context-aware information, quality and maturity of collected data, severity, occurrence and detectability of potential failures (identified through FMECA analysis) and direct and indirect maintenance costs. The decision trees allow the study of different scenarios to identify the conditions under which a PdM policy, based on the ML algorithm, is economically profitable compared to corrective maintenance, considered to be the current scenario. The results show that the proposed methodology is a simple and easy way to implement tool to support the decision process by assessing the different levels of occurrence and severity of failures. For each level, savings and the potential costs have been evaluated at leaf nodes of the trees aimed at defining the most suitable maintenance strategy implementation. Finally, the proposed DTs are applied to a real industrial case to illustrate their applicability and robustness.",industry
10.1016/j.eswa.2021.116045,Journal,Expert Systems with Applications,scopus,2022-02-01,sciencedirect,POSIMNET-R: An immunologic resilient approach to position routers in Industrial Wireless Sensor Networks,https://api.elsevier.com/content/abstract/scopus_id/85117584055,"Industry 4.0 has increased the interest in employing Industrial Wireless Sensor Network (IWSN) technologies in industrial automation. The advantages range from ease of installation and maintenance to reduced deployment time and infrastructure costs. However, industrial automation has critical requirements regarding network infrastructure, such as reliability and failure tolerance. Therefore, it is imperative to have an adequate placement of sensor and router nodes, to obtain a network with multiple paths, allowing the data to reach management systems within a reasonable time, even in the event of failures. The placement of router nodes has to consider latency, network lifespan, connectivity, and failure tolerance aspects in a possibly hostile environment, with classified areas and obstacles such as silos, tanks and buildings. We present a new approach, called POSIMNET-R, to place IWSN routing nodes in an industrial configuration, which circumvents forbidden areas and obstacles, based on Artificial Immunological Networks. The resulting network offers low failure rates and path redundancy criteria. The results have shown that POSIMNET-R was capable of providing a reliable network with multiple paths and resilience of the used routers equal to 81.50% in the basic case study and 73.66% in the real case scenario.",industry
10.1016/j.ress.2021.108119,Journal,Reliability Engineering and System Safety,scopus,2022-02-01,sciencedirect,Prognostics and Health Management (PHM): Where are we and where do we (need to) go in theory and practice,https://api.elsevier.com/content/abstract/scopus_id/85117331443,"We are performing the digital transition of industry, living the 4th industrial revolution, building a new World in which the digital, physical and human dimensions are interrelated in complex socio-cyber-physical systems. For the sustainability of these transformations, knowledge, information and data must be integrated within model-based and data-driven approaches of Prognostics and Health Management (PHM) for the assessment and prediction of structures, systems and components (SSCs) evolutions and process behaviors, so as to allow anticipating failures and avoiding accidents, thus, aiming at improved safe and reliable design, operation and maintenance.
                  There is already a plethora of methods available for many potential applications and more are being developed: yet, there are still a number of critical problems which impede full deployment of PHM and its benefits in practice. In this respect, this paper does not aim at providing a survey of existing works for an introduction to PHM nor at providing new tools or methods for its further development; rather, it aims at pointing out main challenges and directions of advancements, for full deployment of condition-based and predictive maintenance in practice.",industry
10.1016/j.eswa.2021.116014,Journal,Expert Systems with Applications,scopus,2022-02-01,sciencedirect,Broken stitch detection method for sewing operation using CNN feature map and image-processing techniques,https://api.elsevier.com/content/abstract/scopus_id/85116882516,"The inspection of sewing defects is an essential step in the quality assurance of garment manufacturing. Although traditional automated defect detection applications have shown good performance, these methods are usually configured with handcrafted features designed by a human operator. Recently, deep learning methods that include Convolutional Neural Networks (CNNs) have demonstrated excellent performance in a wide variety of computer-vision applications. To take advantage of the CNN’s feature representation, the direct utilization of feature maps from the convolutional layers as universal feature descriptors has been studied. In this paper, we propose a sewing defect detection method using a CNN feature map extracted from the initial layers of a pre-trained VGG-16 to detect a broken stitch from a captured image of a sewing operation. To assess the effectiveness of the proposed method, experiments were conducted on a set of sewing images, including normal images, their synthetic defects, and rotated images. As a result, the proposed method detected true defects with 92.3% accuracy. Moreover, additional conditions for computing devices and deep learning libraries were investigated to reduce the computing time required for real-time computation. Using a general and cheap single-board computer with resizing the image and utilizing a lightweight deep learning library, the computing time was 0.22 s. The results confirm the feasibility of the proposed method’s performance as an appropriate manufacturing technology for garment production.",industry
10.1016/j.rcim.2021.102260,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2022-02-01,sciencedirect,Highly interacting machining feature recognition via small sample learning,https://api.elsevier.com/content/abstract/scopus_id/85115942686,"In the area of intelligent manufacturing, recognising the interacting features on a CAD model is a critical yet challenging task as topology structures of features are damaged due to the feature interaction. Some of the learning-based feature recognition methods produce less favourable results when recognising highly interacting features, while some require a significant amount of 3D models for training, which present an increasing challenge in a real world scenario, especially whenever collecting large training data becomes too difficult and time-consuming. To this end, effective highly interacting feature recognition via small sample learning becomes bottleneck for learning-based methods. To tackle the above issue, the paper proposes a novel method named RDetNet based on single-shot refinement object detection network (RefineDet) which is capable of recognising highly interacting features with small training samples. In addition, the paper further utilises several data augmentation (DA) strategies to increase the amount of relevant 3D training models. Experiments carried out in this paper show that the proposed method yields favourable results in recognising highly interacting features by using small training samples (e.g. 32 models per class).",industry
10.1016/j.future.2021.08.030,Journal,Future Generation Computer Systems,scopus,2022-02-01,sciencedirect,A wearable-based posture recognition system with AI-assisted approach for healthcare IoT,https://api.elsevier.com/content/abstract/scopus_id/85115908462,"Human posture recognition is a challenging task in the medical healthcare industry, when pursuing intelligence, accuracy, security, privacy, and efficiency, etc. Currently, the main posture recognition methods are captured-behaviors-based visual image analysis and wearable devices-based signal analysis. However, these methods suffer from issues such as high misjudgment rate, high-cost and low-efficiency. To address these issues, we propose a collaborative AI-IoT-based solution (namely, WMHPR) that embeds with advanced AI-assisted approach. In WMHPR, we propose the multi-posture recognition (MPR), an offline algorithm is implemented on wearable hardware, to identify posture based on multi-dimensions data. Meanwhile, an AI-based algorithm running on the cloud server (online), named Cascade-AdaBoosting-CART (CACT), is proposed to further enhance the reliability and accuracy of MPR. We recruit 20 volunteers for real-life experiments to evaluate the effectiveness, and the results show our solution is significantly outstanding in terms of accuracy and reliability while comparing with other typical algorithms.",industry
10.1016/j.ymssp.2021.108217,Journal,Mechanical Systems and Signal Processing,scopus,2022-02-01,sciencedirect,Robustness enhancement of machine fault diagnostic models for railway applications through data augmentation,https://api.elsevier.com/content/abstract/scopus_id/85111801223,"The performance of machine learning based machine fault diagnosis (MFD) models could be impaired due to operating condition variations encountered in the real-world industrial environment, such as variations of operating speeds and loads. One major reason for this robustness problem is a lack of adequate training data, especially faulty data, measured in various operating conditions. To cover this gap, we propose a novel data augmentation framework for robustness enhancement in railway MFD applications. First, multibody dynamic simulation (MBS) for physical modeling is applied to simulate arbitrary faulty and operating conditions. Second, fast weighted feature-space averaging (FWFSA) as a new data augmentation technique is developed to augment the simulated faulty data, producing infinite reality-augmented simulation data. The proposed MBS-FWFSA can fit in arbitrary MFD algorithms and transfer-learning settings with minimal effort. Moreover, an in-depth empirical study has been carried out to investigate the causality between condition variations and robustness. A new metric has been defined to evaluate robustness. The experiments also revealed the effect of the proposed MBS-FWFSA and its outperformance against several state-of-the-art augmentation methods. The code and data used in this paper have been shared in our GitHub repository: https://github.com/quickhdsdc/Robustness-Enhancement-of-Machine-Fault-Diagnostic-Models.",industry
10.1016/j.fuel.2021.121234,Journal,Fuel,scopus,2022-01-15,sciencedirect,"Recent progress and perspective on thermal-kinetic, heat and mass transportation of coal spontaneous combustion hazard",https://api.elsevier.com/content/abstract/scopus_id/85115019858,"The thermal dynamic hazard raised by coal spontaneous combustion (CSC) is greatly challenging the worldwide coal industry. Understanding the mechanisms of CSC can provide reliable theoretical basis for process safety. This work conducts a comprehensive review on recent relevant work, aiming at analyzing the status and offering a certain reference for subsequent research endeavors for mechanism illumination and development of advanced fire management technology. Progress based on diversities of experimental and mathematical methods have been witnessed, among which the propensity rating research occupy the largest proportion and their key findings are useful for law description of coal–oxygen reaction. The inhomogeneous thermal field, hot spot migration, shortest self-ignition period etc. provided by large-scale furnace tests and similarity experiments have helped comprehensive understanding the occurrence and development of CSC events. The machine learning approach for real-time forecast of fire status as well as numerical modeling for long-term response prediction have developed a lot. Yet, some blank knowledge on thermal dynamic mechanisms in CSC hazard remains unsolved, such as extrapolation small-scale results to the scale-up situations, multiscale methodology for coupling microscopic phenomena of oxidative reaction and mesoscopic phenomena within single or representative elementary volume of coals as well as morphology variation due to reaction, mechanism illumination of natural convection in self-sustaining spontaneous combustion, threshold descriptions between self-sustaining and extinction conditions for coalfield fire. We thus discussed these potentially useful perspectives for investigation on CSC hazard in the section of summary and future research suggestions, for the sake of process safety in coal industry",industry
10.1016/j.cose.2021.102500,Journal,Computers and Security,scopus,2022-01-01,sciencedirect,AntiViruses under the microscope: A hands-on perspective,https://api.elsevier.com/content/abstract/scopus_id/85118529412,"AntiViruses (AVs) are the main defense line against attacks for most users and much research has been done about them, especially proposing new detection procedures that work in academic prototypes. However, as most current and commercial AVs are closed-source solutions, in practice, little is known about their real internals: information such as what is a typical AV database size, the detection methods effectively used in each operation mode, and how often on average the AVs are updated are still unknown. This prevents research work from meeting the industrial practices more thoroughly. To fill this gap, in this work, we systematize the knowledge about AVs. To do so, we first surveyed the literature and identified existing knowledge gaps in AV internals’ working. Further, we bridged these gaps by analyzing popular (Windows, Linux, and Android) AV solutions to check their operations in practice. Our methodology encompassed multiple techniques, from tracing to fuzzing. We detail current AV’s architecture, including their multiple components, such as browser extensions and injected libraries, regarding their implementation, monitoring features, and self-protection capabilities. We discovered, for instance, a great disparity in the set of API functions hooked by the distinct AV’s libraries, which might have a significant impact in the viability of academically-proposed detection models (e.g., machine learning-based ones).",industry
10.1016/j.compind.2021.103556,Journal,Computers in Industry,scopus,2022-01-01,sciencedirect,C-Ports: A proposal for a comprehensive standardization and implementation plan of digital services offered by the “Port of the Future”,https://api.elsevier.com/content/abstract/scopus_id/85118477493,"In this paper we address the topic of a possible path to standardize the ICT services expected to be delivered by the so-called “Port of the Future”. How the most relevant technologies and Information Systems are used by the Port Communities for their businesses is discussed together with a detailed analysis of the on-going actions carried on by Standard Setting Organizations. Considering the examples given by the C-ITS Platform and the C-Roads programme at EU level, a proposal of contents to be considered in a comprehensive standardization action is given. The innovation services are therefore grouped into four bundles: (i) Vessel & Marine Navigation, (ii) e-Freight & (Intermodal) Logistics, (iii) Passenger Transport, (iv) Environmental sustainability. The standardized version of these applications will be finally labeled as C-Port services. Alongside the standardization plan, a proposal for ranking the ports on the basis of a specially-defined C-Port vector is discussed with the purpose of addressing the well-known lack of consensus around the mathematical definition of the Smart Port Index. Considering the good practice and the background offered by the Port of Livorno in terms of innovation actions, the prospected final user applications are then labeled as Day 1, Day 1.5, and Day 2 services in consideration of the technical and commercial gaps to be filled. As a case study about the evolution in the C-Port vector experienced by the Port of Livorno in the last years will also be discussed.",industry
10.1016/j.conengprac.2021.104957,Journal,Control Engineering Practice,scopus,2022-01-01,sciencedirect,A flexible manufacturing assembly system with deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85117832781,"Traditional assembly line requires a significant amount of designs from engineers, especially in the case of multi-species and small-lot production. Recently, intelligent algorithms based on reinforcement learning are proposed to address this issue. However, the lower success rate and safety reasons limit their industrial applications. In this article, we proposed a systematic solution, including the automatic planning of assembly motions and the monitoring system of the production lines. In the planning stage, we built the digital twin model of the assembly line, then trained a deep reinforcement learning agent to assembly the workpieces. In the production stage, the digital twin model is used to monitor the assembly lines and predict failures. To validate the system we proposed, we conducted a peg-in-hole assembly experiment, and reached a 90% success rate for a single assembly attempt. During the whole experiment, no collision happens in the real world.",industry
10.1016/j.patcog.2021.108218,Journal,Pattern Recognition,scopus,2022-01-01,sciencedirect,Financial time series forecasting with multi-modality graph neural network,https://api.elsevier.com/content/abstract/scopus_id/85112022477,"Financial time series analysis plays a central role in hedging market risks and optimizing investment decisions. This is a challenging task as the problems are always accompanied by multi-modality streams and lead-lag effects. For example, the price movements of stock are reflections of complicated market states in different diffusion speeds, including historical price series, media news, associated events, etc. Furthermore, the financial industry requires forecasting models to be interpretable and compliant. Therefore, in this paper, we propose a multi-modality graph neural network (MAGNN) to learn from these multimodal inputs for financial time series prediction. The heterogeneous graph network is constructed by the sources as nodes and relations in our financial knowledge graph as edges. To ensure the model interpretability, we leverage a two-phase attention mechanism for joint optimization, allowing end-users to investigate the importance of inner-modality and inter-modality sources. Extensive experiments on real-world datasets demonstrate the superior performance of MAGNN in financial market prediction. Our method provides investors with a profitable as well as interpretable option and enables them to make informed investment decisions.",industry
10.1016/j.knosys.2021.107607,Journal,Knowledge-Based Systems,scopus,2021-12-25,sciencedirect,Adaptive multi-objective service composition reconfiguration approach considering dynamic practical constraints in cloud manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85117828056,"Dynamic uncertainty factors such as equipment faults are common in practically implemented cloud manufacturing (CMfg) environments, often causing the manufacturing service to be invalidated. In that case, efficient reconfiguration of the original service composition under practical constraints is critical; however, existing research scarcely focuses on it. This paper proposes a dynamic service composition reconfiguration model to bridge the gap by considering practical constraints (DSCRPC) in a real-life cloud manufacturing environment. Based on the constraints considered in this study, the DSCRPC model redefines three objectives: time (T*), cost (C*), and product service quality (Q*S*). To optimize the DSCRPC model, this study developed an adaptive multi-population multi-objective whale optimization algorithm (AMPOWOA) based on the Pareto strategy. The algorithm adopts four balancing strategies and adaptively optimizes and adjusts the key parameters under various balancing strategies through well-designed reinforcement learning models. Finally, we conduct numerical experiments and actual application case tests to compare the performances of AMPOWOA and other algorithms (MOWOA, MOHHO, NSGA-II). The results show that DSCRPC can continuously tackle the cloud manufacturing service composition (CMSC) reconfiguration issue with constraints until an order is completed. Moreover, AMPOWOA is superior to the other algorithms optimizing the DSCRPC model. This significantly enhances the robustness of service composition reconfiguration in real-life CMfg.",industry
10.1016/j.ejor.2021.03.032,Journal,European Journal of Operational Research,scopus,2021-12-16,sciencedirect,Enhance load forecastability: Optimize data sampling policy by reinforcing user behaviors,https://api.elsevier.com/content/abstract/scopus_id/85103991306,"Load forecasting has long been a key task for reliable power systems planning and operation. Over the recent years, advanced metering infrastructure has proliferated in industry. This has given rise to many load forecasting methods based on frequent measurements of power states obtained by smart meters. Meanwhile, real-world constraints arising in this new setting present both challenges and opportunities to achieve high load forecastability. The bandwidth constraints often imposed on the transmission between data concentrators and utilities are one of them, which limit the amount of data that can be sampled from customers. There lacks a sampling-rate control policy that is self-adaptive to users’ load behaviors through online data interaction with the smart grid environment. In this paper, we formulate the bandwidth-constrained sampling-rate control problem as a Markov decision process (MDP) and provide a reinforcement learning (RL)-based algorithm to solve the MDP for an optimal sampling-rate control policy. The resulting policy can be updated in real time to accommodate volatile load behaviors observed in the smart grid. Numerical experiments show that the proposed RL-based algorithm outperforms competing algorithms and delivers superior predictive performance.",industry
10.1016/j.apenergy.2021.117857,Journal,Applied Energy,scopus,2021-12-15,sciencedirect,A hybrid deep learning-based online energy management scheme for industrial microgrid,https://api.elsevier.com/content/abstract/scopus_id/85115173233,"The fluctuations in electricity prices and intermittency of renewable energy systems necessitate the adoption of online energy management schemes in industrial microgrids. However, it is challenging to design effective and optimal online rolling horizon energy management strategies that can deliver assured optimality, subject to the uncertainties of volatile electricity prices and stochastic renewable resources. This paper presents an adaptable online energy management scheme for industrial microgrids that minimizes electricity costs while meeting production requirements by repeatedly solving an optimization problem over a moving control window, taking advantage of forecasted future prices and renewable energy profiles implemented by a hybrid deep learning model. The predicted values over the control horizon are assumed to be uncertain, and a multivariate Gaussian distribution is used to handle the variations in electricity prices and renewable resources around their predicted nominal values. Simulation results under different scenarios using real-world data verify the effectiveness of the proposed online energy management scheme, assessed by the corresponding gaps with respect to several selected benchmark strategies and the ideal boundaries of the best and worst known solutions. Furthermore, the robustness of the scheme is verified by considering severe errors in forecasted electricity prices and renewable profiles.",industry
10.1016/j.apenergy.2021.117733,Journal,Applied Energy,scopus,2021-12-15,sciencedirect,Controlling distributed energy resources via deep reinforcement learning for load flexibility and energy efficiency,https://api.elsevier.com/content/abstract/scopus_id/85114713033,"Behind-the-meter distributed energy resources (DERs), including building solar photovoltaic (PV) technology and electric battery storage, are increasingly being considered as solutions to support carbon reduction goals and increase grid reliability and resiliency. However, dynamic control of these resources in concert with traditional building loads, to effect efficiency and demand flexibility, is not yet commonplace in commercial control products. Traditional rule-based control algorithms do not offer integrated closed-loop control to optimize across systems, and most often, PV and battery systems are operated for energy arbitrage and demand charge management, and not for the provision of grid services. More advanced control approaches, such as MPC control have not been widely adopted in industry because they require significant expertise to develop and deploy. Recent advances in deep reinforcement learning (DRL) offer a promising option to optimize the operation of DER systems and building loads with reduced setup effort. However, there are limited studies that evaluate the efficacy of these methods to control multiple building subsystems simultaneously. Additionally, most of the research has been conducted in simulated environments as opposed to real buildings. This paper proposes a DRL approach that uses a deep deterministic policy gradient algorithm for integrated control of HVAC and electric battery storage systems in the presence of on-site PV generation. The DRL algorithm, trained on synthetic data, was deployed in a physical test building and evaluated against a baseline that uses the current best-in-class rule-based control strategies. Performance in delivering energy efficiency, load shift, and load shed was tested using price-based signals. The results showed that the DRL-based controller can produce cost savings of up to 39.6% as compared to the baseline controller, while maintaining similar thermal comfort in the building. The project team has also integrated the simulation components developed during this work as an OpenAIGym environment and made it publicly available so that prospective DRL researchers can leverage this environment to evaluate alternate DRL algorithms.",industry
10.1016/j.eswa.2021.115673,Journal,Expert Systems with Applications,scopus,2021-12-15,sciencedirect,CS-ResNet: Cost-sensitive residual convolutional neural network for PCB cosmetic defect detection,https://api.elsevier.com/content/abstract/scopus_id/85111598390,"In the printed circuit board (PCB) industry, cosmetic defect detection is an essential process to ensure product quality. However, existing PCB cosmetic defect detection approaches have a high false alarm rate, which lead to expensive labor costs of manual confirmation. To solve this problem, some traditional machine learning-based approaches have been proposed, but they just utilize hand-crafted features to build classifiers and thus are rough and sub-optimal. Recently, due to its powerful capability in automatic feature extraction, convolutional neural network (CNN) has been widely used in PCB cosmetic defect detection. However, few of them pay attention to the imbalanced class distribution as well as the different misclassification costs of real and pseudo defects, both of which are common problems in the PCB industry. To this end, in this study, we propose a novel model called cost-sensitive residual convolutional neural network (CS-ResNet) by adding a cost-sensitive adjustment layer in the standard ResNet. Specifically, we assign larger weights to minority real defects based on the class-imbalance degree and then optimize CS-ResNet by minimizing the weighted cross-entropy loss function. We conducted a series of experiments by comparing CS-ResNet with the standard ResNet, state-of-the-art CNN-based approach Auto-VRS and traditional machine learning-based approach HOG-SVM on a real-world PCB cosmetic defect dataset. Experimental results show that CS-ResNet achieves the highest 
                        
                           S
                           e
                           n
                           s
                           i
                           t
                           i
                           v
                           i
                           t
                           y
                        
                      (0.89), 
                        G
                     -
                        
                           m
                           e
                           a
                           n
                        
                      (0.91) and the lowest misclassification costs.",industry
10.1016/j.cie.2021.107733,Journal,Computers and Industrial Engineering,scopus,2021-12-01,sciencedirect,SiteForge: Detecting and localizing forged images on microblogging platforms using deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85117254237,"Microblogging applications are currently used to disseminate information with concise text and images. Nevertheless, they are also the largest platform for circulating forged images. Forged images are digital photographs that have been modified to deceive or distort the information they communicate. These manipulated images posted on microblogging apps like Twitter often create biased user emotions leading to harmful consequences like religious feuds or riots. Microblogging platforms and fact-checking industry are investing in artificial intelligence solutions to detect these forged images on time. Many image forensic techniques are proposed earlier, but their effectiveness falls short on real-world images shared over microblogging sites. As forged images shared over these platforms are typically altered using multiple manipulation techniques, it is hard for forensic techniques to detect them. This paper proposes a customized convolutional neural network with an attention mechanism to spot fake images shared over microblogging platforms. Deep learning convolutional networks learn the intrinsic feature set of images and can detect the forged images. To handle multiple manipulations in an image, the applied attention mechanism focuses on the most relevant image region to learn the inherent feature sets. The model utilizes High-pass filters from the image processing domain to initialize kernel weights of the neural network. This supports the proposed model to converge faster and achieve better accuracy. The pooling layers are designed to specifically handle images from microblogging sites. The solution is universal and can detect complex tampering scenarios like text-editing, face-swapping, copy-move, splicing and mirroring. Local Interpretable Model-agnostic Explanations (LIME) is utilized to localize the manipulated region in a forged image. LIME also adds interpretability and confidence to the proposed model, a common concern in deep learning models. The model is verified against the publicly available CASIA 2.0 dataset. An accuracy score of 94.7% is achieved, which is better than the previous state-of-art papers in fake image detection. In order to test the model on real-world images published on Twitter, a recent dataset is built from an Indian viewpoint. The model achieves a modest accuracy of 83.2% over the real-world Twitter dataset. The experiment proves that the proposed model can accurately detect the forged images over social platforms. It can be utilized in the fact-checking field to improve manual efforts. It will also support manual fact-checkers in swift decision making.",industry
10.1016/j.ijpe.2021.108296,Journal,International Journal of Production Economics,scopus,2021-12-01,sciencedirect,An integrated Delphi-MCDM-Bayesian Network framework for production system selection,https://api.elsevier.com/content/abstract/scopus_id/85114948077,"Several attempts are needed to choose the most compatible production system for achieving the desired manufacturing outputs. The significant role of manufacturing strategy deployment is selecting the production system best suited for a manufacturing firm. The appropriately chosen production system (strategic process choice) facilitates a firm to produce “order winning” outputs and provides a production competence to achieve business success. This research presents a novel framework to determine the compatible production system for a manufacturing firm. An integrated three-stage Delphi-MCDM-Bayesian Network (BN) framework has been proposed. The process choice criteria (PCC) considered for deciding production systems are identified through an in-depth literature review and then validated by experts through a Delphi method in the first stage. It resulted in the determination of twenty-six PCC. In the second stage, the multi-criteria decision-making (MCDM) based voting analytical hierarchy process (VAHP) method is adopted to determine each criterion's relative importance for a firm. The relative weights obtained are then used as input for the machine learning (ML) technique- Bayesian network (BN) in the third stage. The BN model quantifies the selection probability of production systems. The proposed Delphi-MCDM-BN framework is demonstrated using a real-life case of a “hydraulic and pneumatic valve” manufacturing firm to select a suitable production system. The three-stage framework is a novel contribution to the literature, which can be used by researchers, practitioners, and manufacturing strategists to choose an appropriate production system for any manufacturing firm.",industry
10.1016/j.asoc.2021.107859,Journal,Applied Soft Computing,scopus,2021-12-01,sciencedirect,Securing Smart Cities using LSTM algorithm and lightweight containers against botnet attacks,https://api.elsevier.com/content/abstract/scopus_id/85114806873,"Smart Cities contains millions of IoT sensors supporting critical applications such as Smart Transport, Buildings, Intelligent Vehicles, and Logistics. A central administrator appointed by the government manages and maintains the security of each node. Smart City relies upon millions of sensors that are heterogeneous and do not support standard security architecture. Different manufacturers have weak protection protocols for their products and do not update their firmware upon newly identified operating systems’ vulnerabilities. Adversaries using brute force methods exploit the lack of inbuilt security systems on IoT devices to grow their bot network. Smart cities require a standard framework combining soft computing and Deep Learning (DL) for device fleet management and complete control of sensor operating systems for absolute security. This paper presents a real-world application for IoT fleet management security using a lightweight container-based botnet detection (C-BotDet) framework. Using a three-phase approach, the framework using Artificial Intelligence detects compromised IoT devices sending malicious traffic on the network. Balena Cloud revokes API keys and prevents a compromised device from infecting other devices to form a more giant botnet. VPN (Virtual Private Network) prevents inter-device communication and routes all malicious traffic through an external server. The framework quickly updates the standard Linux-based operating system IoT device fleet without relying on different manufacturers to update their system security individually. The simulation and analysis of the C-BotDet framework are presented in a practical working environment to demonstrate its implementation feasibility.",industry
10.1016/j.jenvman.2021.113594,Journal,Journal of Environmental Management,scopus,2021-12-01,sciencedirect,A hybrid computational intelligence approach for bioremediation of amoxicillin based on fungus activities from soil resources and aflatoxin B1 controls,https://api.elsevier.com/content/abstract/scopus_id/85113717787,"Nowadays, releasing the Emerging Pollutants (EPs) in the nature is one of the main reasons for many health and environmental disasters. Amoxicillin as an antibiotic is one of the EPs and categorized as the Endocrine Disrupting Compounds (EDCs) in hazardous materials. Accumulation of amoxicillin in the soil bulk increases the cancer risk, drug resistances and other epidemiological diseases. Hence, the soil bioremediation of antibiotics can be a solution for this problem which is more environmental-friendly system. This study technically creates a bio-engine setup in soil bulk for remediation of amoxicillin based on Aspergillus Flavus (AF) activities and Removal Percentage (RP) of amoxicillin with Aflatoxin B1 Generation (AG) controls. The main novelty is to propose a hybrid computational intelligence approach to do optimization for mechanical and biological aspects and to predict the behavior of bio-engine's effective mechanical and biological features in an intelligent way. The optimization model is formulated by the Central Composite Design (CCD) which is set by the Response Surface Methodology (RSM). The prediction model is formulated by the Random Forest (RF), Adaptive Neuro Fuzzy Inference System (ANFIS) and Random Tree (RT) algorithms. According to the experimental practices from real soil samples in different times and places, concentration of amoxicillin and Aflatoxin B1 are set equal to 25 mg/L (ppm) and 15 μg/L (ppb). Likewise, the outcomes of experiments in CCD-RSM computations are evaluated by curve fitting comparisons between linear, 2FI, quadratic and cubic polynomial equations with considering to regression coefficient and predicted regression coefficient values, ANOVA and optimization by sequential differentiation. Based on the results of CCD-RSM, the RP performance in the optimum conditions is measured around 86% and in 25 days after runtime, the RP and AG are balanced in the safe mode. The proposed hybrid model achieves the 0.99 accuracy. The applicability of the research is done using real field evaluations from drug industrial park in Mashhad city in Iran. Finally, a broad analysis is done and managerial insights are concluded. The main findings of the present research are: (I) with application of bioremediation from fungus activities, amoxicillin amounts can be control in soil resources with minimum AG, (II) ANFIS model has the best accuracy for smart monitoring of amoxicillin bioremediation in soil environments and (III) based on the statistical assessments Aeration Intensity and AF/Biological Waste ratio are most effective on the amoxicillin removal percentage.",industry
10.1016/j.rcim.2021.102183,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-12-01,sciencedirect,Autonomous nondestructive evaluation of resistance spot welded joints,https://api.elsevier.com/content/abstract/scopus_id/85110261037,"The application of non-destructive evaluation approaches has attracted strong interests in modern automotive industries. This study presents an autonomous deep-computing framework to analyze raw videos from infrared systems and to predict weld nugget shape and size with unprecedented accuracy and speed. In a comprehensive training and testing experiment with 90 videos (seven sets of welding material stack-ups), a new method was developed to assemble sufficient datasets for neural network training. Our framework successfully predicts all the nugget shapes with F1 scores that range from 0.84 to 0.92. The total training time on Nvidia DGX station takes less than 10 min for each set of welding material stack-up. The real inference time of an individual dataset (with 30 video frames) takes about 0.005 s. The procedure and methods developed in the study can be applied to other image-based weld property prediction, as well as other manufacturing processes. Furthermore, our well-trained neural networks take limited memory resources (2.3 MB) and are suitable for embedded microprocessors for in-situ welding quality control as edge computing within an intelligent welding framework.",industry
10.1016/j.petrol.2021.109151,Journal,Journal of Petroleum Science and Engineering,scopus,2021-12-01,sciencedirect,3D reconstruction of digital cores based on a model using generative adversarial networks and variational auto-encoders,https://api.elsevier.com/content/abstract/scopus_id/85108868168,"The digitalization of cores, namely the reconstruction of digital cores, is a method to reflect the real internal structures of cores by reconstructing the microstructural information and describing the microstructure of cores on the pore scale, which has become an effective way of quantitatively analyzing the pore structures and other matters in cores for rock physics and petroleum science. The modeling method of digital cores can be divided into the physical experimental methods and numerical simulation methods. Physical experimental methods usually are time-consuming and expensive because the drilling and core sampling for physical experiments are quite costly and the manufacturing of experimental samples sometimes are difficult to implement. Without the complex physical preparation and the demands for expensive equipment, numerical simulation methods are relatively cost-effective but still suffer from a lengthy processing time. Recently, deep learning and its variants can effectively extract characteristics from training images (TIs), casting light on the fast reconstruction of digital cores. In this paper, a reconstruction method is proposed by combining the variational auto-encoder (VAE) and the generative adversarial network (GAN) to achieve the balance of their strengths and weaknesses. Besides, the learning diverse generations using determinantal point processes (GDPP) is added to improve the quality of the generated results. Compared to some numerical simulation methods and GAN, the effectiveness and practicability of the proposed method are demonstrated.",industry
10.1016/j.eswa.2021.115429,Journal,Expert Systems with Applications,scopus,2021-11-30,sciencedirect,Active cluster annotation for wafer map pattern classification in semiconductor manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85108662473,"In semiconductor manufacturing, wafer map pattern classification (WMPC) is important for ensuring good manufacturing quality because the defect type on a wafer map provides important information for determining defect causes. To construct a high-performance WMPC model, a large amount of labeled training data is required, which entails a high annotation cost for engineers. To reduce the annotation cost, an active learning framework has been investigated, in which annotation is conducted at the individual wafer map level. If wafer maps can be grouped into clusters based on the similarity of defect patterns, then annotation can be performed at the cluster level rather than at the wafer map level, thereby affording cost effectiveness. Based on the cluster-level annotation, we propose an active cluster annotation to obtain a high-performance WMPC model with reduced annotation cost. For a dataset annotated only for a small subset of wafer maps, clustering is first conducted for unlabeled wafer maps. In an active learning iteration, a convolutional neural network (CNN) is constructed with labeled wafer maps. Subsequently, the cluster-level classification uncertainties of the CNN for unlabeled wafer maps are calculated. With the uncertainties, the query clusters are selected and annotated by an engineer at the cluster level. The performance of the CNN is improved cost-effectively by repeating these iterations. We demonstrate the effectiveness of the proposed method through experiments on real-world data from a semiconductor manufacturer. In addition, we show that cluster-level annotation is a robust annotation method that can yield consistent labels.",industry
10.1016/j.neucom.2021.09.022,Journal,Neurocomputing,scopus,2021-11-27,sciencedirect,Attention-based sequence to sequence model for machine remaining useful life prediction,https://api.elsevier.com/content/abstract/scopus_id/85115966004,"Accurate estimation of remaining useful life (RUL) of industrial equipment can enable advanced maintenance schedules, increase equipment availability and reduce operational costs. However, existing deep learning methods for RUL prediction are not completely successful due to the following two reasons. First, relying on a single objective function to estimate the RUL will limit the learned representations and thus affect the prediction accuracy. Second, while longer sequences are more informative for modelling the sensor dynamics of equipment, existing methods are less effective to deal with very long sequences, as they mainly focus on the latest information. To address these two problems, we develop a novel attention-based sequence to sequence with auxiliary task (ATS2S) model. In particular, our model jointly optimizes both reconstruction loss to empower our model with predictive capabilities (by predicting next input sequence given current input sequence) and RUL prediction loss to minimize the difference between the predicted RUL and actual RUL. Furthermore, to better handle longer sequences, we employ the attention mechanism to focus on all the important input information during the training process. Finally, we propose a new dual-latent feature representation to integrate the encoder features and decoder hidden states, to capture rich semantic information in data. We conduct extensive experiments on four real datasets to evaluate the efficacy of the proposed method. Experimental results show that our proposed method can achieve superior performance over 13 state-of-the-art methods consistently.",industry
10.1016/j.eswa.2021.115225,Journal,Expert Systems with Applications,scopus,2021-11-15,sciencedirect,AutomaticAI – A hybrid approach for automatic artificial intelligence algorithm selection and hyperparameter tuning,https://api.elsevier.com/content/abstract/scopus_id/85108708321,"Recently, more and more real life problems are solved using artificial intelligence (AI) algorithms. One of the biggest challenges when working with AI is the selection and tuning of the best algorithm for solving the problem. The results generated by a given AI algorithm heavily depend on the way in which its hyperparameters are set. In most cases the process of algorithm selection and tuning is a manual, time consuming process in which the developer, based on experience and intuition tries to find the best solution from quality and execution time perspective. In this paper we present a method for solving the problem of AI algorithm selection and tuning, without human intervention, in a fully automated way. The method is a hybrid approach, a combination between particle swarm optimization and simulated annealing. We compare our approach with other similar tools like Auto-sklearn or Hyperopt-sklearn. We demonstrate the time efficiency and high accuracy of this method with some experiments on some known datasets. The paper also presents a platform for AI processing that include a set of procedures and services necessary in case of automatic processing of big datasets as well as the method for AI algorithm selection and tuning. This platform is useful for researchers and developers in an incipient phase of application development, when the best solution must be decided; it is also useful for specialists in different domains (physics, industry, economy) with less experience in using AI algorithms, but which has to process huge amount of data in an automated way.",industry
10.1016/j.livsci.2021.104700,Journal,Livestock Science,scopus,2021-11-01,sciencedirect,A review of deep learning algorithms for computer vision systems in livestock,https://api.elsevier.com/content/abstract/scopus_id/85118744270,"In livestock operations, systematically monitoring animal body weight, biometric body measurements, animal behavior, feed bunk, and other difficult-to-measure phenotypes is manually unfeasible due to labor, costs, and animal stress. Applications of computer vision are growing in importance in livestock systems due to their ability to generate real-time, non-invasive, and accurate animal-level information. However, the development of a computer vision system requires sophisticated statistical and computational approaches for efficient data management and appropriate data mining, as it involves massive datasets. This article aims to provide an overview of how deep learning has been implemented in computer vision systems used in livestock, and how such implementation can be an effective tool to predict animal phenotypes and to accelerate the development of predictive modeling for precise management decisions. First, we reviewed the most recent milestones achieved with computer vision systems and the respective deep learning algorithms implemented in Animal Science studies. Then, we reviewed the published research studies in Animal Science which used deep learning algorithms as the primary analytical strategy for image classification, object detection, object segmentation, and feature extraction. The great number of reviewed articles published in the last few years demonstrates the high interest and rapid development of deep learning algorithms in computer vision systems across livestock species. Deep learning algorithms for computer vision systems, such as Mask R-CNN, Faster R-CNN, YOLO (v3 and v4), DeepLab v3, U-Net and others have been used in Animal Science research studies. Additionally, network architectures such as ResNet, Inception, Xception, and VGG16 have been implemented in several studies across livestock species. The great performance of these deep learning algorithms suggests an improved predictive ability in livestock applications and a faster inference. However, only a few articles fully described the deep learning algorithms and their implementation. Thus, information regarding hyperparameter tuning, pre-trained weights, deep learning backbone, and hierarchical data structure were missing. We summarized peer-reviewed articles by computer vision tasks (image classification, object detection, and object segmentation), deep learning algorithms, animal species, and phenotypes including animal identification and behavior, feed intake, animal body weight, and many others. Understanding the principles of computer vision and the algorithms used for each application is crucial to develop efficient systems in livestock operations. Such development will potentially have a major impact on the livestock industry by predicting real-time and accurate phenotypes, which could be used in the future to improve farm management decisions, breeding programs through high-throughput phenotyping, and optimized data-driven interventions.",industry
10.1016/j.jmapro.2021.09.048,Journal,Journal of Manufacturing Processes,scopus,2021-11-01,sciencedirect,Joint active search and neuromorphic computing for efficient data exploitation and monitoring in additive manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85117322411,"The recent integration of imaging technology with additive manufacturing (AM) leads to the plethora of in-process and high-dimensional data. Machine learning (ML) methods have been implemented to improve understanding of defect formation in AM-built parts and controlling process variability in real-time. However, modern ML methods, in particular deep neural networks, are empowered by massive high-quality labeled data, which are limited in AM due to the following reasons: First, large data labeling is often tedious, costly, and requires substantial human efforts with considerable expertise. Second, the performance of the learning methods depends to a great extent on the presence of positive data instances (i.e., defective) as they are more informative for monitoring. Third, the rare positives result in a severe imbalanced dataset poses critical challenges in training ML methods designed with the assumption that the input contains an equal number of instances from each class. In this research, we propose novel annotation and learning with limited number of data through the integration of active search and hyperdimensional computing (HDC). The active search is developed to benefit from a single bandit model to learn about the data distribution (exploration) while sampling from the regions potentially containing more positives (exploitation). HDC is introduced as an alternative computing method that mimics important brain functionalities and encodes data with high-dimensional vectors, thereby enabling single-pass learning with just a few samples. Experimental results on a real-world case study of drag link joint build show the proposed model locates the rare positives thoroughly and detects lack of fusion defects with the accuracy of 89.58%, in 3.221 ± 0.029 second training time and with only 66 sample data. The joint active search and neuromorphic computing framework is shown to have strong potentials for general applications in a diverse set of domains with in-situ imaging data.",industry
10.1016/j.addma.2021.102328,Journal,Additive Manufacturing,scopus,2021-11-01,sciencedirect,In situ infrared temperature sensing for real-time defect detection in additive manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85115355988,"Melt pool temperature is a critical parameter for the majority of additive manufacturing processes. Monitoring of the melt pool temperature can facilitate the real-time detection of various printing defects such as voids, over-extrusion, filament breakage, clogged nozzle, etc. that occur either naturally or as the result of malicious hacking activity. This study uses an in situ, multi-sensor approach for monitoring melt pool temperature in which non-contact infrared temperature sensors with customized field of view move along with the extruder of a fused deposition modeling-based printer and sense melt pool temperature from a very short working distance regardless of its X-Y translational movements. A statistical method for defect detection is developed and utilized to identify temperature deviations caused by intentionally implemented defects. Effective detection for multiple defect types and sizes is demonstrated using both a simple L-shaped test geometry and a more complex industry standard test article. Strengths and limitations of this approach are presented, and the potential for expansion via more advanced data analysis techniques such as machine learning are discussed.",industry
10.1016/j.cirpj.2021.07.014,Journal,CIRP Journal of Manufacturing Science and Technology,scopus,2021-11-01,sciencedirect,Energy prediction for CNC machining with machine learning,https://api.elsevier.com/content/abstract/scopus_id/85115274916,"Nowadays, the reduction of CO2 emissions by moving from fossil to renewable energy sources is on the policy of many governments. At the same time, these governments are forcing the reduction of energy consumption. Since large industries have been in the focus for the last decade, today also small and medium enterprises with production lot size one are increasingly being obliged to reduce their energy requirements in production. Energy-efficient CNC machine tools contribute to this goal. In machining processes, the machining strategy also has a significant influence on energy demand. For manufacturing of lot size one, the prediction of the energy demand of a machining strategy, before a part is manufactured plays a decisive role. In numerous previous studies, analytical models between the energy demand and the machining strategy have been developed. However, their accuracy depends largely on the parameterization of these models by dedicated experiments. In this paper, different machine learning algorithms, especially variations of the decision tree (’DecisionTree’, ’RandomForest’, boosted ’RandomForest’) are investigated for their ability to predict the energy demand of CNC machining operations based on real production data, without the need for dedicated experiments. As shown in this paper, the most accurate energy demand predictions can be achieved with the ’RandomForest’ algorithm.",industry
10.1016/j.psj.2021.101437,Journal,Poultry Science,scopus,2021-11-01,sciencedirect,Pharmacokinetic/pharmacodynamic profiles of baicalin against Mycoplasma gallisepticum in an in vivo infection model,https://api.elsevier.com/content/abstract/scopus_id/85115144118,"Mycoplasma gallisepticum (
                        M. gallisepticum
                     ), a devastating avian pathogen that commonly causes chronic respiratory disease in chicken, is responsible for tremendous economic losses to the poultry industry. Baicalin is the main constituent of Scutellaria baicalensis that shows potential therapeutic effects against M. gallisepticum. However, the pharmacokinetic/pharmacodynamics (PK/PD) profiles of baicalin against M. gallisepticum are not well understood. The main objective of the present study was to determine the relationship between the PK/PD index and efficacy of baicalin in the M. gallisepticum infection model in chickens. The experiments were carried out on 10-day-old chickens that were challenged with M. gallisepticum in the bilateral air sacs. While, baicalin was orally administrated once in a day for 3 consecutive days, started from d 3 postinfection. Ultra-performance liquid chromatography (UPLC) was used to evaluate the PK parameters of baicalin at doses of 200, 400, and 600 mg/kg in M. gallisepticum-infected chickens. Real-time PCR (RT-PCR) was used for the quantitative detection of M. gallisepticum in lungs. The PK and PD data were fitted to WinNonlin software to evaluate the PK/PD profiles of baicalin against M. gallisepticum. The minimum inhibitory concentration (MIC) of baicalin against M. gallisepticum strain Rlow was 31.25 µg/mL. The in vivo data suggested that baicalin concentration in the lung tissues was higher than plasma (1.21–1.73 times higher). The ratios of AUC24h/MIC of baicalin against bacteriostatic, bactericidal, and eradication were 0.62, 1.33, and 1.49 h, respectively. In conclusion, these results provided potential reference for future clinical dose selection of baicalin and evaluation of susceptibility breakpoints.",industry
10.1016/j.cie.2021.107632,Journal,Computers and Industrial Engineering,scopus,2021-11-01,sciencedirect,Adaptive fault detection framework for recipe transition in semiconductor manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85114017185,"The fault detection and classification (FDC) model is a prediction model that utilizes the sensor data of equipment to predict whether each wafer is faulty or not in the future, which is important to achieve a high yield and reduce the cost. To construct a high-performance FDC model with deep learning, a large amount of labeled training data is required. However, in real-world semiconductor manufacturing processes, the transition of recipe leads to a change in the distribution of input sensor data, which causes performance degradation for the existing FDC model. Model retraining for the new recipe is required, but a large time period is required to acquire a large amount of labeled data for the new recipe. In this study, an adaptive fault detection framework is proposed to minimize the performance degradation caused by the transition of recipe. In this framework, immediately after the recipe transition occurs, unsupervised adaptation is employed to reduce the performance degradation. After inspection results for some new recipe wafers are acquired, semi-supervised adaptation is employed to quickly recover the performance with a small amount of labeled data. Through experiments using real-world data, we demonstrate that the proposed framework can adapt to the new recipe with a reduced performance degradation.",industry
10.1016/j.ins.2021.07.088,Journal,Information Sciences,scopus,2021-11-01,sciencedirect,Fast local representation learning via adaptive anchor graph for image retrieval,https://api.elsevier.com/content/abstract/scopus_id/85113454719,"Linear Discriminant Analysis (LDA) is one of most important methods in dimensionality reduction domain, which is limited with Gaussian assumption. Because of the complexity of real data, data often presents non-Gaussian distribution that points in same class can be divided into several sub-clusters and center point is not enough to describe the distribution of data. In order to solve non-Gaussian data, LDA-based methods consider local structure information through measuring each pairwise distance of full connection graph. However, the strategy of establishing fully-connected graph is at expense of high computational complexity and limits it practical and industrial applications. We propose a Fast Local Representation Learning (FLRL) method which leverages anchor points to establish anchor-based graph and uses similarity matrix to depict the relationships of each pairwise connections. Notably, to avoid the affect of noises and redundant features in original space, anchor points and similarity matrix are updated alternately in subspace that local structure of data will be more precise to learn. Extensive pattern classification and image retrieval experiments on several synthetic datasets, well-known datasets and deep features datasets demonstrate the advantages of our method over the state-of-the-art methods. Our source code available on: 
                     https://github.com/superzcy/FLRL.",industry
10.1016/j.precisioneng.2021.08.010,Journal,Precision Engineering,scopus,2021-11-01,sciencedirect,A method for predicting hobbing tool wear based on CNC real-time monitoring data and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85112751582,"Intelligent monitoring and diagnosis of tool status are of great significance for improving the manufacturing efficiency and accuracy of the workpiece. It is difficult to quickly and accurately predict the wear state of worm gear hob under different working conditions. This paper proposes a novel approach to predict hob wear status based on CNC real-time monitoring data. Based on the open platform communication unified architecture (OPC UA) technology and orthogonal test, the machine data of motor power, current, etc. related to tool wear are collected online in the worm gear machining process. And then, an improved deep belief network (DBN) is used to generate a tool wear model by training data. A growing DBN with transfer learning is introduced to automatically decide its best model structure, which can accelerate its learning process, improve training efficiency and model performance. The experiment results show that the proposed method can effectively predict hob wear status under multi-cutting conditions. To show the advantages of the proposed approach, the performance of the DBN is compared with the traditional back propagation neural network (BP) method in terms of the mean-squared error (MSE). The compared results show that this tool wear prediction method has better prediction accuracy than the traditional BP method during worm gear hobbing.",industry
10.1016/j.jmbbm.2021.104728,Journal,Journal of the Mechanical Behavior of Biomedical Materials,scopus,2021-11-01,sciencedirect,What can artificial intelligence and machine learning tell us? A review of applications to equine biomechanical research,https://api.elsevier.com/content/abstract/scopus_id/85112485329,"Artificial intelligence (AI) and machine learning (ML) are fascinating interdisciplinary scientific domains where machines are provided with an approximation of human intelligence. The conjecture is that machines are able to learn from existing examples, and employ this accumulated knowledge to fulfil challenging tasks such as regression analysis, pattern classification, and prediction. The horse biomechanical models have been identified as an alternative tool to investigate the effects of mechanical loading and induced deformations on the tissues and structures in humans. Many reported investigations into bone fatigue, subchondral bone damage in the joints of both humans and animals, and identification of vital parameters responsible for retaining integrity of anatomical regions during normal activities in all species are heavily reliant on equine biomechanical research. Horse racing is a lucrative industry and injury prevention in expensive thoroughbreds has encouraged the implementation of various measurement techniques, which results in massive data generation. ML substantially accelerates analysis and interpretation of data and provides considerable advantages over traditional statistical tools historically adopted in biomechanical research. This paper provides the reader with: a brief introduction to AI, taxonomy and several types of ML algorithms, working principle of a feedforward artificial neural network (ANN), and, a detailed review of the applications of AI, ML, and ANN in equine biomechanical research (i.e. locomotory system function, gait analysis, joint and bone mechanics, and hoof function). Reviewing literature on the use of these data-driven tools is essential since their wider application has the potential to: improve clinical assessments enabling real-time simulations, avoid and/or minimize injuries, and encourage early detection of such injuries in the first place.",industry
10.1016/j.asoc.2021.107784,Journal,Applied Soft Computing,scopus,2021-11-01,sciencedirect,Towards learning behavior modeling of military logistics agent utilizing profit sharing reinforcement learning algorithm,https://api.elsevier.com/content/abstract/scopus_id/85112396580,"Agent-based modeling has become a beneficial tool in describing the complex and intelligent decision-making behaviors of military logistics entities, which is essential in exploring military logistics system. A challenging task in this field is the learning behavior modeling of military logistics agents. Profit sharing (PS) reinforcement learning algorithm is a representative exploitation-oriented method describing empirical reinforcement learning mechanism, and has been successfully applied to a variety of real-world problems. However, constructing the learning behavior model of military logistics agents is difficult by merely using the original PS algorithm. This difficulty is due to the actual characteristics of equipment support operations and military requirements, such as experience sharing, cooperative action, and hierarchical control. To address this issue, we propose an improved PS algorithm by introducing cooperative task reward correction parameters, experience sharing learning function, and superior command controlled function. We use the research methodology centering on the basic process of the improved PS algorithm as basis to construct the architecture of the learning behavior model of military logistics agents and its corresponding model of elements. Furthermore, we design the implementation algorithm of the learning behavior model. Lastly, we conduct a case study of a tactical military industrial logistics simulation system, thereby verifying the feasibility and effectiveness of the learning behavior model. We find that the improved PS algorithm and corresponding learning behavior model have more advantages than the original PS algorithm.",industry
10.1016/j.aquaeng.2021.102192,Journal,Aquacultural Engineering,scopus,2021-11-01,sciencedirect,"An integrated framework of sensing, machine learning, and augmented reality for aquaculture prawn farm management",https://api.elsevier.com/content/abstract/scopus_id/85112001426,"The rapid growth of prawn farming on an international scale will play an important role in meeting the protein requirements of an expanding global population. Efficient management of the commercial ponds for healthy production of prawns is the key mantra of success in this industry. It is a necessity to maintain the water quality parameters in these ponds within specific ranges to create an ideal environment of optimal growth of healthy prawns. The current practice of water quality data collection and their usage for decision making on most farms is not efficient and does not take full advantage of the latest technologies. The research presented in this paper aimed at addressing this problem by systematic investigation and development of an integrated framework where (i) modern sensors were investigated for their suitability and deployed for continuous monitoring of the water quality variables in prawn ponds; (ii) novel machine learning models were investigated based on collected data and deployed to accurately forecast pond status over next 24 h. This provides farmers insight into upcoming situations and take necessary measures to avoid catastrophic situations; and (iii) augmented reality-based visualisation methods were investigated for improved data capture process and efficient decision making through real-time interactive interfaces. The paper presents the integrated framework as well as the details of sensing, machine learning, and augmented reality components. We found that (i) YSI EXO2 Multi-Sonde is the best sensor for continuous monitoring of prawn ponds; (ii) ForecastNet (our developed machine learning model) provides best forecasting results with symmetric mean absolute percentage error of 6.1 %, 9.6 %, and 8.5 % for dissolved oxygen, pH, and temperature; and (iii) augmented reality-based interactive interface achieves accuracy as high as 89.2 % for management decisions with at least 41 % less time. The experience of the project as presented in this paper can act as a guide for researchers as well as prawn farmers to take advantage of latest sensors, machine learning algorithms and augmented reality tools.",industry
10.1016/j.ins.2021.07.060,Journal,Information Sciences,scopus,2021-11-01,sciencedirect,Deep learning feature-based setpoint generation and optimal control for flotation processes,https://api.elsevier.com/content/abstract/scopus_id/85111482847,"Computer vision-based control is a nonintrusive, cost-effective, and reliable technique for flotation process control. It is known that deep learning features can depict the complex behavior of the froth surface more comprehensively and accurately than handcrafted features. However, few studies have tried to use additional information to improve flotation performance through optimal control. To this end, we have attempted to develop a novel deep learning feature-based two-layer optimal control scheme. The first layer is proposed for setpoint generation of high-dimensional features using improved fuzzy association rule reasoning. Then, an offline conservative double Q-learning control layer that can learn from historical industrial records by mitigating bootstrapping error in action value functions is developed. The proposed method can adapt the setpoint to the change in process feeds. Meanwhile, in contrast to traditional approximate dynamic programming methods that need to interact with real/simulated process systems, this controller can work without any further interactions, which makes it possible to transfer the success of reinforcement learning algorithms to complex industrial process control where opportunities to explore are missing. Experiments demonstrate that the proposed method is effective and promising for practical flotation process control.",industry
10.1016/j.talanta.2021.122608,Journal,Talanta,scopus,2021-11-01,sciencedirect,"PIXE based, Machine-Learning (PIXEL) supported workflow for glass fragments classification",https://api.elsevier.com/content/abstract/scopus_id/85109431731,"This paper presents a structured workflow for glass fragment analysis based on a combination of Elemental Analysis using PIXE and Machine Learning tools, with the ultimate goal of standardizing and helping forensic efforts. The proposed workflow was implemented on glass fragments received from the Israeli DIFS (Israeli Police Force's Division of Identification and Forensic Sciences) that were collected from various vehicles, including glass fragments from different manufacturers and years of production. We demonstrate that this workflow can produce models with high (>80%) accuracy in identifying glass fragment's origins and provide a test-case demonstrating how the model can be applied in real-life forensic events. We provide a standard, reproducible methodology that can be used in many forensic domains beyond glass fragments, for example, Gun Shot Residue, flammable liquids, illegal substances, and more.",industry
10.1016/j.renene.2021.05.155,Journal,Renewable Energy,scopus,2021-11-01,sciencedirect,A deep learning approach towards the detection and recognition of opening of windows for effective management of building ventilation heat losses and reducing space heating demand,https://api.elsevier.com/content/abstract/scopus_id/85107941088,"Building ventilation accounts for up to 30% of the heat loss in commercial buildings and 25% in industrial buildings. To effectively aid the reduction of energy consumption in the building sector, the development of demand-driven control systems for heating ventilation and air-conditioning (HVAC) is necessary. In countries with temperate climates such as the UK, many buildings depend on natural ventilation strategies such as openable windows, which are useful for reducing overheating prevalence during the summer. The manual opening and adjustment of windows by occupants, particularly during the heating season, can lead to substantial heat loss and consequent energy consumption. This could also result in the unnecessary or over ventilation of the space, or the fresh air is more than what is required to ensure adequate air quality. Furthermore, energy losses build up when windows are left open for extended periods. Hence, it is important to develop control strategies that can detect and recognise the period and amount of window opening in real-time and at the same time adjust the HVAC systems to minimise energy wastage and maintain indoor environment quality and thermal comfort. This paper presents a vision-based deep learning framework for the detection and recognition of manual window operation in buildings. A trained deep learning model is deployed into an artificial intelligence-powered camera. To assess the proposed strategy's capabilities, building energy simulation was used with various operation profiles of the opening of the windows based on various scenarios. Initial experimental tests were conducted within a university lecture room with a south-facing window. Deep learning influenced profile (DLIP) was generated via the framework, which uses real-time window detection and recognition data. The generated DLIP were compared with the actual observations, and the initial detection results showed that the method was capable of identifying windows that were opened and had an average accuracy of 97.29%. The results for the three scenarios showed that the proposed strategy could potentially be used to help adjust the HVAC setpoint or alert the occupants or building managers to prevent unnecessary heating demand. Further developments include enhancing the framework ability to detect multiple window opening types and sizes and the detection accuracy by optimising the model.",industry
10.1016/j.ymssp.2021.107915,Journal,Mechanical Systems and Signal Processing,scopus,2021-11-01,sciencedirect,Machine learning based frequency modelling,https://api.elsevier.com/content/abstract/scopus_id/85103975336,"Detection of cracks in structures has always been an important research topic in the industrial domain closely associated with aerospace, mechanical, marine and civil engineering. The presence of the cracks alters the dynamic response properties. Hence, it becomes crucial to locate these cracks in the structures to avoid any catastrophic failures and maintain structural integrity and performance. The study's objective is to propose two distinct statistical procedures for conducting the machine learning experiment for modelling the frequency and show the effect of experiment design on the results. In the study, the predictive performance of machine learning models and their ensembles is compared within each experiment design and between two experimental designs for the task of prediction of first six natural frequencies of a fixed ended cracked beam. The study highlights the significance of more than one experimental design to reduce the confirmation bias in the research and discusses the proposed methods' generalizability over the different modelling constraints and modelling parameters. The study also discusses a real-world implementation of the learned machine learning models from the perspective of Bayesian optimization.",industry
10.1016/j.dss.2021.113523,Journal,Decision Support Systems,scopus,2021-11-01,sciencedirect,Spline-rule ensemble classifiers with structured sparsity regularization for interpretable customer churn modeling,https://api.elsevier.com/content/abstract/scopus_id/85101404963,"An important business domain that relies heavily on advanced statistical- and machine learning algorithms to support operational decision-making is customer retention management. Customer churn prediction is a crucial tool to support customer retention. It allows an early identification of customers who are at risk to abandon the company and provides the ability to gain insights into why customers are at risk. Hence, customer churn prediction models should complement predictive performance with model insights. Inspired by their ability to reconcile strong predictive performance and interpretability, this study introduces rule ensembles and their extension, spline-rule ensembles, as a promising family of classification algorithms to the customer churn prediction domain. Spline-rule ensembles combine the flexibility of a tree-based ensemble classifier with the simplicity of regression analysis. They do, however, neglect the relatedness between potentially conflicting model components which can introduce unnecessary complexity in the models and compromises model interpretability. To tackle this issue, a novel algorithmic extension, spline-rule ensembles with sparse group lasso regularization (SRE-SGL) is proposed to enhance interpretability through structured regularization. Experiments on fourteen real-world customer churn data sets in different industries (i) demonstrate the superior predictive performance of spline-rule ensembles with sparse group lasso over a set well yet powerful benchmark methods in terms of AUC and top decile lift; (ii) show that spline-rule ensembles with sparse group lasso regularization significantly outperform conventional rule ensembles whilst performing at least as well as conventional spline-rule ensembles; and (iii) illustrate the interpretable nature of a spline-rule ensemble model and the advantage of structured regularization in SRE-SGL by means of a case study on customer churn prediction for a telecommunications company.",industry
10.1016/j.jhlste.2020.100275,Journal,"Journal of Hospitality, Leisure, Sport and Tourism Education",scopus,2021-11-01,sciencedirect,Industry 4.0 technologies in tourism education: Nurturing students to think with technology,https://api.elsevier.com/content/abstract/scopus_id/85092173436,"The Industry 4.0 revolution is bringing major transformations in the tourism systems design suitable for technologically oriented consumers. Indeed, methods and technologies introduced by Big Data, Automation, Virtual and augmented reality, Robotics and ICT well fit with the Tourism 4.0 paradigm. However, tourism students are not yet trained on techniques, issues and methods related to the Industry 4.0 framework.
                  Hence, relying on a careful examination of the literature on tourism market trends linked to the offer of innovative technological services, we identified conceptual, methodological, technological and practical skills to be developed in an academic curriculum for Tourism Science students. Learning path were focused on: i) processes of data acquisition from social media, ii) data analysis using Machine Learning techniques and iii) data design into significant elements useful to implement communication systems in the tourism field.
               
                  Results
                  showed that the most of participants achieved a medium-high evaluation for the implementation of the communication systems, applying appropriately techniques and tools learned along the course. Furthermore, the high percentage of students satisfaction registered in relation to the course, revealed that students enjoyed this experience. Outcomes reflects the acquisition and the awareness of those skills that will enable students to be conscious protagonists of their role in tourism 4.0.",industry
10.1016/j.colsurfa.2021.127171,Journal,Colloids and Surfaces A: Physicochemical and Engineering Aspects,scopus,2021-10-20,sciencedirect,Methylene blue adsorption from an aqueous solution by a magnetic graphene oxide/humic acid composite,https://api.elsevier.com/content/abstract/scopus_id/85111111830,"A novel adsorbent called magnetic humic acid/graphene oxide composite (MHAGO) adsorbent was prepared for treating methylene blue (MB) from wastewater. The structure and morphology of MHAGO were characterized by FTIR, XRD, SEM and XPS. The response surface method was used to optimize the quality feeding ratio for the raw materials, and the best graphene oxide: humic acid: ferroferric oxide feeding ratio was determined to be 0.25:0.50:1.66. Batch adsorption experiments were performed with variation in the initial MB dye concentration, pH of the solution, adsorbent dosage and contact time. The results showed that the adsorption reaction occurred at 45 °C with 30 mg adsorbent to adsorb 5.0 mg/L MB in 100 mL solution, with a maximum MB adsorption capacity of approximately 59.00 mg/g for MHAGO. The adsorption kinetics and adsorption isotherms were found to be in accordance with the Elovich equation and Langmuir model, respectively. Moreover, the thermodynamic parameters showed that the adsorption is spontaneously endothermic. The mechanisms for MB adsorption onto the MHAGO surface was mainly electrostatic attraction, π-π interaction and hydrogen bonding. In addition, the MHAGO shows good feasibility for the removal of pollutants from real factory dyeing wastewater.",industry
10.1016/j.neucom.2021.06.075,Journal,Neurocomputing,scopus,2021-10-07,sciencedirect,Emotion-sensitive deep dyna-Q learning for task-completion dialogue policy learning,https://api.elsevier.com/content/abstract/scopus_id/85109428901,"In recent years, task-oriented dialogue systems have received extensive attention from academia and industry. Training a dialogue agent through reinforcement learning is often costly because it requires many interactions with real users. Although the Deep Dyna-Q (DDQ) framework uses simulation experience to alleviate the cost of direct reinforcement learning, it still suffers from challenges such as delayed rewards and policy degradation. This paper proposes an Emotion-Sensitive Deep Dyna-Q (ES-DDQ) model which: (1) presents an emotional world model that considers emotion-related cues to improve the ability of the traditional DDQ framework to model and simulate users, and (2) designs two kinds of emotion-related immediate rewards to mitigate the delayed reward problem. Experimental results show that our proposed approach effectively simulates users’ behaviors and is superior to the state-of-the-art benchmarks.",industry
10.1016/j.probengmech.2021.103173,Journal,Probabilistic Engineering Mechanics,scopus,2021-10-01,sciencedirect,Machine learning based digital twin for stochastic nonlinear multi-degree of freedom dynamical system,https://api.elsevier.com/content/abstract/scopus_id/85117922944,"The potential of digital twin technology is immense, specifically in the infrastructure, aerospace, and automotive sector. However, practical implementation of this technology is not at an expected speed, specifically because of lack of application-specific details. In this paper, we propose a novel digital twin framework for stochastic nonlinear multi-degree of freedom (MDOF) dynamical systems. The proposed digital twin has four modules — (a) a physics-based nominal model, (b) a data collection module, (c) algorithm for real-time update of the digital twin and (d) module for predicting future state. The modules for real-time update and prediction are based on the so-called gray-box modeling approach, and utilizes both physics based and data driven frameworks; this enables the proposed digital twin to generalize and predict future responses. The gray box modeling framework used within the digital twin is developed by coupling Bayesian filtering and machine learning algorithm. Although, the proposed digital twin can be used with any machine learning regression algorithm, we have used Gaussian process in this study. Performance of the proposed approach is illustrated using two examples. Results obtained indicate the applicability and excellent performance of the proposed digital twin framework.",industry
10.1016/j.jocs.2021.101443,Journal,Journal of Computational Science,scopus,2021-10-01,sciencedirect,Towards versatile conversations with data-driven dialog management and its integration in commercial platforms,https://api.elsevier.com/content/abstract/scopus_id/85115363526,"Conversational interfaces have recently become a ubiquitous element in both the personal sphere by easing access to services, and industrial environments by the automation of services, improved customer support and its corresponding cost savings. However, designing the dialog model used by these interfaces to decide system responses is still a hard-to-accomplish task for complex conversational interactions. This paper describes a data-driven dialog management technique, which provides flexibility to develop, deploy and maintain this module. Various configurations for classification algorithms are assessed with two dialog corpora of different application domains, size, dimensionalities and set of possible system responses. The results of the evaluation show satisfactory accuracy and coherence rates in both tasks. As a proof of concept, our proposal has also been integrated with DialogFlow, a platform provided by Google to design conversational user interfaces. Our proposal has been assessed with a real use case, proving that it can be deployed in conjunction with commercial platforms, obtaining satisfactory results for the objective and subjective assessments completed.",industry
10.1016/j.techfore.2021.120986,Journal,Technological Forecasting and Social Change,scopus,2021-10-01,sciencedirect,Big data and firm marketing performance: Findings from knowledge-based view,https://api.elsevier.com/content/abstract/scopus_id/85113910474,"A universal trend in advanced manufacturing countries is defining Industry 4.0, industrialized internet and future factories as a recent wave, which may transform the production and its related services. Further, big data analytics has emerged as a game changer in the business world due to its uses for increasing accuracy in decision-making and enhancing performance of sustainable industry 4.0 applications. This study intends to emphasize on how to support Industry 4.0 with knowledge based view. For the same, a conceptual model is framed and presented with essential components that are required for a real world implementation. The study used qualitative analysis and was guided by a knowledge-based theoretical framework. Thematic analysis resulted in the identification of a number of emergent categories. Key findings highlight significant gaps in conventional decision-making systems and demonstrate how big data enhances firms’ strategic and operational decisions as well as facilitates informational access for improved marketing performance. The resulting proposed model can provide managers with a reference point for using big data to line up firms’ activities for more effective marketing efforts and presents a conceptual basis for further empirical studies in this area.",industry
10.1016/j.jmsy.2021.08.009,Journal,Journal of Manufacturing Systems,scopus,2021-10-01,sciencedirect,Machine learning-based real-time monitoring system for smart connected worker to improve energy efficiency,https://api.elsevier.com/content/abstract/scopus_id/85113549791,"Recent advances in machine learning and computer vision brought to light technologies and algorithms that serve as new opportunities for creating intelligent and efficient manufacturing systems. In this study, the real-time monitoring system of manufacturing workflow for the Smart Connected Worker (SCW) is developed for the small and medium-sized manufacturers (SMMs), which integrates state-of-the-art machine learning techniques with the workplace scenarios of advanced manufacturing systems. Specifically, object detection and text recognition models are investigated and adopted to ameliorate the labor-intensive machine state monitoring process, while artificial neural networks are introduced to enable real-time energy disaggregation for further optimization. The developed system achieved efficient supervision and accurate information analysis in real-time for prolonged working conditions, which could effectively reduce the cost related to human labor, as well as provide an affordable solution for SMMs. The competent experiment results also demonstrated the feasibility and effectiveness of integrating machine learning technologies into the realm of advanced manufacturing systems.",industry
10.1016/j.asoc.2021.107702,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,OrbitNet: A new CNN model for automatic fault diagnostics of turbomachines,https://api.elsevier.com/content/abstract/scopus_id/85111487515,"Unplanned outage due to faults in a high-fidelity turbomachine such as steam turbine and centrifugal compressor often results in the reduced reliability and productivity of a factory while increasing its maintenance costs. Shaft orbit images generated from turbomachine vibration signals have been used to diagnose component faults. However, the existing methods were developed mostly by either using features extracted from orbits or utilizing simulation data which may produce inaccurate results in practical applications due to system complexity and data uncertainties. This paper presents a novel deep learning convolution neural network methodology for accurately automatic diagnostics of multiple faults in general rotating machines by adeptly integrating advanced signal processing with orbit images augmentation, considering the high non-linearity and uncertainty of sensed vibration signals. Environmental noise in vibration signals are filtered through the integration of multiresolution discrete wavelet packet transform and Bayesian hypothesis testing-based automatic thresholding. Shaft orbit images generated from the cleansed vibration data are augmented to increase their representativity and generalization. A novel multi-layer convolutional neural network model, OrbitNet, is specially designed to improve its generality and robustness while avoid possible overfitting in fault identification of various turbomachines. The proposed model retains the pattern information in the axis trajectory to the greatest extent, with the ability of accurately capturing features of various faults in different turbomachines. A generic implementation procedure is proposed for automatic fault diagnosis of rotating machinery based on the presented methodology. A comparison study is conducted to demonstrate the effectiveness and feasibility of the proposed methodology by using the sensed vibration signals collected from three real-world centrifugal compressors, two steam turbines and one generator with four different fault modes including imbalance, friction, misalignment and oil whirl.",industry
10.1016/j.conengprac.2021.104903,Journal,Control Engineering Practice,scopus,2021-10-01,sciencedirect,Synthesizing labeled data to enhance soft sensor performance in data-scarce regions,https://api.elsevier.com/content/abstract/scopus_id/85111246946,"Quality variables are key indicators of the operating performance in industrial processes. Because they are difficult to measure, soft sensor models can be adopted to predict them timely. For accurate prediction, sufficient training data are necessary to construct a good soft sensor model. In practical industrial processes, however, data labeled with quality variables are usually deficient in the desired region. Particularly, when the process is just switched to a new mode, available data in this new mode are initially quite a few. In this paper, a novel data synthesis method based on the regressor-embedded semi-supervised variational autoencoder (RSSVAE) model is proposed to generate synthetic labeled data when the original labeled data are inadequate. The proposed model utilizes not only the original data in the data-scarce region but also the data in other regions, which share some common information with the scarce data. Meanwhile, data synthesis and model correction mechanism are implemented iteratively to avoid model biases. Once the synthetic labeled data of the data-scarce region are acquired, they are combined with the original labeled data to establish a local soft sensor and predict the quality variables of the unlabeled data. Finally, a real ammonia synthesis process is introduced to demonstrate the effectiveness of the proposed method.",industry
10.1016/j.measurement.2021.109819,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-10-01,sciencedirect,Automatic recognition system of pointer meters based on lightweight CNN and WSNs with on-sensor image processing,https://api.elsevier.com/content/abstract/scopus_id/85110012520,"The pointer meter is widely used in the modern industrial process. This paper proposes a novel pointer meter recognition method based on wireless sensor networks (WSNs) and a lightweight convolutional neural network (CNN), which completes image preprocessing, CNN classification, and reading calculation on the WSN end node, and then only transmits the recognized result in the WSN to reduce its payload transmission data. Meanwhile, a lightweight CNN classifier model with a simple structure and small size is designed for embedding in the resource-constrained WSN node. A set of experiments have been carried out on the fabricated prototype to verify the feasibility and adaptability of the proposed method. Experimental results have shown that the maximum error of the recognized results for real-world applications is around 0.27%, while the payload transmission data of the WSN decrease from 112.5 kB to 5 bytes.",industry
10.1016/j.asoc.2021.107644,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,Production scheduling in industrial mining complexes with incoming new information using tree search and deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85109174667,"Industrial mining complexes have implemented digital technologies and advanced sensors to monitor and gather real-time data about their different operational aspects, starting from the supply of materials from the mineral deposits involved to the products provided to customers. However, technologies are not available to respond in real-time to the incoming new information to adapt the short-term production schedule of a mining complex. A short-term production schedule determines the daily/weekly/monthly sequence of extraction, the destination of materials and utilization of processing streams. This paper presents a novel self-learning artificial intelligence algorithm for mining complexes that learns, from its own experience, to adapt the short-term production scheduling decisions by responding to incoming new information. The algorithm plays the game of short-term production scheduling on its own using a Monte Carlo tree search to train a deep neural network agent that adapts the short-term production schedule with incoming new information. The deep neural network agent evaluates the short-term production scheduling decisions and, in parallel, performs searches using the Monte Carlo tree search to generate experiences. The experiences are then used to train the agent. The agent improves the strength of the tree search, which results in an even stronger self-play to generate better experiences. An application of the proposed algorithm at a real-world copper mining complex shows its exceptional performance to adapt the 13-week short-term production schedule almost in real-time. The adapted production schedule successfully meets the different production requirements and makes better use of the processing capabilities, while also increasing copper concentrate production by 7% and cash flows by 12% compared to the initial production schedule. A video of the proposed algorithm can be found at https://youtu.be/_gSbzxMc_W8.",industry
10.1016/j.measurement.2021.109821,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-10-01,sciencedirect,BV-Net: Bin-based Vector-predicted Network for tubular solder joint detection,https://api.elsevier.com/content/abstract/scopus_id/85109091734,"Tubular solder joint detection is an important and challengeable issue in industry, due to the small objects, rarely collected datasets and real-time and high precision requirements. Traditional methods on defect detection cannot solve tubular solder joint detection due to lacking of angle estimation. In this paper, we propose a tubular solder joint detection method named Bin-based Vector-predicted Network (BV-Net), which combines the framework of state-of-the-art deep-learning-based object detector (YOLOv4) with specific characteristics and requirements of tubular solder joint detection. BV-Net could effectively estimate both the center point and the direction of tubular solder joints. Firstly, To regress the center point, we propose a Circle-based Distance-Intersection over Union (CirDIoU) loss, which gets better learning performance for the center point of tubular solder joint than Distance-Intersection over Union (DIOU) loss. Secondly, to estimate the direction, we introduce a bin-based angle regression method, which transforms a regression task into a classification and regression task, improving the precision of direction estimation greatly. Thirdly, we establish a tubular solder joint dataset and design a new evaluation index: mAP (
                        
                           
                              δ
                           
                           
                              d
                           
                        
                     , 
                        
                           
                              δ
                           
                           
                              θ
                           
                        
                     ) for tubular solder joint detection, combining the relative deviation of center point positioning 
                        
                           
                              δ
                           
                           
                              d
                           
                        
                      and the relative deviation of angle regression 
                        
                           
                              δ
                           
                           
                              θ
                           
                        
                     . Finally, comparison experiments on the dataset are carried out. BV-Net achieved 85.5% mAP (0.5%, 3%) with 34.4 FPS, meeting the requirements of industrial system. In direction estimation, bin-based angle regression method promotes 4.3% mAP (-, 3%), compared with the baseline. In center point positioning, BV-Net outperforms YOLOv4 by an improvement of 0.4% mAP (0.5%, -). The experimental results verified the effectiveness of our method.",industry
10.1016/j.compind.2021.103485,Journal,Computers in Industry,scopus,2021-10-01,sciencedirect,Deep learning-based visual control assistant for assembly in Industry 4.0,https://api.elsevier.com/content/abstract/scopus_id/85106362310,"Product assembly is a crucial process in manufacturing plants. In Industry 4.0, the offer of mass-customized products is expanded, thereby increasing the complexity of the assembling phase. This implies that operators should pay close attention to small details, potentially resulting in errors during the manufacturing process owing to its high level of complexity. To mitigate this, we propose a novel architecture that evaluates the activities of an operator during manual assembly in a production cell so that errors in the manufacturing process can be identified, thus avoiding low quality in the final product and reducing rework and waste of raw materials or time. To perform this assessment, it is necessary to use state-of-the-art computer vision techniques, such as deep learning, so that tools, components, and actions may be identified by visual control systems. We develop a deep-learning-based visual control assembly assistant that enables real-time evaluation of the activities in the assembly process so that errors can be identified. A general-use language is developed to describe the actions in assembly processes, which can also be used independently of the proposed architecture. Finally, we generate two datasets with annotated data to be fed to the deep learning methods, the first for the recognition of tools and accessories and the second for the identification of basic actions in manufacturing processes. To validate the proposed method, a set of experiments are conducted, and high accuracy is obtained.",industry
10.1016/j.cofs.2021.03.014,Journal,Current Opinion in Food Science,scopus,2021-10-01,sciencedirect,Novel digital technologies implemented in sensory science and consumer perception,https://api.elsevier.com/content/abstract/scopus_id/85104656313,"New and emerging digital technologies have been implemented in sensory science, which minimize subjectivity and biases in data acquisition and interpretation compared to traditional methods. These technologies have enabled the incorporation of physiological and emotional responses of panelists elicited by food, beverage, and packaging stimuli through accurate and unbiased information from different sensor technologies. This review focused on recent advances of digital technologies used for sensory science, such as (i) software for sensory science, (ii) integration of biometrics to assess physiological and emotional responses of panelists, (iii) incorporation of virtual, augmented, and mixed reality, and (iv) sensor technology (electronic noses and tongues) for sensory analysis. Rapid data acquisition and results’ interpretation could open the way to automation and implementation of Artificial Intelligence that could revolutionize the food and beverage industries. It also presents a proposed framework for integrating and implementing digital technologies through the food chain from farm/manufacturing facilities to the palate.",industry
10.1016/j.rcim.2021.102176,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-10-01,sciencedirect,Robotic grasping: from wrench space heuristics to deep learning policies,https://api.elsevier.com/content/abstract/scopus_id/85104603575,"The robotic grasping task persists as a modern industry problem that seeks autonomous, fast implementation, and efficient techniques. Domestic robots are also a reality demanding a delicate and accurate human–machine interaction, with precise robotic grasping and handling. From decades ago, with analytical heuristics, to recent days, with the new deep learning policies, grasping in complex scenarios is still the aim of several works’ that propose distinctive approaches. In this context, this paper aims to cover recent methodologies’ development and discuss them, showing state-of-the-art challenges and the gap to industrial applications deployment. Given the complexity of the related issue associated with the elaborated proposed methods, this paper formulates some fair and transparent definitions for results’ assessment to provide researchers with a clear and standardised idea of the comparison between the new proposals.",industry
10.1016/j.knosys.2021.107261,Journal,Knowledge-Based Systems,scopus,2021-09-27,sciencedirect,Federated conditional generative adversarial nets imputation method for air quality missing data,https://api.elsevier.com/content/abstract/scopus_id/85111226892,"The air quality is a topic of extreme concern that attracts a lot of attention in the world. Many intelligent air quality monitoring networks have been deployed in various places, especially in big cities. These monitoring networks collect air quality data with some missing data for some reasons which pose an obstacle for air quality publishing and studies. Generative adversarial nets (GAN) methods have achieved state-of-the-art performance in missing data imputation. GAN-based imputation method needs enough training data while one monitoring network has just a few and poor quality monitoring data and these data sets do not meet the independent identical distribution (IID) condition. Therefore, one monitoring network side needs to utilize more monitoring data from other sides as far as possible. However, in the real world, these air quality monitoring networks are owned by different organizations — companies, the government even some secret units. Many of them cannot share detailed monitoring data due to security, privacy, and industrial competition. In this paper, it is the first time to propose a conditional GAN imputation method under a federated learning framework to solve the data sets that come from diverse data-owners without sharing. Furthermore, we improve the vanilla conditional GAN performance with Wasserstein distance and “Hint mask” trick. The experimental results show that our GAN-based imputation methods can achieve the best performance. And our federated GAN imputation method outperforms the GAN imputation method trained locally for each participant which means our imputation model can work. Our proposed federated GAN method can benefit model quality by increasing access to air quality data through private multi-institutional collaborations. We further investigate the effects of data geographical distribution across collaborating participants on model quality and, interestingly, we find that the GAN training process with a federated learning framework performs more stable.",industry
10.1016/j.eswa.2021.115019,Journal,Expert Systems with Applications,scopus,2021-09-15,sciencedirect,A hybrid model integrating deep learning with investor sentiment analysis for stock price prediction,https://api.elsevier.com/content/abstract/scopus_id/85104927982,"Whether stock prices are predictable has been the center of debate in academia. In this paper, we propose a hybrid model that combines a deep learning approach with a sentiment analysis model for stock price prediction. We employ a Convolutional Neural Network model for classifying the investors’ hidden sentiments, which are extracted from a major stock forum. We then propose a hybrid research model by applying the Long Short-Term Memory (LSTM) Neural Network approach for analyzing the technical indicators from the stock market and the sentiment analysis results from the first step. Furthermore, this work has conducted real-life experiments from six key industries of three time intervals on the Shanghai Stock Exchange (SSE) to validate the effectiveness and applicability of the proposed model. The experiment results indicate that the proposed model has achieved better performance in classifying investor sentiments than the baseline classifiers, and this hybrid approach performs better in predicting stock prices compared to the single model and the models without sentiment analysis.",industry
10.1016/j.knosys.2021.107216,Journal,Knowledge-Based Systems,scopus,2021-09-05,sciencedirect,Deep transfer learning for conditional shift in regression[Formula presented],https://api.elsevier.com/content/abstract/scopus_id/85109376376,"Deep transfer learning (DTL) has received increasing attention in smart manufacturing, whereas most current studies focus on the situation of marginal distribution shift in classification. We observe a new regression scenario in machine health monitoring systems (MHMS) with conditional distribution discrepancy across domains and try to propose a general theoretical approach for broader applications. In this paper, we propose a DTL framework CDAR, namely conditional distribution deep adaptation in regression. As only few labeled target data is available, in addition to only considering the prediction accuracy of individual samples, CDAR aims to preserve the global properties of the conditional distribution dominated by the target data. Thus, a hybrid loss function is constructed by combining the mean square error (MSE) and conditional embedding operator discrepancy (CEOD) in CDAR, and the target model is able to be finetuned by minimizing the designed loss function through back-propagation. The performance of the proposed CDAR is compared with two classical marginal distribution adaptation algorithms, TCA and DAN, and a specific method of DTL, FA. Experiments are carried out on two real-world datasets and the results verify the effectiveness of our method.",industry
10.1016/j.displa.2021.102076,Journal,Displays,scopus,2021-09-01,sciencedirect,Voxel-based three-view hybrid parallel network for 3D object classification,https://api.elsevier.com/content/abstract/scopus_id/85114053649,"Three-dimensional models are widely used in the fields of multimedia, computer graphics, virtual reality, entertainment, design, and manufacturing because of the rich information that preserves the surface, color and texture of real objects. Therefore, effective 3D object classification technology has become an urgent need. Previous methods usually directly convert classic 2D convolution into 3D form and apply it to objects with binary voxel representation, which may lose internal information that is essential for recognition. In this paper, we propose a novel voxel-based three-view hybrid parallel network for 3D shape classification. This method first obtains the depth projection views of the three-dimensional model from the front view, the top view and the side view, so as to preserve the spatial information of the three-dimensional model to the greatest extent, and output its predicted probability value for the category of the three-dimensional model, and then combining the three-view parallel network with voxel sub-network performs weight fusion, and then uses Softmax for classification. We conducted a series of experiments to verify the design of the network and achieved competitive performance in the 3D object classification tasks of ModelNet10 and ModelNet40.",industry
10.1016/j.pmcj.2021.101445,Journal,Pervasive and Mobile Computing,scopus,2021-09-01,sciencedirect,Towards generating a reliable device-specific identifier for IoT devices,https://api.elsevier.com/content/abstract/scopus_id/85111971982,"A significant number of IoT devices are being deployed in the wild, mostly in remote locations and in untrusted conditions. This could include monitoring an electronic perimeter fence or a critical infrastructure such as telecom and power grids. Such applications rely on the fidelity of data reported from the IoT devices, and hence it is imperative to identify the trustworthiness of the remote device before taking decisions. Existing approaches use a secret key usually stored in volatile or non-volatile memory for creating an encrypted digital signature. However, these techniques are vulnerable to malicious attacks and have significant computation and energy overhead. This paper presents a novel device-specific identifier, IoT-ID that captures the device characteristics and can be used towards device identification. IoT-ID is based on physically unclonable functions (PUFs), that exploit variations in the manufacturing process to derive a unique fingerprint for integrated circuits. In this work, we design novel PUFs for Commercially Off the Shelf (COTS) components such as clock oscillators and ADC, to derive IoT-ID for a device. Hitherto, system component PUFs are invasive and rely on additional dedicated hardware circuitry to create a unique fingerprint. A highlight of our PUFs is doing away with special hardware. IoT-ID is non-invasive and can be invoked using simple software APIs running on COTS components. IoT-ID has the following key properties viz., constructability, real-time, uniqueness, and reproducibility, making them robust device-specific identifiers.
                  We present detailed experimental results from our live deployment of 50 IoT devices running over a month. Our edge machine learning algorithm has 100% accuracy in uniquely identifying the 50 devices in our deployment and can run locally on the resource-constrained IoT device. We show the scalability of IoT-ID with the help of numerical analysis on 1000s of IoT devices. Further, we discuss approaches to evaluate and improve the reliability of the IoT-ID.
                        1
                     
                     
                        1
                        This manuscript is an extension of the paper ‘IoT-ID: A Novel Device-Specific Identifier Based on Unique Hardware Fingerprints’ Vaidya et al. (2020) published in 2020 IEEE/ACM Fifth International Conference on Internet-of-Things Design and Implementation (IoTDI).",industry
10.1016/j.apmt.2021.101123,Journal,Applied Materials Today,scopus,2021-09-01,sciencedirect,Physics-informed machine learning and mechanistic modeling of additive manufacturing to reduce defects,https://api.elsevier.com/content/abstract/scopus_id/85111269167,"In the past few decades, additive manufacturing has evolved for the one-step fabrication of various complex, customized metallic components that cannot be easily and economically produced by other means. However, widespread applications and market penetration of such components are often hindered by the formation of common defects that affect part quality, reliability, and serviceability, and increase the cost. Here, for the first time, we show that a combination of physics-informed machine learning, mechanistic modeling, and experimental data can reduce the occurrence of common defects in additive manufacturing. By analyzing experimental data on the defect formation for commonly used alloys available in the disjointed, peer-reviewed literature, we identify several important variables that reveal the physics behind the defect formation. Values of those variables computed using a mechanistic model, when used in a physics-informed machine learning, provide the hierarchical importance of the variables on defect formation. In addition, based on the results of the physics-informed machine learning, we provide easy-to-use, verifiable, quantitative formalism that can be used in real-time to predict defects before experiments. The proposed methodology can help in reducing common defects such as balling, cracking, lack of fusion, porosity, and surface roughness, and solve other complex engineering problems beyond additive manufacturing.",industry
10.1016/j.engappai.2021.104382,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-09-01,sciencedirect,Partially Observable Monte Carlo Planning with state variable constraints for mobile robot navigation,https://api.elsevier.com/content/abstract/scopus_id/85111045874,"Autonomous mobile robots employed in industrial applications often operate in complex and uncertain environments. In this paper we propose an approach based on an extension of Partially Observable Monte Carlo Planning (POMCP) for robot velocity regulation in industrial-like environments characterized by uncertain motion difficulties. The velocity selected by POMCP is used by a standard engine controller which deals with path planning. This two-layer approach allows POMCP to exploit prior knowledge on the relationships between task similarities to improve performance in terms of time spent to traverse a path with obstacles. We also propose three measures to support human-understanding of the strategy used by POMCP to improve the performance. The overall architecture is tested on a Turtlebot3 in two environments, a rectangular path and a realistic production line in a research lab. Tests performed on a C++ simulator confirm the capability of the proposed approach to profitably use prior knowledge, achieving a performance improvement from 0.7% to 3.1% depending on the complexity of the path. Experiments on a Unity simulator show that the proposed two-layer approach outperforms also single-layer approaches based only on the engine controller (i.e., without the POMCP layer). In this case the performance improvement is up to 37% comparing to a state-of-the-art deep reinforcement learning engine controller, and up to 51% comparing to the standard ROS engine controller. Finally, experiments in a real-world testing arena confirm the possibility to run the approach on real robots.",industry
10.1016/j.ijcip.2021.100424,Journal,International Journal of Critical Infrastructure Protection,scopus,2021-09-01,sciencedirect,Industrial intrusion detection based on the behavior of rotating machine,https://api.elsevier.com/content/abstract/scopus_id/85111013464,"In this study, a new industrial intrusion detection method is introduced for the control system of rotating machines as critical assets in many industries. Data tampering is a major attack on the control systems which disrupts the functionality of the asset. Hence, our objective is to detect data manipulations in the system. We use the behavior of the rotating machine to propose new industrial intrusion detection for the control system of the rotating machine by machine learning techniques. The behavior is elicited by the data of sensors under all the conditions of the rotating machine operation. In this work, the nonlinear regression, novelty detection, outlier detection, and classification approaches are implemented to create behavioral model. On each implementation, online data are compared with the real data of behavior prediction model during the operation of the rotating machine to detect any abnormality. According to our experimental results, the accuracy of the behavioral models created by the One-classSVM novelty detection, k- Nearest Neighbor (kNN) outlier detection, decision tree classifier, k-Neighbors classifier, random forest classifier, and AdaBoost classifier is obtained as 0.98, 0.994, 0.999, 0.999, 0.999, and 0.999, respectively. The results indicate that the proposed industrial intrusion detection method is able to detect the data tampering attacks on the control system of the rotating machines very accurately.",industry
10.1016/j.segan.2021.100511,Journal,"Sustainable Energy, Grids and Networks",scopus,2021-09-01,sciencedirect,Multi-interval programming based scheduling of appliances with user preferences and dynamic pricing in residential area,https://api.elsevier.com/content/abstract/scopus_id/85110609599,"In industrial and commercial sectors, numerous countries had successfully implemented the dynamic pricing as a solution to the problem of high power demand in peak hours. But, an extensive use of real-time pricing in the residential electricity sector is hugely missing. In order to boost the efficiency of electricity market by demand response, real-time pricing needs to be implemented into residential sector also. In this paper the proposed algorithm is implemented for residential consumers of different categories with real time pricing data of ComEd, Northern Illinois Power Company, and Alactra Utilities Corporation. The proposed algorithm incorporates single interval and multi interval programming for different power pricing schemes. The proposed algorithm is suggested using metaheuristic optimization techniques viz. cuckoo search (CS), adaptive cuckoo search (ACS) and Hybrid GA–PSO for the optimum scheduling of residential appliances. The objective of this paper is to minimize the monthly electricity bill cost as well as peak demand under uncertain electricity prices. The comparative analysis of optimal solutions obtained by various artificial intelligence techniques validates the high performance of proposed algorithm. It facilitates both the residential consumer and utilities with benefits.",industry
10.1016/j.measurement.2021.109529,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-09-01,sciencedirect,A deep sequence multi-distribution adversarial model for bearing abnormal condition detection,https://api.elsevier.com/content/abstract/scopus_id/85108012011,"Time series anomaly detection is one of the key challenges in the field of condition monitoring. Many anomaly detection methods are inefficient and easy to lose effective information due to manual features extracting. Deep learning-based methods can solve the problem effectively, but the detection accuracy is still not satisfactory. In addition, most of the methods cannot take the time-ordered specialty into account which is significant for time-series-based anomaly detection. To address these issues, a novel method named deep sequence multi-distribution adversarial model (DSMDA) is proposed to improve the accuracy of anomaly detection in bearing condition monitoring. The proposed model utilizes the data reconstruction capability of the Variational Autoencoder (VAE) under the framework of generative adversarial network (GAN) to make full use of information. The feedforward neural network layer of VAE is replaced by the long-term and short-term memory (LSTM) layer, which uses the forgetting mechanism of LSTM to effectively avoid the false alarms caused by the excessive influence of the old sequences. Additionally, the fault-attention abnormal state index can be constructed by the real-time spatial distribution and latent spatial distribution features learned by the double discriminators. To verify the effectiveness of the proposed approach, experiments on two public datasets are carried out with only healthy data in training stage that is more suitable for practical industrial applications. The results show that the proposed method is superior to GANomaly and other advanced methods. Furthermore, the 2-D visualization results can indicate the level of fault while the last feature space of the two discriminators is combined and embedded into the visualization, and the fault-attention abnormal state indictor constructed on these features can indicate abnormalities well.",industry
10.1016/j.ijcip.2021.100452,Journal,International Journal of Critical Infrastructure Protection,scopus,2021-09-01,sciencedirect,Adversarial attacks and mitigation for anomaly detectors of cyber-physical systems,https://api.elsevier.com/content/abstract/scopus_id/85107972529,"The threats faced by cyber-physical systems (CPSs) in critical infrastructure have motivated research into a multitude of attack detection mechanisms, including anomaly detectors based on neural network models. The effectiveness of anomaly detectors can be assessed by subjecting them to test suites of attacks, but less consideration has been given to adversarial attackers that craft noise specifically designed to deceive them. While successfully applied in domains such as images and audio, adversarial attacks are much harder to implement in CPSs due to the presence of other built-in defence mechanisms such as rule checkers (or invariant checkers). In this work, we present an adversarial attack that simultaneously evades the anomaly detectors and rule checkers of a CPS. Inspired by existing gradient-based approaches, our adversarial attack crafts noise over the sensor and actuator values, then uses a genetic algorithm to optimise the latter, ensuring that the neural network and the rule checking system are both deceived. We implemented our approach for two real-world critical infrastructure testbeds, successfully reducing the classification accuracy of their detectors by over 50% on average, while simultaneously avoiding detection by rule checkers. Finally, we explore whether these attacks can be mitigated by training the detectors on adversarial samples.",industry
10.1016/j.asoc.2021.107574,Journal,Applied Soft Computing,scopus,2021-09-01,sciencedirect,Nonlinear-based Chaotic Harris Hawks Optimizer: Algorithm and Internet of Vehicles application,https://api.elsevier.com/content/abstract/scopus_id/85107718159,"Harris Hawks Optimizer (HHO) is one of the many recent algorithms in the field of metaheuristics. The HHO algorithm mimics the cooperative behavior of Harris Hawks and their foraging behavior in nature called surprise pounce. HHO benefits from a small number of controlling parameters setting, simplicity of implementation, and a high level of exploration and exploitation. To alleviate the drawbacks of this algorithm, a modified version called Nonlinear based Chaotic Harris Hawks Optimization (NCHHO) is proposed in this paper. NCHHO uses chaotic and nonlinear control parameters to improve HHO’s optimization performance. The main goal of using the chaotic maps in the proposed method is to improve the exploratory behavior of HHO. In addition, this paper introduces a nonlinear control parameter to adjust HHO’s exploratory and exploitative behaviors. The proposed NCHHO algorithm shows an improved performance using a variety of chaotic maps that were implemented to identify the most effective one, and tested on several well-known benchmark functions. The paper also considers solving an Internet of Vehicles (IoV) optimization problem that showcases the applicability of NCHHO in solving large-scale, real-world problems. The results demonstrate that the NCHHO algorithm is very competitive, and often superior, compared to the other algorithms. In particular, NCHHO provides 92% better results in average to solve the uni-modal and multi-modal functions with problem dimension sizes of D = 30 and 50, whereas, with respect to the higher dimension problem, our proposed algorithm shows 100% consistent improvement with D = 100 and 1000 compared to other algorithms. In solving the IoV problem, the success rate was 62.5%, which is substantially better in comparison with the state-of-the-art algorithms. To this end, the proposed NCHHO algorithm in this paper demonstrates a promising method to be widely used by different applications, which brings benefits to industries and businesses in solving their optimization problems experienced daily , such as resource allocation, information retrieval, finding the optimal path for sending data over networks, path planning, and so many other applications.",industry
10.1016/j.jnca.2021.103116,Journal,Journal of Network and Computer Applications,scopus,2021-09-01,sciencedirect,Traffic Engineering in Hybrid Software Defined Network via Reinforcement Learning,https://api.elsevier.com/content/abstract/scopus_id/85107660469,"The emergence of Software Defined Network (SDN) provides a centralized and flexible approach to route network flows. Due to the technical and economic challenges in upgrading to a fully SDN-enabled network, hybrid SDN, with a partial deployment of SDN switches in a traditional network, has been a prevailing network architecture. Meanwhile, Traffic Engineering (TE) in the hydbrid SDN has attracted wide attentions from academia and industry. Previous studies on TE in the hybrid SDN are either traffic-oblivious or time-consuming, which causes routing schemes failed in responding to the dynamically-changing traffic rapidly and intelligently. Therefore, in this paper, we propose a Reinforcement Learning (RL) based method, which learns a traffic-splitting agent to address the dynamically-changing traffic and achieve the link load balancing in the hybrid SDN. Specifically, to rapidly and intelligently determine a routing scheme to the new traffic demands, a traffic-splitting agent is designed and learnt offline by exploiting the RL algorithm to establish the direct relationship between traffic demands and traffic-splitting policies. Once the traffic-splitting agent is learnt, the effective traffic-splitting policies, which are used to determine the traffic-splitting ratios on SDN switches, can be generated rapidly. Additionally, to meet the interactive requirements for learning a traffic-splitting agent, a reasonable simulation environment is proposed to be constructed to avoid routing loops when traffic-splitting policies are taken. Extensive evaluations on different topologies and real traffic demands demonstrate that the proposed method achieves the comparable network performance and performs superiorities in rapidly generating the satisfying routing schemes.",industry
10.1016/j.scs.2021.103009,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,Applying machine learning in intelligent sewage treatment: A case study of chemical plant in sustainable cities,https://api.elsevier.com/content/abstract/scopus_id/85106305327,"Nowadays, sewage treatment in sustainable cities attracts more researchers both from academic and industrial communities. Especially, since industrial sewage is normally highly toxic, which could cause serious pollution in a city and lead to health problems of residents, it is critical to monitor and predictably maintain sewage treatment facilities in cities. This paper presents an intelligent sewage treatment system based on machine learning and Internet of Things sensors to assist to manage the sewage treatment in a fine chemical plant. The implemented system has operated for twenty months, acquired multi-dimension data such as temperatures in different treatment processes, operation parameters of devices, and real-time Chemical Oxygen Demand (COD). Since the change trend of outflow COD is highly related to operation status, this paper innovatively uses different types of temperature and water inflow data as model inputs and applies three algorithms to make prediction, which are Support Vector Regression (SVR), Long Short-Term Memory (LSTM) neural network, and Gated Recurrent Unit (GRU) neural network. The experimental results show that GRU model performs better (MAPE = 10.18%, RMSE = 35.67, MAE = 31.16) than LSTM and SVR. This study can be extended to various sewage treatment scenarios in sustainable cities.",industry
10.1016/j.energy.2021.120700,Journal,Energy,scopus,2021-09-01,sciencedirect,Nonlinear generalized predictive controller based on ensemble of NARX models for industrial gas turbine engine,https://api.elsevier.com/content/abstract/scopus_id/85105736036,"New design and operation of modern gas turbine engines (GTEs) are becoming more and more complex where several limitations and control modes should be fulfilled at the same time to accomplish a safe and ideal performance for the engine. For this purpose, a constrained multi-input multi-output (MIMO) non-linear model predictive controller (NMPC) based on neural network model is designed to fulfill the control requirements of a Siemens SGT-A65 three-spool aero-derivative gas turbine engine (ADGTE) used for power generation. However, the implementation of NMPC in real time has two challenges: Firstly, the design of an accurate non-linear model, which can run many times faster than real time. Secondly, the usage of a rapid and reliable optimization algorithm to solve the optimization problem in real time. To solve these issues, the constrained MIMO NMPC is created based on the generalized predictive control (GPC) algorithm as a result of its clarity, ease of use, and capacity to deal with problems in one algorithm. In addition, seven ensembles of eight multi-input single-output (MISO) non-linear autoregressive network with exogenous inputs (NARX) models are used as a base model for the GPC controller to predict the future process outputs. Estimation of free and forced responses of the GPC based on the neural network (NN) model of the plant each sampling time without performing instantaneous linearization is proposed in this study, which reduces the NMPC optimization problem to a linear optimization problem at each sampling step. In addition, the Hildreth's quadratic programming algorithm is used to solve the quadratic optimization problem within the NMPC controller, which offers ease of use and reliability in real time applications. To demonstrate the performance of the NNGPC controller developed in this study, we have compared the performance of the neural network generalized predictive control (NNGPC) controller to the existing controller of the SGT-A65 engine. The simulation results show that the NNGPC has demonstrated output responses with less oscillatory behavior and smoother control actions to the sudden variation in the electric load disturbance than those observed in the existing min-max controller. However, the min-max controller has faster response than that of the NNGPC controller.",industry
10.1016/j.asoc.2021.107465,Journal,Applied Soft Computing,scopus,2021-09-01,sciencedirect,Click-event sound detection in automotive industry using machine/deep learning,https://api.elsevier.com/content/abstract/scopus_id/85105315919,"In the automotive industry, despite the robotic systems on the production lines, factories continue employing workers in several custom tasks getting for semi-automatic assembly operations. Specifically, the assembly of electrical harnesses of engines comprises a set of connections between electrical components. Despite the task is easy to perform, employees tend not to notice that a few components are not being connected properly due to physical fatigue provoked by repetitive tasks. This yields a low quality of the assembly production line and possible hazards. In this work, we propose a sound detection system based on machine/deep learning (ML/DL) approaches to identify click sounds produced when electrical harnesses are connected. The purpose of this system is to count the number of connections properly made and to feedback to the employees. We collect and release a public dataset of 25,000 click sounds of 25 ms length at 22 kHz during three months of assembly operations in an automotive production line located in Mexico. Then, we design an ML/DL-based methodology for click sound detection of assembled harnesses under real conditions of a noisy environment (noise level ranging from 
                        
                           −
                           16
                           .
                           67
                        
                      dB to 
                        
                           −
                           12
                           .
                           87
                        
                      dB) including other machinery sounds. Our best ML/DL model (i.e., a combination between five acoustic features and an optimized convolutional neural network) is able to detect click sounds in a real assembly production line with an accuracy of 
                        
                           94
                           .
                           55
                           ±
                           0
                           .
                           83
                        
                      %. To the best of our knowledge, this is the first time a click sounds detection system in assembling electrical harnesses of engines for giving feedback to the workers is proposed and implemented in a real-world automotive production line. We consider this work valuable for the automotive industry on how to apply ML/DL approaches for improving the quality of semi-automatic assembly operations.",industry
10.1016/j.eswa.2021.114892,Journal,Expert Systems with Applications,scopus,2021-09-01,sciencedirect,Capturing dynamics of post-earnings-announcement drift using a genetic algorithm-optimized XGBoost,https://api.elsevier.com/content/abstract/scopus_id/85103780721,"Post-Earnings-Announcement Drift (PEAD) is a stock market phenomenon when a stock’s cumulative abnormal return has a tendency to drift in the direction of an earnings surprise in the near term following an earnings announcement. Although it is one of the most studied stock market anomalies, the current literature is often limited in explaining this phenomenon by a small number of factors using simpler regression methods. In this paper, we use a machine learning based approach instead, and aim to capture the PEAD dynamics using data from a large group of stocks and a wide range of both fundamental and technical factors. Our model is built around the Extreme Gradient Boosting (XGBoost) and uses a long list of engineered input features based on quarterly financial announcement data from 1,106 companies in the Russell 1000 index between 1997 and 2018. We perform numerous experiments on PEAD predictions and analysis and have the following contributions to the literature. First, we show how Post-Earnings-Announcement Drift can be analysed using machine learning methods and demonstrate such methods’ prowess in credibly forecasting the drift direction. It is the first time PEAD dynamics are studied using XGBoost. We show that the drift direction is driven by different factors for stocks from different industrial sectors and in different quarters and XGBoost is effective in understanding the changing dynamics. Second, we show that an XGBoost well optimised by a Genetic Algorithm can help allocate out-of-sample stocks to form portfolios with higher positive returns to long and portfolios with lower negative returns to short, a finding that could be adopted in the process of developing market neutral strategies. Third, we show how theoretical event-driven stock strategies have to grapple with ever-changing market prices in reality, reducing their effectiveness. We present a tactic to remedy the difficulty of buying into a moving market when trading on PEAD signals.",industry
10.1016/j.simpa.2021.100081,Journal,Software Impacts,scopus,2021-08-01,sciencedirect,OpenICS: Open image compressive sensing toolbox and benchmark[Formula presented],https://api.elsevier.com/content/abstract/scopus_id/85115856142,"The real-world application of image compressive sensing is largely limited by the lack of standardization in implementation and evaluation. To address this limitation, we present OpenICS, an image compressive sensing toolbox that implements multiple popular image compressive sensing algorithms into a unified framework with a standardized user interface. Furthermore, a corresponding benchmark is also proposed to provide a fair and complete evaluation of the implemented algorithms. We hope this work can serve the growing research community of compressive sensing and the industry to facilitate the development and application of image compressive sensing.",industry
10.1016/j.bspc.2021.102792,Journal,Biomedical Signal Processing and Control,scopus,2021-08-01,sciencedirect,Recognizing drowsiness in young men during real driving based on electroencephalography using an end-to-end deep learning approach,https://api.elsevier.com/content/abstract/scopus_id/85109099510,"It is widely agreed that driving while drowsy is a severe threat to road safety. Therefore, in this work, we present a novel approach that does not require manual selection of feature sets and then delivers them to the classifier, using deep learning theory and convolutional neural network (ConvNets) to automatically detect driver drowsiness based on multi-channel EEG signals during real driving. The proposed 12-layer deep ConvNets model automatically learns and extracts the most prominent features from the raw EEG data through 5 convolutional layers, 3 max pooling layers and 1 mean pooling layer and optimizes the classification results through 3 fully connected layers at the same time, which is an end-to-end manner. To overcome the lack of a large amount of EEG data, a data augmentation strategy is proposed. The proposed deep ConvNets model is trained on 4 s segments of EEG data from different participants and tested using a 10-fold cross validation. It gave an accuracy, precision, sensitivity, specificity, and mean f-measure of 97.02 % ± 0.0177, 96.74 % ± 0.0347, 97.76 % ± 0.0168, 96.22 % ± 0.0426, and 97.19 % ± 0.0157, respectively on the testing data set and outperforms the state-of-the-art systems, which proved the good generalization performance of the deep model. Considering that the proposed model can learn features from the data without using specialized feature extraction and classification methods, ConvNets may be considered as an alternative for similar detections based on EEG signals such as operators fatigue in navigation, construction industry, etc.",industry
10.1016/j.engappai.2021.104296,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-08-01,sciencedirect,Adaptable automation with modular deep reinforcement learning and policy transfer,https://api.elsevier.com/content/abstract/scopus_id/85107671197,"Future industrial automation systems are anticipated to be shaped by intelligent technologies that allow for the adaptability of machines to the variations and uncertainties in processes and work environments. This paper is motivated by the need for devising new intelligent methods that enable efficient and scalable training of collaborative robots on a variety of tasks that foster their adaptability to new tasks and environments. Recent advances in deep Reinforcement Learning (RL) provide new possibilities to realize this vision. The state-of-the-art in deep RL offers proven algorithms that enable autonomous learning and mastery of a variety of robotic manipulation tasks with minimal human intervention. However, current deep RL algorithms predominantly specialize in a narrow range of tasks, are sample inefficient, and lack sufficient stability, which hinders their adoption in real-life, industrial settings. This paper develops and tests a Hyper-Actor Soft Actor–Critic (HASAC) deep RL framework based on the notions of task modularization and transfer learning to tackle this limitation. The goal of the proposed HASAC is to enhance an agent’s adaptability to new tasks by transferring the learned policies of former tasks to the new task through a ”hyper-actor”. The HASAC framework is tested on the virtual robotic manipulation benchmark, Meta-World. Numerical experiments indicate superior performance by HASAC over state-of-the-art deep RL algorithms in terms of reward value, success rate, and task completion time.",industry
10.1016/j.measurement.2021.109565,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-08-01,sciencedirect,Intelligent fault diagnosis of planetary gearbox based on adaptive normalized CNN under complex variable working conditions and data imbalance,https://api.elsevier.com/content/abstract/scopus_id/85107298743,"In real industrial application, the operating conditions of the planetary gearbox are always variable speed and variable load according to production. Meanwhile, the scarcity of fault data and different working conditions lead to serious data imbalance and distribution differences, which make a great challenge for planetary gearbox fault detection and diagnosis. To address these issues, a novel adaptive normalized convolutional neural network (ANCNN) is developed to accurately and automatically diagnose the different fault locations and severities of planetary gearbox considering the scenarios of complex variable working conditions and data imbalance. First, Teager calculated order (TCO) spectrum is applied to avoid the influences of large speed fluctuations and variable loads, which is an efficient pretreatment approach for the proposed ANCNN. Then, the batch normalization algorithm is adopted to eliminate the feature distribution differences caused by variable operating modes and data imbalance. Finally, in order to automatically adapt to different planetary gearbox diagnosis circumstances, the particle swarm optimization (PSO) strategy is used for optimizing and flexibly deciding the key hyperparameters of the designed model, thereby improving the overall performance of the model. The effectiveness of the presented method is confirmed through experiments on two different planetary gearbox datasets, which are from a generic planetary gearbox for industrial applications and a drivetrain dynamic simulator test rig. In addition, comparison with other mainstream intelligent diagnosis techniques validates the superiority of the presented method. The experimental results demonstrate that the presented method can achieve diagnostic accuracies of better than 99.8%, and also shows excellent stability for the unbalanced data classification.",industry
10.1016/j.cag.2021.04.035,Journal,Computers and Graphics (Pergamon),scopus,2021-08-01,sciencedirect,DIMNet: Dense implicit function network for 3D human body reconstruction,https://api.elsevier.com/content/abstract/scopus_id/85105858338,"In recent years, with the improvement of artificial intelligence technology, it has become possible to reconstruct high-precision 3D human body models based on ordinary RGB images. The current 3D human body reconstruction technology requires complex external equipment to scan all angles of the human body, which is complicated to be implemented and cannot be popularized. In order to solve this problem, this paper applies deep learning models on reconstructing 3D human body based on monocular images. First of all, this paper uses Stacked Hourglass network to perform convolution operations on monocular images collected from different views. Then Multi-Layer Perceptrons (MLPs) are used to decode the encoded high-level images. The feature codes in the two views(main and side) are fused, and the interior and exterior points are classified by the fusion features, so as to obtain the corresponding 3D occupancy field. At last, the Marching Cube algorithm is used for 3D reconstruction with a specific threshold and then we use Laplace smoothing algorithm to remove artifacts. This paper proposes a dense sampling strategy based on the important joint points of the human body, which has a certain optimization effect on the realization of high-precision 3D reconstruction. The performance of the proposed scheme has been validated on the open source datasets, MGN dataset and the THuman dataset, provided by Tsinghua University. The proposed scheme can reconstruct features such as clothing folds, color textures, and facial details,and has great potential to be applied in different applications.",industry
10.1016/j.neunet.2021.03.016,Journal,Neural Networks,scopus,2021-08-01,sciencedirect,Bidirectional stochastic configuration network for regression problems,https://api.elsevier.com/content/abstract/scopus_id/85103381001,"To adapt to the reality of limited computing resources of various terminal devices in industrial applications, a randomized neural network called stochastic configuration network (SCN), which can conduct effective training without GPU, was proposed. SCN uses a supervisory random mechanism to assign its input weights and hidden biases, which makes it more stable than other randomized algorithms but also leads to time-consuming model training. To alleviate this problem, we propose a novel bidirectional SCN algorithm (BSCN) in this paper, which divides the way of adding hidden nodes into two modes: forward learning and backward learning. In the forward learning mode, BSCN still uses the supervisory mechanism to configure the parameters of the newly added nodes, which is the same as SCN. In the backward learning mode, BSCN calculates the parameters at one time based on the residual error feedback of the current model. The two learning modes are performed iteratively until the prediction error of the model reaches an acceptable level or the number of hidden nodes reaches its maximum value. This semi-random learning mechanism greatly speeds up the training efficiency of the BSCN model and significantly improves the quality of the hidden nodes. Extensive experiments on ten benchmark regression problems, two real-life air pollution prediction problems, and a classical image processing problem show that BSCN can achieve faster training speed, higher stability, and better generalization ability than SCN.",industry
10.1016/j.eswa.2021.114820,Journal,Expert Systems with Applications,scopus,2021-08-01,sciencedirect,Machine Learning for industrial applications: A comprehensive literature review,https://api.elsevier.com/content/abstract/scopus_id/85102967505,"Machine Learning (ML) is a branch of artificial intelligence that studies algorithms able to learn autonomously, directly from the input data. Over the last decade, ML techniques have made a huge leap forward, as demonstrated by Deep Learning (DL) algorithms implemented by autonomous driving cars, or by electronic strategy games. Hence, researchers have started to consider ML also for applications within the industrial field, and many works indicate ML as one the main enablers to evolve a traditional manufacturing system up to the Industry 4.0 level. Nonetheless, industrial applications are still few and limited to a small cluster of international companies. This paper deals with these topics, intending to clarify the real potentialities, as well as potential flaws, of ML algorithms applied to operation management. A comprehensive review is presented and organized in a way that should facilitate the orientation of practitioners in this field. To this aim, papers from 2000 to date are categorized in terms of the applied algorithm and application domain, and a keyword analysis is also performed, to details the most promising topics in the field. What emerges is a consistent upward trend in the number of publications, with a spike of interest for unsupervised and especially deep learning techniques, which recorded a very high number of publications in the last five years. Concerning trends, along with consolidated research areas, recent topics that are growing in popularity were also discovered. Among these, the main ones are production planning and control and defect analysis, thus suggesting that in the years to come ML will become pervasive in many fields of operation management.",industry
10.1016/j.eswa.2021.114753,Journal,Expert Systems with Applications,scopus,2021-08-01,sciencedirect,A league-winner algorithm for defect classification in an industrial web inspection system,https://api.elsevier.com/content/abstract/scopus_id/85102641846,"This paper presents a modification to be added to multiclass classifiers, that improves their performance when classifying, in this case, defects appearing in polyethylene films. It aims to classify a new defect by confronting every defect type against each of the other types. In a simplified way, the type that results winner in more matches is the type that the defect belongs to. Different ways of implementing neural networks have been tested, using Gradient Descent and techniques for backpropagation. These techniques have been formally and understandably explained. In addition, a method based on decision trees has been included for comparison. Different issues related to the practical implementation of the detection and identification system within an installed production chain are addressed. The resulting system has been incorporated as a real inspection automatism in a polyethylene manufacturing line, and trained with defects previously obtained from the same line.",industry
10.1016/j.neunet.2021.02.016,Journal,Neural Networks,scopus,2021-08-01,sciencedirect,TigeCMN: On exploration of temporal interaction graph embedding via Coupled Memory Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85102629495,"With the increasing demand of mining rich knowledge in graph structured data, graph embedding has become one of the most popular research topics in both academic and industrial communities due to its powerful capability in learning effective representations. The majority of existing work overwhelmingly learn node embeddings in the context of static, plain or attributed, homogeneous graphs. However, many real-world applications frequently involve bipartite graphs with temporal and attributed interaction edges, named temporal interaction graphs. The temporal interactions usually imply different facets of interest and might even evolve over the time, thus putting forward huge challenges in learning effective node representations. Furthermore, most existing graph embedding models try to embed all the information of each node into a single vector representation, which is insufficient to characterize the node’s multifaceted properties. In this paper, we propose a novel framework named TigeCMN to learn node representations from a sequence of temporal interactions. Specifically, we devise two coupled memory networks to store and update node embeddings in the external matrices explicitly and dynamically, which forms deep matrix representations and thus could enhance the expressiveness of the node embeddings. Then, we generate node embedding from two parts: a static embedding that encodes its stationary properties and a dynamic embedding induced from memory matrix that models its temporal interaction patterns. We conduct extensive experiments on various real-world datasets covering the tasks of node classification, recommendation and visualization. The experimental results empirically demonstrate that TigeCMN can achieve significant gains compared with recent state-of-the-art baselines.",industry
10.1016/j.ymssp.2021.107708,Journal,Mechanical Systems and Signal Processing,scopus,2021-08-01,sciencedirect,A novel method for predicting delamination of carbon fiber reinforced plastic (CFRP) based on multi-sensor data,https://api.elsevier.com/content/abstract/scopus_id/85101346868,"Carbon fiber reinforced plastic (CFRP) has been widely used in many fields such as in the aerospace and automotive industries. Drilling of CFRP is a key process in the manufacture of CFRP components. The existing quality control and tool change decision methods are mainly based on delamination damage. However, estimating delamination damage in situ is still a challenge in the process of continuous drilling. To solve this problem, a comprehensive delamination prediction method based on multi-sensor data is proposed in this paper. In process of the drilling, the force, torque, temperature, vibration and hole exit images were collected, and the delamination was quantified by a proposed statistical delamination factor 
                        
                           
                              F
                              s
                           
                        
                     . Singular spectrum analysis (SSA) is used to smooth the 
                        
                           
                              F
                              s
                           
                        
                      sequence to reduce randomness. Then, a XGBoost-ARIMA model is constructed for rolling prediction of 
                        
                           
                              F
                              s
                           
                        
                     . Finally, drilling experiments were carried out to verify the effectiveness of the proposed method. The experimental results showed that compared with traditional delamination evaluation factors, 
                        
                           
                              F
                              s
                           
                        
                      reduced the mean square error (MSE) of prediction by more than 50%. Compared with that of traditional machine learning models such as an SVM and ANN, the MSE of the model’s regression part is decreased by more than 39%. The proposed method can provide a solution for real-time and in situ prediction of delamination damage in the continuous drilling process of CFRP components.",industry
10.1016/j.jclepro.2021.127385,Journal,Journal of Cleaner Production,scopus,2021-07-25,sciencedirect,Improving degradation of real wastewaters with self-heating magnetic nanocatalysts,https://api.elsevier.com/content/abstract/scopus_id/85105709482,"Industrial effluents contain a wide range of organic pollutants that present harmful effects on the environment and deprived communities with no access to clean water. As this organic matter is resistant to conventional treatments, Advanced Oxidation Processes (AOPs) have emerged as a suitable option to counteract these environmental challenges. Engineered iron oxide nanoparticles have been widely tested in AOPs catalysis, but their full potential as magnetic induction self-heating catalysts has not been studied yet on real and highly contaminated industrial wastewaters. In this study we have designed a self-heating catalyst with a finely tuned structure of small cores (10 nm) aggregates to develop multicore particles (40 nm) with high magnetic moment and high colloidal stability. This nanocatalyst, that can be separated by magnetic harvesting, is able to increase reaction temperatures (up to 90 °C at 1 mg/mL suspension in 5 min) under the action of alternating magnetic fields. This efficient heating was tested in the degradation of a model compound (methyl orange) and real wastewaters, such as leachate from a solid landfill (LIX) and colored wastewater from a textile industry (TIW). It was possible to increase reaction rates leading to a reduction of the chemical oxygen demand of 50 and 90%, for TIW and LIX. These high removal and degradation ability of the magnetic nanocatalyst was sustained with the formation of strong reactive oxygen species by a Fenton-like mechanism as proved by electron paramagnetic resonance. These findings represent an important advance for the industrial implementation of a scalable, non-toxic, self-heating catalysts that can certainly enhance AOP for wastewater treatment in a more sustainable and efficient way.",industry
10.1016/j.wear.2021.203622,Journal,Wear,scopus,2021-07-15,sciencedirect,Acoustic emission and machine learning based classification of wear generated using a pin-on-disc tribometer equipped with a digital holographic microscope,https://api.elsevier.com/content/abstract/scopus_id/85103025626,"The efficiency of processes involving frictional contacts between surfaces is often characterized by wear rates or friction coefficients. However, the classification and forecasting of wear rates in friction related processes is a real industrial challenge that is unsolved today. Hence, an on-line monitoring system able to classify wear rate can be crucial for many industries as it could help in preventing catastrophic failures. Applications include lifetime assessment of various industrial components where a range of wear failures occur such as scuffing (a typical sudden failure mechanism). These tribological processes can now be sensorized, and the corresponding sensor signatures can be modelled and monitored using state-of-the-art Machine learning (ML) algorithms. In this study, we use an Acoustic Emission (AE) sensor and ML frameworks to classify different wear categories simulated with a customized pin-on-disc tribometer. A real-time investigation of the wear track is necessary to find out the origins of the wear scar visible at the surface. To achieve this objective, the experiments were conducted on a pin-on-disc tribometer equipped with a Digital Holographic Microscope (DHM). Experiments were carried out using alumina and steel balls against steel discs at room temperature. Real-time DHM images of the wear track surface were recorded for each lap at the same position. An acoustic emission sensor recorded the AE signals during the complete duration of experiments. The AE signatures, in combination with the real-time DHM images, were correlated as input and ground truth labels for the ML algorithm. Several ML frameworks were compared; they are support vector machine, logistic regression, XGBoost, random forest, neural networks, k-Nearest Neighbor, quadratic discriminant analysis and Naive Bayes. The classifier was trained to differentiate the acoustic emission features of the different wear rates. Most ML algorithms had an average classification accuracy above 80%, and the highest was obtained with support vector machine (84.7%). The classification accuracy can be improved by combining two neighboring categories with limited differences in terms of wear rate. Hence, the proposed method has a significant industrial potential for in-situ and real-time quality monitoring of wear processes since it requires minimum modifications of commercially available industrial machines.",industry
10.1016/j.procs.2021.06.013,Conference Proceeding,Procedia Computer Science,scopus,2021-07-01,sciencedirect,Mathematical model of chemical process prediction for industrial safety risk assessment,https://api.elsevier.com/content/abstract/scopus_id/85112600838,The article presents a mathematical model of the functioning of the technological process of styrene production using neural network technologies. The use of a direct propagation neural network with a single hidden layer trained on an experimental sample is considered. An algorithm for forming a neural network is proposed. The model is implemented as a software module. The results of predicting the process of chemical production of styrene based on real data and recommendations for using the developed model in the process of assessing the industrial safety of particularly dangerous production processes are presented.,industry
10.1016/j.jmsy.2021.07.001,Journal,Journal of Manufacturing Systems,scopus,2021-07-01,sciencedirect,Rule-based explanations based on ensemble machine learning for detecting sink mark defects in the injection moulding process,https://api.elsevier.com/content/abstract/scopus_id/85109431807,"Manufacturing quality control (QC) in plastic injection moulding is of the upmost importance since almost one third of plastic products are manufactured via the injection moulding process. Moreover, smart manufacturing technologies are enabling the generation of huge amounts of data in production lines. This data can be used for predicting the quality of manufactured plastic products using machine learning methods, allowing companies to save costs and improve their production efficiency. However, high-performance machine learning models are usually too complicated to be understood by human intuition. Therefore, we have introduced a rule-based explanations (RBE) framework that combines several machine learning interpretation methods to help to understand the decision mechanisms of accurate and complex predictive models – specifically tree ensemble models. These generated rules can be used to visually and easily understand the main factors that affect the quality in the manufacturing process. To demonstrate the applicability of RBE, we present two experiments with real industrial data gathered from a plastic injection moulding machine in a Singapore model factory. The collected datasets contain condition data for several manufacturing processes as well as the QC results for sink mark defects in the production of small plastic products. The experiments revealed that it is possible to extract meaningful explanations in the form of simple decision rules that are enhanced with partial dependence plots and feature importance rankings for a better understanding of the underlying mechanisms and data relationships of accurate tree ensembles.",industry
10.1016/j.jmsy.2021.04.005,Journal,Journal of Manufacturing Systems,scopus,2021-07-01,sciencedirect,LearningADD: Machine learning based acoustic defect detection in factory automation,https://api.elsevier.com/content/abstract/scopus_id/85106283308,"Defect inspection of glass bottles in the beverage industrial is of significance to prevent unexpected losses caused by the damage of bottles during manufacturing and transporting. The commonly used manual methods suffer from inefficiency, excessive space consumption, and beverage wastes after filling. To replace the manual operations in the pre-filling detection with improved efficiency and reduced costs, this paper proposes a machine learning based Acoustic Defect Detection (LearningADD) system. Moreover, to realize scalable deployment on edge and cloud computing platforms, deployment strategies especially partitioning and allocation of functionalities need to be compared and optimized under realistic constraints such as latency, complexity, and capacity of the platforms. In particular, to distinguish the defects in glass bottles efficiently, the improved Hilbert-Huang transform (HHT) is employed to extend the extracted feature sets, and then Shuffled Frog Leaping Algorithm (SFLA) based feature selection is applied to optimize the feature sets. Five deployment strategies are quantitatively compared to optimize real-time performances based on the constraints measured from a real edge and cloud environment. The LearningADD algorithms are validated by the datasets from a real-life beverage factory, and the F-measure of the system reaches 98.48 %. The proposed deployment strategies are verified by experiments on private cloud platforms, which shows that the Distributed Heavy Edge deployment outperforms other strategies, benefited from the parallel computing and edge computing, where the Defect Detection Time for one bottle is less than 2.061 s in 99 % probability.",industry
10.1016/j.tifs.2021.04.042,Journal,Trends in Food Science and Technology,scopus,2021-07-01,sciencedirect,Efficient extraction of deep image features using convolutional neural network (CNN) for applications in detecting and analysing complex food matrices,https://api.elsevier.com/content/abstract/scopus_id/85105814254,"Background
                  The development of techniques and methods for rapidly and reliably detecting and analysing food quality and safety products is of significance for the food industry. Traditional machine learning algorithms based on handcrafted features normally have poor performance due to their limited representation capacity for complex food characteristics. Recently, the convolutional neural network (CNN) emerges as an effective and potential tool for feature extraction, which is considered the most popular architecture of deep learning and has been increasingly applied for the detection and analysis of complex food matrices.
               
                  Scope and approach
                  In the current review, the structure of CNN, the method of feature extraction based on 1-D, 2-D and 3-D CNN models, and multi-feature aggregation methods are introduced. Applications of CNN as a depth feature extractor for detecting and analyzing complex food matrices are discussed, including meat and aquatic products, cereals and cereal products, fruits and vegetables, and others. In addition, data sources, model architecture and overall performance of CNN with other existing methods are compared, and trends of future studies on applying CNN for food detection and analysis are also highlighted.
               
                  Key findings and conclusions
                  CNN combined with nondestructive detection techniques and computer vision system show great potential for effectively and efficiently detecting and analysing complex food matrices, and the features based on CNN show better performance and outperform the features handcrafted or those extracted by machine learning algorithms. Although there still remains some challenges in using CNN, it is expected that CNN models will be deployed on mobile devices for real-time detection and analysis of food matrices in future.",industry
10.1016/j.ipm.2021.102555,Journal,Information Processing and Management,scopus,2021-07-01,sciencedirect,"A machine learning, bias-free approach for predicting business success using Crunchbase data",https://api.elsevier.com/content/abstract/scopus_id/85102076553,"Predicting the success of a business venture has always been a struggle for both practitioners and researchers. However, thanks to companies that aggregate data about other firms, it has become possible to create and validate predictive models based on an unprecedented amount of real-world examples. In this study, we use data obtained from one of the largest platforms integrating business information – Crunchbase. Our final training set consisted of 213 171 companies.
                  This work aims to create a predictive model based on machine learning for the purpose of forecasting a company’s success. Many similar attempts have been made in recent years. Plenty of those experiments, often conducted with the use of data gathered from several different sources, reported promising results. However, we found that very often they were significantly biased by their use of data containing information that was a direct consequence of a company reaching some level of success (or failure). Such an approach is a classic example of the look-ahead bias. It leads to very optimistic test results, but any attempt at using such an approach in a real-world scenario may result in dramatic consequences. We designed our experiments in a way that would prevent the leaking of any information unavailable at the decision moment to the training set.
                  We compared three algorithms – logistic regression, support vector machine, and the gradient boosting classifier. Despite the conscious decision to limit the number of predictors, we reached very promising results in terms of precision, recall, and F1 scores which, for the best model, were 57%, 34%, and 43% respectively. The best outcomes were obtained with the gradient boosting classifier. We give detailed information about the importance of different features, with the top three being country and region that the company operates in and the company’s industry. Our model can be applied directly as a decision support system for different types of venture capital funds.",industry
10.1016/j.ins.2021.01.013,Journal,Information Sciences,scopus,2021-07-01,sciencedirect,Attributed community search based on effective scoring function and elastic greedy method,https://api.elsevier.com/content/abstract/scopus_id/85101624086,"In recent years, with the proliferation of rich attribute information available for entities in real-world networks and the increasing demand for more personalized community searches, attributed community search (ACS), an upgraded version of the community search problem, has attracted great attention from the both academic and industry areas. Some algorithms have been proposed to solve this novel research problem. However, they have a deficiency in evaluating the quality of the attributed community structure, which may mislead them and discover less valuable structures. In this paper, we make up for this defect, and propose the SFEG algorithm to better solve the ACS problem. SFEG designs a more effective scoring function to measure the quality of the discovered attributed community structure, and presents an elastic greedy optimization method to quickly maximize the function value to determine the target community with a specific meaning. The extensive experiments conducted on the attributed graph datasets with ground-truth communities show that our algorithm significantly outperforms the state-of-the-art.",industry
10.1016/j.ress.2021.107556,Journal,Reliability Engineering and System Safety,scopus,2021-07-01,sciencedirect,Transfer learning using deep representation regularization in remaining useful life prediction across operating conditions,https://api.elsevier.com/content/abstract/scopus_id/85101575211,"Intelligent data-driven system prognostic methods have been popularly developed in the recent years. Despite the promising results, most approaches assume the training and testing data are from the same operating condition. In the real industries, it is quite common that different machine entities work under different scenarios, that results in performance deteriorations of the data-driven prognostic methods. This paper proposes a transfer learning method for remaining useful life predictions using deep representation regularization. The practical and challenging scenario is investigated, where the training and testing data are from different machinery operating conditions, and no target-domain run-to-failure data is available for training. In the deep learning framework, data alignment schemes are proposed in the representation sub-space, including healthy state alignment, degradation direction alignment, degradation level regularization and degradation fusion. In this way, the life-cycle data of different machine entities across domains can follow the same degradation trace, thus achieving prognostic knowledge transfer. Extensive experiments on the aero-engine dataset validate the effectiveness of the proposed method, which offers a promising solution for industrial prognostics.",industry
10.1016/j.ymssp.2020.107510,Journal,Mechanical Systems and Signal Processing,scopus,2021-06-16,sciencedirect,Metric-based meta-learning model for few-shot fault diagnosis under multiple limited data conditions,https://api.elsevier.com/content/abstract/scopus_id/85100211264,"The real-world large industry has gradually become a data-rich environment with the development of information and sensor technology, making the technology of data-driven fault diagnosis acquire a thriving development and application. The success of these advanced methods depends on the assumption that enough labeled samples for each fault type are available. However, in some practical situations, it is extremely difficult to collect enough data, e.g., when the sudden catastrophic failure happens, only a few samples can be acquired before the system shuts down. This phenomenon leads to the few-shot fault diagnosis aiming at distinguishing the failure attribution accurately under very limited data conditions. In this paper, we propose a new approach, called Feature Space Metric-based Meta-learning Model (FSM3), to overcome the challenge of the few-shot fault diagnosis under multiple limited data conditions. Our method is a mixture of general supervised learning and episodic metric meta-learning, which will exploit both the attribute information from individual samples and the similarity information from sample groups. The experiment results demonstrate that our method outperforms a series of baseline methods on the 1-shot and 5-shot learning tasks of bearing and gearbox fault diagnosis across various limited data conditions. The time complexity and implementation difficulty have been analyzed to show that our method has relatively high feasibility. The feature embedding is visualized by t-SNE to investigate the effectiveness of our proposed model.",industry
10.1016/j.chemolab.2021.104314,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2021-06-15,sciencedirect,A scalable approach for the efficient segmentation of hyperspectral images,https://api.elsevier.com/content/abstract/scopus_id/85105360467,"The number of applications of hyperspectral imaging (HSI) is steadily increasing, as technology evolves and cameras become more affordable. However, the volume of data in a hyperspectral image is large (order of Gigabytes) and standard off-the-shelf algorithms for multi-channel image analysis cannot be readily applied, due to the prohibitive computational time and large memory requirements. Therefore, new scalable approaches are required to perform hyperspectral image analysis. In this article we address an efficient methodology for conducting Unsupervised Image Segmentation – one of the basic and most fundamental image analysis operations. In the methodology proposed, unsupervised segmentation is conducted after transforming the spectral and spatial dimensions of the raw hyperspectral image into a more compact representation using multivariate and multiresolution techniques. The clusters identified in the compact image representation are then used to train a discriminative classifier. The classifier is then adapted and transferred for application to the raw image, where it will efficiently label all the original pixels. With the proposed methodology, the computational expensive operations (unsupervised clustering and classifier learning) are minimized, whereas the efficient implementation of the classifier guarantees the analysis at the native resolution. The effectiveness of the proposed methodology was tested on a real case study considering an industrial hyperspectral image capturing the reflectance spectrum for several objects made of different unknown materials. A significant reduction in the computational cost was achieved without compromising the quality of the unsupervised segmentation, demonstrating the potential of the proposed approach.",industry
10.1016/j.neucom.2021.01.099,Journal,Neurocomputing,scopus,2021-06-07,sciencedirect,Meta-learning for few-shot bearing fault diagnosis under complex working conditions,https://api.elsevier.com/content/abstract/scopus_id/85102132168,"Deep learning-based bearing fault diagnosis has been systematically studied in recent years. However, the success of most of these methods relies heavily on massive labeled data, which is not always available in real production environments. Training a robust bearing fault diagnosis model with limited data and working well under complex working conditions remains a challenge. In this paper, a novel meta-learning fault diagnosis method (MLFD) based on model-agnostic meta-learning is proposed to address this issue. The raw signals of different working conditions are first converted to time–frequency images and then randomly sampled to form tasks for MLFD according to the protocol of meta-learning. The MLFD model acquires prior knowledge by optimizing initialization parameters based on multiple fault classification tasks of known working conditions during the meta-training process, and achieves fast and accurate few-shot bearing fault diagnosis under unseen working conditions by leveraging the learned knowledge. To comprehensively evaluate the performance of our method, a series of experiments were conducted to simulate different industrial scenarios based on the Case Western Reserve University Bearing Fault Benchmark, and the results demonstrate the superiority of MLFD in solving the few-shot fault classification problem under complex working conditions.",industry
10.1016/j.addma.2021.101961,Journal,Additive Manufacturing,scopus,2021-06-01,sciencedirect,Deep representation learning for process variation management in laser powder bed fusion,https://api.elsevier.com/content/abstract/scopus_id/85105695571,"Laser Powder Bed Fusion (LPBF) is an additive manufacturing process where laser power is applied to fuse the spread powder and fabricate industrial parts in a layer by layer fashion. Despite its great promise in fabrication flexibility, print quality has long been a major barrier for its widespread implementation. Traditional offline post-manufacturing inspections to detect the defects in finished products are expensive and time-consuming and thus cannot be applied in real-time monitoring and control. In-situ monitoring methods by relying on the in-process sensor data, on the other hand, can provide viable alternatives to aid with the online detection of anomalies during the process. Given the crucial importance of melt pool characteristics to the quality of final products, this paper provides a framework to process the melt pool images by a configuration of Convolutional Auto-Encoder (CAE) neural networks. The network’s corresponding bottleneck layer learns a deep yet low-dimensional representation from melt pools while preserving the spatial correlation and complex features intrinsic in the images. As opposed to the manual annotation of data by X-ray imaging or destructive tests, an agglomerative clustering algorithm is applied to these representations to automatically extract the anomalies and annotate the data accordingly. A control charting scheme based on Hotelling’s T
                     2 and S
                     2 statistics is then developed to monitor the process’s stability by keeping track of the learned representations and residuals obtained from the reconstruction of original images. Testing the proposed methodology on the collected data from an experimental build demonstrates that the method can extract a set of complex features that are inextricable otherwise by using hand-crafted feature engineering methods. Moreover, through extensive numerical studies, it is shown that the proposed feature extraction and statistical process monitoring scheme is capable of detecting the anomalies in real-time with accuracy and F
                     1 score of about 95% and 82%, respectively.",industry
10.1016/j.addma.2021.101986,Journal,Additive Manufacturing,scopus,2021-06-01,sciencedirect,Using feedback control of thermal history to improve quality consistency of parts fabricated via large-scale powder bed fusion,https://api.elsevier.com/content/abstract/scopus_id/85105692336,"Process inconsistency in additive manufacturing (AM) leads to irregular quality of the final parts and obstructs its broader adoption in critical structural parts manufacturing. Especially in the manufacture of sizable components, detecting process changes in a real-time and accurate manner for potential corrective operations is crucial. This study aims to develop a feedback control system to reduce inconsistent part quality caused by heat accumulation differences. There are two significant challenges. 1) Thermal images suffer from a low signal-to-noise ratio. 2) Discrete local sintering information should be able to indicate the adjustments to the global temperature field. To tackle these challenges, a feedback model based on a multi-input neural network is proposed to evaluate the sintering status accurately by integrating the thermal history and process features. Subsequently, a layerwise feedback control strategy is proposed to process the discrete sintering status into the variation trend of part quality and ensure that the material has the desired thermal history during sintering. A controlled experiment is used to demonstrate the effectiveness of the proposed approach compared with its traditional counterparts, and the result illustrates the elimination of differences in heat accumulation by the proposed method.",industry
10.1016/j.jprocont.2021.04.001,Journal,Journal of Process Control,scopus,2021-06-01,sciencedirect,ANN model adaptation algorithm based on extended Kalman filter applied to pH control using MPC,https://api.elsevier.com/content/abstract/scopus_id/85104132351,"The performance of model predictive controllers (MPCs) strongly depends on the precision of the prediction model. Nonlinear systems, such as neutralization reactors, provide special challenges to MPC design. Linear prediction models may be inadequate to describe the process at all operating points. One alternative is the use of artificial neural networks (ANNs) as prediction models. ANNs are nonlinear structures that can be trained to reproduce the process behavior. Inside MPC schemes, ANNs can rapidly predict the process response to a control action. The time-consuming step for ANN training is to obtain a representative overall data set from experiments or simulation data from the studied process. In the present work, we propose to obtain this data set from computational simulations using a first principles model. However, mismatches were found between rigorous simulation and actual pH process responses. Those deviations were naturally transferred to the internal neural model, as a consequence, actual control problems were identified. Avoiding high costs of performing actual experimental runs for ANN and MPC design, we used a real-time adaptation algorithm, based on extended Kalman filter (EKF), that acts to correct the ANN prediction while process is running. The adaptive model ANN-based MPC was able to maintain the actual controlled process, in all operating conditions tested. The sum of square error of pH was reduced in 64.3%, compared to the ANN-based MPC without model adaptation. Using a Kalman filter to adapt the internal model has significantly improved the MPC performance, reducing oscillations and maintaining the controlled variable in the setpoint, even in servo regulatory situations of industrial practice. In addition, the proposed scheme has great potential for controlling highly nonlinear processes.",industry
10.1016/j.compeleceng.2021.107121,Journal,Computers and Electrical Engineering,scopus,2021-06-01,sciencedirect,Efficient neural networks for edge devices,https://api.elsevier.com/content/abstract/scopus_id/85103242184,"Due to limited computation and storage resources of industrial internet of things (IoT) edge devices, many emerging intelligent industrial IoT applications based on deep neural networks (DNNs) heavily depend on cloud computing for computation and storage. However, cloud computing faces technical issues in long latency, poor reliability, and weak privacy, resulting in the need for on-device computation and storage. On-device computation is essential for many time-critical industrial IoT applications, which require real-time data processing. In this paper, we review three major research areas for on-device computation, specifically quantization, pruning, and network architecture design. The three techniques could enable a DNN model to be deployed on edge devices for real-time computation and storage, mainly due to the reduction of computation and space complexity. More importantly, these techniques could make DNNs applicable to industrial IoT devices.",industry
10.1016/j.scs.2021.102822,Journal,Sustainable Cities and Society,scopus,2021-06-01,sciencedirect,A real-time tracking controller for piezoelectric actuators based on reinforcement learning and inverse compensation,https://api.elsevier.com/content/abstract/scopus_id/85102276498,"Nanotechnology is a promising technology and has been widely applied for sustainable smart cities. As the fundamental devices for nanotechnology, piezoelectric actuators (PEAs) have gained wide attention in precision manufacturing because of the advantages of rapid response, large mechanical force and high resolution. However, the inherent nonlinearities of PEAs hinder wide applications for nano-positioning and high-precision manipulation. To eliminate these nonlinearities, various control methods have been proposed, while the optimal control of PEAs is considered rarely. Inspired by the reinforcement learning, adaptive dynamic programming (ADP) is proposed to solve the optimal tracking control problem of PEAs. In this paper, a controller based on reinforcement learning and inverse compensation is designed for the tracking control of PEAs. The experiments on the PEA platform are designed to verify the effectiveness of the proposed method. Comparisons with some representative controllers have demonstrated that the proposed controller has a better control performance.",industry
10.1016/j.renene.2021.03.008,Journal,Renewable Energy,scopus,2021-06-01,sciencedirect,Intelligent energy management based on SCADA system in a real Microgrid for smart building applications,https://api.elsevier.com/content/abstract/scopus_id/85102248554,"Energy management is one of the main challenges in Microgrids (MGs) applied to Smart Buildings (SBs). Hence, more studies are indispensable to consider both modeling and operating aspects to utilize the upcoming results of the system for the different applications. This paper presents a novel energy management architecture model based on complete Supervisory Control and Data Acquisition (SCADA) system duties in an educational building with an MG Laboratory (Lab) testbed, which is named LAMBDA at the Electrical and Energy Engineering Department of the Sapienza University of Rome. The LAMBDA MG Lab simulates in a small scale a SB and is connected with the DIAEE electrical network. LAMBDA MG is composed of a Photovoltaic generator (PV), a Battery Energy Storage System (BESS), a smart switchboard (SW), and different classified loads (critical, essential, and normal) some of which are manageable and controllable (lighting, air conditioning, smart plugs operating into the LAB). The aim of the LAMBDA implementation is making the DIAEE smart for energy saving purposes. In the LAMBDA Lab, the communication architecture consists in a complex of master/slave units and actuators carried out by two main international standards, Modbus (industrial serial standard for electrical and technical monitoring systems) and Konnex (an open standard for commercial and domestic building automation). Making the electrical department smart causes to reduce the required power from the main grid. Hence, to achieve the aims, results have been investigated in two modes. Initially, the real-time mode based on the SCADA system, which reveals real daily power consumption and production of different sources and loads. Next, the simulation part is assigned to shows the behavior of the main grid, loads and BESS charging and discharging based on energy management system. Finally, the proposed model has been examined in different scenarios and evaluated from the economic aspect.",industry
10.1016/j.cja.2020.09.011,Journal,Chinese Journal of Aeronautics,scopus,2021-06-01,sciencedirect,Framework and development of data-driven physics based model with application in dimensional accuracy prediction in pocket milling,https://api.elsevier.com/content/abstract/scopus_id/85097765922,"In the manufacturing of thin wall components for aerospace industry, apart from the side wall contour error, the Remaining Bottom Thickness Error (RBTE) for the thin-wall pocket component (e.g. rocket shell) is of the same importance but overlooked in current research. If the RBTE reduces by 30%, the weight reduction of the entire component will reach up to tens of kilograms while improving the dynamic balance performance of the large component. Current RBTE control requires the off-process measurement of limited discrete points on the component bottom to provide the reference value for compensation. This leads to incompleteness in the remaining bottom thickness control and redundant measurement in manufacturing. In this paper, the framework of data-driven physics based model is proposed and developed for the real-time prediction of critical quality for large components, which enables accurate prediction and compensation of RBTE value for the thin wall components. The physics based model considers the primary root cause, in terms of tool deflection and clamping stiffness induced Axial Material Removal Thickness (AMRT) variation, for the RBTE formation. And to incorporate the dynamic and inherent coupling of the complicated manufacturing system, the multi-feature fusion and machine learning algorithm, i.e. kernel Principal Component Analysis (kPCA) and kernel Support Vector Regression (kSVR), are incorporated with the physics based model. Therefore, the proposed data-driven physics based model combines both process mechanism and the system disturbance to achieve better prediction accuracy. The final verification experiment is implemented to validate the effectiveness of the proposed method for dimensional accuracy prediction in pocket milling, and the prediction accuracy of AMRT achieves 0.014 mm and 0.019 mm for straight and corner milling, respectively.",industry
10.1016/j.apenergy.2021.116688,Journal,Applied Energy,scopus,2021-05-15,sciencedirect,Advanced price forecasting in agent-based electricity market simulation,https://api.elsevier.com/content/abstract/scopus_id/85102042154,"Machine learning and agent-based modeling are two popular tools in energy research. In this article, we propose an innovative methodology that combines these methods. For this purpose, we develop an electricity price forecasting technique using artificial neural networks and integrate the novel approach into the established agent-based electricity market simulation model PowerACE. In a case study covering ten interconnected European countries and a time horizon from 2020 until 2050 at hourly resolution, we benchmark the new forecasting approach against a simpler linear regression model as well as a naive forecast. Contrary to most of the related literature, we also evaluate the statistical significance of the superiority of one approach over another by conducting Diebold–Mariano hypothesis tests. Our major results can be summarized as follows. Firstly, in contrast to real-world electricity price forecasts, we find the naive approach to perform very poorly when deployed model-endogenously (mean absolute percentage error 0.40–0.53). Secondly, although the linear regression performs reasonably well (mean absolute percentage error 0.17–0.32), it is outperformed by the neural network approach (mean absolute percentage error 0.17–0.21). Thirdly, the use of an additional classifier for outlier handling substantially improves the forecasting accuracy, particularly for the linear regression approach. Finally, the choice of the model-endogenous forecasting method has a clear impact on simulated electricity prices. This latter finding is particularly crucial since these prices are a major results of electricity market models.",industry
10.1016/j.eswa.2020.114519,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Towards optimal hydro-blasting in reconfigurable climbing system for corroded ship hull cleaning and maintenance,https://api.elsevier.com/content/abstract/scopus_id/85100189762,"The operation of a ship in the ocean depends crucially on the quality of routine offshore dry dock maintenance. Automation by robotics is an efficient solution to address the issues of saving water, energy, time, and easing the labour workload when conducting hydro-blasting hulls in the dry dock ship maintenance industry. In this paper, the automated hydro-blasting in corroded ship hull cleaning by a novel robot platform with reconfigurable manipulators named Hornbill is proposed. The robot is able to maneuver smoothly on a vertical surface by permanent magnetic force, to carry the heavy load, to clean the corroded ship hull by hydro-blasting, and to self-evaluate hydro-blasting task by leveraging the Deep Convolutional Neural Network (DCNN) to synthesis the corrosion level map of the blasted workspace. We also propose an optimal complete waypoint path planning (CWPP) framework to help the robot re-blast the benchmarked workspace. The optimal CWPP problem, including objective functions of the shortest travel distance, the least upward moving direction to reduce water, energy spent while ensuring the visiting of the robot to all uncleaned waypoints defined by benchmarking output, is modeled as the classic Travel Salesman Problem (TSP). The evolutionary-based optimization techniques, including Genetic Algorithm (GA) and Ant Colony Optimization (ACO), are explored to derive the Pareto-optima solution for given TSP. The experimental results show that the magnetic force and motors torque are synchronized to enable the proposed system to navigate smoothly on the vertical surfaces tested with different corrosion levels. The proposed corrosion level benchmarking achieves a mean accuracy of 0.956 with an execution time of 30 fps. Besides, the proposed CWPP enables the proposed robot to yield about 15%, 26%, and 5% the energy, water, and time, respectively, less than the conventional methods when the experiments are conducted in various workspaces on the real ship hull.",industry
10.1016/j.jhazmat.2020.124671,Journal,Journal of Hazardous Materials,scopus,2021-05-15,sciencedirect,Consequences of a short-term exposure to a sub lethal concentration of CdO nanoparticles on key life history traits in the fruit fly (Drosophila melanogaster),https://api.elsevier.com/content/abstract/scopus_id/85098123940,"Nanoparticles of cadmium oxide (CdO NPs) are among the most common industrial metal oxide nanoparticles. Early adulthood (P1) fruit flies (D. melanogaster) were exposed for 7 days to a sub lethal concentration (0.03 mg CdO NPs/mL, which was 20% of the LC50), spiked into food media to test whether short episodes of CdO NPs exposures early in adult life have long-lasting effects on life history traits such as fecundity well beyond exposure times. All studied life history traits, as well as climbing behavior were adversely affected by exposure to CdO NPs. A blistered wing phenotype was also observed in the non-exposed progeny (F1) of adult flies (P1) and their fecundity was significantly decreased (−50%) compared to the fecundity of non-exposed (control) F1 flies. Expressions of antioxidant enzymes encoding genes; catalase and superoxide dismutase (SOD2) were significantly up regulated in P1 flies compared to control. Expression of metallothionein encoding genes (MTn A-D) were significantly up-regulated in both parent flies (P1) and their progeny (F1) after exposure of P1 flies to CdO NPs compared to non-exposed control flies, suggesting long-term potential effects. Taken together, these findings indicate that short-term exposure to a sub-lethal CdO NP concentration is sufficient to have long-lasting, adverse effects on fruit flies.",industry
10.1016/j.comnet.2021.107974,Journal,Computer Networks,scopus,2021-05-08,sciencedirect,TSCRNN: A novel classification scheme of encrypted traffic based on flow spatiotemporal features for efficient management of IIoT,https://api.elsevier.com/content/abstract/scopus_id/85102567214,"In the Industrial Internet of Things (IIoT) in the 5G era, the growth of smart devices will generate a large amount of data traffic, bringing a huge challenge of network traffic classification, which is the prerequisite of IIoT traffic engineering, quality of service (QoS), cyberspace security, etc. It is difficult for current traffic classification methods to distinguish encrypted dataflow and design effective handcraft features. In this paper, a novel identification scheme of encrypted traffic, TSCRNN, is proposed to automatically extract features for efficient traffic classification, which is based on spatiotemporal features. TSCRNN includes the preprocessing phase and the classification phase. In the preprocessing phase, raw traffic data are processed with flow segmentation, sampling, and vectorization, etc. To solve the classification problem of long time flow, sampling strategies are used to collect samples from the middle of the long-lived flow. In the classification phase, TSCRNN extracts abstract spatial features by CNN and then introduces stack bidirectional LSTM to learn the temporal characteristics. The experiments were performed on the dataset ISCXTor2016. The experimental results show that TSCRNN outperforms other typical methods in all scenarios, which achieves the accuracy up to 99.4% and 95.0% respectively in Tor/nonTor binary classification tasks and sixteen classification tasks. Furthermore, TSCRNN is applied to other real network datasets obtained the satisfactory performance, which validates its feasibility and universality. It means that TSCRNN can effectively identify encrypted and anonymous traffic, provide a fine-grained traffic characterization mechanism, which will support the development of core technologies in the Industrial Internet of Things.",industry
10.1016/j.powtec.2021.01.075,Journal,Powder Technology,scopus,2021-05-01,sciencedirect,An artificial neural network model applied to convert sucrose chord length distributions into particle size distributions,https://api.elsevier.com/content/abstract/scopus_id/85101204349,"Online monitoring of the solid phase in industrial processes of sugar crystallization is still a challenge. Laser backscattering is one of the most promising techniques; however, the measured chord length distribution (CLD) does not have a physical meaning of crystal size. This work converted sucrose CLD measured by an online sensor into particle size distribution (PSD) using an artificial neural network (ANN). CLD and suspension concentration of 116 experiments were the input to the ANN and PSD was its output. The trained ANN exhibited a coefficient of variation between experimental and calculated PSD of 0.998. Data of experimental sucrose crystallization was used to validate the model, resulting in a maximum deviation of 0.090 mm in mean size and 6.16% in the coefficient of variation of distribution. This model may be used to improve both industrial processes (process optimization and control) and laboratory studies (kinetics determination).",industry
10.1016/j.atmosres.2021.105490,Journal,Atmospheric Research,scopus,2021-05-01,sciencedirect,Changes of ammonia concentrations in wintertime on the North China Plain from 2018 to 2020,https://api.elsevier.com/content/abstract/scopus_id/85100690328,"The reduced economic and social activities during the Chinese Spring Festival provide a unique experiment to evaluate reductions in anthropogenic NH3 emissions in China. However, quantifying this unique scenario is challenging as meteorology may mask the real changes in observed NH3 concentrations. Here, we applied a machine learning technique to decouple the effects of meteorology and confirmed that the real (deweathered) NH3 concentration dropped to a minimum during the Spring Festival in 2019 and 2020 at both urban (Beijing) and rural (Xianghe) sites on the North China Plain. Compared with the scenario without the Spring Festival effect, we predicted that NH3 concentrations in 2020 were 39.8% and 24.6% higher than the observed values at the urban and rural sites, respectively. The significant difference between the two sites indicates a larger reduction in anthropogenic NH3 emissions in urban areas than in rural areas due to the Spring Festival and lockdown measures of COVID-19. Future control strategies should consider the emissions of NH3 from the transportation, industrial and residential sectors, considering that agricultural emissions are minor in cold seasons.",industry
10.1016/j.eswa.2020.114379,Journal,Expert Systems with Applications,scopus,2021-05-01,sciencedirect,DGTL-Net: A Deep Generative Transfer Learning Network for Fault Diagnostics on New Hard Disks,https://api.elsevier.com/content/abstract/scopus_id/85098696865,"Intelligent fault diagnosis of hard disks becomes significantly important to guarantee reliability of current cloud-based industrial systems. Most intelligent diagnostic methods are commonly based on assumptions that data from different disks are subject to the same distribution and there are sufficient faulty samples for training the models. However, in reality, there are types of hard disks from different manufacturers and their SMART encoding varies widely across manufacturers. It results in distribution discrepancy among disks and influences the generalization of machine learning methods. Moreover, hard disks usually work in healthy state that faulty events rarely happen on most of them, or especially never occur on new ones. Thus, this paper proposes a deep generative transfer learning network (DGTL-Net) for intelligent fault diagnostics on new hard disks. The DGTL-Net combines the deep generative network that generates fake faulty samples and the deep transfer network that solves the problem of distribution discrepancy between hard disks. An iterative end-end training strategy is also proposed for DGTL-Net to get the most optimal parameters of generative and transfer network simultaneously. Experiments have been conducted to prove that our method achieves better performance.",industry
10.1016/j.foodchem.2020.128436,Journal,Food Chemistry,scopus,2021-05-01,sciencedirect,Ultra-sensitive electrochemical aptasensor for label-free detection of Aflatoxin B1 in wheat flour sample using factorial design experiments,https://api.elsevier.com/content/abstract/scopus_id/85094596007,"Considering the significance of mycotoxin detection in food industries, herein, an ultrasensitive aptasensor was developed based on aflatoxin B1 aptamer immobilized on Carbon quantum dots/octahedral Cu2O nanocomposite. Electrochemical measurements were based on Electrochemical Impedance Spectroscopy (EIS) and Differential Pulse Voltammetry (DPV). Since the effective parameters (pH, temperature, incubation time and concentration of aptamers) are interdependent, so their dependent study can be nonideal. Taguchi method has solved this problem and optimized the experimental conditions using a smaller number of experiments. Under optimum conditions, the electrochemical signals declined as AFB1 concentrations increased with a dynamic range of 3 ag.ml−1 −1.9 µg.ml−1 and a low limit of detection (LOD) of 0.9 ± 0.04 ag ml−1. The obtained results proved sufficient repeatability (RSD = 2.4%), reproducibility (RSD = 2.56%), accuracy (97.2–104.4% recovery), and robustness (RSD = 3.25%). Furthermore, considerable selectivity, stability and reliability of the aptasensor confirmed the capability to work in future real assays.",industry
10.1016/j.eswa.2020.114469,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,CPIN: Comprehensive present-interest network for CTR prediction,https://api.elsevier.com/content/abstract/scopus_id/85098466604,"Personalized recommendation is a popular research direction in both industry and academia. Some research on recommender systems utilizes the users’ interaction history on items to represent the users’ interests, which has achieved remarkable success. Users’ interests in the real world are dynamically changing and have a strong correlation with the interaction sequence. However, sometimes users’ interests are less relevant to the order of the current interaction sequence, but are more relevant to certain items in the user interaction history. In this paper, a novel deep neural network model is proposed to deal with this situation. The developed model consists of two parts: the present interest relevant to the order of the interaction sequence and the comprehensive interest relevant to some items in the interaction sequence. An ancillary multi-layer perceptron (MLP) is constructed to improve the training of our model. Experiments on public and industrial datasets are conducted. The experimental results show that our proposed model outperforms the state-of-the-art models which demonstrates the effectiveness of the ancillary MLP.",industry
10.1016/j.neucom.2020.12.013,Journal,Neurocomputing,scopus,2021-04-14,sciencedirect,Harvest shopping advice: Neural Question Generation from multiple information sources in E-commerce,https://api.elsevier.com/content/abstract/scopus_id/85100216874,"The success of recent efforts in Question Generation (QG) has amazed scientists from academia and industry. In this paper, we explore to harvest shopping advice through a novel QG engine for e-commerce platforms. Unlike traditional QG methods conditioned on factual data, generating purchase-oriented questions depends on open-ended product properties and customer reviews. Besides, these questions should follow not only natural expressions but also user-interested aspects simultaneously. For this challenging task, an innovative generative adversarial net-based QG model is proposed – a generator featuring multi-source attention mechanism is employed to yield questions from multiple information sources; a discriminator featuring quality control is applied to fine-tune generated questions in terms of both language performance and aspect compatibility. We conduct extensive experiments on a new dataset comprised of Question-Review-Aspect-Property (Q-RAP) tuples from a real e-commerce site. Our experimental results demonstrate that the proposed approach achieves a significant superiority over seven state-of-the-art QG solutions. Meanwhile, this study indicates that customer reviews play a critical role in generating purchase-oriented questions, which confirms the validity of previous practices using buyer feedback to address natural language generation in e-commerce.",industry
10.1016/j.jmsy.2021.02.012,Journal,Journal of Manufacturing Systems,scopus,2021-04-01,sciencedirect,Robust diagnosis with high protection to gas turbine failures identification based on a fuzzy neuro inference monitoring approach,https://api.elsevier.com/content/abstract/scopus_id/85101807612,"Modern industry requires the development of new monitoring and diagnostic procedures, which enable the detection, localization, and isolation of faults. For sustainable solutions in terms of operational safety and availability, while bringing out zero accidents, zero downtime, and zero faults, for a trend acting on environmental issues. Towards this development, this work proposes solutions for the monitoring of gas turbines and their real-time implementation, in order to approximate and predict the degradation of the components of this system, by an approach of faults detection and isolation, based on an adaptive neural-fuzzy inference system. This will develop a reliable approach to maintain and monitor gas turbines, in case of failure or accident to prevent in real-time and makes it possible to achieve high power with efficiency and small footprint with High performance by operating this rotating machine. However, the application of the Adaptive Neuro-Fuzzy Inference System Observer-Based Approach, makes it possible to increase the life of the examined turbine and keep better reliability for their monitoring system and satisfy the techno-economic and environmental performance impacts. For the purpose of controlling failures and the occurrence of turbine system malfunctions, and avoiding their consequences on the safety and productivity of the installation.",industry
10.1016/j.enconman.2021.113856,Journal,Energy Conversion and Management,scopus,2021-04-01,sciencedirect,The mutual benefits of renewables and carbon capture: Achieved by an artificial intelligent scheduling strategy,https://api.elsevier.com/content/abstract/scopus_id/85101129959,"Renewable power and carbon capture are key technologies to transfer the power industry into low carbon generation. Renewables have been developed fast, however, the intermittent nature has imposed higher requirement for the flexibility of the power grid. Retrofitting carbon capture technologies to existing fossil-fuel fired power plants is an important solution to avoid the “lock-in” of emissions, but the high operating costs hinders their large scale application. The coexistence of renewable power and carbon capture opens up a new avenue that the deployment of carbon capture can provide additional flexibility for better accommodation of renewable power while excess renewables can be used to reduce the operating costs of carbon capture. To this end, this paper proposes an artificial intelligence based optimal scheduling strategy for the power plant-carbon capture system in the context of renewable power penetration to show that the mutual benefits between carbon capture and renewable power can be achieved when the carbon capture process is made fully adjustable. An artificial intelligent deep belief neural network is used to reflect the complex interactions between carbon, heat and electricity within the power plant carbon capture system. Multiple operating goals are considered in the scheduling such as minimizing the operating costs, renewable power curtailment and carbon emission, and the particle swarm heuristic optimization is employed to find the optimal solution. The impacts of carbon capture constraint mode, carbon emission penalty coefficient, carbon dioxide production constraints and renewable power installed capacity are investigated to provide broader insight on the potential benefit of carbon capture in future low-carbon energy system. A case study using real world data of weather condition and load demand shows that renewable power curtailment can be reduced by 51% with the integration of post-combustion capture systems and 35% of total carbon emission are captured by the use of excess renewable power through optimal scheduling. This paper points out a new way of using artificial intelligent technologies to coordinate the couplings between carbon and electricity for efficient and environmentally friendly operation of future low-carbon energy system.",industry
10.1016/j.asoc.2021.107101,Journal,Applied Soft Computing,scopus,2021-04-01,sciencedirect,Att-Net: Enhanced emotion recognition system using lightweight self-attention module,https://api.elsevier.com/content/abstract/scopus_id/85100093498,"Speech emotion recognition (SER) is an active research field of digital signal processing and plays a crucial role in numerous applications of Human–computer interaction (HCI). Nowadays, the baseline state of the art systems has quite a low accuracy and high computations, which needs upgrading to make it reasonable for real-time industrial uses such as detection of content from speech data. The main intent for low recognition rate and high computational cost is a scarceness of datasets, model configuration, and patterns recognition that is the supreme stimulating work for building a robust SER system. In this study, we address these problems and propose a simple and lightweight deep learning-based self-attention module (SAM) for SER system. The transitional features map is given to SAM, which produces efficiently the channel and spatial axes attention map with insignificant overheads. We use a multi-layer perceptron (MLP) in channel attention to extracting global cues and a special dilated convolutional neural network (CNN) in spatial attention to extract spatial info from input tensor. Moreover, we merge, spatial and channel attention maps to produce a combine attention weights as a self-attention module. We placed SAM in the middle of convolutional and connected layers and trained it in an end-to-end mode. The ablation study and comprehensive experimentations are accompanied over IEMOCAP, RAVDESS, and EMO-DB speech emotion datasets. The proposed SER system shows consistent improvements in overall experiments for all datasets and shows 78.01%, 80.00%, and 93.00% average recall, respectively.",industry
10.1016/j.asoc.2020.107069,Journal,Applied Soft Computing,scopus,2021-04-01,sciencedirect,Deep learning feature exploration for Android malware detection,https://api.elsevier.com/content/abstract/scopus_id/85098947132,"Android mobile devices and applications are widely deployed and used in industry and smart city. Malware detection is one of the most powerful and effective approaches to guarantee security of Android systems, especially for industrial platform and smart city. Recently, researches using machine learning-based techniques for Android malware detection increased rapidly. Nevertheless, most of the appeared approaches have to perform feature analysis and selection, so-called feature engineering, which is time-consuming and relies on artificial experience. To solve the inefficiency problem of feature engineering, we propose TC-Droid, an automatic framework for Android malware detection based on text classification method. The core idea of TC-Droid is derived from the field of text classification. TC-Droid feeds on the text sequence of APPs analysis reports generated by AndroPyTool, applies a convolutional neural network (CNN) to explore significant information (or knowledge) under original report text, instead of manual feature engineering. In an evaluation with different number of real-world samples, TC-Droid outperforms state-of-the-art model (Drebin) and several classic models (NB, LR, KNN, RF) as well. With multiple experimental settings and corresponding comparisons, TC-Droid achieves effective and flexible performance in Android malware detection task.",industry
10.1016/j.seppur.2020.118238,Journal,Separation and Purification Technology,scopus,2021-04-01,sciencedirect,Continuous microfluidic solvent extraction of cobalt from mimicked and real asteroid leaching solutions,https://api.elsevier.com/content/abstract/scopus_id/85098699532,"This research proposes a pathway for the last step of the asteroid mining process: the purification of the adjacent metals, cobalt and nickel, in the frame of in-situ resource utilization (ISRU) in space. Major technological and economic challenges will need to be overcome, and one main issue to be tackled is the reduction of water usage in this process. Therefore, the leached metal solutions are expected to contain ultra-high metal concentrations, up to 10 mol/l. These solutions will have challenging thermodynamic properties (increased density, viscosity and interfacial tension). As a result, an analysis of dimensionless numbers for fluidics and mass transport was made, showing that some of these are favourable under the constraints of accessible microfluidic operations. Experiments were performed with advanced microfluidic reactors (a coiled-flow inverter (CFI) and an industrial re-entrance flow reactor from Corning®) at high metal concentrations and high nickel to cobalt ratios (3:0.3 mol/l Ni:Co). Using Cyanex 272 as a selective extractant for cobalt, extraction efficiencies of 60% with high separation factors (>1000) were reached in just one extraction stage. The CFI showed high extraction efficiency for low fluid velocities and a residence time of 60 s. For the Corning® reactor, high fluid velocities or the use of many modules (>3) are needed to obtain an emulsion, resulting in high extraction efficiencies at a very short residence time of 13 s. The comparison between the CFI and the Corning® reactor shows that they share the best operation point (at 120 ml/h), but the Corning® reactor performs better at higher flow rates and thus can leverage higher productivity. However, the CFI is easier to operate and has a much lower pressure drop, resulting in low energy input. Finally, an iron meteorite sample was leached and efficiently extracted in both microfluidic reactors.",industry
10.1016/j.isatra.2020.10.029,Journal,ISA Transactions,scopus,2021-04-01,sciencedirect,A steam injection distribution optimization method for SAGD oil field using LSTM and dynamic programming,https://api.elsevier.com/content/abstract/scopus_id/85092899837,"Steam injection distribution optimization refers to the process of distributing steam injection in steam assisted gravity drainage (SAGD) oil field to maximize the total oil production. A novel optimization method that integrates long short-term memory (LSTM) neural network and dynamic programming is presented in this paper to solve the steam injection distribution optimization problem for the first time. In the proposed method, LSTM is used to construct the prediction model to predict oil production of the wells. With the prediction result, dynamic programming optimizes steam injection distribution in the oil field to maximize total oil production. Convergence stability and computational complexity of the dynamic programming method have been analyzed and presented in this research. A web-based geographical information system called Petroleum Explorer is also developed based on the proposed method. Experiments on two pads of a real-world SAGD project demonstrate that LSTM model gives better prediction result than other five existing models and production improvement of the proposed method is highly related to parameter setting of the optimization process",industry
10.1016/j.neucom.2020.10.097,Journal,Neurocomputing,scopus,2021-03-21,sciencedirect,3D-RVP: A method for 3D object reconstruction from a single depth view using voxel and point,https://api.elsevier.com/content/abstract/scopus_id/85097471582,"Three-dimensional object reconstruction technology has a wide range of applications such as augment reality, virtual reality, industrial manufacturing and intelligent robotics. Although deep learning-based 3D object reconstruction technology has developed rapidly in recent years, there remain important problems to be solved. One of them is that the resolution of reconstructed 3D models is hard to improve because of the limitation of memory and computational efficiency when deployed on resource-limited devices. In this paper, we propose 3D-RVP to reconstruct a complete and accurate 3D geometry from a single depth view, where R, V and P represent Reconstruction, Voxel and Point, respectively. It is a novel two-stage method that combines a 3D encoder-decoder network with a point prediction network. In the first stage, we propose a 3D encoder-decoder network with residual learning to output coarse prediction results. In the second stage, we propose an iterative subdivision algorithm to predict the labels of adaptively selected points. The proposed method can output high-resolution 3D models by increasing a small number of parameters. Experiments are conducted on widely used benchmarks of a ShapeNet dataset in which four categories of models are selected to test the performance of neural networks. Experimental results show that our proposed method outperforms the state-of-the-arts, and achieves about 
                        
                           2.7
                           %
                        
                      improvement in terms of the intersection-over-union metric.",industry
10.1016/j.jclepro.2020.125128,Journal,Journal of Cleaner Production,scopus,2021-03-15,sciencedirect,"Highly selective removal of 2,4-dinitrotoluene for industrial wastewater treatment through hyper-cross-linked resins",https://api.elsevier.com/content/abstract/scopus_id/85096912907,"Here a strategy by designing a series of hyper-cross-linked polystyrene resins (
                        HCLR
                     s) with highly selective adsorption ability toward hazardous 2,4-dinitrotoluene from nitrophenol sodium salt-rich real industrial wastewater was reported. Macroporous cross-linked chloromethylated polystyrene was self-crosslinked or crosslinked with ligands, i.e. toluene, aniline, and phenol to produce 2,4-dinitrotoluene affinitic 
                        HCLR-0
                     , 
                        HCLR-T
                     , 
                        HCLR-A
                      and 
                        HCLR-P
                     , respectively. The ultrahigh affinity through the like dissolves like mechanism toward 2,4-dinitrotoluene was validated by adsorption experiments, i.e. isotherm, kinetics, thermodynamics, effect of pH & 2-nitrophenol sodium salt and dynamic column adsorption-desorption investigations. They showed ultrahigh adsorption capacities toward 2,4-dinitrotoluene, reaching 628.9, 621.1, 657.9 and 641.0 mg/g for 
                        HCLR-0
                     , 
                        HCLR-T
                     , 
                        HCLR-A
                      and 
                        HCLR-P
                      at 303 K, outperforming their matrix cross-linked chloromethylated polystyrene of 79.2 mg/g and 
                        XAD-4
                      of 286 mg/g very much. This advantage was also reflected in the dynamic adsorption study with promising breakthrough and saturated capacities of 195.8 and 334.4 mg/mL wet 
                        HCLR-A
                     s, respectively. The 
                        HCLR
                     s also featured interesting impurity affectless properties, in which 2-nitrophenol sodium salt showed no influence on the 2,4-dinitrotoluene capture even in high concentration. With the interesting properties shown above, the 
                        HCLR-A
                      column worked very well in the large-scale real industrial wastewater, and could also be fully recycling used through simple low-cost treatment.",industry
10.1016/j.elecom.2021.106942,Journal,Electrochemistry Communications,scopus,2021-03-01,sciencedirect,Electrochemical quantification of D-glucose during the production of bioethanol from thermo-mechanically pre-treated wheat straw,https://api.elsevier.com/content/abstract/scopus_id/85100657971,"Mechanical pre-treatment (disc refining) of wheat straw, at both atmospheric and elevated pressure, is shown to be an efficient process to access fermentable monosaccharides, with the potential to integrate within the infrastructure of existing first-generation bioethanol plants. The mild, enzymatic degradation of this sustainable lignocellulosic biomass affords ca. 0.10–0.13 g/g (dry weight) of d-glucose quantifiable voltammetrically in real time, over a two hundred-fold range in experimental laboratory scales (25 mL to 5.0L), with pressure disc refining of the wheat straw enabling almost twice the amount of d-glucose to be generated during the hydrolysis stage than experiments using atmospheric refining (0.06–0.09 g/g dry weight). Fermentation of the resulting hydrolysate affords 0.08–0.10 g/g (dry weight) of ethanol over similar scales, with ethanol productivity at ca. 37 mg/(L h). These results demonstrate that minimal cellulose decomposition occurs during pressure refining of wheat straw, in contrast to hemicellulose, and suggest that the development of green, mechanochemical processes for the scalable and cost-effective manufacture of second-generation bioethanol requires improved cellulose decomposition.",industry
10.1016/j.fbp.2020.12.009,Journal,Food and Bioproducts Processing,scopus,2021-03-01,sciencedirect,Study of Galactooligosaccharides production from dairy waste by FTIR and chemometrics as Process Analytical Technology,https://api.elsevier.com/content/abstract/scopus_id/85099356128,"Galactooligosaccharides (GOS) production from whey, a relevant by-product of dairy industry, answers to the Circular Economy principle of extending the life cycle of products. Indeed, it allows the reuse of dairy waste to produce prebiotics to be used in functional food preparations. For this purpose, the effective monitoring of GOS production should be performed in real time and by environmentally friendly techniques. Thus, FTIR spectroscopy, combined with different chemometric approaches, has been tested to assess a Process Analytical Technology to follow GOS production from cheese whey. Partial Least Square regression models were reliable for lactose, glucose and galactose determination (Root Mean Square Error of Prediction of 21.9, 11.1 and 12.4 mg mL−1, respectively). Furthermore, Multivariate Curve Resolution – Alternating Least Square models were proposed to describe trends of the reaction components along the process being an interesting alternative to chromatographic determinations. The real time implementation of the proposed approach will provide the dairy industry with a reliable and green Process Analytical Technology for dairy waste reallocation, avoiding sample pre-processing, large use of organic solvents and long times of analysis.",industry
10.1016/j.psep.2020.12.040,Journal,Process Safety and Environmental Protection,scopus,2021-03-01,sciencedirect,Modelling of the minimum ignition temperature (MIT) of corn dust using statistical analysis and artificial neural networks based on the synergistic effect of concentration and dispersion pressure,https://api.elsevier.com/content/abstract/scopus_id/85099258936,"Corn dust is a highly energetic substance and frequently found in the food manufacturing industries. It not only poses occupational safety hazards such as suffocation or lung disorders for exposed persons but is often extremely explosible in ignition sensitive environment. This probability of explosion can be assessed and minimised with in-depth knowledge of controlling parameters/physical properties that trigger the ignition. This research takes into account the minimum ignition temperature (MIT), which is the control parameter for explosion risk assessment. MIT relies on multiple factors, such as moisture content, particle size, dust concentration, dispersion pressure, humidity and environmental temperature. In this study, the ignition of corn dust clouds was analysed using a Godbert Greenwald furnace for different combinations of dispersion pressure and concentrations. Test findings revealed that the minimum ignition temperature rises with a decrease in particle size. However, the minimum ignition temperature decreases with increased dispersion pressure and concentration until a specific value known as optimal value for ignition. Moreover, this work focuses on a statistical approach of polynomial surface fitting to forecast the MIT based on the combined impact of concentration and dispersion pressure on MIT for corn dust in a real-time experiment. The minimum value of the Bayesian Information Criterion (BIC) was used to select the most appropriate polynomial model due to its authenticity and strong reputation. An artificial neural network (ANN) is also used as a predictive tool to develop a model that can forecast the MIT with a defined combination of dispersion pressures and corn dust concentrations. As soon as an appropriate estimation of this minimum ignition temperature of the combustible dust is confirmed, it is possible to ensure that the temperatures of the surrounding hot surfaces do not rise to that point to prevent the explosion. The predictive results obtained from ANN were found to be good when compared with the polynomial surface fit. Several models with different numbers of neurons have been trained with different transfer functions. For the training, validation, and test phases, R values are around 1.0, i.e., 0.9863, 0.9930, and 0.9893, respectively. The overall R value was 0.9875 for the proposed network. The findings were considered to be acceptable as the overall value of R was close to 1.0. The network obtained sufficiently comparable findings with the research conducted by Kasalova and Balog.",industry
10.1016/j.asoc.2020.107025,Journal,Applied Soft Computing,scopus,2021-03-01,sciencedirect,Distinguishing computer-generated images from photographic images using two-stream convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85098458515,"Today’s advanced multimedia tools allow us to create photorealistic computer graphic images, effortlessly. There are various fields such as the film industry, virtual reality, video games where computer-generated (CG) images are used widely. CG images can also be misused in many ways. Therefore, there is a need of distinguishing CG images from real photographic (PG) images. This paper proposes a method to distinguish CG images from PG images using a two-stream convolutional neural network (CNN). In the proposed method, the first stream takes the advantage of the knowledge learned by the pre-trained VGG-19 network, and then this knowledge is transferred to learn the distinct features of CG and PG images. Here, we propose a second stream, that preprocesses the images using three high-pass filters which aim to help the network to focus on noise-based distinct features of CG and PG images. Finally, we propose an ensemble model to merge the outcomes of the proposed two streams. Comparative and self-analysis experiments demonstrates that the proposed method outperforms the state-of-the-art methods in terms of classification accuracy. The experimental results also show that the proposed method performs satisfactorily under the additive white Gaussian noise postprocessing operation in the images.",industry
10.1016/j.dss.2020.113452,Journal,Decision Support Systems,scopus,2021-03-01,sciencedirect,A multivariate approach for multi-step demand forecasting in assembly industries: Empirical evidence from an automotive supply chain,https://api.elsevier.com/content/abstract/scopus_id/85097734622,"Demand forecasting works as a basis for operating, business and production planning decisions in many supply chain contexts. Yet, how to accurately predict the manufacturer's demand for components in the presence of end-customer demand uncertainty remains poorly understood. Assigning the proper order quantities of components to suppliers thus becomes a nontrivial task, with a significant impact on planning, capacity and inventory-related costs. This paper introduces a multivariate approach to predict manufacturer's demand for components throughout multiple forecast horizons using different leading indicators of demand shifts. We compare the autoregressive integrated moving average model with exogenous inputs (ARIMAX) with Machine Learning (ML) models. Using a real case study, we empirically evaluate the forecasting and supply chain performance of the multivariate regression models over the component's life-cycle. The experiments show that the proposed multivariate approach provides superior forecasting and inventory performance compared with traditional univariate benchmarks. Moreover, it reveals applicable throughout the component's life-cycle, not just to a single stage. Particularly, we found that demand signals at the beginning of the life-cycle are predicted better by the ARIMAX model, but it is outperformed by ML-based models in later life-cycle stages.",industry
10.1016/j.future.2020.10.031,Journal,Future Generation Computer Systems,scopus,2021-03-01,sciencedirect,DISCERNER: Dynamic selection of resource manager in hyper-scale cloud-computing data centres,https://api.elsevier.com/content/abstract/scopus_id/85096157784,"Data centres constitute the engine of the Internet, and run a major portion of large web and mobile applications, content delivery and sharing platforms, and Cloud-computing business models. The high performance of such infrastructures is therefore critical for their correct functioning. This work focuses on the improvement of data-centre performance by dynamically switching the main data-centre governance software system: the resource manager. Instead of focusing on the development of new resource-managing models as soon as new workloads and patterns appear, we propose DISCERNER, a decision-theory model that can learn from numerous data-centre execution logs to determine which existing resource-managing model may optimise the overall performance for a given time period. Such a decision-theory system employs a classic machine-learning classifier to make real-time decisions based on past execution logs and on the current data-centre operational situation. A set of extensive and industry-guided experiments has been simulated by a validated data-centre simulation tool. The results obtained show that the values of key performance indicators may be improved by at least 20% in realistic scenarios.",industry
10.1016/j.future.2020.10.018,Journal,Future Generation Computer Systems,scopus,2021-03-01,sciencedirect,Large-scale online multi-view graph neural network and applications,https://api.elsevier.com/content/abstract/scopus_id/85095762066,"Recently popularized Graph Neural Network (GNN) has been attaching great attention along with its successful industry applications. This paper focuses on two challenges traditional GNN frameworks face: (i) most of them are transductive and mainly concentrate on homogeneous networks considering single typed nodes and edges; (ii) they are difficult to handle the real-time changing network structures as well as scale to big graph data. To address these issues, a novel attention-based Heterogeneous Multi-view Graph Neural Network (aHMGNN) solution is introduced. aHMGNN models a more intricate heterogeneous multi-view network, where various node and edge types co-exist and each of these objects also contain specific attributes. It is end-to-end, and two stages are designed for node embeddings learning and multi-typed node and edge representations fusion, respectively. Experimental studies on large-scale spam detection and link prediction tasks clearly verify the efficiency and effectiveness of our proposed aHMGNN. Furthermore, we have implemented our approach in one of the largest e-commerce platforms which further verifies that aHMGNN is arguably promising and scalable in real-world applications.",industry
10.1016/j.optlaseng.2020.106431,Journal,Optics and Lasers in Engineering,scopus,2021-03-01,sciencedirect,A technique combining laser spot thermography and neural network for surface crack detection in laser engineered net shaping,https://api.elsevier.com/content/abstract/scopus_id/85094322441,"Laser engineered net shaping (LENS) is one of the core technologies commonly used in additive manufacturing. Improper optimization of the LENS process parameters may lead to defects, such as porosity and cracks, in the manufactured parts. Cracks, for instance, can adversely affect the mechanical properties of the parts, which may render them unserviceable. Therefore, it is necessary to develop online nondestructive testing (NDT) methods to monitor and detect the defects. As an important NDT method, laser spot thermography (LST) has drawn great attention due to its characteristics of non-contact and high-sensitivity. In this study, we design a laser spot scanning system, which can exert a multi-mode point heat source. A new technique combined with laser spot thermography and neural network is developed to characterize the crack parameters in LENS components. The temperature and its gradient at the crack location are extracted and used as inputs for training the neural network. The trained neural network builds a relationship between the input (temperature signal) and output (crack width) data. After verifying the reliability of the neural network by conducting numerical simulations and experiments with artificial cracks, the widths of real cracks in LENS samples are evaluated. An average absolute error of 2.0 μm (and the maximum absolute error was 6.1 μm) is obtained for LENS samples having crack widths in the range 3–68 μm. We conclude that the LST-NN technique can be used to detect the location and width of cracks with reasonable accuracy, and has the potential for further applications in the online monitoring of the LENS manufacturing process.",industry
10.1016/j.measurement.2020.108554,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2021-03-01,sciencedirect,Tool wear mechanism and prediction in milling TC18 titanium alloy using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85092319229,"Rapid tool wear from milling TC18 (Ti-5Al-5Mo-5V-1Cr-1Fe) leads to increased surface deterioration and manufacturing costs. Here, a real-life tool wear experiment was introduced, and the three stages of tool wear were analyzed in detail according to the tool wear micro-topography and chemical elements. In the initial and normal stage, the tool wear was slow because of the protection of the adhesive titanium layer and dense alumina film. Diffusion wear and oxidation wear occurred until the sever wear stage. Based on the above wear mechanism determination, after acquiring the real time cutting force, the tool wear prediction models were established using a convolutional bi-directional long short-term memory networks (CNN + BILSTM) and a convolutional bi-directional gated recurrent unit (CNN + BIGRU). The results show that the errors of the predicted minimum values are all within 8%, demonstrating that the deep learning method offers a new and promising approach for in monitoring tool wear on-line.",industry
10.1016/j.eswa.2020.113925,Journal,Expert Systems with Applications,scopus,2021-03-01,sciencedirect,Utilizing historical data for corporate credit rating assessment,https://api.elsevier.com/content/abstract/scopus_id/85090566623,"Corporate credit rating assessment is one of the crucial problems of credit risk management; it will help the financial institutions and government decide whether to issue debts. Recent studies focusing on the prediction of credit rating by using artificial intelligence (AI) techniques have shown impressive results compared to traditional statistical methods. Although the AI techniques can be used to assess credit risk, the prediction accuracy is still worth improving further, as even a small improvement in credit rating prediction accuracy leads to significant loss reduction in the industry. In this paper, we propose new learning analytic methods to enhance the prediction accuracy of credit rating. First, we devise the metrics based on the credit rating history of the firms, and expand the feature space with new input variables. This approach can be applied to any conventional AI methods for improvement of prediction accuracy. Second, we develop a novel learning algorithm that is designed to take into account historical financial data. We propose the parallel artificial neural networks (PANNs) ensemble model that creates several independent artificial neural networks (ANNs); each ANN deals with financial performance of the firms for each year, and the final output of PANNs is aggregated by ensemble learning. In our experiment, three different real-world datasets are used to validate the performance of our proposed approach. Consequently, the experimental results show that our proposed approach achieved competitive results compared to conventional AI techniques.",industry
10.1016/j.asej.2020.07.001,Journal,Ain Shams Engineering Journal,scopus,2021-03-01,sciencedirect,Evolutionary multi-objective network optimization algorithm in trajectory planning,https://api.elsevier.com/content/abstract/scopus_id/85088971459,"Flight network optimization, one of the airspace planning challenges, effectively manages airspace resources toward increasing airspace capacity and reducing air traffic congestion. In this paper, the structure of the air transport network is analyzed with a multi-objective genetic algorithm to reduce the number of airways and to aggregate the passengers and also to reduce route changes and the travel time fortravelers. The proposed topology model of this study is based on the combination of two topologies – point-to-point and hub-and-spoke – with multiple goals for decreasing in airways and travel length per passenger and also to reach the minimum number of air stops per passenger. Four state-of-the-art Multi-objective Genetic Algorithms (MOGAs) are considered for comparison studies and are tested and assessed in data of the Iran airline industry in 2018, as an experiment to real-world applications. Using the combination of point-to-point and hub-and-spoke topologies can improve the performance of the MOGA to solve a network-wide flight trajectory planning. Based on Iran airline traffic patterns in 2018, the proposed model successfully decreased 50.8% of air routes (184 air routes) compared to the current situations while the average travel length and the average changes in routes were increased up to 13.8% (about 100 km) and up to 18%, respectively. The proposed model also suggests that the current air routes of Iran can be decreased to 24.7% (89 airways) if the travel length and the number of changes increase up to 4.5% (32 km) and 5%, respectively. The simulation results show the potential benefits of the proposed model and the advantages of it. Optimizing the structure of the flight network can significantly reduce operational cost while ensuring the operation safety. According to the results, the multi-objective optimization model is successfully able to precisely design the efficiently optimized airline topologies.",industry
10.1016/j.knosys.2020.106679,Journal,Knowledge-Based Systems,scopus,2021-02-15,sciencedirect,Federated learning for machinery fault diagnosis with dynamic validation and self-supervision,https://api.elsevier.com/content/abstract/scopus_id/85098734354,"Intelligent data-driven machinery fault diagnosis methods have been successfully and popularly developed in the past years. While promising diagnostic performance has been achieved, the existing methods generally require large amounts of high-quality supervised data for training, which are mostly difficult and expensive to collect in real industries. Therefore, it is motivated that the distributed data of multiple clients can be integrated and exploited to build a powerful data-driven model. However, that basically requires data sharing among different users, and is not preferred in most industrial cases due to potential conflict of interests. In order to address the data island problem, a federated learning method for machinery fault diagnosis is proposed in this paper. Model training is locally implemented within each participated client, and a self-supervised learning scheme is proposed to enhance the learning performance. The server aggregates the locally updated models in each training round under the dynamic validation scheme, and a global fault diagnosis model can be established. Only the models are mutually communicated rather than the data, which ensures data privacy among different clients. The experiments on two datasets suggest the proposed method offers a promising approach on confidential decentralized learning.",industry
10.1016/j.abb.2020.108730,Journal,Archives of Biochemistry and Biophysics,scopus,2021-02-15,sciencedirect,Artificial intelligence in the early stages of drug discovery,https://api.elsevier.com/content/abstract/scopus_id/85098095696,"Although the use of computational methods within the pharmaceutical industry is well established, there is an urgent need for new approaches that can improve and optimize the pipeline of drug discovery and development. In spite of the fact that there is no unique solution for this need for innovation, there has recently been a strong interest in the use of Artificial Intelligence for this purpose. As a matter of fact, not only there have been major contributions from the scientific community in this respect, but there has also been a growing partnership between the pharmaceutical industry and Artificial Intelligence companies. Beyond these contributions and efforts there is an underlying question, which we intend to discuss in this review: can the intrinsic difficulties within the drug discovery process be overcome with the implementation of Artificial Intelligence? While this is an open question, in this work we will focus on the advantages that these algorithms provide over the traditional methods in the context of early drug discovery.",industry
10.1016/j.patter.2020.100195,Journal,Patterns,scopus,2021-02-12,sciencedirect,Topic classification of electric vehicle consumer experiences with transformer-based deep learning,https://api.elsevier.com/content/abstract/scopus_id/85100638713,"The transportation sector is a major contributor to greenhouse gas (GHG) emissions and is a driver of adverse health effects globally. Increasingly, government policies have promoted the adoption of electric vehicles (EVs) as a solution to mitigate GHG emissions. However, government analysts have failed to fully utilize consumer data in decisions related to charging infrastructure. This is because a large share of EV data is unstructured text, which presents challenges for data discovery. In this article, we deploy advances in transformer-based deep learning to discover topics of attention in a nationally representative sample of user reviews. We report classification accuracies greater than 91% (F1 scores of 0.83), outperforming previously leading algorithms in this domain. We describe applications of these deep learning models for public policy analysis and large-scale implementation. This capability can boost intelligence for the EV charging market, which is expected to grow to US$27.6 billion by 2027.",industry
10.1016/j.ijepes.2021.107505,Journal,International Journal of Electrical Power and Energy Systems,scopus,2021-02-01,sciencedirect,Global sensitivity analysis for a real-time electricity market forecast by a machine learning approach: A case study of Mexico,https://api.elsevier.com/content/abstract/scopus_id/85113278481,"The study presents the hybridization of global sensitivity analysis with data-driven techniques to evaluate the Mexican electricity market interaction and assess the impact of individual parameters concerning locational marginal prices. The study case pertains to Yucatan, Mexico's electricity grid and market characteristics. A comparison of three artificial intelligence techniques in the electricity market is presented to forecast electricity prices in real-time market conditions. The study contemplates exogenous input parameters classified as regional, operational, meteorological, and economic indicators. A sensitivity analysis was carried out to the model with the best performance of the Artificial Intelligence techniques. The results showed that the impact of the variables fluctuates according to market and consumption conditions. In this study, the most relevant variables were electricity generation (17.06%), fossil fuel costs (natural gas 12.54% and diesel 8.63%), load zone (11.17%), and the day of the year (8.51%). From the qualitative point of view, the complex behavior of the parameters was analyzed; moreover, the quantitative results weighted the relevance of the variables in the Locational Marginal Prices. The meteorological and economic parameters allow assessing the environment where it interacts and serves as an instrument for decision-making in the planning of the energy sector. The presented methodology can be implemented as an alternative tool for market participants to analyze electricity prices.",industry
10.1016/j.jmapro.2020.12.050,Journal,Journal of Manufacturing Processes,scopus,2021-02-01,sciencedirect,Online tool condition monitoring for ultrasonic metal welding via sensor fusion and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85099501543,"In ultrasonic metal welding (UMW), tool wear significantly affects the weld quality and tool maintenance constitutes a substantial part of production cost. Thus, tool condition monitoring (TCM) is crucial for UMW. Despite extensive literature focusing on TCM for other manufacturing processes, limited studies are available on TCM for UMW. Existing TCM methods for UMW require offline high-resolution measurement of tool surface profiles, which leads to undesirable production downtime and delayed decision-making. This paper proposes a completely online TCM system for UMW using sensor fusion and machine learning (ML) techniques. A data acquisition (DAQ) system is designed and implemented to obtain in-situ sensing signals during welding processes. A large feature pool is then extracted from the sensing signals. A subset of features are selected and subsequently used by ML-based classification models. A variety of classification models are trained, validated, and tested using experimental data. The best-performing classification models can achieve close to 100% classification accuracy for both training and test datasets. The proposed TCM system not only provides real-time TCM for UMW but also can support optimal decision-making in tool maintenance. The TCM system can be extended to predict remaining useful life (RUL) of tools and integrated with a controller to adjust welding parameters accordingly.",industry
10.1016/j.antiviral.2020.104998,Journal,Antiviral Research,scopus,2021-02-01,sciencedirect,Infectious bronchitis virus: Identification of Gallus gallus APN high-affinity ligands with antiviral effects,https://api.elsevier.com/content/abstract/scopus_id/85098587922,"Infectious bronchitis virus (IBV) is a coronavirus, causes infectious bronchitis (IB) with high morbidity and mortality, and gives rise to huge economic losses for the poultry industry. Aminopeptidase N (APN) may be one of the IBV functional receptors. In this study, Gallus gallus APN (gAPN) protein was screened by phage-displayed 12-mer peptide library. Two high-affinity peptides H (HDYLYYTFTGNP) and T (TKFSPPSFWYLH) to gAPN protein were selected for in depth characterization of their anti-IBV effects. In vitro, indirect ELISA showed that these two high-affinity ligands could bind IBV S1 antibodies. Quantitative real-time PCR (qRT-PCR) assay, virus yield reduction assay and indirect immunofluorescence assay results revealed 3.125–50 μg/ml of peptide H and 6.25–50 μg/ml of peptide T reduced IBV proliferation in chicken embryo kidney cells (CEKs). In vivo, high-affinity phage-vaccinated chickens were able to induce specific IBV S1 antibodies and IBV neutralizing antibodies. QRT-PCR results confirmed that high-affinity phages reduced virus proliferation in chicken tracheas, lungs and kidneys, and alleviated IBV-induced lesions. By multiple sequence alignment, motif ‘YxYY’ and ‘FxPPxxWxLH’ of high-affinity peptides were identified in IBV S1-NTD, while another motif ‘YxFxGN’ located in S2. These results indicated that high affinity peptides of gAPN could present an alternative approach to IB prevention or treatment.",industry
10.1016/j.psep.2020.12.011,Journal,Process Safety and Environmental Protection,scopus,2021-02-01,sciencedirect,Enhanced spectrum convolutional neural architecture: An intelligent leak detection method for gas pipeline,https://api.elsevier.com/content/abstract/scopus_id/85098537048,"In this work, a novel convolutional neural architecture (SE-CNN), which combines spectrum enhancement (SE) and convolutional neural network (CNN), is proposed to detect the leak of gas pipeline. The SE has the effect of enhancing the leak signals and reducing background noise. CNN can automatically extract leak features and realize leak diagnosis. The experimental results show that the SE-CNN can achieve an average accuracy of 94.3
                        %
                      for 6 categories and only requires 1.04s of detection time. In this experiment, the diameters of the main pipeline and the branch pipeline are 125mm and 25mm. Due to its excellent accuracy and efficiency, the proposed enhanced spectrum convolutional neural architecture paves the way for real-time leak detection in industrial environments, which can ensure the process safety of gas pipeline transportation. Under strong background noise, the average accuracy of the SE-CNN can reach 94.3
                        %
                     , which is 33
                        %
                     , 3.7
                        %
                      higher than that of SVM and CNN. In particular, the SE can be regarded as a data compression method, which can significantly reduce the original data size. The training time of the SE-CNN is 539s, reducing 90.6
                        %
                      compared with CNN.",industry
10.1016/j.micpro.2020.103628,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,Consumer decision-making and smart logistics planning based on FPGA and convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85097718891,"In the fourth Industrial Revolution, cost-effective planning and rational management were the key to the success of the revolution. This paper mainly studies the development and application of models in machine learning technology. The abnormal activities monitored in real time are rectified so that the customer's electronic orders can be displayed through the support of big data, thus laying the foundation for the development of intelligent logistics. Under the data system, an exception model is created and classified and regressed. In this model, the security and stability of customer orders in the network can be automatically detected, and the abnormal data can be analyzed and evaluated. Unusual circumstances of this kind need to be in an intelligent logistics environment, and delivery tasks must be called intuitive for special care. Early detection of abnormal order events is expected to improve the accuracy of delivery planning. To enable new technical solutions, the logistics industry and economic decision-makers often lack the IT background and expertise needed to start developing new systems and technical solutions. Evaluate the benefits of using. Implementation and integration complexity is seen as one of the three major obstacles to the success of the IoT above. This is by hindering long-term investment in new technologies from slowing down digitization.",industry
10.1016/j.micpro.2020.103594,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,Enterprise financial risk management platform based on 5 G mobile communication and embedded system,https://api.elsevier.com/content/abstract/scopus_id/85097578772,"5 G technology has been applied to the financial sector. As a mortgage and supervision of sensors, network cameras, mobile device to improve the financial performance of real-time data generated by the data, bank loan credit risk management has been used. There are many risks of financial credit in modern society, the most important of which is the financial danger on mobile Internet. In the case of mobile phone payment popularity, financial risk has also greatly improved. This makes the traditional statistics and models can not fully meet the needs of the development of modern society. Bank credit risk has also improved to some extent. Therefore, there is a practical need for a more robust risk prediction model of artificial intelligence to predict the default behavior with good accuracy and competency-based big data analytics. This paper presents data mining method optimization and 5 G mobile communications and embedded systems commercial banks, based on financial risk management. It is safe to protect personal privacy, consider these requirements 5 G system design. To successfully connect to the ability to make money, telecom service providers need to ask their players to match their products and the industry. In addition to simple connections, they need a unified high-level function, such as coordination of network resources, analytical capabilities, and automated business and operations. Mob ileum provides Business Assurance Analytics to improve and develop a strong customer value proposition during 5 G technologies deployment. Experimental results show that the risk management models have fast convergence, powerful forecasting capabilities, and effectively perform screening default behavior. Simultaneously, distributed significant data clusters to achieve significantly reduce the processing time model training and testing.",industry
10.1016/j.apenergy.2020.116049,Journal,Applied Energy,scopus,2021-02-01,sciencedirect,Adaptive prognostics in a controlled energy conversion process based on long- and short-term predictors,https://api.elsevier.com/content/abstract/scopus_id/85097470918,"The pulp and paper industry is a fundamental sector of the economy of many countries. However, this sector requires real collaboration and initiatives from stakeholders to reduce its significant consumption of energy and emission of greenhouse gases. Heat exchangers are examples of equipment in pulp mills that are subjected to undesirable and complex phenomena such as evolution of fouling over time, which leads to inefficiency in terms of energy consumption and unplanned shutdowns, resulting in ineffective maintenance strategies and production costs. Therefore, there is a clear need to develop an accurate predictive maintenance tool that helps mill operators avoid such situations. It is necessary for that tool to effectively track the fouling evolution level and, based on it, deploy a reliable prognostics approach to estimate more accurately the time-to-clean of this equipment. This study presents a new hybrid prognostics approach for fouling prediction in heat exchangers. The proposed approach relies on the fusion of information of different prediction horizons to estimate the time-to-clean. Employing long short-term memory, it allows adaptation of long-term predictions by accurate short-term predictions using multiple non-linear auto-regressive exogenous models. This fusion not only captures the changes in degradation trend over time, but also ensures a good accuracy of prognostics results in both the short- and long-term horizons for planning maintenance actions. The effectiveness of the proposed approach was successfully proven on real industrial data collected from a pulp mill heat exchanger located in Canada.",industry
10.1016/j.apenergy.2020.116297,Journal,Applied Energy,scopus,2021-02-01,sciencedirect,An Echo State Network for fuel cell lifetime prediction under a dynamic micro-cogeneration load profile,https://api.elsevier.com/content/abstract/scopus_id/85097452614,"Improving Proton Exchange Membrane Fuel Cell durability is a key that paves the way to its large scale industrial deployment. During the last five years, the prognostics discipline emerged as an interesting field for Proton Exchange Membrane Fuel Cell state of health prediction and lifetime estimation. The information provided by the prognostic module is crucial for optimizing the control strategy to extend the fuel cell lifetime. In this paper, an approach based on Echo State Network for fuel cell prognostics under a variable load is developed. The novelty of this paper is to perform prognostics under a variable load profile without prior knowledge of this latter. Two solutions are developed in this work. The first one consists of evaluating the remaining useful lifetime under a repeated load cycle. The second one is based on using Markov chains to generate estimations of the future load profile, allowing thus to overcome the need of real future load profile prior knowledge. Both proposed solutions give accurate prediction results of proton exchange membrane fuel cell remaining useful lifetime, with low uncertainties.",industry
10.1016/j.micpro.2020.103301,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,IoT enabled cancer prediction system to enhance the authentication and security using cloud computing,https://api.elsevier.com/content/abstract/scopus_id/85094168107,"In recent days, Internet of Things, Cloud Computing, Deep learning, Machine learning and Artificial Intelligence are considered to be an emerging technologies to solve variety of real world problems. These techniques are importantly applied in various fields such as healthcare systems, transportation systems, agriculture and smart cities to produce fruitful results for number of issues in today's environment. This research work focuses on one such application in the field of IoT together with cloud computing. More number of sensors that are deployed in human body is used to collect patient related data such as deviation in body temperature and others which leads to variation in blood cells that turned to be cancerous cells. Main intention of this work is design a cancer prediction system using Internet of Things upon extracting the details of blood results to test whether it is normal or abnormal. In addition to this, encryption is done on the blood results of cancer affected patient and store it in cloud for quick reference through Internet for the doctor or healthcare nurse to handle the patient data secretly. This research work concentrates on enhancing the health care computations and processing. It provides a framework to enhance the performance of the existing health care industry across the globe. As the entire medical data has to be saved in cloud, the traditional medical treatment limitations can be overcome. Encryption and decryption is done using AES algorithm in order to provide authentication and security in handling cancer patients. The main focus is to handle healthcare data effectively for the patient when they are away from the home town since the needed cancer treatment details are stored in cloud. The task completion time is greatly reduce from 400 to 160  by using VMs. CloudSim gives an adaptable simulation structure that empowers displaying and reproduced results.",industry
10.1016/j.petrol.2020.107879,Journal,Journal of Petroleum Science and Engineering,scopus,2021-02-01,sciencedirect,Fault detection and classification in oil wells and production/service lines using random forest,https://api.elsevier.com/content/abstract/scopus_id/85093923819,"This papers deals with the automatic detection and classification of faulty events during the practical operation of oil and gas wells and lines. The events considered here are part of the publicly available 3W database developed by Petrobras, the Brazilian oil holding. Seven fault classes are considered, with distinct dynamics and patterns, as well as several instances of normal operation. A random forest classifier is employed with different statistical measures to identify each fault type. Three experiments are devised in order to evaluate the system performance in distinct classification scenarios. An accuracy rate of 94% indicates a successful performance for the proposed system in detecting real events. Also, the system’s time of detection was on average 12% of the transient period that precedes the fault steady-state.",industry
10.1016/j.isatra.2020.08.024,Journal,ISA Transactions,scopus,2021-02-01,sciencedirect,Data-driven adaptive modeling method for industrial processes and its application in flotation reagent control,https://api.elsevier.com/content/abstract/scopus_id/85089898141,"In real industrial processes, new process “excitation” patterns that largely deviate from previously collected training data will appear due to disturbances caused by process inputs. To reduce model mismatch, it is important for a data-driven process model to adapt to new process “excitation” patterns. Although efforts have been devoted to developing adaptive process models to deal with this problem, few studies have attempted to develop an adaptive process model that can incrementally learn new process “excitation” patterns without performance degradation on old patterns. In this study, efforts are devoted to enabling data-driven process models with incremental learning ability. First, a novel incremental learning method is proposed for process model updating. Second, an adaptive neural network process model is developed based on the novel incremental learning method. Third, a nonlinear model predictive control based on the adaptive process model is implemented and applied for flotation reagent control. Experiments based on historical data provide evidence that the newly developed adaptive process model can accommodate new process “excitation” patterns and preserve its performance on old patterns. Furthermore, industry experiments carried out in a real-world lead–zinc froth flotation plant provide industrial evidence and show that the newly designed controller is promising for practical flotation reagent control.",industry
10.1016/j.rcim.2020.102029,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-02-01,sciencedirect,Towards manufacturing robotics accuracy degradation assessment: A vision-based data-driven implementation,https://api.elsevier.com/content/abstract/scopus_id/85088120602,"In this manuscript we report on a vision-based data-driven methodology for industrial robot health assessment. We provide an experimental evidence of the usefulness of our methodology on a system comprised of a 6-axis industrial robot, two monocular cameras and five binary squared fiducial markers. The fiducial marker system permits to accurately track the deviation of the end-effector along a fixed non-trivial trajectory. Moreover, we monitor the trajectory deflection using three gradually increasing weights attached to the end-effector. When the robot is loaded with the maximum allowed payload, a deviation of 0.77mm is identified in the Z-coordinate of the end-effector. Tracing trajectory information, we train five supervised learning regression models. Such models are afterwards used to predict the deviation of the end-effector, using the pose estimation provided by the visual tracking system. As a result of this study, we show that this procedure is a stable, robust, rigorous and reliable tool for robot trajectory deviation estimation and it even allows to identify the mechanical element producing non-kinematic errors.",industry
10.1016/j.chroma.2020.461855,Journal,Journal of Chromatography A,scopus,2021-01-25,sciencedirect,Model-assisted approaches for continuous chromatography: Current situation and challenges,https://api.elsevier.com/content/abstract/scopus_id/85099136409,"Continuous bioprocessing is a promising trend in biopharmaceutical production, and multi-column continuous chromatography shows advantages of high productivity, high resin capacity utilization, small footprint, low buffer consumption and less waste. Due to the complexity and dynamic nature of continuous processing, traditional experiment-based approaches are often time-consuming and inefficient. In this review, model-assisted approaches were focused and their applications in continuous chromatography process development, validation and control were discussed. Chromatographic models are useful in describing particular process performances of continuous capture and polishing with multi-column chromatography. Model-assisted tools showed powerful ability in evaluating multiple operating parameters and identifying optimal points over the entire design space. The residence time distribution models, model-assisted process analytical technologies and model-predictive control strategies were also developed to reveal the propagation of disturbances, enhance real time monitor and achieve adaptive control to match the transient disturbances and deviations of continuous processes. Moreover, artificial neural networks and machine learning concepts were integrated into modeling approaches to improve data treatment. In general, further development in research and applications of model-assisted approaches for continuous chromatography are needed urgently to support the continuous manufacturing.",industry
10.1016/j.jclepro.2020.124348,Journal,Journal of Cleaner Production,scopus,2021-01-20,sciencedirect,Acoustic emission and machine learning for in situ monitoring of a gold–copper ore weakening by electric pulse,https://api.elsevier.com/content/abstract/scopus_id/85092897110,"The excessive energy consumption from the mining industry are currently receiving international attention. A promising method able to enhance significantly the comminution process efficiency worldwide is by using electric pulse fragmentation treatment. However, to insure a minimum energy consumption in real scale operation, an online process monitoring is of utmost importance. This work presents an in situ and real-time monitoring method by combining acoustic emission sensor and advanced machine learning algorithms. The proposed method was developed on a gold-copper ore in well-controlled single stone experiments and in semi-continuous process, reproducing a real industrial environment. In single stone experiment, the pulse energies was varied from 200 to 750 J leading to three weakening behaviours; no discharge, surface discharge and fragmentation. Acoustic signals for these categories have been decomposed with wavelet packets, and sub-band energies have been chosen as features. Then, only the most informative features were selected via standard linear principal component analysis. Finally, the classification was performed via a traditional support vector machine. In the semi-continuous experiments, an unsupervised learning method was used for classification task based on Laplacian support vector machine. Results for single stone tests showed accuracy above 90% for the three categories. For semi-continuous tests, we demonstrated that the unsupervised classification can be applied efficiently to estimate the amount of weakening of the passed through ore. We are very confident that the proposed method can be easily industrialised to monitor in situ and in real-time the electric discharge process within a comminution operation.",industry
10.1016/j.snb.2020.128921,Journal,"Sensors and Actuators, B: Chemical",scopus,2021-01-15,sciencedirect,"Validation of the rapid detection approach for enhancing the electronic nose systems performance, using different deep learning models and support vector machines",https://api.elsevier.com/content/abstract/scopus_id/85091747374,"Real-time gas classification is an essential issue and challenge in applications such as food and beverage quality control, accident prevention in industrial environments, for instance. In recent years, the Deep Learning (DL) models have shown great potential to classify and forecast data in diverse problems, even in the electronic nose (E-Nose) field. In this work, a Support Vector Machine (SVM) algorithm and three different DL models were used to validate the rapid detection approach (based on processing an early portion of raw signals and a rising window protocol) over diverse measurement conditions. We performed a set of experiments with five different E-Nose databases, including fifteen datasets to be used with these algorithms. Based on the obtained results, we concluded that the proposed approach has a high potential and reduces the response time for making E-nose forecasts. Because in more than 60 % of the cases, it achieved reliable estimates using only the first 30 % or fewer of measurement data (counted after the gas injection starts). The findings suggest that the rapid detection approach generates reliable forecasting models using different classification methods. Moreover, SVM seems to achieve the best accuracy and better training time.",industry
10.1016/j.saa.2021.120534,Journal,Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy,scopus,2021-01-01,sciencedirect,SERS Detection of Benzoic Acid in Milk by Using Ag-COF SERS Substrate,https://api.elsevier.com/content/abstract/scopus_id/85118982830,"Benzoic acid, which has a pivotal role in food additive, is prohibited to add as a preservative in dairy products. China, Brazil, and other countries have proposed standard methods to detect the addition of benzoic acid in food. Surface-enhanced Raman scattering (SERS) is an upcoming spectral detection technique, which has been widely used in the field of material analysis with the advantages of non-invasive, fast detection speed and complex environment with little interference. To detect the illegal use of benzoic acid in dairy industry, we developed Ag-COF (covalent-organic framework) material as SERS substrate to detect benzoic acid in liquid milk. The great enhancement ability of Ag-COF substrate is controlled by the addition of acetic acid and complex interplay between COF material and benzoic acid. This detection method has high sensitivity and reliability that allows us to achieve limit of detection (LOD) of 0.13 μg/mL in milk and 0.00372 μg/mL in water by applying this method. In experiment on recovery rate of real samples, the detection time is less than 15 minutes and the relative standard deviation (RSD) ranged from 2.82% to 5.69%. Therefore, this method has practical significance of the detection of benzoic acid in dairy products.",industry
10.1016/j.apenergy.2021.118127,Journal,Applied Energy,scopus,2021-01-01,sciencedirect,Data-driven control of room temperature and bidirectional EV charging using deep reinforcement learning: Simulations and experiments,https://api.elsevier.com/content/abstract/scopus_id/85118721393,"The control of modern buildings is a complex multi-loop problem due to the integration of renewable energy generation, storage devices, and electric vehicles (EVs). Additionally, it is a complex multi-criteria problem due to the need to optimize overall energy use while satisfying users’ comfort. Both conventional rule-based (RB) controllers, which are difficult to apply in multi-loop settings, and advanced model-based controllers, which require an accurate building model, cannot fulfil the requirements of the building automation industry to solve this problem optimally at low development and commissioning costs. This work presents a fully data-driven pipeline to obtain an optimal control policy from historical building and weather data, thus avoiding the need for complex physics-based modelling. We demonstrate the potential of this method by jointly controlling a room temperature and an EV to minimize the cost of electricity while retaining the comfort of the occupants. We model the room temperature with a recurrent neural network and use it as a simulation environment to learn a deep reinforcement learning (DRL) control policy. It achieves on average 17% energy savings and 19% better comfort satisfaction than a standard RB room temperature controller. When a bidirectional EV is connected additionally and a two-tariff electricity pricing is applied, it successfully leverages the battery and decreases the overall cost of electricity. Finally, we deployed it on a real building, where it achieved up to 30% energy savings while maintaining similar comfort levels compared to a conventional RB room temperature controller.",industry
10.1016/j.promfg.2021.06.086,Conference Proceeding,Procedia Manufacturing,scopus,2021-01-01,sciencedirect,Pervasive environmental sensing for Industry 4.0 as an educational tool,https://api.elsevier.com/content/abstract/scopus_id/85117930435,"The reduced cost of implementing pervasive industrial sensing networks enables universities to incorporate these tools in engineering curricula. They provide engineering students from increasingly computerized backgrounds, such as mechanical and automotive engineering, the opportunity to work alongside students from technical schools who bring different skill sets than what students may be used to, synthesize historical data, and drive the sensing system’s physical system design and implementation. This paper outlines this convergent curriculum’s initial implementation stage, including the wireless environmental sensing Internet of Things (IoT) network, focusing on laboratory environmental sensing. Students placing many sensors around the lab and on equipment generates a wealth of real-time and historical data for use in the classroom and provides them a tangible example of learning to measure the world around them. This setup parallels the current varied Industry 4.0 state of the manufacturing industry, where Big Data exists but is underutilized, and where additional sensors and intelligent machine data streams are added each year. Students in each class are given a defined portion of a broader roadmap to a fully instrumented and intelligent laboratory environment. In the first step, student-programmed environmental sensors were placed around the lab and provide temperature, humidity, pressure, and gas mixture measures every five minutes. Classroom use of the aggregated data includes visualizing the laboratory and essential equipment’s current status using a Microsoft PowerBI dashboard and historical data visualization and analysis through trend forecasting and outlier detection in Python JupyterLab notebooks. The IoT system’s installation also provided an infrastructure for further study of future student-designed IoT projects.",industry
10.1016/j.promfg.2021.06.070,Conference Proceeding,Procedia Manufacturing,scopus,2021-01-01,sciencedirect,Efficient manufacturing processes and performance qualification via active learning: Application to a cylindrical plunge grinding platform,https://api.elsevier.com/content/abstract/scopus_id/85117918696,"The industry invests significant resources towards qualification of its individual processes and machines to assure quality and productivity of the process chain. Process qualification traditionally involves employing elaborate experimental methods to find the response surface mapping the response to various process parameters and measurements. Most of the existing methods are passive experimental designs which take into account the limits of the parameter space and a design method (CCD, Taguchi, orthogonal etc.) to identify the points in the parameter space. More often than not, these methods need a lot of experiments to be conducted and do not take into account how the response changes with each experiment. Also, the number of experiments increase combinatorically to get a desired estimate of the response surface. The formulation of mathematical models for complex, high dimensional, inherently nonstationary, and stochastic systems like abrasive machining process and also catering to the process-machine interactions is challenging. In this work, to address the other alternative for cost-effective experimentation: we adapt a Query by Committee (QBC) based active learning approach where we sequentially find the next best experimental point to reduce the uncertainty of prediction of surface roughness over the sample space. The method uses a carefully curated list of committee members, (i.e., models) which predict the response surface at each instant and selects the next experimental point based on a metric called prediction deviation. We used a real-world dataset from a cylindrical plunge grinding platform to test if the QBC approach performs better than a passive CCD design. The machine tool used is the next generation precision grinder (NGPG) from IIT Madras which is capable to finishing components to an IT3 tolerance grade. We compared the QBC based active learning model to a previous random forest model built on a dataset which gave a test accuracy (R
                     2) of 85% using 178 experimental points. It is demonstrated that similar prediction accuracies can be achieved by reducing the number of experiments by about 65%. The merits of the model in the choice of the members of the committee and the advantage of the current experimental design compared to random experimentation were presented.",industry
10.1016/j.orp.2021.100204,Journal,Operations Research Perspectives,scopus,2021-01-01,sciencedirect,A review of approximate dynamic programming applications within military operations research,https://api.elsevier.com/content/abstract/scopus_id/85117385700,"Sequences of decisions that occur under uncertainty arise in a variety of settings, including transportation, communication networks, finance, defence, etc. The classic approach to find an optimal decision policy for a sequential decision problem is dynamic programming; however its usefulness is limited due to the curse of dimensionality and the curse of modelling, and thus many real-world applications require an alternative approach. Within operations research, over the last 25 years the use of Approximate Dynamic Programming (ADP), known as reinforcement learning in many disciplines, to solve these types of problems has increased in popularity. These efforts have resulted in the successful deployment of ADP-generated decision policies for driver scheduling in the trucking industry, locomotive planning and management, and managing high-value spare parts in manufacturing. In this article we present the first review of applications of ADP within a defence context, specifically focusing on those which provide decision support to military or civilian leadership. This article’s main contributions are twofold. First, we review 18 decision support applications, spanning the spectrum of force development, generation, and employment, that use an ADP-based strategy and for each highlight how its ADP algorithm was designed, evaluated, and the results achieved. Second, based on the trends and gaps identified we discuss five topics relevant to applying ADP to decision support problems within defence: the classes of problems studied; best practices to evaluate ADP-generated policies; advantages of designing policies that are incremental versus complete overhauls when compared to currently practiced policies; the robustness of policies as scenarios change, such as a shift from high to low intensity conflict; and sequential decision problems not yet studied within defence that may benefit from ADP.",industry
10.1016/j.procs.2021.08.095,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,SODA: A real-time simulation framework for object detection and analysis in smart manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85116946450,"For modern manufacturing firms, automation has already become a norm but constantly needs to be improved as firms still face strong demand to increase their productivity. This can be achieved by reducing dependability on manpower, reaching lean and even unmanned production and this is where some of the standards of Industry 4.0 come in useful, not to mention: Machine Vision, Image Recognition or Machine Learning. In our paper, we present SODA – our approach to build a flexible ML and AI enabled framework for object detection, analysis, and simulation. The framework is designed to support a development process of solutions requiring real-time analysis of images of different types of moving objects on a conveyor belt. In our work we discuss architectural challenges of the developed framework as well as the basic components of the system. We do also provide information on how to use the framework and present a sample implementation of an actual system employing some of the machine learning methods.",industry
10.1016/j.procs.2021.09.013,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Exploiting supervised machine learning for driver detection in a real-world environment,https://api.elsevier.com/content/abstract/scopus_id/85116888149,"The proliferation of info-entertainment systems in today’s vehicles has provided a really cheap and easy-to-deploy platform with the ability to gather information about the vehicle under analysis. Ultra-response connectivity networks with a latency below 10 milliseconds are providing the perfect infrastructure in which this information can be sent to improve safety and security. With the purpose of providing an architecture to increase safety and security in an automotive context, we in this paper propose a method for detecting the driver in real-time exploiting supervised machine learning techniques. The experimental analysis performed on real-world data shows that the proposed method obtains encouraging results.",industry
10.1016/j.procs.2021.09.233,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,A note on the applications of artificial intelligence in the hospitality industry: Preliminary results of a survey,https://api.elsevier.com/content/abstract/scopus_id/85116885410,"Intelligent technologies are widely implemented in different areas of modern society but specific approaches should be applied in services. Basic relationships refer to supporting customers and people responsible for services offering for these customers. The aim of the paper is to analyze and evaluate the state-of-the art of artificial intelligence (AI) applications in the hospitality industry. Our findings show that the major deployments concern in-person customer services, chatbots and messaging tools, business intelligence tools powered by machine learning, and virtual reality & augmented reality. Moreover, we performed a survey (n = 178), asking respondents about their perceptions and attitudes toward AI, including its implementation within a hotel space. The paper attempts to discuss how the hotel industry can be motivated by potential customers to apply selected AI solutions. In our opinion, these results provide useful insights for understanding the phenomenon under investigation. Nevertheless, since the results are not conclusive, more research is still needed on this topic. Future studies may concern both qualitative and quantitative methods, devoted to developing models that: a) quantify the potential benefits and risks of AI implementations, b) determine and evaluate the factors affecting the AI adoption by the customers, and c) measure the user (guest) experience of the hotel services, fueled by AI-based technologies.",industry
10.1016/j.matpr.2021.03.109,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Real-time applications and novel manufacturing strategies of incremental forming: An industrial perspective,https://api.elsevier.com/content/abstract/scopus_id/85114180763,"Incremental Sheet-Metal Forming (ISMF) is a flexible and evolving metal forming technology for rapid free-form prototyping and small-batch metal components manufacturing. The end product has evolved by means of localized deformation in addition bi-axial stretching during that deforming tool squeezed on blank with predefined process variables. Owing to a unique process advantages and low manufacturing cost, its market requirement continuous enlargement and the process gradually transforms from prototyping to real-time manufacturing perspective. Over the preceding decades, ISMF technology has been adequately established in research and development, although it is less explored in the real-time industrial environment. The main intention of this exploration is to bring-forth insight into potential applications such as aviation, automotive, bio-medical, research and concept development through implementation of ISMF. Further, component evaluation performed to establish a convenient and feasible solution from deep-drawing and hydro-forming. For customized part forming, conventional forming process seems to be insufficient. Due to industrial transformation, dependent on cost-effectiveness, even prototyping and low-volume manufactured components relying on superior quality. Although, understanding the effect and influence of process variable, which needs the data analysis with implementing the optimization models and Artificial neural-network (ANN) model. These types of analysis majorly focus on monitoring and predict target values at each cycle and also reconfigure to optimistic or organize the iterative method for describing the appropriate process guidelines. Further, recent advances in ISMF process variants are explored, while looking at the benefits of ISMF for real-time part production. ISMF continues to mature into technology for production applications, while exploring the potential field to transform the way sheet components are fabricated in the new-era of digital manufacturing. This study will, in turn, enhance the capabilities of ISMF technology, which has grown significantly over the preceding decades, allowing technology adopters to innovate new design principle and achieve greater production flexibility.",industry
10.1016/j.dss.2021.113653,Journal,Decision Support Systems,scopus,2021-01-01,sciencedirect,AI-based industrial full-service offerings: A model for payment structure selection considering predictive power,https://api.elsevier.com/content/abstract/scopus_id/85114151068,"Artificial Intelligence and servitization reshape the way that manufacturing companies derive value. Aiming to sustain competitive advantage and intensify customer loyalty, full-service providers offer the use of their products as a service to achieve continuous revenues. For this purpose, companies implement AI classification algorithms to enable high levels of service at controllable costs. However, traditional asset sellers who become service providers require previously atypical payment structures, as classic payment methods involving a one-time fee for production costs and profit margins are unsuitable. In addition, a low predictive power of the implemented classification algorithm can lead to misclassifications, which diminish the achievable level of service and the intended net present value of the resultant service. While previous works focus solely on the costs of such misclassifications, our decision model highlights implications for payment structures, service levels, and – ultimately – the net present value of such data-driven service offerings. Our research suggests that predictive power can be a major factor in selecting a suitable payment structure and the overall design of service level agreements. Therefore, we compare common payment structures for data-driven services and investigate their relationship to predictive power. We develop our model using a design science methodology and iteratively evaluate our results using a four-step approach that includes interviews with industry experts and the application of our model to a real-world use case. In summary, our research extends the existing knowledge of servitization and data-driven services in the manufacturing industry through a quantitative decision model.",industry
10.1016/j.matpr.2021.03.658,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Predictive analytics as a service for vehicle health monitoring using edge computing and AK-NN algorithm,https://api.elsevier.com/content/abstract/scopus_id/85114146905,"Smart logistics is a part of Industry 4.0. With the increased development of the technology in the vehicle industry, the machine learning algorithms are applied on sensor data in order to detect the failure of the components of the vehicle. Several systems for vehicle health monitoring are presented in the literature for delivery of services in real-time. The sensor values obtained from the cloud are processed with machine learning algorithms, but have problem with delay in execution and data center failure. Edge computing is introduced in recent years so that intensive operations are performed at the edge of the device than at the cloud. This paper presents edge computing based fault prediction system that will predict vehicle health using internal and external sensors in real-time. Risk details are displayed through a mobile application in the form of notifications as well as a dashboard at the terminal. Such a system reduces latency between sending and processing vehicle data. The proposed system uses ensemble of ANN and k-NN classifiers named as AK-NN so as to improve prediction performance. In the first step, ANN is trained and validated on the Chevrolet car OBD dataset. Error reported from this best trained network is used by k-NN for statistical analysis of the error distributions. Three different experiments based on ANN, k-NN and AK-NN are made and evaluated using NRMSE, COD, cross entropy loss, accuracy and ROC measures. 85% accuracy for k-NN model when k = 3, 78% accuracy using ANN and 98.7% for ensemble method are achieved. Comparative study using key performance indicators such as Mean time between failure (MTBF) and Mean time to Repair (MTTR) is also made on 84 vehicles for prediction alert over mobile phone using analytical dashboard and proved to reach availability objective.",industry
10.1016/B978-0-323-88506-5.50132-7,Book Series,Computer Aided Chemical Engineering,scopus,2021-01-01,sciencedirect,Implementation of first-principles surface interactions in a hybrid machine learning assisted modelling of flocculation,https://api.elsevier.com/content/abstract/scopus_id/85110537894,"Machine learning algorithms are drawing attention for modelling processes in the chemical and biochemical industries. Due to a lack of fundamental understanding of complex processes and a lack of reliable real-time measurement methods in bio-based manufacturing, machine learning approaches have become more important. Hybrid modelling approaches that combine detailed process understanding with machine learning can provide an opportunity to integrate prior process knowledge with various measurement data for efficient modelling of the (bio) chemical processes. In this study, the application of a hybrid modelling framework that combines various first-principles models with machine learning algorithms is demonstrated through a laboratory-scale case of flocculation of silica particles in water. Since flocculation is a process that occurs across length- and time scales, an integrated hybrid multi-scale modelling framework can improve the phenomenological understanding of the process. The first-principles models utilized in this study are molecular scale particle surface interaction models such as combined with a larger-scale population balance model.",industry
10.1016/B978-0-323-88506-5.50161-3,Book Series,Computer Aided Chemical Engineering,scopus,2021-01-01,sciencedirect,Artificial Intelligence Based Prediction of Exergetic Efficiency of a Blast Furnace,https://api.elsevier.com/content/abstract/scopus_id/85110444162,"The iron melting furnaces are the most energy-consuming equipment of the iron and steel industry. The energy efficiency of the furnace is affected by process conditions such as the inlet temperature, velocity of the charge, and its composition. Hence, optimum values of these process conditions are vital in the efficient operation of the furnace. Computational methods have been very helpful in the optimum design and operation of process equipment. In this study, a first principle (FP) model was developed for an iron-making furnace to visualize its internal dynamics. To minimize the large computational time required for the FP-based analysis, a data-based model, i.e., Artificial Neural Networks (ANN), is developed using data extracted from the FP model. The ANN model was developed using data sets comprised of the values of temperature of the charge and gasses, velocity, concentration of the oxygen, pressure, airflow directions, energy and exergy profiles, and overall exergy efficiency of the furnace along with its height. The ANN model was highly accurate in prediction and is suitable for real-time implementation in a steel manufacturing plant.",industry
10.1016/B978-0-323-88506-5.50144-3,Book Series,Computer Aided Chemical Engineering,scopus,2021-01-01,sciencedirect,Machine learning-based approach to identify the optimal design and operation condition of organic solvent nanofiltration (OSN),https://api.elsevier.com/content/abstract/scopus_id/85110354404,"Organic solvent nanofiltration (OSN) is one of the most anticipated separation technologies that provides wide-ranged industrial applications such as solvent recovery, solute concentration, and diluent separation. Despite of technical merits of the OSN technology, the numerous characteristics and perplexing nonlinearity on the OSN system have been a critical obstacle for understanding the governing principles, thereby prohibiting practical deployments. Recently, machine learning (ML) based approaches have been widely used for the modelling, discovery and optimization of complex design problems in chemical engineering area such as catalysis, electrochemistry and physicochemical systems. Therefore, this study aims to develop a new ML-based approach for modelling and optimizing the design scheme and operating condition of the OSN system. By collecting commercial OSN data through literatures reviews, the major descriptors for the prediction of the OSN membrane, such as MWCO, solute mole weight, solute concentration, solvent parameter, temperature, pressure, flux, were defined. We then screened noises and outliers of the collected data to ensure a high and consistent density and uniqueness. Support vector machine (SVM) was implemented as a prediction models to simulate the OSN performance and identify the optimal conditions as well as the process scheme. As a result, the optimal operation strategies (i.e., pressure, temperature and solvent and solvent types) were analyzed to meet the targeted specification of the OSN system (mass flux and rejection rate). The proposed ML-based approach can promote a real-world OSN application by reducing a number of time-consuming and expensive experiments for establishing OSN design and operation strategy.",industry
10.1016/B978-0-323-88506-5.50194-7,Book Series,Computer Aided Chemical Engineering,scopus,2021-01-01,sciencedirect,Attack Detection Using Unsupervised Learning Algorithms in Cyber-Physical Systems,https://api.elsevier.com/content/abstract/scopus_id/85110277992,"Cyber-Physical Systems (CPS) are collections of physical and computer components that are integrated with each other to operate a process safely and efficiently. Examples of CPS include industrial control systems, water systems, robotics systems, smart grid, etc. However, the security aspect of CPS is still a concern that makes them vulnerable to cyber attacks on the control elements, network or physical systems. The work reported here is an attempt towards detecting cyber attacks and improving process monitoring in CPS; using unsupervised machine learning anomaly detection algorithms such as one-class SVM, isolation forest, elliptic envelope. These algorithms are evaluated using the dataset of a real Water Distribution Plant (WADI) built at the iTrust centre at Singapore University of Technology and Design for cyber security research. For modelling purposes, process 1 and 2 of the aforementioned plant were taken into consideration because the implemented attacks were closely related to only these sub-processes. The result of the experiment shows that one-class SVM is found to be the most effective algorithm in determining anomalies for this particular dataset.",industry
10.1016/j.jfoodeng.2021.110732,Journal,Journal of Food Engineering,scopus,2021-01-01,sciencedirect,A simplified modelling approach for predicting shrinkage and sensitive material properties during low temperature air drying of porous food materials,https://api.elsevier.com/content/abstract/scopus_id/85108981426,"Many food materials are dried to enhance shelf-life. Drying is an energy-intensive process, and accurate drying models could be used in real time process control of drying equipment to drive cost optimizations. However, most physics-based models suffer from two shortcomings: they require thermo-physical properties of the food materials to be known a priori, and they usually neglect material shrinkage due to moisture loss. In this work, we first develop a simplified physics-based transport model to predict temperatures and moisture content and corresponding spatial and temporal shrinkage during low temperature air drying process, where volumetric shrinkage is dominated by moisture loss. This model agrees well with experiments conducted by us (reported in this paper) as well as with those conducted by others (taken from the literature) on food samples. Further, using the validated modelling framework, we have developed an experimentally validated deep learning-based artificial neural network (ANN) model for properties' estimation. This ANN model is designed to estimate solid density, initial porosity, and initial water saturation of a given food material, using temperature and moisture data from a set of simple experiments with error less than 1%. Using these predicted parameters as input, the physics-based model can predict temperature and moisture for real-time drying to within 5% accuracy. The method proposed in this work could play an important role in industrial drying process optimisation and will find wide applications in the food processing industry.",industry
10.1016/j.isatra.2021.06.010,Journal,ISA Transactions,scopus,2021-01-01,sciencedirect,A real-world application of Markov chain Monte Carlo method for Bayesian trajectory control of a robotic manipulator,https://api.elsevier.com/content/abstract/scopus_id/85108508566,"Reinforcement learning methods are being applied to control problems in robotics domain. These algorithms are well suited for dealing with the continuous large scale state spaces in robotics field. Even though policy search methods related to stochastic gradient optimization algorithms have become a successful candidate for coping with challenging robotics and control problems in recent years, they may become unstable when abrupt variations occur in gradient computations. Moreover, they may end up with a locally optimal solution. To avoid these disadvantages, a Markov chain Monte Carlo (MCMC) algorithm for policy learning under the RL configuration is proposed. The policy space is explored in a non-contiguous manner such that higher reward regions have a higher probability of being visited. The proposed algorithm is applied in a risk-sensitive setting where the reward structure is multiplicative. Our method has the advantages of being model-free and gradient-free, as well as being suitable for real-world implementation. The merits of the proposed algorithm are shown with experimental evaluations on a 2-Degree of Freedom robot arm. The experiments demonstrate that it can perform a thorough policy space search while maintaining adequate control performance and can learn a complex trajectory control task within a small finite number of iteration steps.",industry
10.1016/j.cirp.2021.04.046,Journal,CIRP Annals,scopus,2021-01-01,sciencedirect,Semi-Double-loop machine learning based CPS approach for predictive maintenance in manufacturing system based on machine status indications,https://api.elsevier.com/content/abstract/scopus_id/85108064671,"The paper presents two original and innovative contributions: 1) the model of machine learning (ML) based approach for predictive maintenance in manufacturing system based on machine status indications only, and 2) semi-Double-loop machine learning based intelligent Cyber-Physical System (I-CPS) architecture as a higher-level environment for ML based predictive maintenance execution. Considering only the machine status information provides rapid and very low investment-based implementation of an advanced predictive maintenance paradigm, especially important for SMEs. The model is validated in real-life situations, exploring different learning algorithms and strategies for learning maintenance predictive models. The findings show very high level of prediction accuracy.",industry
10.1016/j.procir.2021.05.031,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Artificial intelligence enhanced interaction in digital twin shop-floor,https://api.elsevier.com/content/abstract/scopus_id/85107885361,"As an enabling technology for smart manufacturing, digital twin has been widely applied in manufacturing shop-floor. A great deal of research focuses on the key issues in implementing digital twin shop-floor (DTS), including scheduling, production planning, fault diagnosis and prognostics. However, DTS puts forward higher requirements in terms of real-time interaction. Artificial intelligence (AI), as an effective approach to improve the intelligence of the physical shop-floor, provides a new method to meet the above requirements. In this paper, a framework of AI-enhanced DTS in interaction is proposed. AI-enhanced DTS improves the real-time interaction through predictive control. The implementation mechanism of AI-enhanced interaction in DTS is also presented in detail. Enabling technologies for interaction in DTS are introduced at last.",industry
10.1016/j.procs.2021.03.074,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Requirements towards optimizing analytics in industrial processes,https://api.elsevier.com/content/abstract/scopus_id/85106735396,"Modern production systems are composed of complex manufacturing processes with highly technology specific cause-effect relationships. Developments in sensor technology and computational science allow for data-driven decision making that facilitate effcient and objective production management. However, process data may only be beneficial if it is enriched with meta information and process expertise, reduced to relevant information and modelling results interpreted correctly. The importance of data integration in the heterogeneous industrial environment rises at the same momentum as new metrology techniques are deployed. In this paper, we focus on optimizing analytics, containing data-driven decision making for predictive quality and maintenance. We summarize key requirements for data analytics and machine learning application in industrial processes. With a use case from automotive component manufacturing we characterize industrial production, categorize process data and put requirements in context to a real-world example.",industry
10.1016/j.procs.2021.03.072,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Crafting adversarial samples for anomaly detectors in industrial control systems,https://api.elsevier.com/content/abstract/scopus_id/85106726514,"The increasing adoption of the Industry 4.0 paradigm encompasses digitally interconnected factories which enables many advantages. However, it is still necessary to dedicate effort towards investigating protection mechanisms against cyberattacks in these scenarios. Despite the power demonstrated by Anomaly Detection-based Intrusion Detection Systems in industrial scenarios, their vulnerabilities to adversarial attacks, especially to evasion attacks, make Machine Learning and Deep Learning models ineffective for real scenarios. These type of attacks craft samples misclassified by the Intrusion Detection System and potentially reach industrial devices, causing potentially damaging impacts to factory workers and industry resources. Adversarial attacks linked to industrial scenarios are currently in early stages of development, hence most of them have the capability to craft samples misclassified by the IDS but not reach industrial devices. In this work, we present a new adversarial attack named Selective and Iterative Gradient Sign Method that overcomes the limitation of the adversarial attacks present in the literature. To complement this work we also detail a study of how the detection rate of an Intrusion Detection System is degraded and the time required by each technique to generate adversarial samples. The experiments were carried out using a dataset named Electra, collected from an Electric Traction Substation, and showed that adversarial attacks evaluated crafted samples misclassified by the IDS. However, only the method we proposed generated samples that can be understood by intermediate network devices and, therefore, reach their destination. Our experiment outputs demonstrate a lower period of time to achieve and craft adversarial samples using out our iterative based process method as opposed to other current iterative methods currently available.",industry
10.1016/j.procir.2021.03.081,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Evaluation of deep learning with long short-term memory networks for time series forecasting in supply chain management,https://api.elsevier.com/content/abstract/scopus_id/85106397670,"Performance analysis and forecasting the evolution of complex systems are two challenging tasks in manufacturing. Time series data from complex systems capture the dynamic behaviors of the underlying processes. However, non-linear and non-stationary dynamics pose a major challenge for accurate forecasting. To overcome statistical complexities through analyzing time series, we approach the problem with deep learning methods. In this paper, we mainly focus on the long short-term memory (LSTM) networks for demand forecasts in supply chain management, where the future demand for a certain product is the basis for the respective replenishment systems. This study contributes to the literature by conducting experiments on real data to investigate the potential of using LSTM networks for final customer demand forecasting, and hence for increasing the overall value generated by a supply chain. Both forward LSTM and bidirectional LSTM (forward-backward) for short- and long-term demand prediction in supply chain management are considered in this study.",industry
10.1016/j.procs.2021.02.026,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,DDNN based data allocation method for IIoT,https://api.elsevier.com/content/abstract/scopus_id/85104871428,"With the complete application of artificial intelligence in the field of industrial production and manufacturing and the rapid development of edge computing, industrial processing sites often need to deploy machine learning tasks at edges and terminals. We propose a data allocation method based on Distributed Deep Neural Networks (DDNN) framework, which allocates data to edge servers or stays locally for processing. DDNN divides deep learning tasks and deploys pre-trained shallow neural networks and deep neural networks at local or edges, respectively. However, all data is processed locally, and the failure is sent to the edge server or the cloud. It will lead to excessive pressure on local terminal equipment and long-term idle edge servers, which cannot meet industrial production’s real-time requirements on user privacy and time-sensitive tasks. In this paper, the complexity and inference error rate of machine learning model, the data processing speed of local equipment and edge server, and the transmission time are comprehensively considered to establish the system model. A joint optimization problem is proposed to minimize the total data processing delay. The optimal solution is derived analytically, and the optimal data allocation methhod is given. Simulation experiments are designed to verify the method’s effectiveness and study the influence of key parameters on the allocation method.",industry
10.1016/j.procs.2021.02.049,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Research and application of network status prediction based on BP neural network for intelligent production line,https://api.elsevier.com/content/abstract/scopus_id/85104842861,"In the intelligent production line network communication process of the Industrial IoT, communication node congestion will cause the communication quality to decrease, thereby affecting the production efficiency. Therefore, accurately predicting the status of network and making adjustments to the network in real time is of great significance to improving the quality of network communication. Aiming at the urgent problem of the network communication quality of the intelligent production line, this paper proposes a network status prediction algorithm for the intelligent production line. The algorithm uses the ARMA prediction model to predict the network data, and calculates and predicts the entire network operation through the optimized BP neural network. At the same time, an intelligent production line network prediction system is designed based on the algorithm. The system can predict the network operation status in advance, reducing the impact of network status fluctuations on the production efficiency of the intelligent production line. The simulation results show that after a large number of network data prediction experiments, the optimal data prediction period is obtained. Under this period, the accuracy of network status prediction reaches 90%.",industry
10.1016/j.procs.2021.03.075,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Input doubling method based on SVR with RBF kernel in clinical practice: Focus on small data,https://api.elsevier.com/content/abstract/scopus_id/85104314419,"In recent years, machine-learning-based approaches have become of considerable interest to the efficient processing of short or limited data samples. Its so-called small data approach. This is due to the significant growth of new intellectual analysis tasks in various industries, which are characterized by limited historical data. These include Materials Science, Economics, Medicine, and so on. An effective processing of short datasets is especially acute in medicine. Insufficient number of vectors, significant gaps in the data collected during the supervision of patient’s treatment or rehabilitation, reduces the effectiveness or prevents effective intellectual analysis based on them. This paper presents a new approach to processing short medical data samples. The basis of the developed method is SVR with RBF kernel. The algorithmic implementation of the method in both operation modes is described. Experimental modeling on a real short data set (Trabecular bone data) is conducted. It contained only 35 observations. A comparison of the method with a number of existing machine learning methods is conducted. It is experimental established the highest accuracy of the method among those considered. The developed method has potential opportunities for wide application in various fields of medicine.",industry
10.1016/j.procir.2021.01.128,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,A Machine Vision-based Cyber-Physical Production System for Energy Efficiency and Enhanced Teaching-Learning Using a Learning Factory,https://api.elsevier.com/content/abstract/scopus_id/85102656008,"Machine vision (MV) can help in achieving real-time data analysis in a manufacturing environment. This can be implemented in any industry to achieve real-time monitoring of workpieces for geometric defects and material irregularities. Identification of defects, sorting of workpieces based on their physical parameters, and analysis of process abnormalities can be achieved by using the real-time data from simple and cost-effective raspberry pi with camera and open source machine learning platform TensorFlow to run convolutional neural network (CNN) model. The proposed cyber-physical production system enables to develop a MV based system for data acquisition integrating physical entities of learning factory (LF) with the cyber world. Nowadays, LFs are widely used to train the workforce for developing competencies for emerging technologies and challenges faced due to technological advancements in Industry 4.0. This paper demonstrates the application of a cost-effective MV system in a learning factory environment to achieve real-time data acquisition and energy efficiency. The proposed low-cost machine vision is found to detect geometric irregularities, colours and surface defects. The simple cost effective MV system has enhanced the energy efficiency and reduced the total carbon footprint by 18.37 % and 78.83 % depending upon the location of MV system along the flow. The teaching-learning experience is also enhanced through action-based learning strategies. This not only ensures less rework, better control, unbiased decisions, 100% quality assurance but also the need of workers/operators can be reduced.",industry
10.1016/j.procir.2021.01.115,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Development of a Decision Support System for 3D Printing Processes based on Cyber Physical Production Systems,https://api.elsevier.com/content/abstract/scopus_id/85102637852,"3D printing, an additive manufacturing (AM) technology, potentially provides sustainability advantages such as less waste generation, lightweight geometries, reduced material and energy consumption, lower inventory waste, etc. This paper proposes a decision support system for the 3D printing process based on Cyber Physical Production System (CPPS). The user is enabled to dynamically assess the carbon footprint based on the energy and material usage for their 3D printed object. A CPPS framework for the environmental sustainability of the 3D printing process is presented, which supports the derivation of improved strategies for product design and production. A physical world for 3D printing is used with the internet of things (IoT) devices like sensor node, webcam, smart plugs, and raspberry pi to host printer Management Software (PMS) for real-time monitoring and control of material and energy consumption during the printing process. Experiments have been conducted based on Taguchi L9 orthogonal array with polylactic Acid (PLA) as a filament material to estimate the product-related manufacturing energy consumption with the carbon footprint. The proposed framework can be effectively used by the users to supports the decision-making process for saving resources and energy; and minimizing the effect on the environment.",industry
10.1016/j.procir.2021.01.010,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Analysis of Barriers to Industry 4.0 adoption in Manufacturing Organizations: An ISM Approach,https://api.elsevier.com/content/abstract/scopus_id/85102622489,"Industry 4.0 has enabled technological integration of cyber physical systems and internet based communication in manufacturing value creation processes. As of now, many people use it as a collective term for advanced technologies, i.e. advanced robotics, artificial intelligence, machine learning, big data analytics, cloud computing, smart sensors, internet of things, augmented reality, etc. This substantially improves flexibility, quality, productivity, cost, and customer satisfaction by transforming existing centralized manufacturing systems towards digital and decentralized one. Despite having potential benefits of industry 4.0, the organizations are facing typical obstacles and challenges in adopting new technologies and successful implementation in their business models. This paper aims to identify potential barriers which may hinder the implementation of industry 4.0 in manufacturing organizations. The identified barriers, through comprehensive literature review and on the basis of opinions collected from industry experts, are: poor value-chain integration, cyber-security challenges, uncertainty about economic benefits, lack of adequate skills in workforce, high investment requirements, lack of infrastructure, jobs disruptions, challenges in data management and data quality, lack of secure standards and norms, and resistance to change. Interpretive Structural Modeling (ISM) is used to establish relationships among these barriers to develop a hierarchical model and MICMAC analysis for further classification of identified barriers for better understanding. An analysis of driving and dependence of the barriers may help in clear understanding of these for successful implementation of Industry 4.0 practices in the organizations.",industry
10.1016/j.procir.2021.01.018,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Machine learning based approach for process supervision to predict tool wear during machining,https://api.elsevier.com/content/abstract/scopus_id/85102618379,"Tool wear prediction during machining is a challenging problem. Traditional approaches are available to use the process parameters which influence tool wear but there are certain parameters which are very specific to the machining process and available prediction models fail. Present work discusses a Machine Learning based process supervisory system to predict the tool wear. To illustrate the approach an application for the prediction of tool wear while machining is selected as a case study. The analysis was performed on a machining dataset consisting of certain experiments of different levels of input parameters and for each experiment several sensor logged physical parameters (features). From a chosen training set of experiments the features that best describe the state of tool wear (unworn or worn) along with the input parameters were chosen to build a model. Several models employing logistic regression were built and the best one was chosen. The model obtained had good accuracy and interpretability. The results obtained from the test set show the system’s suitability and potential for industrial application. The presented supervisory model can be utilized to predict tool wear in real time and prior to the tool getting worn before a set number of operations, thus cause a reduction in the delay due to the change over required to an unworn tool.",industry
10.1016/j.procs.2021.01.348,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Procedure model for the development and launch of intelligent assistance systems,https://api.elsevier.com/content/abstract/scopus_id/85101779152,"The paper analyses the current state of knowledge on approaches for the practical implementation of machine learning based assistance systems for production planning and control.
                  A concept of a procedure model for application-oriented projects in the field of industrial series production is proposed. It focusses on order sequencing and machine allocation in a real time production environment. As part of an application-oriented research project, a use case is referenced. In this paper, a first conceptual approach is presented, using the example of an industrial production of printed circuit boards.
                  In the following steps, practical suitability is checked on the basis of the practical reference, conclusions are drawn and the methodology will be developed further. The aim is a generally valid procedure model for industrial series production.",industry
10.1016/j.jmsy.2020.12.020,Journal,Journal of Manufacturing Systems,scopus,2021-01-01,sciencedirect,Sound-based remote real-time multi-device operational monitoring system using a Convolutional Neural Network (CNN),https://api.elsevier.com/content/abstract/scopus_id/85099646275,"Smart factory is the main keyword in the field of manufacturing processes about the fourth industrial revolution. To realize the smart factory, making all pieces of device into smart devices that are connected to the centralized system to enable a real-time exchange of information is essential. Sound can be efficient means to make devices as smart devices because sound can contain the status information of various devices simultaneously, and it can be recorded easily outside of a device using only a microphone. In this study, multi-device operation monitoring system by analyzing sound is developed. Mic arrays for acquiring the sound were installed at the outside the devices and recorded the sounds from several devices simultaneously. By analyzing the recorded sound with log-mel spectrogram and Convolutional Neuron Network (CNN), the system could detect the operational status of three devices with an accuracy of 71–92 %. To improve the performance, virtual data set was created by composition of individual device operating sounds of different intensities. With this virtual data set, accuracy can be enhanced to 87 % ∼ 99 % accuracy and, required sound data amount could be reduced. Developed system was applied successfully in monitoring experiments in two different environments: a workshop in which hand-operated device was used and a factory with a computer numerical control machine and verifying the performance.",industry
10.1016/j.jtice.2021.01.007,Journal,Journal of the Taiwan Institute of Chemical Engineers,scopus,2021-01-01,sciencedirect,On the evaluation of solubility of hydrogen sulfide in ionic liquids using advanced committee machine intelligent systems,https://api.elsevier.com/content/abstract/scopus_id/85099564514,"Ionic Liquids (ILs) are increasingly emerging as new innovating green solvents with great importance from academic, industrial, and environmental perspectives. This surge of interest in considering ILs in various applications is owed to their attractive properties. Involvements in the gas sweetening and the reduction of the amounts of sour and acid gasses are among the most promising applications of ILs. In this study, new advanced committee machine intelligent systems (CMIS) were introduced for predicting the solubility of hydrogen sulfide (H2S) in various ILs. The implemented CMIS models were gained by linking robust data-driven techniques, namely multilayer perceptron (MLP) and cascaded forward neural network (CFNN) beneath rigorous schemes using group method of data handling (GMDH) and genetic programming (GP). The proposed paradigms were developed using an extensive database encompassing 1243 measurements of H2S solubility in 33 ILs. The performed comprehensive error investigation revealed that the newly implemented paradigms yielded very satisfactory prediction performance. Besides, it was found that CMIS-GP provided more accurate estimations of H2S solubility in ILs compared with both the other intelligent models and the best-prior paradigms. In this regard, the developed CMIS-GP exhibited overall average absolute relative deviation (AARD) and coefficient of determination (R2) values of 2.3767% and 0.9990, respectively. Lastly, the trend analyses demonstrated that the tendencies of CMIS-GP predictions were in excellent accordance with the real variations of H2S solubility in ILs with respect to pressure and temperature.",industry
10.1016/j.aei.2021.101246,Journal,Advanced Engineering Informatics,scopus,2021-01-01,sciencedirect,"A systematic literature review on intelligent automation: Aligning concepts from theory, practice, and future perspectives",https://api.elsevier.com/content/abstract/scopus_id/85099458674,"With the recent developments in robotic process automation (RPA) and artificial intelligence (AI), academics and industrial practitioners are now pursuing robust and adaptive decision making (DM) in real-life engineering applications and automated business workflows and processes to accommodate context awareness, adaptation to environment and customisation. The emerging research via RPA, AI and soft computing offers sophisticated decision analysis methods, data-driven DM and scenario analysis with regard to the consideration of decision choices and provides benefits in numerous engineering applications. The emerging intelligent automation (IA) – the combination of RPA, AI and soft computing – can further transcend traditional DM to achieve unprecedented levels of operational efficiency, decision quality and system reliability. RPA allows an intelligent agent to eliminate operational errors and mimic manual routine decisions, including rule-based, well-structured and repetitive decisions involving enormous data, in a digital system, while AI has the cognitive capabilities to emulate the actions of human behaviour and process unstructured data via machine learning, natural language processing and image processing. Insights from IA drive new opportunities in providing automated DM processes, fault diagnosis, knowledge elicitation and solutions under complex decision environments with the presence of context-aware data, uncertainty and customer preferences. This sophisticated review attempts to deliver the relevant research directions and applications from the selected literature to the readers and address the key contributions of the selected literature, IA’s benefits, implementation considerations, challenges and potential IA applications to foster the relevant research development in the domain.",industry
10.1016/j.matdes.2020.109201,Journal,Materials and Design,scopus,2021-01-01,sciencedirect,Online prediction of mechanical properties of hot rolled steel plate using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85092064894,"In industrial steel plate production, process parameters and steel grade composition significantly influence the microstructure and mechanical properties of the steel produced. But determining the exact relationship between process parameters and mechanical properties is a challenging process. This work aimed to devise a deep learning model, to predict mechanical properties of industrial steel plate including yield strength (YS), ultimate tensile strength (UTS), elongation (EL), and impact energy (Akv); based on the process parameters as well as composition of raw steel, and apply it online to a real steel manufacturing plant. An optimal deep neural network (DNN) model was formulated with 27 inputs parameters, 2 hidden layers each having 200 nodes and 4 output parameters (27 × 200 × 200 × 4) with an initial learning rate 0.0001, using Adam optimizer and subjected to Z pre-processing method, to yield an accurate model with R2 = 0.907. The tuned DNN model, had a root mean square error of 21.06 MPa, 16.67 MPa, 2.36%, and 39.33 J, and root mean square percentage error of 4.7%, 2.9%, 7.7%, and 16.2%, for YS, UTS, EL and Akv respectively. Through comparative analysis, it was found that the accuracy of DNN model was higher than other classic machine learning algorithms. To interpret the model assumptions and findings, several local linear models were devised and analyzed to establish the link between process parameters and mechanical properties. Finally the tuned DNN model was deployed in the real-steel plant for online monitoring and control of steel mechanical properties, and to guide the production of targeted steel plates with tailored mechanical properties.",industry
10.1016/bs.adcom.2020.08.001,Book Series,Advances in Computers,scopus,2021-01-01,sciencedirect,Demystifying the blockchain technology,https://api.elsevier.com/content/abstract/scopus_id/85091072369,"The blockchain paradigm is being widely touted by many as the innovative and disruptive one capable of bringing in a few exemplary and elegant transformations in the IT space. As business operations and offerings are substantially enabled through the various crucial accomplishments and advancements in the IT field, business executives across the globe are equally keen to experiment with and embrace this new and futuristic technology to reap a slew of business benefits. Interestingly, blockchain has the inherent potential and promise to bring forth a bevy of strategically sound implications for various industry verticals. Cryptocurrency is one of the finest and foremost applications of the blockchain technology. The supply chain domain is exploring this new phenomenon for realizing some crucial advantages. The IoT discipline is another one capable of attaining a number of distinct benefits out of all the trendsetting improvisations being realized in the blockchain space. This chapter is specially crafted to tell what, why, how, and where the indispensable blockchain paradigm is being used toward real digital transformations.",industry
10.1016/j.jclepro.2020.124022,Journal,Journal of Cleaner Production,scopus,2021-01-01,sciencedirect,Artificial intelligence in nuclear industry: Chimera or solution?,https://api.elsevier.com/content/abstract/scopus_id/85090601822,"Nuclear industry is in crisis and innovation is the central theme of its survival in future. Artificial intelligence has made a quantum leap in last few years. This paper comprehensively analyses recent advancement in artificial intelligence for its applications in nuclear power industry. A brief background of machine learning techniques researched and proposed in this domain is outlined. A critical assessment of various nuances of artificial intelligence for nuclear industry is provided. Lack of operational data from real power plant especially for transients and accident scenario is a major concern regarding the accuracy of intelligent systems. There is no universally agreed opinion among researchers for selecting the best artificial intelligence techniques for a specific purpose as intelligent systems developed by various researchers are based on different data set. Interlaboratory work frame or round-robin programme to develop the artificial intelligent tool for any specific purpose, based on the same data base, can be crucial in claiming the accuracy and thus the best technique. The black box nature of artificial techniques also poses a serious challenge for its implementation in nuclear industry, as it makes them prone to fooling.",industry
10.1016/j.jobe.2020.101601,Journal,Journal of Building Engineering,scopus,2021-01-01,sciencedirect,Trainingless multi-objective evolutionary computing-based nonintrusive load monitoring: Part of smart-home energy management for demand-side management,https://api.elsevier.com/content/abstract/scopus_id/85087827958,"Electricity is the most widely used form of energy in modern society. One method of satisfying the continuously increasing industrial, commercial, and residential electrical-energy demands of consumers in smart grids is to use an Internet-of-things (IoT) service-oriented electrical-energy management system (EMS) to intrusively monitor and manage electrical loads, which can effectively react to demand-response schemes for demand-side management (DSM). Nonintrusive load monitoring (NILM), a viable cost-effective load disaggregation technique, has recently gained considerable attention as a nonintrusive alternative to EMS in the research field of smart grids. This paper presents a smart IoT-oriented home EMS founded on trainingless multi-objective evolutionary computing-based NILM for DSM in a smart grid. Evolutionary computing-based NILM is considered and addressed as a multi-objective combinatorial optimization problem. The proposed NILM technique can determine the electrical appliances based on their individual electrical characteristics extracted from composite electrical-load consumption with no intrusive deployment of smart plugs or power meters. A fully nonintrusive NILM alternative is considered and proposed. In addition, this alternative is different from conventional NILM because conventional NILM considers artificial intelligence including artificial neural networks (NNs) and deep NN as load classifiers of NILM where training and retraining stages and a hyperparameter tuning procedure are required. The proposed smart IoT-oriented home EMS was experimentally investigated with the trainingless multi-objective evolutionary computing-based NILM in a real house environment. The experimental results confirm that the proposed methodology is feasible.",industry
10.1016/j.jmsy.2020.06.019,Journal,Journal of Manufacturing Systems,scopus,2021-01-01,sciencedirect,Digital-twin-driven geometric optimization of centrifugal impeller with free-form blades for five-axis flank milling,https://api.elsevier.com/content/abstract/scopus_id/85087755544,"Centrifugal impeller (CI) manufacturing is moving toward a new paradigm, with the objective to improve efficiency and competitiveness through Industry 4.0 and smart manufacturing. Making a CI developable and ruled has become a crucial technology to obviously improve machining efficiency and save costs although it may bring negative effects on aerodynamic performance accordingly. Hence, it is extremely challenging to consider and balance both machinability and aerodynamic performance in the process of CI geometric optimization. Digital Twin (DT) provides an attractive option for the integrated design and manufacturing due to multi-dimension and real-time. This paper breaks traditional procedures and presents a DT-based optimization strategy on the consideration of both machining efficiency and aerodynamic performance, as well as builds a reified 5-dimensional DT model. The virtual model consists of three sub-functional modules, including geometric modeling, machining optimization and aerodynamic performance evaluation. A tool-path generation method for CI five-axis flank milling is proposed to improve machining efficiency. The negative influences on aerodynamic performance and internal flow field are simulated and analyzed. Reinforce Learning is introduced to determine the optimization decision-making. Machining experiment and performance test with respect to various CI workpieces are conducted to provide immediate feedback to DT model. Real world and virtual world are combined to make CI geometry dynamically updated and iteratively optimized, which is desirable and significative to effectively shorten cycles and save costs in CI development.",industry
10.1016/j.jmsy.2020.06.012,Journal,Journal of Manufacturing Systems,scopus,2021-01-01,sciencedirect,"A digital twin to train deep reinforcement learning agent for smart manufacturing plants: Environment, interfaces and intelligence",https://api.elsevier.com/content/abstract/scopus_id/85087690907,"Filling the gaps between virtual and physical systems will open new doors in Smart Manufacturing. This work proposes a data-driven approach to utilize digital transformation methods to automate smart manufacturing systems. This is fundamentally enabled by using a digital twin to represent manufacturing cells, simulate system behaviors, predict process faults, and adaptively control manipulated variables. First, the manufacturing cell is accommodated to environments such as computer-aided applications, industrial Product Lifecycle Management solutions, and control platforms for automation systems. Second, a network of interfaces between the environments is designed and implemented to enable communication between the digital world and physical manufacturing plant, so that near-synchronous controls can be achieved. Third, capabilities of some members in the family of Deep Reinforcement Learning (DRL) are discussed with manufacturing features within the context of Smart Manufacturing. Trained results for Deep Q Learning algorithms are finally presented in this work as a case study to incorporate DRL-based artificial intelligence to the industrial control process. As a result, developed control methodology, named Digital Engine, is expected to acquire process knowledges, schedule manufacturing tasks, identify optimal actions, and demonstrate control robustness. The authors show that integrating a smart agent into the industrial platforms further expands the usage of the system-level digital twin, where intelligent control algorithms are trained and verified upfront before deployed to the physical world for implementation. Moreover, DRL approach to automated manufacturing control problems under facile optimization environments will be a novel combination between data science and manufacturing industries.",industry
10.1016/j.jclepro.2020.123365,Journal,Journal of Cleaner Production,scopus,2020-12-20,sciencedirect,An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,https://api.elsevier.com/content/abstract/scopus_id/85089891280,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers’ maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions.",industry
10.1016/j.oceaneng.2020.108261,Journal,Ocean Engineering,scopus,2020-12-15,sciencedirect,Real-time data-driven missing data imputation for short-term sensor data of marine systems. A comparative study,https://api.elsevier.com/content/abstract/scopus_id/85093700362,"In the maritime industry, sensors are utilised to implement condition-based maintenance (CBM) to assist decision-making processes for energy efficient operations of marine machinery. However, the employment of sensors presents several challenges including the imputation of missing values. Data imputation is a crucial pre-processing step, the aim of which is the estimation of identified missing values to avoid under-utilisation of data that can lead to biased results. Although various studies have been developed on this topic, none of the studies so far have considered the option of imputing incomplete values in real-time to assist instant data-driven decision-making strategies. Hence, a methodological comparative study has been developed that examines a total of 20 widely implemented machine learning and time series forecasting algorithms. Moreover, a case study on a total of 7 machinery system parameters obtained from sensors installed on a cargo vessel is utilised to highlight the implementation of the proposed methodology. To assess the models’ performance seven metrics are estimated (Execution time, MSE, MSLE, RMSE, MAPE, MedAE, Max Error). In all cases, ARIMA outperforms the remaining models, yielding a MedAE of 0.08 r/min and a Max Error of 2.4 r/min regarding the main engine rotational speed parameter.",industry
10.1016/j.eswa.2020.113653,Journal,Expert Systems with Applications,scopus,2020-12-15,sciencedirect,Cost-sensitive learning classification strategy for predicting product failures,https://api.elsevier.com/content/abstract/scopus_id/85088008188,"In the current era of Industry 4.0, sensor data used in connection with machine learning algorithms can help manufacturing industries to reduce costs and to predict failures in advance. This paper addresses a binary classification problem found in manufacturing engineering, which focuses on how to ensure product quality delivery and at the same time to reduce production costs. The aim behind this problem is to predict the number of faulty products, which in this case is extremely low. As a result of this characteristic, the problem is reduced to an imbalanced binary classification problem. The authors contribute to imbalanced classification research in three important ways. First, the industrial application coming from the electronic manufacturing industry is presented in detail, along with its data and modelling challenges. Second, a modified cost-sensitive classification strategy based on a combination of Voronoi diagrams and genetic algorithm is applied to tackle this problem and is compared to several base classifiers. The results obtained are promising for this specific application. Third, in order to evaluate the flexibility of the strategy, and to demonstrate its wide range of applicability, 25 real-world data sets are selected from the KEEL repository with different imbalance ratios and number of features. The strategy, in this case implemented without a predefined cost, is compared with the same base classifiers as those used for the industrial problem.",industry
10.1016/j.neucom.2020.06.116,Journal,Neurocomputing,scopus,2020-12-05,sciencedirect,Intelligent prognostics of machining tools based on adaptive variational mode decomposition and deep learning method with attention mechanism,https://api.elsevier.com/content/abstract/scopus_id/85089841282,"In the modern manufacturing industry, remaining useful life (RUL) prediction of the machining tools plays a significant role in promoting machining efficiency, ensuring product quality and reducing production costs. In recent years, many data-driven prognostic approaches have been developed for machining tools, but few of them have considered the operating conditions such as spindle load and rotating speed that may have great impact on the degradation behavior and sensor signals. It may give rise to more uncertainty and lead to an obvious decrease in prediction accuracy when operating condition changes. Besides, feature extraction from the raw signals that are nonstationary, nonlinear, and mixed with abundant noise is essential but quite challenging. To address these issues, this paper proposes a novel prognostic approach for machining tools under dynamic operating condition with varying spindle load. In the proposed approach, an adaptive variational mode decomposition (VMD) is newly developed to adaptively search the optimal parameters for processing the raw vibration data, then several components with good trendability and noise robustness are obtained for feature extraction. Furthermore, a deep learning model combining one-dimensional convolutional long short-term memory (LSTM) with attention mechanism is constructed to perform RUL prediction. Numerical experiments on a real-world case study show the effectiveness and superiority of the proposed approach in comparison with other baseline data-driven approaches.",industry
10.1016/j.enmm.2020.100387,Journal,"Environmental Nanotechnology, Monitoring and Management",scopus,2020-12-01,sciencedirect,"Artificial neural network for prediction of color adsorption from an industrial textile effluent using modified sugarcane bagasse: Characterization, kinetics and isotherm studies",https://api.elsevier.com/content/abstract/scopus_id/85096213404,"The present work aims to study the biosorption process of color removal from real textile effluent using chemically modified sugarcane bagasse (SBM) as a biosorbent material and the prediction of the process by modeling and simulation of an artificial neural network (ANN). The raw sugarcane bagasse and the biosorbent SBM were characterized by scanning electron microscopy analysis (SEM), Fourier-transform infrared spectroscopy (FTIR), and porous structure. Batch experiments were carried out on the effect of the effluent pH, contact time between adsorbent and adsorbate, adsorbent dosage, particle size, and effluent color concentration on the adsorption process. The best-operating conditions found were in an acid medium, using an SBM particle size of 0.7 mm, and a dosage of 0.6 g, which allowed a color removal of 100 % for an initial true color concentration of 149 PtCo.L−1. The multilayer feed-forward neural network, with five inputs and one output, was trained with eight neurons in the hidden layer. A comparison between the experimental data and the predicted by ANN model showed that color removal results fitted very well to the model with a coefficient of determination (R2) of 0.928 and a mean square error (MSE) of 0.013. Nonlinear adjustments were made to the kinetic and adsorption isotherm models. In general, the adsorption process with SBM proved to be a promising method for the treatment of textile effluent, and the developed ANN model can be successfully used to make predictions for the final color of the effluent.",industry
10.1016/j.ijpx.2020.100058,Journal,International Journal of Pharmaceutics: X,scopus,2020-12-01,sciencedirect,Deep convolutional neural networks: Outperforming established algorithms in the evaluation of industrial optical coherence tomography (OCT) images of pharmaceutical coatings,https://api.elsevier.com/content/abstract/scopus_id/85096171040,"This paper presents a novel evaluation approach for optical coherence tomography (OCT) image analysis of pharmaceutical solid dosage forms based on deep convolutional neural networks (CNNs). As a proof of concept, CNNs were applied to image data from both, in- and at-line OCT implementations, monitoring film-coated tablets as well as single- and multi-layered pellets. CNN results were compared against results from established algorithms based on ellipse-fitting, as well as to human-annotated ground truth data. Performance benchmarks used include, efficiency (computation speed), sensitivity (number of detections from a defined test set) and accuracy (deviation from the reference method). The results were validated by comparing the output of several algorithms to data manually annotated by human experts and microscopy images of cross-sectional cuts of the same dosage forms as a reference method. In order to guarantee comparability for all results, the algorithms were executed on the same hardware. Since modern OCT systems must operate under real-time conditions in order to be implemented in-line into manufacturing lines, the necessary steps are discussed on how to achieve this goal without sacrificing the algorithmic performance and how to tailor a deep CNN to cope with the high amount of image noise and alterations in object appearance. The developed deep learning approach outperforms static algorithms currently available in pharma applications with respect to performance benchmarks, and represents the next level in real time evaluation of challenging industrial OCT image data.",industry
10.1016/j.compind.2020.103329,Journal,Computers in Industry,scopus,2020-12-01,sciencedirect,A Middleware Platform for Intelligent Automation: An Industrial Prototype Implementation,https://api.elsevier.com/content/abstract/scopus_id/85092922057,"The development of dynamic data-based Decision Support Systems (DSSs) along with the increasing availability of data in the industry, makes real-time data acquisition and management a challenge. Intelligent automation appears as a holistic combination of automation with analytics and decisions made by artificial intelligence, delivering smart manufacturing and mass customization while improving resource efficiency. However, challenges towards the development of intelligent automation architectures include the lack of interoperability between systems, complex data preparation steps, and the inability to deal with both high-frequency and high-volume data in a timely fashion. This paper contributes to industrial frameworks focused on the development of standardized system architectures for Industry 4.0, closing the gap between generic architectures and physical realizations. It proposes a platform for intelligent automation relying on a gateway or middleware between field devices, enterprise databases, and DSSs in real-time scenarios. This is achieved by providing the middleware interoperability, determinism, and automatic data structuring over an industrial communication infrastructure such as the OPC UA Standard over Time Sensitive Networks (TSN). Cloud services and database warehousing used to address some of the challenges are handled using fog computing and a multi-workload database. This paper presents an implementation of the platform in the pharmaceutical industry, providing interoperability and real-time reaction capability to changes to an industrial prototype using dynamic scheduling algorithms.",industry
10.1016/j.autcon.2020.103354,Journal,Automation in Construction,scopus,2020-12-01,sciencedirect,Real-time online detection of trucks loading via genetic neural network,https://api.elsevier.com/content/abstract/scopus_id/85091689126,"This article focuses on real-time online detection of trucks loading via genetic neural network. Firstly, according to the state structure of the truck and the deployment of the sensor in the monitoring system, a mathematical model that magnetic sensors detecting the weight of the truck is established, it provides a theoretical basis for the calculation of the compensator deviation. Secondly, a feedback compensator for disturbance signals is designed by genetic neural network in the load monitoring system. Thirdly, the stability of the control system is analyzed by the Lyapunov stability theory. Fourthly, a real-time monitoring system is proposed for the loading of trucks. Finally, a complete experiment is processed to in-depth discussion and analysis. Field experiments showed that this scheme solves the problem of real-time load detection of trucks, it proposes a monitoring system for transportation in the construction industry.",industry
10.1016/j.jbusres.2020.09.012,Journal,Journal of Business Research,scopus,2020-12-01,sciencedirect,Exploring how consumer goods companies innovate in the digital age: The role of big data analytics companies,https://api.elsevier.com/content/abstract/scopus_id/85091665759,"The advent and development of digital technologies have brought about a proliferation of online consumer reviews (OCRs), i.e., real-time customers’ evaluations of products, services, and brands. Increasingly, e-commerce platforms are using them to gain insights from customer feedback. Meanwhile, a new generation of big data analytics (BDA) companies are crowdsourcing large volumes of OCRs by means of controlled ad hoc online experiments and advanced machine learning (ML) techniques to forecast demand and determine the market potential for new products in several industries. We illustrate how this process is taking place for consumer goods companies by exploring the case of UK digital BDA company, SoundOut. Based on an in-depth qualitative analysis, we develop the consumer goods company innovation (CGCI) conceptual framework, which illustrates how digital BDA firms help consumer goods companies to test new products before they are launched on the market, and innovate. Theoretical and managerial implications are discussed.",industry
10.1016/j.asoc.2020.106729,Journal,Applied Soft Computing,scopus,2020-12-01,sciencedirect,Two-stage grasp strategy combining CNN-based classification and adaptive detection on a flexible hand,https://api.elsevier.com/content/abstract/scopus_id/85091509038,"Robotic autonomous grasping of food-related objects requires a nondestructive and safe grasp system for picking up various objects. A novel underactuated flexible hand consisting of a variable palm and four soft fingers is designed and manufactured to enhance the grasp space and deformability during interaction with unknown objects. A position deviation formulation is fitted to estimate the free bend deformation of soft fingers approximately through finite element analysis. A modular convolutional neural network is presented to identify the grasp directions, shape features and anticipated input pressure levels of novel objects for achieving multitarget classification. A vision-based adaptive detection method is proposed to obtain an accurate wrist orientation and the best grasp candidate by using two means of grasp planning (i.e. cross grasp planning and equidistant optimal grasp planning). A two-stage grasp strategy combining the classification and detection methods is developed as an effective solution to estimate the grasp configuration accurately. Results show that our flexible hand achieves 91.1% success rate in a physical grasp experiment on a UR robot, thereby demonstrating the reliability and adaptability of our grasp approach. The target object can be identified and detected within 0.263 s, which indicates the suitability of our approach in real-time applications.",industry
10.1016/j.autcon.2020.103387,Journal,Automation in Construction,scopus,2020-12-01,sciencedirect,Virtual prototyping- and transfer learning-enabled module detection for modular integrated construction,https://api.elsevier.com/content/abstract/scopus_id/85090569290,"Modular integrated construction is one of the most advanced off-site construction technologies and involves the repetitive process of installing prefabricated prefinished volumetric modules. Automatic detection of location and movement of modules should facilitate progress monitoring and safety management. However, automatic module detection has not been implemented previously. Hence, virtual prototyping and transfer-learning techniques were combined in this study to develop a module-detection model based on mask regions with convolutional neural network (Mask R-CNN). The developed model was trained with datasets comprising both virtual and real images, and it was applied to two modular construction projects for automatic progress monitoring. The results indicate the effectiveness of the developed model in module detection. The proposed method using virtual prototyping and transfer learning not only facilitates the development of automation in modular construction, but also provides a new approach for deep learning in the construction industry.",industry
10.1016/j.eswa.2020.113710,Journal,Expert Systems with Applications,scopus,2020-12-01,sciencedirect,A study on adaptation lightweight architecture based deep learning models for bearing fault diagnosis under varying working conditions,https://api.elsevier.com/content/abstract/scopus_id/85088656809,"Deep learning models have been widely studied in fault diagnosis recently. A mainstream application is to recognize patterns in spectrograms of faults. However, some common drawbacks still remain as following: a) Preprocess to improve the quality of spectrograms is rarely explored; b) Computing cost of a conventional CNN far exceeds the requirements of fast analysis in industry; c) Adequate labeled data cannot be acquired to train a comprehensive diagnosis model for varying working conditions. In this paper, an Adaptive Logarithm Normalization (ALN) is proposed to realize preprocess considering data distribution, it attempts to improve the quality of spectrograms via eliminating truncation phenomenon and enriching details simultaneously; Meanwhile, simplified lightweight models are built on the basis of present lightweight building blocks to reduce parameters, while maintaining high performances; Furthermore, an adaptation architecture is proposed by integrating Deep Adaptation Network (DAN) idea with simplified lightweight models, aiming at enhancing the generalization capability of models. Experiments have been carried out to implement the proposed methods with two different datasets. The overall success not only proves the methods feasible, but also indicates a possible diagnosis prospect for real industrial scenarios.",industry
10.1016/j.jclepro.2020.123125,Journal,Journal of Cleaner Production,scopus,2020-12-01,sciencedirect,A systematic literature review on machine tool energy consumption,https://api.elsevier.com/content/abstract/scopus_id/85088635681,"Energy efficiency has become an integral part of the metal manufacturing industries as a means to improve economic and environmental performance, and increase competitiveness. Machine tools are not only the major energy consumer in the manufacturing industry but also have very low efficiency. Therefore, the analysis of energy consumption by the machine tools is primarily important to understand their complex and dynamic energy consumption behavior. This will lead to the development of better corrective measures. Literature review helps in identifying and assessing the existing knowledge to recognize the future research areas for fostering the research interest on the specific topic. In this review article, the reference literature is identified using a systematic methodology followed by descriptive and content analysis to understand the evolution of research in machining energy. The review focuses on four machining energy aspects – classification, modelling, improvement strategies, and efficiency evaluation. A six level hierarchical model is proposed for better understanding of machining energy classification. The literature review shows that the research in this field intensified after 2009. It is observed that the research focus has shifted towards micro level classification of machining energy including transient states. More detailed and accurate energy consumption models are developed in recent years with increased use of soft computational methods. Real time energy data monitoring and its use for online optimization of machining processes is witnessed. The use of micro analysis, energy benchmarking and standardization of energy assessment indices require more research. Deployment of machining energy models for improving the sustainability of machine tools; data analytics and AI applications; and integration with industry 4.0 are new research opportunities in the field.",industry
10.1016/j.ejor.2020.05.010,Journal,European Journal of Operational Research,scopus,2020-12-01,sciencedirect,Data-driven optimization model customization,https://api.elsevier.com/content/abstract/scopus_id/85086372620,"When embedded in software-based decision support systems, optimization models can greatly improve organizational planning. In many industries, there are classical models that capture the fundamentals of general planning decisions (e.g., designing a delivery route). However, these models are generic and often require customization to truly reflect the realities of specific operational settings. Yet, such customization can be an expensive and time-consuming process. At the same time, popular cloud computing software platforms such as Software as a Service (SaaS) are not amenable to customized software applications. We present a framework that has the potential to autonomously customize optimization models by learning mathematical representations of customer-specific business rules from historical data derived from model solutions and implemented plans. Because of the wide-spread use in practice of mixed integer linear programs (MILP) and the power of MILP solvers, the framework is designed for MILP models. It uses a common mathematical representation for different optimization models and business rules, which it encodes in a standard data structure. As a result, a software provider employing this framework can develop and maintain a single code-base while meeting the needs of different customers. We assess the effectiveness of this framework on multiple classical MILPs used in the planning of logistics and supply chain operations and with different business rules that must be observed by implementable plans. Computational experiments based on synthetic data indicate that solutions to the customized optimization models produced by the framework are regularly of high-quality.",industry
10.1016/j.eswa.2020.113595,Journal,Expert Systems with Applications,scopus,2020-11-15,sciencedirect,Rumor detection based on propagation graph neural network with attention mechanism,https://api.elsevier.com/content/abstract/scopus_id/85086634178,"Rumors on social media have always been an important issue that seriously endangers social security. Researches on timely and effective detection of rumors have aroused lots of interest in both academia and industry. At present, most existing methods identify rumors based solely on the linguistic information without considering the temporal dynamics and propagation patterns. In this work, we aim to solve rumor detection task under the framework of representation learning. We first propose a novel way to construct the propagation graph by following the propagation structure (who replies to whom) of posts on Twitter. Then we propose a gated graph neural network based algorithm called PGNN, which can generate powerful representations for each node in the propagation graph. The proposed PGNN algorithm repeatedly updates node representations by exchanging information between the neighbor nodes via relation paths within a limited time steps. On this basis, we propose two models, namely GLO-PGNN (rumor detection model based on the global embedding with propagation graph neural network) and ENS-PGNN (rumor detection model based on the ensemble learning with propagation graph neural network). They respectively adopt different classification strategies for rumor detection task, and further improve the performance by including attention mechanism to dynamically adjust the weight of each node in the propagation graph. Experiments on a real-world Twitter dataset demonstrate that our proposed models achieve much better performance than state-of-the-art methods both on the rumor detection task and early detection task.",industry
10.1016/j.jclepro.2020.122870,Journal,Journal of Cleaner Production,scopus,2020-11-10,sciencedirect,Enhancing the adaptability: Lean and green strategy towards the Industry Revolution 4.0,https://api.elsevier.com/content/abstract/scopus_id/85088397153,"Industry 4.0 has brought forth many advantages and challenges for the industry players. Many organizations are strategizing to take advantage of this industrial paradigm shift, thus improving the sustainability of the enterprise. However, there are many factors such as talent development, machinery advancement and infrastructure development which involve huge investment that need to be considered. This paper presents an enhanced adaptive model for the implementation of the lean and green (L&G) strategy in processing sectors to solve dynamic industry problems associated with Industry 4.0. A feature of this enhanced adaptive model is that it combines experts’ experience and operational data as input in dealing with real industry application. A lean and green index is coupled in the model to serve as a benchmark and process improvement tracking indicator. This allows the industrialists to set a lean and green index (LGI) target for effective process improvement. From this integrated model, an ensemble of backpropagation optimizers is then used to identify the best-optimized strategy. This ensemble optimizer is formulated to perform operation improvement and update the targeted LGI automatically when a higher index is achieved for continuous improvement. A case study on a combined heat and power plant is performed and reflects an improvement of 18.25% on the LGI. This work serves as a practical transition strategy for the industrialist desiring to improve the sustainability of the facility with Industry 4.0 elements at minimum investment cost.",industry
10.1016/j.cie.2020.106868,Journal,Computers and Industrial Engineering,scopus,2020-11-01,sciencedirect,Simulation in industry 4.0: A state-of-the-art review,https://api.elsevier.com/content/abstract/scopus_id/85091194972,"Simulation is a key technology for developing planning and exploratory models to optimize decision making as well as the design and operations of complex and smart production systems. It could also aid companies to evaluate the risks, costs, implementation barriers, impact on operational performance, and roadmap toward Industry 4.0. Although several advances have been made in this domain, studies that systematically characterize and analyze the development of simulation-based research in Industry 4.0 are scarce. Therefore, this study aims to investigate the state-of-the-art research performed on the intersecting area of simulation and the field of Industry 4.0. Initially, a conceptual framework describing Industry 4.0 in terms of enabling technologies and design principles for modeling and simulation of Industry 4.0 scenarios is proposed. Thereafter, literature on simulation technologies and Industry 4.0 design principles is systematically reviewed using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) methodology. This study reveals an increasing trend in the number of publications on simulation in Industry 4.0 within the last four years. In total, 10 simulation-based approaches and 17 Industry 4.0 design principles were identified. A cross-analysis of concepts and evaluation of models’ development suggest that simulation can capture the design principles of Industry 4.0 and support the investigation of the Industry 4.0 phenomenon from different perspectives. Finally, the results of this study indicate hybrid simulation and digital twin as the primary simulation-based approaches in the context of Industry 4.0.",industry
10.1016/j.asoc.2020.106685,Journal,Applied Soft Computing Journal,scopus,2020-11-01,sciencedirect,LAVARNET: Neural network modeling of causal variable relationships for multivariate time series forecasting,https://api.elsevier.com/content/abstract/scopus_id/85090347409,"Multivariate time series forecasting is of great importance to many scientific disciplines and industrial sectors. The evolution of a multivariate time series depends on the dynamics of its variables and the connectivity network of causal interrelationships among them. Most of the existing time series models do not account for the causal effects among the system’s variables and even if they do, they rely just on determining the between-variables causality network. Knowing the structure of such a complex network, and even more specifically knowing the exact lagged variables that contribute to the underlying process is crucial for the task of multivariate time series forecasting. The latter is a rather unexplored source of information to leverage. In this direction, here a novel neural network-based architecture is proposed, termed LAgged VAriable Representation NETwork (LAVARNET), which intrinsically estimates the importance of lagged variables and combines high dimensional latent representations of them to predict future values of time series. Our model is compared with other baseline and state of the art neural network architectures on one simulated data set and four real data sets from the domains of meteorology, music, solar activity, and finance. The proposed architecture outperforms the competitive architectures in most of the experiments.",industry
10.1016/j.infsof.2020.106368,Journal,Information and Software Technology,scopus,2020-11-01,sciencedirect,Large-scale machine learning systems in real-world industrial settings: A review of challenges and solutions,https://api.elsevier.com/content/abstract/scopus_id/85087690796,"Background: Developing and maintaining large scale machine learning (ML) based software systems in an industrial setting is challenging. There are no well-established development guidelines, but the literature contains reports on how companies develop and maintain deployed ML-based software systems.
                  
                     Objective: This study aims to survey the literature related to development and maintenance of large scale ML-based systems in industrial settings in order to provide a synthesis of the challenges that practitioners face. In addition, we identify solutions used to address some of these challenges.
                  
                     Method: A systematic literature review was conducted and we identified 72 papers related to development and maintenance of large scale ML-based software systems in industrial settings. The selected articles were qualitatively analyzed by extracting challenges and solutions. The challenges and solutions were thematically synthesized into four quality attributes: adaptability, scalability, safety and privacy. The analysis was done in relation to ML workflow, i.e. data acquisition, training, evaluation, and deployment.
                  
                     Results: We identified a total of 23 challenges and 8 solutions related to development and maintenance of large scale ML-based software systems in industrial settings including six different domains. Challenges were most often reported in relation to adaptability and scalability. Safety and privacy challenges had the least reported solutions.
                  
                     Conclusion: The development and maintenance on large-scale ML-based systems in industrial settings introduce new challenges specific for ML, and for the known challenges characteristic for these types of systems, require new methods in overcoming the challenges. The identified challenges highlight important concerns in ML system development practice and the lack of solutions point to directions for future research.",industry
10.1016/j.measurement.2020.108043,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-11-01,sciencedirect,Smart frost measurement for anti-disaster intelligent control in greenhouses via embedding IoT and hybrid AI methods,https://api.elsevier.com/content/abstract/scopus_id/85086577761,"A novel Agro-industrial IoT (AIIoT) technology and architecture for intelligent frost forecasting in greenhouses via hybrid Artificial Intelligence (AI), is reported. The Internet of Things (IoT) allows the objects interconnection on the physical world using sensors and actuators via the Internet. The smart system was designed and implemented through a climatological station equipped with Artificial Neural Networks (ANN) and a fuzzy associative memory (FAM) for ecological control of the anti-frost disaster irrigation. The ANN forecasts the inside temperature of the greenhouses and the fuzzy control predicts the cropland temperatures for the activation of five output levels of the water pump. The results were compared to a Fourier-statistical analysis of hourly data, showing that the ANN models provide a temperature prediction with effectiveness higher than 90%, as compared to monthly data model. Moreover, results of this process were validated through the determination of the coefficient of variance analysis method (
                        
                           
                              
                                 R
                              
                              2
                           
                        
                     ).",industry
10.1016/j.measurement.2020.108052,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-11-01,sciencedirect,Deep learning-based prognostic approach for lithium-ion batteries with adaptive time-series prediction and on-line validation,https://api.elsevier.com/content/abstract/scopus_id/85086367941,"Prognostics for lithium-ion batteries is very critical in many industrial applications, and accurate prediction of battery state of health (SOH) is of great importance for health management. This paper proposes a novel deep learning-based prognostic method for lithium-ion batteries with on-line validation. An effective variant of recurrent neural network, i.e. long short-term memory structure, is used with variable input dimension, that facilitates network training with additional labeled samples. Adaptive time-series predictions are carried out for prognostics. An on-line validation method is further proposed for parameter optimization in real time based on the available system information, which allows for continuous model improvement. Experiments on a popular lithium-ion battery dataset are implemented to validate the effectiveness and superiority of the proposed method. The experimental results show the prognostic performances are promising both for the multi-steps-ahead predictions and long-horizon SOH estimations.",industry
10.1016/j.heliyon.2020.e05243,Journal,Heliyon,scopus,2020-10-01,sciencedirect,"Fast, easy, cheap, robust and safe method of analysis of Sudan dyes in chilli pepper powder",https://api.elsevier.com/content/abstract/scopus_id/85092504210,"Illicit use of Sudan dyes, a group of harmful and carcinogenic azo dyes, in the food industry has taken a surge in various parts of the world, especially in Africa. Their use in food as additives pose a dire health risk to consumers and have been banned by various food regulatory bodies worldwide. To help increase surveillance, various methods have been proposed for their analysis in literature. This study also sought to experiment and propose an alternative method for quick, easy, cheap, robust and ecologically safe analysis of Sudan dyes in chilli pepper powder and similar matrices. The optimized method used a 6.0 mL mixture of acetone:acetonitrile (1:5 v/v) solvent in a modified QuEChERs method for extraction of Sudan dyes I-IV. The simultaneous analysis of the dyes were achieved on Shimadzu prominence UFLC 20AD coupled with SPD 20AX UV detector operated at dual wavelength of 500 and 480 nm. A total of twenty four (24) chilli pepper powder samples from eight different vendors on the Ghana market were analysed using the optimized method. Quantitation of analytes were done using the external standard calibration method with determination coefficient, R2 > 0.9999. The limit of detection (LOD) and limit of quantitation (LOQ) of the method were 0.02–0.04 mg/kg and 0.05–0.13 mg/kg respectively. A good recovery range between 85.3 – 121.2% were obtained for a spike level of 1.0 mg/kg in real samples. ANOVA analysis at 95% CL showed statistically no significant difference (p > 0.05) in the recoveries between samples and also between the individual compounds. The method experimented and proposed in this study is fast, easy, cheap, robust and ecologically safe, presenting an alternative method for routine analysis for increased rate of surveillance against the illicit use of Sudan dyes as food additives.",industry
10.1016/j.micpro.2020.103227,Journal,Microprocessors and Microsystems,scopus,2020-10-01,sciencedirect,Fog Computing-inspired Smart Home Framework for Predictive Veterinary Healthcare,https://api.elsevier.com/content/abstract/scopus_id/85089574391,"Domestic Pet Care has been an important domain in the healthcare industry. In the presented study, a comprehensive framework of the Smart VetCare system for the health monitoring of domestic pets has been presented. The work is focused on the remote surveillance of domestic animals’ health conditions inside the home environment using IoMT Technology. Specifically, pet health is analyzed for vulnerability in the ambient home environment and ubiquitous activities over a fog computing platform of FogBus. Furthermore, a temporal data granule is formulated and the Probability of Health Vulnerability (PoHV) is defined for determining the health severity of the animal. Additionally, the Temporal Sensitivity Measure (TSM) is defined for real-time pet healthcare analysis, which is visualized using the Self Organized Mapping (SOM) Technique. For validation purposes, the framework is deployed in the smart home environment using 12 IoMT WiSense Nodes and Health Sensor belt for monitoring a domestic dog of American Bully breed over the dynamic resource management platform of FogBus and iFogSim simulator. Based on the comparison with numerous state-of-the-art techniques, the proposed framework can register a better precision value (94.78%), accuracy value (95.38%), sensitivity value (93.71%), and f-measure value (94.41%).",industry
10.1016/j.nucengdes.2020.110817,Journal,Nuclear Engineering and Design,scopus,2020-10-01,sciencedirect,Machine learning enabled advanced manufacturing in nuclear engineering applications,https://api.elsevier.com/content/abstract/scopus_id/85089553568,"Advanced manufacturing has gained tremendous interest in both research and industry in the past few years. Over nearly the same period of time, machine learning (ML) has made phenomenal advancements, finding its way into many aspects of manufacturing. For the nuclear engineering field, the adoption of advanced manufacturing is a compelling argument due to the ambitious challenges the field faces. The combination of advanced manufacturing with ML holds great potential in the nuclear engineering field, and even further development is needed to accelerate their deployment towards real-world applications. This review paper seeks to detail several key aspects of ML enabled advanced manufacturing that are used or could prove useful to nuclear applications ranging from radiation detector materials to reactor parts fabrication. The applications covered here include new material extrapolation, manufacturing defect detection, and additive manufacturing parameters’ optimization.",industry
10.1016/j.aei.2020.101153,Journal,Advanced Engineering Informatics,scopus,2020-10-01,sciencedirect,A neurophysiological approach to assess training outcome under stress: A virtual reality experiment of industrial shutdown maintenance using Functional Near-Infrared Spectroscopy (fNIRS),https://api.elsevier.com/content/abstract/scopus_id/85089076628,"Shutdown maintenance, i.e., turning off a facility for a short period for renewal or replacement operations is a highly stressful task. With the limited time and complex operation procedures, human stress is a leading risk. Especially shutdown maintenance workers often need to go through excessive and stressful on-site trainings to digest complex operation information in limited time. The challenge is that workers’ stress status and task performance are hard to predict, as most trainings are only assessed after the shutdown maintenance operation is finished. A proactive assessment or intervention is needed to evaluate workers’ stress status and task performance during the training to enable early warning and interventions. This study proposes a neurophysiological approach to assess workers’ stress status and task performance under different virtual training scenarios. A Virtual Reality (VR) system integrated with the eye-tracking function was developed to simulate the power plant shutdown maintenance operations of replacing a heat exchanger in both normal and stressful scenarios. Meanwhile, a portable neuroimaging device – Functional Near-Infrared Spectroscopy (fNIRS) was also utilized to collect user’s brain activities by measuring hemodynamic responses associated with neuron behavior. A human–subject experiment (n = 16) was conducted to evaluate participants’ neural activity patterns and physiological metrics (gaze movement) related to their stress status and final task performance. Each participant was required to review the operational instructions for a pipe maintenance task for a short period and then perform the task based on their memory in both normal and stressful scenarios. Our experiment results indicated that stressful training had a strong impact on participants’ neural connectivity patterns and final performance, suggesting the use of stressors during training to be an important and useful control factors. We further found significant correlations between gaze movement patterns in review phase and final task performance, and between the neural features and final task performance. In summary, we proposed a variety of supervised machine learning classification models that use the fNIRS data in the review session to estimate individual’s task performance. The classification models were validated with the k-fold (k = 10) cross-validation method. The Random Forest classification model achieved the best average classification accuracy (80.38%) in classifying participants’ task performance compared to other classification models. The contribution of our study is to help establish the knowledge and methodological basis for an early warning and estimating system of the final task performance based on the neurophysiological measures during the training for industrial operations. These findings are expected to provide more evidence about an early performance warning and prediction system based on a hybrid neurophysiological measure method, inspiring the design of a cognition-driven personalized training system for industrial workers.",industry
10.1016/j.asoc.2020.106539,Journal,Applied Soft Computing Journal,scopus,2020-10-01,sciencedirect,Cognitive visual anomaly detection with constrained latent representations for industrial inspection robot,https://api.elsevier.com/content/abstract/scopus_id/85088661065,"With the fast growth of intelligent manufacturing industry, developing advanced industrial inspection robots is becoming a research and application hotspot in the fields of both computer vision and robotics. This kind of industrial inspection robots is expected to automatically detect anomalous structures (e.g., defects, damages, rejects, etc.) from the images of the manufactured products. Generally, the existing visual anomaly detection (VAD) methods mainly focus on modeling the complex and high-dimensional distribution of normal data, while neglecting the specific visual properties of abnormal data since their frequency of occurrence is much less than that of the normal data. In this paper, inspired by the human cognition on extracting abstractly visual properties and to distinguish the anomaly patterns from the observed data, we propose a novel cognitive VAD method for industrial inspection robot. Specifically, we introduce a constrained latent space to mimic the cognitive ability of humans, where the abstraction learned from the observed normal and anomaly data are represented. We build our method based on a convolutional generative adversarial network and a denoising auto-encoder, where the adversarial learning mechanism is adopted to establish the boundary between the normal and anomaly data. In the experiment, we evaluate our method on a real-world dataset where the images are captured for the manufactured products. The comprehensive results comparing with several recent VAD methods show that the proposed method is effective to detect the anomaly images of different categories with a high accuracy.",industry
10.1016/j.asoc.2020.106515,Journal,Applied Soft Computing Journal,scopus,2020-10-01,sciencedirect,Fault diagnosis of rolling bearing of wind turbines based on the Variational Mode Decomposition and Deep Convolutional Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85087937848,"Machine learning techniques have been successfully applied in intelligent fault diagnosis of rolling bearings in recent years. However, in the real world industrial application, the dissimilarity of data due to changes in the working conditions and data acquisition environment often cause a poor performance of the existing fault diagnosis methods. Consequently, to address these inadequacies, this paper developed a novel method by integrating the Convolutional Neural Networks (CNNs) with the Variational Mode Decomposition (VMD) algorithms. Named as “Variational Mode Decomposition with Deep Convolutional Neural Networks (VMD-DCNNs)”, the method, in an end-to-end way, directly processes raw vibration signals without artificial experiences and manual intervention to realize the fault diagnosis of rolling bearings. In addition, the CNN technique is used to extract features from each Intrinsic Mode Function (IMF) in order to address the deficiency in extracting features from a single source and to achieve an effective and efficient fault diagnosis of rolling bearings under different environments and states. The value of parameter K of the VMD-DCNNs model is optimized by considering time complexity and generalization ability of the model. Lastly, bearing experiments are conducted to verify the superiority of the VMD-DCNNs in diagnosing fault under different conditions. The visualizations of the signals in the convolutional layer explain the reasonability in selecting the value of parameter K and they also indicate that the translational invariances in a raw IMF component have been learned by the VMD-DCNNs model.",industry
10.1016/j.aei.2020.101136,Journal,Advanced Engineering Informatics,scopus,2020-10-01,sciencedirect,Ensemble deep learning based semi-supervised soft sensor modeling method and its application on quality prediction for coal preparation process,https://api.elsevier.com/content/abstract/scopus_id/85087393963,"Coal preparation is the most effective and economical technique to reduce impurities and improve the product quality for run-of-mine coal. The timely and accurate prediction for key quality characteristics of separated coal plays a significant role in condition monitoring and production control. However, these quality characteristics are usually difficult to directly measure online in industrial practices Although some computation intelligence based soft sensor modeling methods have been developed and reported in existing research for these quality variables estimation, some problems still exist, i.e., manual feature extraction, considerable unlabeled data, temporal dynamic behavior in data, which will influence the accuracy and efficiency for established soft sensor model. To address above-mentioned problem and develop an more excellent quality prediction model for coal preparation process, a novel deep learning based semi-supervised soft sensor modeling approach is proposed which combining the advantage of unsupervised deep learning technique (i.e., Stacked Auto-Encoder (SAE)) with the advantage of supervised deep bidirectional recurrent learner (i.e., Bidirectional Long Short-Term Memory (BLSTM)). More specifically, the unsupervised SAE networks are implemented to learn the representative features hidden in all available input data (labeled and unlabeled samples) and store them as context vector. Then, partial context vector with corresponding labels and the quality variable measure value at previous time are concatenated to form a new merged input feature vector. After that, the temporal and dynamic features are further extracted from the new merged input feature vector via BLSTM networks. Subsequently, the fully connected layers (FCs) are exploited to learn the higher-level features from the last hidden layer of the BLSTM. Lastly, the learned output features by FCs are fed into a supervised liner regression layer to predict the coal quality metrics. Meanwhile, to avoid over-fitting, some regularization techniques are utilized and discussed in proposed network. The application in ash content estimation for a real dense medium coal preparation process and some comparison experiment result demonstrate that the effectiveness and priority of proposed soft sensor modeling approach.",industry
10.1016/j.patrec.2020.06.028,Journal,Pattern Recognition Letters,scopus,2020-10-01,sciencedirect,On the use of a full stack hardware/software infrastructure for sensor data fusion and fault prediction in industry 4.0,https://api.elsevier.com/content/abstract/scopus_id/85087339064,"Aspects related to prognostics are becoming a crucial part in the industrial sector. In this sense, Industry 4.0 is considered as a new paradigm that leverages on the IoT to propose increasingly more solutions to provide an estimate on the working conditions of an industrial plant. However, in context like the industrial sector where the number and heterogeneity of sensors can be very large, and the time requirements are very stringent, emerges the challenge to design effective infrastructures to interact with these complex systems. In this paper, we propose a full stack hardware/software infrastructure to collect, manage, and analyze the data gathered from a set of heterogeneous sensors attached to a real scale replica industrial plant available in our laboratory. On top of the proposed infrastructure we designed and implemented a fault prediction algorithm which exploits sensors data fusion with the aim to assess the working conditions of the industrial plant. The result section shows the obtained results in terms of accuracy from testing our proposed model and provides a comparison with a traditional Deep Neural Network (DNN) topology.",industry
10.1016/j.compind.2020.103255,Journal,Computers in Industry,scopus,2020-10-01,sciencedirect,Temporal action proposal for online driver action monitoring using Dilated Convolutional Temporal Prediction Network,https://api.elsevier.com/content/abstract/scopus_id/85086498336,"This paper presents a new approach for temporal detection of short human activities in untrimmed videos. Most present methods for temporal action detection, to our best knowledge, are trained on public action datasets that feature actions spanning up to tens and hundreds of seconds. However, it is often desired in manufacturing, transportation, and other safety-critical scenes that fine-grained actions be automatically detected, classified, and monitored. We propose a new Dilated Convolutional Temporal Prediction Network that features 1-D dilated convolution operation in a Residual network (ResNet)-like architecture for the generation of action proposals on orders of fractions of a second. The new architecture is used as a part of the action monitoring pipeline in subway cars. Experiments demonstrate that the proposed model outperforms the state-of-the-art on the task of temporal action proposal generation on a real-world video dataset, while achieving a fast processing speed suitable for online monitoring.",industry
10.1016/j.ins.2020.05.028,Journal,Information Sciences,scopus,2020-10-01,sciencedirect,Input selection methods for data-driven Soft sensors design: Application to an industrial process,https://api.elsevier.com/content/abstract/scopus_id/85086080455,"Soft Sensors (SSs) are inferential models which are widely used in industry. They are generally built through data-driven approaches that exploit industry historical databases. Selection of input variables is one of the most critical issues in SSs design. This paper aims at highlighting difficulties arising from the implementation of data-driven input selection methods when solving real-world case studies. A procedure is, therefore, proposed for input selection, based on both data-driven and expert-driven input selection methods. The procedure allows designing SSs with good prediction accuracy and a low number of inputs.
                  The design of an SS for a real-world industrial process is used. The results reported show that the selection methods proposed in literature do not give consistent results when applied to the considered case study. The key role for plant expert knowledge emerges, outlining the opportunity of judicious use of automatic data-driven procedures.",industry
10.1016/j.petrol.2020.107434,Journal,Journal of Petroleum Science and Engineering,scopus,2020-10-01,sciencedirect,"Probabilistic Neural Network with Bayesian-based, spectral torque imaging and Deep Convolutional Autoencoder for PDC bit wear monitoring",https://api.elsevier.com/content/abstract/scopus_id/85085583360,"Drill bit wear monitoring plays an important role during drilling operations, particularly in drilling challenging environments, such as ultradeep water and hard rock formations. The machine learning algorithms, applied to real-time analysis, has occupied an important role in the oil well industry. We here propose a machine learning system to aid drill bit wear assessment for real-time operations, using a Probabilistic Neural Network (PNN) and Bayes Theorem, combined with Power Spectral Density (PSD) of surface torque image and feature extraction by Deep Convolutional Autoencoder (DCAE). A case study was performed with wells from Brazilian ultradeep water pre-salt fields. The analysis shows that a feature extraction DCAE is more efficient to discriminate the bit wear state when compared with PSD torque image and torque raw data. After that, several numerical experiments were performed to investigate the best machine learning classification model, considering DCAE feature extraction. The cross-validation results considering all the dataset shows the PNN evaluation metrics: 87% accuracy, 83% precision, 91% recall and 86% for F1-score. The field tests validation was performed in real-time simulation, with 3 wells from the original dataset plus 2 offset wells. The simulations show that the proposed system can capture the best moment for the tripping pipe to replace a worn-out drill bit. The field tests experimental results indicate that the system proposed can aid drilling engineers in monitoring Polycrystalline Diamond Compact (PDC) drill bit wear in real-time operations.",industry
10.1016/j.knosys.2020.106178,Journal,Knowledge-Based Systems,scopus,2020-09-27,sciencedirect,Deep learning-based unsupervised representation clustering methodology for automatic nuclear reactor operating transient identification,https://api.elsevier.com/content/abstract/scopus_id/85087409980,"Transient identification of condition monitoring data in nuclear reactor is important for system health assessment. Conventionally, the operating transients are correlated with the pre-designed ones by human operators during operations. However, due to necessary conservatism and significant differences between the operating and pre-designed transients, it has been less effective to manually identify transients, that usually contribute to different system degradation modes. This paper proposes a deep learning-based unsupervised representation clustering method for automatic transient pattern recognition based on the on-site condition monitoring data. Sample entropy is used as indicator for transient extraction, and a pre-training stage is implemented using an auto-encoder architecture for learning high-level features. An iterative representation clustering algorithm is further proposed to enhance the clustering effects, where a novel distance metric learning strategy is integrated. Experiments on a real-world nuclear reactor condition monitoring dataset validate the effectiveness and superiority of the proposed method, which provides a promising tool for transient identification in the real industrial scenarios. This study offers a new perspective in exploring unlabeled data with deep learning, and the end-to-end implementation scheme facilitates applications in the real nuclear industry.",industry
10.1016/j.seppur.2020.116931,Journal,Separation and Purification Technology,scopus,2020-09-15,sciencedirect,Synergistic degradation of acid blue 113 dye in a thermally activated persulfate (TAP)/ZnO-GAC oxidation system: Degradation pathway and application for real textile wastewater,https://api.elsevier.com/content/abstract/scopus_id/85084210321,"The performance of a binary persulfate activation system based on the simultaneous use of heat (TAP) and ZnO coated granular activated carbon (ZnO-GAC) catalyst was investigated for the degradation of Acid Blue 113 (AB113) azo dye and the treatment of textile industry wastewater. FESEM, XRD, FTIR, EDX-mapping and BET analyses confirmed the successful loading of ZnO nanoparticles onto the GAC substrate. The effect of five independent variables on AB113 removal in the TAP/ZnO-GAC oxidation system was optimized by a 5-level full central composite design (CCD). All experiments were performed in a 6250 mL volume reactor. Adequacy and validity of the proposed model were confirmed with p-value < 0.0001 and R2 = 0.9994. The optimum values for solution pH, reaction time, persulfate (PS) concentration, ZnO-GAC dosage, and solution temperature were obtained to be 4.7, 50 min, 4.2 mM, 2.5 g/L, and 70 °C, respectively. Under these conditions, the maximum removal efficiency of AB113 in PS/ZnO-GAC, TAP, and TAP/ZnO-GAC oxidation systems was 26, 83 and 94.2%, respectively. The synergistic effect of ZnO-GAC on TAP oxidation system reduced the apparent activation energy by approximately 83%. The naphthalen-1-ol, phthalic acid, malonic acid, ethane-1,2-diol, and oxalic acid were the most abundant intermediates produced during AB113 degradation. Radical scavenging experiments showed that 
                        
                           
                              S
                              O
                           
                           
                              4
                           
                           
                              ·
                              -
                           
                        
                      was the predominant radical species in the TAP/ZnO-GAC system. The optimized TAP/ZnO-GAC process effectively improved the biodegradability of real textile wastewater samples (
                        
                           B
                           O
                           D
                           /
                           C
                           O
                           D
                           >
                           0.4
                        
                     ).",industry
10.1016/j.neucom.2020.05.013,Journal,Neurocomputing,scopus,2020-09-03,sciencedirect,Multi-source urban data fusion for property value assessment: A case study in Philadelphia,https://api.elsevier.com/content/abstract/scopus_id/85084813673,"The property value assessment in the real estate market still remains as a challenges due to incomplete and insufficient information, as well as the lack of efficient algorithms. House attributes, such as size and number of bedrooms, are currently being employed to perform the estimation by professional appraisers and researchers. Numerous algorithms have been proposed; however, a better assessment performance is still expected by the market. Nowadays, there are more available relevant data from various sources in urban areas, which have a potential impact on the house value. In this paper, we propose to fuse urban data, i.e., metadata and imagery data, with house attributes to unveil the market value of the property in Philadelphia. Specifically, two deep neural networks, i.e., metadata fusion network and image appraiser, are proposed to extract the representations, i.e., expected levels, from metadata and street-view images, respectively. A boosted regression tree (BRT) is adapted to estimate the market values of houses with the fused metadata and expected levels. The experimental results with the data collected from the city of Philadelphia demonstrate the effectiveness of the proposed model. The research presented in this paper also provides the real estate industry a new reference to the property value assessment with the data fusion methodology.",industry
10.1016/j.cjche.2020.06.015,Journal,Chinese Journal of Chemical Engineering,scopus,2020-09-01,sciencedirect,Deep learning technique for process fault detection and diagnosis in the presence of incomplete data,https://api.elsevier.com/content/abstract/scopus_id/85089986909,"In modern industrial processes, timely detection and diagnosis of process abnormalities are critical for monitoring process operations. Various fault detection and diagnosis (FDD) methods have been proposed and implemented, the performance of which, however, could be drastically influenced by the common presence of incomplete or missing data in real industrial scenarios. This paper presents a new FDD approach based on an incomplete data imputation technique for process fault recognition. It employs the modified stacked autoencoder, a deep learning structure, in the phase of incomplete data treatment, and classifies data representations rather than the imputed complete data in the phase of fault identification. A benchmark process, the Tennessee Eastman process, is employed to illustrate the effectiveness and applicability of the proposed method.",industry
10.1016/j.robot.2020.103578,Journal,Robotics and Autonomous Systems,scopus,2020-09-01,sciencedirect,Real-time topological localization using structured-view ConvNet with expectation rules and training renewal,https://api.elsevier.com/content/abstract/scopus_id/85086575996,"Mobile service robots possess high potential of providing numerous assistances in the working areas. In an attempt to develop a mobile service robot which is dynamically balanced for faster movement and taller manipulation capability, we designed and prototyped J4.alpha, which is intended for swift navigation and nimble manipulation. Previously, we devised a pure visual method based on a supervised deep learning model for real-time recognition of nodal locations. Four low-resolution RGB cameras are installed around J4.alpha to capture the surrounding visual features for training and detection. As the method is developed for ease of implementation, fast real-time application, accurate detection, and low cost, we further improve the accuracy and the practicality of the method in this study. Specifically, a set of expectation rules are introduced to reject outlier detections, and a scheme of training renewal is devised to effectively react to environmental modifications. In our previous tests, precision and recall rates of the location coordinate detection by the ConvNet models were generally between 0.78 and 0.91; by introducing the expectation rules, precision and recall are improved by approximately 10%. A large scale field test is also carried out here for both corridor and factory scenarios; the performance of the proposed method was tested for detection accuracy and verified for 2 m and 0.5 m nodal intervals. The scheme of training renewal designed for capturing and reflecting environmental modifications was also proved to be effective.",industry
10.1016/j.scs.2020.102252,Journal,Sustainable Cities and Society,scopus,2020-09-01,sciencedirect,A deep learning-based IoT-oriented infrastructure for secure smart City,https://api.elsevier.com/content/abstract/scopus_id/85085594643,"In recent years, the Internet of Things (IoT) infrastructures are developing in various industrial applications in sustainable smart cities and societies such as smart manufacturing, smart industries. The Cyber-Physical System (CPS) is also part of IoT-oriented infrastructure. CPS has gained considerable success in industrial applications and critical infrastructure with a distributed environment. This system aims to integrate the physical world to computational facilities as cyberspace. However, there are many challenges, such as security and privacy, centralization, communication latency, scalability in such an environment. To mitigate these challenges, we propose a Deep Learning-based IoT-oriented infrastructure for a secure smart city where Blockchain provides a distributed environment at the communication phase of CPS, and Software-Defined Networking (SDN) establishes the protocols for data forwarding in the network. A deep learning-based cloud is utilized at the application layer of the proposed infrastructure to resolve communication latency and centralization, scalability. It enables cost-effective, high-performance computing resources for smart city applications such as the smart industry, smart transportation. Finally, we evaluated the performance of our proposed infrastructure. We compared it with existing methods using quantitative analysis and security and privacy analysis with different measures such as scalability and latency. The evaluation of our implementation results shows that performance is improved.",industry
10.1016/j.compind.2020.103226,Journal,Computers in Industry,scopus,2020-09-01,sciencedirect,Perspective on holonic manufacturing systems: PROSA becomes ARTI,https://api.elsevier.com/content/abstract/scopus_id/85085261123,"Looking back at 30 years of research into holonic manufacturing systems, these explorations made a lasting scientific contribution to the overall architecture of intelligent manufacturing systems. Most notably, holonic architectures are defined in terms of their world-of-interest (Van Brussel et al., 1998). They do not have an information layer, a communication layer, etc. Instead, they have components that relate to real-world assets (e.g. machine tools) and activities (e.g. assembly). And, they mirror and track the structure of their world-of-interest, which allows them to scale and adapt accordingly.
                  This research has wandered around, at times learning from its mistakes, and progressively carved out an invariant structure while it translated and applied scientific insights from complex-adaptive systems theory (e.g. autocatalytic sets) and from bounded rationality (e.g. holons). This paper presents and discusses the outcome of these research efforts.
                  At the top level, the holonic structure distinguishes intelligent beings (or digital twins) from intelligent agents. These digital twins inherit the consistency from reality, which they mirror. They are intelligent beings when they reflect what exists in the world without imposing artificial limitations in this reality. Consequently, a conflict with a digital twin is a conflict with reality.
                  In contrast, intelligent agents typically transform NP-hard challenges into computations with low-polynomial complexity. Unavoidably, this involves arbitrariness (e.g. don’t care choices). Likewise, relying on case-specific properties, to ensure an outcome in polynomial time, usually renders the validity of an agent’s choices both short-lived and situation-dependent. Here, intelligent agents create conflicts by imposing limitations of their own making in their world-of-interest.
                  Real-world smart systems are aggregates comprising both intelligent beings and intelligent agents. They are performers. Inside these performers, digital twins may constitute the foundations, supporting walls, support beams and pillars because these intelligent beings are protected by their real-world counterpart. Further refining the top-level of this architecture, a holonic structure enables these digital twins to shadow their real-world counterpart whenever it changes, adapts and evolves.
                  In contrast, the artificial limitations, imposed by the intelligent agents, cannot be allowed to build up inertia, which would hamper the undoing of arbitrary or case-specific limitations. To this end, performers explicitly manage the rights over their assets. Revoking such rights from a limitation-imposing agent will free the assets. This will be at the cost of reduced services from the agent. When other service providers rely on this agent, their services may be affected as well; that’s how the inertia builds up and how harmful legacy is created. Thus, the services of digital twins are to be preferred over the services of an intelligent agent by developers of holonic manufacturing systems.
                  Finally, digital twins corresponding to the decision making in the world-of-interest (a non-physical asset) allow to mirror the world-of-interest in a predictive mode (in addition to track and trace). It allows to generate short-term forecasts while preserving the benefits of intelligent beings. These twins are the intentions of the decision-making intelligent agents. Evidently, when intentions change, the forecasts needs to be regenerated (i.e. tracking the corresponding reality by the twin). This advanced feature can be deployed in a number of configurations (cf. annex).",industry
10.1016/j.compind.2020.103244,Journal,Computers in Industry,scopus,2020-09-01,sciencedirect,Machine learning for predictive scheduling and resource allocation in large scale manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/85084401966,"The digitalization processes in manufacturing enterprises and the integration of increasingly smart shop floor devices and software control systems caused an explosion in the data points available in Manufacturing Execution Systems. The degree in which enterprises can capture value from big data processing and extract useful insights represents a differentiating factor in developing controls that optimize production and protect resources. Machine learning and Big Data technologies have gained increased traction being adopted in some critical areas of planning and control. Cloud manufacturing allows using these technologies in real time, lowering the cost of implementing and deployment. In this context, the paper offers a machine learning approach for reality awareness and optimization in cloud.
                  Specifically, the paper focuses on predictive production planning (operation scheduling, resource allocation) and predictive maintenance. The main contribution of this research consists in developing a hybrid control solution that uses Big Data techniques and machine learning algorithms to process in real time information streams in large scale manufacturing systems, focusing on energy consumptions that are aggregated at various layers. The control architecture is distributed at the edge of the shop floor for data collecting and format transformation, and then centralized at the cloud computing platform for data aggregation, machine learning and intelligent decisions. The information is aggregated in logical streams and consolidated based on relevant metadata; a neural network is trained and used to determine possible anomalies or variations relative to the normal patterns of energy consumption at each layer. This novel approach allows for accurate forecasting of energy consumption patterns during production by using Long Short-term Memory neural networks and deep learning in real time to re-assign resources (for batch cost optimization) and detect anomalies (for robustness) based on predicted energy data.",industry
10.1016/j.mechmachtheory.2020.103932,Journal,Mechanism and Machine Theory,scopus,2020-09-01,sciencedirect,Intelligent ball screw fault diagnosis using a deep domain adaptation methodology,https://api.elsevier.com/content/abstract/scopus_id/85084176694,"Intelligent data-driven fault diagnosis methods have been successfully developed in the recent years. However, as one of the most important machines in the industries, the ball screw health monitoring problem has received less attention, due to the complex operating patterns and sophisticated mechanical structures. In practice, the working conditions of the ball screws usually change, that further makes the fault diagnosis problem more challenging since the data distributions are not the same. In order to address this issue, a deep learning-based domain adaptation method is proposed for the cross-domain ball screw fault diagnosis problem. The deep convolutional neural network is adopted for feature extraction and health condition classification. The maximum mean discrepancy metric is proposed to measure and optimize the data distributions of different operating conditions. A data segmentation method which is specially designed for the ball screw is further integrated. The experiments on the real ball screw condition monitoring data are carried out for validation. The results indicate the proposed approach is promising for the cross-domain diagnostic tasks of the ball screw in the real industries.",industry
10.1016/j.ejor.2020.01.061,Journal,European Journal of Operational Research,scopus,2020-09-01,sciencedirect,A learning-based metaheuristic for a multi-objective agile inspection planning model under uncertainty,https://api.elsevier.com/content/abstract/scopus_id/85080942007,"In this paper, we present an agile integrated inspection-operation planning model wherein inspection actions are planned alongside the machining operations to make the production process agile. Such an agile integrated plan can respond quickly to inspection-machining needs while still controlling costs and quality. A tri-objective mixed-integer nonlinear programming (TMINLP) model is developed for planning the integrated process in a serial multi-stage production (MSP) system. This model addresses several inter-related decisions; (1) what is the most appropriate inspection process for a quality characteristic, (2) at which stage the inspection of these quality characteristics should be performed, (3) how these inspections should be performed, (4) which inspection tools should be used, and (5) which machine should operate on products. The three objectives are: (1) minimizing the total manufacturing cost, (2) minimizing the number of nonconforming products shipped, and (3) minimizing the total manufacturing time for each product. We also address the uncertainty of manufacturing parameters and equipment disruptions. To solve the model, a novel learning-based metaheuristic is developed based on Multi-Objective Differential Evolution (MODE) algorithm, k-Means clustering method, and an Iterated Local Search (ILS) algorithm. The proposed learning-based metaheuristic algorithm is then integrated with the Taguchi Loss Function and Monte Carlo methods to address the input parameters’ uncertainty. The proposed model and solution algorithm are validated through a set of experiments against optimal solutions, and benchmarked against four existing well-known approaches, i.e. NSGA-II, MODE and two learning-based metaheuristics. The proposed approach is applied to a real industrial case and insights are provided.",industry
10.1016/j.neucom.2020.02.109,Journal,Neurocomputing,scopus,2020-08-04,sciencedirect,Tracking control of redundant mobile manipulator: An RNN based metaheuristic approach,https://api.elsevier.com/content/abstract/scopus_id/85082490397,"In this paper, we propose a topology of Recurrent Neural Network (RNN) based on a metaheuristic optimization algorithm for the tracking control of mobile-manipulator while enforcing nonholonomic constraints. Traditional approaches for tracking control of mobile robots usually require the computation of Jacobian-inverse or linearization of its mathematical model. The proposed algorithm uses a nature-inspired optimization approach to directly solve the nonlinear optimization problem without any further transformation. First, we formulate the tracking control as a constrained optimization problem. The optimization problem is formulated on position-level to avoid the computationally expensive Jacobian-inversion. The nonholonomic limitation is ensured by adding equality constraints to the formulated optimization problem. We then present the Beetle Antennae Olfactory Recurrent Neural Network (BAORNN) algorithm to solve the optimization problem efficiently using very few mathematical operations. We present a theoretical analysis of the proposed algorithm and show that its computational cost is linear with respect to the degree of freedoms (DOFs), i.e., O(m). Additionally, we also prove its stability and convergence. Extensive simulation results are prepared using a simulated model of IIWA14, a 7-DOF industrial-manipulator, mounted on a differentially driven cart. Comparison results with particle swarm optimization (PSO) algorithm are also presented to prove the accuracy and numerical efficiency of the proposed controller. The results demonstrate that the proposed algorithm is several times (around 75 in the worst case) faster in execution as compared to PSO, and suitable for real-time implementation. The tracking results for three different trajectories; circular, rectangular, and rhodonea paths are presented.",industry
10.1016/j.heliyon.2020.e04667,Journal,Heliyon,scopus,2020-08-01,sciencedirect,Effects of mobile augmented reality apps on impulse buying behavior: An investigation in the tourism field,https://api.elsevier.com/content/abstract/scopus_id/85089806662,"Many of today's online services are designed specifically to encourage impulse buying. Moreover, many studies have shown that with the assistance of Mobile Augmented Reality, retailers have the potential to significantly improve their sales. However, the effects of Mobile AR on consumer impulse buying behavior have yet to be examined, particularly in the tourism field. Consequently, the present study integrates the Technology Acceptance Model (TAM), Stimulus-Organism-Response (SOR) framework, and flow theory to examine the effects of Mobile AR apps on tourist impulse buyingbehavior. The research model is implemented using an online questionnaire, with the results analyzed by Partial-Least-Squares Structural Equation Modeling (PLS-SEM) approach. The results obtained from 479 valid samples show that the characteristics of Mobile AR apps play an important role in governing tourist behavior in making unplanned purchases. In particular, as the utility, ease-of-use, and interactivity of the apps increase, the perceived enjoyment and satisfaction of the user also increase and give rise to a stronger impulse buying behavior. The results also reveal a mediating effect of the flow experience on the relationship between the perceived ease of use of the Mobile AR app and the user satisfaction in using the app. Overall, the findings presented in this study provide a useful source of reference for Mobile AR app developers, retailers, and tourism marketers in better understanding users' preferences for Mobile AR apps and strengthening their impulse buying behavior in the tourism context as a result.",industry
10.1016/j.aei.2020.101101,Journal,Advanced Engineering Informatics,scopus,2020-08-01,sciencedirect,Predictive model-based quality inspection using Machine Learning and Edge Cloud Computing,https://api.elsevier.com/content/abstract/scopus_id/85084733420,"The supply of defect-free, high-quality products is an important success factor for the long-term competitiveness of manufacturing companies. Despite the increasing challenges of rising product variety and complexity and the necessity of economic manufacturing, a comprehensive and reliable quality inspection is often indispensable. In consequence, high inspection volumes turn inspection processes into manufacturing bottlenecks.
                  In this contribution, we investigate a new integrated solution of predictive model-based quality inspection in industrial manufacturing by utilizing Machine Learning techniques and Edge Cloud Computing technology. In contrast to state-of-the-art contributions, we propose a holistic approach comprising the target-oriented data acquisition and processing, modelling and model deployment as well as the technological implementation in the existing IT plant infrastructure. A real industrial use case in SMT manufacturing is presented to underline the procedure and benefits of the proposed method. The results show that by employing the proposed method, inspection volumes can be reduced significantly and thus economic advantages can be generated.",industry
10.1016/j.ymssp.2020.106770,Journal,Mechanical Systems and Signal Processing,scopus,2020-08-01,sciencedirect,Bayesian linear regression for surface roughness prediction,https://api.elsevier.com/content/abstract/scopus_id/85083240491,"To improve the prediction accuracy of surface roughness in milling process, this paper provides an unique feature extraction method and comprehensively analyzes four types of Bayesian linear regression (BLR) model (Standard_BLR, Gaussian_BLR, Standard_SBLR and Gaussian_SBLR). Among them, Standard_SBLR is firstly proposed. Vibration information of the workpiece, fixture and spindle is adopted as the monitoring signal. The unique feature extraction method consists of three stages: extraction of time-domain features from the vibration signals, dimension-reduction by principal component analysis (PCA) and dimension-increment by the integrated radial basis function based kernel principal component analysis (KPCA_IRBF). The BLR models can provide both the predicted value and the corresponding confidence interval (CI). Two types of milling experiment (down milling and up milling) are conducted to reveal the influence of dimension-increment process of KPCA_IRBF on the predictive performance of the BLR models. Experimental results show that when combined with KPCA_IRBF, Standard_SBLR has the best predictive performance among the four BLR models. This also shows that KPCA_IRBF is highly effective in improving the prediction accuracy and compressing the CI of Standard_SBLR. To further prove the superiority of Standard_SBLR, other powerful machine learning methods such as partial least squares regression (PLS), artificial neural network (ANN) and support vector machine (SVM) are also utilized to realize surface roughness prediction under the support of KPCA_IRBF. This paper lays the foundation for accurate monitoring of surface roughness in real industrial settings.",industry
10.1016/j.physa.2019.124049,Journal,Physica A: Statistical Mechanics and its Applications,scopus,2020-08-01,sciencedirect,Fast Super-Paramagnetic Clustering,https://api.elsevier.com/content/abstract/scopus_id/85078038012,"We map stock market interactions to spin models to recover their hierarchical structure using a simulated annealing based Super-Paramagnetic Clustering (SPC) algorithm. This is directly compared to a modified implementation of a maximum likelihood approach we call fast Super-Paramagnetic Clustering (f-SPC). The methods are first applied to standard toy test-case problems, and then to a data-set of 447 stocks traded on the New York Stock Exchange (NYSE) over 1249 days. The signal to noise ratio of stock market correlation matrices is briefly considered. Our result recover approximately clusters representative of standard economic sectors and mixed ones whose dynamics shine light on the adaptive nature of financial markets and raise concerns relating to the effectiveness of industry based static financial market classification in the world of real-time data analytics. A key result is that we show that f-SPC maximum likelihood solutions converge to ones found within the Super-Paramagnetic Phase where the entropy is maximum, and those solutions are qualitatively better for high dimensionality data-sets.",industry
10.1016/j.measurement.2020.107768,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-07-15,sciencedirect,"Intelligent fault diagnosis of rotating machinery via wavelet transform, generative adversarial nets and convolutional neural network",https://api.elsevier.com/content/abstract/scopus_id/85082880587,"The fault detection of rotating machinery systems especially its typical components such as bearings and gears is of special importance for maintaining machine systems working normally and safely. However, due to the change of working conditions, the disturbance of environment noise, the weakness of early features and various unseen compound failure modes, it is quite hard to achieve high-accuracy intelligent failure monitoring task of rotating machinery using existing intelligent fault diagnosis approaches in real industrial applications. In the paper, a novel and high-accuracy fault detection approach named WT-GAN-CNN for rotating machinery is presented based on Wavelet Transform (WT), Generative Adversarial Nets (GANs) and convolutional neural network (CNN). The proposed WT-GAN-CNN approach includes three parts. To begin with, WT is employed for extracting time-frequency image features from one-dimension raw time domain signals. Secondly, GANs are used to generate more training image samples. Finally, the built CNN model is used to accomplish the fault detection of rotating machinery by the original training time-frequency images and the generated fake training time-frequency images. Two experiment studies are implemented to assess the effectiveness of our proposed approach and the results demonstrate it is higher in testing accuracy than other intelligent failure detection approaches in the literatures even in the interference of strong environment noise or when working conditions are changed. Furthermore, its result in the stability of testing accuracy is also quite excellent.",industry
10.1016/j.chempr.2020.05.014,Journal,Chem,scopus,2020-07-09,sciencedirect,"Learning to Make Chemical Predictions: The Interplay of Feature Representation, Data, and Machine Learning Methods",https://api.elsevier.com/content/abstract/scopus_id/85087384615,"Recently, supervised machine learning has been ascending in providing new predictive approaches for chemical, biological, and materials sciences applications. In this Perspective, we focus on the interplay of machine learning methods with the chemically motivated descriptors and the size and type of datasets needed for molecular property prediction. Using nuclear magnetic resonance chemical shift prediction as an example, we demonstrate that success is predicated on the choice of feature extracted or real-space representations of chemical structures, whether the molecular property data are abundant and/or experimentally or computationally derived, and how these together will influence the correct choice of popular machine learning methods drawn from deep learning, random forests, or kernel methods.",industry
10.1016/j.knosys.2020.105971,Journal,Knowledge-Based Systems,scopus,2020-07-08,sciencedirect,Intelligent fault diagnosis of rolling bearings based on normalized CNN considering data imbalance and variable working conditions,https://api.elsevier.com/content/abstract/scopus_id/85084170861,"Intelligent fault detection and diagnosis, as an important approach, play a crucial role in ensuring the stable, reliable and safe operation of rolling bearings, which is one of the most important components in the rotating machinery. In real industries, it is common to face that the issues of severe data imbalance and distribution difference since the number of fault data is small and the equipments frequently change the working conditions according to the production. To accurately and automatically identify the conditions of rolling bearings, a normalized convolutional neural network is proposed for the diagnosis of different fault severities and orientations considering data imbalance and variable working conditions. First, the batch normalization is adopted as a novel application to eliminate feature distribution difference, which is the prerequisite for ensuring generalization ability under different working conditions. Then, a special model structure is established and the overall performances of the proposed model are optimized by iterative update, which combines the exponential moving average technology. Finally, the proposed model is applied to the fault diagnosis under different data imbalance cases and working conditions. The effectiveness of the proposed method is verified based on two popular experiment dataset, and the diagnosis performance is widely evaluated in different scenarios. Comparisons with other commonly used methods and related works on the same dataset demonstrate the superiority of the proposed method. The results show that the proposed method has excellent diagnosis accuracy and admirable robustness, and also has sufficient stability on the data imbalance.",industry
10.1016/j.heliyon.2020.e04289,Journal,Heliyon,scopus,2020-07-01,sciencedirect,Predicting extrusion process parameters in Nigeria cable manufacturing industry using artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/85088638910,"The extrusion process is a very complex process due to the number of process parameters that are associated with it which are prone to high fluctuations. The main purpose of this work is to determine the realistic extrusion process parameters in the thermoplastic extrusion process in Nigeria cable manufacturing industries with the use of an artificial neural network. Conventionally, the use of trial and error technique which involves full-size experiments is generally used to determine the process parameters in the thermoplastic extrusion process. This conventional technique is expensive and it is also time-consuming. The use of an artificial neural network to predict extrusion process parameters before plant execution will make extrusion process operations more efficient. This technique also bridges the gap that exists between theoretical analysis and real manufacturing system because real manufacturers' data was used. The neural network was developed in a MATLAB environment and was trained with a supervised learning method based on Levenberg Marquardt Algorithm and the developed ANN model is capable of predicting manufacturing process parameters for different grades of PVC thermoplastic material.",industry
10.1016/j.jmsy.2020.06.001,Journal,Journal of Manufacturing Systems,scopus,2020-07-01,sciencedirect,Deep reinforcement learning for a color-batching resequencing problem,https://api.elsevier.com/content/abstract/scopus_id/85086638517,"In automotive paint shops, changes of colors between consecutive production orders cause costs for cleaning the painting robots. It is a significant task to re-sequence orders and group orders with identical color as a color batch to minimize the color changeover costs. In this paper, a Color-batching Resequencing Problem (CRP) with mix bank buffer systems is considered. We propose a Color-Histogram (CH) model to describe the CRP as a Markov decision process and a Deep Q-Network (DQN) algorithm to solve the CRP integrated with the virtual car resequencing technique. The CH model significantly reduces the number of possible actions of the DQN agent, so that the DQN algorithm can be applied to the CRP at a practical scale. A DQN agent is trained in a deep reinforcement learning environment to minimize the costs of color changeovers for the CRP. Two experiments with different assumptions on the order attribute distributions and cost metrics were conducted and evaluated. Experimental results show that the proposed approach outperformed conventional algorithms under both conditions. The proposed agent can run in real time on a regular personal computer with a GPU. Hence, the proposed approach can be readily applied in the production control of automotive paint shops to resolve order-resequencing problems.",industry
10.1016/j.telpol.2020.101960,Journal,Telecommunications Policy,scopus,2020-07-01,sciencedirect,Innovation ecosystems theory revisited: The case of artificial intelligence in China,https://api.elsevier.com/content/abstract/scopus_id/85083340447,"Beyond the mainstream discussion on the key role of China in the global AI landscape, the knowledge about the real performance and future perspectives of the AI ecosystem in China is still limited. This paper evaluates the status and prospects of China's AI innovation ecosystem by developing a Triple Helix framework particularized for this case. Based on an in-depth qualitative study and on interviews with experts, the analysis section summarizes the way in which the AI innovation ecosystem in China is being built, which are the key features of the three spheres of the Triple Helix -governments, industry and academic/research institutions-as well as the dynamic context of the ecosystem through the identification of main aspects related to the flows of skills, knowledge and funding and the interactions among them. Using this approach, the discussion section illustrates the specificities of the AI innovation ecosystem in China, its strengths and its gaps, and which are its prospects. Overall, this revisited ecosystem approach permits the authors to address the complexity of emerging environments of innovation to draw meaningful conclusions which are not possible with mere observation. The results show how a favourable context, the broad adoption rate and the competition for talent and capital among regional-specialized clusters are boosting the advance of AI in China, mainly in the business to customer arena. Finally, the paper highlights the challenges ahead in the current implementation of the ecosystem that will largely determine the potential global leadership of China in this domain.",industry
10.1016/j.ins.2020.03.063,Journal,Information Sciences,scopus,2020-07-01,sciencedirect,Generating behavior features for cold-start spam review detection with adversarial learning,https://api.elsevier.com/content/abstract/scopus_id/85083304717,"Due to the wide applications, spam detection has long been a hot research topic in both academia and industry. Existing studies show that behavior features are effective in distinguishing the spam and legitimate reviews. However, it usually takes a long time to collect such features and thus is hard to apply them to cold-start spam review detection tasks. Recent advances leveraged the neural network to encode the various types of textual, behavior, and attribute information for this task. However, the inherent problem, i.e., lack of effective behavior features for new users who post just one review, is still unsolved.
                  In this paper, we exploit the generative adversarial network (GAN) for addressing this problem. The key idea is to generate synthetic behavior features (SBFs) for new users from their easily accessible features (EAFs). Specifically, we first select six well recognized real behavior features (RBFs) existing for regular users. We then train a GAN framework including a generator to generate SBFs from their EAFs including text, rating, and attribute features, and a discriminator to discriminate RBFs and SBFs. We design a new implementation of generator and discriminator for effective training. The trained GAN is finally applied to new users for generating synthetic behavior features. We conduct extensive experiments on two Yelp datasets. Experimental results demonstrate that our proposed framework significantly outperforms the state-of-the-art methods.",industry
10.1016/j.petrol.2020.107087,Journal,Journal of Petroleum Science and Engineering,scopus,2020-07-01,sciencedirect,Transformation of academic teaching and research: Development of a highly automated experimental sucker rod pumping unit,https://api.elsevier.com/content/abstract/scopus_id/85079611752,"Sucker rod pumps are one of the most popular solutions for artificial lift since their inception in the 19th century with minimum changes in design. Presently, companies are deploying digital technology in the field and, there has been a big push for a networked oilfield in recent years. This means technology is now able to control machines in remote places, evaluate their performances and control safety operating parameters. But these digital solutions are still not available in universities, causing a technological and technical gap for students and researchers.
                  This study presents a prototype of a new dedicated Interactive Digital Sucker Rod Pumping Unit (ID-SRP) system at the University of Oklahoma with representative operating conditions. The prototype mimics sucker rod pump working principles and also imitates different realistic rod string motions. The application and solutions are focused on providing authentic learning experiences for petroleum engineers. The system is also designed to address and optimize SRP well performance and safety through Model Predictive Controller (MPC) implementation and meeting industrial requirements. It connects the physical and virtual interaction with learning technologies. The objective is to bridge the tangible and the abstract for a better understanding of sucker rod concept and implement existing theories into the digital system. Additionally, it aids our future petroleum engineers on how to apply basic industry principles and upsurge their problem-solving skills.
                  The developed unit is capable of simulating any situations in real time and using Internet of Things (IoT) for data acquisition to create tailored diagnostic tools that students and laboratory staff can utilize. The software selected for the system is LabVIEW, which controls all the necessary equipment. This system can build personalized dynocard graphs, intake live data and export them to other programs live Excel, MATLAB, Python or any other programming languages.",industry
10.1016/j.eswa.2020.113251,Journal,Expert Systems with Applications,scopus,2020-07-01,sciencedirect,Integrating complex event processing and machine learning: An intelligent architecture for detecting IoT security attacks,https://api.elsevier.com/content/abstract/scopus_id/85079340111,"The Internet of Things (IoT) is growing globally at a fast pace: people now find themselves surrounded by a variety of IoT devices such as smartphones and wearables in their everyday lives. Additionally, smart environments, such as smart healthcare systems, smart industries and smart cities, benefit from sensors and actuators interconnected through the IoT. However, the increase in IoT devices has brought with it the challenge of promptly detecting and combating the cybersecurity attacks and threats that target them, including malware, privacy breaches and denial of service attacks, among others. To tackle this challenge, this paper proposes an intelligent architecture that integrates Complex Event Processing (CEP) technology and the Machine Learning (ML) paradigm in order to detect different types of IoT security attacks in real time. In particular, such an architecture is capable of easily managing event patterns whose conditions depend on values obtained by ML algorithms. Additionally, a model-driven graphical tool for security attack pattern definition and automatic code generation is provided, hiding all the complexity derived from implementation details from domain experts. The proposed architecture has been applied in the case of a healthcare IoT network to validate its ability to detect attacks made by malicious devices. The results obtained demonstrate that this architecture satisfactorily fulfils its objectives.",industry
10.1016/j.engappai.2020.103643,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-06-01,sciencedirect,Distributed gas concentration prediction with intelligent edge devices in coal mine,https://api.elsevier.com/content/abstract/scopus_id/85083340076,"Gas disaster can be triggered by gas concentrations exceeding standard levels, and gas concentration prediction system can reduce the occurrence of gas disaster by predicting the trend of gas concentration and alerting engineers to take necessary measures whenever needed. With the increasing use of intelligent edge devices in coal mines and the limitations of some existing systems, developing a new gas concentration prediction system for large-scale intelligent edge devices has become an important issue. This work proposes to address the issue through a novel method for predicting gas concentrations by taking full advantage of multidimensional data in an intelligent edge system. Specifically, 1) it proposed a Single hidden layer Random Weights Neural Network (SRWNN) as the prediction model, which is based on interval prediction rather than point prediction; 2) It employs a Non-dominated Sorting Genetic Algorithm II (NSGA-II) to train SRWNN; 3) To significantly reduce the time consumed during model training and facilitate real-time predictions, it proposes a distributed gas concentration prediction scheme based on an intelligent edge system; and 4) it conducts extensive experiments by using actual industrial data collected from a company to demonstrate the superior performance of the proposed method.",industry
10.1016/j.asoc.2020.106208,Journal,Applied Soft Computing Journal,scopus,2020-06-01,sciencedirect,Dynamic scheduling for flexible job shop with new job insertions by deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85081140568,"In modern manufacturing industry, dynamic scheduling methods are urgently needed with the sharp increase of uncertainty and complexity in production process. To this end, this paper addresses the dynamic flexible job shop scheduling problem (DFJSP) under new job insertions aiming at minimizing the total tardiness. Without lose of generality, the DFJSP can be modeled as a Markov decision process (MDP) where an intelligent agent should successively determine which operation to process next and which machine to assign it on according to the production status of current decision point, making it particularly feasible to be solved by reinforcement learning (RL) methods. In order to cope with continuous production states and learn the most suitable action (i.e. dispatching rule) at each rescheduling point, a deep Q-network (DQN) is developed to address this problem. Six composite dispatching rules are proposed to simultaneously select an operation and assign it on a feasible machine every time an operation is completed or a new job arrives. Seven generic state features are extracted to represent the production status at a rescheduling point. By taking the continuous state features as input to the DQN, the state–action value (Q-value) of each dispatching rule can be obtained. The proposed DQN is trained using deep Q-learning (DQL) enhanced by two improvements namely double DQN and soft target weight update. Moreover, a “softmax” action selection policy is utilized in real implementation of the trained DQN so as to promote the rules with higher Q-values while maintaining the policy entropy. Numerical experiments are conducted on a large number of instances with different production configurations. The results have confirmed both the superiority and generality of DQN compared to each composite rule, other well-known dispatching rules as well as the stand Q-learning-based agent.",industry
10.1016/j.mineng.2020.106332,Journal,Minerals Engineering,scopus,2020-06-01,sciencedirect,Convolutional memory network-based flotation performance monitoring,https://api.elsevier.com/content/abstract/scopus_id/85081131615,"In flotation process monitoring, visual soft sensors provide stable and reliable online estimations for a concentrate grade, which is difficult to be measured online owing to technical or economic limitations. It is known that hand-crafted features are at times inefficient in extracting features consistent with the experiences of operators. Furthermore, the froth layer always contains some undesired impurities. To grade the product appropriately, soft sensors need to be capable of differentiating patterns produced by different substances. In the context of these issues, this study developed a convolutional memory network-based visual soft-sensor, in which GoogLeNet, trained in a Siamese paradigm, is used to learn the representations for froth images and a semantic key-value memory network is used to recall similar historical records, helping to achieve accurate grade estimation. Simulations using real-world production data verified the effectiveness of the proposed monitoring method. Further, industrial experiments conducted in a lead-zinc flotation plant in China corroborated the fact that our method can provide reliable concentrate grade estimation.",industry
10.1016/j.reth.2019.12.001,Journal,Regenerative Therapy,scopus,2020-06-01,sciencedirect,Thickness-wise growth technique for human articular chondrocytes to fabricate three-dimensional cartilage grafts,https://api.elsevier.com/content/abstract/scopus_id/85077922678,"Introduction
                  Cutting the cost of manufacturing is important for extending the use of tissue-engineered therapeutic products. The present study aimed to develop a simple method for fabrication of cartilaginous tissues for regenerative therapy, utilizing the phenomenon where human articular chondrocytes grow thickness-wise and spontaneously form three-dimensionally thick tissues.
               
                  Methods
                  Normal human articular chondrocytes (NHACs) were cultured with varying concentrations of transforming growth factor beta 1 (TGF-β1) and/or fibroblast growth factor-2 (FGF-2) to optimize the culture condition for thickness-wise growth of chondrocytes. Next, the tissues grown in the optimal condition were subjected to re-differentiation culture in attached and detached states to assess differentiation capacity by evaluating secreted factors, histological analysis, and a gene expression assay.
               
                  Results
                  NHACs grew thickness-wise efficiently in the presence of 1 ng/mL TGF-β1 and 10 ng/mL FGF-2. After two weeks of culture, NHACs grew with 11-fold higher thickness and 16-fold higher cell number compared to cells which were neither treated with TGF-β1 nor with FGF-2. These thickness-wise-grown chondrocytes could be re-differentiated by a differentiation medium according to the increase in melanoma inhibitory activity (MIA) and positive safranin-O staining. Interestingly, the cartilaginous gene expression was considerably different between the attached and detached conditions even in the same culture medium, indicating the necessity of detachment and shrinkage to achieve further differentiation.
               
                  Conclusions
                  Spontaneous thickness-wise growth might provide a simple tissue-engineering method for manufacturing cartilaginous 3D tissues.",industry
10.1016/j.rcim.2019.101887,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2020-06-01,sciencedirect,Deep learning-based smart task assistance in wearable augmented reality,https://api.elsevier.com/content/abstract/scopus_id/85074770255,"Wearable augmented reality (AR) smart glasses have been utilized in various applications such as training, maintenance, and collaboration. However, most previous research on wearable AR technology did not effectively supported situation-aware task assistance because of AR marker-based static visualization and registration. In this study, a smart and user-centric task assistance method is proposed, which combines deep learning-based object detection and instance segmentation with wearable AR technology to provide more effective visual guidance with less cognitive load. In particular, instance segmentation using the Mask R-CNN and markerless AR are combined to overlay the 3D spatial mapping of an actual object onto its surrounding real environment. In addition, 3D spatial information with instance segmentation is used to provide 3D task guidance and navigation, which helps the user to more easily identify and understand physical objects while moving around in the physical environment. Furthermore, 2.5D or 3D replicas support the 3D annotation and collaboration between different workers without predefined 3D models. Therefore, the user can perform more realistic manufacturing tasks in dynamic environments. To verify the usability and usefulness of the proposed method, we performed quantitative and qualitative analyses by conducting two user studies: 1) matching a virtual object to a real object in a real environment, and 2) performing a realistic task, that is, the maintenance and inspection of a 3D printer. We also implemented several viable applications supporting task assistance using the proposed deep learning-based task assistance in wearable AR.",industry
10.1016/j.neucom.2019.07.103,Journal,Neurocomputing,scopus,2020-05-21,sciencedirect,Visual Recognition of traffic police gestures with convolutional pose machine and handcrafted features,https://api.elsevier.com/content/abstract/scopus_id/85074513481,"Autonomous vehicles have become a hot spot of the automotive industry, many cities have claimed that autonomous vehicles should be capable of recognizing gestures used by traffic police. Traditional traffic police gesture recognition methods rely on depth-sensor or wearable-devices, which limits their availability in the domain of the intelligent vehicle. Vision-based methods have fewer requirements for distance, but the modeling process is challenging due to the complexity of the visual scenes. Inspired by the recent success in vision-based pose estimation networks such as Convolutional Pose Machine (CPM), in this paper, we propose a novel vision-based human-machine interface to recognize eight kinds of Chinese traffic police gestures and apply it in the real-time recognition tasks. This method integrates a modified CPM network and two kinds of handcrafted features: Relative Bone Length and Angle with Gravity as spatial domain features, and adopt a Long short-term memory (LSTM) network to extract temporal domain features. To train and validate our method, we create a gestures dataset with two hours of traffic police gesture videos, which has 3354 gesture instances. The experiment results show that the proposed method is capable of recognizing traffic police gestures, and is fast enough for online gesture prediction.",industry
10.1016/j.comcom.2020.04.053,Journal,Computer Communications,scopus,2020-05-15,sciencedirect,IOT and cloud computing based parallel implementation of optimized RBF neural network for loader automatic shift control,https://api.elsevier.com/content/abstract/scopus_id/85089243295,"One of the key issues in automatic shift control of V-type cyclical loaders is determining how to find the best gear for the current conditions according to a certain mapping relation, but this complex and nonlinear mapping is difficult to express by a mathematical relation. However, to solve such nonlinear problems, a radial basis function (RBF) neural network is the best choice. In this paper, a certain type of wheel loader is taken as the research object, and an RBF neural network algorithm based on an improved genetic algorithm (GA) optimization is proposed. The global search ability of the GA is improved by adaptively adjusting the crossover probability and mutation probability. The RBF neural network expansion coefficient is optimized by an improved GA. Using industrial IOT technology, an optimized RBF neural network based on Map-Reduce on a cloud computing cluster is designed. The diesel engine computer and transmission computer on the loader are integrated to achieve dual-processor distributed parallel data processing and calculation. Then the loader automatic variable speed control algorithm model of improved GA optimized RBF neural network based on IOT cloud computing is established. The network model is trained and simulated using real vehicle automatic shift test data. The simulation results show that the improved GA-RBF neural network algorithm can achieve a correct recognition rate of 97.92%. The error matrix norm reaches the minimum value when the algorithm is iterated to the 17th generation. The improved algorithm has the advantages of a high gear recognition rate, fast convergence speed and strong real-time shift performance and is an effective new shift control method. The test results show that the shift boost time is less than 0.15 s and has a certain gradient. Compared with the manual shift process performed in the past, some improvements are achieved in the optimal shift time, shift response speed and shift quality. Compared with the traditional single computer based on serial training RBF neural network learning algorithm, whether it is Great progress has been made in convergence speed, training time, recognition rate, and data processing capabilities. Through the simulation and test, the validity of the intelligent shift control method of the improved GA optimized RBF neural network based on IOT cloud computing is verified. It has better engineering application value.",industry
10.1016/j.neucom.2020.01.032,Journal,Neurocomputing,scopus,2020-05-07,sciencedirect,A robust approach to reading recognition of pointer meters based on improved mask-RCNN,https://api.elsevier.com/content/abstract/scopus_id/85078095125,"In this paper, we address a challenging task in real-word applications, i.e., automatic reading recognition for pointer meters, called PRM.
                        1
                     
                     
                        1
                        PRM: Pointer merters Recognition based on Mask-RCNN.
                      This application is valuable in the fields of military, industry, and aerospace. However, the accuracy of recognizing the readings of pointer meters by machine vision is, oftentimes, affected by several factors, such as uneven illumination in each image, large range variation of illumination in different images, complex backgrounds, tilting of pointer meters, image blur, and scale change, resulting in the recognized readings with unacceptable accuracy. In this paper, a new robust approach to reading recognition of pointer meters is proposed. The proposed method consists of three main contributions: (1) constructing a novel deep learning algorithm in which the PrRoIPooling is used in lieu of the RoiAlign in the existing Mask-RCNN, (2) classifying the type of pointer meters while fitting the pointer binary mask, and (3) calculating the readings of pointer meters by the proposed angle method. In addition, we also report and release a new dataset for the community. Experiments show that the new algorithm can significantly improve the accuracy of the recognized readings of pointer meters, meanwhile, the proposed approach is also robust to the natural environments and computationally efficient.",industry
10.1016/j.microrel.2020.113640,Journal,Microelectronics Reliability,scopus,2020-05-01,sciencedirect,Two phase cooling with nano-fluid for highly dense electronic systems-on-chip – A pilot study,https://api.elsevier.com/content/abstract/scopus_id/85083093178,"In recent days, electronics gadgets need to design for higher functionalities with dense populated systems in order to meet the demands like lower in size, weight and power consumption. Even industrial electronic component and system design also prefer same slim fashion. On other hand the overheating of electronic components reduces its performance, life and by the way the reliability of such electronic product/system is greatly affected due to overheating. The conventional cooling methods failed to offer best performances. Hence this part of research proposed a effective two phase cooling technique with nano-fluid. The objective of this research is to maintain the maximum temperature at the junction and hot spots in order to break a new ground in the cooling of electronic systems. The Maximum permissible operating temperature for any commercial electronic applications is only upto 70 °C (equal to 343.15 K) and above which most of the inherent electronic circuits may malfunction and destroy the entire application.The HotSpot Simulator-6.0 software employed for establish, verify the simulated model and trial runs to answer many ‘what if’ questions. In the simulation, hottest spot has been found in Int_Reg region, where the steady temperature grows beyond the threshold temperature level. The temperature has to be decreased in order to provide reliable working environment. Hence, HFO 1234ze nano-fluid employed with flow rate of 1100 ml per minute. The nanofliuid minimizes the temperature of the simulated electronic circuit from 351.80 K to 326.86 K in UUT. The proposed two phase nano-fluid cooling system for 3-D Unit-Under Test (UUT) was verified and validated with real system and simulated for experiments. Thus, a high range of temperature difference from the initial and final steady state temperature has been evidently shown in the proposed two phase nano fluid cooling method. The system found outperforms as best of both the worlds. The nanofluid cooling system can be used in thermal-aware systems and highly dense systems to maintain the temperature not much than 343.15 K, even at full load conditions.",industry
10.1016/j.precisioneng.2020.03.002,Journal,Precision Engineering,scopus,2020-05-01,sciencedirect,An integrated error compensation method based on on-machine measurement for thin web parts machining,https://api.elsevier.com/content/abstract/scopus_id/85081052034,"Thin webs are widely used in the aerospace industry for the advantages of compact structure, light weight and high strength-to-weight ratio. Due to its low rigidity, serious machining error may occur, therefore, Finite Element method and mechanism analysis are usually utilized to modeling its deformation. However, they are very time-consuming and only suitable for elastic deformation error. In this study, an integrated error compensation method is proposed based on on-machine measurement (OMM) inspection and error compensation. The OMM inspection is firstly applied to measure the comprehensive machining errors. The Hampel filtering is then used to eliminate outliers, followed by the triangulation-based cubic interpolation as well as a machine learning algorithm which are used to establish the compensation model. At last, the real time compensation of high-density cutting points is realized by developing the compensation system based on External Machine Zero Point Shift (EMZPS) function of machine tool. Three sets of machining experiment of a typical thin web part are conducted to validate the feasibility and efficiency of the proposed method. Experiment results revealed that after compensation, the comprehensive machining errors were controlled under different machining conditions and 58.1%, 68.4% and 62.6% of the machining error ranges were decreased, respectively. This method demonstrates immense potential for further applications in efficiency and accuracy improvement of thin-walled surface parts.",industry
10.1016/j.conengprac.2020.104360,Journal,Control Engineering Practice,scopus,2020-05-01,sciencedirect,Timed key-value memory network for flotation reagent control,https://api.elsevier.com/content/abstract/scopus_id/85081012301,"Computer vision-based flotation reagent control (FRC) is a nonintrusive, cost-effective, and reliable technique for changing a deviated flotation status to an optimal status, which produces a product at the target concentrate grade and recovery. It is known that deep froth image features can depict the complex behavior of the froth layer comprehensively and accurately. However, it is still a major challenge to use high-dimensional deep features to construct FRC controllers. In this study, a novel FRC method based on memory networks is proposed. First, a convolutional neural network-based image encoder is constructed to extract deep froth image features. Then, a key–value structured memory network is designed to learn heuristic rules relating deep froth image features to the corresponding corrective operation actions for the reagents. The proposed method can be incrementally updated without catastrophic forgetting and can explore time-series information and changing patterns of froth surface appearance. Additionally, it can handle input images whose size is variable. Experiments using real-world production data verified the effectiveness of the proposed FRC method. In addition, industrial experiments in a real lead–zinc flotation plant in China demonstrated that the new method could obtain reliable flotation process control.",industry
10.1016/j.ijmultiphaseflow.2019.103194,Journal,International Journal of Multiphase Flow,scopus,2020-05-01,sciencedirect,Bubble patterns recognition using neural networks: Application to the analysis of a two-phase bubbly jet,https://api.elsevier.com/content/abstract/scopus_id/85079560188,"Gas-liquid two-phase bubbly flows are found in different areas of science and technology such as nuclear energy, chemical industry, or piping systems. Optical diagnostics of two-phase bubbly flows with modern panoramic techniques makes it possible to capture simultaneously instantaneous characteristics of both continuous and dispersed phases with a high spatial resolution. In this paper, we introduce a novel approach based on neural networks to recognize bubble patterns in images and identify their geometric parameters. The originality of the proposed method consists in training of a neural network ensemble using synthetic images that resemble real photographs gathered in experiment. The use of neural networks in combination with automatically generated data allowed us to detect overlapping, blurred, and non-spherical bubbles in a broad range of volume gas fractions. Experiments on a turbulent bubbly jet proved that the implemented method increases the identification accuracy, reducing errors of various kinds, and lowers the processing time compared to conventional recognition methods. Furthermore, utilizing the new method of bubbles recognition, the primary physical parameters of a dispersed phase, such as bubble size distribution and local gas content, were calculated in a near-to-nozzle region of the bubbly jet. The obtained results and integral experimental parameters, especially volume gas fraction, are in good agreement with each other.",industry
10.1016/j.marpol.2020.103829,Journal,Marine Policy,scopus,2020-05-01,sciencedirect,Analyzing gaps in policy: Evaluation of the effectiveness of minimum landing size (MLS) regulations in Turkey,https://api.elsevier.com/content/abstract/scopus_id/85079518573,"The Mediterranean and Black Sea host the most intense overfishing and Turkey has the largest commercial fisheries in them (when both seas considered). However, the state of the Turkish fisheries is in critical condition as both the quality (i.e, in number of caught species, value and sizes of fish) and quantity of fisheries catches have been rapidly declining in recent decades. One pioneer fisheries management initiative thoroughly evaluated here pertains to minimum landing size (MLS) regulations for commercial taxa, with the aim of promoting stock sustainability by ensuring fish reproduce before they are caught. This study examines 29 taxa in relation to MLS by analyzing changes in catch per unit effort trends pre-and post MLS to gauge regulation effectiveness, changes to MLS regulations since implementation, and finally evaluates the Turkish MLS sizes in relation to Turkish maturity sizes, to provide advice for taxa requiring changes. It seems intensive fishing may have reduced the size at maturity for many species in Turkey, as they mature smaller here than the Mediterranean and global averages. Eleven taxa listed in MLS regulations are under the lengths of first maturity (Lmat) sizes in Turkish waters and need to be increased, especially that of bonito, hake, swordfish and bluefish (by 18 cm, 10 cm, 10 cm and 8 cm, respectively), while 16 taxa still require national studies to determine their Lmat sizes in Turkish waters. In conclusion, in Turkey, MLS regulations are completely ineffective due to a lack of monitoring and control for juvenile fish at landing sites, markets and processing plants, along with insufficient penalties for such infractions, yet, there remains plenty of room for improvement. To improve the state of the fisheries, MLS measures could be improved by increasing fines, monitoring and control, making some gear types more selective and use of real-time closures and no fishing zones to protect spawning and nursery habitats.",industry
10.1016/j.measurement.2020.107539,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-05-01,sciencedirect,A simple data augmentation algorithm and a self-adaptive convolutional architecture for few-shot fault diagnosis under different working conditions,https://api.elsevier.com/content/abstract/scopus_id/85079319367,"In the era of big data, various data-driven fault diagnosis algorithms, which are mainly based on traditional machine learning and deep learning, have been developed and successfully applied on several benchmark datasets. However, in the real world, there are two major obstacles that prevent existing data-driven algorithms from being applied in actual industrial diagnostics applications: a) few-shot learning with limited labelled data, and b) high requirement for model’s generalization ability to adapt different diagnosis circumstances. Two classic feature engineering methods of Order Tracking and Fast Fourier Transform give us inspirations to solve these problems. In this paper, we propose a data augmentation algorithm based on the core assumption of Order Tracking and present a self-adaptive convolutional neural network for fault diagnosis. The data augmentation algorithm utilizes resampling technique to simulate data under different rotating speeds and working loads, in which the Fast Fourier Transform is embedded alternately to calculate the frequency spectra of the expanded dataset. Based on the robust features in the spectra, the self-adaptive convolutional architecture is designed with much fewer Floating Points Operations (FLOPs) and trainable parameters than the deep counterparts, by which the extracted features are invariant for generalization and discriminative for classification. Experiments based on two bearing databases have been carried out and the results have verified the generalization ability and adaptability for few-shot learning of our proposed methods.",industry
10.1016/j.ress.2020.106821,Journal,Reliability Engineering and System Safety,scopus,2020-05-01,sciencedirect,Towards Efficient Robust Optimization using Data based Optimal Segmentation of Uncertain Space,https://api.elsevier.com/content/abstract/scopus_id/85078707908,"Performing multi-objective optimization under uncertainty is a common requirement in industries and academia. Robust optimization (RO) is considered as an efficient and tractable approach provided one has access to behavioral data for the uncertain parameters. However, solutions of RO may be far from the real solution and less reliable due to inability to map the uncertain space accurately, especially when the data appears discontinuous and scattered in the uncertain domain. Amalgamating machine learning algorithms with RO, this paper proposes a data-driven methodology, where a novel fuzzy clustering mechanism is implemented along-with boundary construction, to transcript the uncertain space such that the specific regions of uncertainty are identified. Subsequently, using intelligent Sobol sampling, samples are generated in the mapped uncertain regions. Results of two test cases are presented along with a comprehensive comparison study. Considered case-studies include highly nonlinear model for continuous casting process from steelmaking industries, where a multi-objective optimization problem under uncertainty is solved to balance the conflict between productivity and energy consumption. The Pareto-optimal solutions of the resulting RO problem are obtained through Non-Dominated Sorting Genetic Algorithm – II, and ~23–29% improvement is observed in the uncertain objective function. Further, the spread and diversity metrics are enhanced by ~10–95% as compared to those obtained using other standard uncertainty sets.",industry
10.1016/j.chemosphere.2019.125730,Journal,Chemosphere,scopus,2020-05-01,sciencedirect,Toxicity assessment of parabens in Caenorhabditis elegans,https://api.elsevier.com/content/abstract/scopus_id/85077400711,"Parabens, the alkyl esters of p-hydroxybenzoic acid such as methylparaben (MeP), ethylparaben (EtP), propylparaben (PrP), butylparaben (BuP) are used as a preservative in food, personal care products (PCPs), and pharmaceuticals, due to their antimicrobial properties. Parabens are continuously released into the environment, during washout of PCPs, disposal of industrial waste from the pharmaceutical and paper industries. Parabens have been detected in the indoor dust, wastewater stream, surface water of rivers, and the marine system. Recent eco-toxicological data and the environmental presence of parabens, has raised concerns regarding the safety and health of environment/humans. Thus, to further understand the toxicity of parabens, the present study was carried out in the soil nematode and well established biological model organism Caenorhabditis elegans. In the present study, LC50 of MeP, EtP, PrP and BuP for 72 h exposures from L1 larva to adult stage was found to be 278.1, 217.8, 169.2, and 131.88 μg/ml, respectively. Further exposure to 1/5th of LC50 of parabens yielded an internal concentration ranging from 1.67 to 2.83 μg/g dry weight of the organism. The toxicity of parabens on the survival, growth, behavior, and reproduction of the C. elegans was found in the order of BuP > PrP > EtP > MeP. Worms exposed to parabens show significant down-regulation of vitellogenin genes, high levels of reactive oxygen species and anti-oxidant transcripts, the latter being concordant with nuclear localization of DAF-16 and up-regulation of HSF-1 and SKN-1/Nrf. Hence, parabens caused endocrine disruption, oxidative stress and toxicity in C. elegans at environment relevant internal concentration of parabens.",industry
10.1016/j.ejor.2019.10.015,Journal,European Journal of Operational Research,scopus,2020-05-01,sciencedirect,From one-class to two-class classification by incorporating expert knowledge: Novelty detection in human behaviour,https://api.elsevier.com/content/abstract/scopus_id/85074814083,"One-class classification is the standard procedure for novelty detection. Novelty detection aims to identify observations that deviate from a determined normal behaviour. Only instances of one class are known, whereas so called novelties are unlabelled. Traditional novelty detection applies methods from the field of outlier detection. These standard one-class classification approaches have limited performance in many real business cases. The traditional techniques are mainly developed for industrial problems such as machine condition monitoring. When applying these to human behaviour, the performance drops significantly. This paper proposes a method that improves existing approaches by creating semi-synthetic novelties in order to have labelled data for the two classes. Expert knowledge is incorporated in the initial phase of this data generation process. The method was deployed on a real-life test case where the goal was to detect fraudulent subscriptions to a telecom family plan. This research demonstrates that the two-class expert model outperforms a one-class model on the semi-synthetic dataset. In a next step the model was validated on a real dataset. A fraud detection team of the company manually checked the top predicted novelties. The results show that incorporating expert knowledge to transform a one-class problem into a two-class problem is a valuable method.",industry
10.1016/j.chemolab.2020.103932,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2020-04-15,sciencedirect,An adaptive mode convolutional neural network based on bar-shaped structures and its operation modeling to complex industrial processes,https://api.elsevier.com/content/abstract/scopus_id/85078848370,"Optimal operation modeling plays an important role in complex industrial processes; however, with the increasing complexity and high nonlinearity in industrial processes, it becomes more and more difficult to establish an accurate operation modeling using first-principles methods. In this paper, an adaptive mode convolutional neural network framework based on bar-shaped structures (BS-AMCNN) is proposed, which is a data-driven model. First, a bar-shaped structure is designed to deal with the industrial process data specifically. The bar-shaped structure can transfer the advantages of CNN on processing image data to processing industrial process data. Meanwhile, the convolution windows and pooling windows in the proposed BS-AMCNN algorithm is replaced by translation-only sliding bar-shaped windows. Therefore, the algorithm can adjust the CNN structure adaptively among three different modes depending on different process statuses. the optimal operation model can be obtained with the proposed BS-AMCNN method accordingly. An experiment on real complex industrial process, methanol production process, is carried out, which validates the effectiveness of the proposed method. The proposed method is further compared with the traditional CNN method, and the back propagation (BP) method. The results demonstrate the effectiveness of the proposed method.",industry
10.1016/j.jhazmat.2020.122032,Journal,Journal of Hazardous Materials,scopus,2020-04-15,sciencedirect,Reducing residual antibiotic levels in animal feces using intestinal Escherichia coli with surface-displayed erythromycin esterase,https://api.elsevier.com/content/abstract/scopus_id/85077918259,"Antibiotics are widely used in livestock and poultry industries, which results in large quantities of antibiotic residues in manure that influences subsequent treatments. In this study, an Escherichia coli strain was engineered to display erythromycin esterase on its cell surface. The engineered strain (E. coli ereA) efficiently degraded erythromycin by opening the macrocyclic 14-membered lactone ring in solution. Erythromycin (50 mg/L) was completely degraded in a solution by E. coli ereA (1 × 109 CFU/mL) within 24 h. E. coli ereA retained over 86.7 % of the initial enzyme activity after 40 days of storage at 25 °C, and 78.5 % of the initial activity after seven repeated batch reactions in solution at 25 °C. Mice were fed with E. coli ereA and real-time quantitative PCR data showed that E. coli ereA colonized in the mice large intestine. The mice group fed E. coli ereA exhibited 83.13 % decrease in erythromycin levels in their feces compared with the mice group not fed E. coli ereA. E. coli ereA eliminated antibiotics from the source preventing its release into the environment. The surface-engineered strain therefore is an effective alternative agent for treating recalcitrant antibiotics, and has the potential to be applied in livestock and poultry industries.",industry
10.1016/j.jmsy.2020.03.009,Journal,Journal of Manufacturing Systems,scopus,2020-04-01,sciencedirect,Automated defect inspection system for metal surfaces based on deep learning and data augmentation,https://api.elsevier.com/content/abstract/scopus_id/85084418292,"Recent efforts to create a smart factory have inspired research that analyzes process data collected from Internet of Things (IOT) sensors, to predict product quality in real time. This requires an automatic defect inspection system that quantifies product quality data by detecting and classifying defects in real time. In this study, we propose a vision-based defect inspection system to inspect metal surface defects. In recent years, deep convolutional neural networks (DCNNs) have been used in many manufacturing industries and have demonstrated the excellent performance as a defect classification method. A sufficient amount of training data must be acquired, to ensure high performance using a DCNN. However, owing to the nature of the metal manufacturing industry, it is difficult to obtain enough data because some defects occur rarely. Owing to this imbalanced data problem, the generalization performance of the DCNN-based classification algorithm is lowered. In this study, we propose a new convolutional variational autoencoder (CVAE) and deep CNN-based defect classification algorithm to solve this problem. The CVAE-based data generation technology generates sufficient defect data to train the classification model. A conditional CVAE (CCVAE) is proposed to generate images for each defect type in a single CVAE model. We also propose a classifier based on a DCNN with high generalization performance using data generated from the CCVAE. In order to verify the performance of the proposed method, we performed experiments using defect images obtained from an actual metal production line. The results showed that the proposed method exhibited an excellent performance.",industry
10.1016/j.jmsy.2020.02.010,Journal,Journal of Manufacturing Systems,scopus,2020-04-01,sciencedirect,Smart augmented reality instructional system for mechanical assembly towards worker-centered intelligent manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85080923298,"Quality and efficiency are crucial indicators of any manufacturing company. Many companies are suffering from a shortage of experienced workers across the production line to perform complex assembly tasks. To reduce time and error in an assembly task, a worker-centered system consisting of multi-modal Augmented Reality (AR) instructions with the support of a deep learning network for tool detection is introduced. The integrated AR is designed to provide on-site instructions including various visual renderings with a fine-tuned Region-based Convolutional Neural Network, which is trained on a synthetic tool dataset. The dataset is generated using CAD models of tools and displayed onto a 2D scene without using real tool images. By experimenting the system to a mechanical assembly of a CNC carving machine, the result of a designed experiment shows that the system helps reduce the time and errors of the given assembly tasks by 33.2 % and 32.4 %, respectively. With the integrated system, an efficient, customizable smart AR instruction system capable of sensing, characterizing requirements, and enhancing worker’s performance has been built and demonstrated.",industry
10.1016/j.dss.2020.113266,Journal,Decision Support Systems,scopus,2020-04-01,sciencedirect,ForeSim-BI: A predictive analytics decision support tool for capacity planning,https://api.elsevier.com/content/abstract/scopus_id/85079423691,"This paper proposes a decision support tool for maintenance capacity planning of complex product systems. The tool – ForeSim-BI – addresses the problem faced by maintenance organizations in forecasting the workload of future maintenance interventions and in planning an adequate capacity to face that expected workload. Developed and implemented from a predictive analytics perspective in the particular context of a Portuguese aircraft maintenance organization, the tool integrates four main modules: (1) a forecasting module used to predict future and unprecedented maintenance workloads from historical data; (2) a Bayesian inference module used to transform prior workload forecasts, resulting from the forecasting module, into predictive forecasts after observations on the maintenance interventions being predicted become available; (3) a simulation module used to characterize the forecasted total workloads through sets of random variables, including maintenance work types, maintenance work phases, and maintenance work skills; and (4) a Bayesian network module used to combine the simulated workloads with historical data through probabilistic inference. A linear programming model is also developed to improve the efficiency of the decision-making process supported by Bayesian networks. The tool uses real industrial data, comprising 171 aircraft maintenance projects collected at the host organization, and is validated by comparing its results with real observations of a given maintenance intervention to which predictions were made and with a model simulating current forecasting practices employed in industry. Significantly more accurate forecasts have been obtained with the proposed tool, resulting in an important cost saving potential for maintenance organizations.",industry
10.1016/j.aei.2020.101052,Journal,Advanced Engineering Informatics,scopus,2020-04-01,sciencedirect,Deep learning-based method for vision-guided robotic grasping of unknown objects,https://api.elsevier.com/content/abstract/scopus_id/85079340469,"Nowadays, robots are heavily used in factories for different tasks, most of them including grasping and manipulation of generic objects in unstructured scenarios. In order to better mimic a human operator involved in a grasping action, where he/she needs to identify the object and detect an optimal grasp by means of visual information, a widely adopted sensing solution is Artificial Vision. Nonetheless, state-of-art applications need long training and fine-tuning for manually build the object’s model that is used at run-time during the normal operations, which reduce the overall operational throughput of the robotic system. To overcome such limits, the paper presents a framework based on Deep Convolutional Neural Networks (DCNN) to predict both single and multiple grasp poses for multiple objects all at once, using a single RGB image as input. Thanks to a novel loss function, our framework is trained in an end-to-end fashion and matches state-of-art accuracy with a substantially smaller architecture, which gives unprecedented real-time performances during experimental tests, and makes the application reliable for working on real robots. The system has been implemented using the ROS framework and tested on a Baxter collaborative robot.",industry
10.1016/j.autcon.2019.103062,Journal,Automation in Construction,scopus,2020-04-01,sciencedirect,Towards automated clash resolution of reinforcing steel design in reinforced concrete frames via Q-learning and building information modeling,https://api.elsevier.com/content/abstract/scopus_id/85078657649,"The design of reinforcing steel bars (rebars) is critical to reinforced concrete (RC) structures. Generally, a good number of rebars are required by a design code, particularly at member connections. As such, rebar clashes (i.e., collisions and congestions) would be inevitable. It would be impractical, labor-intensive, and error-prone to avoid all possible clashes manually or even using standard design software. The building information modeling (BIM) technology has been utilized by the present architecture, engineering, and construction (ACE) industry for clash-free rebar designs. However, most existing BIM-based approaches offer the clash resolution strategy for moving components with an optimization algorithm, and are only applicable to the RC structures with regular shapes. In particular, the optimized path of rebars cannot be adjusted to avoid the obstacles, thus limiting the practical applications. Furthermore, most existing studies lack the learning from design code and constructibility constraints to realize automatic and intelligent arrangement and adjustment of rebars for avoiding the obstacles encountered in complex RC joints and frame structures. Considering these shortcomings, the authors have recently proposed an immediate reward-based multi-agent reinforcement learning (MARL) system with BIM, towards automatic clash-free rebar designs of RC joints without clashes. However, as the immediate reward is required in the MARL system for guiding the learning of a rebar design, it will not succeed in clash-free rebar designs of complex RC structures where immediate reward is often unavailable. In this study, this study further extends the previous work with Q-learning (a model-free reinforcement learning algorithm) for more realistic path planning considering both immediate and delayed rewards in clash-free rebar designs for real-world RC structures. In particular, the rebar design problem is treated as a path-planning problem of multi-agent system, where each rebar is deemed as an intelligence reinforcement learning agent. Next, by employing the Q-learning as the reinforcement learning engine, the particular form of state, action, and immediate and delayed rewards for the reinforcement MARL for automatic rebar designs considering more actual constructible constraints and design codes can be developed. Comprehensive experiments on three typical beam-column joints and a two-story RC building frame were conducted to evaluate the efficiency of the proposed method. The study results of paths of rebar designs, success rates, and average time confirm that the proposed framework with MARL and BIM is effective and efficient.",industry
10.1016/j.talanta.2019.120664,Journal,Talanta,scopus,2020-04-01,sciencedirect,Modelling of bioprocess non-linear fluorescence data for at-line prediction of etanercept based on artificial neural networks optimized by response surface methodology,https://api.elsevier.com/content/abstract/scopus_id/85076829838,"In the last years, regulatory agencies in biopharmaceutical industry have promoted the design and implementation of Process Analytical Technology (PAT), which aims to develop rapid and high-throughput strategies for real-time monitoring of bioprocesses key variables, in order to improve their quality control lines. In this context, spectroscopic techniques for data generation in combination with chemometrics represent alternative analytical methods for on-line critical process variables prediction. In this work, a novel multivariate calibration strategy for the at-line prediction of etanercept, a recombinant protein produced in a mammalian cells-based perfusion process, is presented. For data generation, samples from etanercept processes were daily obtained, from which fluorescence excitation-emission matrices were generated in the spectral ranges of 225.0 and 495.0 nm and 250.0 and 599.5 nm for excitation and emission modes, respectively. These data were correlated with etanercept concentration in supernatant (measured by an off-line HPLC-based reference univariate technique) by implementing different chemometric strategies, in order to build predictive models. Partial least squares (PLS) regression evidenced a non-linear relation between signal and concentration when observing actual vs. predicted concentrations. Hence, a non-parametric approach was implemented, based on a multilayer perceptron artificial neural network (MLP). The MLP topology was optimized by means of the response surface methodology. The prediction performance of MLP model was superior to PLS, since the first is able to cope with non-linearity in calibration models, reaching percentage mean relative error in predictions of about 7.0% (against 12.6% for PLS). This strategy represents a fast and inexpensive approach for etanercept monitoring, which conforms the principles of PAT.",industry
10.1016/j.neucom.2019.09.050,Journal,Neurocomputing,scopus,2020-03-28,sciencedirect,Deep attention user-based collaborative filtering for recommendation,https://api.elsevier.com/content/abstract/scopus_id/85076520226,"The user-based collaborative filtering (UCF) model has been widely used in industry for recommender systems. UCF predicts a user’s interest in an item based on rating information from similar user profiles. A neural network UCF model can learn effectively the high-order relations between users and items, but it cannot distinguish the importance of users in learning process. To mine the complex relationships between users and items, we incorporate a Deep+Shadow pattern to improve learning features effectively, namely as DeepUCF. Firstly, we define historical users, that is, users from the historical data of interactions with an item. The target user and historical users are calculated to capture complex process of user’s interacted item. Secondly, we integrate a shallow linear model to effectively solve single pair interaction problems. Finally, DeepUCF construct of a pair of user relations (interactive users with a history of items) for the input, and joint linear and nonlinear models to build relationships between users. More importantly, DeepUCF+a add an attention network to distinguish the historical user importance of items, which make DeepUCF more expressive. Experiments on real datasets show that DeepUCF and DeepUCF+a can effectively capture users’ complex high-order relationships, and achieve better performance.",industry
10.1016/j.compag.2020.105284,Journal,Computers and Electronics in Agriculture,scopus,2020-03-01,sciencedirect,An experimental study of stunned state detection for broiler chickens using an improved convolution neural network algorithm,https://api.elsevier.com/content/abstract/scopus_id/85079902403,"Effective recognition method of broiler stunned state has always been an important issue in real industries. In recent years, recognition methods such as neural networks have been receiving increasing attention due to their great merits of high diagnostic accuracy and easy implementation. To improve the accuracy and efficiency of broiler stunned state recognition, an improved fast region-based convolutional neural network (You Only Look Once + Multilayer Residual Module (YOLO + MRM)) algorithm was proposed and applied to the recognition of three broiler stunned states: insufficient, appropriate and excessive stuns. The images were collected from a broiler-slaughtering line using a complementary metal-oxide semiconductor (CMOS) camera. The area of the head and wings of a broiler in the original image was marked according to the PASCAL VOC data format and the dataset of each broiler stunned state was obtained. The results showed that the YOLO + MRM algorithm achieved good performance with an accuracy of 96.77%. To compare YOLO + MRM with other models, similar experiments were conducted using a conventional back propagation neural network (BP-NN) classifier, as well as YOLO, and the recognition accuracies were 90.11% and 94.74%, respectively. YOLO + MRM can complete the detection task of more than 180,000 broilers per hour. Compared with the traditional method, little prior expertise on image recognition is required, the recognition accuracy and speed are improved obviously. This study has provided a foundation and highlighted the potential for automatically detecting the stunned state of broiler chickens, which is crucial for the success of an automatic electric stunning process in the poultry industry.",industry
10.1016/j.artmed.2020.101817,Journal,Artificial Intelligence in Medicine,scopus,2020-03-01,sciencedirect,Real-world data medical knowledge graph: construction and applications,https://api.elsevier.com/content/abstract/scopus_id/85079325883,"Objective
                  Medical knowledge graph (KG) is attracting attention from both academic and healthcare industry due to its power in intelligent healthcare applications. In this paper, we introduce a systematic approach to build medical KG from electronic medical records (EMRs) with evaluation by both technical experiments and end to end application examples.
               
                  Materials and Methods
                  The original data set contains 16,217,270 de-identified clinical visit data of 3,767,198 patients. The KG construction procedure includes 8 steps, which are data preparation, entity recognition, entity normalization, relation extraction, property calculation, graph cleaning, related-entity ranking, and graph embedding respectively. We propose a novel quadruplet structure to represent medical knowledge instead of the classical triplet in KG. A novel related-entity ranking function considering probability, specificity and reliability (PSR) is proposed. Besides, probabilistic translation on hyperplanes (PrTransH) algorithm is used to learn graph embedding for the generated KG.
               
                  Results
                  A medical KG with 9 entity types including disease, symptom, etc. was established, which contains 22,508 entities and 579,094 quadruplets. Compared with term frequency - inverse document frequency (TF/IDF) method, the normalized discounted cumulative gain (NDCG@10) increased from 0.799 to 0.906 with the proposed ranking function. The embedding representation for all entities and relations were learned, which are proven to be effective using disease clustering.
               
                  Conclusion
                  The established systematic procedure can efficiently construct a high-quality medical KG from large-scale EMRs. The proposed ranking function PSR achieves the best performance under all relations, and the disease clustering result validates the efficacy of the learned embedding vector as entity’s semantic representation. Moreover, the obtained KG finds many successful applications due to its statistics-based quadruplet.
                  where 
                        
                           N
                           
                              c
                              o
                           
                           
                              m
                              i
                              n
                           
                        
                      is a minimum co-occurrence number and R is the basic reliability value. The reliability value can measure how reliable is the relationship between Si
                      and Oij
                     . The reason for the definition is the higher value of N
                     co(Si, Oij
                     ), the relationship is more reliable. However, the reliability values of the two relationships should not have a big difference if both of their co-occurrence numbers are very big. In our study, we finally set 
                        
                           N
                           
                              c
                              o
                           
                           
                              m
                              i
                              n
                           
                        
                      = 10 and R = 1 after some experiments. For instance, if co-occurrence numbers of three relationships are 1, 100 and 10000, their reliability values are 1, 2.96 and 5 respectively.",industry
10.1016/j.csi.2019.103389,Journal,Computer Standards and Interfaces,scopus,2020-03-01,sciencedirect,A systematic literature review on requirement prioritization techniques and their empirical evaluation,https://api.elsevier.com/content/abstract/scopus_id/85076538445,"[Context and Motivation] Many requirements prioritization approaches have been proposed, however not all of them have been investigated empirically in real-life settings. As a result, our knowledge of their applicability and actual use is incomplete. [Question/problem] A 2007 systematic review on requirements prioritization mapped out the landscape of proposed prioritization approaches and their prioritization criteria. To understand how this sub-field of requirements engineering has developed since 2007 and what evidence has been accumulated through empirical evaluations, we carried out a literature review that takes as input publications published between 2007 and 2019. [Principle ideas/results] We evaluated 102 papers that proposed and/or evaluated requirements prioritization methods. Our results show that the newly proposed requirements prioritization methods tend to use as basis fuzzy logic and machine learning algorithms. We also concluded that the Analytical Hierarchy Process is the most accurate and extensively used requirement prioritization method in industry. However, scalability is still its major limitation when requirements are large in number. We have found that machine learning has shown potential to deal with this limitation. Last, we found that experiments were the most used research method to evaluate the various aspects of the proposed prioritization approaches. [Contribution] This paper identified and evaluated requirements prioritization techniques proposed between 2007 and 2019, and derived some trends. Limitations of the proposals and implications for research and practice are identified as well.",industry
10.1016/j.adhoc.2019.102047,Journal,Ad Hoc Networks,scopus,2020-03-01,sciencedirect,An intelligent Edge-IoT platform for monitoring livestock and crops in a dairy farming scenario,https://api.elsevier.com/content/abstract/scopus_id/85076174369,"Today’s globalized and highly competitive world market has broadened the spectrum of requirements in all the sectors of the agri-food industry. This paper focuses on the dairy industry, on its need to adapt to the current market by becoming more resource efficient, environment-friendly, transparent and secure. The Internet of Things (IoT), Edge Computing (EC) and Distributed Ledger Technologies (DLT) are all crucial to the achievement of those improvements because they allow to digitize all parts of the value chain, providing detailed information to the consumer on the final product and ensuring its safety and quality. In Smart Farming environments, IoT and DLT enable resource monitoring and traceability in the value chain, allowing producers to optimize processes, provide the origin of the produce and guarantee its quality to consumers. In comparison to a centralized cloud, EC manages the Big Data generated by IoT devices by processing them at the network edge, allowing for the implementation of services with shorter response times, and a higher Quality of Service (QoS) and security. This work presents a platform oriented to the application of IoT, Edge Computing, Artificial Intelligence and Blockchain techniques in Smart Farming environments, by means of the novel Global Edge Computing Architecture, and designed to monitor the state of dairy cattle and feed grain in real time, as well as ensure the traceability and sustainability of the different processes involved in production. The platform is deployed and tested in a real scenario on a dairy farm, demonstrating that the implementation of EC contributes to a reduction in data traffic and an improvement in the reliability in communications between the IoT-Edge layers and the Cloud.",industry
10.1016/j.future.2019.10.043,Journal,Future Generation Computer Systems,scopus,2020-03-01,sciencedirect,HealthFog: An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments,https://api.elsevier.com/content/abstract/scopus_id/85074613864,"Cloud computing provides resources over the Internet and allows a plethora of applications to be deployed to provide services for different industries. The major bottleneck being faced currently in these cloud frameworks is their limited scalability and hence inability to cater to the requirements of centralized Internet of Things (IoT) based compute environments. The main reason for this is that latency-sensitive applications like health monitoring and surveillance systems now require computation over large amounts of data (Big Data) transferred to centralized database and from database to cloud data centers which leads to drop in performance of such systems. The new paradigms of fog and edge computing provide innovative solutions by bringing resources closer to the user and provide low latency and energy efficient solutions for data processing compared to cloud domains. Still, the current fog models have many limitations and focus from a limited perspective on either accuracy of results or reduced response time but not both. We proposed a novel framework called HealthFog for integrating ensemble deep learning in Edge computing devices and deployed it for a real-life application of automatic Heart Disease analysis. HealthFog delivers healthcare as a fog service using IoT devices and efficiently manages the data of heart patients, which comes as user requests. Fog-enabled cloud framework, FogBus is used to deploy and test the performance of the proposed model in terms of power consumption, network bandwidth, latency, jitter, accuracy and execution time. HealthFog is configurable to various operation modes which provide the best Quality of Service or prediction accuracy, as required, in diverse fog computation scenarios and for different user requirements.",industry
10.1016/j.compind.2019.103164,Journal,Computers in Industry,scopus,2020-02-01,sciencedirect,Integrating artificial intelligent techniques and continuous time simulation modelling. Practical predictive analytics for energy efficiency and failure detection,https://api.elsevier.com/content/abstract/scopus_id/85099790267,"Energy efficiency and reliability needs are growing in many economic sectors, where predictive analytics are becoming essential tools for these key variables forecasting.
                  When predicting these variables, in many occasions, the problem to simplify the prediction model format when dealing with similar systems, which are placed in different functional locations, is a very complex problem due to model unavoidable dependency on changing operating conditions (per time and location). So effort is placed in this paper to develop tools that can easily adapt prediction models’ structure to existing operating conditions, for a given time period and place where the asset is located. Furthermore, these tools may allow the model to be easily trained and tested for automated implementation within the plant’s remote surveillance system.
                  To this end, Artificial Intelligence (AI) techniques, and in particular artificial neural network (ANN) models, have been selected in this paper as prediction models, since their structure can be adapted to improve predictions accuracy and they can also learn from dynamic changes in environmental conditions.
                  To demonstrate the adaptability for prediction accuracy and self-learning capabilities of the model, we have implemented an ANN with a backpropagation algorithm as a continuous time simulation model, which is then implemented using Vensim simulation environment, to benefit of the outstanding software optimization features for fast training.
                  Using this model we provide predictions of asset degradation and operational risk under existing real time internal and locational variables. We can also dynamically release preventive maintenance activities. This prediction model is exemplified in an industrial case for failures in cryogenic pumps of LNG tanks.",industry
10.1016/j.comcom.2020.01.018,Journal,Computer Communications,scopus,2020-02-01,sciencedirect,Enhanced resource allocation in mobile edge computing using reinforcement learning based MOACO algorithm for IIOT,https://api.elsevier.com/content/abstract/scopus_id/85077781443,"The Mobile networks deploy and offers a multiaspective approach for various resource allocation paradigms and the service based options in the computing segments with its implication in the Industrial Internet of Things (IIOT) and the virtual reality. The Mobile edge computing (MEC) paradigm runs the virtual source with the edge communication between data terminals and the execution in the core network with a high pressure load. The demand to meet all the customer requirements is a better way for planning the execution with the support of cognitive agent. The user data with its behavioral approach is clubbed together to fulfill the service type for IIOT. The swarm intelligence based and reinforcement learning techniques provide a neural caching for the memory within the task execution, the prediction provides the caching strategy and cache business that delay the execution. The factors affecting this delay are predicted with mobile edge computing resources and to assess the performance in the neighboring user equipment. The effectiveness builds a cognitive agent model to assess the resource allocation and the communication network is established to enhance the quality of service. The Reinforcement Learning techniques Multi Objective Ant Colony Optimization (MOACO) algorithms has been applied to deal with the accurate resource allocation between the end users in the way of creating the cost mapping tables creations and optimal allocation in MEC.",industry
10.1016/j.cie.2019.106246,Journal,Computers and Industrial Engineering,scopus,2020-02-01,sciencedirect,A Parallel Gated Recurrent Units (P-GRUs) network for the shifting lateness bottleneck prediction in make-to-order production system,https://api.elsevier.com/content/abstract/scopus_id/85077469749,"In the make-to-order production system, the lateness bottleneck is the constraint of just-in-time management and orders on-time delivery. Since the dynamic nature of the manufacturing system, the bottleneck frequently shifts and influences the stability during the production runs. Therefore, predicting the bottleneck allows operators to foresee the future production status and to make proactive decision towards a balanced-line. Based on the large volumes of manufacturing data collected by Internet of Things (IoT), a novel Parallel gated recurrent units (P-GRUs) network with main inputs and auxiliary inputs are particularly developed for shifting bottleneck prediction. The designed P-GRUs can capture the temporal correlations of shifting bottlenecks and depict the production status simultaneously to make accurate bottleneck prediction. The P-GRUs model is applied in a large-scale production system to validate the performance and demonstrate the practical impacts. Finally, the experiment results from both real-world production as well as simulation environment show that the P-GRUs model yields better performance than benchmark models, including Autoregressive integrated moving average model (ARIMA), vanilla Recurrent nueral network (RNN), Deep neural network (DNN), and regular GRUs network.",industry
10.1016/j.cie.2019.106225,Journal,Computers and Industrial Engineering,scopus,2020-02-01,sciencedirect,Fuzzy possibility regression integrated with fuzzy adaptive neural network for predicting and optimizing electrical discharge machining parameters,https://api.elsevier.com/content/abstract/scopus_id/85076689961,"An electrical discharge machining (EDM) is one of the special production methods that are widely used in moldings, repairs and production of specific industrial components. Due to extensive production costs, optimal machining specifications are significant. Machining specifications are effective on output quality and thus attract more customers leading to higher profits. In this study, the impact of EDM parameters on surface roughness, material removal rate and electrode corrosion percentage have been investigated. In order to consider uncertainty of real production environments, the fuzzy theory is employed. Also, using the design of experiment (DOE) parameters calibration is performed and mathematical programming approach is applied for optimization purpose. The relationship between the machining parameters and the output process specification is examined by a fuzzy possibility regression model. Then, the mathematical relation of exact inputs and fuzzy outputs of the EDM process are extracted. The effectiveness of the three outputs is evaluated by interfacing models and fuzzy hypothesis testing. To determine the optimal levels of each output, a fuzzy adaptive neural network is used and appropriate models are prepared to be adapted with a fitted model of fuzzy possibility regression for comparison purposes. Validation tests imply the effectiveness of the proposed method. The integrated model is implemented in real case study. The results show that, fitted models can predict the material removal rate, surface fineness, and corrosion percentage of the electrode. The prediction accuracy of the proposed method is shown in comparison with the optimal fuzzy adaptive neural network outputs considering error value. Also, the proposed method is successful in identifying the optimal process parameters for EDM with reliable accuracy. The proposed integrated prediction and optimization model can be used as a calibration decision support in production systems to handle dynamic data structures and provide real time machining specifications to increase the output quality.",industry
10.1016/j.aca.2019.10.063,Journal,Analytica Chimica Acta,scopus,2020-02-01,sciencedirect,Dual-mode detection of avian influenza virions (H9N2) by ICP-MS and fluorescence after quantum dot labeling with immuno-rolling circle amplification,https://api.elsevier.com/content/abstract/scopus_id/85075378560,"Avian influenza virus (AIVs), hosted in poultry, are the pathogens of many poultry diseases and human infections, which bring huge losses to the poultry breeding industry and huge panic to society. Therefore, it is of great significance to establish accurate and sensitive detection methods for AIVs. In this work, a dual-mode detection method based on immuno-rolling circle amplification (immuno-RCA) and quantum dots (QDs) labeling for inductively coupled plasma mass spectrometry (ICP-MS) and fluorescence detection of H9N2 AIV was developed. The dual-mode detection of the QDs by ICP-MS and fluorescence is used to achieve mutual verification within the analysis results, thus improving the accuracy of the method. With the immuno-RCA, the sensitivity of the method was increased by two orders of magnitude. The limit of detection of the proposed method is 17 ng L−1 and 61 ng L−1, and the linear range of the proposed method is 0.05–5 ng mL−1 and 0.1–5 ng mL−1 with ICP-MS and fluorescence detection, respectively. The relative standard deviation (n = 7) is 4.9% with ICP-MS detection and 3.1% with fluorescence detection. Furthermore, the proposed method was applied to the analysis of chicken serum samples, no significant different was found for two modes detection and the recoveries of the spiking experiments are acceptable, indicating that the method has good practical potential for real sample analysis.",industry
10.1016/j.measurement.2019.107155,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-02-01,sciencedirect,Transfer between multiple machine plants: A modified fast self-organizing feature map and two-order selective ensemble based fault diagnosis strategy,https://api.elsevier.com/content/abstract/scopus_id/85073936697,"The signal differences cause machine fault diagnosis (MFD) models developed in one plant to not be readily applicable to others. This paper presents a modified fast self-organizing feature map (FSOM) and two-order selective ensemble (SE) strategy to realize transfer learning (TL) between multiple plants, including three major processes: i) modified FSOM to map the original real-imaginary polar diagrams to a new feature space where the differences in the same fault category are reduced, ii) cross Minkowski distance matrix to calculate the similarity between channels, and to select the helpful channels in the source plant by an evaluation process, iii) two-order SE to fuse high-powered channels in the target plant to promote diagnosis. Experiments in two gearbox systems demonstrate the effectiveness of transferring from a simple/local to a complex/global device, thus being a useful tool to solve the practical problem that model in the laboratory and apply in the industrial field.",industry
10.1016/j.micpro.2019.102906,Journal,Microprocessors and Microsystems,scopus,2020-02-01,sciencedirect,Area and power efficient pipelined hybrid merged adders for customized deep learning framework for FPGA implementation,https://api.elsevier.com/content/abstract/scopus_id/85073599282,"With the rapid growth of deep learning and neural network algorithms, various fields such as communication, Industrial automation, computer vision system and medical applications have seen the drastic improvements in recent years. However, deep learning and neural network models are increasing day by day, while model parameters are used for representing the models. Although the existing models use efficient GPU for accommodating these models, their implementation in the dedicated embedded devices needs more optimization which remains a real challenge for researchers. Thus paper, carries an investigation of deep learning frameworks, more particularly as review of adders implemented in the deep learning framework. A new pipelined hybrid merged adders (PHMAC) optimized for FPGA architecture which has more efficient in terms of area and power is presented. The proposed adders represent the integration of the principle of carry select and carry look ahead principle of adders in which LUT is re-used for the different inputs which consume less power and provide effective area utilization. The proposed adders were investigated on different FPGA architectures in which the power and area were analyzed. Comparison of the proposed adders with the other adders such as carry select adders (CSA), carry look ahead adder (CLA), Carry skip adders and Koggle Stone adders has been made and results have proved to be highly vital into a 50% reduction in the area, power and 45% when compared with above mentioned traditional adders.",industry
10.1016/j.ejor.2019.07.057,Journal,European Journal of Operational Research,scopus,2020-02-01,sciencedirect,Automating the planning of container loading for Atlas Copco: Coping with real-life stacking and stability constraints,https://api.elsevier.com/content/abstract/scopus_id/85070381903,"The Atlas Copco☆ distribution center in Allen, TX, supplies spare parts and consumables to mining and construction companies across the world. For some customers, packages are shipped in sea containers. Planning how to load the containers is difficult due to several factors: heterogeneity of the packages with respect to size, weight, stackability, positioning and orientation; the set of packages differs vastly between shipments; it is crucial to avoid cargo damage. Load plan quality is ultimately judged by shipping operators.
                  This container loading problem is thus rich with respect to practical considerations. These are posed by the operators and include cargo and container stability as well as stacking and positioning constraints. To avoid cargo damage, the stacking restrictions are modeled in detail. For solving the problem, we developed a two-level metaheuristic approach and implemented it in a decision support system. The upper level is a genetic algorithm which tunes the objective function for a lower level greedy-type constructive placement heuristic, to optimize the quality of the load plan obtained.
                  The decision support system shows load plans on the forklift laptops and has been used for over two years. Management has recognized benefits including reduction of labour usage, lead time, and cargo damage risk.",industry
10.1016/j.patrec.2018.10.011,Journal,Pattern Recognition Letters,scopus,2020-02-01,sciencedirect,Workflow recognition with structured two-stream convolutional networks,https://api.elsevier.com/content/abstract/scopus_id/85054866809,"Intelligent monitoring plays an important role in the context of Industry 4.0”, and behavior recognition is one of the research points in computer vision. However, monitoring the workflow of human beings and machines in production process is very difficult in the real-world complex factory environment. In this paper, we propose a novel workflow recognition framework based on the structured two-stream convolutional neural networks (CNNs) to recognize the behavior of both workers and machines. To improve the accuracy of workflow recognition, we use the CNNs to extract the spatial-temporal features and integrate an attention mechanism to detect the valuable behavior. Then, a Video Triple model is introduced to gain extra timestamp information, which can extend the behavior recognition to workflow recognition. Extensive simulation experiments are conducted on THUMOS’14 dataset and a real-world workflow dataset that show the significant performance improvement in video activity recognition.",industry
10.1016/j.neucom.2019.09.082,Journal,Neurocomputing,scopus,2020-01-29,sciencedirect,A scalable and reconfigurable in-memory architecture for ternary deep spiking neural network with ReRAM based neurons,https://api.elsevier.com/content/abstract/scopus_id/85073152550,"Neuromorphic computing using post-CMOS technologies is gaining increasing popularity due to its promising potential to resolve the power constraints in Von-Neumann machine and its similarity to the operation of the real human brain. In this work, we propose a scalable and reconfigurable architecture that exploits the ReRAM-based neurons for deep Spiking Neural Networks (SNNs). In prior publications, neurons were implemented using dedicated analog or digital circuits that are not area and energy efficient. In our work, for the first time, we address the scaling and power bottlenecks of neuromorphic architecture by utilizing a single one-transistor-one-ReRAM (1T1R) cell to emulate the neuron. We show that the ReRAM-based neurons can be integrated within the synaptic crossbar to build extremely dense Process Element (PE)–spiking neural network in memory array–with high throughput. We provide microarchitecture and circuit designs to enable the deep spiking neural network computing in memory with an insignificant area overhead. Simulation results on MNIST and CIFAR-10 datasets with spiking Resnet (SResnet) and spiking Squeezenet (SSqueez) show that compared to the baseline CPU only solution, our proposed architecture achieves energy saving between 1222 ×  and 1853 ×  and speed improvement between 791 ×  to 1120 ×.",industry
10.1016/j.jclepro.2019.118788,Journal,Journal of Cleaner Production,scopus,2020-01-20,sciencedirect,Rapid evaluation of micro-scale photovoltaic solar energy systems using empirical methods combined with deep learning neural networks to support systems’ manufacturers,https://api.elsevier.com/content/abstract/scopus_id/85073926377,"Solar energy is becoming one of the most attractive renewable sources. In many cases, due to a wide range of financial or installation limitations, off-grid small scale micro power panels are favoured as modular systems to power lighting in gardens or to be integrated together to power small devices such as mobile phone chargers and distributed smart city facilities and services. Manufacturers and systems’ integrators have a wide range of options of micro-scale photo voltaic panels to choose from. This makes the selection of the right panel a challenging task and risky investment. To address this and to help manufacturers, this paper suggests and evaluates a novel approach based on integrating empirical lab-testing with short-term real data and neural networks to assess the performance of micro-scale photovoltaic panels and their suitability for a specific application in specific environment. The paper outlines the combination of lab testing power output under seasonal and hourly conditions during the year combined with environmental and operating conditions such as temperature, dust accumulation and tilt angle performance. Based on the lab results, a short in-situ experimental work is implemented and the performance over the year in the selected location in Kuwait is evaluated using deep learning neural networks. The findings of this approach are compared with simulation and long-term real data. The results show a maximum error of 23% of the neural network output when compared with the actual data, and a correlation values with previous work within 87.3% and 91.9% which indicate that the proposed approach could provide an experimental rapid and accurate assessment of the expected power output. Hence, supporting the rapid decision-making process for manufacturers and reducing investment risks.",industry
10.1016/j.fuel.2019.116250,Journal,Fuel,scopus,2020-01-15,sciencedirect,"On the development of experimental methods to determine the rates of asphaltene precipitation, aggregation, and deposition",https://api.elsevier.com/content/abstract/scopus_id/85072862208,"Despite the efforts throughout the last few decades, asphaltene deposition remains as one of the greatest challenges in the petroleum industry. In this work, we present a comprehensive series of experimental studies to better understand the asphaltene precipitation, aggregation, and deposition mechanisms. Here, we introduce a simple method to determine the amount of precipitated asphaltene using NIR spectroscopy measurements without the implementation of calibration curves. Moreover, the kinetics of asphaltene precipitation and aggregation is simultaneously investigated by a newly developed, fast, and reliable NIR spectroscopy technique. In the new method, only less than 2 ml of sample is required for each experiment. In addition, unlike gravimetric techniques, less time consuming and labor-intensive measurements can be performed. In addition, the temperature can be controlled; hence, experiments can be conducted to evaluate the effects of temperature and the driving force on the kinetics of asphaltene precipitation and aggregation. Subsequently, the quantified precipitated asphaltene amount can be used to calibrate the precipitation and aggregation kinetic parameters of the asphaltene deposition model. The results obtained from the kinetics experiments facilitate in establishing a function to scale the precipitation kinetic parameter from laboratory-scale experiments to real field high-pressure high-temperature conditions. Additionally, a multi-section stainless steel packed bed column is proposed to study asphaltene deposition at high temperature and under dynamic conditions. In these experiments, the amount of deposited asphaltene is directly quantified. The results from the packed bed column deposition tests can be used to calibrate the deposition kinetic parameter of the asphaltene deposition model.",industry
10.1016/j.neucom.2019.08.082,Journal,Neurocomputing,scopus,2020-01-02,sciencedirect,Finding decision jumps in text classification,https://api.elsevier.com/content/abstract/scopus_id/85072622520,"Text classification is one of the key problems in natural language processing (NLP), and in early years, it was usually accomplished by feature-based machine learning models. Recently, the deep neural network has become a powerful learning machine, making it possible to work with text itself as raw input for the classification problems. However, existing neural networks are typically end-to-end and lack explicit interpretation of the prediction. In this paper, we propose Jumper, a novel framework that models text classification as a sequential decision process. Generally, Jumper is a neural system that scans a piece of text sequentially and makes classification decisions at the time it wishes, which is inspired by the cognitive process of human text reading. In our framework, both the classification result and when to make the classification are part of the decision process, controlled by a policy network and trained with reinforcement learning. Experimental results of real-world applications demonstrate the following properties of a properly trained Jumper: (1) it tends to make decisions whenever the evidence is enough, therefore reducing total text reading by 30–40% and often finding the key rationale of the prediction; and (2) it achieves classification accuracy better than or comparable to state-of-the-art models in several benchmark and industrial datasets. We further conduct a simulation experiment with mock data, which confirms that Jumper is able to make a decision at the theoretically optimal decision position.",industry
10.1016/j.neucom.2019.09.004,Journal,Neurocomputing,scopus,2020-01-02,sciencedirect,Digital neuromorphic real-time platform,https://api.elsevier.com/content/abstract/scopus_id/85072526243,"Hardware implementations of spiking neural networks in portable devices can improve many applications of robotics, neurorobotics or prosthetic fields in terms of power consumption, high-speed processing and learning mechanisms. Analog and digital platforms have been previously proposed to run these networks. Analog designs are closer to biology since they implement the original mathematical model. However, digital platforms are, to some extent, abstractions of this model so far. In this paper, a full digital platform to design, implement and run real-time analog-like spiking neural networks is presented. Specifically, we present the design and implementation of digital circuits to run real-time biologically plausible spiking neural networks on a Field Programmable Gate Array (FPGA). The circuit designed for the neuron implements the Leaky Integrate and Fire (LIF) model. The synapsis implemented is a bi-exponential current-based one. The synaptic circuit design consists of one static memory with the baseline current and a dynamic memory which stores the updated contribution over time of each pre-synaptic connection. All the parameters of both the neuron and the synapse are configurable. The results of the circuits are validated by running the same experiments on the Brian simulator. The circuits, which are totally original and independent of the technology, use only 136 slice registers of hardware resources. Thus, these designs allow the scale of the network. These circuits aim to be the basis of the spiking neural networks on digital devices. This platform allows the user to first simulate their network within the Brian simulator and then, confidently, move to the hardware platform replicating the same performance or even replace their analog platform with the digital one.",industry
10.1016/j.ifacol.2020.12.2866,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Reinforcement learning for dual-resource constrained scheduling,https://api.elsevier.com/content/abstract/scopus_id/85107805245,"This paper proposes using reinforcement learning to solve scheduling problems where two types of resources of limited availability must be allocated. The goal is to minimize the makespan of a dual-resource constrained flexible job shop scheduling problem. Efficient practical implementation is very valuable to industry, yet it is often only solved combining heuristics and expert knowledge. A framework for training a reinforcement learning agent to schedule diverse dual-resource constrained job shops is presented. Comparison with other state-of-the-art approaches is done on both simpler and more complex instances that the ones used for training. Results show the agent produces competitive solutions for small instances that can outperform the implemented heuristic if given enough time. Other extensions are needed before real-world deployment, such as deadlines and constraining resources to work shifts.",industry
10.1016/j.ifacol.2020.12.2856,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,A deep learning unsupervised approach for fault diagnosis of household appliances,https://api.elsevier.com/content/abstract/scopus_id/85107800132,Fault detection and fault diagnosis are crucial subsystems to be integrated within the control architecture of modern industrial processes to ensure high quality standards. In this paper we present a two-stage unsupervised approach for fault detection and diagnosis in household appliances. In particular a suitable testing procedure has been implemented on a real industrial production line in order to extract the most meaningful features that allow to efficiently classify different types of fault by consecutively exploiting deep autoencoder neural network and k-means or hierarchical clustering techniques.,industry
10.1016/j.ifacol.2020.12.2855,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Fault prediction as a service in the smart factory: Addressing common challenges for an effective implementation,https://api.elsevier.com/content/abstract/scopus_id/85107753365,"Fault prediction in manufacturing systems has consistently been an important theme in engineering research. Data-driven methods to deliver this service are gaining momentum due to developments regarding information and communication technologies. Particularly, fault prediction may be interpreted as a supervised learning classification problem, in which algorithms trained by operational data gathered from the shop-floor are capable of informing managers whether a machine might enter in a failure state or not. Despite the relevance of this approach, implementations are hindered by several challenges. In this work, we review approaches aimed to deal with four of these challenges, namely: limited amount of training data, unbalanced training data sets, uncertainty regarding which variables should be monitored, and uncertainty regarding how exactly historical data should be employed in the algorithm’s training. To deal with training sets with limited size, learning procedures observed to perform well with a lower volume of training data can be used, such as the Random Forests technique. Alternatively, transfer learning techniques can be utilized to adapt models trained in a virtual domain with abundant synthetic data to the real manufacturing system domain. To deal with unbalance among classification classes, cost-sensitive learning methods can be employed to alter the penalties incurred when misclassifications occurs in the minority class. Alternatively, resampling methods can be applied before learning occurs. Lastly, both the decisions regarding which variables to track, and to what extent historical data should be included in the training process, can be addressed through the use of specific feature selection methods.",industry
10.1016/j.ifacol.2020.12.299,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Artificial intelligence platform proposal for paint structure quality prediction within the industry 4.0 concept,https://api.elsevier.com/content/abstract/scopus_id/85103128034,"This article provides an artificial intelligence platform proposal for paint structure quality prediction using Big Data analytics methodologies. The whole proposal fits into the current trends that are outlined in the Industry 4.0 concept. The painting process is very complex, producing huge volumes of data, but the main problem is that the data comes from different data sources, often heterogeneous, and it is necessary to propose a way to collect and integrate them into a common repository. The motivation for this work were the industry requirements to solve specific problems that cannot be solved by standard methods but require a sophisticated and holistic approach. It is the application of artificial intelligence that suggests a solution that is not otherwise visible, and the use of standard methods would not give any satisfactory results. The result is the design of an artificial intelligence platform that has been deployed in a real manufacturing process, and the initial results confirm the correctness and validity of this step. We also present a data collection and integration architecture, which is an integral part of every big data analytics solution, and a principal component analysis that was used to reduce the dimensionality of the large number of production process data.",industry
10.1016/j.matpr.2020.08.718,Conference Proceeding,Materials Today: Proceedings,scopus,2020-01-01,sciencedirect,Hybrid clustering algorithm for an efficient brain tumor segmentation,https://api.elsevier.com/content/abstract/scopus_id/85102451494,"This work describes the data mining methods, techniques and algorithms used for implementation. It is an emerging field of IT industry and research. There are many other fields such as Artificial Intelligence, Machine Learning, Deep Learning, Virtualization, Visualization, Parallel Computing and Image Processing. The human internal Brain can be seen or visualized by the Magnetic Resonance Imaging scan or Computerized Tomography scan. The MRI image is scanned and will be taken as input for processing. The MRI scan is more advantageous and more comfortable than CT scan for diagnosis. MRI scan provides detailed picture of organs. It does not affect the human health and body condition. It doesn't use any radiation. It is purely based on the magnetic field and radio waves. LIPC technique makes the training samples from the patients and arranges them into different group of classes used to construct different dictionaries. Image segmentation is a technique of dividing an image into different multiple portions, which is used to spot out objects and boundaries in images. There are many image segmentation techniques applicable for image processing. No acceptable method is available for solving all kinds of segmentation problem. Every method has merits and demerits. So, choosing good method is the challenging task. The hybrid clustering method is proposed in this work. The k-means algorithm and fuzzy c-means algorithm is proposed for brain tumor segmentation. The algorithm is implemented in synthetic and real time dataset. From the experimental results, this method provides better results in the form of accuracy.",industry
10.1016/j.procir.2020.03.134,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Reconstructing CNC platform for EDM machines towards smart manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85102047186,"CNC (computer numerical control) systems play an ultimately important role for controlling EDM (electrical discharge machining) machine tools and their machining processes. Till now, existing CNC systems do not offer sufficient openness that supports researchers and engineers to expend its capabilities and functionalities in response to the increasing demands of smart manufacturing; on the other hand, transforming an EDM machine made by small and medium-sized machine tool builders, into a smart manufacturing system has never been an easy job. To address the issues and overcome the difficulties which block the way towards smart manufacturing, this paper proposes an open architecture CNC platform for EDM machine tools. This platform utilizes the state-of-the-art technologies in implementation of the hardware and software without compromising with the constraints of obsolete techniques. For demonstrating the unique capabilities, the generalized unit arc length increment (GUALI) interpolation method and the Digitizer/Player system architecture are adopted. To exhibit the feasibilities of the newly developed platform, three kinds of EDM machine tools are applied associated with advanced functionalities such as machining process adaptive control, applications of machine learning, 6-axis EDM of shrouded turbine blisks etc. In addition, a small-scale smart manufacturing unit for drilling film cooling holes of turbine blades is built up into real production by applying the new CNC system and related software applications. From the practitioner’s viewpoint, openness and standardization are the keys that enable the people from academia and industry bringing in their domain knowledge to enrich the smart manufacturing ecosystem.",industry
10.1016/j.promfg.2020.11.012,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Application of machine learning and vision for real-time condition monitoring and acceleration of product development cycles,https://api.elsevier.com/content/abstract/scopus_id/85100766330,"Development work within an experimental environment, in which certain properties are investigated and optimized, requires many test runs and is therefore often associated with long execution times, costs and risks. This can affect product, material and technology development in industry and research. New digital driver technologies offer the possibility to automate complex manual work steps in a cost-effective way, to increase the relevance of the results and to accelerate the processes many times over. In this context, this article presents a low-cost, modular and open-source machine vision system for test execution and evaluates it on the basis of a real industrial application. For this purpose a methodology for the automated execution of the load intervals, the process documentation and for the evaluation of the generated data by means of machine learning to classify wear levels. The software and the mechanical structure are designed to be adaptable to different conditions, components and for a variety of tasks in industry and research. The mechanical structure is required for tracking the test object and represents a motion platform with independent positioning by machine vision operators or machine learning. An evaluation of the state of the test object is performed by the transfer learning after the initial documentation run. The manual procedure for classifying the visually recorded data on the state of the test object is described for the training material. This leads to an increased resource efficiency on the material as well as on the personnel side since on the one hand the significance of the tests performed is increased by the continuous documentation and on the other hand the responsible experts can be assigned time efficiently. The presence and know-how of the experts are therefore only required for defined and decisive events during the execution of the experiments. Furthermore, the generated data are suitable for later use as an additional source of data for predictive maintenance of the developed object.",industry
10.1016/j.procs.2020.10.091,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Towards smart manufucturing: Implementation and benefits,https://api.elsevier.com/content/abstract/scopus_id/85099879698,"Production activities are generating a large amount of data in different types (i.e., text, images), that is not well exploited. This data can be translated easily to knowledge that can help to predict all the risks that can impact the business, solve problems, promote efficiency of the manufacturing to the maximum, make the production more flexible and improving the quality of making smart decisions, however, implementing the Smart Manufacturing(SM) concept provides this opportunity supported by the new generation of the technologies. Internet Of Things (IoT) for more connectivity and getting data in real time, Big Data to store the huge volume of data and Deep Learning algorithms(DL) to learn from the historical and real time data to generate knowledge, that can be used, predict all the risks, problem solving, and better decision-making.
                  In this paper, we will introduce SM and the main technologies to success the implementation, the benefits, and the challenges.",industry
10.1016/j.promfg.2020.10.053,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Enabling real-time quality inspection in smart manufacturing through wearable smart devices and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85099870958,"In this paper, we present a novel method for utilising wearable devices with Convolutional Neural Networks (CNN) trained on acoustic and accelerometer signals in smart manufacturing environments in order to provide real-time quality inspection during manual operations. We show through our framework how recorded or streamed sound and accelerometer data gathered from a wrist-attached device can classify certain user actions as successful or unsuccessful. The classification is designed with a Deep CNN model trained on Mel-frequency Cepstral Coefficients (MFCC) from the acoustic input signals. The wearable device provides feedback on three different modalities: audio, visual and haptic; thus ensuring the worker’s awareness at all time. We validate our findings through deployments of the complete AI-enabled device in production facilities of Mercedes-Benz AG. From the conducted experiments it is concluded that the use of acoustic and accelerometer data is valuable to train a classifier with the purpose of action examination during industrial assembly operations, and provides an intuitive interface for ensuring continued and improved quality inspection.",industry
10.1016/j.promfg.2020.10.164,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Deep multi-layer perceptron based prediction of energy efficiency and surface quality for milling in the era of sustainability and big data,https://api.elsevier.com/content/abstract/scopus_id/85099828504,"In advanced industries such as aerospace, medical and automotive, high precision machining is increasingly required for many parts made by difficult-to-cut alloys. Machine tool manufacturers respond to this demand by developing more advanced machine tools that have advanced sub-systems for attaining high-precision and wide flexibility, with the expense of energy efficiency. Unfortunately, worldwide primary energy resources continue to run out. Furthermore, GHG emissions mostly related to energy, remain to be a global issue with the ever-increasing economic expansion in many developed and developing economies.
                  In the meantime, increasing use of sensors and Internet of Things (IoT) technologies in shop-floors set off a data explosion, warranting the use of emerging Deep Learning techniques to cope with “Big Data” reality of manufacturing. Therefore, in this study a Deep Multi-Layer Perceptron (DMLP) based algorithm for predicting surface roughness and specific cutting energy - major measures of precision and energy efficiency-, has been developed for slot milling of AL7075. Design of Experiment is used to collect the required data and train DMLP based model. The finalized prediction algorithm estimated quality and energy efficiency with 91.5% and 90.7% accuracy rates in slot milling, verified by additional machining and data collection.",industry
10.1016/j.promfg.2020.10.126,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Simulation-as-a-service for reinforcement learning applications by example of heavy plate rolling processes,https://api.elsevier.com/content/abstract/scopus_id/85099821374,"In the production industry, the digital transformation enables a significant optimization potential. The concept of reinforcement learning offers a suitable approach to train agents on learning control strategies, further advancing automation. While applications training directly on real-world processes are rare due to economical and safety constraints, simulations offer a way to develop and evaluate agents prior to deployment. With the rise of service-based business models, the simulation owner and the machine learning expert are likely to be different stakeholders in a joint project. Due to different requirements for both simulations and reinforcement-learning agents, the stakeholders may be reluctant or unable to grant full access to the respective software. This poses a serious impediment to the potential of the digital transformation. In this paper, a distributed architecture is proposed, which allows the remote training of reinforcement learning agents on a simulation. It is shown that this architecture allows the cooperation between two stakeholders by exposing a suitable technical interface to the simulation. The proposed architecture is implemented for a simulation of the multi-step metal forming process of heavy plate rolling. Furthermore, the implemented architecture is used to successfully train a reinforcement-learning agent on the task of designing optimal parameter schedules.",industry
10.1016/j.promfg.2020.05.123,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Integrated tool condition monitoring systems and their applications: A comprehensive review,https://api.elsevier.com/content/abstract/scopus_id/85095576577,"In conventional metal cutting, different tool wear modes, and their individual deterioration rates play vital roles in overall production performance. For a given tool (i.e., geometry or materials), many shop floors still follow a standard rule by pre-setting a tool life, which is conservative but not realistic. Premature failure of a tool can cause unexpected machine downtime and material losses, while another tool could serve beyond that pre-set life. As a result, optimized tool life and productivity cannot be achieved. Moreover, nowadays, there is an increased demand of process monitoring and optimization on the unmanned and the semi-automated shop floors.
                  Tool condition monitoring (TCM) systems for process improvement and optimization have been in research for several decades. Both offline and online TCM systems are invented and discussed. A wide range of original publications are reported focusing on different sub-topics, e.g., specific machining process-based TCM methods, measurement or signal acquisition methods, processing methods, and classifiers. With the recent evolution of smart sensors in the era of Industry 4.0, development of online TCM systems received much attention to the researchers. Accordingly, research on some sub-topics also gets motivated into different directions, such as, feasibility of power or current sensors, machine vision technique, and combination of multi-sensors. Thus, from the industrial viewpoint, the current state of implementation of the proposed TCM systems for (near) real-time process monitoring and control needs to be clear. This paper presents the state-of-the-art of the TCM systems covering three major machining operations, discusses their application feasibility in industry environments, and states some current TCMS implementations. Challenges being faced by the industry are concluded, along with direction and suggestions for future researches.",industry
10.1016/j.promfg.2020.05.131,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Real-time assembly operation recognition with fog computing and transfer learning for human-centered intelligent manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85095118290,"In a human-centered intelligent manufacturing system, every element is to assist the operator in achieving the optimal operational performance. The primary task of developing such a human-centered system is to accurately understand human behavior. In this paper, we propose a fog computing framework for assembly operation recognition, which brings computing power close to the data source in order to achieve real-time recognition. For data collection, the operator's activity is captured using visual cameras from different perspectives. For operation recognition, instead of directly building and training a deep learning model from scratch, which needs a huge amount of data, transfer learning is applied to transfer the learning abilities to our application. A worker assembly operation dataset is established, which at present contains 10 sequential operations in an assembly task of installing a desktop CNC machine. The developed transfer learning model is evaluated on this dataset and achieves a recognition accuracy of 95% in the testing experiments.",industry
10.1016/j.promfg.2020.05.122,Conference Proceeding,,scopus,2020-01-01,sciencedirect,On-machine measurement-based compensation for machining of thin web parts,https://api.elsevier.com/content/abstract/scopus_id/85095116401,"Thin web parts are widely used in the aerospace industry; however, serious machining errors may happen due to their low rigidity. In this study, a highly automatic method that integrates machining status monitoring, on-machine measurement (OMM) inspection, machining error modeling and real time compensation is proposed and developed. The OMM inspection is firstly applied to measure the comprehensive machining errors, the Hampel filtering, the triangulation-based cubic interpolation and a machine learning algorithm are then used to train the machining error model. Finally, the real time compensation of high-density cutting points is realized by developing the compensation system based on External Machine Zero Point Shift (EMZPS) function of machine tool. The proposed method was validated through three sets of compensation experiment of a thin web part. The results revealed that 58.1%, 68.4% and 62.6% of the machining error ranges were decreased, respectively. This method demonstrates immense potential for further applications in efficiency and accuracy improvement of thin-walled freeform surface parts.",industry
10.1016/j.promfg.2020.05.146,Conference Proceeding,,scopus,2020-01-01,sciencedirect,One-shot recognition of manufacturing defects in steel surfaces,https://api.elsevier.com/content/abstract/scopus_id/85095111982,"Quality control is an essential process in manufacturing to make the product defect-free as well as to meet customer needs. The automation of this process is important to maintain high quality along with the high manufacturing throughput. With recent developments in deep learning and computer vision technologies, it has become possible to detect various features from the images with near-human accuracy. However, many of these approaches are data intensive. Training and deployment of such a system on manufacturing floors may become expensive and time-consuming. The need for large amounts of training data is one of the limitations of the applicability of these approaches in real-world manufacturing systems. In this work, we propose the application of a Siamese convolutional neural network to do one-shot recognition for such a task. Our results demonstrate how one-shot learning can be used in quality control of steel by identification of defects on the steel surface. This method can significantly reduce the requirements of training data and can also be run in real-time.",industry
10.1016/j.procs.2020.09.082,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Proposed model to intelligent recommendation system based on markov chains and grouping of genres,https://api.elsevier.com/content/abstract/scopus_id/85093359265,"A recommendation system (RS) provides users with a list of recommended tags or resources that they may like. Still, most systems are vulnerable with certain limitations and gaps related to the recommendation environment. Several RSs do not take into account the changes of the user preference over time to ensure his satisfaction. Thus, the role of these systems is limited to define the general orientations of each user according to their observed preferences without shading light on the importance of the user preferences in short time. In this regard, we propose a new approach of recommendation for the entertainment industry that permits to guide the user towards suggestions that are more relevant according to their previous interactions. That means, we offer our users suggestions to decrease the time and frustration of discovering engaging content. Thereby, we have created our own solution, a Recommendation System based on Markov Chains and Grouping of Genres (RSMCG). It is a simple method that enables to construct an intelligent system which explores the Markov chains to predict the following actions taking into consideration the most recent actions of the user. Also, we adapt a machine learning algorithm DBSCAN clustering in order to exactly identify the interest of each user and provide adaptable answers. This approach has been studied and evaluated on the basis of a movie collection of the most popular video streaming service “Netflix”. The results of the experiments show the efficiency of our hypothesis in comparison to a sample of the user’s real needs.",industry
10.1016/j.procir.2020.04.158,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Image processing based on deep neural networks for detecting quality problems in paper bag production,https://api.elsevier.com/content/abstract/scopus_id/85092428222,"It is critical for manufacturers to identify quality issues in production and prevent defective products being delivered to customers. We investigate the use of deep neural networks to perform automatic quality inspections based on image processing to eliminate the current manual inspection. A deep neural network was implemented in a real-world industrial case study, and its ability to detect quality problems was evaluated and analyzed. The results show that the network has an accuracy of 94.5%, which is considered good in comparison to the 70–80% accuracy of a trained human inspector.",industry
10.1016/j.procir.2020.04.135,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Application of Artificial Intelligence to an Electrical Rewinding Factory Shop,https://api.elsevier.com/content/abstract/scopus_id/85091693237,"The evolution of artificial intelligence (AI) and big data resulted in the full potential realization of technologies through convergence. Tremendous acceptance, adoption and implementation of the United Nations Sustainable Development Goals (SDG) Agenda 2030, has resulted in original equipment manufacturers (OEM) developing various designs of rotary machines in a bid to improve energy efficiency, with more improvements expected in the coming decade. An effective technique to manage energy efficiency in the smart grid is through integration of demand side management, inclusive of optimization of rewinding of an electric motor in a machine shop. This paper aims to conceptualize application of AI and augmented reality (AR) towards process visibility of remanufacturing rotary machine stators by robotic vision. SLT is the triangulation methodology used in laser scanning for 3D modelling, and instantaneous condition assessment of the core. A pre-defined robotic path is used towards identification of features for range image acquisition. Therefore, the potential of industry 4.0 in resuscitation of end-of-life products through service remanufacturers by RE in a rewinding shop are presented.",industry
10.1016/j.eng.2020.06.016,Journal,Engineering,scopus,2020-01-01,sciencedirect,A Fast Charging–Cooling Coupled Scheduling Method for a Liquid Cooling-Based Thermal Management System for Lithium-ion Batteries,https://api.elsevier.com/content/abstract/scopus_id/85089296180,"Efficient fast-charging technology is necessary for the extension of the driving range of electric vehicles. However, lithium-ion cells generate immense heat at high-current charging rates. In order to address this problem, an efficient fast charging–cooling scheduling method is urgently needed. In this study, a liquid cooling-based thermal management system equipped with mini-channels was designed for the fast-charging process of a lithium-ion battery module. A neural network-based regression model was proposed based on 81 sets of experimental data, which consisted of three sub-models and considered three outputs: maximum temperature, temperature standard deviation, and energy consumption. Each sub-model had a desirable testing accuracy (99.353%, 97.332%, and 98.381%) after training. The regression model was employed to predict all three outputs among a full dataset, which combined different charging current rates (0.5C, 1C, 1.5C, 2C, and 2.5C (1C = 5 A)) at three different charging stages, and a range of coolant rates (0.0006, 0.0012, and 0.0018 kg·s−1). An optimal charging–cooling schedule was selected from the predicted dataset and was validated by the experiments. The results indicated that the battery module’s state of charge value increased by 0.5 after 15 min, with an energy consumption lower than 0.02  J. The maximum temperature and temperature standard deviation could be controlled within 33.35 and 0.8 °C, respectively. The approach described herein can be used by the electric vehicles industry in real fast-charging conditions. Moreover, optimal fast charging–cooling schedule can be predicted based on the experimental data obtained, that in turn, can significantly improve the efficiency of the charging process design as well as control energy consumption during cooling.",industry
10.1016/j.promfg.2020.05.149,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Deep learning-based cross-machine health identification method for vacuum pumps with domain adaptation,https://api.elsevier.com/content/abstract/scopus_id/85089146261,"Intelligent data-driven machinery health identification has been attracting increasing attention in the manufacturing industries, due to reduced maintenance cost and enhanced operation safety. Despite the successful development, the main limitation of most existing methods lies in the assumption that the training and testing data are collected from the same distribution, i.e. the same machine under identical condition. However, this assumption is difficult to be met in the real industries, since the diagnostic model is generally expected to be applied on new machines. In order to address this issue, a deep learning-based cross-machine health identification method is proposed for industrial vacuum pumps, which are of great importance in the manufacturing industry but have received far less research attention in the literature. Generalized diagnostic features can be learnt using the proposed domain adaptation technique with maximum mean discrepancy metric. The health identification model learnt from the training machines can be well applied on new machines. Experiments on a real-world vacuum pump dataset validate the proposed method, which is promising for industrial applications.",industry
10.1016/j.promfg.2020.05.128,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Deep learning-based intelligent defect detection of cutting wheels with industrial images in manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85089137367,"The cutting wheel is an important tool in the television liquid crystal display (LCD) panel manufacturing process. The degradation of the cutting wheel significantly affects the LCD panel quality. Currently, there is few effective approaches that can detect the degradation of the cutting wheel at the working station for health monitoring purpose, due to the small size of the component and the complex manufacturing operation. That leads to high economic costs in the production lines in the real industries. In order to address this issue, this paper presents a deep convolutional neural network-based method for defect detection of the cutting wheels using the industrial images. An end-to-end health monitoring system is built based on machine vision, which directly takes the raw images as inputs, and outputs the detection results. That facilitates the industrial applications since little prior knowledge on image processing and fault detection is required. The experiments on a real-world cutting wheel degradation dataset are carried out for validation. High fault diagnosis testing accuracies are obtained, that indicates the proposed method offers an effective and promising approach for the cutting wheel health monitoring problem.",industry
10.1016/j.procs.2020.05.068,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Adoption of the conceive-design-implement-operate approach to the third year project in a team-based design-build environment,https://api.elsevier.com/content/abstract/scopus_id/85089026312,"The high-quality engineering education is one of the challenges in the 21stcentury, where the teaching-learning process will be enhanced by integrating and involving the students in the teaching process and the course will be delivered in an interesting and engaging way. So in the process of reforming the engineering education, the Department of Mechanical Engineering of RIT, Rajaramnagar has initiated Conceive, Design, Implement and Operate (CDIO) approach to produce the 21st-century engineers. CDIO approach caters an engineering education that stresses fundamentals set in the context of real-world systems and products. It provides a universal structure for a strong engineering education integrating an entire set of graduate attributes. Developing undergraduate students into successful engineers requires integration of technical knowledge and soft skills. As a part of CDIO implementation, the mechanical program has been modified to provide integrated team-based project learning. The paper presents the implementation methodology of the concept with an emphasis on the Third year design projects. As per the CDIO standards and syllabus, the program has been modified and the required facilities were made available in the college campus such as Workspaces and laboratories. The structured research-driven approach is provided to monitor and review the implementation of the CDIO principles and standards. It is observed that CDIO provides integrated learning to develop deep learning of technical knowledge whilst simultaneously develops personal, interpersonal, process, product, and system developing skills. The primary outcome of the CDIO is the students are exposed to the work environment used in the industry for the product and process development and the secondary outcome is that it provides a useful tool for devolvement and assessment of the skill set of the students. Finally, the effect of CDIO initiative for project enrichment is discussed and future plan is presented.",industry
10.1016/j.promfg.2020.05.093,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Deep learning-based intelligent process monitoring of directed energy deposition in additive manufacturing with thermal images,https://api.elsevier.com/content/abstract/scopus_id/85088876794,"Additive manufacturing (AM) techniques have been successfully developed in the past years with the great potential of overcoming the existing obstacles in traditional manufacturing. In order to improve the quality of the manufactured parts and reduce costs, it is important to timely and accurately monitor the AM process during manufacturing. However, it remains a challenging task due to the high complexity of the AM process and the difficulty in processing the condition monitoring data. This paper proposes a deep learning-based process monitoring method for directed energy deposition in AM. The thermal images collected during manufacturing are used to identify the process condition, and a deep convolutional neural network model is proposed to build an end-to-end condition monitoring framework. Experiments on a real directed energy deposition dataset in AM are carried out for validation. The results suggest the proposed method offers a promising approach in process monitoring based on the industrial images. Furthermore, little prior knowledge on signal processing and AM is required, that largely facilitates the potential applications in the real industrial scenarios.",industry
10.1016/j.matpr.2019.11.152,Conference Proceeding,Materials Today: Proceedings,scopus,2020-01-01,sciencedirect,Multiresponse optimization of friction stir welding process parameters by an integrated WPCA-ANN-PSO approach,https://api.elsevier.com/content/abstract/scopus_id/85088571156,"Majority of conventional optimization techniques found in the literature deals with single response optimization problems. However, real life industrial processes are having multiple responses, which are conflicting with each other i.e, if we try to optimize one response we may have to compromise with the other. An attempt to optimize all the responses simultaneously to get all response in their acceptable range is called as Multiresponse Optimization (MRO) problem. This paper proposes an integrated WPCA-ANN-PSO approach to perform MRO of Friction Stir Welding (FSW) processes. It is a three stage process, in the first stage the multiple responses are converted into a single multiperformance index (MPI) using Taguchi-Weighted Principal Component Analysis (WPCA) approach. In the second stage an Artificial Neural Network (ANN) model is developed which is capable of predicting MPI for given set of control factors. Finally, in the third stage Particle Swarm Optimization (PSO) algorithm is used to search the global optimal solution using the developed ANN model. Further, to demonstrate the effectiveness of the proposed approach a case study on MRO of FSW process was carried-out to join two plates of AA2024-T4 aluminum using tool of HS steel of grade 304. The control factors considered were D/d ratio, tool rotation speed (TRS) and weld speed (WS). The responses considered were ultimate tensile strength (UTS) and hardness of the joint. The experiments were planned as per Taguchi orthogonal array L8. By WPCA approach the optimal parameters were found to be D/d ratio of 3, TRS of 670 rpm and WS of 17. This solution was further improved by WPCA-ANN-PSO approach and validated by confirmation experiments successfully.",industry
10.1016/j.procs.2020.04.199,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Perspective Vehicle License Plate Transformation using Deep Neural Network on Genesis of CPNet,https://api.elsevier.com/content/abstract/scopus_id/85086630682,"Recent development in vehicular industries and increased number of cars in modern society leads the people to pay more attention on Vehicle License Plate Recognition (V-LPR). V-LPR plays a major role in traffic related application such as road traffic monitoring, vehicle parking lots access control etc. Existing state of the art V-LPR systems in real world deployment works under restricted conditions, such as static illumination, fixed background etc. Most of them fails to work when any of the above given conditions are violated. Hence to address this issue, a novel V-LPR system is designed using modern deep learning framework called ""Capsule Network"". The proposed system is robust and works fine in any condition. Further, the proposed method aims to improve the processing time by integrating the segmentation process within the CN framework which involves the training and recognizing of entire license plate cropped region. Moreover, the feature extraction is performed by CN framework over a segmented alphanumeric character. Finally, Data augmentation technique is also used as a supplement to the CN framework to strengthen the process of training with various orientations like rotation, shift and flip for improving the recognition task.",industry
10.1016/j.procs.2020.03.050,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,A compact and understandable associative classifier based on overall coverage,https://api.elsevier.com/content/abstract/scopus_id/85085583655,"Associative classification is a machine learning approach that aims to build accurate, effective and compact classification models (classifiers) by combining paradigms from classification and association rule mining. Research studies show that associative classification approaches could achieve higher accuracy than some of the traditional classification methods. In this paper, we propose a simple and accurate classification method by selecting “strong” class association rules that highly contribute to improve the overall coverage of the classifier. The advantage of our proposed classifier is that it generates reasonably less rules on bigger datasets compared to traditional rule-based classifiers. We also discuss how the overall coverage of such classifiers affects their classification accuracy. We have performed experiments on 15 real-life datasets from the UCI Machine Learning Database Repository and compared our proposed associative classifier with other 8 well-known classification algorithms on accuracy and the number of classification rules (all differences were tested for statistical significance). Experimental results show that our proposed method was comparative with other well-known classification algorithms on accuracy, it achieved the fourth-highest average accuracy (82.7%) among all classification methods, and tends to outperform the other algorithms in terms of average number of rules (especially on bigger datasets). Although not achieving the best results in terms of classification accuracy, our approach is relatively simple and produces a compact and understandable classifier by exhaustively searching the entire example space.",industry
10.1016/j.procs.2020.03.027,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Strategic zoning approach for urban areas: Towards a shared transportation system,https://api.elsevier.com/content/abstract/scopus_id/85085571988,"Investigating downstream freight demand is a prerequisite to accomplishing the overall strategic implementation of transportation systems. Machine learning has recently become widely applied in order to support decision-making in several logistic operational levels: travel/arrival time prediction, occupancy forecasting of logistic spaces, route optimization and so on. Nevertheless, strategic decision-making often overlooks flow tendencies forecasting. Targeting this perspective, the present paper aims at proposing an urban zoning approach based on time series forecasting of supply chain demand through clustering customers. To conduct our approach, we have selected a set of machine learning algorithms that are believed to be robust according to the literature and the achieved accuracy benchmarks. Considering real-life data-based computational results, a number of analytical insights are illustrated.",industry
10.1016/j.procs.2020.03.044,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,An artificial intelligence based crowdsensing solution for on-demand accident scene monitoring,https://api.elsevier.com/content/abstract/scopus_id/85085566175,"Road traffic crashes have a devastating impact on societies by claiming more than 1.35 million lives each year and causing up to 50 million injuries. Improving the efficiency of emergency management systems constitutes a key measure to reduce road traffic deaths and injuries. In this work, we propose a comprehensive crowdsensing-based solution for the real-time collection and the analysis of accident scene intelligence as a means to improve the efficiency of the emergency response process and help reduce road fatalities. The solution leverages sensory, mobile, and web technologies for the real-time monitoring of accident scenes, and employs Artificial Intelligence for the automatic analysis of the accident scene data, to allow the automatic generation of accident intelligence reports. Police officers and rescue teams can use those reports for fast and accurate situational assessment and effective response to emergencies. The proposed system was fully implemented and its operation was successfully tested using a variety of scenarios. This work gives interesting insights into the possibility of leveraging crowdsensing and artificial intelligence for offering emergency situational awareness and improving the efficiency of emergency response operations.",industry
10.1016/j.procs.2020.03.004,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Activity Recognition in Smart Homes using UWB Radars,https://api.elsevier.com/content/abstract/scopus_id/85085563629,"In the last decade, smart homes have transitioned from a potential solution for aging-in-place to a real set of technologies being deployed in the real-world. This technological transfer has been mostly supported by simple, commercially available sensors such as passive infrared and electromagnetic contacts. On the other hand, many teams of research claim that the sensing capabilities are still too low to offer accurate, robust health-related monitoring and services. In this paper, we investigate the possibility of using Ultra-wideband (UWB) Doppler radars for the purpose of recognizing the ongoing ADLs in smart homes. Our team found out that with simple configuration and classical features engineering, a small set of UWB radars could reasonably be used to recognize ADLs in a realistic home environment. A dataset was built from 10 persons performing 15 different ADLs in a 40 square meters apartment with movement on the other side of the wall. Random Forest was able to attain 80% accuracy with an F1-Score of 79%, and a Kappa of 77%. Those results indicate the use of Doppler radars can be a good research avenue for smart homes.",industry
10.1016/j.procs.2020.03.036,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Air Quality Forecasting using LSTM RNN and Wireless Sensor Networks,https://api.elsevier.com/content/abstract/scopus_id/85085553433,"In the past few decades, many urban areas around the world have suffered from severe air pollution and the health hazards that come with it, making gathering real-time air quality and air quality forecasting very important to take preventive and corrective measures. This paper proposes a scalable architecture to monitor and gather real-time air pollutant concentration data from various places and to use this data to forecast future air pollutant concentrations. Two sources are used to collect air quality data. The first being a wireless sensor network that gathers and sends pollutant concentrations to a server, with its sensor nodes deployed in various locations in Bengaluru city in South India. The second source is the real-time air quality data gathered and made available by the Government of India as a part of its Open Data initiative. Both sources provide average concentrations of various air pollutants on an hourly basis. Due to its proven track record of success with time-series data, a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) model was chosen to perform the task of air quality forecasting. This paper critically analyses the performance of the model in two regions that exhibit a significant difference in temporal variations in air quality. As these variations increase, the model suffers performance degradation necessitating adaptive modelling.",industry
10.1016/j.promfg.2020.04.017,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,PPE compliance detection using artificial intelligence in learning factories,https://api.elsevier.com/content/abstract/scopus_id/85085527469,"This project demonstrates the application of Artificial Intelligence (AI) and machine vision for the identification of Personal Protective Equipment (PPE), particularly safety glasses in zones of the Learning Factory, where safety risks exist. The objective is to design and implement an automated system for ensuring the safety of personnel when they are in the vicinity of machinery that presents potential risks to the eyes. Microsoft Azure Custom Vision AI and Intelligent AI Services, in conjunction with low-cost vision devices with lightweight onboard AI capability, provide a platform for a deep learning neural network model using publicly available images under the Creative Commons License. A combination of cloud-based and on-premises AI is used in this proof of concept system to provide a real-time vision-based safety system capable of detecting and recording potential safety breaches, promoting compliance, and ultimately preventing accidents before they happen. This system can be used to initiate different control actions in the event of safety violations and can detect multiple forms of protective wear. The flexibility of the system offers multiple benefits to learning factories and manufacturing organizations such as improved user safety, reduced insurance costs, and better detection and recording of safety violations. The hybrid AI architecture approach allows for flexibility in training and deployment based on the capability of local computing resources.",industry
10.1016/j.promfg.2020.04.082,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Integrating virtual and physical production processes in learning factories,https://api.elsevier.com/content/abstract/scopus_id/85085519100,"Scaled learning factories are industrial learning environments that provide production systems and processes for learners on a model scale rather than using actual productive machines. This approach has benefits as for instance lower invest, increased approachability and higher safety levels. At the same time, constraints for implementation of actual production processes and required abstraction levels from industrial processes are limitations. To bridge the gap between benefits and limitation we propose the integration of virtual production processes in a prevalent physical learning factories. Resulting mixed reality solutions bear the potential to combine real and virtual objects at the same time and thus extend the physical model environment with virtually represented processes. Based on an initial analysis we develop a concept using spatial augmented reality and a game engine based simulation to realize a virtual integrated production process. The theoretical concept as well as the technical implementation is described. A first evaluation indicates a high rate of acceptance by trainees and illustrates the benefits for learning performance.",industry
10.1016/j.promfg.2020.04.055,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,From digital shop floor to real-time reporting: An IIoT based educational use case,https://api.elsevier.com/content/abstract/scopus_id/85085498833,"The Smart Production Lab (Lab)at the FH JOANNEUM in Kapfenberg, Austria, is a digital learning and research factory with an interdisciplinary focus on vertical and horizontal IT-integration. It is aiming at a higher transparency and productivity by applying latest digital technologies. The key technology is the Industrial Internet of Things (IIoT). Therefore, research driven IoT use cases are further developed such as hybrid IoT-concepts and architectures involving edge and cloud computing. State-of-the-Art use cases apply of-the-shelf technologies for ready-to-use implementations and teaching purposes. This paper introduces a case-based teaching concept in the area of IIoT. It provides students with a hands-on experience as well as deep insights in what is meant by modelling and implementing an IoT data flow from the shop floor to real-time reporting. For this purpose, on the operational technology (OT) layer IoT nodes were attached to the machinery in the Lab gathering and providing data for the IoT middleware layer, based on Open Platform Communication Unified Architecture (OPC UA). This central middleware-layer is represented by the open source platform Node-RED. In the respective use case the data is transformed in order to be stored in a NoSQL database, from where it can be accessed for real-time reporting either by cloud or on premise applications. The interdisciplinary nature of these use case consists of integrating the different aspects of a digital production, involving disciplines such as automation, digital retrofitting, operational technology, and informational technology. Thus, it provides students with a comprehensive understanding of the benefits and limitations of IIoT.",industry
10.1016/j.promfg.2020.04.037,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Implementing AR/MR - Learning factories as protected learning space to rise the acceptance for mixed and augmented reality devices in production,https://api.elsevier.com/content/abstract/scopus_id/85085498037,"When talking about digitization, changes in the way of working are inevitable: The implementation of intelligent machines or dealing with real-time data lead to new tasks supported by new technology. Also digital technologies such as Augmented and Mixed Reality (AR/MR) are pushing the market and setting new standards in collaboration, prototyping or maintenance. The correct handling of AR/MR devices requires a change in the employees’ behavior; changing working routines are followed by a new skill set and a change in the culture. The acceptance of employees can therefore be regarded as a critical success factor for the implementation of such technologies. Thus, the present paper answers the research question ‘what factors influence the employee’s acceptance of AR and MR data glasses in industry’. On the basis of a comprehensive literature analysis, an implementation workshop was developed and validated in cooperation with an industrial partner. The results were transformed into a workshop within the learning and research factory ‘Smart Production Lab’ to give employees and students the opportunity to train the handling of data glasses in a protected learning space in order to increase the acceptance for the technology.",industry
10.1016/j.promfg.2020.04.066,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,5G and AI technology application in the AMTC learning factory,https://api.elsevier.com/content/abstract/scopus_id/85085489730,"5G and AI (Artificial Intelligence) are changing industrial production and offer great potential for manufacturing enterprises. One of the effects resulting from the increasing quantity of production data is the increasing demands of transmission of large amounts of data, fast transmission speed, and rapid data analysis. However, merely relying on traditional communication technology and manual data processing does not lead to high transmission performance and low analysis time. It is essential to integrate 5G and AI technology to flexibly transmit large amounts of data and real-time data. To demonstrate the feasibility and potential of these two technologies, a concept was developed at the Advanced Manufacturing Technology Center (AMTC) at the Tongji University (Shanghai, China) and further implemented in the AMTC learning factory in cooperation with wbk of Karlsruhe Institute of Technology (Karlsruhe, Germany) and Ruhr-University Bochum (Bochum, Germany). This paper presents the learning factory design in detail, describing the concept design, training environment and training phases in the AMTC learning factory. It is followed by a case study consisting of specific examples of 5G and AI, implemented in the AMTC learning factory. The importance of integrated 5G and AI applications is pointed out and discussed.",industry
10.1016/j.promfg.2020.04.038,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Seamless data integration in the CAM-NC process chain in a learning factory,https://api.elsevier.com/content/abstract/scopus_id/85085473050,"The seamless data integration of different components in the CAM-NC process chain (tool management software, tool dispensing system, presetting machine and machine tool) is essential for maximizing the efficiency and minimizing the total error rate. This is done by entering the data into the system of the network only once. Then this data is available for all participants in this network at any time. This paper describes the aforementioned integration by using the example of creating a digital tool, which is used in a CAM simulation afterwards. Then the real set-up and machining process is discussed. The process chain explained in this paper was implemented at the smartfactory@tugraz - the Learning Factory at Graz University of Technology.",industry
10.1016/j.procs.2020.03.187,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Churn Prediction in Telecommunication using Logistic Regression and Logit Boost,https://api.elsevier.com/content/abstract/scopus_id/85084443717,"Today in every industry weather, it is ISP, IT products, social network or mobile services there is the problem of customer churn (Customers changing their services from one service provider to another). However, in telecommunication the customers churning very frequently. As the market in telecom is fiercely competitive, in that case, companies proactively have to determine the customers churn by analyzing their behavior and try to put effort and money in retaining the customers. In this proposed model, two machine-learning techniques were used for predicting customer churn Logistic regression and Logit Boost. Experiment was carried out in the WEKA Machine-learning tool, along with a real database from an American company Orange. The result were shown in different evaluation measures.",industry
10.1016/j.softx.2020.100419,Journal,SoftwareX,scopus,2020-01-01,sciencedirect,TWINKLE: A digital-twin-building kernel for real-time computer-aided engineering,https://api.elsevier.com/content/abstract/scopus_id/85079158568,"TWINKLE is a library for building families of solvers to perform Canonical Polyadic Decomposition (CPD) of tensors. The common characteristic of these solvers is that the data structure supporting the tuneable solution strategy is based on a Galerkin projection of the phase space. This allows processing and recovering tensors described by highly sparse and unstructured data. For achieving high performance, TWINKLE is written in C++ and uses the Armadillo open source library for linear algebra and scientific computing, based on LAPACK (Linear Algebra PACKage) and BLAS (Basic Linear Algebra Subprograms) routines. The library has been implemented keeping in mind its future extensibility and adaptability to fulfil the different users’ needs in academia and industry regarding Reduced Order Modelling (ROM) and data analysis by means of tensor decomposition. It is especially focused on post-processing data from Computer-Aided-Engineering (CAE) simulation tools.",industry
10.1016/j.aei.2020.101044,Journal,Advanced Engineering Informatics,scopus,2020-01-01,sciencedirect,IoT edge computing-enabled collaborative tracking system for manufacturing resources in industrial park,https://api.elsevier.com/content/abstract/scopus_id/85078852726,"In manufacturing industry, the movement of manufacturing resources in production logistics often affects the overall efficiency. This research is motivated by a world-leading air-conditioner manufacturer. In order to provide the right manufacturing resources for subsequent production steps, excessive time and human effort has been consumed in locating the manufacturing resources in a huge industrial park. The development of Internet of Things (IoT) has made a profound impact on establish smart manufacturing workshop and tracking applications, however a growing trend of data quantity that generated from massive, heterogeneous and bottomed manufacturing resources objects pose challenge to centralized decision. In this study, the concept of edge-computing deeply integrated in collaborative tracking purpose in virtue of IoT technology. An IoT edge computing enabled collaborative tracking architecture is developed to offload the computation pressure and realize distributed decision making. A supervised learning of genetic tracking method is innovatively presented to ensure tracking accuracy and effectiveness. Finally, the research output is developed and implemented in a real-life industrial park for verification. The results show that the proposed tracking method not only performs constant improving accuracy up to 96.14% after learning compared to other tracking method, but also ensure quick responsiveness and scalability.",industry
10.1016/j.aei.2020.101037,Journal,Advanced Engineering Informatics,scopus,2020-01-01,sciencedirect,A smart surface inspection system using faster R-CNN in cloud-edge computing environment,https://api.elsevier.com/content/abstract/scopus_id/85078666892,"Automated surface inspection has become a hot topic with the rapid development of machine vision technologies. Traditional machine vision methods need experts to carefully craft image features for defect detection. This limits their applications to wider areas. The emerging convolutional neural networks (CNN) can automatically extract features and yield good results in many cases. However, the CNN-based image classification methods are more suitable for flat surface texture inspection. It is difficult to accurately locate small defects in geometrically complex products. Furthermore, the computational power required in CNN algorithms is usually high and it is not efficient to be implemented on embedded hardware. To solve these problems, a smart surface inspection system is proposed using faster R-CNN algorithm in the cloud-edge computing environment. The faster R-CNN as a CNN-based object detection method can efficiently identify defects in complex product images and the cloud-edge computing framework can provide fast computation speed and evolving algorithm models. A real industrial case study is presented to illustrate the effectiveness of the proposed method. The results show that the proposed method can provide high detection accuracy within a short time.",industry
10.1016/j.aei.2019.101013,Journal,Advanced Engineering Informatics,scopus,2020-01-01,sciencedirect,Guidelines for applied machine learning in construction industry—A case of profit margins estimation,https://api.elsevier.com/content/abstract/scopus_id/85075778987,"The progress in the field of Machine Learning (ML) has enabled the automation of tasks that were considered impossible to program until recently. These advancements today have incited firms to seek intelligent solutions as part of their enterprise software stack. Even governments across the globe are motivating firms through policies to tape into ML arena as it promises opportunities for growth, productivity and efficiency. In reflex, many firms embark on ML without knowing what it entails. The outcomes so far are not as expected because the ML, as hyped by tech firms, is not the silver bullet. However, whatever ML offers, firms urge to capitalise it for their competitive advantage. Applying ML to real-life construction industry problems goes beyond just prototyping predictive models. It entails intensive activities which, in addition to training robust ML models, provides a comprehensive framework for answering questions asked by construction folks when intelligent solutions are getting deployed at their premises to substitute or facilitate their decision-making tasks. Existing ML guidelines used in the IT industry are vastly restricted to training ML models. This paper presents guidelines for Applied Machine Learning (AML) in the construction industry from training to operationalising models, which are drawn from our experience of working with construction folks to deliver Construction Simulation Tool (CST). The unique aspect of these guidelines lies not only in providing a novel framework for training models but also answering critical questions related to model confidence, trust, interpretability, bias, feature importance and model extrapolation capabilities. Generally, ML models are presumed black boxes; hence argued that nobody knows what a model learns and how it generates predictions. Even very few ML folks barely know approaches to answer questions asked by the end users. Without explaining the competence of ML, the broader adoption of intelligent solutions in the construction industry cannot be attained. This paper proposed a detailed process for AML to develop intelligent solutions in the construction industry. Most discussions in the study are elaborated in the context of profit margin estimation for new projects.",industry
10.1016/j.asoc.2019.105929,Journal,Applied Soft Computing Journal,scopus,2020-01-01,sciencedirect,Multi robot distance based formation using Parallel Genetic Algorithm,https://api.elsevier.com/content/abstract/scopus_id/85075464885,"In this paper an alternative method to achieve distance based formation is presented. The method uses Genetic Algorithms to find a suitable solution based on angle and distance, and an appropriate constant velocity to avoid collisions. The designed algorithm is extended to a parallel scheme to improve its performance and achieve Artificial Distributed Intelligence, in which the robots share, through solution migration, the best ways to converge to desired distances while avoiding collisions, finally reaching consensus on the solution. The algorithm is tested using simulations and real robots experiments.",industry
10.1016/j.xphs.2019.09.026,Journal,Journal of Pharmaceutical Sciences,scopus,2020-01-01,sciencedirect,"Silicone Oil Particles in Prefilled Syringes With Human Monoclonal Antibody, Representative of Real-World Drug Products, Did Not Increase Immunogenicity in In Vivo and In Vitro Model Systems",https://api.elsevier.com/content/abstract/scopus_id/85075396123,"Silicone oil is a lubricant for prefilled syringes (PFS), a common primary container for biotherapeutics. Silicone oil particles (SiOP) shed from PFS are a concern for patients due to their potential for increased immunogenicity and therefore also of regulatory concern. To address the safety concern in a context of manufacturing and distribution of drug product (DP), SiOP was increased (up to ∼25,000 particles/mL) in PFS filled with mAb1, a fully human antibody drug, by simulated handling of DP mimicked by drop shock. These samples are characterized in a companion report (Jiao N et al. J Pharm Sci. 2020). The risk of immunogenicity was then assessed using in vitro and in vivo immune model systems. The impact of a common DP excipient, polysorbate 80, on both the formation and biological consequences of SiOP was also tested. SiOP was found associated with (1) minimal cytokine secretion from human peripheral blood mononuclear cells, (2) no response in cell lines that report NF-κB/AP-1 signaling, and (3) no antidrug antibodies or significant cytokine production in transgenic Xeno-het mice, whether or not mAb1 or polysorbate 80 was present. These results suggest that SiOP in mAb1, representative of real-world DP in PFS, poses no increased risk of immunogenicity.",industry
10.1016/j.ergon.2019.102878,Journal,International Journal of Industrial Ergonomics,scopus,2020-01-01,sciencedirect,Relative Pointing Interface: A gesture interaction method based on the ability to divide space,https://api.elsevier.com/content/abstract/scopus_id/85075264255,"A new type of 3D gesture interface called Relative Pointing Interface (RelPoInt) is suggested in this study. RelPoInt allows users to select a virtual button by pointing to a relative position in a virtual 3D menu. This approach makes use of the distance or angle between the relative point and the reference point. Users can set the reference point freely and operate all the functions on the menu with a simple gesture. Microsoft Kinect was used to implement the RelPoInt in this study. To suggest a radial menu suitable for the RelPoInt, we conducted an experiment in which 20 participants were asked to point to virtual buttons, which were divided into four to eight regions. Errors and subjective assessment of easiness were measured at each treatment condition. RelPoInt can make users to manipulate functions without memorizing complicated gesture vocabularies, which is among the most serious pain points of using a gesture interface. Furthermore, RelPoInt does not require expensive gesture recognition equipment compared with finger recognition interfaces because the required resolution of interaction recognition is less sophisticated. It can be useful in applying 3D gesture interfaces to a variety of devices for smart home, virtual or augmented reality.
               
                  Relevance to industry
                  The proposed interface can be applied to various environments with low cost and easy to implement. Therefore, this interface is highly worthy of use in areas where gestures are useful to interact, such as IoT (Internet of Things) and VR (Virtual Reality)/AR (Augmented Reality).",industry
10.1016/bs.adcom.2019.09.005,Book Series,Advances in Computers,scopus,2020-01-01,sciencedirect,Impact of cloud security in digital twin,https://api.elsevier.com/content/abstract/scopus_id/85073737509,"Digital Twin is a way to virtually represent or model a physical object using the real time data. This innovation sets up a way to deal with industries and organizations to supervise their products, consequently bridging the gap between design and implementations. As the name suggests, “Digital Twin” infers that a reproduction of the product is made in order to have a nearby relationship with the live item. The procedure of computerized twin begins by gathering real time data, processed data, and operational data and performs distinctive investigation which helps in anticipating the future. This additionally enhances the customer experiences by giving a digital feel of their product. The objective behind all these is the job of gathering information and putting them in a place, i.e., the cloud which could store exorbitant data. The user experience gets enhanced by the intervention of digital twin technology which could help in the successful working of the products geographically distributed. The impact of Internet of Things and Cloud Computing lifts up the digital twin.
                  The information gathered from the sources can be arranged in terms of utilization and prospect to change on a timely basis. These data, as they are stored require proper coordination and a legitimate use.
                  Digital Twin innovation assumes incredible opportunities in the field of manufacturing, healthcare, smart cities, automobile and so on. The effect of having a digital twin for the product makes it simple for activities and recognize the blemishes, if any happened. This approach can help reduce the workload and furthermore can get trained on the virtual machine without the need of a specific training.
                  With the most prevailing technologies of today, like Artificial Intelligence, Machine Learning and Internet of Things more prominent approach to train and monitor products, taking care of its own execution, collaborating to different frameworks, performing self-repairs are made possible. Hence the future is getting unfolded with the emerging DIGITAL TWIN era. The massive data utilized in the field of digital twin is prone to severe security breaches. Thus digital twin technology should be handled with extreme care so as to protect the data. Hence, this chapter identifies the ways and means of collecting, organizing and storing the data in a secured cloud environment. The data is filtered according to the use and priority and pushed into the cloud. It is determined to implement an exclusive algorithm for a secured cloud which would greatly benefit the users and the providers to handle and process it effectively.",industry
10.1016/j.vehcom.2019.100198,Journal,Vehicular Communications,scopus,2020-01-01,sciencedirect,In-vehicle network intrusion detection using deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85073150001,"The implementation of electronics in modern vehicles has resulted in an increase in attacks targeting in-vehicle networks; thus, attack detection models have caught the attention of the automotive industry and its researchers. Vehicle network security is an urgent and significant problem because the malfunctioning of vehicles can directly affect human and road safety. The controller area network (CAN), which is used as a de facto standard for in-vehicle networks, does not have sufficient security features, such as message encryption and sender authentication, to protect the network from cyber-attacks. In this paper, we propose an intrusion detection system (IDS) based on a deep convolutional neural network (DCNN) to protect the CAN bus of the vehicle. The DCNN learns the network traffic patterns and detects malicious traffic without hand-designed features. We designed the DCNN model, which was optimized for the data traffic of the CAN bus, to achieve high detection performance while reducing the unnecessary complexity in the architecture of the Inception-ResNet model. We performed an experimental study using the datasets we built with a real vehicle to evaluate our detection system. The experimental results demonstrate that the proposed IDS has significantly low false negative rates and error rates when compared to the conventional machine-learning algorithms.",industry
10.1016/j.petrol.2019.106490,Journal,Journal of Petroleum Science and Engineering,scopus,2020-01-01,sciencedirect,Fault identification using a chain of decision trees in an electrical submersible pump operating in a liquid-gas flow,https://api.elsevier.com/content/abstract/scopus_id/85072610900,"The monitoring of centrifugal pumps is essential for the suitable operation of several industrial applications. The reliability of petroleum artificial lifting systems that use Electrical Submersible Pumps (ESP) depends substantially on the performance of these pumps. ESP can operate subjected to severe operating conditions such as viscous and two-phase flow. In recent years, real-time technologies based on machine learning algorithms have gained importance due to the capability to take advantage of historical data for future predictions. The present work proposes a particular assembly of Classification and Regression Trees (CART) for the detection and classification of incipient faults in a pumping system. Experiments were carried out on a ten-stage ESP to simulate, monitor and label the faults. The pump worked at 1800, 2400, 3000 and 3500 rpm, with a two-phase liquid-gas mixture. The gas-phase was nitrogen, and the liquid-phase was a heavy oil with a viscosity between 200 and 1000 cP. The proposed methodology, named here as Chain of Decision Trees, observe the system behavior based on the monitoring of the pressure, flow, torque, and temperature only. The algorithm has two steps. The first determines whether the system is in a fault state; if it is, the second determines the type of fault. The failures considered were the unexpected closure of the choke valve, the input pressure decreasing, the fluid viscosity increasing and the gas flow rate increasing. The proposed approach intends to improve the balance in classification and the interpretation of the cause of failure. The Chain of Decision Trees and the Decision Tree were compared regarding the overall accuracy and the individual fault misclassification getting a reduction in individual misclassification and better comprehensibility for the Chain of Decision Tree.",industry
10.1016/j.snb.2019.127056,Journal,"Sensors and Actuators, B: Chemical",scopus,2019-12-12,sciencedirect,Quality level identification of West Lake Longjing green tea using electronic nose,https://api.elsevier.com/content/abstract/scopus_id/85071936122,"China grows and consumes numerous types of tea, which have diverse processing techniques. West Lake Longjing Tea is one of the most famous and popular varieties of tea in China. It is difficult for consumers to assess the quality of Longjing green tea, as it usually requires well-trained experts to make the judgement based on colour, aroma, and taste. To this end, we propose a quality identification system consisting of a self-developed electronic nose and a data analysis algorithm to assess the quality of West Lake Longjing Tea based on its aroma. The equipment was tested extensively in experiments conducted on real-world data. The results show that the proposed system is capable of distinguishing the tea grades accurately. Furthermore, we studied the quality specifications of Longjing tea sold by different brands and found that standard certified brands have more accurate quality identification criteria than non-standard certified brands. Our findings will assist customers and tea factories in evaluating the quality of Longjing Tea and guide the optimisation of quality standards.",industry
10.1016/j.vetmic.2019.108450,Journal,Veterinary Microbiology,scopus,2019-12-01,sciencedirect,UV-C irradiation is able to inactivate pathogens found in commercially collected porcine plasma as demonstrated by swine bioassay,https://api.elsevier.com/content/abstract/scopus_id/85075243758,"Liquid porcine plasma is an animal origin raw material for the manufacturing process of spray-dried porcine plasma that is used in pig nutrition worldwide. In previous studies we found that the application of ultraviolet light C (UV-C) in liquid plasma that was inoculated with a variety of bacteria or viruses of importance in the swine industry can be considered as redundant safety steps because in general achieve around 4 logs reduction for most of these pathogens. However, the final validation of the UV-C light as safety feature should be conducted with commercial liquid plasma and using the pig bioassay model. As a first objective, the potential infectivity of a raw liquid plasma product collected from an abattoir was tested by means of a swine bioassay. We used Porcine circovirus 2 (PCV-2), a ubiquitous virus that has been systematically detected by PCR in porcine plasma at abattoirs as selection criteria for commercial liquid plasma lot. As a second aim of the study, the effects of different doses of UV-C irradiation on the selected raw liquid plasma were assayed in the animal bioassay. Moreover, other swine infecting agents, including Porcine reproductive and respiratory syndrome virus (PRRSV), were also determined in the original plasma and monitored in the inoculated animals. Pigs negative for PCV-2 and PRRSV genome and antibodies were allotted to one of five groups (6 to 8 pigs/ group) and injected intra-peritoneally with 10 mL of their assigned inoculum at 50 d of age. Negative control pigs (group 1) were injected with PBS. Positive control pigs (group 5) were injected with a PCV-2 inoculum. Groups 2, 3 and 4 were injected with liquid porcine plasma that had been subjected to 0 (raw plasma), 3000 or 9000 J/L UV-C irradiation, respectively. Group 2 pigs (0 J/L UV-C) got infection by PRRSV but no PCV-2 infection or seroconversion. However, one pig from group 2 seroconverted to Rotavirus A (RVA) and Hepatitis E virus (HEV) and three group 2 pigs seroconverted to Porcine parvovirus (PPV). Groups 1, 3 and 4 pigs showed no evidence of infection or seroconversion associated with the tested viruses or any other pathogens found in the liquid plasma before UV-C irradiation. Group 5 pigs developed PCV-2 infectivity as expected. UV-C irradiation of liquid plasma at 3000 and 9000 J/L was effective in preventing PRRSV and other pathogens transmission. Moreover, raw liquid plasma was non-infectious for PCV-2 in naïve pigs.",industry
10.1016/j.jmapro.2019.10.020,Journal,Journal of Manufacturing Processes,scopus,2019-12-01,sciencedirect,Data-driven smart manufacturing: Tool wear monitoring with audio signals and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85074281429,"Tool wear in machining could result in poor surface finish, excessive vibration and energy consumption. Monitoring tool wear in real-time is crucial to improve manufacturing productivity and quality. While numerous sensor-based tool wear monitoring techniques have been demonstrated in laboratory environments, few tool wear monitoring systems have been deployed in factories because it is not realistic to install some of the important sensors such as dynamometers on manufacturing machines. To address this issue, a novel audio signal processing approach is introduced. This technique does not require expensive sensors but audio sensors only. A blind source separation method is used to separate source signals from noise. An extended principal component analysis is used for dimensionality reduction. Real-time multi-channel audio signals are collected during a set of milling tests under varying cutting conditions. The experimental data are used to develop and validate a predictive model. Experimental results have shown that the predictive model is capable of classifying tool wear conditions with high accuracy.",industry
10.1016/j.jprocont.2019.10.009,Journal,Journal of Process Control,scopus,2019-12-01,sciencedirect,Predicting the combustion state of rotary kilns using a Convolutional Recurrent Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85074280427,"The combustion state of rotary kilns during normal burning conditions is critical for entire industrial production processes. However, predicting this state is also challenging. To date, no-one has tried directly using flame images to enable such a prediction. In this paper, a novel neural network architecture is presented that can use a series of flame image sequences with a dynamic spatiotemporal relationship to predict a rotary kiln's combustion state. The proposed neural network architecture implements an end-to-end model of the output that directly draws upon input data, thereby eliminating the need for traditional complicated feature extraction procedures. This method combines the advantages of convolutional neural networks (CNN) and recurrent neural networks (RNN) to facilitate an effective prediction. The method was tested by conducting numerous experiments based on real datasets from a steel plant. The proposed convolutional recurrent neural network (CRNN) achieved an average prediction accuracy of 93.26%, thus verifying that the method is effective and suggesting that it may have the potential for industrial application.",industry
10.1016/j.lwt.2019.108548,Journal,LWT,scopus,2019-12-01,sciencedirect,Combination of LF-NMR and BP-ANN to monitor water states of typical fruits and vegetables during microwave vacuum drying,https://api.elsevier.com/content/abstract/scopus_id/85071455481,"To set up a rapid real-time nondestructive detection of moisture content, this paper reported the results of a combination of LF-NMR and BP-ANN to monitor the relationship between drying parameters and state of water under different microwave vacuum drying conditions. Three kinds of materials, carrot (fruit), banana (vegetable) and pleurotus eryngii (edible fungus), were tested in the experiment of applicability. The resulted showed that the information of Atotal and T23 can be used to analyze the drying behavior and the information of A20, A21 and A22 can be used as the fingerprint characteristics of material discrimination. Three classic models (PLS, SVM and BP-ANN) were compared to study the prediction ability of moisture content with the inputs of A20, A21, A22, A23 and Atotal. The performance of BP-ANN model was the best. Although the BP-ANN model of mixed species was not as good as the BP-ANN model of single fruit or vegetable, it still had excellent predictive performances with R2 0.9969 and RMSE 0.0184 to meet the needs of current industry and production.",industry
10.1016/j.petrol.2019.106332,Journal,Journal of Petroleum Science and Engineering,scopus,2019-12-01,sciencedirect,Machine learning methods applied to drilling rate of penetration prediction and optimization - A review,https://api.elsevier.com/content/abstract/scopus_id/85070879413,"Drilling wells in challenging oil/gas environments implies in large capital expenditure on wellbore's construction. In order to optimize the drilling related operation, real-time decisions making have been put in place, so that prediction of rate of penetration (ROP) with accuracy is essential. Despite many efforts (theoretical and experimental) throughout the years, modeling the ROP as a mathematical function of some key variables is not so trivial, due to the highly non-linearity behavior experienced. Therefore, several researches in the recent years have been proposing to use data-driven models from artificial intelligence field for ROP prediction and optimization.
                  This paper presents an extensive review of the literature on ROP prediction, especially, with machine learning techniques, as well as how these models can be used to optimize the drilling activities. The ROP models are classified as traditional models (based on physics-models), statistical models (e.g. multiple regression), or machine learning methods. This review enables to see that machine learning techniques can potentially outperform in terms of ROP-prediction accuracy on top of traditional or statistical models. Throughout this work, an extensive analysis of different ways of obtaining ROP models is carried out, concluding with different strategies adopted in literature to perform data-driven model optimization.
                  Despite the saving potential which can be achieved with real-time optimization based on data-driven ROP models, it is noticeable that there is a lack of implementation of those techniques in the industry, as per literature review. To take a step forward in real implementations, the petroleum industry must be aware that yet no rule of thumb already exists on this specific area, but still, good and very reasonable results can be achieved by following the best practices identified in this review. In addition, the modern practices of machine learning provide promising guidelines for implementing projects in oil and gas industry.",industry
10.1016/j.future.2019.07.059,Journal,Future Generation Computer Systems,scopus,2019-12-01,sciencedirect,Predicting supply chain risks using machine learning: The trade-off between performance and interpretability,https://api.elsevier.com/content/abstract/scopus_id/85069864648,"Managing supply chain risks has received increased attention in recent years, aiming to shield supply chains from disruptions by predicting their occurrence and mitigating their adverse effects. At the same time, the resurgence of Artificial Intelligence (AI) has led to the investigation of machine learning techniques and their applicability in supply chain risk management. However, most works focus on prediction performance and neglect the importance of interpretability so that results can be understood by supply chain practitioners, helping them make decisions that can mitigate or prevent risks from occurring. In this work, we first propose a supply chain risk prediction framework using data-driven AI techniques and relying on the synergy between AI and supply chain experts. We then explore the trade-off between prediction performance and interpretability by implementing and applying the framework on the case of predicting delivery delays in a real-world multi-tier manufacturing supply chain. Experiment results show that prioritising interpretability over performance may require a level of compromise, especially with regard to average precision scores.",industry
10.1016/j.chemosphere.2019.07.069,Journal,Chemosphere,scopus,2019-12-01,sciencedirect,Effect of hydraulic retention time on pollutants removal from real ship sewage treatment via a pilot-scale air-lift multilevel circulation membrane bioreactor,https://api.elsevier.com/content/abstract/scopus_id/85068844938,"Developing a real ship sewage treatment system that not only satisfies the requirement of small space onboard but also meets the latest emission standards of International Maritime Organization (IMO) is still a challenging task for ship industry. To overcome these problems, in this study, a novel pilot-scale air-lift multilevel circulation membrane bioreactor (AMCMBR) was used to explore the effect of hydraulic retention time (HRT) on effluent chemical oxygen demand (COD) and total nitrogen (TN) while treating real ship sewage. Results indicated that the satisfactory removal efficiencies of COD and TN was achieved in the former stages (Re(COD) = 91.57% and 87.82%; Re(TN) = 77.17% and 81.19%). When HRT decreased to 4 h, the removal efficiencies of COD and TN was 86.93% and 70.49% respectively, which still met the strict IMO discharge standards. This mainly because the biofilm-assistant membrane filtration lead to the increase of physical removal rate. The high ratio of mixed liquor volatile suspended solids (MLVSS)/mixed liquid suspended solids (MLSS) (i.e. 0.75) indicated a high biomass content in the attached sludge and resulted into perfect pollutants removal effort. The compliance rate of COD and TN was 100% and 89%, respectively, which indicated stable operation of the pilot-scale AMCMBR throughout the whole experiment. Fluorescence in situ Hybridization (FISH) analysis revealed that the abundance of β-Proteobacteria was a key microbial reason for TN removal. In addition, wavelet neural network (WNN) model was proved to be suitable to simulate and predict the COD and TN removal. These conclusions indicated that the pilot-scale AMCMBR technology is an effective way for real ship sewage treatment.",industry
10.1016/j.sigpro.2019.06.019,Journal,Signal Processing,scopus,2019-12-01,sciencedirect,A generic parallel computational framework of lifting wavelet transform for online engineering surface filtration,https://api.elsevier.com/content/abstract/scopus_id/85068175044,"Nowadays, complex geometrical surface texture measurement and evaluation require advanced filtration techniques. Discrete wavelet transform (DWT), especially the second-generation wavelet (Lifting Wavelet Transform – LWT), is the most adopted one due to its unified and abundant characteristics in measured data processing, geometrical feature extraction, manufacturing process planning, and production monitoring. However, when dealing with varied complex functional surfaces, the computational payload for performing DWT in real-time often becomes a core bottleneck in the context of massive measured data and limited computational capacities. It is a more prominent problem for the areal surface texture filtration by using 2D DWT. To address the issue, this paper presents a generic parallel computational framework for lifting wavelet transform (GPCF-LWT) based on Graphics Process Unit (GPU) clusters and the Compute Unified Device Architecture (CUDA). Due to its cost-effective hardware design and the powerful parallel computing capacity, the proposed framework can support online (or near real-time) engineering surface filtration for micro- and nano-scale surface metrology through exploring a novel parallel method named LBB model, the improved algorithms of lifting scheme and three implementation optimizations on the heterogeneous multi-GPU systems. The innovative approach enables optimizations on individual GPU node through an overarching framework that is capable of data-oriented dynamic load balancing (DLB) driven by a fuzzy neural network (FNN). The paper concludes with a case study on filtering and extracting manufactured surface topographical characteristics from real surfaces. The experimental results have demonstrated substantial improvements on the GPCF-LWT implementation in terms of computational efficiency, operational robustness, and task generalization.",industry
10.1016/j.rcim.2019.05.008,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2019-12-01,sciencedirect,A real-time human-robot interaction framework with robust background invariant hand gesture detection,https://api.elsevier.com/content/abstract/scopus_id/85066259834,"In the light of factories of the future, to ensure productive and safe interaction between robot and human coworkers, it is imperative that the robot extracts the essential information of the coworker. We address this by designing a reliable framework for real-time safe human-robot collaboration, using static hand gestures and 3D skeleton extraction. OpenPose library is integrated with Microsoft Kinect V2, to obtain a 3D estimation of the human skeleton. With the help of 10 volunteers, we recorded an image dataset of alpha-numeric static hand gestures, taken from the American Sign Language. We named our dataset OpenSign and released it to the community for benchmarking. Inception V3 convolutional neural network is adapted and trained to detect the hand gestures. To augment the data for training the hand gesture detector, we use OpenPose to localize the hands in the dataset images and segment the backgrounds of hand images, by exploiting the Kinect V2 depth map. Then, the backgrounds are substituted with random patterns and indoor architecture templates. Fine-tuning of Inception V3 is performed in three phases, to achieve validation accuracy of 99.1% and test accuracy of 98.9%. An asynchronous integration of image acquisition and hand gesture detection is performed to ensure real-time detection of hand gestures. Finally, the proposed framework is integrated in our physical human-robot interaction library OpenPHRI. This integration complements OpenPHRI by providing successful implementation of the ISO/TS 15066 safety standards for “safety rated monitored stop” and “speed and separation monitoring” collaborative modes. We validate the performance of the proposed framework through a complete teaching by demonstration experiment with a robotic manipulator.",industry
10.1016/j.isatra.2018.12.025,Journal,ISA Transactions,scopus,2019-12-01,sciencedirect,Deep residual learning-based fault diagnosis method for rotating machinery,https://api.elsevier.com/content/abstract/scopus_id/85059116434,"Effective fault diagnosis of rotating machinery has always been an important issue in real industries. In the recent years, data-driven fault diagnosis methods such as neural networks have been receiving increasing attention due to their great merits of high diagnosis accuracy and easy implementation. However, it is mostly difficult to fully train a deep neural network since gradients in optimization may vanish or explode during back-propagation, which results in deterioration and noticeable variance in model performance. In fault diagnosis researches, larger data sequence of machinery vibration signal containing sufficient information is usually preferred and consequently, deep models with large capacity are generally adopted. In order to improve network training, a residual learning algorithm is proposed in this paper. The proposed architecture significantly improves the information flow throughout the network, which is well suited for processing machinery vibration signal with variable sequential length. Little prior expertise on fault diagnosis and signal processing is required, that facilitates industrial applications of the proposed method. Experiments on a popular rolling bearing dataset are implemented to validate the proposed method. The results of this study suggest that the proposed intelligent fault diagnosis method for rotating machinery offers a new and promising approach.",industry
10.1016/j.inffus.2018.11.020,Journal,Information Fusion,scopus,2019-12-01,sciencedirect,Data fusion based coverage optimization in heterogeneous sensor networks: A survey,https://api.elsevier.com/content/abstract/scopus_id/85059069923,"Sensor networks, as a promising network paradigm, have been widely applied in a great deal of critical real-world applications. A key challenge in sensor networks is how to improve and optimize coverage quality which is a fundamental metric to characterize how well a point or a region or a barrier can be sensed by the geographically deployed heterogeneous sensors. Because of the resource-limited, battery-powered and type-diverse features of the sensors, maintaining and optimizing coverage quality includes a significant amount of challenges in heterogeneous sensor networks. Many researchers from both academic and industrial communities have performed numerous significant works on coverage optimization problem in the past decades. Some of them also have surveyed the current models, theories and solutions on the problem of coverage optimization. However, most of the existing surveys and analytical studies ignore how to exploit data fusion and cooperation of the deployed sensors to enhance coverage performance. In this paper, we provide an insightful and comprehensive summarization and classification on the data fusion based coverage optimization problem and techniques. Aiming at overcoming the shortcomings existed in current solutions, we also discuss the future issues and challenges in this area and sketch a general research framework in the context of reinforcement learning.",industry
10.1016/j.eswa.2019.05.052,Journal,Expert Systems with Applications,scopus,2019-11-30,sciencedirect,Unsupervised collective-based framework for dynamic retraining of supervised real-time spam tweets detection model,https://api.elsevier.com/content/abstract/scopus_id/85067174995,"Twitter is one of the most popular social platforms. It has changed the way of communication and information dissemination through its real-time messaging mechanism. Recently, it has been used by researchers and industries as a new source of data for various intelligent systems, such as tweet sentiment analysis and recommendation systems, which require high data quality. However, due to its flexibility and popularity, Twitter has become the main target for spamming activities such as phishing legitimate users or spreading malicious software, which introduces new security issues and waste resources. Therefore, researchers have developed various machine-learning algorithms to reveal Twitter spam. However, as spammers have become smarter and more crafty, the characteristics of the spam tweets are varying over time making these methods inefficient to detect new spammers tricks and strategies. In addition, some of the employed methods (e.g. blacklisting) or spammer features (e.g. graph-based features) are extremely time-consuming, which hinders the ability to detect spammer activities in real-time. In this paper, we introduce a framework to deal with the volatility of the spam contents and new spamming patterns, called the spam drift. The framework combines the strength of unsupervised machine learning approach, which learns from unlabeled tweets, to retrain a real-time supervised tweet-level spam detection model in a batch mode. A set of experiments on a large-scale data set show the effectiveness of the proposed online unsupervised method in adaptively discovers and learns the patterns of new spam activities and achieve stable recall values reaching more than 95%. Although the average spam precision of our method is around 60%, the high spam recall values show the ability of our proposed method in reducing spam drift problems compared to traditional machine learning algorithms.",industry
10.1016/j.jclepro.2019.117870,Journal,Journal of Cleaner Production,scopus,2019-11-20,sciencedirect,"Digestate evaporation treatment in biogas plants: A techno-economic assessment by Monte Carlo, neural networks and decision trees",https://api.elsevier.com/content/abstract/scopus_id/85070258305,"Biogas production is one of the most promising pathways toward fully utilizing green energy within a circular economy. The anaerobic digestion process is the industry standard technology for biogas production due to its lowered energy consumption and its reliance on microbiology. Even in such an environmental-friendly process, liquid digestate is still produced from the remains of digested bio-feedstock and will require treatment. With unsuitable treatment procedure for liquid digestate, the mass of bio-feedstock can potentially escape the circular supply chain within the economy. This paper recommends the implementation of evaporator systems to provide a sustainable liquid digestate treating mechanism within the economy. Studied evaporator systems are represented by vacuum evaporation in combination with ammonia scrubber, stripping and reverse osmosis. Nevertheless, complex multi-dimensional decisions should be made by stakeholders before implementing such systems. Our work utilizes a novel techno-economics model to study the techno-economics robustness in implementing recent state-of-art vacuum evaporation systems with exploitation of waste heat from combined heat and power (CHP) units in biogas plants (BGP). To take into the account the stochasticity of the real world and robustness of the analysis, we used the Monte-Carlo simulation technique to generate more than 20,000 of different possibilities for the implementation of the evaporation system. Favourable decision pathways are then selected using a novel methodology which utilizes the artificial neural network and a hyper-optimized decision tree classifier. Two pathways that give the highest probability of providing a fast payback period are identified. Descriptive statistics are also used to analyse the distributions of decision parameters that lead to success in implementing the evaporator system. The results highlighted that integration of evaporation system are favourable when transport costs and incentives for CHP units are large and while feed-in tariffs for electricity production and specific investment costs are low. The result of this work is expected to pave the way for BGP stakeholders and decision makers in implementing liquid digestate treating technologies within the currently existing infrastructure.",industry
10.1016/j.compchemeng.2019.05.037,Journal,Computers and Chemical Engineering,scopus,2019-11-02,sciencedirect,Modern day monitoring and control challenges outlined on an industrial-scale benchmark fermentation process,https://api.elsevier.com/content/abstract/scopus_id/85071606321,"This paper outlines real-world control challenges faced by modern-day biopharmaceutical facilities through the extension of a previously developed industrial-scale penicillin fermentation simulation (IndPenSim). The extensions include the addition of a simulated Raman spectroscopy device for the purpose of developing, evaluating and implementation of advanced and innovative control solutions applicable to biotechnology facilities. IndPenSim can be operated in fixed or operator controlled mode and generates all the available on-line, off-line and Raman spectra for each batch. The capabilities of IndPenSim were initially demonstrated through the implementation of a QbD methodology utilising the three stages of the PAT framework. Furthermore, IndPenSim evaluated a fault detection algorithm to detect process faults occurring on different batches recorded throughout a yearly campaign. The simulator and all data presented here are available to download at www.industrialpenicillinsimulation.com and acts as a benchmark for researchers to analyse, improve and optimise the current control strategy implemented on this facility. Additionally, a highly valuable data resource containing 100 batches with all available process and Raman spectroscopy measurements is freely available to download. This data is highly suitable for the development of big data analytics, machine learning (ML) or artificial intelligence (AI) algorithms applicable to the biopharmaceutical industry.",industry
10.1016/j.cherd.2019.09.005,Journal,Chemical Engineering Research and Design,scopus,2019-11-01,sciencedirect,Machine learning-based modeling and operation for ALD of SiO<inf>2</inf> thin-films using data from a multiscale CFD simulation,https://api.elsevier.com/content/abstract/scopus_id/85072515659,"Atomic layer deposition (ALD) is a widely utilized deposition technology in the semiconductor industry due to its superior ability to generate highly conformal films and to deposit materials into high aspect-ratio geometric structures. However, ALD experiments remain expensive and time-consuming, and the existing first-principles based models have not yet been able to provide solutions to key process outputs that are computationally efficient, which is necessary for on-line optimization and real-time control. In this work, a multiscale data-driven model is proposed and developed to capture the macroscopic process domain dynamics with a linear parameter varying model, and to characterize the microscopic domain film growth dynamics with a feed-forward artificial neural network (ANN) model. The multiscale data-driven model predicts the transient deposition rate from the following four key process operating parameters that can be manipulated, measured or estimated by process engineers: precursor feed flow rate, operating pressure, surface heating, and transient film coverage. Our results demonstrate that the multiscale data-driven model can efficiently characterize the transient input-output relationship for the SiO2 thermal ALD process using bis(tertiary-butylamino)silane (BTBAS) as the Si precursor. The multiscale data-driven model successfully reduces the computational time from 0.6 to 1.2h for each time step, which is required for the first-principles based multiscale computational fluid dynamics (CFD) model, to less than 0.1s, making its real-time usage feasible. The developed data-driven modeling methodology can be further generalized and used for other thermal ALD or similar deposition systems, which will greatly enhance the feasibility of industrial manufacturing processes.",industry
10.1016/j.cie.2019.106031,Journal,Computers and Industrial Engineering,scopus,2019-11-01,sciencedirect,Machine learning based concept drift detection for predictive maintenance,https://api.elsevier.com/content/abstract/scopus_id/85071975175,"In this work we present a machine learning based approach for detecting drifting behavior – so-called concept drifts – in continuous data streams. The motivation for this contribution originates from the currently intensively investigated topic Predictive Maintenance (PdM), which refers to a proactive way of triggering servicing actions for industrial machinery. The aim of this maintenance strategy is to identify wear and tear, and consequent malfunctioning by analyzing condition monitoring data, recorded by sensor equipped machinery, in real-time. Recent developments in this area have shown potential to save time and material by preventing breakdowns and improving the overall predictability of industrial processes. However, due to the lack of high quality monitoring data and only little experience concerning the applicability of analysis methods, real-world implementations of Predictive Maintenance are still rare. Within this contribution, we present a method, to detect concept drift in data streams as potential indication for defective system behavior and depict initial tests on synthetic data sets. Further on, we present a real-world case study with industrial radial fans and discuss promising results gained from applying the detailed approach in this scope.",industry
10.1016/j.enconman.2019.111932,Journal,Energy Conversion and Management,scopus,2019-11-01,sciencedirect,Cultural coyote optimization algorithm applied to a heavy duty gas turbine operation,https://api.elsevier.com/content/abstract/scopus_id/85070893013,"In the past decades, the quantity of researches regarding industrial gas turbines (GT) has increased exponentially in terms of number of publications and diversity of applications. The GTs offer high power output along with a high combined cycle efficiency and high fuel flexibility. As consequence, the energy efficiency, the pressure oscillations, the pollutant emissions and the fault diagnosis have become some of the recent concerns related to this type of equipment. In order to solve these GTs related problems and many other real-world engineering and industry 4.0 issues, a set of new technological approaches have been tested, such as the combination of Artificial Neural Networks (ANN) and metaheuristics for global optimization. In this paper, the recently proposed metaheuristic denoted Coyote Optimization Algorithm (COA) is applied to the operation optimization of a heavy duty gas turbine placed in Brazil and used in power generation. The global goal is to find the best valves setup to reduce the fuel consumption while coping with environmental and physical constraints from its operation. In order to treat it as an optimization problem, an integrated simulation model is implemented from original data-driven models and others previously proposed in literature. Moreover, a new version of the COA that links some concepts from Cultural Algorithms (CA) is proposed, which is validated under a set of benchmarks functions from the Institute of Electrical and Electronics Engineers (IEEE) Congress on Evolutionary Computation (CEC) 2017 and tested to the GT problem. The results show that the proposed Cultural Coyote Optimization Algorithm (CCOA) outperforms its counterpart for benchmark functions. Further, non-parametric statistical significance tests prove that the CCOA’s performance is competitive when compared to other state-of-the-art metaheuristics after a set of experiments for five case studies. In addition, the convergence analysis shows that the cultural mechanism employed in the CCOA has improved the COA balance between exploration and exploitation. As a result, the CCOA can improve the current GT operation significantly, reducing the fuel consumption up to 
                        
                           3.6
                           %
                        
                      meanwhile all constraints are accomplished.",industry
10.1016/j.chieco.2019.101344,Journal,China Economic Review,scopus,2019-10-01,sciencedirect,Does renaming promote economic development? New evidence from a city-renaming reform experiment in China,https://api.elsevier.com/content/abstract/scopus_id/85071947169,"To explore the impact of city-renaming reform on economic growth, we compare the empirical performance of the synthetic control method, panel data approach and machine learning method (LASSO and elastic net) by the case of Xiangyang, which was officially renamed in 2010. We find that for the data on real GDP growth, the panel data approach reveals the best performance under the criteria of evaluating the quality of a model. The estimation results show that Xiangyang's real GDP growth rate rose by about 1.43% annually after the renaming reform. However, further discussions show that the annual growth rate of the tertiary industry decreased by 1.59%, which contradicts the mechanism of the brand effect of the reform. The statistical inference demonstrates that even if a city did not implement the city-renaming reform in 2010, the probability of obtaining an effect as large as Xiangyang's would be 25.9%. Therefore, the effect of the city-renaming reform is insignificant and other policy interventions—rather than the city-renaming reform—promote economic growth in Xiangyang. In summary, policymakers cannot win a “Promotion Tournament” by renaming cities.",industry
10.1016/j.engfracmech.2019.106642,Journal,Engineering Fracture Mechanics,scopus,2019-10-01,sciencedirect,Necking-induced fracture prediction using an artificial neural network trained on virtual test data,https://api.elsevier.com/content/abstract/scopus_id/85071523401,"The imperfection-based necking model by Marciniak and Kuczyński (MK) is frequently used for predicting the onset of localized necking under proportional and non-proportional loading, which can be considered a lower limit for the occurrence of fracture in a vehicle body structure subjected to crash loading. A large number of virtual imperfection lines at different orientation angles have to be analysed simultaneously in order to find the critical imperfection causing necking under arbitrary loading. This, and the continuous computation of a “distance to necking” quantity, representing a crucial output quantity for the simulation engineer, makes the model computationally expensive and limits industrial use in full-scale vehicle crash simulations.
                  In this work, an extended MK model is used for creating a virtual test data base under proportional and non-proportional loading for training of a computationally more efficient simple feed-forward neural network (NN). Both models are implemented in a User Material routine of an explicit crash code, where the predictions of the NN are in good agreement with the predictions of the MK reference model, however at a significantly reduced computational cost. Besides a pure numerical validation study, an experimental validation study has been performed, imposing biaxial tension loading followed by plane strain tension loading until necking using a special punch test apparatus. Whereas MK and NN are in good agreement with the experimental observations, the agreement of classical necking models, applied in conjunction with a linear damage accumulation (forming severity) concept was less accurate.",industry
10.1016/j.cie.2019.07.042,Journal,Computers and Industrial Engineering,scopus,2019-10-01,sciencedirect,Real-time quality monitoring and diagnosis for manufacturing process profiles based on deep belief networks,https://api.elsevier.com/content/abstract/scopus_id/85070093845,"A large number of real-time quality data are collected through various sensors in the manufacturing process. However, most process data are high-dimension, nonlinear and high-correlated, so that it is difficult to model the process profiles, which restricts the application of conventional statistical process control technique. Motivated by the powerful ability of deep belief network (DBN) to extract the essential features of input data, this paper develops a real-time quality monitoring and diagnosis scheme for manufacturing process profiles based on DBN. The profiles collected from a manufacturing process are mapped into quality spectra. A novel DBN recognition model for quality spectra is established in the off-line learning phase, which can be applied to monitor and diagnose the process profiles in the on-line phase. The effectiveness of DBN recognition model for manufacturing process profiles is demonstrated by simulation experiment, and a real injection molding process example is applied to analyze the performance. The results show that the proposed DBN model outperforms alternative methods.",industry
10.1016/j.ibiod.2019.104744,Journal,International Biodeterioration and Biodegradation,scopus,2019-10-01,sciencedirect,Comparative evaluation of Pseudomonas species in single chamber microbial fuel cell with manganese coated cathode for reactive azo dye removal,https://api.elsevier.com/content/abstract/scopus_id/85069842075,"Microbial fuel cell (MFCs), distinguished by different strains of Pseudomonas species; Pseudomonas aeruginosa (MPEM-MFC I) and Pseudomonas fluorescens (MPEM-MFC II), was analyzed. Results have shown that, over a period of 360 h in the presence of 0.5 mM of model dye, MPEM MFC I produced the maximum power density of 2887 ± 13 μW m−2 (RO-16) and 1906 ± 7 μW m−2 (RB-5) compared with MPEM-MFC II with 1896 ± 15 μW m−2 (RO-16) and 1028 ± 9 μW m−2 (RB-5). Decolorization efficiency of MPEM-MFC I was 98 ± 1.2% (RO-16) and 95 ± 2% (RB-5). Total phenazine production in MPEM-MFC I was 12.3 ± 0.5 μg mL−1 higher than that of 8.9 ± 0.05 μg mL−1 (MPEM-MFC II) and its production have positive influence of electron shuttling that brought out high power output. Addition of phenazine externally reduced the dye degradation. Bioadhesion capability of P. aeruginosa on the anode reduced the internal resistance in MFCs. Thus the implementation of MFC is a most promising technology for the complete decolorization of reactive azo dyes and it has potential economic benefits in real-life industrial application.",industry
10.1016/j.future.2019.04.014,Journal,Future Generation Computer Systems,scopus,2019-10-01,sciencedirect,TIDE: Time-relevant deep reinforcement learning for routing optimization,https://api.elsevier.com/content/abstract/scopus_id/85065443852,"Routing optimization has been researched in network design for a long time, and plenty of optimization schemes have been proposed from both academia and industry. However, such schemes are either too complicated in applications or far from the optimal performance. In recent years, with the development of Software-defined Networking (SDN) and Artificial Intelligence (AI), AI-based methods of routing strategy are being considered. In this paper, we propose TIDE, an intelligent network control architecture based on deep reinforcement learning that can dynamically optimize routing strategies in an SDN network without human experience. TIDE is implemented and validated on a real network environment. Experiment result shows that TIDE can adjust the routing strategy dynamically according to the network condition and can improve the overall network transmitting delay by about 9% compared with traditional algorithms.",industry
10.1016/j.isatra.2019.02.035,Journal,ISA Transactions,scopus,2019-10-01,sciencedirect,RBF-ARX model-based fast robust MPC approach to an inverted pendulum,https://api.elsevier.com/content/abstract/scopus_id/85062601384,"In general, the online computation burden of robust model predictive control (RMPC) is very heavy, and the mechanical model of a plant, which is used in RMPC, is hard to obtain precisely in real industry. These issues may largely restrict the applicability of RMPC in real applications. This paper proposes a RBF-ARX (state-dependent Auto-Regressive model with eXogenous input and Radial Basis Function network type coefficients) model-based efficient robust predictive control (RBF-ARX-ERPC) approach to an inverted pendulum system, which is a complete and systematic method for designing robust MPC controller because it integrates the RBF-ARX modeling method and a fast RMPC approach. First, based on the offline identified RBF-ARX model without offset term, two convex polytopic sets are constructed to wrap the globally nonlinear behavior of the system. Then, the optimization problem of implementing a quasi-min–max MPC algorithm including several linear matrix inequalities (LMIs) is formulated, and it is solved offline to synthesize a sequence of explicit control laws that correspond to a sequence of asymptotically stable invariant ellipsoids, of which all the optimization results are stored in a look-up table. During the online real-time control, the controller only needs to carry out a simple state-vector computation and bisection search. The proposed approach is applied to an actual linear one-stage inverted pendulum (LOSIP), which is a fast-responding and nonlinear plant. The real-time control experiments demonstrate the effectiveness of the proposed RBF-ARX model-based efficient RMPC approach.",industry
10.1016/j.enbuild.2019.07.029,Journal,Energy and Buildings,scopus,2019-09-15,sciencedirect,Whole building energy model for HVAC optimal control: A practical framework based on deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85069552761,"Whole building energy model (BEM) is a physics-based modeling method for building energy simulation. It has been widely used in the building industry for code compliance, building design optimization, retrofit analysis, and other uses. Recent research also indicates its strong potential for the control of heating, ventilation and air-conditioning (HVAC) systems. However, its high-order nature and slow computational speed limit its practical application in real-time HVAC optimal control. Therefore, this study proposes a practical control framework (named BEM-DRL) that is based on deep reinforcement learning. The framework is implemented and assessed in a novel radiant heating system in an existing office building as a case study. The complete implementation process is presented in this study, including: building energy modeling for the novel heating system, multi-objective BEM calibration using the Bayesian method and the Genetic Algorithm, deep reinforcement learning training and simulation results evaluation, and control deployment. By analyzing the real-life control deployment data, it is found that BEM-DRL achieves 16.7% heating demand reduction with more than 95% probability compared to the old rule-based control. However, the framework still faces the practical challenges including building energy modeling of novel HVAC systems and multi-objective model calibration. Systematic study is also needed for the design of deep reinforcement learning training to provide a guideline for practitioners.",industry
10.1016/j.jnca.2019.06.003,Journal,Journal of Network and Computer Applications,scopus,2019-09-15,sciencedirect,MAPLE: A Machine Learning Approach for Efficient Placement and Adjustment of Virtual Network Functions,https://api.elsevier.com/content/abstract/scopus_id/85067443855,"As one of the many advantages of cloud computing, Network Function Virtualization (NFV) has revolutionized the network and telecommunication industry through enabling the migration of network functions from expensive dedicated hardware to software-defined components that run in the form of Virtual Network Functions (VNFs). However, with NFV comes numerous challenges related mainly to the complexity of deploying and adjusting VNFs in the physical networks, owing to the huge number of nodes and links in today's datacenters, and the inter-dependency among VNFs forming a certain network service. Several contributions have been made in an attempt to answer these challenges, where most of the existing solutions focus on the static placement of VNFs and overlook the dynamic aspect of the problem, which arises mainly due to the ever-changing resource availability in the cloud datacenters and the continuous mobility of the users. Few attempts have been lately made to incorporate the dynamic aspect to the VNF deployment solutions. The main problem of these approaches lies in their reactive readjustment scheme which determines the placement/migration strategy upon the receipt of a new request or the happening of a certain event, thus resulting in high setup latencies. In this paper, we take advantage of machine learning to reduce the complexity of the placement and readjustment processes through designing a cluster-based proactive solution. The solution consists of (1) an Integer Linear Programming (ILP) model that considers a tradeoff between the minimization of the latency, Service-Level Objective (SLO) violation cost, hardware utilization, and VNF readjustment cost, (2) an optimized k-medoids clustering approach which proactively partitions the substrate network into a set of disjoint on-demand clusters and (3) data-driven cluster-based placement and readjustment algorithms that capitalize on machine learning to intelligently eliminate some cost functions from the optimization problem to boost its feasibility in large-scale networks. Simulation results show that the proposed solution considerably reduces the readjustment time and decrease the hardware utilization compared to the K-means, original k-medoids and migration without clustering approaches.",industry
10.1016/j.seppur.2019.03.091,Journal,Separation and Purification Technology,scopus,2019-09-15,sciencedirect,Real-time monitoring of the moisture content of filter cakes in vacuum filters by a novel soft sensor,https://api.elsevier.com/content/abstract/scopus_id/85065559202,"The moisture content of filter cakes is probably the most important characteristic that should be kept at a desired level in industrial cake filtration applications to maintain consistent product quality and minimize energy consumption. Most of the currently applied methods for contactless real-time monitoring of the moisture content are based for example on x-ray or microwave techniques, and therefore, the equipment for the purpose is highly specialized. This paper introduces a novel soft sensor for filter cake moisture estimation that uses machine learning algorithms and data collected with basic process instrumentation. The method is primarily based on the cooling effect observed in the cake and air, caused by evaporation of liquid from the cake during the dewatering period, and it can be supported by other process data. The specific energy consumption of vacuum filtration and the subsequent thermal drying to zero moisture is also analyzed. The results of pilot-scale experiments with calcite slurry and a horizontal belt vacuum filter show that in order to minimize the specific energy consumption of vacuum filtration, it is crucial to find the right combination of slurry concentration, vacuum level, and mass of filter cake per unit area. The proposed method for estimating the filter cake moisture content is especially suitable for real-time monitoring and control, enabling also considerable reduction in the energy consumption of the overall process. When applying the proposed soft sensor method in a pilot-scale process, the mean absolute error of the estimated moisture content of the filter cake is ∼0.4 percentage points when the temperature of air at the vacuum pump inlet and the vacuum pump air flow rate are included in the input variables.",industry
10.1016/j.ifacol.2019.11.102,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Sustainable operations management for industry 4.0 and its social return,https://api.elsevier.com/content/abstract/scopus_id/85078948022,"In today’s industrial environment, where concepts of smart factories are consolidating their application in companies, it is still necessary to approach management decision making from a perspective that encompasses all aspects of sustainability without losing sight of the social return to which they must contribute. In order to obtain a reliable prediction, of the operation of a Sustainable Manufacturing System (SMS) and its Social Return (SR), this paper develops a methodology and procedures that allow predicting the system performance as a whole. This will allow us to assist management decision making in industries 4.0, supported by multi-criteria methods in knowledge management, simulation, value analysis and operational research by means of:
                  a) Study the economic, social and environmental impacts in the organization and management of the efficient operation of an SMS with the selection of strategies and alternatives in production chains to minimize and / or mitigate environmental and labor risks.
                  b) Encourage of industrial symbiosis or eco-industries networks that create opportunities increasing eco-efficiency and the positive social return of production systems.
                  This proposed methodology will facilitate changes in the structure of production systems in order to implement industry 4.0 paradigms through facilitator technologies such as simulation and virtual reality. This framework will allow Small and Medium Enterprises (SMEs) and other companies to address the decision-making activities that improve the economic-functional efficiency, which will lead to reduce the environmental impact and increase the positive social return of certain production strategies, considering working conditions.
                  The proposed approach went validated, in the area of the Euroregion Galicia North of Portugal, to favour the implementation of the decision-making through the Industry 4.0 Technologies.",industry
10.1016/j.ifacol.2019.11.172,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Machine learning framework for predictive maintenance in milling,https://api.elsevier.com/content/abstract/scopus_id/85078904429,"In the Industry 4.0 era, artificial intelligence is transforming the manufacturing industry. With the advent of Internet of Things (IoT) and machine learning methods, manufacturing systems are able to monitor physical processes and make smart decisions through realtime communication and cooperation with humans, machines, sensors, and so forth. Artificial intelligence enables manufacturers to reduce equipment downtime, spot production defects, improve the supply chain, and shorten design times by using machine learning technologies which learn from experiences. One of the last application of these technologies is the development of Predictive Maintenance systems. Predictive maintenance combines Industrial IoT technologies with machine learning to forecast the exact time in which manufacturing equipment will need maintenance, allowing problems to be solved and adaptive decisions to be made in a timely fashion. This study will discuss the implementation of a milling Cutting-tool Predictive Maintenance solution (including Wear Monitoring), applied to a real milling data set as validation of the framework. More generally, this work provides a basic framework for creating a tool to monitor the wear level, preventing the breakdown, of a generic manufacturing tool, in order to improve human-machine interaction and optimize the production process.",industry
10.1016/j.ifacol.2019.11.385,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Towards a data-driven predictive-reactive production scheduling approach based on inventory availability,https://api.elsevier.com/content/abstract/scopus_id/85078884096,"To survive in a competitive business environment, manufacturing systems require the proper deployment of advanced technologies coming from Industry 4.0. These technologies allow access to quasi-real-time data that provide a continuously updated picture of the production system, including the state of available inventory. Data-driven predictive-reactive production scheduling has the potential to support the anticipation and prompt reaction to overcome different kinds of disruptions that occur in production execution nowadays. This research paper aims to propose a conceptual model for a data-driven predictive-reactive production scheduling approach combining machine learning and simulation-based optimization, considering current inventory of raw material, work in process and final products inventory to characterize a job-shop production execution state. The approach supports decision-making in dynamic situations related to inventory availability that can affect production schedules.",industry
10.1016/j.ifacol.2019.11.465,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,"Integration of automatic generated simulation models, machine control projects and management tools to support whole life cycle of industrial digital twins",https://api.elsevier.com/content/abstract/scopus_id/85078871061,"The paper presents a framework of automatic generation of industrial digital twins. These digital twins will be suitable to support preliminary design phases of systems development, but also to support next phases of detailed designs implementation and systems running phases. These digital twin allow, from the preliminary designing phase, to generate a complete simulation of the target industrial system. But, at the same time, and without the need to develop and add any subsequent code, they should be a valuable support for the phases and tasks of exploitation: maintenance, machine or system learning, etc. The problem is that the requirements for first development phases are much more generic than those for later phases. For this reason, instead of incorporating specificities in the simulation system, the framework takes advantage of the applications which are being developed for the implementation of the real system. In these applications (the control program and the decisions and the high level management system), the specificities have had to be taken into account. The system has been specialized in industrial transportation and warehouse systems which, although have a finite number or building objects, they have an infinite set of final configurations, very different one from each other. The paper presents an evaluation of current simulation platforms suitable to be used as part of the framework, and the digital twin industrial system generation framework itself. An example of application is as well presented.",industry
10.1016/j.jngse.2019.102933,Journal,Journal of Natural Gas Science and Engineering,scopus,2019-09-01,sciencedirect,Machine learning for surveillance of fluid leakage from reservoir using only injection rates and bottomhole pressures,https://api.elsevier.com/content/abstract/scopus_id/85068973220,"Carbon-neutral economies would require preventing the release of industrial-scale CO2 into the atmosphere by injecting into geologic formations. Large-scale injection of CO2 into deep reservoirs carries a potential for its undesired leakage into above zones, which can act as an obstacle to its large-scale implementation. Current methods for surveillance of CO2 leaks are costly and not very robust, especially the methods that simulate expected pressure behavior based on an assumed reservoir model.
                  This study proposes a machine learning method for surveillance of fluid leakage using deconvolution response function (a non-linear function of time varying bottomhole pressure and injection rates) from injection and monitoring wells as a measure of leakage that is simulated via multivariate linear regression of all the wells present in the reservoir. Leakage is detected by comparing “expected” (baseline without leaks) deconvolution response of all monitoring wells with their “observed” deconvolution response. Three key advantages of the proposed method are that it i) uses only injection rates and bottomhole pressure data (with no reservoir or geological model), ii) is independent of physical process parameterization uncertainties, and iii) applicable to both conventional and unconventional (e.g. fractured tight formations) reservoirs with any fluid (e.g. compressible, incompressible). The proposed method is first trained to learn well history with no leakage, followed by its validation after which it can be used to detect leakage by tracking a meaningful deviation error (at least twenty times the error of no leakage base scenario over same time period) between expected well response and observed well response at all monitoring wells. The well history required for the proposed method comes directly from measurements made at wells in a real field, but in absence of field data the proposed method is illustrated through well history simulated by reservoir simulations; no such numerical simulations are required for application of this method in a real world scenario with well measurements.",industry
10.1016/j.compind.2019.04.016,Journal,Computers in Industry,scopus,2019-09-01,sciencedirect,A comparison of fog and cloud computing cyber-physical interfaces for Industry 4.0 real-time embedded machine learning engineering applications,https://api.elsevier.com/content/abstract/scopus_id/85065718296,"Industrial cyber-physical systems are the primary enabling technology for Industry 4.0, which combine legacy industrial and control engineering, with emerging technology paradigms (e.g. big data, internet-of-things, artificial intelligence, and machine learning), to derive self-aware and self-configuring factories capable of delivering major production innovations. However, the technologies and architectures needed to connect and extend physical factory operations to the cyber world have not been fully resolved. Although cloud computing and service-oriented architectures demonstrate strong adoption, such implementations are commonly produced using information technology perspectives, which can overlook engineering, control and Industry 4.0 design concerns relating to real-time performance, reliability or resilience. Hence, this research compares the latency and reliability performance of cyber-physical interfaces implemented using traditional cloud computing (i.e. centralised), and emerging fog computing (i.e. decentralised) paradigms, to deliver real-time embedded machine learning engineering applications for Industry 4.0. The findings highlight that despite the cloud’s highly scalable processing capacity, the fog’s decentralised, localised and autonomous topology may provide greater consistency, reliability, privacy and security for Industry 4.0 engineering applications, with the difference in observed maximum latency ranging from 67.7%–99.4%. In addition, communication failures rates highlighted differences in both consistency and reliability, with the fog interface successfully responding to 900,000 communication requests (i.e. 0% failure rate), and the cloud interface recording failure rates of 0.11%, 1.42%, and 6.6% under varying levels of stress.",industry
10.1016/j.fuel.2019.02.122,Journal,Fuel,scopus,2019-09-01,sciencedirect,An experimental investigation of nanoemulsion enhanced oil recovery: Use of unconsolidated porous systems,https://api.elsevier.com/content/abstract/scopus_id/85064655092,"Utilization of nanoparticles in oil and gas industry has attracted considerable attention of engineers and researchers. In this article, the feasibility of nanoemulsion flooding is investigated as a method for Enhanced Oil Recovery (EOR) through coreflooding experiments, using a packed bed and real reservoir fluids. Nine different mixtures of the solvent, surfactant, and nanoparticles in the form of a nanoemulsion phase are generated and used to recover the oil in the context of an EOR process. Various tests are conducted to determine the properties of porous medium and fluids. To study the production performance of this EOR technique, pressure drop across the packed bed are measured, along with the volumetric measurements of the produced fluids. A baseline injection scheme using seawater is also performed. All the nanoemulsion fluids are synthesized using the same base seawater. The Taguchi experimental design approach is employed in this research to design the experiments. The effects of nanoparticles concentration, along with those of surfactant and solvent components of the injection fluid on the oil recovery at the laboratory scale are investigated using the Analysis of Variance (ANOVA) method. Comparing the performance of waterflooding (WF) and nanoemulsion flooding, enhancement in the Recovery Factor (RF) by using emulsions is between 40–107%. Both the pressure and pressure fluctuations are surprisingly higher in the case of WF in comparison to the emulsion flooding. It is also found that under optimal concentration conditions (0.01 g of nanoparticles, 0.015 mL of surfactant, and 1 mL of solvent per one liter of brine), a recovery factor of up to 60% is achieved.",industry
10.1016/j.ejor.2019.02.051,Journal,European Journal of Operational Research,scopus,2019-09-01,sciencedirect,Appointment scheduling with multiple providers and stochastic service times,https://api.elsevier.com/content/abstract/scopus_id/85063228230,"In many appointment scheduling systems with multiple providers, customers are assigned appointment times but they are not assigned a specific provider in advance – that is, customers can be seen by any available provider. This type of system is common in a variety of service sectors, such as healthcare, banking, and legal counseling. The majority of the existing literature assumes constant service times or does not consider customer no-shows, which are unrealistic assumptions in many situations. In this paper, we overcome this shortcoming by developing an appointment scheduling model that considers stochastic service times along with customer no-shows for multiple-provider systems with identical providers. The objective is to minimize the weighted sum of customers’ waiting time, and providers’ idle time and overtime. We model this problem as a time-inhomogeneous Discrete-Time Markov Chain process. We use analytical results to reduce the space of optimal schedule candidates, and we employ machine learning techniques to detect patterns among optimal or near-optimal schedules. We then develop an effective heuristic method which provides schedules that perform better than the ones generated by existing models. We test our heuristic both on simulated data and a real-world application. As the real-world application, we collaborate with a local counseling center to implement the schedules suggested by our method. Results from this field experiment reveal an average schedule cost reduction of 16% per day, with a maximum reduction of 40% per day.",industry
10.1016/j.eswa.2019.03.011,Journal,Expert Systems with Applications,scopus,2019-08-15,sciencedirect,Constraint learning based gradient boosting trees,https://api.elsevier.com/content/abstract/scopus_id/85063576343,"Predictive regression models aim to find the most accurate solution to a given problem, often without any constraints related to the model’s predicted values. Such constraints have been used in prior research where they have been applied to a subpopulation within the training dataset which is of greater interest and importance. In this research we introduce a new setting of regression problems, in which each instance can be assigned a different constraint, defined based on the value of the target (predicted) attribute. The new use of constraints is taken into account and incorporated into the learning process, and is also considered when evaluating the induced model. We propose two algorithms which are modifications to the regression boosting method. There are two advantages of the proposed algorithms: they are not dependent on the base learner used during the learning process, and they can be adopted by any boosting technique. We implemented the algorithms by modifying the gradient boosting trees (GBT) model, and we also introduced two measures for evaluating the models that were trained to solve the constraint problems. We compared the proposed algorithms to three baseline algorithms using four real-life datasets. Due to the algorithms’ focus on satisfying the constraints, in most cases the results showed significant improvement in the constraint-related measures, with just a minimal effect on the general prediction error. The main impact of the proposed approach is in its ability to derive a model with a higher level of assurance for specific cases of interest (i.e., the constrained cases). This is extremely important and has great significance in various use cases and expert and intelligent systems, particularly critical systems, such as critical healthcare systems (e.g., when predicting blood pressure or blood sugar level), safety systems (e.g., when aiming to estimate the distance of cars or airplanes from other objects), or critical industrial systems (e.g., require to estimate their usability along time). In each of these cases, there is a subpopulation of all instances that is of greater interest to the expert or system, and the sensitivity of the model’s error changes according to the real value of the predicted feature. For example, for a subpopulation of patients (e.g., patients under the age of eight, or patients known to be at risk), physicians often require a sensitive model that accurately predicts blood pressure values.",industry
10.1016/j.mfglet.2019.08.003,Journal,Manufacturing Letters,scopus,2019-08-01,sciencedirect,A self-aware and active-guiding training &amp; assistant system for worker-centered intelligent manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85070738030,"Training and on-site assistance is critical to help workers master required skills, improve worker productivity, and guarantee the product quality. Traditional training methods lack worker-centered considerations that are particularly in need when workers are facing ever-changing demands. In this study, we propose a worker-centered training & assistant system for intelligent manufacturing, which is featured with self-awareness and active-guidance. Multi-modal sensing techniques are applied to perceive each individual worker and a deep learning approach is developed to understand the worker’s behavior and intention. Moreover, an object detection algorithm is implemented to identify the parts/tools the worker is interacting with. Then the worker’s current state is inferred and used for quantifying and assessing the worker performance, from which the worker’s potential guidance demands are analyzed. Furthermore, onsite guidance with multi-modal augmented reality is provided actively and continuously during the operational process. Two case studies are used to demonstrate the feasibility and great potential of our proposed approach and system for applying to the manufacturing industry for frontline workers.",industry
10.1016/j.compind.2019.04.010,Journal,Computers in Industry,scopus,2019-08-01,sciencedirect,Managing workflow of customer requirements using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85065732680,"Customer requirements – product specifications issued by the customer – organize the dialog between suppliers and customers and, hence, affect the dynamics of supply networks. These large and complex documents are frequently updated over time, while changes are seldom marked by the customers who issue the requirements. The lack of structure and defined responsibilities, thus, demands an expert to manually process the requirements. Here, the possibility to improve the usual workflow with machine learning algorithms is explored.
                  The whole requirements management process has two major bottlenecks, which can be automatized. The first one, detecting changes, can be accomplished via a document comparison tool. The second one, recognizing the responsibilities and assigning them to the right department, can be solved with standard machine learning algorithms. Here, such algorithms are applied to a dataset obtained from a global automotive industry supplier.
                  The proposed method improves the requirements management process by reducing an expert’s workload and thus decreasing the time for processing one document was reduced from 2 weeks to 1 h. Moreover, the method gives a high accuracy of department assignment and can self-improve once implemented into a requirements management system.
                  Although the machine learning methods are very popular nowadays, they are seldom used to improve business processes in real companies, especially in the case of processes that did not require digitalization in the past. Here we show, how such methods can solve some of the management problems and improve their workflow.",industry
10.1016/j.compind.2019.05.001,Journal,Computers in Industry,scopus,2019-08-01,sciencedirect,Industrial robot control and operator training using virtual reality interfaces,https://api.elsevier.com/content/abstract/scopus_id/85065132267,"Nowadays, we are involved in the fourth industrial revolution, commonly referred to as “Industry 4.0,” where cyber-physical systems and intelligent automation, including robotics, are the keys. Traditionally, the use of robots has been limited by safety and, in addition, some manufacturing tasks are too complex to be fully automated. Thus, human-robot collaborative applications, where robots are not isolated, are necessary in order to increase the productivity ensuring the safety of the operators with new perception systems for the robot and new interaction interfaces for the human. Moreover, virtual reality has been extended to the industry in the last years, but most of its applications are not related to robots. In this context, this paper works on the synergies between virtual reality and robotics, presenting the use of commercial gaming technologies to create a totally immersive environment based on virtual reality. This environment includes an interface connected to the robot controller, where the necessary mathematical models have been implemented for the control of the virtual robot. The proposed system can be used for training, simulation, and what is more innovative, for robot controlling in an integrated, non-expensive and unique application. Results show that the immersive experience increments the efficiency of the training and simulation processes, offering a cost-effective solution.",industry
10.1016/j.autcon.2019.04.015,Journal,Automation in Construction,scopus,2019-08-01,sciencedirect,Impact assessment of reinforced learning methods on construction workers' fall risk behavior using virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85064642464,"Given the nature of construction activities, construction workers usually work in a collaborative way. Thus, interpersonal influences among workers play a crucial role in forming and affecting construction workers' safety behaviors. The social learning literature indicates that interpersonal learning occurs in two opposing ways – positive reinforcement by demonstrating preferred behaviors, and negative reinforcement by demonstrating negative consequences of inappropriate behaviors. Amid theoretical disagreements in the social learning literature, it remains unclear in the construction safety literature how the two reinforced learning methods affect construction workers in safety training. To fill the gap, a human-subject experiment (n = 126) was conducted to investigate people's social learning behaviors in a hazardous construction situation – walking between two high-rise buildings. The experiment utilizes a multi-user Virtual Reality (VR) system with a motion tracking feature. Participants were randomly assigned to one of three groups: control group (no instruction was given), not-falling group (participants observed an avatar demonstrating appropriate walking behaviors), and falling group (participants watched an avatar quickly walking across a plank and falling off). Indicators, including walking time on the plank, walking speed, and gaze movement, were recorded and analyzed to quantify the effects of the two reinforced learning methods. The results indicate that demonstrating information with positive consequences (not-falling group) encourages people to follow the demonstration and maintain normal walking in a hazardous situation. Showing information with negative consequences (falling group) induced participants to walk faster and more irregularly, which further led to more mistakes and unsafe behaviors. This study demonstrates the effectiveness of using VR in safety studies and provides recommendations for better safety training programs.",industry
10.1016/j.future.2019.03.026,Journal,Future Generation Computer Systems,scopus,2019-08-01,sciencedirect,Pairwise comparison learning based bearing health quantitative modeling and its application in service life prediction,https://api.elsevier.com/content/abstract/scopus_id/85063195689,"Cognitive computing is expected to meet the challenges posed by the avalanche problem of data being produced by experimental instruments and sensors in academia and industry. How to systematically, purposefully and reasonably interact with human beings and make-decision accordingly is one of the key factors for exerting the potential of cognitive computing and providing services for human beings. As one of the crucial supporting technologies for industrial equipment health management, bearing health analysis has increasingly become an important research field that is promising to improve the reliability and efficiency of modern industrial systems. One of the main challenges in condition-based maintenance and management of bearing is the health quantitative modeling and assessment. Therefore, a learning-based health modeling method, on the basis of newly defined multidimensional frequency-domain health feature, is proposed to realize quantitative assessment of bearing health state. First, a multilayer neural network with a special structure is designed. Then, a novel algorithm, namely PAirwiSe CompArison Learning (PASCAL) is proposed for network parameters learning. In addition, experiments are designed and carried out on a real industrial bearing testing dataset to verify the feasibility and efficiency of the proposed health modeling method. Experimental results are compared with those of two others recent research works, and the performance is measured with a percentage error metric.",industry
10.1016/j.artint.2018.12.008,Journal,Artificial Intelligence,scopus,2019-08-01,sciencedirect,Ridesharing car detection by transfer learning,https://api.elsevier.com/content/abstract/scopus_id/85061523747,"Ridesharing platforms like Uber and Didi are getting more and more popular around the world. However, unauthorized ridesharing activities taking advantages of the sharing economy can greatly impair the healthy development of this emerging industry. As the first step to regulate on-demand ride services and eliminate black market, we design a method to detect ridesharing cars from a pool of cars based on their trajectories. Since licensed ridesharing car traces are not openly available and may be completely missing in some cities due to legal issues, we turn to transferring knowledge from public transport open data, i.e., taxis and buses, to ridesharing detection among ordinary vehicles. We propose a novel two-stage transfer learning framework, called CoTrans. In Stage 1, we take taxi and bus data as input to learn a random forest (RF) classifier using trajectory features shared by taxis/buses and ridesharing/other cars. Then, we use the RF to label all the candidate cars. In Stage 2, leveraging the subset of high confident labels from the previous stage as input, we further learn a convolutional neural network (CNN) classifier for ridesharing detection, and iteratively refine the RF and CNN, as well as the feature set, via a co-training process. Finally, we use the resulting ensemble of the RF and CNN to identify the ridesharing cars in the candidate pool. Experiments on real car, taxi and bus traces show that CoTrans, with no need of a pre-labeled ridesharing dataset, can outperform state-of-the-art transfer learning methods with an accuracy comparable to human labeling.",industry
10.1016/j.comnet.2019.02.007,Journal,Computer Networks,scopus,2019-07-20,sciencedirect,An industrial missing values processing method based on generating model,https://api.elsevier.com/content/abstract/scopus_id/85065085342,"The issue of missing values (MVs) has been found widely in real-world datasets and obstructed the use of many statistical or machine learning algorithms for data analytics due to their incompetence in processing incomplete datasets. Most of the current MVs filling methods are applied to the datasets with certain specific types or low missing rate. This paper proposes a method of missing values processing based on the combination of denoising autoencoder (DAE) and generative adversarial networks (GAN), aiming at the missing completely at random (MCAR) datasets with high missing rate and noise interference in industrial scenes. We execute the training process on a discrete dataset with missing values, in order to ensure the generated dataset is completely similar to the feature distribution of the original dataset. We conduct our experiments for different dimensional datasets to prove the feasibility and efficiency of this method, including three public authority datasets and an industrial production monitoring dataset. The results compared with traditional missing values imputation methods have shown when the missing rate is higher than 30%, our method performs better in robustness and accuracy.",industry
10.1016/j.ymssp.2019.03.023,Journal,Mechanical Systems and Signal Processing,scopus,2019-07-15,sciencedirect,Relevance vector machine for tool wear prediction,https://api.elsevier.com/content/abstract/scopus_id/85063349356,"In order to realize real-time and accurate monitoring of the tool wear in machining process, this paper presents a tool wear predictive model based on the integrated radial basis function based kernel principal component analysis (KPCA_IRBF) and relevance vector machine (RVM). The traditional methods such as partial least squares regression (PLS), artificial neural network (ANN) and support vector machine (SVM) can only provide predicted values which have no probabilistic significance. As a sparse probabilistic model, RVM can provide both the predicted value and the corresponding confidence interval (CI). However, the existence of process noises and redundancy will seriously affect the prediction accuracy and the stability of CI. As a new dimension-increment technique, KPCA_IRBF helps to weaken the negative effects of process noises and redundancy by increasing the dimensionality of monitoring features. The fused features obtained by KPCA_IRBF are more sensitive to the change of tool wear. Two different cutting experiments are carried out to verify the effectiveness of KPCA_IRBF in improving the prediction accuracy and ameliorating the CI of RVM. The experimental results show that KPCA_IRBF can reduce the root mean square error (RMSE) of RVM by more than 30% and compress the average width of CI by more than 90%. To further show the advantages of RVM, the traditional methods such as PLS, ANN and SVM are also utilized to realize tool wear prediction. This paper lays the foundation for the application of RVM to industrial field.",industry
10.1016/j.eswa.2019.02.012,Journal,Expert Systems with Applications,scopus,2019-07-15,sciencedirect,RuleCOSI: Combination and simplification of production rules from boosted decision trees for imbalanced classification,https://api.elsevier.com/content/abstract/scopus_id/85061729685,"In the field of machine learning, the problem of imbalanced classification arises when the class percentage on the data is unevenly distributed. Different strategies using boosting ensemble algorithms have shown improved results over the imbalanced classification problem by combining weak learners to produce a single strong learner. In particular, decision trees are often used as base learners in ensemble learning for classification or regression. However, boosting ensemble algorithms sometimes generate a large number of decision trees that could grow too large to be understandable and interpretable. Additionally, the use of weights adds more complexity to the final result. For this reason, in this paper, we present RuleCOSI, a novel method for combining and simplifying the output of an ensemble of binary decision trees into a single set of production rules. The proposed method takes into account the weight of each decision tree and using a combination matrix generates a single set of simplified production rules with performance comparable to that of the original boosting ensemble. In order to measure the performance and prove the applicability of the proposed method, we carried out an empirical validation using three different boosting algorithms over several well-known machine learning datasets as well as real-life data collected from a manufacturing company. The results of the algorithm are acceptable in most of the experiments reducing the complexity of the boosting ensemble output while maintaining a similar performance.",industry
10.1016/j.jmapro.2019.05.013,Journal,Journal of Manufacturing Processes,scopus,2019-07-01,sciencedirect,Real-time weld geometry prediction based on multi-information using neural network optimized by PCA and GA during thin-plate laser welding,https://api.elsevier.com/content/abstract/scopus_id/85066236249,"Real-time monitoring of the welding quality is quite important during the process of industrial laser manufacturing. In this paper, a multi-information fused neural network, combining welding parameters and morphological features of the molten pool, was proposed to predict geometric features of the weld seam. Firstly, a modified optical fiber laser coaxial monitoring platform was set up to acquire clear images of the molten pool. Then, several morphological characteristics of the molten pool were extracted. By using principal component analysis (PCA) to reduce the redundancy of these features, the welding speed, the laser power and the two PCA components acted on as the four input neurons, while the two output neurons consisted of the weld waist width (WW) and the weld back width (BW) representing weld seam quality. Before training, the genetic algorithm (GA) was adopted to optimize the initialized weights and bias of the neural network due to its globally search ability. The experiment results showed that our proposed model can effectively and steadily predict the geometric features of the weld seam with the mean absolute percentage error (MAPE) less than 1% and the mean square error (MSE) less than 10−3. Time analysis showed that the whole process time of our system containing feature extraction and neural network was less than 90 ms which can meet the time requirements of large-scale real-time thin-plate laser welding application. Our system lays a foundation on the real-time quality monitoring in the process of laser welding thin-plate butt joint.",industry
10.1016/j.psep.2019.05.016,Journal,Process Safety and Environmental Protection,scopus,2019-07-01,sciencedirect,An intelligent fire detection approach through cameras based on computer vision methods,https://api.elsevier.com/content/abstract/scopus_id/85065893982,"Fire that is one of the most serious accidents in petroleum and chemical factories, may lead to considerable production losses, equipment damages and casualties. Traditional fire detection was done by operators through video cameras in petroleum and chemical facilities. However, it is an unrealistic job for the operator in a large chemical facility to find out the fire in time because there may be hundreds of video cameras installed and the operator may have multiple tasks during his/her shift. With the rapid development of computer vision, intelligent fire detection has received extensive attention from academia and industry. In this paper, we present a novel intelligent fire detection approach through video cameras for preventing fire hazards from going out of control in chemical factories and other high-fire-risk industries. The approach includes three steps: motion detection, fire detection and region classification. At first, moving objects are detected through cameras by a background subtraction method. Then the frame with moving objects is determined by a fire detection model which can output fire regions and their locations. Since false fire regions (some objects similar with fire) may be generated, a region classification model is used to identify whether it is a fire region or not. Once fire appears in any camera, the approach can detect it and output the coordinates of the fire region. Simultaneously, instant messages will be immediately sent to safety supervisors as a fire alarm. The approach can meet the needs of real-time fire detection on the precision and the speed. Its industrial deployment will help detect fire at the very early stage, facilitate the emergency management and therefore significantly contribute to loss prevention.",industry
10.1016/j.cie.2019.04.054,Journal,Computers and Industrial Engineering,scopus,2019-07-01,sciencedirect,Agent-based modelling and heuristic approach for solving complex OEM flow-shop productions under customer disruptions,https://api.elsevier.com/content/abstract/scopus_id/85065083945,"The application of the agent-based simulation approach in the flow-shop production environment has recently gained popularity among researchers. The concept of agent and agent functions can help to automate a variety of difficult tasks and assist decision-making in flow-shop production. This is especially so in the large-scale Original Equipment Manufacturing (OEM) industry, which is associated with many uncertainties. Among these are uncertainties in customer demand requirements that create disruptions that impact production planning and scheduling, hence, making it difficult to satisfy demand in due time, in the right order delivery sequence, and in the right item quantities. It is however important to devise means of adapting to these inevitable disruptive problems by accommodating them while minimising the impact on production performance and customer satisfaction.
                  In this paper, an innovative embedded agent-based Production Disruption Inventory-Replenishment (PDIR) framework, which includes a novel adaptive heuristic algorithm and inventory replenishment strategy which is proposed to tackle the disruption problems. The capabilities and functionalities of agents are utilised to simulate the flow-shop production environment and aid learning and decision making. In practice, the proposed approach is implemented through a set of experiments conducted as a case study of an automobile parts facility for a real-life large-scale OEM. The results are presented in term of Key Performance Indicators (KPIs), such as the number of late/unsatisfied orders, to determine the effectiveness of the proposed approach. The results reveal a minimum number of late/unsatisfied orders, when compared with other approaches.",industry
10.1016/j.robot.2019.04.002,Journal,Robotics and Autonomous Systems,scopus,2019-07-01,sciencedirect,A robust and efficient framework for fast cylinder detection,https://api.elsevier.com/content/abstract/scopus_id/85064242644,"In this work, a complete solution is provided for detecting and identifying cylindrical shapes, which are commonly found in household and industrial environments, using consumer-grade RGB-D cameras. Most standard approaches to detect and identify cylinders are not robust to outliers (e.g. points on other objects in the scene), which limits their applicability in realistic scenes. In addition, these methods fail to benefit from environmental constraints, e.g. the fact that cylinders often lie or stand on flat surfaces. To tackle the aforementioned limitations, we introduce three main novelties: (i) a point cloud soft voting scheme with curvature information that reduces the influence of outliers and noise, (ii) a selective sampling of the orientation space that favorsorientations known a priori, and (iii) a deep-learning based classifier to filter out objects with non-cylindrical appearance in the 2D images, thus further improving robustness to outliers.
                  A set of experiments with synthetically generated data are used to assess the robustness of our fitting method to different levels of outliers and noise. The results demonstrate that incorporating the principal curvature direction within the orientation voting process allows for large improvements on cylinders parameters estimation. Furthermore, we demonstrate that combining the 2D deep-learning cylinder classifier with the 3D orientation voting scheme allows for large speed-up and accuracy improvements on cylinder identification. The qualitative and quantitative results with real data acquired from a consumer RGB-D camera, confirm the advantages of the proposed framework.",industry
10.1016/j.neucom.2019.01.087,Journal,Neurocomputing,scopus,2019-06-14,sciencedirect,Robot skill acquisition in assembly process using deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85063108149,"Uncertain factors in environments restrict the intelligence level of industrial robots. Based on deep reinforcement learning, a skill-acquisition method is used to solve the posed problems of uncertainty in a complex assembly process. Under the frame of the Markov decision process, a quaternion sequence of the assembly process is represented. The reward function uses a trained classification model, which mainly recognizes whether the assembly is successful. The proposed skill-acquisition method is designed to make robots acquire assembly skills. The input of the model is the contact state of the assembly process, and the output is the robot action. The robot can complete the assembly by self-learning with little prior knowledge. To evaluate the performance of the proposed skill-acquisition method, simulations and real-world experiments were performed in a low-voltage apparatus assembly. The assembly success rate increases with the learning time. In the case of a random initial position and orientation, the assembly success rate was greater than 80% with little prior knowledge. The results show that the robot has a capability to complex assembly through skill acquisition.",industry
10.1016/j.est.2019.04.015,Journal,Journal of Energy Storage,scopus,2019-06-01,sciencedirect,Comparison of a physical and a data-driven model of a Packed Bed Regenerator for industrial applications,https://api.elsevier.com/content/abstract/scopus_id/85064907454,"Thermal Energy Storage systems are promising technologies to match intermittent heat supply with demand and improve the energy efficiency of industrial processes. To optimally integrate these energy storage systems in industry, reliable and industrially applicable models are required. This work examines two different modeling approaches for a Sensible Thermal Energy Storage device, namely a Packed Bed Regenerator. A physical 1D-model using finite difference methods and a data-driven grey box model using Recurrent Neural Networks are described. Experimental data from a Packed Bed Regenerator test rig is used to create the data-driven model and to compare the results of both models with real measurements. A quantitative and qualitative comparison of the data-driven and the physical model is conducted. The results of the quantitative investigation show, that both models are able to capture the complex behavior of the Packed Bed Regenerator. With the qualitative analysis, the features of the different models are highlighted and advantages and limitations are discussed. Thus, it provides an orientation in the decision-making process for the choice of an appropriate modeling approach. The findings of this work can support the creation of physical, as well as data-driven models of sensible energy storage systems and strengthen their implementation to industrial processes. The generic grey box modeling approach and the findings of the qualitative comparison of the models can be also applied to other modeling tasks.",industry
10.1016/j.scitotenv.2019.02.213,Journal,Science of the Total Environment,scopus,2019-05-20,sciencedirect,Passive sampling of volatile organic compounds in industrial atmospheres: Uptake rate determinations and application,https://api.elsevier.com/content/abstract/scopus_id/85061829807,"This study describes the implementation of a passive sampling-based method followed by thermal desorption gas-chromatography-mass spectrometry (TD-GC–MS) for the monitoring of volatile organic compounds (VOCs) in industrial atmospheres. However, in order to employ passive sampling as a reliable sampling technique, a specific diffusive uptake rate is required for each compound. Accordingly, the aim of the present study was twofold. First, the experimental diffusive uptake rates of the target VOCs were determined under real industrial air conditions using Carbopack X thermal desorption tubes, and active sampling as reference method. The sampling campaigns carried out between October 2017 and May 2018 provided us of experimental diffusive uptake rates between 0.40 mL min−1 and 0.70 mL min−1 and stable over time (RSD % < 8%) for up to 41 VOCs. Secondly, the uptake rates obtained experimentally were applied for the determination of VOCs concentrations at 16 sampling sites in the North Industrial Complex of Tarragona. The results showed i-pentane, n-pentane and the compounds known as BTEX as the most representative ones. Moreover, some sporadic peaks of 1,3-butadiene, acrylonitrile, ethylbenzene and styrene resulting from certain industrial activities were detected.",industry
10.1016/j.engappai.2019.03.011,Journal,Engineering Applications of Artificial Intelligence,scopus,2019-05-01,sciencedirect,Distributed parallel deep learning of Hierarchical Extreme Learning Machine for multimode quality prediction with big process data,https://api.elsevier.com/content/abstract/scopus_id/85063385858,"In this work, the distributed and parallel Extreme Learning Machine (dp-ELM) and Hierarchical Extreme Learning Machine (dp-HELM) are proposed for multimode process quality prediction with big data. The efficient ELM algorithm is transformed into the distributed and parallel modeling form according to the MapReduce framework. Since the deep learning network structure of HELM is more accurate than the single layer of ELM in feature representation, the dp-HELM is further developed through decomposing the ELM-based Auto-encoders (ELM-AE) of deep hidden layers into a loop of MapReduce jobs. Additionally, the multimode issue is solved through the “divide and rule” strategy. The distributed and parallel K-means (dp-K-means) is utilized to divide the process modes, which are further trained in a synchronous parallel way by dp-ELM and dp-HELM. Finally, the Bayesian model fusion technique is utilized to integrate the local models for online prediction. The proposed algorithms are deployed on a Hadoop MapReduce computing cluster and the feasibility and efficiency are illustrated through building a real industrial quality prediction model with big process data.",industry
10.1016/j.ijheatmasstransfer.2018.12.170,Journal,International Journal of Heat and Mass Transfer,scopus,2019-05-01,sciencedirect,Visualization-based nucleate boiling heat flux quantification using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85059864859,"Processes involving complex phenomena are ubiquitous in nature and industry, many of which are difficult to simulate computationally. Nucleate boiling heat transfer, for instance, has numerous practical applications, while the film boiling is an undesirable operation regime. So far, most correlations and computer simulations to quantify boiling heat transfer rely on direct measurement of thermohydraulic data, such as heater temperature, which is often invasive. Here it is demonstrated that neural network-based models can quantify heat transfer using only direct and indirect visual information of the boiling phenomenon, without any prior knowledge of the governing equations, which enables the non-intrusive measurement of heat flux based on boiling process imaging. It is shown that neural networks can encode bubble morphology and its correlation with heat flux returning errors as low as 7% when compared with precise experimental measurements, a significant improvement over current prediction methods of boiling heat transfer. Furthermore, it is shown that these systems may be implemented in inexpensive, compact computers, such as the Raspberry Pi, to infer heat flux in real time from visualization.",industry
10.1016/j.future.2018.12.009,Journal,Future Generation Computer Systems,scopus,2019-05-01,sciencedirect,Multi-scale Dense Gate Recurrent Unit Networks for bearing remaining useful life prediction,https://api.elsevier.com/content/abstract/scopus_id/85059117198,"Internet of thing (IoT), with the rapid development, is the systematic combination of physical process, information and communication technologies. Industry internet of thing (IIoT), as the extension of IoT in industry, makes the industrial production more intelligent and efficient. Remaining useful life prediction (RUL), as an essential application area of IIoT, plays an increasingly crucial role. In traditional data-based methods, the feature extraction methods depend on the prior knowledge and are separated from the RUL models. Though ensemble learning can be applied to prevent overfitting, the methods about ensemble learning are still separated from the RUL model. To overcome these drawbacks, a novel deep learning network, namely Multi-scale Dense Gate Recurrent Unit Network (MDGRU) is proposed in this paper, which is composed of the feature layers initialized by pre-trained Restricted Boltzmann Machine (RBM) network, multi-scale layers, skip gate recurrent unit layers, dense layers. By adding multi-scale layers and dense layers, the network can capture the sequence features and ensemble different time-scale attention information. Meanwhile it is an end-to-end network combining the feature extraction methods and RUL models only by pre-training the RBM model so it is more convenient for application. Our experiments with real bearings datasets show that proposed MDGRU network is able to achieve higher accuracy compared to other data-driven methods.",industry
10.1016/j.mfglet.2019.05.003,Journal,Manufacturing Letters,scopus,2019-04-01,sciencedirect,A blockchain enabled Cyber-Physical System architecture for Industry 4.0 manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/85066168835,"Cyber-Physical Production Systems (CPPSs) are complex manufacturing systems which aim to integrate and synchronize machine world and manufacturing facility to the cyber computational space. However, having intensive interconnectivity and a computational platform is crucial for real-world implementation of CPPSs. In this paper, the potential impacts of blockchain technology in development and realization of real-world CPPSs are discussed. A unified three-level blockchain architecture is proposed as a guideline for researchers and industries to clearly identify the potentials of blockchain and adapt, develop, and incorporate this technology with their manufacturing developments towards Industry 4.0.",industry
10.1016/j.neucom.2018.12.024,Journal,Neurocomputing,scopus,2019-03-07,sciencedirect,Multimode process monitoring based on robust dictionary learning with application to aluminium electrolysis process,https://api.elsevier.com/content/abstract/scopus_id/85059541395,"In modern process industries, many parameters or states can be acquired with sensors, and these parameters or states often have a close relationship with operation conditions. Unfortunately, the process often operates under different modes, and labels thereof are often unknown. In practice, labeling for sampled data is expensive and time-consuming, so identifying the operation conditions of the industrial process is difficult. In addition, sampled data from the industrial system are always contaminated by outliers or noise. Therefore, a robust process monitoring method for the multimode process is particularly important and challenging. In this paper, a robust dictionary learning method is proposed for processes with multiple unknown modes. Firstly, by taking the sparsity of outliers into account, a robust dictionary learning method is proposed to identify and remove the outliers and noise in the sampled training data. Secondly, an iterative minimization algorithm is designed for solving the dictionary learning optimization program. Thirdly, based on the sparsity of the sparse code, we partition the sparse code into different clusters via spectral clustering method, and then the dictionary is divided into some sub-dictionaries according to the cluster results of sparse code. Lastly, when a new sample is generated, we reconstruct it under different sub-dictionaries, and the smallest dictionary reconstruction error is calculated as a classifier for process monitoring and fault detection. To evaluate the validity and effectiveness of the proposed monitoring approach, we conduct extensive experiments on a numerical simulation, the continuous stirred tank heater (CSTH) process, and an industrial aluminum electrolysis process, in comparison with several state-of-the-art methods. The experimental results demonstrate that the proposed method is able to provide satisfying monitoring results, and it is also robust to outliers in the sampled training data. It is worth mentioning that the proposed method is an unsupervised learning method, therefore, it is more suitable for the process monitoring of real industrial systems.",industry
10.1016/j.compeleceng.2018.03.015,Journal,Computers and Electrical Engineering,scopus,2019-03-01,sciencedirect,BCI cinematics – A pre-release analyser for movies using H <inf>2</inf> O deep learning platform,https://api.elsevier.com/content/abstract/scopus_id/85046107707,"Entertainment industry has seen a phenomenal growth throughout the globe in recent times and movie industry enjoys a crucial role in the above emergence. A movie can capture the attention of a viewer and can trigger cognitive and emotional processes in the brain. In this article we assess the emotional outcome of the viewer while they watch the movie before its actual release that is, during its preview. Traditionally FMRI was used to assess the activity of brain but proved to be non-feasible and costly so we used EEG Sensors to monitor and record the functioning of the brain of movie viewer for further analysis. The collected data through EEG sensor were analysed using deep learning framework. H2O package of deep learning was employed to find high and low of different brain waves mapping to the emotions depicted in the every scene of the movie. Our proposed system named BCI cinematics obtained 85% accuracy and results were validated by obtaining the feedback from the stake holders. The outcome of this work will assist the creators to understand the emotional impact of movie over a normal viewer impartially thus enable them to modify certain scenes or change sequence of scenes and so on. When deployed in real time our system prove to be a cost saver for movie makers.",industry
10.1016/j.future.2018.02.011,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,Collaborative prognostics in Social Asset Networks,https://api.elsevier.com/content/abstract/scopus_id/85042391186,"With the spread of Internet of Things (IoT) technologies, assets have acquired communication, processing and sensing capabilities. In response, the field of Asset Management has moved from fleet-wide failure models to individualised asset prognostics. Individualised models are seldom truly distributed, and often fail to capitalise the processing power of the asset fleet. This leads to hardly scalable machine learning centralised models that often must find a compromise between accuracy and computational power. In order to overcome this, we present a novel theoretical approach to collaborative prognostics within the Social Internet of Things. We introduce the concept of Social Asset Networks, defined as networks of cooperating assets with sensing, communicating and computing capabilities. In the proposed approach, the information obtained from the medium by means of sensors is synthesised into a Health Indicator, which determines the state of the asset. The Health Indicator of each asset evolves according to an equation determined by a triplet of parameters. Assets are given the form of the equation but they ignore their parametric values. To obtain these values, assets use the equation in order to perform a non-linear least squares fit of their Health Indicator data. Using these estimated parameters, they are interconnected to a subset of collaborating assets by means of a similarity metric. We show how by simply interchanging their estimates, networked assets are able to precisely determine their Health Indicator dynamics and reduce maintenance costs. This is done in real time, with no centralised library, and without the need for extensive historical data. We compare Social Asset Networks with the typical self-learning and fleet-wide approaches, and show that Social Asset Networks have a faster convergence and lower cost. This study serves as a conceptual proof for the potential of collaborative prognostics for solving maintenance problems, and can be used to justify the implementation of such a system in a real industrial fleet.",industry
10.1016/j.enbuild.2018.12.034,Journal,Energy and Buildings,scopus,2019-02-15,sciencedirect,"IntelliMaV: A cloud computing measurement and verification 2.0 application for automated, near real-time energy savings quantification and performance deviation detection",https://api.elsevier.com/content/abstract/scopus_id/85059816255,"Energy conservation measures (ECMs) are implemented in all sectors with the objective of improving the efficiency with which energy is consumed. Measurement and verification (M&V) is required to verify the performance of every ECM to ensure its successful implementation and operation. The methodologies implemented to achieve this are currently evolving to a more dynamic state, known as measurement and verification 2.0, through the use of automated and advanced analytics. The primary barrier to the adoption of M&V 2.0 practices are the tools available to practitioners. This paper aims to populate the knowledge gap in the industrial buildings sector by presenting a novel cloud computing-based application, IntelliMaV, that applies advanced machine learning techniques on large datasets to automatically verify the performance of ECMs in near real-time. Additionally, a performance deviation detection system is incorporated, ensuring persistence of savings beyond the typical period of analysis in M&V.
                  IntelliMaV allows M&V practitioners to quantify energy savings with minimum levels of uncertainty by applying powerful analytics to data readily available in industrial facilities. The use of a cloud computing-based architecture reduces the resources required on-site and decreases the time required to train the baseline energy model through the use of parallel processing. The robust nature of the application ensures it is applicable across the broad spectrum of ECMs in the industrial buildings sector. A case study carried out in a large biomedical manufacturing facility demonstrates the ease of use of the application and the benefits realised through its adoption. The energy savings from an ECM were calculated to be 2,353,225 kWh/yr with 25.5% uncertainty at a 90% confidence interval.",industry
10.1016/j.oceaneng.2019.01.003,Journal,Ocean Engineering,scopus,2019-02-01,sciencedirect,Data management for structural integrity assessment of offshore wind turbine support structures: data cleansing and missing data imputation,https://api.elsevier.com/content/abstract/scopus_id/85061324147,"Structural Health Monitoring (SHM) and Condition Monitoring (CM) Systems are currently utilised to collect data from offshore wind turbines (OWTs), to enhance the accurate estimation of their operational performance. However, industry accepted practices for effectively managing the information that these systems provide have not been widely established yet. This paper presents a four-step methodological framework for the effective data management of SHM systems of OWTs and illustrates its applicability in real-time continuous data collected from three operational units, with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures. Firstly, a time-efficient synchronisation method that enables the continuous monitoring of these systems is presented, followed by a novel approach to noise cleansing and the posterior missing data imputation (MDI). By the implementation of these techniques those data-points containing excessive noise are removed from the dataset (Step 2), advanced numerical tools are employed to regenerate missing data (Step 3) and fatigue is estimated for the results of these two methodologies (Step 4). Results show that after cleansing, missing data can be imputed with an average absolute error of 2.1%, while this error is kept within the [+ 15.2%−11.0%] range in 95% of cases. Furthermore, only 0.15% of the imputed data fell outside the noise thresholds. Fatigue is found to be underestimated both, when data cleansing does not take place and when it takes place but MDI does not. This makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses.",industry
10.1016/j.therap.2018.12.002,Journal,Therapie,scopus,2019-02-01,sciencedirect,"Early access to health products in France: Major advances of the French “Conseil stratégique des industries de santé” (CSIS) to be implemented (modalities, regulations, funding)",https://api.elsevier.com/content/abstract/scopus_id/85061149651,"In a context of perpetual evolution of treatments, access to therapeutic innovation is a major challenge for patients and the various players involved in the procedures of access to medicines. The revolutions in genomic and personalized medicine, artificial intelligence and biotechnology will transform the medicine of tomorrow and the organization of our health system. It is therefore fundamental that France prepares for these changes and supports the development of its companies in these new areas. The recent “Conseil stratégique des industries de santé” launched by Matignon makes it possible to propose a regulatory arsenal conducive to the implementation and diffusion of therapeutic innovations. In this workshop, we present a number of proposals, our approach having remained pragmatic with a permanent concern to be effective in the short term for the patients and to simplify the procedures as much as possible. This was achieved thanks to the participation in this workshop of most of the players involved (industrial companies, “Agence nationale de sécurité du médicament et des produits de santé”, “Haute Autorité de santé”, “Institut national du cancer”, “Les entreprises du médicament”, hospitals, “Observatoire du médicament, des dispositifs médicaux et de l’innovation thérapeutique”…). The main proposals tend to favor the implementation of clinical trials on our territory, especially the early phases, a wider access to innovations by favoring early access programs and setting up a process called “autorisation temporaire d’utilisation d’extension” (ATUext) that make it possible to prescribe a medicinal product even if the latter has a marketing authorisation in another indication. In addition, we propose a conditional reimbursement that will be available based on preliminary data but will require re-evaluation based on consolidated data from clinical trials and/or real-life data. Finally, in order to better carry out these assessments, with a view to access or care, we propose the establishment of partnership agreements with health agencies/hospitals in order to encourage the emergence of field experts, in order to prioritize an ascending expertise closer to patients’ needs and to real life.",industry
10.1016/j.compind.2018.11.004,Journal,Computers in Industry,scopus,2019-02-01,sciencedirect,A machine learning case study with limited data for prediction of carbon fiber mechanical properties,https://api.elsevier.com/content/abstract/scopus_id/85058555677,"Predicting success before full scale manufacturing is the cornerstone of every high-tech industry. Many factors should be considered when designing a product. Design of Experiments (DOE) has been a major, conventional method for such purpose. Moreover, nowadays, Machine Learning (ML) provides fast processing, real-time predictions with a continuous quality improvement for complex industrial design processes. ML with big data is known to handle multi-dimensional and multi-variate data in dynamic industrial systems. However, the ability of the ML methods against limited training datasets has been addressed scarcely.
                  In the present study, a Taguchi DOE approach combined with two selected common ML approaches, the Support Vector Regression (SVR) and Artificial Neural Network (ANN), have been assessed against producing a robust prediction tool for mechanical properties of carbon fibers with a limited training dataset. To this end, empirical models based on three rendering parameters of the stabilization reaction process of oxidized Polyacrylonitrile (PAN) fibers (OPF) have been created. These rendering parameters were obtained according to the explanation of whole Fourier transform infrared attenuated total reflectance (FT-IR ATR) spectra. ML revealed a very promising agreement between the trained empirical models and experimental data. Namely, in terms of the fibers Young’s modulus, the results showed that the SVR empirical model with the average error of less than ±2.4% had a better performance than ANN-LMA (Levenberg –Marquardt algorithm) with the average error of less than ±2.7%. However, in terms of the fibers tensile strength, it was concluded that ANN-LMA empirical model with the average error of less than ±3.7% had slightly surpassed the SVR with the average error of less than ±4.1% in this case study.",industry
10.1016/j.measurement.2018.10.043,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2019-02-01,sciencedirect,3D reconstruction of GMAW pool surface using composite sensor technology,https://api.elsevier.com/content/abstract/scopus_id/85055282411,"Weld pool is the most direct signal to reflect welding quality, that means measurement and reconstruction of the pool surface is one of the most urgent task in industrial robotic welding. A lot of researches have been done in this area, but the strong welding arc and the violent oscillation of weld pool affect their effectiveness. To better resolve this problem, a composite vision sensing system was proposed in our previous study, which consists of an active vision part and a passive vision part. The geometric parameters of the weld cross section and the weld pool have been successfully extracted by using this system. Based on the obtained information, the dynamic relationship between the weld speed and the bead geometric parameters is established by multistep predictive model based on neural network. By using the established model and iterative algorithm, the pool tail height is estimated in this paper. A spatial vision calibration is also proposed to calculate the real geometric parameters of the weld pool. Then the 3D surface of the weld pool is also reconstructed by the means of space curved surface fitting. Finally, the verification experiment is also conducted to verify the feasibility of this method.",industry
10.1016/j.cie.2018.08.018,Journal,Computers and Industrial Engineering,scopus,2019-02-01,sciencedirect,Ensemble-based big data analytics of lithofacies for automatic development of petroleum reservoirs,https://api.elsevier.com/content/abstract/scopus_id/85052098750,"Big data-driven ensemble learning is explored in this paper for quantitative geological lithofacies modeling, which is an integral and challenging part of petroleum reservoir development and characterization. Quantitative lithofacies modeling involves detection and recognition of underlying subsurface rock’s lithofacies. It requires real-time data acquisition, handling, storage, conditioning, analysis, and interpretation of raw sensory petroleum logging data. The real-time well-logs data collected from the sensor-based tools suffer from complications such as noise, nonlinearity, imbalance, and high-dimensionality which makes the prediction task more challenging. The existing literature on quantitative lithofacies modeling includes several data-driven techniques ranging from conventional well-logs to artificial intelligence (AI). Recently, multiple classifiers based Ensemble learners have been found to be more robust and reliable paradigms for detection and identification tasks in various machine learning applications, however, these are not well embraced in the petroleum industry. Ensemble methodology combines diverse expert’s opinions to obtain overall ensemble decision which in turn reduces the risk of a wrong decision. Thus, the uncertainties associated with complex reservoir data can be better handled by the use of Ensemble learners than the existing single learner based conventional models. Ensemble-based big data analytics, proposed in the paper, includes development and comparative performance testing of five popular ensemble methods (viz. Bagging, AdaBoost, Rotation forest, Random subspace, and DECORATE) for quantitative lithofacies modeling. Seven state-of-the-art base classifiers were used as members of different Ensemble learners for the analysis of Kansas (U.S.A.) oil-field data. The proposed techniques have been implemented on the widely used WEKA platform. The comparative performance analysis of the proposed techniques, presented in the paper, confirms its supremacy over the existing techniques used for quantitative lithofacies modeling.",industry
10.1016/j.matpr.2020.03.363,Conference Proceeding,Materials Today: Proceedings,scopus,2019-01-01,sciencedirect,Real-time Thermal Error Compensation Strategy for Precision Machine tools,https://api.elsevier.com/content/abstract/scopus_id/85085555603,"Present manufacturing trend is towards producing precision components with better accuracy. Machine errors like geometrical, thermal and process errors affect the component accuracy. Among these errors, thermal error contributes more than 50-60% of the total machining error. This paper mainly focuses on the development of a real-time thermal error compensation module for precision machine tools and talks about effective modeling of thermal errors, development of thermal error compensation model using feed-forward backpropagation neural network and also simplified model using regression analysis technique, algorithm development for real-time compensation and implementation of module onto the open architecture CNC controller. The developed module has been successfully tested on a Diamond Turning Machine (DTM) by machining the precision component and also verified the effectiveness of the module",industry
10.1016/j.promfg.2020.01.033,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Deep learning-based production forecasting in manufacturing: A packaging equipment case study,https://api.elsevier.com/content/abstract/scopus_id/85083533827,"We propose a Deep Learning (DL)-based approach for production performance forecasting in fresh products packaging. On the one hand, this is a very demanding scenario where high throughput is mandatory; on the other, due to strict hygiene requirements, unexpected downtime caused by packaging machines can lead to huge product waste. Thus, our aim is predicting future values of key performance indexes such as Machine Mechanical Efficiency (MME) and Overall Equipment Effectiveness (OEE). We address this problem by leveraging DL-based approaches and historical production performance data related to measurements, warnings and alarms. Different architectures and prediction horizons are analyzed and compared to identify the most robust and effective solutions. We provide experimental results on a real industrial case, showing advantages with respect to current policies implemented by the industrial partner both in terms of forecasting accuracy and maintenance costs. The proposed architecture is shown to be effective on a real case study and it enables the development of predictive services in the area of Predictive Maintenance and Quality Monitoring for packaging equipment providers.",industry
10.1016/j.promfg.2020.01.136,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Transferring human manipulation knowledge to industrial robots using reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85083532554,"Nowadays in the context of Industry 4.0, manufacturing companies are faced by increasing global competition and challenges, which requires them to become more flexible and able to adapt fast to rapid market changes. Advanced robot system is an enabler for achieving greater flexibility and adaptability, however, programming such systems also become increasingly more complex. Thus, new methods for programming robot systems and enabling self-learning capabilities to accommodate the natural variation exhibited in real-world tasks are needed. In this paper, we propose a Reinforcement Learning (RL) enabled robot system, which learns task trajectories from human workers. The presented work demonstrates that with minimal human effort, we can transfer manual manipulation tasks in certain domains to a robot system without the requirement for a complicated hardware system model or tedious and complex programming. Furthermore, the robot is able to build upon the learned concepts from the human expert and improve its performance over time. Initially, Q-learning is applied, which has shown very promising results. Preliminary experiments, from a use case in slaughterhouses, demonstrate the viability of the proposed approach. We conclude that the feasibility and applicability of RL for industrial robots and industrial processes, holds and unseen potential, especially for tasks where natural variation is exhibited in either the product or process.",industry
10.1016/j.promfg.2020.01.031,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,A deep learning approach for anomaly detection with industrial time series data: A refrigerators manufacturing case study,https://api.elsevier.com/content/abstract/scopus_id/85083532061,"In refrigerators production, vacuum creation is fundamental to guarantee the correct manufacturing of the product. Before inserting the refrigerant in the refrigerator cabinet, the vacuum is tested through a Pirani gauge that assesses the pressure within the cabinet. Such readings are used to evaluate the vacuum creation process and to verify if leakings are present. In this work, we employ a Deep Learning-based Anomaly Detection approach to associate an Anomaly Score to each pressure profile; this score can be exploited to optimize actions performed by human operators like more detailed inspections or unit exclusion from the downstream production stages. We propose a native time series-based approach based on Deep Learning and compare it with classic ones based on hand-craft features. The proposed approach is designed to be deployed in a Decision Support System for assisting human operators in the following testing operations, helping them in reducing evaluation bias and attention losses that are inevitable in production line environment. Moreover, costs associated with false positives (normally operating units detected as anomalous) and false negatives (undetected anomalies) are considered here to optimize decision making in a cost-reduction perspective. We also describe promising results obtained on real industrial data spanning on a 5-month period and consisting of thousands of tested household units.",industry
10.1016/j.promfg.2020.01.333,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Prognostic health management of production systems. New proposed approach and experimental evidences,https://api.elsevier.com/content/abstract/scopus_id/85082764769,"Prognostic Health Management (PHM) is a maintenance policy aimed at predicting the occurrence of a failure in components and consequently minimizing unexpected downtimes of complex systems. Recent developments in condition monitoring (CM) techniques and Artificial Intelligence (AI) tools enabled the collection of a huge amount of data in real-time and its transformation into meaningful information that will support the maintenance decision-making process. The emerging Cyber-Physical Systems (CPS) technologies connect distributed physical systems with their virtual representations in the cyber computational world. The PHM assumes a key role in the implementation of CPS in manufacturing contexts, since it allows to keep CPS and its machines in proper conditions. On the other hand, CPS-based PHM provide an efficient solution to maximize availability of machines and production systems. In this paper, evolving and unsupervised approaches for the implementation of PHM at a component level are described, which are able to process streaming data in real-time and with almost-zero prior knowledge about the monitored component. A case study from a real industrial context is presented. Different unsupervised and online anomaly detection methods are combined with evolving clustering models in order to detect anomalous behaviours in streaming vibration data and integrate the so-generated knowledge into supervised and adaptive models; then, the degradation model for each identified fault is built and the resulting RUL prediction model integrated into the online analysis. Supervised methods are applied to the same dataset, in batch mode, to validate the proposed procedure.",industry
10.1016/j.procir.2019.05.017,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,The growing path in search of an industrial design identity,https://api.elsevier.com/content/abstract/scopus_id/85076752868,"Knowing that the education system must be reinvented periodically to face the changes of social and cultural paradigm, was reviewed the pedagogical organization of a set of disciplines of an industrial design course that were in operation for a decade. Thus, in view of the objective of restructuring the disciplinary group of industrial design, a new structure has been developed and implemented that could offer students the opportunity to explore problems and challenges that have real applications, increasing the possibility of acquiring competences effectively needed to practice the profession of designer.
                  This restructuring had as its starting point the concept of Project-based learning, which is designated as student-centered pedagogy that involves a dynamic classroom approach in which it is believed that students acquire a deeper knowledge through active exploration of real-world challenges and problems. Consequently, resulting in a learning process organized into levels with increasing degree of complexity. As well, different assimilations of markets and design scenarios.
                  Starting from the first year of the course, where students are still understanding the context of industrial design and its potentialities. At a time when their techniques, principles and methods are still very raw and basic. They are initiated in a LOW-ID and local industry context, to acquire basic skills. The second year allows embark on an intermediate level called MID-ID, with new skills in international brands approach. In the last year of the course the 3rd level is reached, HIGH-ID, with projects with the national industry.
                  The first year of implementation of this curriculum structure showed good results. Thus, favoring a solid interdisciplinary formation with, skills and competences that allow future designers to intervene creatively and competently in a variety of fields. This process allows to progress to the next academic degree to complete and validate the entire formation of the student.",industry
10.1016/j.procir.2019.03.212,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,Contribution to the development of a Digital Twin based on product lifecycle to support the manufacturing process,https://api.elsevier.com/content/abstract/scopus_id/85076726437,"The current manufacture challenges are closely linked to the aim of digitalizing the product, the process and the means of production. In such aspects, information about the production processes is available in real-time, allowing managers to act on digital models and, through them, apply decisions in real systems. Thus, having a mirror model or a Digital Twin enables real-time absorption, simulation and implementation of manufacturing variations from the real environment, allowing faster detection of physical problems, and faster production response. The Digital Twin is a virtual representation of the physical system, which is equipped with sensors and actuators and feed the digital system, where the monitoring of data and simulation of variations, for instance, take place. From the synchronized interactions of both components, it is possible to deliver the mentioned faster production responses. Brazilian and German universities joined efforts to develop a Digital Twin based on product lifecycle to support the Manufacturing Process to address these challenges. The proposed Digital Twin seeks to integrate the product twin and the twin of its development process. It shall represent the manufacturing process, enabling the monitoring and optimization of the real production process. The Digital Twin itself is addressed as a product inside the production system and, therefore, its development process will follow the product lifecycle perspective, from the conception and planning to its implementation and usage. The Digital Twin will be further improved with the introduction of Artificial Intelligence tools, characterizing a Smart Digital Twin of the Manufacturing Process. Thus, this paper aims to present the concepts of a research project that is being developed in a joint Brazilian-German Cooperative Research.",industry
10.1016/j.ifacol.2019.09.143,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-01-01,sciencedirect,Machine Learning approaches for Anomaly Detection in Multiphase Flow Meters,https://api.elsevier.com/content/abstract/scopus_id/85076262725,"Multiphase Flow Meters (MPFM) are important metering tools in the oil and gas industry. A MPFM provides real-time measurements of gas, oil and water flows of a well without the need to separate the phases, a time-consuming procedure that has been classically adopted in the industry. Evaluating the composition of the flow is fundamental for the well management and productivity prediction; therefore, procedures for measuring quality assessment are of crucial importance. In this work we propose an Anomaly Detection approach to MPFM that is effectively able to hand the complexity and variability associated with MPFM data. The proposed approach is designed for embedded implementation and it exploits unsupervised Anomaly Detection approaches like Cluster Based Local Outlier Factor and Isolation Forest.",industry
10.1016/j.procs.2019.09.198,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Enhancing deep learning with semantics: An application to manufacturing time series analysis,https://api.elsevier.com/content/abstract/scopus_id/85076259705,"Manufacturing enterprises are engaged in implementing new technologies to enhance their manufacturing lines in a smart way. These new technologies give manufacturing enterprises the knowledge, understanding, insight and foresight to improve products, processes and decisions, thereby creating a competitive advantage. In this paper, we explore the use of semantics to enhance deep learning models. We propose an ontology-based LSTM neural network, in which the deep architecture is designed with an ontology to extract high-level cognitive features and stacked LSTM layers for learning temporal dependencies. Our model is applied to a real manufacturing data set with multivariate time series for classification problems. The experiments show that our model can improve performance compared with conventional methods.",industry
10.1016/j.ifacol.2019.08.225,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-01-01,sciencedirect,Curriculum change for graduate-level control engineering education at the Universidad Pontificia Bolivariana,https://api.elsevier.com/content/abstract/scopus_id/85076258553,"This paper addresses the graduate-level control engineering curriculum change performed at the Universidad Pontificia Bolivariana (UPB), Medellin, Colombia. New proposed methodologies include active learning activities using a new multipurpose experimental test bed that was developed with industrial components. The renovated graduate-level control engineering related courses include: Continuous Processes, Discrete Processes, Fuzzy Logic, Neural Networks and Genetic Algorithms, Linear Control, Nonlinear Control, and Optimal Estimation. The new experimental station was developed for teaching, research, and industrial training activities for the School of Engineering at the UPB. In this work, we report the use of the station in an Optimal Estimation course to replace a traditional homework/exams evaluation approach with an applied work that required independent study, the implementation of different observers in a real lab-scale industrial plant, and a paper-style written report. Increasing independent study activities resulted in academic discussions that are valuable for the learning process of the student. The use of the experimental station and the real comparison of estimation algorithms, implemented by using industrial controllers and high-level programming environments, provided the student skills that cannot be acquired by using only simulations in which real implementation restrictions/challenges do not appear. This work represents one of the first approaches for the implementation of the new curriculum model at the UPB for graduate education. The methodology used in the Optimal Estimation class promoted independent learning, critical thinking and writing skills through significant learning activities.",industry
10.1016/j.procs.2019.09.169,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,IAssistMe - Adaptable assistant for persons with eye disabilities,https://api.elsevier.com/content/abstract/scopus_id/85076257910,"Visually challenged people may experience certain difficulties in their daily interaction with technology. That is essentially because the main way to exchange and process information is by written text, images or videos. Since the basic purpose of innovation is to improve people’s lifestyle, in this paper we propose a system that can make technology accessible to a broader group. Our prototype is presented as a mobile application based on vocal interaction, which can help people facing visual disorders consult their personal agenda, create an event, invite other friends to attend it, check the weather in certain areas and many other day-to-day tasks. Regarding the implementation, the project consists of a mobile application that interacts with a cloud based system, which makes it reliable and low in latency due to the resource availability in multiple global regions, provided by the newly emerging platform used in building the infrastructure. The novelty of the system lays in the highly flexible serverless architecture [1] that is open to extension and closed to modification through the set of autonomous cloud processing methods that sustain the base of the functionality. This distributed processing approach guarantees that the user always receives a response from his personal assistant, either by using artificial intelligence context generated phrases, by real-time cloud function processing or by fallback to the training answers.",industry
10.1016/j.procs.2019.09.224,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Hybrid system for information extraction from social media text: Drug abuse case study,https://api.elsevier.com/content/abstract/scopus_id/85076256057,"Social media are becoming widely used in the healthcare field as a patients-caregivers communication tool giving birth to new sources of information rich with the knowledge that may improve this field. Therefore, social media data analysis becomes a real business requirement for healthcare industrials and data scientists.
                  However, regarding their complexity and unstructured character, existing natural language processing tools cannot succeed their exploitation. In the literature, a wide range of approaches appeared based on dictionaries, linguistic patterns and machine learning having their strengths and weaknesses.
                  In this work, we propose a hybrid system combining the above approaches by taking the advantage of each of them to extract structured and salient drug abuse information from health-related tweets. We improve the system accuracy by real time update of the domain dictionary. We collected 1000000 tweets and we conducted different experiments showing the advantage of hybridization on efficient information extraction from social media data.",industry
10.1016/j.procs.2019.09.069,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,An Innovative Technology: Augmented Reality Based Information Systems,https://api.elsevier.com/content/abstract/scopus_id/85076255225,"In our generation the information systems evolve with new technologies: augmented reality (AR), IoT, artificial intelligence, blockchain etc. Anymore they perform information exchange by sensors. It is estimated that the systems will be in a state of extreme interaction and reach 50 billion devices connected in Internet in 2020. We know that everything around us will be in interaction and they will do everything without any need of human interference. For example, when our dishwasher is full, it will start to wash automatically, or when the run out of the gasoline, our car will drive to the nearest station, or even when a burglar is entered to our house, it will automatically be detected and be announced to the police office. In business life, the processes will be automatical in maximum level and this technology will increase productivity and efficiency. Next to mobile technology, it is thought that these new generation information systems (IS) will take the biggest place in our lives. AR also will be integrated to these systems to augment the information in real world. Humanity will augment its habitat in an innovative way thanks to these AR based IS. This paper surveys the current state-of-the-art AR systems related with aerospace & defense, industry, education, medical and gaming sectors. The connection of AR based IS and innovation is explained with a technological insight. In addition to international use cases HAVELSAN’s use cases are also given that are performed from the aspect of applied open innovation strategy. This strategy is addressed specific to the implemented activities of AR based IS.",industry
10.1016/j.procs.2019.09.014,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Websocket to support real time smart home applications,https://api.elsevier.com/content/abstract/scopus_id/85073121141,"As we already know, the IoT (Internet of Thing) system has developed and is used in many fields, such as agriculture, security, industry etc. The IoT system requires real time monitoring and this is one of the problems that exists today. Transfering data from the sensor via the internet network to a monitoring device must be less than 300 ms. One process that can cause non-fulfillment of these requirements is a method for displaying the data on a monitor. There are several methods for delivering data from the sensor to a monitor. This paper has been compared between two methods, namely the polling method and the websocket method. The experiment was conducted to compare these two method. The result obtained that the websocket method was better in presenting real time data compared to the polling method. It can be shown in bandwidth usage and memory usage. In the experiment was found that the average of bandwidth usage is 478KB for polling method, and 91KB for web socket method in web based and the memory consumption of websocket less as much as 16% compared to polling method. In android smartphone the average bandwidth usage is 5.1 KB for web socket method and 15 KB for polling method and the memory consumption of websocket less as much as 22% compared to polling method.",industry
10.1016/j.promfg.2018.12.017,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,AI based injection molding process for consistent product quality,https://api.elsevier.com/content/abstract/scopus_id/85072584818,"In manufacturing processes, Injection Molding is widely used for producing plastic components with large lot size. So, continuous improvements in product quality consistency is crucial to maintaining a competitive edge in the injection molding industry. Various optimization techniques like ANN, GA, Iterative method, and simulation based are being used for optimization of Injection Molding process and obtaining optimal processing conditions. But still due to variation during molding cycles, quality failure occurs. As many constituents like process, Material, machine together yields product quality. This paper is focused on Real time AI based control of process parameters in injection molding cycle. Process parameters and their interrelationship with quality failure has been studied and later supposed to be used to generate algorithm for compensating the deviation of process parameters. Pressure and temperature sensor assisted monitoring system is used to collect data in real time and based on its comparison with the standard values an interrelationship is formed between parameters and plastic material properties. Algorithm generates new process parameter values to compensate the deviation and machine control follows the same. The entire process is supposed to be smart and automatic after being trained with AI and machine learning techniques. Simulation using Moldflow software and real industry collected data has been used for understanding whole molding process establishing relationship between failure and parameters. An automotive product in real industry is chosen for data acquisition, implementation and validation of entire AI based system.",industry
10.1016/j.promfg.2018.12.026,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Hybrid artificial intelligence system for the design of highly-automated production systems,https://api.elsevier.com/content/abstract/scopus_id/85072561400,"The automated design of production systems is a young field of research which has not been widely explored by industry nor research in recent decades. Currently, the effort spent in production system design is increasing significantly in automotive industry due to the number of product variants and product complexity. Intelligent methods can support engineers in repetitive tasks and give them more opportunity to focus on work which requires their core competencies. This paper presents a novel artificial intelligence methodology that automatically generates initial production system configurations based on real industrial scenarios in the automotive field of body-in-white production. The hybrid methodology reacts flexibly against data sets of different content and has been implemented in a software prototype.",industry
10.1016/j.procs.2019.04.090,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Deep neural network method of recognizing the critical situations for transport systems by video images,https://api.elsevier.com/content/abstract/scopus_id/85071926362,"The deep neural network method of recognizing critical situations for transport systems according to video frames from the intelligent vehicles cameras is offered, that is effective in terms of accuracy and high-speed performance. Unlike the known solutions for the objects and normal or critical situations detection and recognition, it uses the classification with the subsequent reinforcement on the basis of several video stream frames and with the automatic annotation algorithm. The adapted architectures of neural networks are offered: the dual network to identify drivers and passengers according to the face image, the network with independent recurrent layers to classify situations according to the video fragment. The scheme of the intellectual distributed city system of transport safety using the cameras and on-board computers united in a single network is offered. Software modules in Python are developed and natural experiments are made. The possibility of the offered algorithms and programs in UGV or in the driver assistant systems implementation is shown with the illustrating examples in real-time.",industry
10.1016/j.promfg.2020.01.288,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Action recognition in manufacturing assembly using multimodal sensor fusion,https://api.elsevier.com/content/abstract/scopus_id/85070765380,"Production innovations are occurring faster than ever. Manufacturing workers thus need to frequently learn new methods and skills. In fast changing, largely uncertain production systems, manufacturers with the ability to comprehend workers’ behavior and assess their operation performance in near real-time will achieve better performance than peers. Action recognition can serve this purpose. Despite that human action recognition has been an active field of study in machine learning, limited work has been done for recognizing worker actions in performing manufacturing tasks that involve complex, intricate operations. Using data captured by one sensor or a single type of sensor to recognize those actions lacks reliability. The limitation can be surpassed by sensor fusion at data, feature, and decision levels. This paper presents a study that developed a multimodal sensor system and used sensor fusion methods to enhance the reliability of action recognition. One step in assembling a Bukito 3D printer, which composed of a sequence of 7 actions, was used to illustrate and assess the proposed method. Two wearable sensors namely Myo-armband captured both Inertial Measurement Unit (IMU) and electromyography (EMG) signals of assembly workers. Microsoft Kinect, a vision based sensor, simultaneously tracked predefined skeleton joints of them. The collected IMU, EMG, and skeleton data were respectively used to train five individual Convolutional Neural Network (CNN) models. Then, various fusion methods were implemented to integrate the prediction results of independent models to yield the final prediction. Reasons for achieving better performance using sensor fusion were identified from this study.",industry
10.1016/j.procir.2019.03.041,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,"Design, implementation and evaluation of reinforcement learning for an adaptive order dispatching in job shop manufacturing systems",https://api.elsevier.com/content/abstract/scopus_id/85068485505,"Modern production systems tend to have smaller batch sizes, a larger product variety and more complex material flow systems. Since a human oftentimes can no longer act in a sufficient manner as a decision maker under these circumstances, the demand for efficient and adaptive control systems is rising. This paper introduces a methodical approach as well as guideline for the design, implementation and evaluation of Reinforcement Learning (RL) algorithms for an adaptive order dispatching. Thereby, it addresses production engineers willing to apply RL. Moreover, a real-world use case shows the successful application of the method and remarkable results supporting real-time decision-making. These findings comprehensively illustrate and extend the knowledge on RL.",industry
10.1016/j.promfg.2019.03.047,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,A Practical Approach of Teaching Digitalization and Safety Strategies in Cyber-Physical Production Systems,https://api.elsevier.com/content/abstract/scopus_id/85065658005,"Digitalization strategies in cyber-physical production systems (CPPS) are one of the key factors of Industry 4.0. The topic not only addresses data preparation, real-time data processing, big data analytics, visualization and machine interface design but also cyber security and safety. Especially, unauthorized access to protected (personal or enterprise) data or unauthorized control of production facilities imply risks when it comes to digitalization. Because of the increased complexity of state-of-the-art technologies, educational institutions need to provide practice-oriented teaching methods in learning factories to help engineers of today understand the impact of those developments.
                  In the light of this fact, this paper presents a practical approach of teaching digitalization strategies in CPPS. Planning, implementing and impacts of digitalization strategies are taught on a use-case with human-robot-collaboration. The objective of the use-case is to realize a real-time obstacle avoidance approach for a collaborative application based on a local positioning system. Here, students not only learn how to model the kinematics of a robot and program a robot but also how to design machine interfaces for real-time data transfer and processing as well as impacts of digitalization on safety and security.
                  The implementation of the use-case is part of the TU Wien teaching portfolio and thus part of its learning factory, where students and apprentices have the possibility to experiment and gain experiences by deliberate error simulations.",industry
10.1016/j.toxrep.2019.05.002,Journal,Toxicology Reports,scopus,2019-01-01,sciencedirect,Effect of untreated pharmaceutical plant effluent on cardiac Na<sup>+</sup>-K<sup>+</sup>- ATPase and Ca<sup>2+</sup>-Mg<sup>2+</sup>-ATPase activities in mice (Mus Musculus),https://api.elsevier.com/content/abstract/scopus_id/85065627449,"Cardiovascular diseases are major causes of non-communicable diseases (NCDs)-related throughout the world. Water pollution has been linked with the high global NCD burden but no report exists on the cardiotoxicity of untreated or poorly treated pharmaceutical effluent, despite its indiscriminate discharge into the aquatic environment in Nigeria, as in many other locations of the world. Thus, this study investigated the cardiotoxic effect of oral exposure to pharmaceutical effluent in mice. Thirty (30) male mice (Mus musculus) were randomly divided into 6 groups. Group A (control) received 0.2 ml distilled water, while groups B-F were treated with 0.2 ml 2.5%, 5.0%, 10.0%, 20.0% and 40% concentrations (v/v, effluent/distilled water) of the effluent respectively, for 28 days. Significant reductions (p<0.05) in heart weight and cardiac weight index were observed in the groups treated with 5%, 10%, 20% and 40% concentrations of the effluent, without significant change in body weight. Similarly, 28 day administration of the effluent showed significant decrease in cardiac Na+-K+-ATPase activity (p<0.05) at concentrations 10% and above, in a concentration dependent manner. However, there was insignificant decrease in cardiac Ca2+-Mg2+-ATPase activity of the exposed mice, when compared with the control group. This study provides novel information on the cardiotoxic effects of oral exposure to untreated pharmaceutical effluent, showing reduced Na+-K+-ATPase activity and decreseased myocardial atrophy. Therefore, drinking water contaminated with pharmaceutical effluent may promote the incidence of cardiovascular diseases. Further studies on the exact mechanistic routes of the induced cardiotoxicity are recommended.",industry
10.1016/j.procir.2019.02.101,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,Autonomous order dispatching in the semiconductor industry using reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85065424368,"Cyber Physical Production Systems (CPPS) provide a huge amount of data. Simultaneously, operational decisions are getting ever more complex due to smaller batch sizes, a larger product variety and complex processes in production systems. Production engineers struggle to utilize the recorded data to optimize production processes effectively because of a rising level of complexity. This paper shows the successful implementation of an autonomous order dispatching system that is based on a Reinforcement Learning (RL) algorithm. The real-world use case in the semiconductor industry is a highly suitable example of a cyber physical and digitized production system.",industry
10.1016/j.cirpj.2018.12.002,Journal,CIRP Journal of Manufacturing Science and Technology,scopus,2019-01-01,sciencedirect,"From factory floor to process models: A data gathering approach to generate, transform, and visualize manufacturing processes",https://api.elsevier.com/content/abstract/scopus_id/85058703955,"The need for tools to help guide decision making is growing within the manufacturing industry. The analysis performed by these tools will help operators and engineers to understand the behaviour of the manufacturing stations better and thereby take data-driven decisions to improve them. The tools use techniques borrowed from fields such as Data Analytics, BigData, Predictive Modelling, and Machine Learning. However, to be able to use these tools efficiently, data from the factory floor is required as input. This data needs to be extracted from two sources, the PLCs, and the robots. In practice, methods to extract usable data from robots are rather scarce. The present work describes an approach to capture data from robots, which can be applied to both legacy and current state-of-the-art manufacturing systems. The described approach is developed using Sequence Planner – a tool for modelling and analyzing production systems – and is currently implemented at an automotive company as a pilot project to visualize and examine the ongoing process. By exploiting the robot code structure, robot actions are converted to event streams that are abstracted into operations. We then demonstrate the applicability of the resulting operations, by visualizing the ongoing process in real-time as Gantt charts, that support the operators performing maintenance. And, the data is also analyzed off-line using process mining techniques to create a general model that describes the underlying behaviour existing in the manufacturing station. Such models are used to derive insights about relationships between different operations, and also between resources.",industry
10.1016/j.impact.2018.12.001,Journal,NanoImpact,scopus,2019-01-01,sciencedirect,SUNDS probabilistic human health risk assessment methodology and its application to organic pigment used in the automotive industry,https://api.elsevier.com/content/abstract/scopus_id/85058641247,"The increasing use of engineered nanomaterials (ENMs) in nano-enabled products (NEPs) has raised societal concerns about their possible health and ecological implications. To ensure a high level of human and environmental protection it is essential to properly estimate the risks of these new materials and to develop adequate risk management strategies. To this end, we propose a quantitative Human Health Risk Assessment (HHRA) methodology, which was developed in the European Seventh Framework research project SUN (Sustainable Nanotechnologies) and implemented in the web-based SUN Decision Support System (SUNDS). One of the major strengths of this probabilistic approach as compared to its deterministic alternatives is its ability to clearly communicate the uncertainties in the estimated risks in order to support better risk communication for more objective decision making by industries and regulators.
                  To demonstrate this methodology, we applied it in a real case study involving a nanoscale organic red pigment used in the automotive industry. Our analysis clearly showed that the main source of uncertainty was the extrapolation from (sub)acute in vivo toxicity data to long-term risk. This extrapolation was necessary due to a lack of (sub)chronic in vivo studies for the investigated nanomaterial. Despite the high uncertainty in the final results due to the conservative assumptions made in the risks assessment, the estimated risks are acceptable for all investigated exposure scenarios along the product lifecycle.",industry
10.1016/j.ijepes.2018.07.022,Journal,International Journal of Electrical Power and Energy Systems,scopus,2019-01-01,sciencedirect,Design and implementation of flexible Numerical Overcurrent Relay on FPGA,https://api.elsevier.com/content/abstract/scopus_id/85050986246,"This paper presents the contemporary design and implementation of an intelligent revelation in the field of the over-current relay to meet the challenges of the modern grid. The unique three-neuron single layered architecture of Artificial Neural Network (ANN) provides flexibility by exploiting its universal function approximation capabilities. The Unique Selling Proposition (USP) of the present development is the simple design of ANN, suitable for low-end, low-cost Field Programmable Gate Array (FPGA) implementation. The nano-scaled internal processing time for three-phase design, with the provision of remotely controlled adaptive relay settings, would definitely an innovative solution for grid connection of renewable energy sources. The proposed design of the universal over-current relay, confirmed by the real-time testing, is a true fusion of electrical power, communication and information technology to meet the global trend of the electrical power industries.",industry
10.1016/j.foodchem.2018.07.072,Journal,Food Chemistry,scopus,2019-01-01,sciencedirect,Patulin removal from apple juice using a novel cysteine-functionalized metal-organic framework adsorbent,https://api.elsevier.com/content/abstract/scopus_id/85049805250,"Patulin (PAT) is one of the most common toxic contaminants of apple juice, which causes severe food safety issues throughout the apple industry. In order to remove PAT efficiently, a metal-organic framework-based adsorbent (UiO-66(NH2)@Au-Cys) was successfully synthesized and used for PAT removal from juice-pH simulation solution and real apple juice. Batch adsorption experiments were systematically performed to study the adsorption behavior for PAT. The results showed that adsorption process could be well described by the Pseudo-second order model and Freundlich isotherm model. The maximum adsorption capacity (4.38 µg/mg) was 10 times higher than the microbe-based biosorbents. Thermodynamic investigation demonstrated that adsorption process was spontaneous and endothermic. Furthermore, no marked cytotoxicity on NIH 3T3 cell lines was observed when the concentration of the adsorbent was lower than 10 μg/mL. Therefore, UiO-66(NH2)@Au-Cys is a potential adsorbent for PAT removal from apple juice with little quality changes.",industry
10.1016/j.jmapro.2018.10.042,Journal,Journal of Manufacturing Processes,scopus,2018-12-01,sciencedirect,Adaptive control for laser welding with filler wire of marine high strength steel with tight butt joints for large structures,https://api.elsevier.com/content/abstract/scopus_id/85056243076,"To large structures, ensuring a uniform joint gap without mismatch over an entire seam remains a challenge. Varying gaps and mismatches significantly affect the welding qualities, especially for sheet metal. In the paper, an adaptive filling model for process parameters based on back propagation neural network (BPNN) combined with genetic algorithm (GA) is used as an adaptive controller to solve the problems. First, a real-time closed loop feedback control from groove information collection, processing to model prediction and control output was established. Then, an adaptive control approach was investigated, a precision 3D laser sensor was used for measuring the size of gap and mismatch, and an adaptive parameters table was designed as an adaptive controller based on the optimal BPNN, an interpolation operation was introduced for an intermediate value. The results of the experiment showed that the welding parameters can be continuously adjusted in real time despite the variation in the gap and mismatch according to the adaptive filling algorithm and the laser sensor; the welds with desirable uniform weld appearance was achieved despite the changing gap, from 0 to 1.0 mm, and mismatch, from 0 to 1.2 mm, meet the requirement of practical industrial application.",industry
10.1016/j.ejor.2018.05.018,Journal,European Journal of Operational Research,scopus,2018-11-16,sciencedirect,Robust identification of email tracking: A machine learning approach,https://api.elsevier.com/content/abstract/scopus_id/85047795704,"Email tracking allows email senders to collect fine-grained behavior and location data on email recipients, who are uniquely identifiable via their email address. Such tracking invades user privacy in that email tracking techniques gather data without user consent or awareness. Striving to increase privacy in email communication, this paper develops a detection engine to be the core of a selective tracking blocking mechanism in the form of three contributions. First, a large collection of email newsletters is analyzed to show the wide usage of tracking over different countries, industries and time. Second, we propose a set of features geared towards the identification of tracking images under real-world conditions. Novel features are devised to be computationally feasible and efficient, generalizable and resilient towards changes in tracking infrastructure. Third, we test the predictive power of these features in a benchmarking experiment using a selection of state-of-the-art classifiers to clarify the effectiveness of model-based tracking identification. We evaluate the expected accuracy of the approach on out-of-sample data, over increasing periods of time, and when faced with unknown senders.",industry
10.1016/j.powtec.2018.08.064,Journal,Powder Technology,scopus,2018-11-01,sciencedirect,"Settling velocity of drill cuttings in drilling fluids: A review of experimental, numerical simulations and artificial intelligence studies",https://api.elsevier.com/content/abstract/scopus_id/85052516468,"In this paper, a comprehensive review of experimental, numerical and artificial intelligence studies on the subject of cuttings settling velocity in drilling muds made by researchers over the last seven decades is brought to the fore. In this respect, 91 experimental, 13 numerical simulations and 7 artificial intelligence researches were isolated, reviewed, tabulated and discussed. A comparison of the three methods and the challenges facing each of these methods were also reviewed. The major outcomes of this review include: (1) the unanimity among experimental researchers that mud rheology, particle size and shape and wall effect are major parameters affecting the settling velocity of cuttings in wellbores; (2) the prevalence of cuttings settling velocity experiments done with the mud in static conditions and the wellbore in the vertical configuration; (3) the extensive use of rigid particles of spherical shape to represent drill cuttings due to their usefulness in experimental visualization, particle tracking, and numerical implementation; (4) the existence of an artificial intelligence technique - multi-gene genetic programming (MGGP) which can provide an explicit equation that can help in predicting settling velocity; (5) the limited number of experimental studies factoring in the effect of pipe rotation and well inclination effects on the settling velocity of cuttings and (6) the most applied numerical method for determining settling velocity is the finite element method. Despite these facts, there is need to perform more experiments with real drill cuttings and factor in the effects of conditions such as drillstring rotation and well inclination and use data emanating therefrom to develop explicit models that would include the effects of these. It should be noted however, that the aim of this paper is not to create an encyclopaedia of particle settling velocity research, but to provide to the researcher with a basic, theoretical, experimental and numerical overview of what has so far been achieved in the area of cuttings settling velocity in drilling muds.",industry
10.1016/j.petrol.2018.06.072,Journal,Journal of Petroleum Science and Engineering,scopus,2018-11-01,sciencedirect,Data driven model for sonic well log prediction,https://api.elsevier.com/content/abstract/scopus_id/85050476760,"Near wellbore failure during the exploration of hydrocarbon reservoirs presents a serious concern to the oil and gas industry. To predict the probability of these undesirable phenomena, engineers study the mechanical rock properties of the formation such as Young's modulus, Bulk modulus, shear modulus and Poisson's ratio. Conventionally, these are measured indirectly using the established petro physical relationships from sonic wave velocities which can be obtained from sonic well logs. Unfortunately, reliable sonic well logs are not always available, due to poor borehole conditions (wash out), damaged tools and offset well data. Most offset well log data are not acquired with dipole sonic tools; they are acquired with a borehole compensated logging tool. This limits the application of acoustic measurements to estimate the mechanical rock properties.
                  In this study, a three-layer feedforward multilayered perceptron artificial neural network model is presented. This model aims to estimate compressional wave transit time and shear wave transit time using real gamma ray and formation density logs. The validation of the model is confirmed by using an oil and gas offshore shaley sandstone reservoir located in West Africa. The results of the validation show that the model presented in this study can be used to determine the sanding potential of the formation without performing a compressive geoscientific analysis in the absence of sonic well logs. The developed model's effectiveness is tested by comparing the predicted results with results obtained from the measured well log. The paper provides a tool to give preliminary recommendations of the likelihood of the formation to produce sand. Implementation of the proposed model can serve as a cost-effective and reliable alternative for the oil and gas industry.",industry
10.1016/j.measurement.2018.05.099,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-11-01,sciencedirect,Parallel three-dimensional electrical capacitance data imaging using a nonlinear inversion algorithm and L<sup>p</sup> norm-based model regularization,https://api.elsevier.com/content/abstract/scopus_id/85049483981,"In order to improve image reconstructions, different classes of nonlinear inversion algorithms are developed and used in different research topics like imaging processes in oil industry or the characterization of complex porous media or multiphase flows. These algorithms are able to avoid local minima and to reach more adapted minima of a given misfit function between observed/measured and computed data. Techniques as different as electrical, ultrasound or potential methods, are used. We present here a nonlinear algorithm that allows us to produce permittivity images by using electrical capacitance tomography (ECT). ECT is a non-invasive technique to image non-conductive permittivity distributions and is used in many oil industry imaging applications such as multiphase flows in pipelines, fluidized bed reactors, mixing vessels, and tanks of phase separation. Even if the ECT technique provides low resolution reconstructions, it is cheap, robust and very fast when compared to other imaging tools. In this method one or more rings of electrodes excite a medium to be imaged at high frequencies, and more particularly at frequencies for which a static electrical potential field has fully developed. In many studies of other research groups only one ring of sources is introduced but the reconstruction accuracy was not totally satisfactory due to the 3D nature of the problem to be solved. Instead of using nonlinear stochastic algorithms like the simulated annealing (SA) technique that we optimized in previous studies to image permittivity distributions of granular or solid materials as well as real oil–gas or two-phase flows in 2D cylindrical vessel configurations, we propose here a new ECT inversion tool to image permittivities in a 3D cylindrical configuration. 3D stochastic optimization methods such as SA, neural networks, genetic algorithms can become computationally too prohibitive, and classical local or linear inversion methods excessively smooth images in many cases. Therefore, we propose here a 3D parallel inversion procedure with different numbers of rings and different 
                        
                           
                              
                                 L
                              
                              
                                 p
                              
                           
                        
                      norms, with
                        
                           1
                           <
                           p
                           ⩽
                           2
                        
                     , applied to the model regularization of the misfit function to increase the resolution of the models after inversion. We are able to better reconstruct two-phase and three-phase (oil, gas and solids) mixtures by combining 
                        
                           
                              
                                 L
                              
                              
                                 p
                              
                           
                        
                     -norm regularizations of the misfit function to minimize and several rings of electrodes. All these algorithms have been implemented in a more general parallel framework TOMOFAST-X designed for multi-physics joint inversion purposes, and could also be used in other fields of research such as larger-scale geophysical exploration for instance.",industry
10.1016/j.ssci.2018.06.012,Journal,Safety Science,scopus,2018-11-01,sciencedirect,Occupational health and safety in the industry 4.0 era: A cause for major concern?,https://api.elsevier.com/content/abstract/scopus_id/85049323662,"Real-time communication, Big Data, human–machine cooperation, remote sensing, monitoring and process control, autonomous equipment and interconnectivity are becoming major assets in modern industry. As the fourth industrial revolution or Industry 4.0 becomes the predominant reality, it will bring new paradigm shifts, which will have an impact on the management of occupational health and safety (OHS).
                  In the midst of this new and accelerating industrial trend, are we giving due consideration to changes in OHS imperatives? Are the OHS consequences of Industry 4.0 being evaluated properly? Do we stand to lose any of the gains made through proactive approaches? Are there rational grounds for major concerns? In this article, we examine these questions in order to raise consciousness with regard to the integration of OHS into Industry4.0.
                  It is clear that if the technologies driving Industry 4.0 develop in silos and manufacturers’ initiatives are isolated and fragmented, the dangers will multiply and the net impact on OHS will be negative. As major changes are implemented, previous gains in preventive management of workplace health and safety will be at risk. If we are to avoid putting technological progress and OHS on a collision course, researchers, field experts and industrialists will have to collaborate on a smooth transition towards Industry 4.0.",industry
10.1016/j.measurement.2018.06.028,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-11-01,sciencedirect,A machine-learning based solution for chatter prediction in heavy-duty milling machines,https://api.elsevier.com/content/abstract/scopus_id/85048823035,"The main productivity constraints of milling operations are self-induced vibrations, especially regenerative chatter vibrations. Two key parameters are linked to these vibrations: the depth of cut achievable without vibrations and the chatter frequency. Both parameters are linked to the dynamics of machine component excitation and the milling operation parameters. Their identification in any cutting direction in milling machine operations requires complex analytical models and mechatronic simulations, usually only applied to identify the worst cutting conditions in operating machines. This work proposes the use of machine learning techniques with no need to calculate the two above-mentioned parameters by means of a 3-step strategy. The strategy combines: 1) experimental frequency responses collected at the tool center point; 2) analytical calculations of both parameters; and, 3) different machine learning techniques. The results of these calculations can then be used to predict chatter under different combinations of milling directions and machine positions. This strategy is validated with real experiments on a bridge milling machine performing concordance roughing operations on AISI 1045 steel with a 125 mm diameter mill fitted with nine cutters at 45°, the results of which have confirmed the high variability of both parameters along the working volume. The following regression techniques are tested: artificial neural networks, regression trees and Random Forest. The results show that Random Forest ensembles provided the highest accuracy with a statistical advantage over the other machine learning models; they achieved a final accuracy of 0.95 mm for the critical depth and 7.3 Hz for the chatter frequency (RMSE) in the whole working volume and in all feed directions, applying a 10 × 10 cross validation scheme. These RMSE values are acceptable from the industrial point of view, taking into account that the critical depth of this range varies between 0.68 mm and 19.20 mm and the chatter frequency between 1.14 Hz and 65.25 Hz. Besides, Random Forest ensembles are more easily optimized than artificial neural networks (1 parameter configuration versus 210 MLPs). Additionally, tools that incorporate regression trees are interesting and highly accurate, providing immediately accessible and useful information in visual formats on critical machine performance for the design engineer.",industry
10.1016/j.jlp.2018.01.011,Journal,Journal of Loss Prevention in the Process Industries,scopus,2018-11-01,sciencedirect,Deep neural network and random forest classifier for source tracking of chemical leaks using fence monitoring data,https://api.elsevier.com/content/abstract/scopus_id/85041960230,"Chemical plant leak accidents are classified as one of the major industrial accidents that can spread secondary and tertiary major disasters. It is very important to keep track and diagnose the source location(s) and notify the plant manager and emergency responders promptly to alleviate secondary and tertiary damages, improving the effectiveness of emergency responses. In this study, we propose an emergency response system that can cope with leak accidents of a chemical plant by monitoring sensor data and track down the suspected leak source using machine learning: Deep-learning and Random Forest classifiers. It is also difficult to get enough chemical leak accident scenario data or perform actual leak experiments on real plants due to high risk and cost factors. Consequently, Computational Fluid Dynamics (CFD) simulations are used to derive fence monitoring data for chemical leak accident scenarios. These data are to train the machine learning models to predict leak source locations. Six time-series Deep Neural Network (DNN) structures and three Random Forest (RF) structures are trained using CFD dispersion simulation results for 640 leak accident scenarios of a real chemical plant, divided as training and test datasets. As a result, on DNN model using 25 hidden layers and on RF model using 100 decision trees, 75.43% and 86.33% prediction accuracy are achieved, respectively, classifying the most probable leak source out of 40 potential leak source locations. Analyzing the predicted leak source locations that are wrongly classified, those predicted leak sources are also quite adjacent to the actual leak location and hardly called as misclassifications. Considering the superb performance of DNN and RF classifiers for chemical leak tracking, the proposed method would be very useful for chemical emergency management and is highly recommended for real-time diagnosis of the chemical leak sources.",industry
10.1016/j.neucom.2018.05.021,Journal,Neurocomputing,scopus,2018-10-08,sciencedirect,A robust intelligent fault diagnosis method for rolling element bearings based on deep distance metric learning,https://api.elsevier.com/content/abstract/scopus_id/85047276386,"Intelligent data-driven fault diagnosis methods for rolling element bearings have been widely developed in the recent years. In real industries, the collected machinery signals are usually exposed to environmental noises, and the bearing operating condition changes in different working scenarios. That leads to distribution discrepancy between the labeled training data and the unlabeled testing data, and consequently the diagnosis performance deteriorates. This paper proposes a novel deep distance metric learning method for rolling bearing fault diagnosis based on deep learning. A deep convolutional neural network is used as the main architecture. Based on the learned representations through multiple hidden layers, a representation clustering algorithm is proposed to minimize the distance of intra-class variations and maximize the distance of inter-class variations simultaneously. A domain adaptation method is adopted to minimize the maximum mean discrepancy between training and testing data. In this way, the robustness of the fault diagnosis method can be significantly improved against noise and variation of working condition. Extensive experiments on a popular rolling bearing dataset are carried out to validate the effectiveness of the proposed method, and the diagnosis performance is widely evaluated in different scenarios. Comparisons with other approaches and the related works on the same dataset demonstrate the superiority of the proposed method. The experimental results of this study suggest the proposed deep distance metric learning method offers a new and promising tool for intelligent fault diagnosis of rolling bearings.",industry
10.1016/j.jmsy.2018.10.001,Journal,Journal of Manufacturing Systems,scopus,2018-10-01,sciencedirect,Application of the artificial neural network method to detect defective assembling processes by using a wearable technology,https://api.elsevier.com/content/abstract/scopus_id/85054907924,"Recently, the Industry 4.0 connects production processes and smart production technologies to lead up to a new technological age. The Industry 4.0 utilizes digital technologies such as augmented reality, sensors and wearables (e.g. smart watches, gloves, and glasses) to track all production operations. This study considers the problem of distinguishing proper and defective operations in connector assembly tasks in an automotive company. A digital assembly glove is developed as a wearable technology prototype. This glove is introduced to measure vibration and force values on the fingers to classify proper and defective operations in connector assembly processes. Experiments were conducted with 17 subjects to obtain force and vibration signals of the considered assembly task. For the signal classification of the digital assembly glove, the artificial neural network (ANN) methodology was used. Performance of the ANN was tested on the case of connector assembly process of the company. The collected proper and defective connection measurements were used for the training, validation, and testing of the ANN. As a result of the MATLAB computations, a neural network structure was obtained with 95% accuracy. The performance of the neural network showed that the ANN is an applicable method for the considered wearable technology to detect defective operations.",industry
10.1016/j.vetmic.2018.08.026,Journal,Veterinary Microbiology,scopus,2018-10-01,sciencedirect,Detection of non-notifiable H4N6 avian influenza virus in poultry in Great Britain,https://api.elsevier.com/content/abstract/scopus_id/85053845094,"A 12-month pilot project for notifiable avian disease (NAD) exclusion testing in chicken and turkey flocks in Great Britain (GB) offered, in partnership with industry, opportunities to carry out differential diagnosis in flocks where NAD was not suspected, and to identify undetected or undiagnosed infections. In May 2014, clinical samples received from a broiler breeder chicken premises that had been experiencing health and production problems for approximately one week tested positive by avian influenza (AI) real-time reverse transcription polymerase chain reaction (RRT-PCR). Following immediate escalation to an official, statutory investigation to rule out the presence of notifiable AI virus (AIV; H5 or H7 subtypes), a non-notifiable H4N6 low pathogenicity (LP) AIV was detected through virus isolation in embryonated specific pathogen free (SPF) fowls’ eggs, neuraminidase inhibition test, cleavage site sequencing and AIV subtype H4-specific serology. Premises movement restrictions were lifted, and no further disease control measures were implemented as per the United Kingdom (UK) legislation. Phylogenetic analysis of the haemagglutinin and neuraminidase genes of the virus revealed closest relationships to viruses from Mallard ducks in Sweden during 2007 and 2009. In June 2014, clinical suspicion of NAD was reported in a flock of free-range laying chickens elsewhere in GB, due to increasing daily mortality and reduced egg production over a five-day period. An H4N6 LPAIV with an intravenous pathogenicity index of 0.50 was isolated. This virus was genetically highly similar, but not identical, to the virus detected during May 2014. Full viral genome analyses showed characteristics of a strain that had not recently transferred from wild birds, implying spread within the poultry sector had occurred. A stalk deletion in the neuraminidase gene sequence indicated an adaptation of the virus to poultry. Furthermore, there was unexpected evidence of systemic spread of the virus on post-mortem. No other cases were reported. Infection with LPAIVs often result in variable clinical presentation in poultry, making detection of disease more difficult.",industry
10.1016/j.mfglet.2018.09.002,Journal,Manufacturing Letters,scopus,2018-10-01,sciencedirect,Industrial Artificial Intelligence for industry 4.0-based manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/85053749537,"The recent White House report on Artificial Intelligence (AI) (Lee, 2016) highlights the significance of AI and the necessity of a clear roadmap and strategic investment in this area. As AI emerges from science fiction to become the frontier of world-changing technologies, there is an urgent need for systematic development and implementation of AI to see its real impact in the next generation of industrial systems, namely Industry 4.0. Within the 5C architecture previously proposed in Lee et al. (2015), this paper provides an insight into the current state of AI technologies and the eco-system required to harness the power of AI in industrial applications.",industry
10.1016/j.compind.2018.07.004,Journal,Computers in Industry,scopus,2018-10-01,sciencedirect,IDARTS – Towards intelligent data analysis and real-time supervision for industry 4.0,https://api.elsevier.com/content/abstract/scopus_id/85050319341,"The manufacturing industry represents a data rich environment, in which larger and larger volumes of data are constantly being generated by its processes. However, only a relatively small portion of it is actually taken advantage of by manufacturers. As such, the proposed Intelligent Data Analysis and Real-Time Supervision (IDARTS) framework presents the guidelines for the implementation of scalable, flexible and pluggable data analysis and real-time supervision systems for manufacturing environments. IDARTS is aligned with the current Industry 4.0 trend, being aimed at allowing manufacturers to translate their data into a business advantage through the integration of a Cyber-Physical System at the edge with cloud computing. It combines distributed data acquisition, machine learning and run-time reasoning to assist in fields such as predictive maintenance and quality control, reducing the impact of disruptive events in production.",industry
10.1016/j.asoc.2018.07.034,Journal,Applied Soft Computing Journal,scopus,2018-10-01,sciencedirect,A hybrid multi-objective AIS-based algorithm applied to simulation-based optimization of material handling system,https://api.elsevier.com/content/abstract/scopus_id/85050115741,"Optimization of complex real-world problems often involves multiple objectives to be considered simultaneously. These objectives are often non-commensurable and competing. For example, material handling is a vital element of industrial processes, which involves a variety of operations including the movement, storage and control of materials throughout the processes of manufacturing, distribution, and disposal while having to satisfy multiple objectives. Having an efficient and effective material handling system (MHS) is of great importance to various industries, such as manufacturing and logistics industries, for maintaining and facilitating a continuous flow of materials through the workplace and guaranteeing that required materials are available when needed. In this paper, a hybrid multi-objective optimization algorithm largely based on Artificial Immune Systems (AIS) is applied to simulation-based optimization of material handling system. This proposed algorithm hybridizes the AIS with the Genetic Algorithm (GA) by incorporating the crossover operator derived from the biological evolution. The reason behind such hybridization is to further enhance the diversity of the clone population and the convergence of the algorithm. In this paper, other than conducting numerical experiments to assess the performance of the proposed algorithm by using several benchmark problems, the proposed algorithm is also applied to optimize a multi-objective simulation-based problem on a material handling system in order to demonstrate the applicability of the proposed algorithm in real-life cases. The results show that for most cases the proposed algorithm outperforms the other benchmark algorithms especially in terms of solution diversity.",industry
10.1016/j.cie.2018.07.016,Journal,Computers and Industrial Engineering,scopus,2018-10-01,sciencedirect,New decision support system for strategic planning in process industries: Computational results,https://api.elsevier.com/content/abstract/scopus_id/85049776857,"The impact of a Stochastic Linear Programming (SLP) based Decision Support System in a manufacturing company, such as an integrated aluminum plant, is measured by two important parameters, the VSS and EVPI. With the real data of an integrated steel plant in India, we demonstrate that SLP based DSS can be very effective in managing demand uncertainty and performing futuristic integrated planning, and their financial impact can be in millions of dollars. A two stage stochastic programming model with recourse is implementedin the DSS here. A set of experiments is conducted. Real data from an aluminum company is used to validate the system. The importance of SLP based DSS can be realized from the fact that the value of the stochastic solution (VSS) is USD 3.58 million with 30% demand variability and equally likely demand distribution. The VSS as a percentage of Expectation of Expected Value (EEV) ranges from 0.90% to 18.93% across experiments.",industry
10.1016/j.chemosphere.2018.06.065,Journal,Chemosphere,scopus,2018-10-01,sciencedirect,In-vitro metabolomics to evaluate toxicity of particulate matter under environmentally realistic conditions,https://api.elsevier.com/content/abstract/scopus_id/85049310414,"In this pilot study three fractions of particulate matter (PM0.25, PM2.5-0.25, and PM10-2.5) were collected in three environments (classroom, home, and outdoors) in a village located nearby an industrial complex. Time-activity pattern of 20 students attending the classroom was obtained, and the dose of particles reaching the children's lungs under actual environmental conditions (i.e. real dose) was calculated via dosimetry model. The highest PM concentrations were reached in the classroom. Simulations showed that heavy intensity outdoor activities played a major role in PM deposition, especially in the upper part of the respiratory tract. The mass of PM10-2.5 reaching the alveoli was minor, while PM2.5-0.25 and PM0.25 apportion for most of the PM mass retained in the lungs. Consequently, PM2.5-0.25 and PM0.25 were the only fractions used in two subsequent toxicity assays onto alveolar cells (A549). First, a cytotoxicity dose-response assay was performed, and doses corresponding to 5% mortality (LC5) were estimated. Afterwards, two LC-MS metabolomic assays were conducted: one applying LC5, and another applying real dose. A lower estimated LC5 value was obtained for PM0.25 than PM2.5-0.25 (8.08 and 73.7 ng/mL respectively). The number of altered features after LC5 exposure was similar for both fractions (39 and 38 for PM0.25 and PM2.5-0.25 respectively), while after real dose exposure these numbers differed (10 and 5 for PM0.25 and PM2.5-0.25 respectively). The most metabolic changes were related to membrane and lung surfactant lipids. This study highlights the capacity of PM to alter metabolic profile of lung cells at conventional environmental levels.",industry
10.1016/j.chemolab.2018.07.003,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2018-09-15,sciencedirect,Active learning based semi-supervised exponential discriminant analysis and its application for fault classification in industrial processes,https://api.elsevier.com/content/abstract/scopus_id/85053167328,"For the industrial fault classification, exponential discriminant analysis (EDA) requires that all the training samples should be labeled; however, only a minority of the training samples are randomly labeled in real industrial processes. This motivates the formulation of the active learning based semi-supervised exponential discriminant analysis in this paper. Firstly, to make EDA applicable to the semi-supervised industrial scenario, scatter matrices are transformed into their regularization variants through combining unlabeled training samples. Moreover, to reduce the adverse effect of random labeling of training samples, the best versus second-best rule is employed to select more informative training samples in an active way to upgrade the model classification performance. And the obvious performance improvement of the proposed method is demonstrated with extensive experiments on synthesized data, the TE process and a real industrial process.",industry
10.1016/j.apenergy.2018.06.040,Journal,Applied Energy,scopus,2018-09-15,sciencedirect,Optimal scheduling of a microgrid in a volatile electricity market environment: Portfolio optimization approach,https://api.elsevier.com/content/abstract/scopus_id/85048767400,"This paper proposes an optimal scheduling strategy for a microgrid participating in a volatile electricity market. The microgrid system includes photovoltaic generators, a wind turbine, a load, grid connection, and a battery storage system. An optimal microgrid operation is achieved by maximizing the utility function represented by the exponential rate of growth of the electricity market value through electricity transactions between the microgrid and main grid, on the premise of satisfying the power balance and generation limit of system components. The uncertainties occurring during the microgrid operation are represented by generator output, load demand, and electricity price fluctuation. The proposed strategy utilizes the Kelly Criterion, an optimal strategy that maximizes the growth rate of an asset’s net worth over repeated investments, coupled with an artificial neural network forecast of electricity price to deal with the volatile energy market. The proposed algorithm provides significant improvements in microgrid scheduling by eliminating the reliance on renewable generation and load forecasts, which makes it computationally inexpensive and thus feasible for real-time implementation. In representative case scenarios, using real-world tracers, we show that the algorithm has no dependency on meteorological forecasts and performs optimally in a volatile electricity market.",industry
10.1016/j.polymertesting.2018.06.002,Journal,Polymer Testing,scopus,2018-08-01,sciencedirect,A soft sensor for prediction of mechanical properties of extruded PLA sheet using an instrumented slit die and machine learning algorithms,https://api.elsevier.com/content/abstract/scopus_id/85048112484,"A soft sensor has been designed to accurately predict the yield stress of extruded Polylactide (PLA) sheet inline, during extrusion processing using an instrumented slit die. A number of experiments over a wide range of processing conditions have been carried out to develop the soft sensor model. The instrumented slit die had a number of embedded sensors monitoring pressure and temperature. The data collected from the slit die sensors was then used to predict the yield stress of the extruded PLA sheet using machine learning algorithms. The yield stress of the extruded sheet, which was measured offline, is compared to the model predictions to check the performance of the model. The soft sensor has the potential to provide real time feedback into the process and become a Quality Assurance (QA) tool which indicates if a product is going out of specification. This model can lead to reduced scrap rates and lower manufacturing costs by reducing machine downtime and making the process more energy efficient. Soft sensors have the potential to be introduced as part of a smart manufacturing process in keeping with the developments of Industry 4.0.",industry
10.1016/j.jisa.2018.05.002,Journal,Journal of Information Security and Applications,scopus,2018-08-01,sciencedirect,Identification of malicious activities in industrial internet of things based on deep learning models,https://api.elsevier.com/content/abstract/scopus_id/85047072990,"Internet Industrial Control Systems (IICSs) that connect technological appliances and services with physical systems have become a new direction of research as they face different types of cyber-attacks that threaten their success in providing continuous services to organizations. Such threats cause firms to suffer financial and reputational losses and the stealing of important information. Although Network Intrusion Detection Systems (NIDSs) have been proposed to protect against them, they have the difficult task of collecting information for use in developing an intelligent NIDS which can proficiently detect existing and new attacks. In order to address this challenge, this paper proposes an anomaly detection technique for IICSs based on deep learning models that can learn and validate using information collected from TCP/IP packets. It includes a consecutive training process executed using a deep auto-encoder and deep feedforward neural network architecture which is evaluated using two well-known network datasets, namely, the NSL-KDD and UNSW-NB15. As the experimental results demonstrate that this technique can achieve a higher detection rate and lower false positive rate than eight recently developed techniques, it could be implemented in real IICS environments.",industry
10.1016/j.cad.2018.03.006,Journal,CAD Computer Aided Design,scopus,2018-08-01,sciencedirect,FeatureNet: Machining feature recognition based on 3D Convolution Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85045570569,"Automated machining feature recognition, a sub-discipline of solid modeling, has been an active research area for last three decades and is a critical component in digital manufacturing thread for detecting manufacturing information from computer aided design (CAD) models. In this paper, a novel framework using Deep 3D Convolutional Neural Networks (3D-CNNs) termed FeatureNet to learn machining features from CAD models of mechanical parts is presented. FeatureNet learns the distribution of complex manufacturing feature shapes across a large 3D model dataset and discovers distinguishing features that help in recognition process automatically. To train FeatureNet, a large-scale mechanical part datasets of 3D CAD models with labeled machining features is automatically constructed. The proposed framework can recognize manufacturing features from the low-level geometric data such as voxels with a very high accuracy. The developed framework can also recognize planar intersecting features in the 3D CAD models. Extensive numerical experiments show that FeatureNet enables significant improvements over the state-of-the-arts manufacturing feature detection techniques. The developed data-driven framework can easily be extended to identify a large variety of machining features leading to a sound foundation for real-time computer aided process planning (CAPP) systems.",industry
10.1016/j.renene.2018.02.092,Journal,Renewable Energy,scopus,2018-08-01,sciencedirect,An experimental investigation of three new hybrid wind speed forecasting models using multi-decomposing strategy and ELM algorithm,https://api.elsevier.com/content/abstract/scopus_id/85042473238,"The wind speed forecasting is important for the wind power industry to achieve the intelligent management. Three new hybrid methods using the WPD (Wavelet Packet Decomposition), the EMD (Empirical Mode Decomposition) and the ELM (Extreme Learning Machine) are presented for wind speed multi-step predictions. In the proposed architectures, the WPD is chosen to decompose the actual wind speed series into several sub-layers, while the EMD is adopted to further decompose the obtained LF (Low Frequency) sub-layers, the obtained HF (High Frequency) sub-layers and all the obtained sub-layers into a number of IMFs (Intrinsic Mode Functions), respectively. Finally, the ELM is used to complete the wind speed predicting computation for these decomposed wind speed sub-layers. To investigate the performance of the proposed hybrid models in the wind speed multi-step forecasting and find which kind of signal decomposing approach is the most suitable for the ELM based wind speed forecasting, the PM (Persistent Model), the ARIMA model, the SVM model, the ELM model, the WPD-ELM model, the WPD-EMD (LF)-ELM model, the WPD-EMD (HF)-ELM model and the WPD-EMD-ELM model are all included in the forecasting performance comparisons. The results of the two real experiments indicate that among all the involved models, the WPD-EMD (LF)-ELM model has the best predicting performance.",industry
10.1016/j.chemosphere.2018.03.090,Journal,Chemosphere,scopus,2018-07-01,sciencedirect,Sequential application of Fenton and ozone-based oxidation process for the abatement of Ni-EDTA containing nickel plating effluents,https://api.elsevier.com/content/abstract/scopus_id/85047432383,"Treatment of Ni-EDTA in industrial nickel plating effluents was investigated by integrated application of Fenton and ozone-based oxidation processes. Determination of integrated sequence found that Fenton oxidation presented higher apparent kinetic rate constant of Ni-EDTA oxidation and capacity for contamination load than ozone-based oxidation process, the latter, however, was favorable to guarantee the further mineralization of organic substances, especially at a low concentration. Serial-connection mode of two oxidation processes was appraised, Fenton effluent after treated by hydroxide precipitation and filtration negatively affected the overall performance of the sequential system, as evidenced by the removal efficiencies of Ni2+ and TOC dropping from 99.8% to 98.7%, and from 74.8% to 66.6%, respectively. As a comparison, O3/Fe2+ oxidation process was proved to be more effective than other processes (e.g. O3-Fe2+, O3/H2O2/Fe2+, O3/H2O2-Fe2+), and the final effluent Ni2+ concentration could satisfied the discharge standard (<0.1 mg L−1, China) under the optimal conditions (H2O2 dosage of 1.0 mL L−1, Fe2+: H2O2 mole ratio of 1.46, and reaction time of 10 min for Fenton reaction, initial influent pH of 3.0, O3 dosage of 252 mg L−1, Fe2+ of 150 mg L−1, and reaction time of 30 min for O3/Fe2+ oxidation). Furthermore, pilot-scale test was carried out to study the practical treatability towards the real nickel plating effluent, revealing the effective removal of some other co-existence contaminations. And Fenton reaction has contributed most, with the percentage ranging from 72.41% to 93.76%. The economic cost advantage made it a promising alternative to the continuous Fenton oxidation.",industry
10.1016/j.knosys.2018.03.025,Journal,Knowledge-Based Systems,scopus,2018-07-01,sciencedirect,On the predictive analysis of behavioral massive job data using embedded clustering and deep recurrent neural networks,https://api.elsevier.com/content/abstract/scopus_id/85044262883,"The recent proliferation of social networks as a main source of information and interaction has led to a huge expansion of automatic e-recruitment systems and by consequence the multiplication of web channels (job boards) that are dedicated to job offers disseminating. In a strategic and economic context where cost control is fundamental, it has become necessary to identify the relevant job board for a given new job offer has become necessary. The purpose of this work is to present the recent results that we have obtained on a new job board recommendation system that is a decision-making tool intended to guide recruiters while they are posting a job on the Internet. Firstly, the Doc2Vec embedded representation is used to analyse the textual content of the job offers, then the job applicant clickstreams history on various job boards are stored in a large learning database, and then represented as time series. Secondly, a deep neural network architecture is used to predict future values of the clicks on the job boards. Third, and in parallel, dimensionality reduction techniques are used to transform the clicks numerical time series into temporal symbolic sequences. Forecasting algorithms are then used to predict future symbols for each sequence. Finally, a list of top ranked job boards are kept by maximizing the clickstreams forecasting in both representations. Our experiments are tested on a real dataset, coming from a job-posting database of an industrial partner. The promising results have shown that using deep learning, the recommendation system outperforms standard multivariate models.",industry
10.1016/j.omega.2017.10.002,Journal,Omega (United Kingdom),scopus,2018-07-01,sciencedirect,Flow shop learning effect scheduling problem with release dates,https://api.elsevier.com/content/abstract/scopus_id/85032183656,"In a real-world assembly environment, the components of a product arrive at a plant over time. Works-in-process are assembled into end-products by following an identical processing route. When a worker at a particular stage repeatedly handles similar tasks and gains the knowledge to execute a task efficiently, the processing time for later tasks is shortened significantly. This assembly process can be described as the flow shop learning effect scheduling problem with release dates, in which the learning effect is dependent on position. The objective is to minimize one of three different criteria, namely, makespan, total completion time and total quadratic completion time. This scheduling problem is formulated as a mixed integer programming (MIP) model. For small-scale problems, a branch and bound (B&B) algorithm with an efficient branching rule is proposed to obtain optimal solutions. The MIP model and the B&B algorithm provide key evidence for academic research. For large-scale problems, the asymptotic optimality of a class of shortest processing time available (SPTA)-based heuristics is proven in terms of probability limit. The convergence property indicates that an SPTA-based heuristic can serve as an optimal schedule under the industrial setting, where thousands of tasks are typically executed on a set of machines. Extensive numerical experiments demonstrate the effectiveness of the proposed algorithms.",industry
10.1016/j.enconman.2018.03.044,Journal,Energy Conversion and Management,scopus,2018-06-01,sciencedirect,Adaptive air-fuel ratio control of dual-injection engines under biofuel blends using extreme learning machine,https://api.elsevier.com/content/abstract/scopus_id/85044138298,"Dual-injection engines, which allow real-time control and injection of two different fuels, are capable of varying the ratio of biofuel blends at different engine operating conditions for optimal engine performance. However, while many experiments have been carried out on these engines to demonstrate their advantages, very few studies have focused on the corresponding air–fuel ratio (AFR) control strategy. In order to achieve stable engine operation, it is essential to maintain transient AFR during the change of fuel blend ratio. Therefore, this study proposes an adaptive controller for AFR control of dual-injection engines. The proposed controller is designed based on a recently developed machine learning method called extreme learning machine, and its stability is verified with Lyapunov analysis. Simulations have been performed on an industry-level engine simulation software to verify the controller. Since dual-injection engines are not available in the market, a spark-ignition engine has been retrofitted for dual-injection operation so that the proposed controller can be implemented and evaluated experimentally. Both simulation and experiment results show that the proposed controller can effectively regulate the AFR to desired level. The results also show that the proposed controller outperforms the engine built-in AFR controller, indicating its significance for dual-injection engines.",industry
10.1016/j.vaccine.2017.03.018,Journal,Vaccine,scopus,2018-05-24,sciencedirect,Propagation of Brazilian Zika virus strains in static and suspension cultures using Vero and BHK cells,https://api.elsevier.com/content/abstract/scopus_id/85016059574,"The recent spread of Zika virus (ZIKV) in the Americas and the Pacific has reached alarming levels in more than 60 countries. However, relatively little is known about the disease on a virological and epidemiological level and its consequences for humans. Accordingly, a large demand for in vitro derived Brazilian ZIKV material to support in vitro and in vivo studies has arisen. However, a prompt supply of ZIKV and ZIKV antigens cannot be guaranteed as the production of this virus typically using Vero or C6/36 cell lines remains challenging.
                  Here we present a production platform based on BHK-21 suspension (BHK-21SUS) cells to propagate Brazilian ZIKV at larger quantities in perfusion bioreactors. Scouting experiments performed in tissue culture flasks using adherent BHK-21 and Vero cells have demonstrated similar permissivity and virus yields for four different Brazilian ZIKV isolates. The cell-specific yield of infectious virus particles varied between respective virus strains (1–48PFU/cell), and the ZIKV isolate from the Brazilian state Pernambuco (ZIKVPE) showed to be a best performing isolate for both cell lines. However, infection studies of BHK-21SUS cells with ZIKVPE in shake flasks resulted in poor virus replication, with a maximum titer of 8.9×103
                     PFU/mL. Additional RT-qPCR measurements of intracellular and extracellular viral RNA levels revealed high viral copy numbers within the cell, but poor virus release. Subsequent cultivation in a perfusion bioreactor using an alternating tangential flow filtration system (ATF) under controlled process conditions enabled cell concentrations of about 1.2×107
                     cells/mL, and virus titers of 3.9×107
                     PFU/mL. However, while the total number of infectious virus particles was increased, the cell-specific yield (3.3PFU/cell) remained lower than determined in adherent cell lines. Nevertheless, the established perfusion process allows to provide large amounts of ZIKV material for research and is a first step towards process development for manufacturing inactivated or live-attenuated ZIKV vaccines.",industry
10.1016/j.engappai.2018.02.011,Journal,Engineering Applications of Artificial Intelligence,scopus,2018-05-01,sciencedirect,Computational narrative mapping for the acquisition and representation of lessons learned knowledge,https://api.elsevier.com/content/abstract/scopus_id/85043510280,"Lessons learned knowledge is traditionally gained from trial and error or narratives describing past experiences. Learning from narratives is the preferred option to transfer lessons learned knowledge. However, learners with insufficient prior knowledge often experience difficulties in grasping the right information from narratives. This paper introduces an approach that uses narrative maps to represent lessons learned knowledge to help learners understand narratives. Since narrative mapping is a time-consuming, labor-intensive and knowledge-intensive process, the proposed approach is supported by a computational narrative mapping (CNM) method to automate the process. CNM incorporates advanced technologies, such as computational linguistics and artificial intelligence (AI), to identify and extract critical narrative elements from an unstructured, text-based narrative and organize them into a structured narrative map representation. This research uses a case study conducted in the construction industry to evaluate CNM performance in comparison with existing paragraph and concept mapping approaches. Among the results, over 90% of respondents asserted that CNM enhanced their understanding of the lessons learned. CNM’s performance in identifying and extracting narrative elements was evaluated through an experiment using real-life narratives from a reminiscence study. The experiment recorded a precision and recall rate of over 75%.",industry
10.1016/j.autcon.2018.01.003,Journal,Automation in Construction,scopus,2018-05-01,sciencedirect,Transfer learning and deep convolutional neural networks for safety guardrail detection in 2D images,https://api.elsevier.com/content/abstract/scopus_id/85041454603,"Safety has been a concern for the construction industry for decades. Unsafe conditions and behaviors are considered as the major causes of construction accidents. The current safety inspection of conditions and behaviors heavily rely on human efforts which are limited onsite. To improve the safety performance of the industry, a more efficient approach to identify the unsafe conditions on site is required to supplement the current manual inspection practice. A promising way to supplement the current manual safety inspection is automated and intelligent monitoring/inspection through information and sensing technologies, including localization techniques, environment monitoring, image processing and etc. To assess the potential benefits of contemporary technologies for onsite safety inspection, the authors focused on real-time guardrail detection, as unprotected edges are the ones cause for workers falling from heights.
                  In this paper, the authors developed a safety guardrail detection model based on convolutional neural network (CNN). An augmented data set is generated with the addition of background image to guardrail 3D models and used as training set. Transfer learning is utilized and the Visual Geometry Group architecture with 16 layers (VGG-16) model is adopted to construct the basic features extraction for the neural network. In the CNN implementation, 4000 augmented images were used to train the proposed model, while another 2000 images collected from real construction jobsites and 2000 images from Google were used to validate the proposed model. The proposed CNN-based guardrail detection model obtained a high accuracy of 96.5%. In addition, this study indicates that the synthetic images generated by augment technology can be used to create a large training dataset, and CNN-based image detection algorithm is a promising approach in construction jobsite safety monitoring.",industry
10.1016/j.neucom.2018.01.002,Journal,Neurocomputing,scopus,2018-04-12,sciencedirect,Robot manipulator control using neural networks: A survey,https://api.elsevier.com/content/abstract/scopus_id/85041636063,"Robot manipulators are playing increasingly significant roles in scientific researches and engineering applications in recent years. Using manipulators to save labors and increase accuracies are becoming common practices in industry. Neural networks, which feature high-speed parallel distributed processing, and can be readily implemented by hardware, have been recognized as a powerful tool for real-time processing and successfully applied widely in various control systems. Particularly, using neural networks for the control of robot manipulators have attracted much attention and various related schemes and methods have been proposed and investigated. In this paper, we make a review of research progress about controlling manipulators by means of neural networks. The problem foundation of manipulator control and the theoretical ideas on using neural network to solve this problem are first analyzed and then the latest progresses on this topic in recent years are described and reviewed in detail. Finally, toward practical applications, some potential directions possibly deserving investigation in controlling manipulators by neural networks are pointed out and discussed.",industry
10.1016/j.jmsy.2018.04.001,Journal,Journal of Manufacturing Systems,scopus,2018-04-01,sciencedirect,Porosity prediction: Supervised-learning of thermal history for direct laser deposition,https://api.elsevier.com/content/abstract/scopus_id/85045401863,"The objective of this study is to investigate the relationship between the melt pool characteristics and the defect occurrence in an as-built additive manufacturing part. One of the major detrimental microstructure properties associated with additive manufacturing (AM) is porosity within final parts. State-of-the-art porosity detection methods focus primarily on post-manufacturing approaches that are susceptible to high cost of process, longer process time, and are incapable of characterizing pores during fabrication. A real-time porosity prediction method is developed using morphological characteristics of the melt pool boundary (i.e., features obtained via functional principal component analysis (FPCA)). A thermal monitoring system is used to capture the time-varying melt pool signal, which are labeled as either pores or normal melt pools by X-ray tomography. Supervised learning methods are utilized to identify the patterns of melt pool images and build a black-box model for the probability distribution of class labels (namely, porosity) based on data characteristics of predictors (e.g., melt pool characteristics). The resultant model does not depend on specific design of specimens with varying material properties; and can be effectively developed as long as thermal-porosity data can be obtained. In the current study, multiple supervised machine learning approaches are used to classify melt pools to predict porosity in a part. Two different accuracy measures are used and numerical experiments show that among the classification approaches used (i.e., Decision Tree (DT), K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Linear Discriminant Analysis (LDA), and Quadratic Discriminant Analysis (QDA)), KNN results in the highest rate of accurately classifying melt pools (98.44%). However, DT results in the lowest rate for incorrectly identifying normal melt pools as pores (0.03%). A comparative study is conducted that compares the performance of supervised learning methods leveraging the proposed morphological model and simple metrics of the melt pool. Numerical experiments show that the morphological model combined with supervised learning techniques vastly outperform the simple melt pool metrics combined with supervised learning techniques (approximately 250% better performance for correctly predicting abnormal melt pools). Our approach may potentially be applied to other AM processes that share similar energy-material interactions (e.g., powder bed fusion, electron beam melting).",industry
10.1016/j.energy.2018.01.159,Journal,Energy,scopus,2018-04-01,sciencedirect,Multiobjective optimization of ethylene cracking furnace system using self-adaptive multiobjective teaching-learning-based optimization,https://api.elsevier.com/content/abstract/scopus_id/85041748366,"The ethylene cracking furnace system is crucial for an olefin plant. Multiple cracking furnaces are used to convert various hydrocarbon feedstocks to smaller hydrocarbon molecules, and the operational conditions of these furnaces significantly influence product yields and fuel consumption. This paper develops a multiobjective operational model for an industrial cracking furnace system that describes the operation of each furnace based on current feedstock allocations, and uses this model to optimize two important and conflicting objectives: maximization of key products yield, and minimization of the fuel consumed per unit ethylene. The model incorporates constraints related to material balance and the outlet temperature of transfer line exchanger. The self-adaptive multiobjective teaching-learning-based optimization algorithm is improved and used to solve the designed multiobjective optimization problem, obtaining a Pareto front with a diverse range of solutions. A real industrial case is investigated to illustrate the performance of the proposed model: the set of solutions returned offers a diverse range of options for possible implementation, including several solutions with both significant improvement in product yields and lower fuel consumption, compared with typical operational conditions.",industry
10.1016/j.ins.2017.08.042,Journal,Information Sciences,scopus,2018-04-01,sciencedirect,Task aware hybrid DVFS for multi-core real-time systems using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85028388448,"There have been renewed interest in embedded battery powered devices due to their widespread applications in sectors such as automotive, industrial, and health care. In order to reduce energy consumption and enhance battery life, dynamic voltage and frequency scaling (DVFS) techniques have been applied to processors (one of the most energy consuming components). In order to keep pace with advancements in fabrication technologies, it is important to scale voltage and frequency intelligently; otherwise, DVFS techniques could result in a higher energy consumption. In our previous work, depending on the execution characteristics of real-time tasks, DVFS decisions were made using machine learning method in unicore processors. We also used learning-based approach to select the best real-time DVFS technique for the situation from a set of techniques and proposed a framework that integrates the selection of various scheduling policies and the optimization of existing real-time DVFS techniques in multi-core processors. In this paper, we describe the design of the framework to make an effective learning-based DVFS system, and demonstrate the utility of the generalized learning-based framework using experiments on multi-core real-time systems for both synthetic tasks and benchmark tasks from real applications. Our findings show that the framework is computationally lightweight and effective in reducing energy consumption.",industry
10.1016/j.petlm.2017.11.003,Journal,Petroleum,scopus,2018-03-01,sciencedirect,Application of artificial intelligence to forecast hydrocarbon production from shales,https://api.elsevier.com/content/abstract/scopus_id/85044139353,"Artificial intelligence (AI) methods and applications have recently gained a great deal of attention in many areas, including fields of mathematics, neuroscience, economics, engineering, linguistics, gaming, and many others. This is due to the surge of innovative and sophisticated AI techniques applications to highly complex problems as well as the powerful new developments in high speed computing. Various applications of AI in everyday life include machine learning, pattern recognition, robotics, data processing and analysis, etc. The oil and gas industry is not behind either, in fact, AI techniques have recently been applied to estimate PVT properties, optimize production, predict recoverable hydrocarbons, optimize well placement using pattern recognition, optimize hydraulic fracture design, and to aid in reservoir characterization efforts. In this study, three different AI models are trained and used to forecast hydrocarbon production from hydraulically fractured wells. Two vastly used artificial intelligence methods, namely the Least Square Support Vector Machine (LSSVM) and the Artificial Neural Networks (ANN), are compared to a traditional curve fitting method known as Response Surface Model (RSM) using second order polynomial equations to determine production from shales. The objective of this work is to further explore the potential of AI in the oil and gas industry. Eight parameters are considered as input factors to build the model: reservoir permeability, initial dissolved gas-oil ratio, rock compressibility, gas relative permeability, slope of gas oil ratio, initial reservoir pressure, flowing bottom hole pressure, and hydraulic fracture spacing. The range of values used for these parameters resemble real field scenarios from prolific shale plays such as the Eagle Ford, Bakken, and the Niobrara in the United States. Production data consists of oil recovery factor and produced gas-oil ratio (GOR) generated from a generic hydraulically fractured reservoir model using a commercial simulator. The Box-Behnken experiment design was used to minimize the number of simulations for this study. Five time-based models (for production periods of 90 days, 1 year, 5 years, 10 years, and 15 years) and one rate-based model (when oil rate drops to 5 bbl/day/fracture) were considered. Particle Swarm Optimization (PSO) routine is used in all three surrogate models to obtain the associated model parameters. Models were trained using 80% of all data generated through simulation while 20% was used for testing of the models. All models were evaluated by measuring the goodness of fit through the coefficient of determination (R2) and the Normalized Root Mean Square Error (NRMSE). Results show that RSM and LSSVM have very accurate oil recovery forecasting capabilities while LSSVM shows the best performance for complex GOR behavior. Furthermore, all surrogate models are shown to serve as reliable proxy reservoir models useful for fast fluid recovery forecasts and sensitivity analyses.",industry
10.1016/j.dss.2018.01.011,Journal,Decision Support Systems,scopus,2018-03-01,sciencedirect,Unsupervised tip-mining from customer reviews,https://api.elsevier.com/content/abstract/scopus_id/85042649396,"In recent years, large review-hosting platforms have extended their functionality to allow their users to submit tips: short pieces of text that deliver valuable insight on a specific aspect of the reviewed business. These tips are meant to serve as a concise source of information that complements the often overwhelming number of customer reviews. Recent work has tackled the problem of automatically generating tips by mining review text. The motivation for this effort is to obtain tips for businesses or business aspects that have been overlooked by users. Another motivating factor is the quality of the user-submitted tips, which often provide trivial or redundant information. Existing tip-mining methods are limited by a reliance on training data, which is unlikely to be available and is also very costly to create for different domains. In this work, we present TipSelector, a completely unsupervised algorithm that delivers high quality-tips without the need for annotated training data. We verify the efficacy of TipSelector via an evaluation that includes real data from the hospitality industry and comparisons with the state-of-the-art. A secondary contribution of our work is a method for automatically evaluating tip-mining algorithms without humans in the loop. As we demonstrate in our experiments, this method can be used to enable large-scale evaluations and complement the user studies that are typically used for this purpose.",industry
10.1016/j.measurement.2017.12.026,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-03-01,sciencedirect,NARX ANN-based instrument fault detection in motorcycle,https://api.elsevier.com/content/abstract/scopus_id/85039147782,"In the context of motorcycle, we can assist to an increasing interest toward semi-active suspension control systems able to improve both the comfort and the passenger’s safety in both racing and original equipment manufacturer applications. Such systems implement suitable strategies based on the measure of several quantities, among which the relative velocity of the wheels respect to the vehicle body with the aim of regulating in real-time the damping forces. The actual effectiveness of such strategy strongly depends on the reliability and accuracy of the data measured by the sensors involved in the control loop. Due to their simplicity and good performance in terms of linearity, the most used sensors for suspension displacement measurements are based on linear potentiometers but such kind of sensors suffer of wear and tear and aging higher than the other sensors involved in the control loop strategy. As a consequence, the fault detection of such sensor is strongly recommended to avoid wrong and in some cases dangerous suspension behaviors.
                  To this aim, in this paper a Fault Detection scheme for the rear suspension stroke sensor is designed and verified. The residual generation is based on the use of a Nonlinear Auto-Regressive with eXogenous inputs (NARX) network which is able to effectively take into account for the system nonlinearity. Experimental results have proven the good promptness and reliability of the scheme in detecting different kind of faults as “un-calibration faults” (e.g. due to slight variations of the input/output sensor curve), “hold-faults” (e.g. due to the breaking of the potentiometer cursor), “open circuit” and “short circuit” (e.g. due to electrical interruptions and short circuits, respectively).
                  In addition, to verify the feasibility of a real-time implementation on actual processing units employed in such context, the scheme has been successfully implemented on a microcontroller STM32 based on the general-purpose ARM-M4 architecture. The validation tests and analysis have shown that the proposed Instrument Fault Detection scheme could be successfully developed on these kind of architectures by assuring a real-time operating.",industry
10.1016/j.cose.2017.11.014,Journal,Computers and Security,scopus,2018-03-01,sciencedirect,Intelligent agents defending for an IoT world: A review,https://api.elsevier.com/content/abstract/scopus_id/85038807783,"Transition to the Internet of Things (IoT) is progressing without realization. In light of this securing traditional systems is still a challenging role requiring a mixture of solutions which may negatively impact, or simply, not scale to a desired operational level. Rule and signature based intruder detection remains prominent in commercial deployments, while the use of machine learning for anomaly detection has been an active research area. Behavior detection means have also benefited from the widespread use of mobile and wireless applications. For the use of smart defense systems we propose that we must widen our perspective to not only security, but also to the domains of artificial intelligence and the IoT in better understanding the challenges that lie ahead in hope of achieving autonomous defense. We investigate how intruder detection fits within these domains, particularly as intelligent agents. How current approaches of intruder detection fulfill their role as intelligent agents, the needs of autonomous action regarding compromised nodes that are intelligent, distributed and data driven. The requirements of detection agents among IoT security are vulnerabilities, challenges and their applicable methodologies. In answering aforementioned questions, a survey of recent research work is presented in avoiding refitting old solutions into new roles. This survey is aimed toward security researchers or academics, IoT developers and information officers concerned with the covered areas. Contributions made within this review are the review of literature of traditional and distributed approaches to intruder detection, modeled as intelligent agents for an IoT perspective; defining a common reference of key terms between fields of intruder detection, artificial intelligence and the IoT, identification of key defense cycle requirements for defensive agents, relevant manufacturing and security challenges; and considerations to future development. As the turn of the decade draws nearer we anticipate 2020 as the turning point where deployments become common, not merely just a topic of conversation but where the need for collective, intelligent detection agents work across all layers of the IoT becomes a reality.",industry
10.1016/j.microrel.2017.11.002,Journal,Microelectronics Reliability,scopus,2018-02-01,sciencedirect,Prognostics of aluminum electrolytic capacitors using artificial neural network approach,https://api.elsevier.com/content/abstract/scopus_id/85033701102,"In this work, an effort is being made to monitor the condition of in-circuit aluminum electrolytic capacitor using artificial neural network (ANN). Recent industrial surveys on the reliability of power electronic systems shows that most of faults occur due to the wear out of aluminum electrolytic capacitors and thermal stress is the major cause for its parametric degradation. The condition of target capacitors can be estimated by monitoring variation in equivalent series resistance (ESR) from the initial pristine state value. ANN is used to estimate ESR of pristine and weak target capacitors at the test conditions. The data set for training and testing of proposed back-propagation trained artificial neural network are experimentally obtained from the developed test bed. Using the test bed, target capacitors are subjected to different operating frequency and temperature in the output section of DC/DC buck converter circuit to determine the effect of variation in electrical and thermal stress on ESR value. After off-line training, the proposed ANN is implemented using National Instruments LabVIEW software. A low cost microcontroller is programmed for real time data acquisition of target capacitors and the serial transmission of acquired dataset to the LabVIEW software installed at host computer. The performance of the proposed method is evaluated in real time by comparing the resulting ESR with the experimental values of in-circuit target capacitors. The proposed ANN, once trained properly, can be used for different circuits and in different operating conditions because of its generalization capability.",industry
10.1016/j.engappai.2017.10.016,Journal,Engineering Applications of Artificial Intelligence,scopus,2018-02-01,sciencedirect,Time-adaptive support vector data description for nonstationary process monitoring,https://api.elsevier.com/content/abstract/scopus_id/85033363759,"Statistical process control techniques are widely used for quality control to monitor the stability of a process over time. In modern manufacturing systems with complex and variable processes, appropriate control chart techniques that can efficiently address nonnormal processes are required. Furthermore, in real manufacturing environments, process changes occur frequently because of various factors such as product and setpoint changes, catalyst degradation, seasonal variations, and sensor drift. However, conventional control chart schemes cannot necessarily accommodate all possible future conditions of a process because they are formulated based on information recorded in the early stages of the process. Several attempts have been made to accommodate process changes over time. In the present paper, we propose a time-adaptive support vector data description-based control chart that can address not only nonnormal in-control observations, but also time-varying processes. The effectiveness and applicability of the proposed chart was demonstrated through experiments with simulated data and real data from the metal frame process in mobile device manufacturing.",industry
10.1016/j.patcog.2017.09.042,Journal,Pattern Recognition,scopus,2018-02-01,sciencedirect,Active garment recognition and target grasping point detection using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85030791138,"Identification and bi-manual handling of deformable objects, like textiles, is one of the most challenging tasks in the field of industrial and service robotics. Their unpredictable shape and pose makes it very difficult to identify the type of garment and locate the most relevant parts that can be used for grasping. In this paper, we propose an algorithm that first, identifies the type of garment and second, performs a search of the two grasping points that allow a robot to bring the garment to a known pose. We show that using an active search strategy it is possible to grasp a garment directly from predefined grasping points, as opposed to the usual approach based on multiple re-graspings of the lowest hanging parts. Our approach uses a hierarchy of three Convolutional Neural Networks (CNNs) with different levels of specialization, trained both with synthetic and real images. The results obtained in the three steps (recognition, first grasping point, second grasping point) are promising. Experiments with real robots show that most of the errors are due to unsuccessful grasps and not to the localization of the grasping points, thus a more robust grasping strategy is required.",industry
10.1016/j.neucom.2017.08.036,Journal,Neurocomputing,scopus,2018-01-31,sciencedirect,Data-driven model-free slip control of anti-lock braking systems using reinforcement Q-learning,https://api.elsevier.com/content/abstract/scopus_id/85029168035,"This paper proposes the design and implementation of a model-free tire slip control for a fast and highly nonlinear Anti-lock Braking System (ABS). A reinforcement Q-learning optimal control approach is inserted in a batch neural fitted scheme using two neural networks to approximate the value function and the controller, respectively. The transition samples required for learning high performance control can be collected by interacting with the process either by online exploiting the current iteration controller (or policy) under an ε-greedy exploration strategy, or by using data collected under any other controller that is capable of ensuring efficient exploration of the action-state space. Both approaches are highlighted in the paper. Fortunately, the ABS process fits this type of learning-by-interaction because it does not need an initial stabilizing controller. The validation case studies conducted on a real laboratory setup reveal that high control system performance can be achieved using the proposed approaches. Insightful comments on the observed control behavior are offered along with performance comparisons with several types of model-based and model-free controllers including relay, model-based optimal PI, an original model-free neural network state-feedback VRFT controller and a model-free neural network adaptive actor-critic one. With the ability to improve control performance starting from different supervisory controllers or to learn high performance controllers from scratch, the proposed Q-learning optimal control approach proves its performance in a wide operating range and is therefore recommended to its industrial application on ABS.",industry
10.1016/j.chemolab.2017.12.005,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2018-01-15,sciencedirect,A new reconstruction-based auto-associative neural network for fault diagnosis in nonlinear systems,https://api.elsevier.com/content/abstract/scopus_id/85037701407,"Auto-associative neural network (AANN) is a typical nonlinear principal component analysis method, which is widely used in industry for fault diagnosis purposes, especially in nonlinear systems. However, the basic AANN often suffers from “smearing effects” problems that may lead to misdiagnosis, particularly with regards to the complex faults involving multiple variables. In this work, a new reconstruction-based AANN (RBAANN) method is proposed to enhance the capacity of fault diagnosis. In RBAANN, a generic derivative equation is developed to investigate the effects of AANN model inputs on the prediction error between model inputs and outputs. Based on the derivative equation, the reconstruction-based index for single or multiple variables, which is defined as the minimum prediction error, is obtained by tuning the corresponding model inputs iteratively. However, without the prior knowledge of the real faulty variables, all the possible variable sets need to be evaluated by the reconstruction-based index, and this may result in an exhaustive search and cause a huge computational burden. Thus, a branch and bound algorithm is introduced into RBAANN to solve the variable selection problem. Finally, an efficient fault diagnosis strategy by integrating RBAANN and branch and bound algorithm (BAB-RBAANN) is implemented to further pinpoint the source of the detected faults. This BAB-RBAANN method can handle both single and multiple variable(s) faults for nonlinear systems without prior knowledge efficiently. The effectiveness of the proposed methods is evaluated on a validation example and an industrial example. Comparisons with other methods, including principal component analysis techniques, are also presented.",industry
10.1016/j.knosys.2017.11.002,Journal,Knowledge-Based Systems,scopus,2018-01-15,sciencedirect,Knowledge discovery of consensus and conflict interval-based temporal patterns: A novel group decision approach,https://api.elsevier.com/content/abstract/scopus_id/85034247510,"Temporal pattern mining problems, developed from sequential pattern mining problems, have recently been discussed frequently regarding the gathering of temporal sequences and aggregating them in order to gain insight into consensus decision-making. Existing temporal pattern mining problems reveal only point-based relations; however, in reality, several interval-based circumstances exist, which enable precisely describing temporal relationships. Practical applications include the order and duration of investors purchasing stocks and portfolio management. This study proposes a novel model and its associated algorithm for identifying consensus and conflict patterns from user-provided subjective interval-based temporal sequences. We conducted an experiment on stock investments in the semiconductor industry by drawing on collected authentic datasets and user ratings to demonstrate the model’s effectiveness. The experimental results reveal six consensus patterns and one pair of conflict patterns from the participants’ subjective investment intuitions, which is consistent with common sense concerning the semiconductor stock market.",industry
10.1016/B978-0-12-813314-9.00011-6,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Unsupervised anomaly detection for high dimensional data-An exploratory analysis,https://api.elsevier.com/content/abstract/scopus_id/85081928867,"Context: Anomaly detection is a crucial area engaging the attention of many researchers. It is a process of finding an unusual point or pattern in a given dataset. It is useful in many real time applications such as industry damage detection, detection of fraudulent usage of credit card, detection of failures in sensor nodes, detection of abnormal health and network intrusion detection. Algorithms proposed for anomaly detection in low dimensional data are not suitable for high dimensional data due to the well-known “dimensionality curses”.
               
                  Motivation: To tackle this issue, a plethora of algorithms dedicated to high dimensional data has been proposed. However, unsupervised algorithms have many problems and challenges, as there is no predefined data label to predict anomaly.
               
                  Objective: We aim at providing a complete view of unsupervised anomaly detection for high dimensional data which gives a clear perception of the concept.
               
                  Contribution: In this paper, existing algorithms and real time applications of unsupervised anomaly detection for high dimensional data have been studied. Evaluation measures, datasets and tools used by different authors have been discussed in detail. In addition, a hybrid framework of unsupervised anomaly detection algorithm called DBN–K means applied two different disease dataset is also proposed.
               
                  Future work: As future work, the proposed framework could be implemented and analyzed in other applications. High dimensional streaming data is another interesting area for further investigation, following this research work.",industry
10.1016/j.procir.2018.01.036,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,"Intuitive robot programming through environment perception, augmented reality simulation and automated program verification",https://api.elsevier.com/content/abstract/scopus_id/85061975291,"The increasing complexity of products and machines as well as short production cycles with small lot sizes present great challenges to production industry. Both, the programming of industrial robots in online mode using hand-held control devices or in offline mode using text-based programming requires specific knowledge of robotics and manufacturer-dependent robot control systems. In particular for small and medium-sized enterprises the machine control software needs to be easy, intuitive and usable without time-consuming learning steps, even for employees with no in-depth knowledge of information technology. To simplify the programming of application programs for industrial robots, we extended a cloud-based, task-oriented robot control system with environment perception and plausibility check functions. For the environment perception a depth camera and pointcloud processing hardware were installed. We detect objects located in the robot’s workspace by pointcloud processing with ROS and the PCL and add them to the augmented reality user interface of the robot control. The combination of process knowledge from task-oriented application programming and information about available workpieces from automated image processing enables a plausibility check and verification of the robot program before execution. After a robot program has been approved by the plausibility check, it is tested in an augmented reality simulation for collisions with the detected objects before deployment to the physical robot hardware. Experiments were carried out to evaluate the effectiveness of the developed extensions and confirmed their functionality.",industry
10.1016/j.procir.2018.09.067,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,A Conceptual Design for Smell Based Augmented Reality: Case Study in Maintenance Diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85059916374,"The trend of Industry 4.0 encourages the next generation of manufacturing to be flexible, intelligent, and interoperable. The implementations of the Artificial Intelligence (AI) technology could potentially enhance maintenance in efficiency, and accuracy. However, it will not be a substitution to the human operator’s flexibility, decision-making and information received by the natural five senses. Augmented reality (AR) is commonly understood as a technology that overlays virtual information onto the existing environment to provide users a new and improved experience to assist their daily activities. However, AR can be used to enhance all human five senses rather than just overlay virtual imagery. In this paper, a design and a practical plan of smell augmentation for diagnosis is initialised, via a case study in maintenance. The aim of this paper is to evaluate the feasibilities, identify challenges, and summarise initial results of overlaying information through smell augmentations.",industry
10.1016/j.promfg.2018.04.009,Conference Proceeding,Procedia Manufacturing,scopus,2018-01-01,sciencedirect,Mixed Reality in Learning Factories,https://api.elsevier.com/content/abstract/scopus_id/85052906978,"Supported by rapid technological development, mixed reality (MR) applications are increasingly deployed in industrial practice. In manufacturing, MR can be utilized for information visualization, remote collaboration, human-machine-interfaces, design tools and education and training. This development makes new demands on learning factories in two major fields: One is the empowerment of users to work with MR in industrial applications. The second field is the utilization of the potential of MR for teaching and learning in learning factories. A great potential lies in the new possibilities of connecting digital content with the physical world. To analyze the potential applications of MR in learning factories in a structured way, an overview of potential MR applications based on the reality-virtuality continuum is presented with an analysis of case studies of applications in a learning factory including a mixed-reality-hackathon.",industry
10.1016/j.promfg.2018.04.026,Conference Proceeding,Procedia Manufacturing,scopus,2018-01-01,sciencedirect,Design and implementation of a low cost RFID track and trace system in a learning factory,https://api.elsevier.com/content/abstract/scopus_id/85052890798,"The factories of the future will make use of actuators, sensors and cyber-physical systems (CPS) to provide an environment in which human beings, machines, and resources will communicate as in a social network. In such a network, communication between various “objects” relay the current state of the physical world. Business decisions are made using the information and it is therefore critical that this information is accurate and in real-time. Information flow is a key enabler of such future factories. Industrial engineers, as designers and improvement agents of such factories of the future, will need to develop better skills in various aspects of data analytics and information communication technologies. This paper describes the development and implementation of a low cost RFID track and trace system (by students) for application in a Learning Factory for teaching undergraduate industrial engineering students key concepts related to Industry 4.0 and “smart factories”. The benefit of this system is not only a demonstrator to be used in the Learning Factory, but also can be used to teach students in a “learning by doing” fashion critical skills related to real time tracking in a manufacturing environment. The system also demonstrates potential low cost implementation of such technologies in SME’s.",industry
10.1016/j.ifacol.2018.08.421,Conference Proceeding,,scopus,2018-01-01,sciencedirect,A Multi Agent System architecture to implement Collaborative Learning for social industrial assets,https://api.elsevier.com/content/abstract/scopus_id/85052888258,"The ‘Industrial Internet of Things’ aims to connect industrial assets with one another and benefit from the data that is generated, and shared, among these assets. In recent years, the extensive instrumentation of machines and the advancements in Information Communication Technologies are re-shaping the role of assets in our industrial systems. An emerging concept here is that of ‘social assets’: assets that collaborate with each other in order to improve system optimisation. Cyber-Physical Systems (CPSs) are formed by embedding the assets with computers, or microcontrollers, which run real-time decision-making algorithms over the data originating from the asset. These are known as the ‘Digital Twins’ of the assets, and form the backbone of social assets. It is essential to have an architecture which enables a seamless integration of these technological advances for an industry. This paper proposes a Multi Agent System (MAS) architecture for collaborative learning, and presents the findings of an implementation of this architecture for a prognostics problem. Collaboration among assets is performed by calculating inter-asset similarity during operating condition to identify ‘friends’ and sharing operational data within these clusters of friends. The architecture described in this paper also presents a generic model for the Digital Twins of assets. Prognostics is demonstrated for the C-MAPSS turbofan engine degradation simulated data-set (Saxena and Goebel (2008)).",industry
10.1016/j.promfg.2018.07.152,Conference Proceeding,,scopus,2018-01-01,sciencedirect,Worker Activity Recognition in Smart Manufacturing Using IMU and sEMG Signals with Convolutional Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85052862050,"In a smart manufacturing system involving workers, recognition of the worker’s activity can be used for quantification and evaluation of the worker’s performance, as well as to provide onsite instructions with augmented reality. In this paper, we propose a method for activity recognition using Inertial Measurement Unit (IMU) and surface electromyography (sEMG) signals obtained from a Myo armband. The raw 10-channel IMU signals are stacked to form a signal image. This image is transformed into an activity image by applying Discrete Fourier Transformation (DFT) and then fed into a Convolutional Neural Network (CNN) for feature extraction, resulting in a high-level feature vector. Another feature vector representing the level of muscle activation is evaluated with the raw 8-channel sEMG signals. Then these two vectors are concatenated and used for work activity classification. A worker activity dataset is established, which at present contains 6 common activities in assembly tasks, i.e., grab tool/part, hammer nail, use power-screwdriver, rest arm, turn screwdriver, and use wrench. The developed CNN model is evaluated on this dataset and achieves 98% and 87% recognition accuracy in the half-half and leave-one-out experiments, respectively.",industry
10.1016/j.procs.2018.07.108,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Ambience Inhaling: Speech Noise Inhaler in Mobile Robots using Deep Learning,https://api.elsevier.com/content/abstract/scopus_id/85051344062,"Audio based, machine learning human-computer interface with speech recognition systems performs sensibly well with the human voice under clean ambience, but become frail in applied technological implementation involving real-life interface. In mobile robotic systems, the speech machines are normally retrained with new changing acoustic ambience conditions are to be met. To inhale, classify, and track the real-world ambience noise with the new changing acoustic condition, we introduce an Ambience Inhaling (AI) framework in this article. This framework of an AI is to seek out complete noise information from speech data, in contrast with noise-nature discovery. Our proposed framework uses a deep convolutional neural network (CNN) based learning for classification with speech spectrogram patch segments, including a hybrid Harold Hotelling's T-square algorithm with Bayesian statistics for segmentation analysis. We use a symposium presentation-ambience as a test platform. In the symposium presentation-ambience, noise modeling is done with n-gram language having the parameter of n = 2. The impulsive or short-term noise which is superimposed with long-term noise caused degradation in classification. This degradation caused the classification errors. The provision of decision was made. The Gaussian mixture model and hidden Markova model are used with noise-only and noisy speech respectively. Time and frequency pooling are used with spectrogram also. The classification scores of 62.26%, 65.89%, and 69.12% are achieved with 5, 10 and 15 CNN filters respectively. As a significance, an AI is efficient and innovative.",industry
10.1016/B978-0-444-64241-7.50087-2,Book Series,Computer Aided Chemical Engineering,scopus,2018-01-01,sciencedirect,Reinforcement Learning Applied to Process Control: A Van der Vusse Reactor Case Study,https://api.elsevier.com/content/abstract/scopus_id/85050599810,"With recent advances in industrial automation, data acquisition, and successful applications of Machine Learning methods to real-life problems, data-based methods can be expected to grow in use within the process control community in the near future. Model-based control methods rely on accurate models of the process to be effective. However, such models may be laborious to obtain and, even when available, the optimization problem underlying the online control problem may be too computationally demanding. Furthermore, the process degradation with time imposes that the model should be periodically updated to stay reliable. One way to address these drawbacks is through the merging of Reinforcement Learning (RL) techniques into the classical process control framework. In this work, a methodology to tackle the control of nonlinear chemical processes with RL techniques is proposed and tested on the wellknown benchmark problem of the non-isothermal CSTR with the Van de Vusse reaction. The controller proposed herein is based on the implementation of a policy that associates each state of the process to a certain control action. This policy is directly deduced from a measure of the expected performance gain, given by a value function dependent on the states and actions. In other words, in a given state, the action that provides the highest expected performance gain is chosen and implemented. The value function is approximated by a neural network that can be trained with pre-simulated data and adapted online with the continuous inclusion of new process data through the implementation of an RL algorithm. The results show that the proposed adaptive RLbased controller successfully manages to control and optimize the Van de Vusse reactor against unmeasured disturbances.",industry
10.1016/j.ifacol.2018.06.356,Conference Proceeding,,scopus,2018-01-01,sciencedirect,Design Principles Behind the Construction of an Autonomous Laboratory-Scale Drilling Rig,https://api.elsevier.com/content/abstract/scopus_id/85050080748,"In recent years, hot topics such as digitalization, machine learning, digital twin and big data have evolved from being envisions on the paper to state of art solutions, expected to revolutionize drilling efficiency in the industry. Drilling automation tomorrow is all about exploiting the current state of technologies available to the entire operation of drilling a well. Not only can drilling automation limit costs and reduce the risk to rig personnel and the environment, but they also give access to locations of considerable potential that previously have been regarded unsafe or uneconomical to operate in. There are however some challenges in keeping up with the ever-increasing pace of the development. For one, testing of novel and innovative solutions is often very expensive because of non-productive rig time during implementation, trial runs and data evaluation. Also, the modern technologies require extensive R&D before on-site testing can even commence. While on land-rigs, some of these costs and risks can be greatly minimized, many offshore solutions lack that luxury. This paper presents an overview of the design principles that go into the construction of a fully autonomous laboratory-scale drilling rig at the University of Stavanger. It aims at describing 1) the engineering principles involved to resemble full-scale drilling operations on the laboratory scale, 2) design considerations and components, 3) component requirements for the rig, 4) control system algorithms for real-time optimization of drilling parameters and detection and handling of drilling anomalies, 5) development of drilling models (drill string dynamics, bit-vibration, etc.) and 6) benefits and future work with the laboratory-scale system. Some of the concepts that are presented in this paper have yet to be implemented during 2018.",industry
10.1016/j.procir.2018.03.022,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,Fostering Robust Human-Robot Collaboration through AI Task Planning,https://api.elsevier.com/content/abstract/scopus_id/85049587790,"Recent advances in Artificial Intelligence (AI) are facilitating the deployment of intelligent systems in manufacturing. In Human-Robot Collaboration (HRC), industrial robots offer accuracy and efficiency while humans guarantee both experience and specialized and not replaceable skills. The seamless coordination of such different abilities constitutes one of the current challenges. This paper presents a dynamic task sequencing system for robust HRC developed within a EU-funded project. The proposed solution uses AI techniques to deal with the temporal variance entailed by the active presence of humans as well as to dynamically adapt task plans according to actual behavior of the pair human-worker/robot. The tool has been deployed in a real pilot plant.",industry
10.1016/j.procir.2018.03.087,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,Transfer-Learning: Bridging the Gap between Real and Simulation Data for Machine Learning in Injection Molding,https://api.elsevier.com/content/abstract/scopus_id/85049564787,"In the field of manufacturing process planning and initial operation of machines, machine parameters are often provided from few either expensive and time-consuming experiments or faster but less accurate numerical simulations. Another option is to use machine learning to predict process qualities based on machine parameters. Thereby, transfer learning can overcome the gap between real and simulation data. We evaluated two different approaches based on artificial neural networks, namely soft-start and random initialization, in a real injection molding process. The results show better learning rates and predictions that are more accurate while using fewer experimental data.",industry
10.1016/j.procs.2018.05.113,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Real Time High Performance of Sliding Mode Controlled Induction Motor Drives,https://api.elsevier.com/content/abstract/scopus_id/85049099142,"Several industrial applications demand high performance speed functioning and require new control techniques so as to ensure a fast dynamic response. The present work investigates real time implementation and experimental sliding mode controlled (SMC) induction motor drives (IM). The strategy of sliding mode control is a powerful tool to ensure robustness. Nevertheless, the chattering phenomenon is a major disadvantage for non linear systems. For this purpose, two different types of analysis such as layer boundary methods are implemented in dSPACE 1104 controller board and compared between them in order to obtain the best method to reduce or eliminate chattering phenomenon. An experimental results using dSPACE 1104 based on TMS320F240 DSP are described in this work.",industry
10.1016/j.cirp.2018.04.041,Journal,CIRP Annals,scopus,2018-01-01,sciencedirect,Reinforcement learning for adaptive order dispatching in the semiconductor industry,https://api.elsevier.com/content/abstract/scopus_id/85045954603,"The digitalization of production systems tends to provide a huge amount of data from heterogeneous sources. This is particularly true for the semiconductor industry wherein real time process monitoring is inherently required to achieve a high yield of good parts. An application of data-driven algorithms in production planning to enhance operational excellence for complex semiconductor production systems is currently missing. This paper shows the successful implementation of a reinforcement learning-based adaptive control system for order dispatching in the semiconductor industry. Furthermore, a performance comparison of the learning-based control system with the traditionally used rule-based system shows remarkable results. Since a strict rulebook does not bind the learning-based control system, a flexible adaption to changes in the environment can be achieved through a combination of online and offline learning.",industry
10.1016/j.mfglet.2017.12.013,Journal,Manufacturing Letters,scopus,2018-01-01,sciencedirect,Artificial neural network based framework for cyber nano manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85042371124,"Nanomanufacturing plays an important role for high performance products in several applications. The challenge for fabricating products with nanomaterials is the inability to interconnect and interface with nano/micro manufacturing equipment. This paper presents a framework for cyber nanomanufacturing. Input part designs of nano/micro scale components are evaluated with an artificial neural network (ANN) based smart agent to predict optimal nanomanufacturing processes. An internet-of-things (IoT) based cyber-interface simulator is implemented to simulate real-time machine availability. Further, an application program interface (API) is developed to integrate the ANN smart agent and IoT simulator outcomes to predict dynamic machine allocations in real-time.",industry
10.1016/j.addma.2017.11.009,Journal,Additive Manufacturing,scopus,2018-01-01,sciencedirect,Anomaly detection and classification in a laser powder bed additive manufacturing process using a trained computer vision algorithm,https://api.elsevier.com/content/abstract/scopus_id/85035797198,"Despite the rapid adoption of laser powder bed fusion (LPBF) Additive Manufacturing by industry, current processes remain largely open-loop, with limited real-time monitoring capabilities. While some machines offer powder bed visualization during builds, they lack automated analysis capability. This work presents an approach for in-situ monitoring and analysis of powder bed images with the potential to become a component of a real-time control system in an LPBF machine. Specifically, a computer vision algorithm is used to automatically detect and classify anomalies that occur during the powder spreading stage of the process. Anomaly detection and classification are implemented using an unsupervised machine learning algorithm, operating on a moderately-sized training database of image patches. The performance of the final algorithm is evaluated, and its usefulness as a standalone software package is demonstrated with several case studies.",industry
10.1016/j.ins.2017.09.027,Journal,Information Sciences,scopus,2018-01-01,sciencedirect,Incorporating negative information to process discovery of complex systems,https://api.elsevier.com/content/abstract/scopus_id/85029528097,"The discovery of a formal process model from event logs describing real process executions is a challenging problem that has been studied from several angles. Most of the contributions consider the extraction of a model as a one-class supervised learning problem where only a set of process instances is available. Moreover, the majority of techniques cannot generate complex models, a crucial feature in some areas like manufacturing. In this paper we present a fresh look at process discovery where undesired process behaviors can also be taken into account. This feature may be crucial for deriving process models which are less complex, fitting and precise, but also good on generalizing the right behavior underlying an event log. The technique is based on the theory of convex polyhedra and satisfiability modulo theory (SMT) and can be combined with other process discovery approach as a post processing step to further simplify complex models. We show in detail how to apply the proposed technique in combination with a recent method that uses numerical abstract domains. Experiments performed in a new prototype implementation show the effectiveness of the technique and the ability to be combined with other discovery techniques.",industry
10.1016/j.biosystems.2017.10.001,Journal,BioSystems,scopus,2017-12-01,sciencedirect,Towards a first implementation of the WLIMES approach in living system studies advancing the diagnostics and therapy in personalized medicine,https://api.elsevier.com/content/abstract/scopus_id/85033459793,"The goal of this paper is to advance an extensible theory of living systems using an approach to biomathematics and biocomputation that suitably addresses self-organized, self-referential and anticipatory systems with multi-temporal multi-agents. Our first step is to provide foundations for modelling of emergent and evolving dynamic multi-level organic complexes and their sustentative processes in artificial and natural life systems. Main applications are in life sciences, medicine, ecology and astrobiology, as well as robotics, industrial automation, man-machine interface and creative design. Since 2011 over 100 scientists from a number of disciplines have been exploring a substantial set of theoretical frameworks for a comprehensive theory of life known as Integral Biomathics. That effort identified the need for a robust core model of organisms as dynamic wholes, using advanced and adequately computable mathematics. The work described here for that core combines the advantages of a situation and context aware multivalent computational logic for active self-organizing networks, Wandering Logic Intelligence (WLI), and a multi-scale dynamic category theory, Memory Evolutive Systems (MES), hence WLIMES. This is presented to the modeller via a formal augmented reality language as a first step towards practical modelling and simulation of multi-level living systems. Initial work focuses on the design and implementation of this visual language and calculus (VLC) and its graphical user interface. The results will be integrated within the current methodology and practices of theoretical biology and (personalized) medicine to deepen and to enhance the holistic understanding of life.",industry
10.1016/j.simpat.2015.07.004,Journal,Simulation Modelling Practice and Theory,scopus,2017-12-01,sciencedirect,A reinforcement learning methodology for a human resource planning problem considering knowledge-based promotion,https://api.elsevier.com/content/abstract/scopus_id/84939200331,"This paper addresses a combined problem of human resource planning (HRP) and production-inventory control for a high-tech industry, wherein the human resource plays a critical role. The main characteristics of this resource are the levels of “knowledge” and the learning process. The learning occurs during the production process in which a worker can promote to the upper knowledge level. Workers in upper levels have more productivity in the production. The objective is to maximize the expected profit by deciding on the optimal numbers of workers in various knowledge levels to fulfill both production and training requirement. As taking an action affects next periods’ decisions, the main problem is to find the optimal hiring policy of non-skilled workers in long-time horizon. Thus, we develop a reinforcement learning (RL) model to obtain the optimal decision for hiring workers under the demand uncertainty. The proposed interval-based policy of our RL model, in which for each state there are multiple choices, makes it more flexible. We also embed some managerial issues such as layoff and overtime-working hours into the model. To evaluate the proposed methodology, stochastic dynamic programming (SDP) and a conservative method implemented in a real case study are used. We study all these methods in terms of four criteria: average obtained profit, average obtained cost, the number of new-hired workers, and the standard deviation of hiring policies. The numerical results confirm that our developed method end up with satisfactory results compared to two other approaches.",industry
10.1016/j.cie.2017.09.016,Journal,Computers and Industrial Engineering,scopus,2017-11-01,sciencedirect,Smart operators in industry 4.0: A human-centered approach to enhance operators’ capabilities and competencies within the new smart factory context,https://api.elsevier.com/content/abstract/scopus_id/85029476237,"As the Industry 4.0 takes shape, human operators experience an increased complexity of their daily tasks: they are required to be highly flexible and to demonstrate adaptive capabilities in a very dynamic working environment. It calls for tools and approaches that could be easily embedded into everyday practices and able to combine complex methodologies with high usability requirements. In this perspective, the proposed research work is focused on the design and development of a practical solution, called Sophos-MS, able to integrate augmented reality contents and intelligent tutoring systems with cutting-edge fruition technologies for operators’ support in complex man-machine interactions. After establishing a reference methodological framework for the smart operator concept within the Industry 4.0 paradigm, the proposed solution is presented, along with its functional and non-function requirements. Such requirements are fulfilled through a structured design strategy whose main outcomes include a multi-layered modular solution, Sophos-MS, that relies on Augmented Reality contents and on an intelligent personal digital assistant with vocal interaction capabilities. The proposed approach has been deployed and its training potentials have been investigated with field experiments. The experimental campaign results have been firstly checked to ensure their statistical relevance and then analytically assessed in order to show that the proposed solution has a real impact on operators’ learning curves and can make the difference between who uses it and who does not.",industry
10.1016/j.xphs.2017.06.017,Journal,Journal of Pharmaceutical Sciences,scopus,2017-11-01,sciencedirect,A Formulation Development Approach to Identify and Select Stable Ultra–High-Concentration Monoclonal Antibody Formulations With Reduced Viscosities,https://api.elsevier.com/content/abstract/scopus_id/85027448238,"High protein concentration formulations are required for low-volume administration of therapeutic antibodies targeted for subcutaneous, self-administration by patients. Ultra-high concentrations (≥150 mg/mL) can lead to dramatically increased solution viscosities, which in turn can lead to stability, manufacturing, and delivery challenges. In this study, various categories and individual types of pharmaceutical excipients and other additives (56 in total) were screened for their viscosity reducing effects on 2 different mAbs. The physicochemical stability profile, as well as viscosity ranges, of several candidate antibody formulations, identified and designed based on the results of the excipient screening, were evaluated over a 6-month time period under accelerated and real-time storage conditions. In addition to reducing the solution viscosities to acceptable levels for parenteral administration (using currently available and acceptable delivery devices), the candidate formulations did not result in notable losses of physicochemical stability of the 2 antibodies on storage for 6 months at 25°C. The experiments described here demonstrate the feasibility of a formulation development and selection approach to identify candidate high-concentration antibody formulations with viscosities within pharmaceutically acceptable ranges that do not adversely affect their physicochemical storage stability.",industry
10.1016/j.compind.2017.06.009,Journal,Computers in Industry,scopus,2017-11-01,sciencedirect,A comprehensive health assessment framework to facilitate IoT-assisted smart workouts: A predictive healthcare perspective,https://api.elsevier.com/content/abstract/scopus_id/85021057118,"Enormous potential of Internet of Things (IoT) Technology has made it feasible to perceive and analyze real time health conditions in ubiquitous manner. Moreover, incorporation of IoT in healthcare industry has led researchers around the world to develop smart applications like mobile healthcare, health-aware recommendations, and intelligent healthcare systems. Inspired from these aspects, this research presents an intelligent healthcare framework based on IoT Technology to provide ubiquitous healthcare to person during his/her workout sessions. The intelligence of the presented framework lies with its ability to analyze real time health conditions during workouts and predict probabilistic health state vulnerability. For predictive purpose, the proposed framework indulges the utilization of Artificial Neural Network (ANN) model, which is comprised of three phases namely, monitor, learn, and predict. In addition to this, the presented framework is supported by a mathematical foundation to predict probabilistic vulnerability, in terms of Probabilistic State of Vulnerability (PSoV). In order to determine the validity and applicability of the proposed framework, experiments were performed where 5 people with different attributes are monitored for 14 days using numerous smart sensors. Results, upon comparison with various state-of-the-art techniques, depict that the proposed system is superior in performance and is highly effective in delivering healthcare services during workouts.",industry
10.1016/j.neucom.2017.01.077,Journal,Neurocomputing,scopus,2017-10-11,sciencedirect,Teaching robots to do object assembly using multi-modal 3D vision,https://api.elsevier.com/content/abstract/scopus_id/85012868996,"The motivation of this paper is to develop an intelligent robot assembly system using multi-modal vision for next-generation industrial assembly. The system includes two phases where in the first phase human beings demonstrate assembly to robots and in the second phase robots detect objects, plan grasps, and assemble objects following human demonstration using AI searching. A notorious difficulty to implement such a system is the bad precision of 3D visual detection. This paper presents multi-modal approaches to overcome the difficulty: It uses AR markers in the teaching phase to detect human operation, and uses point clouds and geometric constraints in the robot execution phase to avoid unexpected occlusion and noises. The paper presents several experiments to examine the precision and correctness of the approaches. It demonstrates the applicability of the approaches by integrating them with graph model-based motion planning, and by executing the results on industrial robots in real-world scenarios.",industry
10.1016/j.jmsy.2017.08.003,Journal,Journal of Manufacturing Systems,scopus,2017-10-01,sciencedirect,On-line self-adaptive framework for tailoring a neural-agent learning model addressing dynamic real-time scheduling problems,https://api.elsevier.com/content/abstract/scopus_id/85030762400,"The dynamic nature and time-varying behavior of actual environments provide serious challenges for learning models. Thus, changes may deteriorate the constructed control policy over time, which requires permanent adaptation strategies. Changes usually appear as an evolution in the relationship between instance variables composing stream data, known in machine learning under the term concept drift. Several adaptation strategies have been performed to tackle concept drifting data streams, always assuming that arrived instances are labeled, either completely or partially. However, this assumption is violated in many application areas, especially in the manufacturing field. We propose, in this paper, a new framework called Labeling Extraction from the current Model (LEM). LEM is adapted to retrieve learning labels, relying uniquely on unlabeled received instances and without any external supervision, which has never been previously addressed. Hence, to the best of our knowledge, there has been no effort addressing scheduling manufacturing problems for adaptation to data streams with concept drifts. Experiments are conducted to show the effectiveness of LEM. The obtained results demonstrate the ability of LEM to maintain the stability and efficiency of the control policy approximated by the learning model, by significantly improving its prediction performance, compared to its use without adaptation.",industry
10.1016/j.ejor.2017.02.034,Journal,European Journal of Operational Research,scopus,2017-09-16,sciencedirect,Automatic synthesis of constraints from examples using mixed integer linear programming,https://api.elsevier.com/content/abstract/scopus_id/85015642159,"Constraints form an essential part of most practical search and optimization problems, and are usually assumed to be given. However, there are plausible real-world scenarios in which constraints are not known or can be only approximated, for instance when the process in question is complex and/or noisy. To address such problems, we propose a method that synthesizes constrains from examples of feasible and infeasible solutions. The method can produce linear, quadratic and trigonometric constraints that are guaranteed to separate the feasible and infeasible regions and minimize the number of terms involved. The synthesized constraints are represented symbolically and can be used to simulate, predict or optimize the original process. We assess empirically several characteristics of the method on three benchmarks, in particular the fidelity and the complexity of the synthesized constraints with respect to the actual constraints. We also demonstrate its application to a real-world process of concrete manufacturing. Experiments demonstrate that the method is capable of producing human-readable constraints that reflect well the underlying process and can be used to simulate it.",industry
10.1016/j.asoc.2017.04.049,Journal,Applied Soft Computing Journal,scopus,2017-09-01,sciencedirect,Quadratic-radial-basis-function-kernel for classifying multi-class agricultural datasets with continuous attributes,https://api.elsevier.com/content/abstract/scopus_id/85018391133,"Classification of agricultural data such as soil data and crop data is significant as it allows the stakeholders to make meaningful decisions for farming. Soil classification aids farmers in deciding the type of crop to be sown for a particular type of soil. Similarly, wheat variety classification assists in selecting the right type of wheat for a particular product. Current methods used for classifying agricultural data are mostly manual. These methods involve agriculture field visits and surveys and are labor-intensive, expensive, and prone to human error. Recently, data mining techniques such as decision trees, k-nearest neighbors (k-NN), support vector machine (SVM), and Naive Bayes (NB) have been used in classification of agricultural data such as soil, crops, and land cover. The resulting classification aid the decision making process of government organizations and agro-industries in the field of agriculture. SVM is a popular approach for data classification. A recent study on SVM highlighted the fact that using multiple kernels instead of a single kernel would lead to better performance because of the greater learning and generalization power. In this work, a hybrid kernel based support vector machine (H-SVM) is proposed for classifying multi-class agricultural datasets having continuous attributes. Genetic algorithm (GA) or gradient descent (GD) methods are utilized to select the SVM parameters C and γ. The proposed kernel is called the quadratic-radial-basis-function kernel (QRK) and it combines both quadratic and radial basis function (RBF) kernels. The proposed classifier has the ability to classify all kinds of multi-class agricultural datasets with continuous features. Rigorous experiments using the proposed method are performed on standard benchmark and real world agriculture datasets. The results reveal a significant performance improvement over state of the art methods such as NB, k-NN, and SVM in terms of performance metrics such as accuracy, sensitivity, specificity, precision, and F-score.",industry
10.1016/j.jprot.2017.06.020,Journal,Journal of Proteomics,scopus,2017-08-23,sciencedirect,iTRAQ-based quantitative proteomic analysis reveals multiple effects of Emodin to Haemophilus parasuis,https://api.elsevier.com/content/abstract/scopus_id/85025438874,"Haemophilus parasuis, a symbiotic bacteria of upper respiratory tract of swine, is the etiological agent of Glässer's disease, which is characterized by fibrinous polyserositis. Emodin, exhibits antibacterial activity against H. parasuis, yet the action mode has not been fully understood. In present study, isobaric tag for relative and absolute quantification (iTRAQ) method was applied to analyze the global protein alteration of H. parasuis in response to 16μg/mL Emodin. In total, 338 proteins exhibiting significant differential expressions were identified. It was speculated that, through application of bioinformatics analysis to theses differentially expressed proteins, Emodin mainly inhibited some key proteins expression of ABC transport system, carbohydrate metabolism pathway and bacterial cell division by inhibiting the ribosome synthesis, resulting in the growth inhibition of H. parasuis. Remarkably, nine virulence-associated proteins were detected differently expressed, further experiments revealed that after treatment with Emodin, H. parasuis could be inhibited to adhere to and invade into porcine kidney epithelial cells (PK-15 line) and exhibited increased sensitivity to serum complement in a concentration-dependent manner. Phagocytosis assay showed Emodin also could enhance phagocytic activity of porcine alveolar macrophages PAM to H. parasuis. These results indicated that Emodin also can attenuate virulence of H. parasuis and reduce infection.
               
                  Biological significance
                  The Glässer's disease caused by H. parasuis has become a typical bacterial disease and cause serious economic loss to the swine industry around the world. Antibiotics are extensively used to control the infection, but increasing antibiotic resistance has been a severe problem. Hence, novel treatment agents are needed. So far, few antibacterial agents were reported that could control H. parasuis infection. In the present study, the state-of-the-art quantitative proteomic technology was applied to uncover underlying action mechanism of Emodin. This study extends understanding of antibacterial effect of Emodin to H. parasuis at molecular level and provides useful information for further investigations. Moreover, our results provide theoretical foundation for the practical application of Emodin.",industry
10.1016/j.eneco.2017.06.020,Journal,Energy Economics,scopus,2017-08-01,sciencedirect,"Composite forecasting approach, application for next-day electricity price forecasting",https://api.elsevier.com/content/abstract/scopus_id/85024479867,"Accurate forecasting of electricity prices can provide significant benefits to energy suppliers when allocating their assets and to energy consumers for defining an optimal portfolio. There are numerous methods that efficiently support the forecasting of time series, such as electricity prices, which have high volatility. However, the performance of these approaches varies depending on data sets and operational conditions. In this work, the concept of composite forecasting is presented and implemented in a retrospective study, in real industrial forecasting conditions to show the potential of forecast performance improvement and comparable high consistency of a forecast performance across different ‘Day Peak’ and ‘Day Base’ electricity price data sets for different seasons. As individual methods support vector regression, artificial neural networks and ridge regression are implemented. The forecast performances of these methods are evaluated and compared with their forecast combination using different error measures. The results show that composite forecasting processes with ‘inverse root mean squared error’ combination approach can generate, on average, a more accurate and robust forecast than using an individual methods or other combination schemas.",industry
10.1016/j.jmapro.2017.04.012,Journal,Journal of Manufacturing Processes,scopus,2017-08-01,sciencedirect,Particle learning in online tool wear diagnosis and prognosis,https://api.elsevier.com/content/abstract/scopus_id/85018418044,"Automated Tool condition monitoring is critical in intelligent manufacturing to improve both productivity and sustainability of manufacturing operations. Estimation of tool wear in real-time for critical machining operations can improve part quality and reduce scrap rates. This paper proposes a probabilistic method based on a Particle Learning (PL) approach by building a linear system transition function whose parameters are updated through online in-process observations of the machining process. By applying PL, the method helps to avoid developing a complex closed form formulation for a specific tool wear model. It increases the robustness of the algorithm and reduces the time complexity of computation. The application of the PL approach is tested using experiments performed on a milling machine. We have demonstrated one-step and two-step look ahead tool wear state prediction using online indirect measurements obtained from vibration signals. Additionally, the study also estimates remaining useful life (RUL) of the cutting tool inserts.",industry
10.1016/j.ifacol.2017.08.986,Conference Proceeding,IFAC-PapersOnLine,scopus,2017-07-01,sciencedirect,Using data mining methods for manufacturing process control,https://api.elsevier.com/content/abstract/scopus_id/85031805594,"The Industry 4.0 concept assumes that modern manufacturing systems generate huge amounts of data that must be collected, stored, managed and analysed. The case study is focused on predicting the manufacturing process behaviour according to production data. The paper presents the way of gaining knowledge about the future behaviour of manufacturing system by data mining predictive tasks. The proposed simulation model of the real manufacturing process was designed to obtain the data necessary for the control process. The predictions of the manufacturing process behaviour were implemented varying the input parameters using selected methods and techniques of data mining. The predicted process behaviour was verified using the simulation model.
                  The authors analysed different methods. The neural network method was selected for deploying new data by PMML files in the final phases. The objectives of the research are to design and verify the data mining tools in order to support the manufacturing system control by aiming at improving the decisionmaking process. Based on the prediction of the goal production outcomes, the actual control strategies can be precisely modified. Then they can be used in real manufacturing system without risks.",industry
10.1016/j.ifacol.2017.08.902,Conference Proceeding,IFAC-PapersOnLine,scopus,2017-07-01,sciencedirect,A Networked Production System to Implement Virtual Enterprise and Product Lifecycle Information Loops,https://api.elsevier.com/content/abstract/scopus_id/85031797675,"This paper is aimed at considering supply chain and related data management within an integrated vision of the product lifecycle management (PLM) implemented through the unified approach which is proper to the Industry 4.0 initiative. In particular, with the proposed manufacturing system architecture, decision support tools can use a unified repository fed by a factory replication application, powered by data from the field, even from remote production units. Such data allow to monitor the behaviour of the digital twin of the real machine and produces a digital twin of the real product, incorporating its actual characteristics measured by means of suitable acquiring systems (in the treated example: a 3D laser scanner). Moreover, it is provided a description of the plant technological subsystems that allow to share designing and manufacturing activities across multiple similar units located in remote areas. In this context of virtual enterprise, the supply chain management results as a key factor in enabling a cooperative approach.",industry
10.1016/j.infsof.2017.03.003,Journal,Information and Software Technology,scopus,2017-07-01,sciencedirect,Uncertainty-wise evolution of test ready models,https://api.elsevier.com/content/abstract/scopus_id/85015382293,"Context
                  Cyber-Physical Systems (CPSs), when deployed for operation, are inherently prone to uncertainty. Considering their applications in critical domains (e.g., healthcare), it is important that such CPSs are tested sufficiently, with the explicit consideration of uncertainty. Model-based testing (MBT) involves creating test ready models capturing the expected behavior of a CPS and its operating environment. These test ready models are then used for generating executable test cases. It is, therefore, necessary to develop methods that can continuously evolve, based on real operational data collected during the operation of CPSs, test ready models and uncertainty captured in them, all together termed as Belief Test Ready Models (BMs)
               
                  Objective
                  Our objective is to propose a model evolution framework that can interactively improve the quality of BMs, based on operational data. Such BMs are developed by one or more test modelers (belief agents) with their assumptions about the expected behavior of a CPS, its expected physical environment, and potential future deployments. Thus, these models explicitly contain subjective uncertainty of the test modelers.
               
                  Method
                  We propose a framework (named as UncerTolve) for interactively evolving BMs (specified with extended UML notations) of CPSs with subjective uncertainty developed by test modelers. The key inputs of UncerTolve include initial BMs of CPSs with known subjective uncertainty and real data collected from the operation of CPSs. UncerTolve has three key features: 1) Validating the syntactic correctness and conformance of BMs against real operational data via model execution, 2) Evolving objective uncertainty measurements of BMs via model execution, and 3) Evolving state invariants (modeling test oracles) and guards of transitions (modeling constraints for test data generation) of BMs with a machine learning technique.
               
                  Results
                  As a proof-of-concept, we evaluated UncerTolve with one industrial CPS case study, i.e., GeoSports from the healthcare domain. Using UncerTolve, we managed to evolve 51% of belief elements, 18% of states, and 21% of transitions as compared to the initial BM developed in an industrial setting.
               
                  Conclusion
                  
                     UncerTolve can successfully evolve model elements of the initial BM, in addition to objective uncertainty measurements using real operational data. The evolved model can be used to generate additional test cases covering evolved model elements and objective uncertainty. These additional test cases can be used to test the current and future deployments of a CPS to ensure that it will handle uncertainty gracefully during its operations.",industry
10.1016/j.neucom.2017.02.003,Journal,Neurocomputing,scopus,2017-06-14,sciencedirect,Multiple-shot person re-identification via fair set-collaboration metric learning,https://api.elsevier.com/content/abstract/scopus_id/85015681817,"As an issue that attracts increasing interests in both academia and industry, multiple-shot person re-identification has shown promising results but suffers from real-scenario complexities and feature-crafting heuristics. To tackle the problems of set-level data variation and sparseness during re-identification, this paper proposes a novel metric learning method, named “Fair Set-Collaboration Metric Learning”, motivated by utilizing the opportunities whilst overcoming the challenges from the set of multiple instances. This method optimizes a new set-collaboration dissimilarity measure, which introduces the fairness principle into the collaborative representation based set to sets distance, in the set based metric learning framework. Experiments on widely-used benchmark datasets have demonstrated the advantages of this method in terms of effectiveness and robustness.",industry
10.1016/j.engappai.2016.08.019,Journal,Engineering Applications of Artificial Intelligence,scopus,2017-06-01,sciencedirect,GPU-based parallel optimization of immune convolutional neural network and embedded system,https://api.elsevier.com/content/abstract/scopus_id/84995489085,"Up to now, the image recognition system has been utilized more and more widely in the security monitoring, the industrial intelligent monitoring, the unmanned vehicle, and even the space exploration. In designing the image recognition system, the traditional convolutional neural network has some defects such as long training time, easy over-fitting and high misclassification rate. In order to overcome these defects, we firstly used the immune mechanism to improve the convolutional neural network and put forward a novel immune convolutional neural network algorithm, after we analyzed the network structure and parameters of the convolutional neural network. Our algorithm not only integrated the location data of the network nodes and the adjustable parameters, but also dynamically adjusted the smoothing factor of the basis function. In addition, we utilized the NVIDIA GPU (Graphics Processing Unit) to accelerate the new immune convolutional neural network (ICNN) in parallel computing and built a real-time embedded image recognition system for this ICNN. The immune convolutional neural network algorithm was improved with CUDA programming and was tested with the sample data in the GPU-based environment. The GPU-based implementation of the novel immune convolutional neural network algorithm was made with the cuDNN, which was designed by NVIDIA for GPU-based accelerating of DNNs in machine learning. Experimental results show that our new immune convolutional neural network has higher recognition rate, more stable performance and faster computing speed than the traditional convolutional neural network.",industry
10.1016/j.neucom.2016.09.005,Journal,Neurocomputing,scopus,2017-05-10,sciencedirect,Wood moisture content prediction using feature selection techniques and a kernel method,https://api.elsevier.com/content/abstract/scopus_id/84996497604,"Wood is a renewable, abundant bio-energy and environment friendly resource. Woody biomass Moisture Content (
                        MC
                     ) is a key parameter for controlling the biofuel product qualities and properties. In this paper, we are interested in predicting 
                        MC
                      from data. The input impedance of half-wave dipole antenna when buried in the wood pile varies according to the permittivity of wood. Hence, the measurement of reflection coefficient, that gives information about the input impedance, depends directly on the 
                        MC
                      of wood. The relationship between the reflection coefficient measurements and the 
                        MC
                      is studied. Based upon this relationship, 
                        MC
                      predictive models that use machine learning techniques and feature selection methods are proposed. Numerical experiments using real world data show the relevance of the proposed approach that requires a limited computational power. Therefore, a real-time implementation for industrial processes is feasible.",industry
10.1016/j.jmsy.2017.02.013,Journal,Journal of Manufacturing Systems,scopus,2017-04-01,sciencedirect,Multi-bearing remaining useful life collaborative prediction: A deep learning approach,https://api.elsevier.com/content/abstract/scopus_id/85014511127,"Rolling bearing health analysis and remaining useful life prediction have become an increasingly crucial research area that can promote reliability and efficiency in the modern manufacturing industry. Internet-of-Things and cyber manufacturing techniques make it convenient to collect large volumes of sensor data that can provide powerful support for efficient data analytics such as deep learning. The combination of a massive amount of available data and advanced machine learning models brings new opportunities for bearing remaining useful life prediction. This paper proposes an integrated deep learning approach for multi-bearing remaining useful life collaborative prediction by combining both time domain features and frequency domain features. The method can extract high-quality degradation patterns of rolling bearing from vibration signals. Regarding features extracted from bearing vibration signals, in addition to three conventional time domain features, a novel frequency domain feature is adopted in the proposed method as well. Based on the extracted features, the deep neural network model is introduced to predict the remaining useful life of rolling bearing. We evaluate the performance of the proposed method on a real dataset and compare it with several commonly used shallow prediction methods Numerical experiment results show the effectiveness and superiority of the proposed approach.",industry
10.1016/j.jmsy.2017.02.007,Journal,Journal of Manufacturing Systems,scopus,2017-04-01,sciencedirect,Framework and development of fault detection classification using IoT device and cloud environment,https://api.elsevier.com/content/abstract/scopus_id/85014081409,"While Cyber-physical system (CPS) is considered as a key foundation for cyber manufacturing, many related frameworks and applications have been provided. This research suggests a new and effective CPS architecture for supporting multi-sites and multi-products manufacturing. As target processes, the manufacturing processes for vehicles’ High Intensity Discharge (HID) headlight and cable modules are considered. These modules are manufactured with several multi-manufacturing sites consisting of internal manufacturing tasks and intermediate outsourcing processes. In addition, they produce multiple types of HID cable modules with different components. These issues make it difficult to improve the qualities of the overall processes and to control those considering overall manufacturing plants and processes. In order to overcome these limitations, this research provides an Internet of Things (IoT) embedded cloud control architecture. The mixed flow issues are overcome with the cloud control server with the suggested framework. The developed IoT device detects several system status and transmits the signals. The data is analyzed for the fault detection classification (FDC) mechanism using deep learning based analytics. Then, the cyber manufacturing based simulation is executed using the provided multi-products queueing network model. The estimated simulation results is used for generating dynamic manufacturing decisions reflecting the real-time changes of the production environment. The suggested framework and its implementations can be used for various industrial processes and applications.",industry
10.1016/j.jmsy.2017.02.011,Journal,Journal of Manufacturing Systems,scopus,2017-04-01,sciencedirect,A fog computing-based framework for process monitoring and prognosis in cyber-manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85013912214,"Small- and medium-sized manufacturers, as well as large original equipment manufacturers (OEMs), have faced an increasing need for the development of intelligent manufacturing machines with affordable sensing technologies and data-driven intelligence. Existing monitoring systems and prognostics approaches are not capable of collecting the large volumes of real-time data or building large-scale predictive models that are essential to achieving significant advances in cyber-manufacturing. The objective of this paper is to introduce a new computational framework that enables remote real-time sensing, monitoring, and scalable high performance computing for diagnosis and prognosis. This framework utilizes wireless sensor networks, cloud computing, and machine learning. A proof-of-concept prototype is developed to demonstrate how the framework can enable manufacturers to monitor machine health conditions and generate predictive analytics. Experimental results are provided to demonstrate capabilities and utility of the framework such as how vibrations and energy consumption of pumps in a power plant and CNC machines in a factory floor can be monitored using a wireless sensor network. In addition, a machine learning algorithm, implemented on a public cloud, is used to predict tool wear in milling operations.",industry
10.1016/j.jmsy.2017.01.004,Journal,Journal of Manufacturing Systems,scopus,2017-04-01,sciencedirect,Study of spindle power data with neural network for predicting real-time tool wear/breakage during inconel drilling,https://api.elsevier.com/content/abstract/scopus_id/85012885297,"Digital manufacturing systems are determined to be a major key to enhance productivity and quality mainly due to real-time process monitoring and control capability with instant data processing. During machining, such systems are anticipated to excerpt reliable data within a short time-lapse, monitor tool wear progress, anticipate its wear and breakage, alert the machinist in real time to avoid unexpected failure of tool or machine, and help obtaining quality products. This is vital, especially, when drilling Ni-/Ti-based superalloys because catastrophic failure and premature breakage of tools occur in random manner due to aggressive welding and chipping of tool including the rake and/or flank faces and tool corner.
                  Nowadays, spindle power data are easy to collect directly from modern machine tools and can be made available in production floor for such real-time data processing. This work aims to evaluate spindle power data for real-time tool wear/breakage prediction during drilling of a Ni-based superalloy, Inconel 625. Experiments were performed by varying speed and feed. Spindle power data were collected from the power meter (also called load meter) to feed into the neural network (NN) for functional processing. To understand the reliability of the spindle power data, force data were also collected and compared. The results show that the trends of these two different types of data over cutting time are similar for any feed and speed combinations. The error in NN prediction from actual wear was found to be between 0.8–18.4% with power data as compared to that between 0.4–17.9% with force data. Findings suggest that spindle power data integrated with the artificial intelligence (NN) system can be used for real-time tool wear/breakage monitoring and process control, thus appreciate digital manufacturing systems.",industry
10.1016/j.compositesb.2016.12.050,Journal,Composites Part B: Engineering,scopus,2017-03-01,sciencedirect,Digitisation of manual composite layup task knowledge using gaming technology,https://api.elsevier.com/content/abstract/scopus_id/85009923562,"Increased market demand for composite products and shortage of expert laminators is compelling the composite industry to explore ways to acquire layup skills from experts and transfer them to novices and eventually to machines. There is a lack of holistic methods in literature for capturing composite layup skills especially involving complex moulds. This research aims to develop an informatics-based method, enabled by consumer-grade gaming technology and machine learning, to capture and digitise manufacturing task knowledge from skill-intensive hand layup. The digitisation is underpinned by the proposed human-workpiece interaction theory and implemented to automatically extract and decode key knowledge constituents such as layup strategies, ply manipulation techniques, motion mechanics and problem-solving during hand layup, collectively categorised as layup skills. The significance of this research is its potential to facilitate cost-effective transfer of skills from experts to novices, real-time automated supervision of hand layup and automation of layup tasks in the future.",industry
10.1016/j.simpat.2016.08.007,Journal,Simulation Modelling Practice and Theory,scopus,2017-02-01,sciencedirect,Intelligent simulation: Integration of SIMIO and MATLAB to deploy decision support systems to simulation environment,https://api.elsevier.com/content/abstract/scopus_id/84996798684,"Discrete-event simulation is a decision support tool which enables practitioners to model and analyze their own system behavior. Although simulation packages are capable of mimicking most tasks in a real-world system, there are some decision-making activities, which are beyond the reach of simulation packages. The Application Programmers Interface (API) of SIMIO provides a wide range of opportunities for researchers to develop their own logic and apply it during the simulation run. This paper illustrates how to deploy MATLAB, as a computational tool coupled with SIMIO, as a simulation package by using a new user-defined step instance named “CallMATLAB”. A manufacturing system case study is introduced where the CallMATLAB step instance is used to create an Iterative Optimization-based Simulation (IOS) model. This model is created to evaluate the performance of different optimizers. The benefits of this hybridization for other industries, including healthcare systems, supply chain management systems, and project management problems are discussed.",industry
10.1016/j.promfg.2017.07.167,Journal,Procedia Manufacturing,scopus,2017-01-01,sciencedirect,Towards Robust Early Stage Data Knowledge-based Inference Engine to Support Zero-defect Strategies in Manufacturing Environment,https://api.elsevier.com/content/abstract/scopus_id/85029884694,"Decision Support Systems are considered as a robust technology able to provide an advantage to several manufacturing companies. As part of the Z-Fact0r EU project, an autonomous and self-adjusted inference engine; namely the Early Stage-Decision Support System (ES-DSS) will be deployed. The scope is to facilitate real-time inspection, condition monitoring and control - diagnosis at the shop-floor, utilizing continuously mine multiple data streams and run the suitable models to monitor operations and quality performance, to classify products on the basis of quality metrics, as well to predict occurrence of defects and deviations from production and quality requirements.",industry
10.1016/j.procir.2017.03.093,Conference Proceeding,Procedia CIRP,scopus,2017-01-01,sciencedirect,Cyber-Physical Manufacturing Metrology Model (CPM<sup>3</sup>) for Sculptured Surfaces - Turbine Blade Application,https://api.elsevier.com/content/abstract/scopus_id/85028681766,"Cyber-Physical Manufacturing (CPM) and digital manufacturing represent the key elements for implementation of Industry 4.0 framework. Worldwide, Industry 4.0 becomes national research strategy in the field of engineering for the following ten years. The International Conference USA-EU-Far East-Serbia Manufacturing Summit was held from 31st May to 2nd June 2016 in Belgrade, Serbia. The result of the conference was the development of Industry 4.0 Model for Serbia as a framework for New Industrial Policy – Horizon 2020/2030.
                  Implementation of CPM in manufacturing systems generates “smart factory”. Products, resources, and processes within smart factory are realized and controlled through CPM model. This leads to significant advantages with respect to high product/process quality, real-time applications, savings in resources consumption, as well as, lower costs in comparison with classical manufacturing systems. Smart factory is designed in accordance with sustainable and service-oriented best business practices/models. It is based on optimization, flexibility, self-adaptability and learning, fault tolerance, and risk management. Complete manufacturing digitalization and digital factory are the key elements of Industry 4.0 Program.
                  In collaborative research, which we carry out in the field of quality control and manufacturing metrology at University of Belgrade, Faculty of Mechanical Engineering in Serbia and at Department of Mechanical Engineering, University of Texas, Austin in USA, three research areas are defined: (а) Digital manufacturing – towards Cloud Manufacturing Systems (as a basis for CPS), in which quality and metrology represent integral parts of process optimization based on Taguchi model, and (б) Cyber-Physical Quality Model (CPQM) – our approach, in which we have developed and tested intelligent model for prismatic parts inspection planning on CMM (Coordinate Measuring Machine). The third research area directs our efforts to the development of framework for Cyber-Physical Manufacturing Metrology Model (CPM3). CPM3 framework will be based on integration of digital product metrology information through metrology features recognition, and generation of global/local inspection plan for free-form surfaces; we will illustrate our approach using turbine blade example. This paper will present recent results of our research on CPM3.",industry
10.1016/j.procir.2017.03.090,Conference Proceeding,Procedia CIRP,scopus,2017-01-01,sciencedirect,Big Data Analytics Based Optimisation for Enriched Process Planning: A Methodology,https://api.elsevier.com/content/abstract/scopus_id/85028667638,"To improve flexibility and accurateness of the optimisation in machining, this paper presents a big data analytics based optimisation method for enriched process planning in the concept of which cutting condition and cutting tool are optimised together and simultaneously. Within the context, the machining factors (workpiece, machining requirement, machine tool, machining process and machining result etc.) are concerned and represented by data attributes. In case that, the new machining resource, new materials and new machining tools etc., can be represented by a group of parameters, so that each machining cases can be treated by data regardless of the relevant experiments, which can enhance practicality and flexibility of potential application in real industry. Also a hybrid method combining neural networks (NN), analytic hierarchy process (AHP), and evolution based algorithm (EBA) or swarm intelligence based algorithm (SIBA) is proposed. NN based model is trained by the big data to improve the accurateness of each single objective, AHP is employed for multi-objective, and EBA or SBA is used to execute the optimising calculation.",industry
10.1016/j.procir.2017.03.115,Conference Proceeding,Procedia CIRP,scopus,2017-01-01,sciencedirect,Dynamic Analysis of Intelligent Coil Leveling Machine for Cyber-physical Systems Implementation,https://api.elsevier.com/content/abstract/scopus_id/85028650941,"In manufacturing industry, wider range variants and personalized productions are becoming formidable challenges that needed to be for smart manufacturing. In smart manufacturing, machines are connected cooperatively to seamlessly and quickly adjust production setting to reach market requirements. Furthermore, real-time production data visualization and evaluation are the keys to increase manufacturing productivity, efficiency, and flexibility. This integrated research is aimed to develop an intelligent coil leveling machine through dynamic analysis of real-time machine sensors network for cyber-physical systems implementation in smart manufacturing. In this proposed intelligent coil leveling machine, intelligent sensors network is embedded in the machine to allow real-time monitoring of the machine through feedback controlled system and cloud network to ensure optimized production with optimal machine setting instantly. Intelligent sensors network of the proposed coil leveling machine such as leveling roller indentation, leveling force, and coil curvature has been completed. Preliminary real-time dynamic monitoring of the leveling rollers and coil curvature has been accomplished. Following, real-time dynamic analysis is performed to demonstrate the implementation of the cyber-physical systems where machine learning intelligence can be achieved. Lastly, real-time cloud network monitoring are implemented to allow users to collect manufacturing data online. Through this research, conventional leveling machine can be transformed in which machine setting configurations can be adjusted to the production line through virtual cyber-physical system. Production data can be visualized and evaluated in real-time with precise and intelligent production strategies to ensure customer's requirements and to enhance production efficiency and flexibility in smart manufacturing of sheet metal coil.",industry
10.1016/j.procir.2017.03.125,Conference Proceeding,Procedia CIRP,scopus,2017-01-01,sciencedirect,Ant Colony Optimization Algorithms to Enable Dynamic Milkrun Logistics,https://api.elsevier.com/content/abstract/scopus_id/85028644167,"Flexibility in combination with high capacities are the main reasons for milkruns being one of the most popular intralogistics solutions. In most cases they are only used for static routes to always deliver the same material to the same stations. However, in the context of Industry 4.0, milkrun logistic also has become very popular for use cases where different materials have to be delivered to different stations in little time, so routes cannot be planned in advance anymore. As loading and unloading the milkrun requires a significant amount of time, beside the routing problem itself, both driving and loading times have to be taken into account. Especially in scenarios where high flexibility is required those times will vary significantly and thus are a crucial factor for obtaining the optimal solution. Although containing stochastic components, those times can be predicted by considering the optimal point of time for delivery. In consequence, the best tradeoff between short routes and optimal delivery times is in favor of the shortest route. To solve this optimization problem a biology-inspired method – the ant colony optimization algorithm – has been enhanced to obtain the best solution regarding the above-mentioned aspects. A manufacturing scenario was used to prove the ability of the algorithm in real world problems. It also demonstrates the ability to adapt to changes in manufacturing systems very quickly by dynamically modelling and simulating the processes in intralogistics. The paper describes the ant colony optimization algorithm with the necessary extensions to enable it for milkrun logistic problems. Additionally the implemented software environment to apply the algorithm in practice is explained.",industry
10.1016/j.petrol.2016.11.033,Journal,Journal of Petroleum Science and Engineering,scopus,2017-01-01,sciencedirect,A hybrid particle swarm optimization and support vector regression model for modelling permeability prediction of hydrocarbon reservoir,https://api.elsevier.com/content/abstract/scopus_id/85028257367,"The significance of accurate permeability prediction cannot be over-emphasized in oil and gas reservoir characterization. Support vector machine regression (SVR), a computational intelligence technique, has been very successful in the estimation of permeability and has been widely deployed due to its unique features. However, careful selection of SVR hyper-parameters is highly essential to its optimum performance and this task is traditionally done using trial and error approach (TE-SVR) which takes a lot of time and do not guarantee optimal selection of the hyper-parameters. In this work, the performance of particle swarm optimization (PSO) technique, a heuristic optimization technique, is investigated for the optimal selection of SVR hyper-parameters for the first time in modelling and characterization of hydrocarbon reservoir. The technique is capable of automatic selection of the optimum combination of SVR hyper-parameters resulting in higher predictive accuracy and generalization ability of the developed model. The resulting PSO-SVR model is compared to SVR models whose parameters are obtained through random search (RAND-SVR) and trial and error approach (TE-SVR). The comparison is done using real-life industrial datasets obtained during petroleum exploration from four distinct oil wells located in a Middle Eastern oil and gas field. Simulation results indicate that the PSO-SVR model outperforms all the other models. Error reduction of 15.1%, 26.15%, 12.32% and 7.1% are recorded for PSO-SVR model compared to ordinary SVR (TE-SVR) in well-A, well-B, well-C and well-D, respectively. Also, reduction of 12.8%, 23.97%, 2.51% and 0.11 are recorded when PSO-SVR and RAND-SVR results are compared in the respective wells. Furthermore, the results show the potential of the application of heuristics algorithms, such as PSO, in the optimization of computational intelligence techniques employed in hydrocarbon reservoir characterizations. Therefore, PSO technique is proposed for the optimization of SVR hyper-parameters in permeability prediction and reservoir characterization based on its superior performance over the commonly employed optimization techniques.",industry
10.1016/j.promfg.2017.07.091,Conference Proceeding,Procedia Manufacturing,scopus,2017-01-01,sciencedirect,Machine Learning-based CPS for Clustering High throughput Machining Cycle Conditions,https://api.elsevier.com/content/abstract/scopus_id/85023607399,"Cyber-physical systems (CPS) have opened up a wide range of opportunities in terms of performance analysis that can be applied directly to the machine tool industry and are useful for maintenance systems and machine designers. High-speed communication capabilities enable the data to be gathered, pre-processed and processed for the purpose of machine diagnosis. This paper describes a complete real-world CPS implementation cycle, ranging from machine data acquisition to processing and interpretation. In fact, the aim of this paper is to propose a CPS for machine component knowledge discovery based on clustering algorithms using real data from a machining process. Therefore, it compares three clustering algorithms –k-means, hierarchical agglomerative and Gaussian mixture models– in terms of their contribution to spindle performance knowledge during high throughput machining operation.",industry
10.1016/j.procs.2017.01.213,Conference Proceeding,Procedia Computer Science,scopus,2017-01-01,sciencedirect,Hybrid Agents Implementation for the Control of the Construction Company,https://api.elsevier.com/content/abstract/scopus_id/85016095509,"Planning the project duration together with separate works is an essential element of managing the construction. The final duration depends on multiple factors, including the funds, customer requests, and capabilities of the construction company. In order to avoid additional costs in penalties or additional expenses, the management needs to estimate the real construction duration in advance, before the contract is signed. Further on, these terms need to be monitored both in whole and for the specific jobs in order to be able to edit further stages with regard of the remaining time, resources and used resources ratio. The development of a decision support system for the construction company is a pressing problem due to the growing demand in decision making persons’ labor automation in planning and monitoring the construction processes. The paper presents the model and the application experience for such a system.",industry
10.1016/j.paerosci.2016.10.001,Journal,Progress in Aerospace Sciences,scopus,2017-01-01,sciencedirect,An evolutionary outlook of air traffic flow management techniques,https://api.elsevier.com/content/abstract/scopus_id/85006413338,"In recent years Air Traffic Flow Management (ATFM) has become pertinent even in regions without sustained overload conditions caused by dense traffic operations. Increasing traffic volumes in the face of constrained resources has created peak congestion at specific locations and times in many areas of the world. Increased environmental awareness and economic drivers have combined to create a resurgent interest in ATFM as evidenced by a spate of recent ATFM conferences and workshops mediated by official bodies such as ICAO, IATA, CANSO the FAA and Eurocontrol. Significant ATFM acquisitions in the last 5 years include South Africa, Australia and India. Singapore, Thailand and Korea are all expected to procure ATFM systems within a year while China is expected to develop a bespoke system. Asia-Pacific nations are particularly pro-active given the traffic growth projections for the region (by 2050 half of all air traffic will be to, from or within the Asia-Pacific region). National authorities now have access to recently published international standards to guide the development of national and regional operational concepts for ATFM, geared to Communications, Navigation, Surveillance/Air Traffic Management and Avionics (CNS+A) evolutions. This paper critically reviews the field to determine which ATFM research and development efforts hold the best promise for practical technological implementations, offering clear benefits both in terms of enhanced safety and efficiency in times of growing air traffic. An evolutionary approach is adopted starting from an ontology of current ATFM techniques and proceeding to identify the technological and regulatory evolutions required in the future CNS+A context, as the aviation industry moves forward with a clearer understanding of emerging operational needs, the geo-political realities of regional collaboration and the impending needs of global harmonisation.",industry
10.1016/j.ijpe.2016.10.021,Journal,International Journal of Production Economics,scopus,2017-01-01,sciencedirect,Single-hidden layer neural networks for forecasting intermittent demand,https://api.elsevier.com/content/abstract/scopus_id/84994731834,"Managing intermittent demand is a vital task in several industrial contexts, and good forecasting ability is a fundamental prerequisite for an efficient inventory control system in stochastic environments. In recent years, research has been conducted on single-hidden layer feedforward neural networks, with promising results. In particular, back-propagation has been adopted as a gradient descent-based algorithm for training networks. However, when managing a large number of items, it is not feasible to optimize networks at item level, due to the effort required for tuning the parameters during the training stage. A simpler and faster learning algorithm, called the extreme learning machine, has been therefore proposed in the literature to address this issue, but it has never been tried for forecasting intermittent demand. On the one hand, an extensive comparison of single-hidden layer networks trained by back-propagation is required to improve our understanding of them as predictors of intermittent demand. On the other hand, it is also worth testing extreme learning machines in this context, because of their lower computational complexity and good generalisation ability.
                  In this paper, neural networks trained by back-propagation and extreme learning machines are compared with benchmark neural networks, as well as standard forecasting methods for intermittent demand on real-time series, by combining different input patterns and architectures. A statistical analysis is then conducted to validate the best performance through different aggregation levels. Finally, some insights for practitioners are presented to improve the potential of neural networks for implementation in real environments.",industry
10.1016/j.trb.2016.09.004,Journal,Transportation Research Part B: Methodological,scopus,2016-12-01,sciencedirect,Designing a supply chain resilient to major disruptions and supply/demand interruptions,https://api.elsevier.com/content/abstract/scopus_id/84989182951,"Global supply chains are more than ever under threat of major disruptions caused by devastating natural and man-made disasters as well as recurrent interruptions caused by variations in supply and demand. This paper presents a hybrid robust-stochastic optimization model and a Lagrangian relaxation solution method for designing a supply chain resilient to (1) supply/demand interruptions and (2) facility disruptions whose risk of occurrence and magnitude of impact can be mitigated through fortification investments. We study a realistic problem where a disruption can cause either a complete facility shutdown or a reduced supply capacity. The probability of disruption occurrence is expressed as a function of facility fortification investment for hedging against potential disruptions in the presence of certain budgetary constraints. Computational experiments and thorough sensitivity analyses are completed using some of the existing widely-used datasets. The performance of the proposed model is also examined using a Monte Carlo simulation method. To explore the practical application of the proposed model and methodology, a real world case example is discussed which addresses mitigating the risk of facility fires in an actual oil production company. Our analysis and investigation focuses on exploring the extent to which supply chain design decisions are influenced by factors such as facility fortification strategies, a decision maker's conservatism degree, demand fluctuations, supply capacity variations, and budgetary constraints.",industry
10.1016/j.epsr.2016.07.018,Journal,Electric Power Systems Research,scopus,2016-12-01,sciencedirect,Classification for consumption data in smart grid based on forecasting time series,https://api.elsevier.com/content/abstract/scopus_id/84981303127,"One of the most important tasks of present day smart grid implementations is to classify different types of consumers (households, office buildings and industrial plants) because they may be served by the power supplier with different parameters, rates, contracts.
                  In this paper, we propose a novel classification scheme for smart grid systems where the collected data are processed in order to increase the efficiency of electricity transportation as well as demand-supply management. The new scheme is based on forecasting the consumption time series obtained from a smart meter. Class assignment is determined using the forecast error. Different linear and nonlinear methods were tested based on the corresponding assumptions on the statistical behavior of the underlying consumption time series.
                  Performance tests were carried out with simulations in order to demonstrate the capabilities and to compare the achieved performance of the proposed scheme with existing solutions. The simulations have been executed using (i) artificially generated consumption data, which data came from a bottom-up semi-Markov model and (ii) real, measured power consumption data as well. The parameters of the model have been validated on real data. The numerical results have demonstrated that our method can better model and classify the consumption patterns of office-buildings than the existing methods. As a result, the proposed method may prove to be a promising classification tool.",industry
10.1016/j.carbpol.2016.06.045,Journal,Carbohydrate Polymers,scopus,2016-11-05,sciencedirect,Functionalization of magnetic chitosan with graphene oxide for removal of cationic and anionic dyes from aqueous solution,https://api.elsevier.com/content/abstract/scopus_id/84978500114,"In the present study, we decorated chitosan (©) with Fe3O4 nanoparticles followed by cross-linking with GO to prepare Fe3O4 supported chitosan-graphene oxide composite (Fe3O4©-GO). Different properties of synthesized material were investigated by SEM, XRD, FTIR, TGA and EDX. Batch adsorption experiments were performed to remove toxic cationic and anionic dyes from industrial wastewater. To maximize removal efficiency of composite material, effect of pH (4–12), time (0–80min), Fe3O4©-GO dosage (2–10mg), initial dye concentration (2–30μgmL̄ 1) and temperature (303, 313, and 323K) were studied. The uptake of dyes presented relatively fast adsorption kinetics with pseudo-second-order equation as the best fitting model. To understand the interaction of dye with adsorbent, Langmuir and Freundlich isotherm were applied. Thermodynamic studies were conducted to calculate the changes in free energy (ΔG
                     0), enthalpy (ΔH
                     0) and entropy (ΔS
                     0). In view of practical application, the influence of ionic strength, recycling as well as investigations based on percent recoveries from spiked real water samples were also taken into account.",industry
10.1016/j.resconrec.2016.03.012,Journal,"Resources, Conservation and Recycling",scopus,2016-11-01,sciencedirect,Implementation of OPTIMASS to optimise municipal wastewater sludge processing chains: Proof of concept,https://api.elsevier.com/content/abstract/scopus_id/85028239611,"In sludge management, sludge is increasingly perceived as a marketable product rather than as a waste material. This awareness in combination with the variety of factors influencing the optimal management strategy and disposal route, introduces the need to optimise the sludge treatment throughout the whole chain instead of only minimising its production. In this paper, OPTIMASS, a mixed integer linear programming model to optimise strategic and tactical decisions in biomass-based supply chains, is proposed in order to meet this need. The applicability of OPTIMASS is illustrated through its implementation with a view to minimise the overall global warming impact of a real municipal wastewater sludge processing chain in “region X”. A first scenario addresses the optimisation of the allocation and treatment of municipal wastewater sludge within the current network. Second, OPTIMASS is used to identify the optimal location(s) for new drying facilities in this chain. Finally, the effect on the optimal chain of changes in municipal wastewater sludge production and of changes in global warming impact of the cement industry as a disposal route is evaluated.
                  The analysis reveals that municipal wastewater sludge processing chains can be considered to be instances of the generic biomass-based supply chain and that the OPTIMASS tool can be applied to support strategic and tactical decisions for optimising sludge management in case new technologies, new treatment facility locations, new disposal options, etc. are at stake. The validity of the OPTIMASS approach is confirmed by the close correspondence between its outcome and the results of a decision support system, specifically developed for the municipal wastewater sludge processing chain.",industry
10.1016/j.jclepro.2016.05.091,Journal,Journal of Cleaner Production,scopus,2016-10-01,sciencedirect,Developing an ant colony approach for green closed-loop supply chain network design: a case study in gold industry,https://api.elsevier.com/content/abstract/scopus_id/84988844589,"The forward/reverse logistics network design is an important and strategic issue due to its effects on efficiency and responsiveness of a supply chain. In practice, it is needed to formulate and solve real problems through efficient algorithms in a reasonable time. Hence, this paper tries to cover real case problem with a multi-objective model and an integrated forward/reverse logistics network design. Further, the model is customized and implemented for a case study in gold industry where the reverse logistics play crucial role. A new solution approach is applied for the proposed 7-layer network of the case study and the solutions are achieved in order solve the current difficulties of the investigated supply chain. This paper seeks to address how a multi objective logistics model in the gold industry can be created and solved through an efficient meta-heuristic algorithm. A green approach based on the CO2 emission is considered in the network design approach. The developed model includes four echelons in the forward direction and three echelons in the reverse. First, an integer linear programming model is developed to minimize costs and emissions. Then, in order to solve the model, an algorithm based on ant colony optimization is developed. The performance of the proposed algorithm has been compared with the optimum solutions of the LINGO software through various numerical examples based on the random data and real-world instances. The evaluation studies demonstrate that the proposed model is practical and applicable and the developed algorithm is reliable and efficient. The results prove the managerial implications of the model and the solution approach in terms of presenting appropriate modifications to the mangers of the selected supply chain. Further, a Taguchi-based parameter setting is undertaken to ensure using the appropriate parameters for the algorithm.",industry
10.1016/j.adhoc.2016.06.011,Journal,Ad Hoc Networks,scopus,2016-10-01,sciencedirect,Feature selection for performance characterization in multi-hop wireless sensor networks,https://api.elsevier.com/content/abstract/scopus_id/84977657790,"Current trends in Wireless Sensor Networks are faced with the challenge of shifting from testbeds in controlled environments to real-life deployments, characterized by unattended and long-term operation. The network performance in such settings depends on various factors, ranging from the operational space, the behavior of the protocol stack, the intra-network dynamics, and the status of each individual node. As such, characterizing the network’s high-level performance based exclusively on link-quality estimation, can yield episodic snapshots on the performance of specific, point-to-point links. The objective of this work is to provide an integrated framework for the unsupervised selection of the dominant features that have crucial impact on the performance of end-to-end links, established over a multi-hop topology. Our focus is on compressing the original feature vector of network parameters, by eliminating redundant network attributes with predictable behavior. The proposed approach is implemented alongside different cases of protocol stacks and evaluated on data collected from real-life deployments in rural and industrial environments. Discussions on the efficacy of the proposed scheme, and the dominant network characteristics per deployment are offered.",industry
10.1016/j.mechmachtheory.2016.05.022,Journal,Mechanism and Machine Theory,scopus,2016-10-01,sciencedirect,Intelligent diagnosis of bearing knock faults in internal combustion engines using vibration simulation,https://api.elsevier.com/content/abstract/scopus_id/84975476102,"Big-end bearing knock faults in IC engines can be considered as a real industrial case of a slider-crank mechanism including a joint with clearance and lubrication. In this paper, an Artificial Neural Network (ANN) based system was used to solve the problem of intelligent big-end bearing knock fault diagnosis in Internal Combustion (IC) engine. But when the ANN is used in machine condition monitoring, it is either unlikely or uneconomical to experience all different real faults to generate sufficient training data. Therefore, model based method should be a viable way to generate adequate data to train the networks for the intelligent big-end bearing fault diagnosis in IC engines. In order to evaluate and update the simulation model, experiments with normal bearing clearance and with different oversize bearing clearances were first carried out on the engine test rig. It was found that the relevant diagnostic information lies in the squared envelope of the vibration signals. Therefore, we only need build a proper simulation model to simulate the correct envelope signals rather than the raw vibration signals. As the important inputs of the simulation model, the inertia properties of the simulated engine components were also measured and studied. Next, we built an ANN-based bearing knock diagnosis system which consists of three phases: fault detection phase, fault localization phase and fault severity identification phase. Particularly, a saturating linear function is selected as the transfer function of the fault severity identification stage, so the networks can linearly classify the fault levels and the output is more in agreement with the reality in industry. Following the feature extraction and selection from the processed squared envelope signals, the networks were purely trained by the simulated data with normal bearing clearance and with different oversize bearing clearances. Finally the networks was tested by the real experimental data and it was demonstrated that the networks can successfully detect different bearing knock faults in real tests, and also classify the faults' location and severity levels.",industry
10.1016/j.ijpe.2016.06.005,Journal,International Journal of Production Economics,scopus,2016-09-01,sciencedirect,Hybrid flow shop batching and scheduling with a bi-criteria objective,https://api.elsevier.com/content/abstract/scopus_id/84975859979,"This paper addresses the hybrid flow shop batching and scheduling problem where sequence-dependent family setup times are present and the objective is to simultaneously minimize the weighted sum of the total weighted completion time and total weighted tardiness. In particular, it disregards the group technology assumptions by allowing for the possibility of splitting pre-determined groups of jobs into inconsistent batches in order to improve the operational efficiency. A benchmark of small size problems is considered to show the benefits of batching on group scheduling. Since the problem is strongly NP-hard, several algorithms based upon tabu search are developed at three levels, which move back and forth between batching and scheduling phases. Two algorithms incorporate tabu search into the framework of path-relinking to exploit the information on good solutions. These tabu search/path-relinking algorithms comprise several distinguishing features including two relinking procedures to effectively construct paths and the stage-based improvement procedure to consider the move interdependency. The best tabu search algorithm as a local search algorithm is compared to a population-based algorithm, and the superiority of the former over the latter is shown using a statistical experiment. The initial solution finding mechanism is implemented to trigger the search into the solution space. The efficiency and effectiveness of the best algorithm is verified with the help of the results found by CPLEX. The results show that the best algorithm, based on tabu search/path relinking and the stage-based improvement procedure, could find solutions at least as good as CPLEX, but in drastically shorter computational time. In order to reflect the real industry requirements, dynamic machine availability times, dynamic job release times, machine eligibility and machine capability for processing jobs, desired lower bounds on batch sizes, and job skipping are considered.",industry
10.1016/j.jpowsour.2016.05.092,Journal,Journal of Power Sources,scopus,2016-08-30,sciencedirect,Prognostics of Proton Exchange Membrane Fuel Cells stack using an ensemble of constraints based connectionist networks,https://api.elsevier.com/content/abstract/scopus_id/84975104897,"Proton Exchange Membrane Fuel Cell (PEMFC) is considered the most versatile among available fuel cell technologies, which qualify for diverse applications. However, the large-scale industrial deployment of PEMFCs is limited due to their short life span and high exploitation costs. Therefore, ensuring fuel cell service for a long duration is of vital importance, which has led to Prognostics and Health Management of fuel cells. More precisely, prognostics of PEMFC is major area of focus nowadays, which aims at identifying degradation of PEMFC stack at early stages and estimating its Remaining Useful Life (RUL) for life cycle management. This paper presents a data-driven approach for prognostics of PEMFC stack using an ensemble of constraint based Summation Wavelet- Extreme Learning Machine (SW-ELM) models. This development aim at improving the robustness and applicability of prognostics of PEMFC for an online application, with limited learning data. The proposed approach is applied to real data from two different PEMFC stacks and compared with ensembles of well known connectionist algorithms. The results comparison on long-term prognostics of both PEMFC stacks validates our proposition.",industry
10.1016/j.cie.2016.05.001,Journal,Computers and Industrial Engineering,scopus,2016-07-01,sciencedirect,Minimizing the total completion time for parallel machine scheduling with job splitting and learning,https://api.elsevier.com/content/abstract/scopus_id/84968779704,"This paper examines parallel machine scheduling with the objective of minimizing total completion time considering job splitting and learning. This study is motivated by real situations in labor-intensive industry, where learning effects take place and managers need to make decisions to split and assign orders to parallel production teams. Firstly, some analytical properties which are efficient at reducing complexity of the problem are presented. Utilizing the analytical property of the problem, a branch-and-bound algorithm which is efficient at solving small-sized problems is proposed. For the large-sized problems, several constructive heuristics and meta-heuristics are presented. Among them, the greedy search, which can take both the current profit and future cost after splitting a job into consideration, obtains a near-optimal solution for the small sized problems and performs best in all proposed heuristics for the large sized problems. Finally, extensive numerical experiments are conducted to test the performance of the proposed methods.",industry
10.1016/j.cviu.2016.03.018,Journal,Computer Vision and Image Understanding,scopus,2016-07-01,sciencedirect,"Wize Mirror-a smart, multisensory cardio-metabolic risk monitoring system",https://api.elsevier.com/content/abstract/scopus_id/84963813154,"In the recent years personal health monitoring systems have been gaining popularity, both as a result of the pull from the general population, keen to improve well-being and early detection of possibly serious health conditions and the push from the industry eager to translate the current significant progress in computer vision and machine learning into commercial products. One of such systems is the Wize Mirror, built as a result of the FP7 funded SEMEOTICONS (SEMEiotic Oriented Technology for Individuals CardiOmetabolic risk self-assessmeNt and Self-monitoring) project. The project aims to translate the semeiotic code of the human face into computational descriptors and measures, automatically extracted from videos, multispectral images, and 3D scans of the face. The multisensory platform, being developed as the result of that project, in the form of a smart mirror, looks for signs related to cardio-metabolic risks. The goal is to enable users to self-monitor their well-being status over time and improve their life-style via tailored user guidance. This paper is focused on the description of the part of that system, utilising computer vision and machine learning techniques to perform 3D morphological analysis of the face and recognition of psycho-somatic status both linked with cardio-metabolic risks. The paper describes the concepts, methods and the developed implementations as well as reports on the results obtained on both real and synthetic datasets.",industry
10.1016/j.epsr.2016.03.012,Journal,Electric Power Systems Research,scopus,2016-06-01,sciencedirect,Metalearning to support competitive electricity market players' strategic bidding,https://api.elsevier.com/content/abstract/scopus_id/84962522494,"Electricity markets are becoming more competitive, to some extent due to the increasing number of players that have moved from other sectors to the power industry. This is essentially resulting from incentives provided to distributed generation. Relevant changes in this domain are still occurring, such as the extension of national and regional markets to continental scales. Decision support tools have thereby become essential to help electricity market players in their negotiation process. This paper presents a metalearner to support electricity market players in bidding definition. The proposed metalearner uses a dynamic artificial neural network to create its own output, taking advantage on several learning algorithms already implemented in ALBidS (Adaptive Learning strategic Bidding System). The proposed metalearner considers different weights for each strategy, based on their individual performance. The metalearner's performance is analysed in scenarios based on real electricity markets data using MASCEM (Multi-Agent Simulator for Competitive Electricity Markets). Results show that the proposed metalearner is able to provide higher profits to market players when compared to other current methodologies and that results improve over time, as consequence of its learning process.",industry
10.1016/j.asoc.2016.01.004,Journal,Applied Soft Computing Journal,scopus,2016-06-01,sciencedirect,Distributed parameter system identification using finite element differential neural networks,https://api.elsevier.com/content/abstract/scopus_id/84962429243,"Most of the previous work on identification involves systems described by ordinary differential equations (ODEs). Many industrial processes and physical phenomena, however, should be modeled using partial differential equations (PDEs) which offer both spatial and temporal distributions that are simply not available with ODE models. Systems described by a PDE belong to a class of system called distributed parameter system (DPS). This article presents a method for solving the problem of identification of uncertain DPSs using a differential neural network (DNN). The DPS, assumed to be described by a PDE, is approximated using the finite element method (FEM). The FEM discretizes the domain into a set of distributed and connected nodes, thereby, allowing a representation of the DPS in a finite number of ODEs. The proposed DNN follows the same interconnection structure of the FEM, thus allowing the DNN to identify the FEM approximation of the DPS in both 2D and 3D domains. Lyapunov's second method was used to derive adaptive learning laws for the proposed DNN structure. The identification algorithm, here developed in Nvidia's CUDA/C to reduce the execution time, runs mostly on the graphics processing unit (GPU). A physical experiment served to validate the 2D case. In the experiment, the DNN followed the trajectory of 57 markers that were placed on an undulating square piece of silk. The proposed DNN is compared against a method based on principal component analysis and an artificial neural network trained with group search optimization. In addition to the 2D case, a simulation validated the 3D case, where input data for the DNN was generated by solving a PDE with appropriate initial and boundary conditions over an unitary domain. Results show that the proposed FEM-based DNN approximates the dynamic behavior of both a real 2D and a simulated 3D system.",industry
10.1016/j.engappai.2016.02.016,Journal,Engineering Applications of Artificial Intelligence,scopus,2016-06-01,sciencedirect,Label consistent semi-supervised non-negative matrix factorization for maintenance activities identification,https://api.elsevier.com/content/abstract/scopus_id/84961626004,"Health prognostic is playing an increasingly essential role in product and system management, for which non-negative matrix factorization (NMF) has been an effective method to model the high dimensional recorded data of the device or system. However, the existing unsupervised and supervised NMF models fail to learn from both labeled and unlabeled data together. Therefore, we propose a label consistent semi-supervised non-negative matrix factorization (LCSSNMF) framework that can simultaneously factorize both labeled and unlabeled data, where the discriminability of label data is preserved. Specifically, it firstly incorporates a class-wise coefficient distance regularization term that makes the coefficients for similar samples or samples with the same label close. Moreover, a label reconstruction regularization term is also presented, as the classification error with coefficient matrix of labeled data is expected as low as possible, which will potentially improve the classification accuracy in maintenance activities identification for industrial remote monitoring and diagnostics. The experiment results on real maintenance activities identification application from PHM 2013 data challenge competition demonstrate that LCSSNMF outperforms the state-of-arts NMF methods and results provided by the competition.",industry
10.1016/j.eswa.2015.12.027,Journal,Expert Systems with Applications,scopus,2016-06-01,sciencedirect,Semi-supervised support vector regression based on self-training with label uncertainty: An application to virtual metrology in semiconductor manufacturing,https://api.elsevier.com/content/abstract/scopus_id/84955137019,"Dataset size continues to increase and data are being collected from numerous applications. Because collecting labeled data is expensive and time consuming, the amount of unlabeled data is increasing. Semi-supervised learning (SSL) has been proposed to improve conventional supervised learning methods by training from both unlabeled and labeled data. In contrast to classification problems, the estimation of labels for unlabeled data presents added uncertainty for regression problems. In this paper, a semi-supervised support vector regression (SS-SVR) method based on self-training is proposed. The proposed method addresses the uncertainty of the estimated labels for unlabeled data. To measure labeling uncertainty, the label distribution of the unlabeled data is estimated with two probabilistic local reconstruction (PLR) models. Then, the training data are generated by oversampling from the unlabeled data and their estimated label distribution. The sampling rate is different based on uncertainty. Finally, expected margin-based pattern selection (EMPS) is employed to reduce training complexity. We verify the proposed method with 30 regression datasets and a real-world problem: virtual metrology (VM) in semiconductor manufacturing. The experiment results show that the proposed method improves the accuracy by 8% compared with conventional supervised SVR, and the training time for the proposed method is 20% shorter than that of the benchmark methods.",industry
10.1016/j.ins.2016.01.001,Journal,Information Sciences,scopus,2016-05-01,sciencedirect,Solving integrated process planning and scheduling problem with constructive meta-heuristics,https://api.elsevier.com/content/abstract/scopus_id/84957879888,"For product manufacturing, process planning is to select a series of manufacturing processes according to the product design specification, and scheduling is to allocate manufacturing resources such as machines and tools to these processes. It is a common problem that the process plan and the schedule are not able to cope with the changes in real time manufacturing. Integrated process planning and scheduling (IPPS) is to conduct the process planning and scheduling functions concurrently, with the aim to improve the dynamic responsiveness of the production schedule. This paper investigates the formulation and implementation of constructive meta-heuristics for solving IPPS problems. To begin with, a model representation is established to express IPPS problems with AND/OR graphs. With this model representation, a generic framework is proposed for implementing constructive meta-heuristics in the solution model. The generic framework provides a common procedure for the constructive meta-heuristics, which encapsulates the calculation of the search frontier and state transitions, and provides two interfaces for accommodating different constructive search algorithms. Ant colony optimization (ACO), a commonly-used algorithm which possesses all typical characteristics of constructive meta-heuristics, is adopted as a representative example for illustrating the implementation. Experiments and tests are conducted to validate the proposed system. The single objective minimizing the makespan is set for evaluating the performance of the proposed system. Experimental results of the benchmark problems have shown the effectiveness and high performance of the proposed approach based on the integration of the generic framework and ACO strategy.",industry
10.1016/B978-0-08-100571-2.00008-7,Book,Information Systems for the Fashion and Apparel Industry,scopus,2016-04-08,sciencedirect,Intelligent demand forecasting systems for fast fashion,https://api.elsevier.com/content/abstract/scopus_id/84979900385,"Sales forecasting in the fashion industry has been a very challenging issue for decades. Recently, the concept of fast fashion has emerged as a successful strategy for retailers. In terms of sales forecasting, this concept involves new approaches to deal with specific features such as the limited amount of historical data and shortened time for the computation. The literature review of existing methods in this domain shows that many models have been proposed. They are mainly based on artificial intelligence techniques. Among these techniques, we focus on the two models that arise as references for long-term and short-term forecasts to develop a two-stage sales forecasting system. Associated with a store replenishment model, which is inspired from a method implemented in a famous fast fashion brand, we propose to simulate our two-stage forecasting system on real data to evaluate the real benefits of advanced forecasting techniques for fast fashion retailing.",industry
10.1016/B978-0-12-803192-6.00012-8,Book,Cloud Computing in Ocean and Atmospheric Sciences,scopus,2016-03-24,sciencedirect,Using Cloud-Based Analytics to Save Lives,https://api.elsevier.com/content/abstract/scopus_id/84969730169,"The National Flood Interoperability Experiment (NFIE) is research initiative among government, academia, and industry to help demonstrate the next generation of national flood hydrology modeling to enable early warning systems and emergency response. The goal of NFIE is to answer the questions—What if it were easier to predict more accurately where floods will occur? What if more flood information could be shared in real time to aid in response that is more effective for planning and prevent deaths and property damage? This paper presents an approach to these problems based on cloud computing and machine learning. The paper also addresses the characteristics of cloud computing that can make it an attractive alternative to on-premises infrastructure for much scientific collaboration.",industry
10.1016/j.neucom.2015.11.085,Journal,Neurocomputing,scopus,2016-03-19,sciencedirect,Adaptive chaotification of robot manipulators via neural networks with experimental evaluations,https://api.elsevier.com/content/abstract/scopus_id/84951774957,"Chaotification is a problem that has been studied in recent years. It consists in injecting a chaotic behavior by means of a control scheme to a system, which in natural form does not present it. This paper explores the chaotification (also denoted anticontrol of chaos) of robot manipulators. Adaptive neural networks have the advantage of compensating the dynamics of a system with practically null information about this. By using a Lyapunov-like framework, chaotification of robot manipulators is assured with an adaptive neural network control law. A two layer neural network is used. Adaptation of the output weights are designed. Real-time experiments in a two degrees-of-freedom robot are presented. The new neural network-based controller is compared theoretically and experimentally with respect to a regressor-based controller.",industry
10.1016/j.ymssp.2015.09.025,Journal,Mechanical Systems and Signal Processing,scopus,2016-03-01,sciencedirect,Classification of acoustic emission signals using wavelets and Random Forests: Application to localized corrosion,https://api.elsevier.com/content/abstract/scopus_id/84961163563,"This paper aims to propose a novel approach to classify acoustic emission (AE) signals deriving from corrosion experiments, even if embedded into a noisy environment. To validate this new methodology, synthetic data are first used throughout an in-depth analysis, comparing Random Forests (RF) to the k-Nearest Neighbor (k-NN) algorithm. Moreover, a new evaluation tool called the alter-class matrix (ACM) is introduced to simulate different degrees of uncertainty on labeled data for supervised classification. Then, tests on real cases involving noise and crevice corrosion are conducted, by preprocessing the waveforms including wavelet denoising and extracting a rich set of features as input of the RF algorithm. To this end, a software called RF-CAM has been developed. Results show that this approach is very efficient on ground truth data and is also very promising on real data, especially for its reliability, performance and speed, which are serious criteria for the chemical industry.",industry
10.1016/j.cviu.2015.08.010,Journal,Computer Vision and Image Understanding,scopus,2016-03-01,sciencedirect,Spatio-temporal texture modelling for real-time crowd anomaly detection,https://api.elsevier.com/content/abstract/scopus_id/84956610770,"With the rapidly increasing demands from surveillance and security industries, crowd behaviour analysis has become one of the hotly pursued video event detection frontiers within the computer vision arena in recent years. This research has investigated innovative crowd behaviour detection approaches based on statistical crowd features extracted from video footages. In this paper, a new crowd video anomaly detection algorithm has been developed based on analysing the extracted spatio-temporal textures. The algorithm has been designed for real-time applications by deploying low-level statistical features and alleviating complicated machine learning and recognition processes. In the experiments, the system has been proven a valid solution for detecting anomaly behaviours without strong assumptions on the nature of crowds, for example, subjects and density. The developed prototype shows improved adaptability and efficiency against chosen benchmark systems.",industry
10.1016/j.mechatronics.2015.06.015,Journal,Mechatronics,scopus,2016-03-01,sciencedirect,Symbolic discrete-time planning with continuous numeric action parameters for agent-controlled processes,https://api.elsevier.com/content/abstract/scopus_id/84939200231,"In industrial domains such as manufacturing control, a trend away from centralized planning and scheduling towards more flexible distributed agent-based approaches could be observed over recent years. To be of practical relevance, the local control mechanisms of the autonomous agents must be able to dependably adhere and dynamically adjust to complex numeric goal systems like business key performance indicators in an economically beneficial way. However, planning with numeric state variables and objectives still poses a challenging task within the field of artificial intelligence (AI).
                  In this article, a new general-purpose AI planning approach is presented that operates in two stages and extends existing domain-independent modeling formalisms like PDDL with continuous (i.e., infinite-domain) numeric action parameters, which are currently still unsupported by state-of-the-art AI planners. In doing so, it enables the solution of mathematical optimization problems at the action level of the planning tasks, which are inherent to many real-world control problems. To deal with certain difficulties concerning reliable and fast detection of action applicability that arise when planning with real-valued action parameters, the implemented planner allows resorting to an adjustable “satisficing” strategy by means of partial execution and subsequent repair of infeasible plans over the course of time. The functioning of the system is evaluated in a multi-agent simulation of a shop floor control scenario with focus on the effects the possible problem cases and different degrees of satisficing have on attained plan quality and total planning time. As the results demonstrate the basic practicability of the approach for the given setting, this contribution constitutes an important step towards the effective and dependable integration of complex numeric goal systems and non-linear multi-criteria optimization tasks into autonomous agent-controlled industrial processes in a reusable, domain-independent way.",industry
10.1016/j.seppur.2015.12.056,Journal,Separation and Purification Technology,scopus,2016-02-29,sciencedirect,Rapid cultivation of aerobic granule for the treatment of solvent recovery raffinate in a bench scale sequencing batch reactor,https://api.elsevier.com/content/abstract/scopus_id/84954169665,"Aerobic granular sludge (AGS) was cultivated in a bench scale sequencing batch reactor within 21days. Strategy of the rapid startup was inoculated with part of mature AGS during cultivation, while aerobic biological selector was implemented for the inhibiting outgrowth of filamentous bacteria and fast selection of zoogloea bacteria. Then, the cultivated AGS was employed for the treatment of solvent recovery raffinate. Stable AGS was successfully domesticated after 55days under strategy of gradually increase the proportion of real wastewater in influent. The domesticated AGS was orange, irregular shape, smooth and compact. SVI, SV30/SV5, MLVSS/MLSS, EPS, PN/PS, average particle size, granulation rate, (SOUR)H and (SOUR)N of AGS were 19.06mL/g, 0.97, 0.55, 30.05mg/g MLVSS, 1.10, 1.28mm, 98.87%, 32.47 and 7.97mg O2/hgVSS respectively. Finally, COD, TIN, NH4
                     +–N and TP of the effluent were lower than 25.9mg/L, 1.64mg/L, 1.13mg/L and 0.21mg/L, and their removal rate was more than 98.43%, 97.12%, 98.02% and 98.09% respectively. Thus, COD, TP removal, nitrification and denitrification were realized in a single bioreactor. The result indicated that the feasibility of AGS for high C/N ratio industrial wastewater treatment.",industry
10.1016/j.compag.2015.12.009,Journal,Computers and Electronics in Agriculture,scopus,2016-02-01,sciencedirect,Early warning in egg production curves from commercial hens: A SVM approach,https://api.elsevier.com/content/abstract/scopus_id/84952683856,"Artificial Intelligence allows the improvement of our daily life, for instance, speech and handwritten text recognition, real time translation and weather forecasting are common used applications. In the livestock sector, machine learning algorithms have the potential for early detection and warning of problems, which represents a significant milestone in the poultry industry. Production problems generate economic loss that could be avoided by acting in a timely manner.
                  In the current study, training and testing of support vector machines are addressed, for an early detection of problems in the production curve of commercial eggs, using farm’s egg production data of 478,919 laying hens grouped in 24 flocks.
                  Experiments using support vector machines with a 5k-fold cross-validation were performed at different previous time intervals, to alert with up to 5days of forecasting interval, whether a flock will experience a problem in production curve. Performance metrics such as accuracy, specificity, sensitivity, and positive predictive value were evaluated, reaching 0-day values of 0.9874, 0.9876, 0.9783 and 0.6518 respectively on unseen data (test-set).
                  The optimal forecasting interval was from zero to three days, performance metrics decreases as the forecasting interval is increased. It should be emphasized that this technique was able to issue an alert a day in advance, achieving an accuracy of 0.9854, a specificity of 0.9865, a sensitivity of 0.9333 and a positive predictive value of 0.6135. This novel application embedded in a computer system of poultry management is able to provide significant improvements in early detection and warning of problems related to the production curve.",industry
10.1016/j.eswa.2015.08.048,Journal,Expert Systems with Applications,scopus,2016-02-01,sciencedirect,Time-evolving O-D matrix estimation using high-speed GPS data streams,https://api.elsevier.com/content/abstract/scopus_id/84945288965,"Portable digital devices equipped with GPS antennas are ubiquitous sources of continuous information for location-based Expert and Intelligent Systems. The availability of these traces on the human mobility patterns is growing explosively. To mine this data is a fascinating challenge which can produce a big impact on both travelers and transit agencies.
                  This paper proposes a novel incremental framework to maintain statistics on the urban mobility dynamics over a time-evolving origin-destination (O-D) matrix. The main motivation behind such task is to be able to learn from the location-based samples which are continuously being produced, independently on their source, dimensionality or (high) communicational rate. By doing so, the authors aimed to obtain a generalist framework capable of summarizing relevant context-aware information which is able to follow, as close as possible, the stochastic dynamics on the human mobility behavior. Its potential impact ranges Expert Systems for decision support across multiple industries, from demand estimation for public transportation planning till travel time prediction for intelligent routing systems, among others.
                  The proposed methodology settles on three steps: (i) Half-Space trees are used to divide the city area into dense subregions of equal mass. The uncovered regions form an O-D matrix which can be updated by transforming the trees’leaves into conditional nodes (and vice-versa). The (ii) Partioning Incremental Algorithm is then employed to discretize the target variable’s historical values on each matrix cell. Finally, a (iii) dimensional hierarchy is defined to discretize the domains of the independent variables depending on the cell’s samples.
                  A Taxi Network running on a mid-sized city in Portugal was selected as a case study. The Travel Time Estimation (TTE) problem was regarded as a real-world application. Experiments using one million data samples were conducted to validate the methodology. The results obtained highlight the straightforward contribution of this method: it is capable of resisting to the drift while still approximating context-aware solutions through a multidimensional discretization of the feature space. It is a step ahead in estimating the real-time mobility dynamics, regardless of its application field.",industry
10.1016/j.promfg.2016.08.004,Conference Proceeding,Procedia Manufacturing,scopus,2016-01-01,sciencedirect,Enhancing Spindle Power Data Application with Neural Network for Real-time Tool Wear/Breakage Prediction During Inconel Drilling,https://api.elsevier.com/content/abstract/scopus_id/85014334948,"Nowadays, digital manufacturing systems with real-time process monitoring and control are in high demand in industries for productivity and quality improvement. During machining, such a system is anticipated to excerpt reliable data within a short time-lapse, monitor tool wear progress, anticipate its wear and breakage, alert the machinist in real time to avoid unexpected failure, and help obtaining quality products. This is vital, especially, when drilling Ni-/Ti-based superalloys as catastrophic failure and premature breakage of tools occur in random manner due to aggressive welding and chipping of the rake and flank faces. Spindle power data are easy to collect from modern machine tools and can be made available for such real-time data processing. This work aims to evaluate and analyze spindle power data for real-time tool wear/breakage monitoring during drilling of a Ni-based superalloy, Inconel 625. Experiments were performed by varying speed and feed. Power data were collected from the power meter (also called load meter) of the machine spindle to feed into the neural network (NN) for functional processing. As a counterpart, force data were also collected and processed to understand the reliability of the spindle power data. The results show that the trends of these two different types of data are similar for any feed and speed combinations. It is believed that such spindle power data integrated with the artificial intelligence (NN) system can be used for real-time tool wear/breakage monitoring and process control, thus can enhance digital manufacturing systems.",industry
10.1016/j.ifacol.2016.11.160,Conference Proceeding,IFAC-PapersOnLine,scopus,2016-01-01,sciencedirect,Neural networks as a diagnosing tool for industrial level measurement through non-contacting radar type and support to the decision for its better application,https://api.elsevier.com/content/abstract/scopus_id/85006454620,"The aim of this study was to develop an analysis tool based on artificial neural networks (ANN) to detect level measurement problems with free wave propagation radars. The trend of using this type of radar has been growing in the last ten years mainly because of its easy installation on the top of tanks and reservoirs, and for its low rate maintenance comparing to other level measurement technologies. For the experiments, a Rosemount radar was used and the training of the neural network was based on the data from the software Radar Master. Therefore, some network topologies in different scenarios were tested and it was possible to demonstrate the efficiency of the ANN with accuracy rate between 94.44 to 100% for the first experiment with networks using 10, 20 or 50 neurons in the hidden layer. This technique was applied in a real industrial application, a sugar and ethanol mill, and accuracy rate was about 87,0 to 96,1%. This methodology can be applied to asset management software for diagnosis report or troubleshooting which would increase the level measurement reliability and plant safety.",industry
10.1016/j.procir.2016.06.096,Conference Proceeding,Procedia CIRP,scopus,2016-01-01,sciencedirect,Transfer of Model of Innovative Smart Factory to Croatian Economy Using Lean Learning Factory,https://api.elsevier.com/content/abstract/scopus_id/84999791899,"Croatia's manufacturing industry faces many problems and obstacles that have a large impact on its competitiveness. Insufficiently educated and unskilled personnel, particularly in the production and management fields, are decreasing competitiveness that is necessary for survival in the global market. Objective of project Innovative Smart Enterprise is to establish a special learning environment in one Laboratory asLean Learning Factory, i.e. simulation of a real factory through specialized equipment. The Lean Learning Factory's mission is to integrate needed knowledge into the engineering curriculum. Therefore, Lean Learning Factory at University of Split is in continuous developing process to support practice-based engineering curriculum with possibility of learning necessary tools and methods, using didactic games or real life products and equipment. Solution proposal for best balance between toys and real products consider design and production line development for product Karet. It is a traditional and original product from Croatia, so it will raise enthusiasmin learning process in both students and industry employees. Two assembly lines will be developed, one traditionally equipped and one intelligent, networked, flexible, and fully improved by Lean tools. By deeper analysis of both assembly lines, hybrid assembly lines could be designed, to balance on one side assembly tact time according to customer demand and total cost of installation and running on the other side. Methods and tools adapted and implemented, in both design and analysis process for optimization of this hybrid assembly line would be scaled and adjusted for industry use as part as knowledge transfer from university to enterprises.",industry
10.1016/j.ifacol.2016.07.167,Conference Proceeding,IFAC-PapersOnLine,scopus,2016-01-01,sciencedirect,A proposal for teaching SCADA systems using Virtual Industrial Plants in Engineering Education,https://api.elsevier.com/content/abstract/scopus_id/84994803392,"The main objectives of SCADA (Supervisory Control And Data Acquisition) systems are the supervisory analysis of the system, control algorithms validation, and data acquisition. These systems are normally implemented according to the international standards: UNE-EN ISO 9241, ISAIOI-Human-Machine Interfaces, ISA S5, and in the case treated in this paper The Spanish Royal Decree 488/1997. This paper presents a software architecture for the development of educational laboratories, through industrial virtual plants which models and logic are implemented in Matlab® and used within LabVIEW® through an appropriate protocol. Lab VIEW® from National Instruments, a specific purpose software for this kind of applications, was used, since it allows us to provide a friendly interface, to perform communications, data acquisition and the information management. In addition, to illustrate the use of the proposed architecture, different virtual industrial plants for students of different Bachelor and Master degrees in engineering at the University of Almeria have been developed. This paper shows the different virtual industrial plants that have been developed using SCADA systems to facilitate students’ learning of basic concepts and techniques for an Industrial Informatics course.",industry
10.1016/B978-0-444-63428-3.50407-0,Book Series,Computer Aided Chemical Engineering,scopus,2016-01-01,sciencedirect,Process Integration: Pinch Analysis and Mathematical Programming - Directions for Future Development,https://api.elsevier.com/content/abstract/scopus_id/84994259521,"Numerous studies have been performed process systems engineering field for improving the efficiency of supplying and using energy, water and other resources and consequently for reducing the emissions of greenhouse gases, volatile organic compounds and other pollutants, accumulating a significant body of methods, applications and results. It has become apparent that the resource inputs and effluents of industrial processes and the other units including the business centres, civic objects and even agricultural plants can and are often connected with each other. Most industrial plants and the other units throughout the world still use more energy and water than necessary, they are proven cases in the range 20 – 30 %, emitting too large volumes of Greenhouse Gases and other pollutants.
                  Water-saving measures and the reuse of water may reduce groundwater consumption by as much as 25 – 30 %. Usually reducing resource consumption is achieved by increasing internal recycling and the reuse of energy and material streams. Projects for improving process resource efficiencies can be very beneficial and also potentially improve the public perception of the companies.
                  Motivating, launching and carrying out such projects, however, involve appropriate optimisation, based on adequate process models, applied within the framework of appropriate resource minimisation strategies and procedures. Process Integration supporting process design, integration and optimisation has been around for nearly 45 years. It has been closely related to the development of process systems engineering, as well as utilising mathematical modelling and information technology.
                  In the broader sense Process Integration methods can be classified into those relying on process based insight and targeting on the one hand, mainly employing targeting, heuristics and artificial intelligence—AI. On the other hand are the methods employing detailed mathematical models usually implemented as algebraic models with embedded superstructures in the case of process network synthesis. The methods relying on thermodynamic insights have been first published in the early 1980-s (Linnhoff and Flower, 1978) as well as those using mathematical programming—MP (Papoulias and Grossmann, 1983). There can also be a combined approach (Klemeš and Kravanja, 2013).
                  On the one hand, the concept relying on thermodynamic and/or physical insights using the well-known Pinch Analysis has been the more widely accepted in both academia and industry. Process Integration has thus converged towards two schools of thought, the thermodynamic based (Pinch) and the mathematically based MP, each having its own advantages and drawbacks. The thermodynamic school has mostly preceded that of the MP in generating ideas based on engineering creativity. The MP school has enacted its ideas and described them as explicit mathematical models for solving advanced PI problems.
                  The collaboration between both approaches has been widening, taking from each other the more applicable parts. Its development has been accelerating as the combined methodology has been able to provide answers and support for important issues regarding economic development—energy, water and resources better utilisation and savings. This contribution is targeted towards a short overview of recent achievements and future challenges.",industry
10.1016/j.procir.2015.12.071,Conference Proceeding,Procedia CIRP,scopus,2016-01-01,sciencedirect,Enhancing Constraint Propagation in ACO-based Schedulers for Solving the Job Shop Scheduling Problem,https://api.elsevier.com/content/abstract/scopus_id/84968773482,"Increasing number of variants lead to growing complexity in planning processes in production. Not only is the initial planning a tremendous task if there is a huge variety of products but also reacting to changes becomes more frequent and more demanding. Many algorithms being able to solve the static problem need to perform a full recalculation if there is disturbance in production which makes them too time consuming for instant reactions to changes in production.
                  Ant Colony Optimization (ACO) has proven its potentials in solving the theoretical Job Shop Scheduling Problem offering the advantage of not needing an entire recalculation in the case of changes. But when using the algorithm for calculation in real time scenarios with returning data from production plants several restrictions have to be fulfilled. The reaction to those restriction is currently not sufficiently provided by implementations of the ACO which prevents the use in practical applications. These restrictions are modelled as constraints that can for example involve the reaction to disturbances like failures or manual changes. But also considering transportation times or providing the possibility to realize batch processes is discussed. There are different possibilities to realize the reactions to restrictions in ACO, but in this paper they are modelled as constraints affecting the ACO during optimization. The constraint propagation is implemented by restricting the selection of succeeding edges, an approach that only has little impact on computational performance.
                  In this paper the concept of constraining the Ant Colony Optimization in Job Shop Scheduling is being introduced and explained. Subsequently the demand for additional constraints is presented and enhancements to the existing approach are defined and commented theoretically.",industry
10.1016/j.neucom.2015.07.102,Journal,Neurocomputing,scopus,2016-01-01,sciencedirect,Optimizing the controllability index of directed networks with the fixed number of control nodes,https://api.elsevier.com/content/abstract/scopus_id/84944515482,"The studies on the controllability of complex networks, arising from natural, social, and man-made-engineered systems, have attracted great attention from both network community and control community. With the fixed number of control nodes, it is of great significance in both academic research and industrial applications to design the optimal control configurations of a directed network to make its controllability index (i.e., the maximum dimension of the controllable subnetwork) maximum. In this paper, a design strategy for the optimal control configurations is proposed, and the results of the experiments conducted on multiple real and model networks show the effectiveness of this design strategy compared to other commonly-used design strategies. Moreover, we have two interesting findings in the macroscopic level and the microscopic level, respectively: (1) the dense and homogeneous networks have larger controllability indexes than the sparse and heterogeneous ones; (2) the average in-degree of the controlled state nodes in the optimal control configurations is far less than that of the network, which provides us a heuristic way to design a sub-optimal control configuration. These findings are helpful to further our understanding on the interplay between the network structure and its control.",industry
10.1016/j.eswa.2015.07.016,Journal,Expert Systems with Applications,scopus,2016-01-01,sciencedirect,Applying supplier selection methodologies in a multi-stakeholder environment: A case study and a critical assessment,https://api.elsevier.com/content/abstract/scopus_id/84944345232,"In the contemporary global market, supplier selection represents a crucial process for enhancing firms’ competitiveness. In firms operating in low-complexity sectors, supplier selection generally leverages on few significant variables (price, delivery time, quality) and it is often left to the buyers’ experience. On the other hand, in industries characterised by remarkable product complexity, supplier selection systems gain the characteristics of a multi-stakeholder and multi-criteria problem, which needs to be theoretically formalised and realistically adapted to specific contexts.
                  An increasing number of researches have been devoted to the development of different methodologies to cope with this problem. Nevertheless, while the number of applications is growing, there is little empirical evidence of the practical usefulness of such tools, that are mainly tested on numerical examples or computational experiments and focused on a dyadic version of the problem, overlooking the wider set of actors involved in the decision-making problem. The result is a clear dichotomy between academic theory and business practice.
                  Therefore, the paper contributes to understand the above dichotomy by evaluating the applicability to real-world multi-stakeholder problems of the two main approaches proposed in the literature to deal with supplier selection, the analytic hierarchic process (AHP) and the fuzzy set theory (FST). Based on an industrial case study, a thorough discussion is developed, dealing with the issues arising during the implementation and practical functioning of such decision support systems, also providing provide practical guidelines and managerial implications.",industry
10.1016/j.ultsonch.2015.07.022,Journal,Ultrasonics Sonochemistry,scopus,2016-01-01,sciencedirect,"Impact of ultrasound on solid-liquid extraction of phenolic compounds from maritime pine sawdust waste. Kinetics, optimization and large scale experiments",https://api.elsevier.com/content/abstract/scopus_id/84938390300,"Maritime pine sawdust, a by-product from industry of wood transformation, has been investigated as a potential source of polyphenols which were extracted by ultrasound-assisted maceration (UAM). UAM was optimized for enhancing extraction efficiency of polyphenols and reducing time-consuming. In a first time, a preliminary study was carried out to optimize the solid/liquid ratio (6g of dry material per mL) and the particle size (0.26cm2) by conventional maceration (CVM). Under these conditions, the optimum conditions for polyphenols extraction by UAM, obtained by response surface methodology, were 0.67W/cm2 for the ultrasonic intensity (UI), 40°C for the processing temperature (T) and 43min for the sonication time (t). UAM was compared with CVM, the results showed that the quantity of polyphenols was improved by 40% (342.4 and 233.5mg of catechin equivalent per 100g of dry basis, respectively for UAM and CVM). A multistage cross-current extraction procedure allowed evaluating the real impact of UAM on the solid–liquid extraction enhancement. The potential industrialization of this procedure was implemented through a transition from a lab sonicated reactor (3L) to a large scale one with 30L volume.",industry
10.1016/j.cie.2015.09.007,Journal,Computers and Industrial Engineering,scopus,2015-12-01,sciencedirect,A hybrid estimation of distribution algorithm for simulation-based scheduling in a stochastic permutation flowshop,https://api.elsevier.com/content/abstract/scopus_id/84942597200,"The permutation flowshop scheduling problem (PFSP) is NP-complete and tends to be more complicated when considering stochastic uncertainties in the real-world manufacturing environments. In this paper, a two-stage simulation-based hybrid estimation of distribution algorithm (TSSB-HEDA) is presented to schedule the permutation flowshop under stochastic processing times. To deal with processing time uncertainty, TSSB-HEDA evaluates candidate solutions using a novel two-stage simulation model (TSSM). This model first adopts the regression-based meta-modelling technique to determine a number of promising candidate solutions with less computation cost, and then uses a more accurate but time-consuming simulator to evaluate the performance of these selected ones. In addition, to avoid getting trapped into premature convergence, TSSB-HEDA employs both the probabilistic model of EDA and genetic operators of genetic algorithm (GA) to generate the offspring individuals. Enlightened by the weight training process of neural networks, a self-adaptive learning mechanism (SALM) is employed to dynamically adjust the ratio of offspring individuals generated by the probabilistic model. Computational experiments on Taillard’s benchmarks show that TSSB-HEDA is competitive in terms of both solution quality and computational performance.",industry
10.1016/j.simpat.2015.05.011,Journal,Simulation Modelling Practice and Theory,scopus,2015-11-01,sciencedirect,A flexible framework for accurate simulation of cloud in-memory data stores,https://api.elsevier.com/content/abstract/scopus_id/84947019341,"In-memory (transactional) data stores, also referred to as data grids, are recognized as a first-class data management technology for cloud platforms, thanks to their ability to match the elasticity requirements imposed by the pay-as-you-go cost model. On the other hand, determining how performance and reliability/availability of these systems vary as a function of configuration parameters, such as the amount of cache servers to be deployed, and the degree of in-memory replication of slices of data, is far from being a trivial task. Yet, it is an essential aspect of the provisioning process of cloud platforms, given that it has an impact on the amount of cloud resources that are planned for usage. To cope with the issue of predicting/analysing the behavior of different configurations of cloud in-memory data stores, in this article we present a flexible simulation framework offering skeleton simulation models that can be easily specialized in order to capture the dynamics of diverse data grid systems, such as those related to the specific (distributed) protocol used to provide data consistency and/or transactional guarantees. Besides its flexibility, another peculiar aspect of the framework lies in that it integrates simulation and machine-learning (black-box) techniques, the latter being used to capture the dynamics of the data-exchange layer (e.g. the message passing layer) across the cache servers. This is a relevant aspect when considering that the actual data-transport/networking infrastructure on top of which the data grid is deployed might be unknown, hence being not feasible to be modeled via white-box (namely purely simulative) approaches. We also provide an extended experimental study aimed at validating instances of simulation models supported by our framework against execution dynamics of real data grid systems deployed on top of either private or public cloud infrastructures. Particularly, our validation test-bed has been based on an industrial-grade open-source data grid, namely Infinispan by JBoss/Red-Hat, and a de-facto standard benchmark for NoSQL platforms, namely YCSB by Yahoo. The validation study has been conducted by relying on both public and private cloud systems, scaling the underlying infrastructure up to 100 (resp. 140) Virtual Machines for the public (resp. private) cloud case. Further, we provide some experimental data related to a scenario where our framework is used for on-line capacity planning and reconfiguration of the data grid system.",industry
10.1016/j.compbiomed.2015.07.015,Journal,Computers in Biology and Medicine,scopus,2015-11-01,sciencedirect,"Implementation of a web based universal exchange and inference language for medicine: Sparse data, probabilities and inference in data mining of clinical data repositories",https://api.elsevier.com/content/abstract/scopus_id/84941884468,"We extend Q-UEL, our universal exchange language for interoperability and inference in healthcare and biomedicine, to the more traditional fields of public health surveys. These are the type associated with screening, epidemiological and cross-sectional studies, and cohort studies in some cases similar to clinical trials. There is the challenge that there is some degree of split between frequentist notions of probability as (a) classical measures based only on the idea of counting and proportion and on classical biostatistics as used in the above conservative disciplines, and (b) more subjectivist notions of uncertainty, belief, reliability, or confidence often used in automated inference and decision support systems. Samples in the above kind of public health survey are typically small compared with our earlier “Big Data” mining efforts. An issue addressed here is how much impact on decisions should sparse data have. We describe a new Q-UEL compatible toolkit including a data analytics application DiracMiner that also delivers more standard biostatistical results, DiracBuilder that uses its output to build Hyperbolic Dirac Nets (HDN) for decision support, and HDNcoherer that ensures that probabilities are mutually consistent. Use is exemplified by participating in a real word health-screening project, and also by deployment in a industrial platform called the BioIngine, a cognitive computing platform for health management.",industry
10.1016/j.asoc.2015.07.009,Journal,Applied Soft Computing,scopus,2015-08-03,sciencedirect,Fuzzy classification of pre-harvest tomatoes for ripeness estimation - An approach based on automatic rule learning using decision tree,https://api.elsevier.com/content/abstract/scopus_id/84938634597,"Tomato (Solanum lycopersicum) ripeness estimation is an important process that affects its quality evaluation and marketing. However, the slow speed, subjectivity, time consumption associated with manual assessment has been forcing the agriculture industry to apply automation through robots. The vision system of harvesting robot is responsible for two-tasks. The first task is the recognition of object (tomato) and second is the classification of recognized objects (tomatoes). In this paper, Fuzzy Rule-Based Classification approach (FRBCS) has been proposed to estimate the ripeness of tomatoes based on color. The two color depictions: red-green color difference and red-green color ratio are derived from extracted RGB color information. These are then compared as a criterion for classification. Fuzzy partitioning of the feature space into linguistic variables is done by means of a learning algorithm. A rule set is automatically generated from the derived feature set using Decision Trees. Mamdani fuzzy inference system is adopted for building the fuzzy rule based classification system that classifies the tomatoes into six maturity stages. Dataset used for experiments has been created using the real images that were collected from a farm. 70% of the total images were used for training and 30% images of the total were used for testing the dataset respectively. Training dataset is divided into six classes representing the six different stages of tomato ripeness. Experimental results showed the system achieved the ripeness classification accuracy of 94.29% using proposed FRBCS.",industry
10.1016/j.eswa.2015.04.036,Journal,Expert Systems with Applications,scopus,2015-07-28,sciencedirect,Clustering and visualization of failure modes using an evolving tree,https://api.elsevier.com/content/abstract/scopus_id/84937967581,"Despite the popularity of Failure Mode and Effect Analysis (FMEA) in a wide range of industries, two well-known shortcomings are the complexity of the FMEA worksheet and its intricacy of use. To the best of our knowledge, the use of computation techniques for solving the aforementioned shortcomings is limited. As such, the idea of clustering and visualization pertaining to the failure modes in FMEA is proposed in this paper. A neural network visualization model with an incremental learning feature, i.e., the evolving tree (ETree), is adopted to allow the failure modes in FMEA to be clustered and visualized as a tree structure. In addition, the ideas of risk interval and risk ordering for different groups of failure modes are proposed to allow the failure modes to be ordered, analyzed, and evaluated in groups. The main advantages of the proposed method lie in its ability to transform failure modes in a complex FMEA worksheet to a tree structure for better visualization, while maintaining the risk evaluation and ordering features. It can be applied to the conventional FMEA methodology without requiring additional information or data. A real world case study in the edible bird nest industry in Sarawak (Borneo Island) is used to evaluate the usefulness of the proposed method. The experiments show that the failure modes in FMEA can be effectively visualized through the tree structure. A discussion with FMEA users engaged in the case study indicates that such visualization is helpful in comprehending and analyzing the respective failure modes, as compared with those in an FMEA table. The resulting tree structure, together with risk interval and risk ordering, provides a quick and easily understandable framework to elucidate important information from complex FMEA forms; therefore facilitating the decision-making tasks by FMEA users. The significance of this study is twofold, viz., the use of a computational visualization approach to tackling two well-known shortcomings of FMEA; and the use of ETree as an effective neural network learning paradigm to facilitate FMEA implementations. These findings aim to spearhead the potential adoption of FMEA as a useful and usable risk evaluation and management tool by the wider community.",industry
10.1016/j.measurement.2015.06.004,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2015-07-06,sciencedirect,A signal pre-processing algorithm designed for the needs of hardware implementation of neural classifiers used in condition monitoring,https://api.elsevier.com/content/abstract/scopus_id/84934767009,"Gearboxes have a significant influence on the durability and reliability of a power transmission system. Currently, extensive research studies are being carried out to increase the reliability of gearboxes working in the energy industry, especially with a focus on planetary gears in wind turbines and bucket wheel excavators. In this paper, a signal pre-processing algorithm designed for condition monitoring of planetary gears working in non-stationary operation is presented. The algorithm is dedicated for hardware implementation on Field Programmable Gate Arrays (FPGAs). The purpose of the algorithm is to estimate the features of a vibration signal that are related to failures, e.g. misalignment and unbalance. These features can serve as the components of an input vector for a neural classifier. The approach proposed here has several important benefits: it is resistant to small speed fluctuations up to 7%, it can be performed in real-time conditions and its implementation does not require many resources of FPGAs.",industry
10.1016/j.ijfoodmicro.2015.03.010,Journal,International Journal of Food Microbiology,scopus,2015-07-02,sciencedirect,A strategy to establish food safety model repositories,https://api.elsevier.com/content/abstract/scopus_id/84926308733,"Transferring the knowledge of predictive microbiology into real world food manufacturing applications is still a major challenge for the whole food safety modelling community. To facilitate this process, a strategy for creating open, community driven and web-based predictive microbial model repositories is proposed. These collaborative model resources could significantly improve the transfer of knowledge from research into commercial and governmental applications and also increase efficiency, transparency and usability of predictive models. To demonstrate the feasibility, predictive models of Salmonella in beef previously published in the scientific literature were re-implemented using an open source software tool called PMM-Lab. The models were made publicly available in a Food Safety Model Repository within the OpenML for Predictive Modelling in Food community project. Three different approaches were used to create new models in the model repositories: (1) all information relevant for model re-implementation is available in a scientific publication, (2) model parameters can be imported from tabular parameter collections and (3) models have to be generated from experimental data or primary model parameters. All three approaches were demonstrated in the paper. The sample Food Safety Model Repository is available via: http://sourceforge.net/projects/microbialmodelingexchange/files/models and the PMM-Lab software can be downloaded from http://sourceforge.net/projects/pmmlab/. This work also illustrates that a standardized information exchange format for predictive microbial models, as the key component of this strategy, could be established by adoption of resources from the Systems Biology domain.",industry
10.1016/j.ifacol.2015.08.045,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-07-01,sciencedirect,Downhole pressure estimation using committee machines and neural networks,https://api.elsevier.com/content/abstract/scopus_id/84992511260,"In gas-lifted oil wells the monitoring of downhole pressure plays an important role. However, the permanent downhole gauge (PDG) sensor often fails. Because maintenance or replacement of PDGs is usually unfeasible, soft-sensors are promising alternatives to monitor the downhole pressure in the case of sensor failure. In this paper, a data-driven soft-sensor is implemented to estimate the downhole pressure using committee machines composed by finite impulse response (FIR) neural networks. Experimental results in three real datasets of the same oil well indicate that the identified soft-sensor is able to predict the downhole pressure with satisfactory accuracy. The model input variables were selected by statistical tests which increased insight concerning such variables. Committee machines outperformed single-model soft-sensors on experimental data.",industry
10.1016/j.ifacol.2015.08.106,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-07-01,sciencedirect,Path planning and motion coordination for multi-robots system using probabilistic neuro-fuzzy,https://api.elsevier.com/content/abstract/scopus_id/84992476822,"In this paper, a Neuro-fuzzy and fuzzy probabilistic coordination and path planning for multiple mobile robots are presented. The coordination relies on a leader-followers conception which means related to the leader position, the followers will behave. The method consists of two fuzzy level controllers architecture based on a fuzzy probabilistic control and an Adaptive Neuro-Fuzzy Inference System (ANFIS). Each robot has low level probabilistic fuzzy controller to eliminate the stochastic uncertainties as well as to make the multi-robots team navigates from the start point to the target point without any dangerous collision. The first order Sugeno fuzzy inference system is utilized to model the leader robot system and create the high level controller. The approach starts by generating the input/output data. Then, the subtractive clustering algorithm along with least square estimation (LSE) generates the fuzzy rules that describe the relationship between input/output data. A learning algorithm based on neural network is developed to tune parameters of membership function and the fuzzy rules are tuned by ANFIS. The feasibility and effectiveness of the proposed approach is verified by simulation. The simulation results demonstrate the effectiveness of the proposed system. In addition, some parts of the proposed approach verified by experiments on real robot.",industry
10.3382/ps/pev207,Journal,Poultry Science,scopus,2015-06-29,sciencedirect,Controlling Aspergillus flavus and Aspergillus parasiticus growth and aflatoxin production in poultry feed using carvacrol and trans-cinnamaldehyde,https://api.elsevier.com/content/abstract/scopus_id/84940837052,"Aflatoxins (AF) are toxic metabolites primarily produced by molds, Aspergillus flavus and Aspergillus parasiticus. Contamination of poultry feed with AF is a major concern to the poultry industry due to severe economic losses stemming from poor performance, reduced egg production, and diminished egg hatchability. This study investigated the inhibitory effect of 2 generally regarded as safe (GRAS), natural plant compounds, namely carvacrol (CR) and trans-cinnamaldehyde (TC), on A. flavus and A. parasiticus growth and AF production in potato dextrose broth (PDB) and in poultry feed. In broth culture, PDB supplemented with CR (0%, 0.02%, 0.04% and 0.08%) or TC (0%, 0.005%, 0.01% and 0.02%) was inoculated with A. flavus or A. parasiticus (6 log CFU/mL), and mold counts and AF production were determined on days 0, 1, 3, and 5. Similarly, 200 g portions of poultry feed supplemented with CR or TC (0%, 0.4%, 0.8%, and 1.0%) were inoculated with each mold, and their counts and AF concentrations in the feed were determined at 0, 1, 2, 3, 4, 8, and 12 weeks of storage. Moreover, the effect of CR and TC on the expression of AF synthesis genes in A. flavus and A. parasiticus (aflC, nor1, norA, and ver1) was determined using real-time quantitative PCR (RT-qPCR). All experiments had duplicate samples and were replicated 3 times. Results indicated that CR and TC reduced A. flavus and A. parasiticus growth and AF production in broth culture and chicken feed (P < 0.05). All tested concentrations of CR and TC decreased AF production in broth culture and chicken feed by at least 60% when compared to controls (P < 0.05). In addition, CR and TC down-regulated the expression of major genes associated with AF synthesis in the molds (P < 0.05). Results suggest the potential use of CR and TC as feed additives to control AF contamination in poultry feed.",industry
10.1016/j.jal.2014.11.005,Journal,Journal of Applied Logic,scopus,2015-06-01,sciencedirect,Implementation and testing of a soft computing based model predictive control on an industrial controller,https://api.elsevier.com/content/abstract/scopus_id/84922903117,"This work presents a real time testing approach of an Intelligent Multiobjective Nonlinear-Model Predictive Control Strategy (iMO-NMPC). The goal is the testing and analysis of the feasibility and reliability of some Soft Computing (SC) techniques running on a real time industrial controller. In this predictive control strategy, a Multiobjective Genetic Algorithm is used together with a Recurrent Artificial Neural Network in order to obtain the control action at each sampling time. The entire development process, from the numeric simulation of the control scheme to its implementation and testing on a PC-based industrial controller, is also presented in this paper. The computational time requirements are discussed as well. The obtained results show that the SC techniques can be considered also to tackle highly nonlinear and coupled complex control problems in real time, thus optimising and enhancing the response of the control loop. Therefore this work is a contribution to spread the SC techniques in on-line control applications, where currently they are relegated mainly to be used off-line, as is the case of optimal tuning of control strategies.",industry
10.1016/j.compind.2015.05.001,Journal,Computers in Industry,scopus,2015-05-04,sciencedirect,Artificial cognitive control with self-x capabilities: A case study of a micro-manufacturing process,https://api.elsevier.com/content/abstract/scopus_id/84955410573,"Nowadays, even though cognitive control architectures form an important area of research, there are many constraints on the broad application of cognitive control at an industrial level and very few systematic approaches truly inspired by biological processes, from the perspective of control engineering. Thus, our main purpose here is the emulation of human socio-cognitive skills, so as to approach control engineering problems in an effective way at an industrial level. The artificial cognitive control architecture that we propose, based on the shared circuits model of socio-cognitive skills, seeks to overcome limitations from the perspectives of computer science, neuroscience and systems engineering. The design and implementation of artificial cognitive control architecture is focused on four key areas: (i) self-optimization and self-leaning capabilities by estimation of distribution and reinforcement-learning mechanisms; (ii) portability and scalability based on low-cost computing platforms; (iii) connectivity based on middleware; and (iv) model-driven approaches. The results of simulation and real-time application to force control of micro-manufacturing processes are presented as a proof of concept. The proof of concept of force control yields good transient responses, short settling times and acceptable steady-state error. The artificial cognitive control architecture built into a low-cost computing platform demonstrates the suitability of its implementation in an industrial setup.",industry
10.1016/j.ifacol.2015.06.036,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-05-01,sciencedirect,Dexrov: Dexterous undersea inspection and maintenance in presence of communication latencies,https://api.elsevier.com/content/abstract/scopus_id/84992521813,"Underwater inspection and maintenance (e.g. in the oil & gas industry) are demanding and costly activities for which ROV based setups are often deployed in addition or in substitution to deep divers - contributing to operations risks and costs cutting. However the operation of a ROV requires significant off-shore dedicated manpower to handle and operate the robotic platform. In order to reduce the burden of operations, DexROV proposes to work out more cost effective and time efficient ROV operations, where manned support is in a large extent delocalized onshore (i.e. from a ROV control center), possibly at a large distance from the actual operations, relying on satellite communications. The proposed scheme also makes provision for advanced dexterous manipulation capabilities, exploiting human expertise when deemed useful. The outcomes of the project will be integrated and evaluated in a series of tests and evaluation campaigns, culminating with a realistic deep sea (1,300 meters) trial.",industry
10.1016/j.ifacol.2015.06.159,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-05-01,sciencedirect,A benchmark dataset for depth sensor based activity recognition in a manufacturing process,https://api.elsevier.com/content/abstract/scopus_id/84953879013,Algorithms for automated recognition of human activities are crucial for supporting the next generation of process measures in manufacturing. While there is active research underway for many sensor systems and algorithms they will need to be tested in real-world conditions in order to mature and become robust or generalized enough for broad deployment in industry. In this paper we present a case study and dataset from a real-world setting along with three performance measures for six common classifiers. The intent is to provide a dataset and baseline performance level metrics so that others may compare their activity recognition algorithms to a common standard.,industry
10.1016/j.ifacol.2015.06.228,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-05-01,sciencedirect,Multicast dataset synchronization and agent negotiation in distributed manufacturing control systems,https://api.elsevier.com/content/abstract/scopus_id/84953870369,"Multi agent systems represent an elegant approach for the control architecture of manufacturing systems. Distributed control architectures have the potential to achieve greater flexibility by being capable of local decision making based on real time reasoning. One of the main challenges of these distributed architectures is represented by the capability to synchronize the production data across all execution points in a reliable and consistent fashion. In this context, this paper aims to resolve the problems associated with real time production data synchronization in distributed multi-agent control systems by proposing a common dataset synchronized across all agent entities using multicast network communication. On top of this common dataset approach, an agent negotiation mechanism is proposed that addresses the operation sequencing and resource allocation in decentralized operation model. The pilot implementation is using JADE multi agent platform and JGroups for real time data synchronization and NetLogo for abstract representation of the simulation system. Experimental results gathered from the pilot implementation are discussed.",industry
10.1016/j.isatra.2014.11.011,Journal,ISA Transactions,scopus,2015-05-01,sciencedirect,Online monitoring and control of particle size in the grinding process using least square support vector regression and resilient back propagation neural network,https://api.elsevier.com/content/abstract/scopus_id/84929271125,"Particle size soft sensing in cement mills will be largely helpful in maintaining desired cement fineness or Blaine. Despite the growing use of vertical roller mills (VRM) for clinker grinding, very few research work is available on VRM modeling. This article reports the design of three types of feed forward neural network models and least square support vector regression (LS-SVR) model of a VRM for online monitoring of cement fineness based on mill data collected from a cement plant. In the data pre-processing step, a comparative study of the various outlier detection algorithms has been performed. Subsequently, for model development, the advantage of algorithm based data splitting over random selection is presented. The training data set obtained by use of Kennard–Stone maximal intra distance criterion (CADEX algorithm) was used for development of LS-SVR, back propagation neural network, radial basis function neural network and generalized regression neural network models. Simulation results show that resilient back propagation model performs better than RBF network, regression network and LS-SVR model. Model implementation has been done in SIMULINK platform showing the online detection of abnormal data and real time estimation of cement Blaine from the knowledge of the input variables. Finally, closed loop study shows how the model can be effectively utilized for maintaining cement fineness at desired value.",industry
10.1016/j.asoc.2015.03.034,Journal,Applied Soft Computing Journal,scopus,2015-04-30,sciencedirect,A genetic algorithm based decision support system for the multi-objective node placement problem in next wireless generation network,https://api.elsevier.com/content/abstract/scopus_id/84929176273,"The node placement problem involves positioning and configuring infrastructure for wireless networks. Applied to next generation networks, it establishes a new wireless architecture able to integrate heterogeneous components that can collaborate and exchange data. Furthermore, the heterogeneity of wireless networks makes the problem more intractable. This paper presents a novel multi-objective node placement problem that optimizes concurrently four objectives: maximizing communication coverage, minimizing the active structures’ costs, maximizing of the total capacity bandwidth and minimizing the noise level in the network. Known to be 
                        NP
                     -hard, the problem can be approached by applying heuristics mainly for large problem instances. As the number of nodes to place is not determined beforehand; we propose to apply a multi-objective variable-length genetic algorithm (VLGA) that simultaneously searches for the optimal number, positions and nature of heterogeneous nodes and communication devices. The performance of the VLGA is highlighted through the implementation of a decision support system (DSS) applied to the surveillance maritime problem using real data instances. We compare the ability of the proposed algorithm with an existing multi-objective model from the literature in order to validate its effectiveness in dealing with heterogeneous components. The results show that the proposed model well fits the network architecture constraints with a better balance between the objectives applied to the surveillance problem.",industry
10.1016/j.mee.2015.01.018,Journal,Microelectronic Engineering,scopus,2015-04-20,sciencedirect,An FPGA based human detection system with embedded platform,https://api.elsevier.com/content/abstract/scopus_id/84922572817,"Focusing on the computing speed of the practical machine learning based human detection system at the testing (detecting) stage to reach the real-time requirement in an embedded platform, the idea of iterative computing HOG with FPGA circuit design is proposed. The completed HOG accelerator contains gradient calculation circuit module and histogram accumulation circuit module. The linear SVM classification algorithm producing a number of necessary weak classifiers is combined with Adaboost algorithm to establish a strong classifier. The human detection is successfully implemented on a portable embedded platform to reduce the system cost and size. Experimental result shows that the performance error of accuracy appears merely about 0.1–0.4% in comparison between the presented FPGA based HW/SW co-design and the PC based pure software. Meanwhile, the computing speed achieves the requirement of a real-time embedded system, 15fps.",industry
10.1016/j.isatra.2014.09.019,Journal,ISA Transactions,scopus,2015-03-01,sciencedirect,Soft sensor for real-time cement fineness estimation,https://api.elsevier.com/content/abstract/scopus_id/84926259783,"This paper describes the design and implementation of soft sensors to estimate cement fineness. Soft sensors are mathematical models that use available data to provide real-time information on process variables when the information, for whatever reason, is not available by direct measurement. In this application, soft sensors are used to provide information on process variable normally provided by off-line laboratory tests performed at large time intervals. Cement fineness is one of the crucial parameters that define the quality of produced cement. Providing real-time information on cement fineness using soft sensors can overcome limitations and problems that originate from a lack of information between two laboratory tests. The model inputs were selected from candidate process variables using an information theoretic approach. Models based on multi-layer perceptrons were developed, and their ability to estimate cement fineness of laboratory samples was analyzed. Models that had the best performance, and capacity to adopt changes in the cement grinding circuit were selected to implement soft sensors. Soft sensors were tested using data from a continuous cement production to demonstrate their use in real-time fineness estimation. Their performance was highly satisfactory, and the sensors proved to be capable of providing valuable information on cement grinding circuit performance. After successful off-line tests, soft sensors were implemented and installed in the control room of a cement factory. Results on the site confirm results obtained by tests conducted during soft sensor development.",industry
10.1016/j.ins.2014.09.042,Journal,Information Sciences,scopus,2015-02-10,sciencedirect,Automated intelligent system for sound signalling device quality assurance,https://api.elsevier.com/content/abstract/scopus_id/84922154737,"This paper presents a novel approach to the detection and recognition of faulty audio signalling devices as part of an automated industrial manufacturing quality assurance process. The proposed system outperforms other well-established automated systems based on mel-frequency cepstrum coefficients (MFCC) and multi-layer perceptron (MLP). It uses both unlabelled sound data and labelled historical data acquired from human experts in detecting faulty signalling devices. The unlabelled data is used to train a deep neural network generative model to create multiple levels of hierarchical feature extractors which are used to train an MLP classifier, with the intent to model the human reasoning and judging processes in respect to sound classification. This paper presents the results of real world experiments based on data pertaining to the audio signalling quality assurance process for car instrument cluster manufacturing. These results show that the proposed system is able to successfully classify speakers into two groups: “Good” and “No good” depending on the part quality. The proposed system proves to be capable enough to eliminate the need for a manual inspection within the manufacturing process and is shown to be able to diagnose a fault with a high degree of accuracy. This work can be extended to other areas of automotive inspection where there is a need for a robust solution to sound detection and where an output signal is represented by a complex and changing frequency spectrum even with significant environmental noise.",industry
10.1016/j.compind.2015.05.002,Journal,Computers in Industry,scopus,2015-02-01,sciencedirect,Local weather prediction system for a heating plant using cognitive approaches,https://api.elsevier.com/content/abstract/scopus_id/84955654000,"Present-day requirements emphasize the need of saving energy. It relates mainly to industrial companies, where the minimization of energy consumption is one of their most important tasks they face. In our paper, we deal with the design of the so-called weather prediction system (WPS) for the needs of a heating plant. The primary task of such a WPS is timely predicting expected heat consumption to prepare the technology characterized by long delays in advance. Heat prediction depends primarily on weather so the crucial part of WPS is the weather, especially temperature, prediction. However, a prediction system needs a variety of further data, too. Therefore, WPS must be regarded as a complex system, including data collection, its processing, own prediction and eventual decision support. This paper gives the overview about existing data processing systems and prediction methods and then it describes a concrete design of a WPS with distributed data measuring points (stations), which are processed using a structure of neural networks based on multilayer perceptrons (MLP) with a combination of fuzzy logic. Based on real experiments we show that also such simple means as MLPs are able to solve complex problems. The paper contains a basic methodology for designing similar WPS, too.",industry
10.1016/j.compag.2014.12.010,Journal,Computers and Electronics in Agriculture,scopus,2015-02-01,sciencedirect,A Decision Support System to design modified atmosphere packaging for fresh produce based on a bipolar flexible querying approach,https://api.elsevier.com/content/abstract/scopus_id/84921031926,"To design new packaging for fresh food, stakeholders of the food chain express their needs and requirements, according to some goals and objectives. These requirements can be gathered into two groups: (i) fresh food related characteristics and (ii) packaging intrinsic characteristics. Modified Atmosphere Packaging (MAP) is an efficient way to delay senescence and spoilage and thus to extend the very short shelf life of respiring products such as fresh fruits and vegetables. Consequently, packaging O2/CO2 permeabilities must fit the requirements of fresh fruits and vegetable as predicted by virtual MAP simulating tools. Beyond gas permeabilities, the choice of a packaging material for fresh produce includes numerous other factors such as the cost, availability, potential contaminants of raw materials, process ability, and waste management constraints. For instance, the user may have the following multi-criteria query for his/her product asking for a packaging with optimal gas permeabilities that guarantee product quality and optionally a transparent packaging material made from renewable resources with a cost for raw material less than 3€/kg. To help stakeholders taking a rational decision based on the expressed needs, a new multi-criteria Decision Support System (DSS) for designing biodegradable packaging for fresh produce has been built. In this paper we present the functional specification, the software architecture and the implementation of the developed tool. This tool includes (i) a MAP simulation module combining mass transfer models and respiration of the food, (ii) a multi-criteria flexible querying module which handles imprecise, uncertain and missing data stored in the database. We detail its operational functioning through a real life case study to determine the most satisfactory materials for apricots packaging.",industry
10.1016/j.promfg.2015.07.372,Journal,Procedia Manufacturing,scopus,2015-01-01,sciencedirect,Case Study: Use of Online Tools in the Classroom and their Impact on Industrial Design Pedagogy,https://api.elsevier.com/content/abstract/scopus_id/85009959445,"Industrial Design education is going through a rapid evolution with more Design students making use of internet resources and tools such as crowdsourcing, 3D printing services, and other web-based tools to validate their ideas more quickly. The popularity of online 3D printing services such as Shapeways and Sculpteo accelerate the design process and learning. These services allow the designer to “print” virtually in any material such as plastics or metals. The impact of this new technology and other new web-based tools is significant not only in the industry but in the classroom as well. Current Industrial Design pedagogy is still partially based on technology, materials and processes that were developed a century ago. For example, pencils and paper are still the primary idea development tool. Books and magazines used to be the primary research tool but already have been surpassed by the Internet. Computer technology has improved significantly since the appearance of the first PCs, Macs and CNC machines. With all these advances in technology, one aspect of Industrial Design education that needs to be re-visited is the pedagogy of Design Drafting in this new age of online 3D printing services. The traditional Design pedagogy that was based on the development of different skills or competencies in separate courses or classes have not changed significantly in the last 40 years, 3D printing technology could potentially change this situation. Some new academic papers discuss this newer trend in Industrial Design schools but very few provide examples on how they implemented the new Internet-based 3D printing services in their curriculum. Industrial Design schools need to adapt quickly to the new reality, embracing Internet resources and online tools as core skills that every designer must have. This paper will discuss one case in particular where student projects were developed using online 3D printing services.",industry
10.1016/j.procir.2015.08.081,Conference Proceeding,Procedia CIRP,scopus,2015-01-01,sciencedirect,Predictive modelling for energy consumption in machining using artificial neural network,https://api.elsevier.com/content/abstract/scopus_id/84966564899,"The energy efficiency is important evaluation criterion for new investment in machinery and equipment in addition to the classical parameters accuracy, performance, cost and reliability. Even the users in the automotive industry demand new acquisitions of energy consumed by a machine tool during machining. Large interrelated parameters that influence the energy consumption of a machine tool make the development of an appropriate predictive model a very difficult task. In this paper, a real machining experiment is referred to investigate the capability of artificial neural network model for predicting the value of energy consumption. Results indicate that the model proposed in the research is capable of predicting the energy consumption. The present scenario demands such type of models so that the acceptability of prediction models can be raised and can be applied in sustainable process planning during the manufacturing phase of life cycle of a machine tool.",industry
10.1016/j.bica.2015.04.008,Journal,Biologically Inspired Cognitive Architectures,scopus,2015-01-01,sciencedirect,Automatic navigation of wall following mobile robot using Adaptive Resonance Theory of Type-1,https://api.elsevier.com/content/abstract/scopus_id/84960798237,"The automatic navigation of wall following robot is playing important role in various real world tasks such as underwater exploration, unmanned flight, and in automotive industries based on its computational complexity. In this work, a novel navigation approach based on biologically inspired neural network, known as “Adaptive Resonance Theory-1” which was proposed by Carpenter and Grossberg, has been implemented and investigated for navigation of wall following mobile robots. The proposed navigation algorithm is successfully tested with three sensor reading datasets obtained from clockwise navigation of SCITOS G5 mobile robot. Test decision accuracy (%), and simulation time were used as performance analysis parameters for the proposed algorithm and it has been found that the present work can achieve 99.59% of maximum decision accuracy.",industry
10.1016/j.neucom.2015.04.068,Journal,Neurocomputing,scopus,2015-01-01,sciencedirect,Locality based discriminative measure for multiple-shot human re-identification,https://api.elsevier.com/content/abstract/scopus_id/84952628215,"Multiple-shot human re-identification is an important issue in both academia and industry. It addresses the problem of building correspondences among object instances appearing in a camera network using biometric cues. Among all possible cues, face is a typical one that has long been investigated, while the whole body has become a recent trend. This problem is challenging because of small intra-class similarities and inter-class dissimilarities caused by the variations of human appearance in real scenarios. Existing methods mainly involve designing a representation and/or devising a measure to explore the within-class compactness and between-class separation. Although encouraging progress has been made, the results are still far from satisfactory. In this paper, we propose a novel set-based matching model, “Locality Based Discriminative Measure”, to re-identify the human body when a set of test samples for each person are available. A new set-to-set dissimilarity is crafted considering both majorities and minorities of samples from each pair of sets. The discriminability of this dissimilarity is then further exploited by the local metric field; it can thereby serve as a more capable low-level measure to support the high-level measure for the final matching. Extensive experiments on widely used benchmarks demonstrate that our proposal remarkably outperforms state-of-the-arts.",industry
10.1016/j.jmsy.2014.06.004,Journal,Journal of Manufacturing Systems,scopus,2015-01-01,sciencedirect,"A toolbox for the design, planning and operation of manufacturing networks in a mass customisation environment",https://api.elsevier.com/content/abstract/scopus_id/84942294486,"The task of design, planning and operation of manufacturing networks is becoming more and more challenging for companies, as globalisation, mass customisation and the turbulent economic landscape create demand volatility, uncertainties and high complexity. In this context, this paper investigates the performance of decentralised manufacturing networks through a set of methods developed into a software framework in a toolbox approach. The Tabu Search and Simulated Annealing metaheuristic methods are used together with an Artificial Intelligence method, called Intelligent Search Algorithm. A multi-criteria decision making procedure is carried out for the evaluation of the quality of alternative manufacturing network configurations using multiple conflicting criteria including dynamic complexity, reliability, cost, time, quality and environmental footprint. A comparison of the performance of each method based on the quality of the solutions that it provided is carried out. The statistical design of experiments robust engineering technique is used for the calibration of the adjustable parameters of the methods. Moreover, the impact of demand fluctuation to the operational performance of the alternative networks, expressed thorough a dynamic complexity indicator, is investigated through simulation. The developed framework is validated through a real life case, with data coming from the CNC machine building industry.",industry
10.1016/B978-0-444-63578-5.50097-9,Book Series,Computer Aided Chemical Engineering,scopus,2015-01-01,sciencedirect,Data Analysis and Modelling of a Fluid Catalytic Cracking Unit (FCCU) for an Implementation of Real Time Optimization,https://api.elsevier.com/content/abstract/scopus_id/84940474774,"In the Fluid Catalytic Cracking Units (FCCU) large hydrocarbon molecules are cracked into smaller molecules, generating high value products such as diesel, gasoline and useful petrochemical olefins. The control of these units is fundamental to maintain a satisfactory operation. Hence, the Real Time Optimization has proved an interesting strategy. A dynamic simulation of a FCCU was developed using a phenomenological industrial validated model. A Dynamic Neural Network (DNN) was trained with data from the FCCU model and gross and systematic errors were added to employ this system as a virtual plant. Data from this virtual plant were used to study strategies of online data processing, considering steady state identification (SSI) and gross error detection (GED), in order to eliminate measurement noise, as the initial steps into an RTO implementation.",industry
10.1016/j.ins.2015.06.007,Journal,Information Sciences,scopus,2015-01-01,sciencedirect,Membership-margin based feature selection for mixed type and high-dimensional data: Theory and applications,https://api.elsevier.com/content/abstract/scopus_id/84940061430,"The present paper describes a new feature weighting method based on a membership margin. Distinctive properties of the proposed method include its capability to process problems characterized by mixed-type data (quantitative, qualitative and interval) as well as a huge number of features. The key idea is to map simultaneously all the features of different types into a common space; the membership space. Once all features are represented in a homogeneous space, a feature weighting task can be performed in unified way. This weighting approach is integrated here within a fuzzy classifier through a fuzzy rule weighted concept in order to improve its performance. Each antecedent fuzzy set in the fuzzy if–then rule is weighted to characterize the importance of each proposition and therefore its corresponding feature. Weight estimation process is based on membership margin maximization to estimate a fuzzy weight of each feature in the membership space. Experiments on low and high dimensional real-world datasets demonstrate that the proposed approach can improve significantly the performance of the fuzzy rule-based as well as other state of the art classifiers and can even outperform classical feature weighting approaches. In particular, we show that this approach can yield meaningful results on two real-world applications for cancer prognosis and industrial process diagnosis.",industry
10.1016/j.procir.2015.02.113,Conference Proceeding,Procedia CIRP,scopus,2015-01-01,sciencedirect,Die lernfabrik-research-based learning for sustainable production engineering,https://api.elsevier.com/content/abstract/scopus_id/84939801646,"Engineering Education directed at topics like sustainable production or life cycle engineering needs adequate teaching approaches. Methods like research-oriented teaching, project-based learning or game-based learning are suitable techniques to promote a deeper understanding and develop competencies in respect to complex dynamic systems. However, providing appropriate teaching environments which allow for self dependent learning and practical experiences while making state of the art research insights available is quite challenging. Die Lernfabrik has been developed to suit these exact issues by providing a didactic framework for sustainable production engineering education in a real factory environment. This paper introduces a new didactic concept to combine the benefits of research-based learning approaches in engineering curriculum with the physical infrastructure of Die Lernfabrik. While gaining theoretical background in a related lecture, students utilize machinery and installations of the learning factory independently for experiments to solve their self-chosen research questions. Application and validation of the concept are exemplified by the TU Braunschweig course Energy Efficiency in Production Engineering, focusing on energy efficiency solutions for production systems. It could be proved that the individual learning motivation and success of the students as well as their competency to solve real engineering problems was significantly improved by the new approach.",industry
10.1016/j.procir.2014.07.072,Conference Proceeding,Procedia CIRP,scopus,2015-01-01,sciencedirect,Predictive modeling for power consumption in machining using artificial intelligence techniques,https://api.elsevier.com/content/abstract/scopus_id/84939211709,"The objective of this work is to highlight the modeling capabilities of artificial intelligence techniques for predicting the power requirements in machining process. The present scenario demands such types of models so that the acceptability of power prediction models can be raised and can be applied in sustainable process planning. This paper presents two artificial intelligence modeling techniques - artificial neural network and support vector regression - used for predicting the power consumed in machining process. In order to investigate the capability of these techniques for predicting the value of power, a real machining experiment is performed. Experiments are designed using Taguchi method so that effect of all the parameters could be studied with minimum possible number of experiments. A L16 (43) 4-level 3-factor Taguchi design is used to elaborate the plan of experiments. The power predicted by both techniques are compared and evaluated against each other and it has been found that ANN slightly performs better as compare to SVR. To check the goodness of models, some representative hypothesis tests t-test to test the means, f-test and Leven's test to test variance are conducted. Results indicate that the models proposed in the research are suitable for predicting the power.",industry
10.1016/j.virusres.2015.07.010,Journal,Virus Research,scopus,2015-01-01,sciencedirect,Isolation and characterization of a Korean porcine epidemic diarrhea virus strain KNU-141112,https://api.elsevier.com/content/abstract/scopus_id/84938696515,"Severe outbreaks of porcine epidemic diarrhea virus (PEDV) have re-emerged in Korea and rapidly swept across the country, causing tremendous economic losses to producers and customers. Despite the availability of PEDV vaccines in the domestic market, the disease continues to plague the Korean pork industry, raising issues regarding their protective efficacy and new vaccine development. Therefore, PEDV isolation in cell culture is urgently needed to develop efficacious vaccines and diagnostic assays and to conduct further studies on the virus biology. In the present study, one Korean PEDV strain, KOR/KNU-141112/2014, was successfully isolated and serially propagated in Vero cells for over 30 passages. The in vitro and in vivo characteristics of the Korean PEDV isolate were investigated. Virus production in cell culture was confirmed by cytopathology, immunofluorescence, and real-time RT-PCR. The infectious virus titers of the viruses during the first 30 passages ranged from 105.1 to 108.2 TCID50 per ml. The inactivated KNU-141112 virus was found to mediate potent neutralizing antibody responses in immunized guinea pigs. Animal studies showed that KNU-141112 virus causes severe diarrhea and vomiting, fecal shedding, and acute atrophic enteritis, indicating that strain KNU-141112 is highly enteropathogenic in the natural host. In addition, the entire genomes or complete S genes of KNU-141112 viruses at selected cell culture passages were sequenced to assess the genetic stability and relatedness. Our genomic analyses indicated that the Korean isolate KNU-141112 is genetically stable during the first 30 passages in cell culture and is grouped within subgroup G2b together with the recent re-emergent Korean strains.",industry
10.1016/S1006-706X(15)30031-5,Journal,Journal of Iron and Steel Research International,scopus,2015-01-01,sciencedirect,Intelligent Multivariable Modeling of Blast Furnace Molten Iron Quality Based on Dynamic AGA-ANN and PCA,https://api.elsevier.com/content/abstract/scopus_id/84937545858,"Blast furnace (BF) ironmaking process has complex and nonlinear dynamic characteristics. The molten iron temperature (MIT) as well as Si, P and S contents of molten iron is difficult to be directly measured online, and large-time delay exists in offline analysis through laboratory sampling. A nonlinear multivariate intelligent modeling method was proposed for molten iron quality (MIQ) based on principal component analysis (PCA) and dynamic genetic neural network. The modeling method used the practical data processed by PCA dimension reduction as inputs of the dynamic artificial neural network (ANN). A dynamic feedback link was introduced to produce a dynamic neural network on the basis of traditional back propagation ANN. The proposed model improved the dynamic adaptability of networks and solved the strong fluctuation and resistance problem in a nonlinear dynamic system. Moreover, a new hybrid training method was presented where adaptive genetic algorithms (AGA) and ANN were integrated, which could improve network convergence speed and avoid network into local minima. The proposed method made it easier for operators to understand the inside status of blast furnace and offered real-time and reliable feedback information for realizing close-loop control for MIQ. Industrial experiments were made through the proposed model based on data collected from a practical steel company. The accuracy could meet the requirements of actual operation.",industry
10.1016/j.neucom.2014.09.030,Journal,Neurocomputing,scopus,2015-01-01,sciencedirect,A multiobjective optimization-based neural network model for short-term replenishment forecasting in fashion industry,https://api.elsevier.com/content/abstract/scopus_id/84922757376,"A multiobjective optimization-based neural network (MOONN) model is proposed to tackle the short-term replenishment forecasting problem in fashion industry. Our approach utilizes a new multiobjective evolutionary algorithm called nondominated sorting adaptive differential evolution algorithm (NSJADE) to optimize the weights of neural networks (NNs) for the short-term replenishment forecasting problem, acquiring the forecasting accuracy while alleviating the overfitting effect at the same time. The presented NSJADE also selects the appropriate number of hidden nodes for the NN according to different short-term replenishment forecasting problems. Extensive experiments based on real fashion industry data are performed to validate the effectiveness of the developed model. Experimental results reveal that the performance of the proposed model is superior than several popular models for the short-term replenishment forecasting problem.",industry
10.1016/j.measurement.2014.11.031,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2015-01-01,sciencedirect,Lithium-ion battery remaining useful life estimation with an optimized Relevance Vector Machine algorithm with incremental learning,https://api.elsevier.com/content/abstract/scopus_id/84919789608,"Lithium-ion battery plays a key role in most industrial systems, which is critical to the system availability. It is important to evaluate the performance degradation and estimate the remaining useful life (RUL) for those batteries. With the capability of uncertainty representation and management, Relevance Vector Machine (RVM) becomes an effective approach for lithium-ion battery RUL estimation. However, small sample size and low precision of multi-step prediction limits its application in battery RUL estimation for sparse RVM algorithm. Due to the continuous on-line update of monitoring data, to improve the prediction performance of battery RUL model, dynamic training and on-line learning capability is desirable. Another challenge in on-line and real-time processing is the operating efficiency and computational complexity. To address these issues, this paper implements a flexible and effective on-line training strategy in RVM algorithm to enhance the prediction ability, and presents an incremental optimized RVM algorithm to the model via efficient on-line training. The proposed on-line training strategy achieves a better prediction precision as well as improves the operating efficiency for battery RUL estimation. Experiments based on NASA battery data set show that the proposed method yields a satisfied performance in RUL estimation of lithium-ion battery.",industry
10.1016/j.future.2014.11.015,Journal,Future Generation Computer Systems,scopus,2015-01-01,sciencedirect,On-line failure prediction in safety-critical systems,https://api.elsevier.com/content/abstract/scopus_id/84917709364,"In safety-critical systems such as Air Traffic Control system, SCADA systems, Railways Control Systems, there has been a rapid transition from monolithic systems to highly modular ones, using off-the-shelf hardware and software applications possibly developed by different manufactures. This shift increased the probability that a fault occurring in an application propagates to others with the risk of a failure of the entire safety-critical system. This calls for new tools for the on-line detection of anomalous behaviors of the system, predicting thus a system failure before it happens, allowing the deployment of appropriate mitigation policies.
                  The paper proposes a novel architecture, namely CASPER, for online failure prediction that has the distinctive features to be (i) black-box: no knowledge of applications internals and logic of the system is required (ii) non-intrusive: no status information of the components is used such as CPU or memory usage; The architecture has been implemented to predict failures in a real Air Traffic Control System. CASPER exhibits high degree of accuracy in predicting failures with low false positive rate. The experimental validation shows how operators are provided with predictions issued a few hundred of seconds before the occurrence of the failure.",industry
10.1016/j.ijpe.2014.09.004,Journal,International Journal of Production Economics,scopus,2015-01-01,sciencedirect,An RFID-based intelligent decision support system architecture for production monitoring and scheduling in a distributed manufacturing environment,https://api.elsevier.com/content/abstract/scopus_id/84915733989,"Global manufacturing companies have some pressing needs to improve production visibility and decision-making performance by implementing effective production monitoring and scheduling. This paper proposes a radio frequency identification (RFID)-based intelligent decision support system architecture to handle production monitoring and scheduling in a distributed manufacturing environment. A pilot implementation of the architecture is reported in a distributed clothing manufacturing environment. RFID and cloud technologies were integrated for real-time and remote production capture and monitoring. Intelligent optimization techniques were also implemented to generate effective production scheduling solutions. A prototype system with remote monitoring and production scheduling functions was developed and implemented in a distributed manufacturing environment, which demonstrated the effectiveness of the architecture. The proposed architecture has good extensibility and scalability, which can easily be integrated with production decision-making as well as production and logistics operations in the supply chain. Lastly, this paper discusses the difficulties encountered and lessons learned during system implementation and the managerial implications of the proposed architecture.",industry
10.1016/j.asoc.2014.10.018,Journal,Applied Soft Computing Journal,scopus,2015-01-01,sciencedirect,Performance assessment of heat exchanger using intelligent decision making tools,https://api.elsevier.com/content/abstract/scopus_id/84912132496,"Process and manufacturing industries today are under pressure to deliver high quality outputs at lowest cost. The need for industry is therefore to implement cost savings measures immediately, in order to remain competitive. Organizations are making strenuous efforts to conserve energy and explore alternatives. This paper explores the development of an intelligent system to identify the degradation of heat exchanger system and to improve the energy performance through online monitoring system. The various stages adopted to achieve energy performance assessment are through experimentation, design of experiments and online monitoring system. Experiments are conducted as per full factorial design of experiments and the results are used to develop artificial neural network models. The predictive models are used to predict the overall heat transfer coefficient of clean/design heat exchanger. Fouled/real system value is computed with online measured data. Overall heat transfer coefficient of clean/design system is compared with the fouled/real system and reported. It is found that neural net work model trained with particle swarm optimization technique performs better comparable to other developed neural network models. The developed model is used to assess the performance of heat exchanger with the real/fouled system. The performance degradation is expressed using fouling factor, which is derived from the overall heat transfer coefficient of design system and real system. It supports the system to improve the performance by asset utilization, energy efficient and cost reduction in terms of production loss. This proposed online energy performance system is implemented into the real system and the adoptability is validated.",industry
10.1016/j.engappai.2014.09.011,Journal,Engineering Applications of Artificial Intelligence,scopus,2015-01-01,sciencedirect,Automatic amber gemstones identification by color and shape visual properties,https://api.elsevier.com/content/abstract/scopus_id/84910595337,"This paper proposes and describes novel techniques for the amber gemstones labeling system. The amber data used in experiments are collected by amber art craft industry experts and the presented investigations were carried out in order to develop a classifier for online amber sorting application. Amber pieces are identified and labeled to one of 30 color classes or to one of 20 geometric shape classes. For identification Quadratic Discriminant Analysis, K Nearest Neighbors, Radial Basis Function, Naive Bayes, Decision Tree, and pruned Decision Tree classifiers were tested. As color descriptive features mean, standard deviation, kurtosis, and skewness calculated on amber pixels from grayscale and HSV color spaces were chosen. The best classification result with the features calculation on all the pixels of sample was 69.29% accuracy, obtained by Pruned Decision Tree classifier. In order to improve the classification results, the pixels of amber samples were grouped into predefined concentric ring segments and the accuracy rose by 10%. Then the final improvement was introduced by forming a committee of Decision Tree classifiers with Half&Half method which increased accuracy up to 81.60%. For shapes identification the Centroid Distance Function was selected as it preserves the order of landmark points. Using labeled samples the Decision Tree classifier was trained. The training of classifier was made by acquiring all possible orientations of Centroid Distance Function for each image in training set and then feeding them to Decision Tree. In the classification step all the shifted and flipped Centroid Distance Function variations of the testing sample are voting for the class using the trained Decision Tree. Experimental results have shown that the proposed technique is effective in organic shapes classification to selected geometric shapes even if there is high ambiguity between organic shapes and 72.10% accuracy was acquired. Both proposed classifiers can be used in real time application independently or in combination.",industry
10.1016/j.jss.2014.07.038,Journal,Journal of Systems and Software,scopus,2014-11-01,sciencedirect,A learning-based module extraction method for object-oriented systems,https://api.elsevier.com/content/abstract/scopus_id/84908163044,"Developers apply object-oriented (OO) design principles to produce modular, reusable software. Therefore, service-specific groups of related software classes called modules arise in OO systems. Extracting the modules is critical for better software comprehension, efficient architecture recovery, determination of service candidates to migrate legacy software to a service-oriented architecture, and transportation of such services to cloud-based distributed systems. In this study, we propose a novel approach to automatic module extraction to identify services in OO software systems. In our approach, first we create a weighted and directed graph of the software system in which vertices and edges represent the classes and their relations, respectively. Then, we apply a clustering algorithm over the graph to extract the modules. We calculate the weight of an edge by considering its probability of being within a module or between modules. To estimate these positional probabilities, we propose a machine-learning-based classification system that we train with data gathered from a real-world OO reference system. We have implemented an automatic module extraction tool and evaluated the proposed approach on several open-source and industrial projects. The experimental results show that the proposed approach generates highly accurate decompositions that are close to authoritative module structures and outperforms existing methods.",industry
10.1016/j.neucom.2014.03.043,Journal,Neurocomputing,scopus,2014-10-22,sciencedirect,Employing box plots to build high-dimensional manufacturing models for new products in TFT-LCD plants,https://api.elsevier.com/content/abstract/scopus_id/84904317401,"Electronics product life cycles are becoming shorter and shorter because of the severe global competition. In such highly competitive industry, it has become an important strategy to accelerate new products launching to the market to earn more shares. However, the lead times of pilot runs are usually long in new product development (NPD) processes, and reducing pilot runs has thus become one of the key tasks of manufacturing systems. Specifically, since the shorter a test period is the smaller sample size one can obtain, making that to find a small data learning method for a manufacturing system being a new challenge. Facing the problem, this work, based on the box plots and the fuzzy techniques, develops an approach to systematically generate synthetic samples to help stabilize the learning process for the used back-propagation neural network (BPN). A real learning task taken from the Array process of a TFT-LCD manufacturer (a new high-resolution product of 4K2K in 2013) is employed as an example to illustrate the details of the proposed method. The task contains nine inputs and 72 output manufacturing attributes, but only with 20 samples. It is quite difficult for most existing modeling algorithms to deal with such a high dimensional situation when the sample size is small. The experiment results show that the proposed approach can effectively improve the robustness and preciseness of a BPN forecasting model. In addition to the reduction of pilot runs, more process knowledge is obtained in the input–output analysis.",industry
10.1016/j.cej.2014.05.055,Journal,Chemical Engineering Journal,scopus,2014-10-01,sciencedirect,C2/C3 fatty acid stress on anammox consortia dominated by Candidatus Jettenia asiatica,https://api.elsevier.com/content/abstract/scopus_id/84902149235,"Anaerobic ammonium oxidation (anammox) is a promising technology for autotrophic removal of ammonium and nitrite. In order to expand its industrial application niche, effects of organic matter need more specific investigation. In this study, the effects of C2/C3 fatty acids stress on anaerobic ammonium oxidation (anammox) process were evaluated in batch experiments. BLAST search analysis of 16S rRNA sequences showed that the homology of the highly enriched anammox consortia used here and Candidatus Jettenia asiatica (J. asiatica) reached 99%. Results showed that low acetate (⩽30mg/L) and propionate (⩽50mg/L) concentration does not significantly influence ammonium oxidation. Higher acetate/propionate concentrations caused decrease of ammonium removal. A level of acetate no more than 240mg/L caused the decrease of ammonium consumption rate by 33%, and 29% for propionate with (<400mg/L). J. asiatica showed higher adaptability to propionate stress than acetate. Real-time quantitative PCR (qPCR) results reveal that anammox bacteria J. asiatica are capable of growing at the present of low-concentration acetate (⩽120mg/L)/propionate (⩽200mg/L). The anammox hzo gene concentrations reached to round 0.5×108–1.0×108
                     copies/ml after 36days cultivation with C2/C3 fatty acid. However, there is no superiority for J. asiatica consortia to grow under organotrophic conditions compared to autotrophic ones.",industry
10.1016/j.ejor.2014.02.032,Journal,European Journal of Operational Research,scopus,2014-09-16,sciencedirect,A hybrid wrapper-filter approach to detect the source(s) of out-of-control signals in multivariate manufacturing process,https://api.elsevier.com/content/abstract/scopus_id/84899898372,"With modern data-acquisition equipment and on-line computers used during production, it is now common to monitor several correlated quality characteristics simultaneously in multivariate processes. Multivariate control charts (MCC) are important tools for monitoring multivariate processes. One difficulty encountered with multivariate control charts is the identification of the variable or group of variables that cause an out-of-control signal. Expert knowledge either in combination with wrapper-based supervised classifier or a pre-filter with wrapper are the standard approaches to detect the sources of out-of-control signal. However gathering expert knowledge in source identification is costly and may introduce human error. Individual univariate control charts (UCC) and decomposition of 
                        
                           
                              
                                 T
                              
                              
                                 2
                              
                           
                        
                      statistics are also used in many cases simultaneously to identify the sources, but these either ignore the correlations between the sources or may take more time with the increase of dimensions. The aim of this paper is to develop a source identification approach that does not need any expert-knowledge and can detect out-of-control signal in less computational complexity. We propose, a hybrid wrapper–filter based source identification approach that hybridizes a Mutual Information (MI) based Maximum Relevance (MR) filter ranking heuristic with an Artificial Neural Network (ANN) based wrapper. The Artificial Neural Network Input Gain Measurement Approximation (ANNIGMA) has been combined with MR (MR-ANNIGMA) to utilize the knowledge about the intrinsic pattern of the quality characteristics computed by the filter for directing the wrapper search process. To compute optimal ANNIGMA score, we also propose a Global MR-ANNIGMA using non-functional relationship between variables which is independent of the derivative of the objective function and has a potential to overcome the local optimization problem of ANN training. The novelty of the proposed approaches is that they combine the advantages of both filter and wrapper approaches and do not require any expert knowledge about the sources of the out-of-control signals. Heuristic score based subset generation process also reduces the search space into polynomial growth which in turns reduces computational time. The proposed approaches were tested by exhaustive experiments using both simulated and real manufacturing data and compared to existing methods including independent filter, wrapper and Multivariate EWMA (MEWMA) methods. The results indicate that the proposed approaches can identify the sources of out-of-control signals more accurately than existing approaches.",industry
10.1016/j.jhazmat.2014.07.071,Journal,Journal of Hazardous Materials,scopus,2014-09-15,sciencedirect,Batch and fixed-bed assessment of sulphate removal by the weak base ion exchange resin Amberlyst A21,https://api.elsevier.com/content/abstract/scopus_id/84906355472,"This paper investigated sulphate removal from aqueous solutions by Amberlyst A21, a polystyrene weak base ion exchange resin. Both the pH and initial sulphate concentration were observed to strongly affect sorption yields, which were largest in acidic environments. Working under optimum operational conditions, sulphate sorption by Amberlyst A21 was relatively fast and reached equilibrium after 45min of contact between the solid and liquid phases. Sorption kinetics could be described by either the pseudo-first order (k
                     1
                     =3.05×10−5
                     s−1) or pseudo-second order model (k
                     2
                     =1.67×10−4
                     s−1), and both the Freundlich and Langmuir models successfully fitted the equilibrium data. Sulphate uptake by Amberlyst A21 was a physisorption process (ΔH
                     =−25.06kJmol−1) that occurred with entropy reduction (ΔS
                     =−0.042kJmol−1
                     K−1). Elution experiments showed that sulphate is easily desorbed (∼100%) from the resin by sodium hydroxide solutions at pH 10 or pH 12. Fixed-bed experiments assessed the effects of the initial sulphate concentration, bed height and flow rate on the breakthrough curves and the efficiency of the Amberlyst A21 in the treatment of a real effluent. In all studied conditions, the maximum sulphate loading resin varied between 8 and 40mg(SO4
                     2−)mL(resin)−1.",industry
10.1016/j.neucom.2013.07.048,Journal,Neurocomputing,scopus,2014-05-20,sciencedirect,Customer profile classification: To adapt classifiers or to relabel customer profiles?,https://api.elsevier.com/content/abstract/scopus_id/84896722022,"Customer profiles are, by definition, made up of factual and transactional data. It is often the case that due to reasons such as high cost of data acquisition and/or protection, only the transactional data are available for data mining operations. Transactional data, however, tend to be highly sparse and skewed due to a large proportion of customers engaging in very few transactions. This can result in a bias in the prediction accuracy of classifiers built using them. The problem is even more so when identifying and classifying changing customer profiles whose classification may change either due to a concept drift or due to a change in buying behaviour. This paper presents a comparative investigation of 4 approaches for classifying dynamic customer profiles built using evolving transactional data over time. The changing class values of the customer profiles were analysed together with the challenging problem of deciding whether to change the class label or adapt the classifier. The results from the experiments we conducted on a highly sparse and skewed real-world transactional data show that adapting the classifiers leads to more stable classification of customer profiles in the shorter time windows; while relabelling the changed customer profile classes leads to more accurate and stable classification in the longer time windows.",industry
10.1016/j.mejo.2013.12.006,Journal,Microelectronics Journal,scopus,2014-03-01,sciencedirect,Enhancing confidence in indirect analog/RF testing against the lack of correlation between regular parameters and indirect measurements,https://api.elsevier.com/content/abstract/scopus_id/84897670549,"The greedy specification testing remains mandatory for analog and radio frequency (RF) integrated circuits because of the accuracy of the sorting based on these measurements. Unfortunately, to be implemented, this kind of testing method often incurs very high costs (expensive instruments, long test time…). A common approach, in the literature, is the so-called indirect/alternate test strategy. This strategy consists in deriving targeted specifications from low-cost Indirect Measurements (IMs). During the industrial test phase, the estimation of regular specifications using IMs is based on a correlation model that has been built previously, during a training phase. Despite the substantial test cost reduction offered by this strategy, its deployment in industry is limited, mainly because of a lack of confidence in the accuracy of estimations made by the correlation model. A solution to increase the confidence in the estimation of specifications using the indirect approach is to implement redundancy in the prediction phase. In this paper, we demonstrate that the redundancy implementation brings more than identifying rare misjudged circuits from a high-correlated model. Indeed redundancy massively increases the accuracy despite of the lack of accurate models that have been assumed in previous implementations of redundant indirect testing. This approach is illustrated on a real case study for which we have experimental measurements on a set of 10,000 devices.",industry
10.1016/j.patcog.2013.09.007,Journal,Pattern Recognition,scopus,2014-03-01,sciencedirect,The cluster assessment of facial attractiveness using fuzzy neural network classifier based on 3D Moiré features,https://api.elsevier.com/content/abstract/scopus_id/84888386508,"Facial attractiveness has long been argued upon varied emphases by philosophers, artists, psychologists and biologists. A number of studies empirically investigated how facial attractiveness was influenced by 2D facial characteristics, such as symmetry, averageness and golden ratio. However, few implementations of facial beauty assessment were based on 3D facial features. The purpose of this paper is to propose a novel cluster assessment system for facial attractiveness that is characterized by the incorporation of 3D geometric Moiré features with an adjusted fuzzy neural network (FNN). We first extract 3D facial features from images acquired by a 3dMD scanner. Seven Moiré features are employed to represent a 3D facial image. The FNN classifier, taking the Moiré features as the parameters, is then trained and validated against independently conducted attractiveness ratings. A number of diverse referees were invited and offered their attractiveness ratings over a five-item Likert scale for 100 female facial images. The proposed assessment presents a high accuracy rate of 90%, and the area under curve (AUC) computed from the receiver operating characteristic (ROC) curve is 0.95. The results show that the perceptions of facial attractiveness are essentially consensus among raters, and can be mathematically modeled through supervised learning techniques. The high accuracy achieved proves that the proposed FNN classifier can serve as a general, automated and human-like judgment tool for objective classification of female facial attractiveness, and thus has potential applications to the entertainment industry, cosmetic industry, virtual media, and plastic surgery.",industry
10.1016/j.enbuild.2014.08.004,Journal,Energy and Buildings,scopus,2014-01-01,sciencedirect,Neural network model ensembles for building-level electricity load forecasts,https://api.elsevier.com/content/abstract/scopus_id/84907570987,"The future power grid is expected to provide unprecedented flexibility in how energy is generated, distributed, and managed, which increasingly necessitates an ability to perform accurate short-term small-scale electricity load and generation forecasting, e.g., at the level of individual buildings or sites. In this paper, we present a novel building-level neural network-based ensemble model for day-ahead electricity load forecasting and show that it outperforms the previously established best performing model, SARIMA, by up to 50%, in the context of load data from half a dozen operational commercial and industrial sites. In addition, we show a straightforward, automated way to select model parameters, making our model practical for use in real deployments.",industry
10.1016/j.cjche.2014.05.011,Journal,Chinese Journal of Chemical Engineering,scopus,2014-01-01,sciencedirect,A graph-based ant colony optimization approach for integrated process planning and scheduling,https://api.elsevier.com/content/abstract/scopus_id/84906327432,"This paper considers an ant colony optimization algorithm based on AND/OR graph for integrated process planning and scheduling (IPPS). Generally, the process planning and scheduling are studied separately. Due to the complexity of manufacturing system, IPPS combining both process planning and scheduling can depict the real situation of a manufacturing system. The IPPS is represented on AND/OR graph consisting of nodes, and undirected and directed arcs. The nodes denote operations of jobs, and undirected/directed arcs denote possible visiting path among the nodes. Ant colony goes through the necessary nodes on the graph from the starting node to the end node to obtain the optimal solution with the objective of minimizing makespan. In order to avoid local convergence and low convergence, some improved strategy is incorporated in the standard ant colony optimization algorithm. Extensive computational experiments are carried out to study the influence of various parameters on the system performance.",industry
10.1016/j.asoc.2014.06.020,Journal,Applied Soft Computing Journal,scopus,2014-01-01,sciencedirect,Multi-agent based approach for single machine scheduling with sequence-dependent setup times and machine maintenance,https://api.elsevier.com/content/abstract/scopus_id/84903934434,"Scheduling of single machine in manufacturing systems is especially complex when the order arrivals are dynamic. The complexity of the problem increases by considering the sequence-dependent setup times and machine maintenance in dynamic manufacturing environment. Computational experiments in literature showed that even solving the static single machine scheduling problem without considering regular maintenance activities is NP-hard. Multi-agent systems, a branch of artificial intelligence provide a new alternative way for solving dynamic and complex problems. In this paper a collaborative multi-agent based optimization method is proposed for single machine scheduling problem with sequence-dependent setup times and maintenance constraints. The problem is solved under the condition of both regular and irregular maintenance activities. The solutions of multi-agent based approach are compared with some static single machine scheduling problem sets which are available in the literature. The method is also tested under real-time manufacturing environment where computational time plays a critical role during decision making process.",industry
10.1016/j.anifeedsci.2014.04.017,Journal,Animal Feed Science and Technology,scopus,2014-01-01,sciencedirect,Keeping under control a liquid feed fermentation process for pigs: A reality scale pilot based study,https://api.elsevier.com/content/abstract/scopus_id/84903816625,"An original and fully automated liquid feeding pilot has been designed and implemented to monitor and optimize the fermentation process of liquid feed for pigs at a pre-industrial scale. The installation was designed and instrumented to continuously record the temperature, pH and redox potential (E
                     
                        h
                     ) during the fermentation course of wheat flour based feed mixed with water in a 1:2.5 (w:w) ratio. Single and multiple batches experiments were carried-out with feed inoculation achieved by leftover or with a selected culture of lactic acid producing bacteria (LAB). Physicochemical and microbiological characteristics of the fermentation process which include lactic and acetic acids and ethanol concentrations, enumerations of lactic acid producing bacteria, yeasts, total coliforms and Escherichia coli, were monitored and analyzed as a function of the main feed control factors: incubation time, operating temperature, feed time schedule and percentage of leftover. From batch experiments, it was observed that increasing the operating temperature from 15 to 30°C, accelerates the rate of fermentation by reducing about 5–6-folds the process latency and the duration to reach a pH value of 4.0 which is considered as optimal to achieve biosafety. Nevertheless, this does not prevent the blooming of coliforms as their counts increases from 4 to 6 log10
                     CFU/mL within 24h. In opposite, multiple batches are proved to be effective in both accelerating the fermentation rates and reducing the survival of Coliform bacteria in fermented liquid feed (FLF). Feed fermented at 25°C during 24-h cycles with a 22% leftover ensures the prominence of LAB strains over yeasts with a population level that stabilizes at around 9 log10
                     CFU/mL (vs. 7 log10
                     CFU/mL for single batches), a lactic acid production up to 35g/kg dry matter (DM) and a pH value between 5 and 3.5 throughout the period. Concomitantly, total Coliforms number decreases from 7.5 to 2.2 log10
                     CFU/mL within 72h whereas E. coli became undetectable beyond 48h. Addition of a starter culture (Pediococcus acidilactici, Bactocell®) at 9 log10
                     CFU/kg DM at the initial stage of FLF production reduces 25–35 times the total coliforms and E. coli counts. No significant differences in the amounts of organic compounds produced by the microflora as compared to the control FLF after 80h nor in the microbial levels are observed. It is concluded that sequences of fermentation cycles allows, in a given temperature range, establishing a positive, robust, microbial ecosystem.",industry
10.1016/j.powtec.2014.05.051,Journal,Powder Technology,scopus,2014-01-01,sciencedirect,"Soft sensing of particle size in a grinding process: Application of support vector regression, fuzzy inference and adaptive neuro fuzzy inference techniques for online monitoring of cement fineness",https://api.elsevier.com/content/abstract/scopus_id/84902965121,"Use of soft sensors for online particle size monitoring in a grinding process is a viable alternative since physical sensors for the same are not available for many such processes. Cement fineness is an important quality parameter in the cement grinding process. However, very few studies have been done for soft sensing of cement fineness in the grinding process. Moreover, most of the grinding process modeling approaches have been reported for ball mills and rarely any modeling of vertical roller mill is available. In this research, modeling of vertical roller mill used for clinker grinding has been done using support vector regression (SVR), fuzzy inference and adaptive neuro fuzzy inference(ANFIS) techniques since these techniques have not yet been largely explored for particle size soft sensing. The modeling has been done by collection of the real industrial data from a cement grinding process followed by data cleaning and a structured method of dividing the data into training and validation data sets using the Kennard–Stone subset selection algorithm. Optimum SVR hyper parameters were determined using a combined approach of analytical method and grid search plus cross validation. The models were developed using MATLAB from the training data and were tested with the validation data. Results reveal that the proposed ANFIS model of the clinker grinding process shows much superior performance compared with the other types of model. The ANFIS model was implemented in the SIMULINK environment for real-time monitoring of cement fineness from the knowledge of input variables and the model computation time was determined. It is observed that the model holds good promise to be implemented online for real-time estimation of cement fineness which will certainly help the plant operators in maintaining proper cement quality and in reducing losses.",industry
10.1016/j.proeng.2014.03.111,Conference Proceeding,Procedia Engineering,scopus,2014-01-01,sciencedirect,Application of neural networks in computer security,https://api.elsevier.com/content/abstract/scopus_id/84899124174,"This contribution is focused on the insurance of control system data communication via neural network technologies in connection with classical methods used in expert systems. The solution proposed defines a way of data element identification in transfer networks, solves the transformation of their parameters for neural network input and defines the type and architecture of a suitable neural network. This is supported by experiments with various architecture types and neural network activation functions and followed by subsequent real environment tests. A functional system proposal with possible practical application is the result.",industry
10.1016/j.ifset.2013.10.005,Journal,Innovative Food Science and Emerging Technologies,scopus,2014-01-01,sciencedirect,Metal release from stainless steel electrodes of a PEF treatment chamber: Effects of electrical parameters and food composition,https://api.elsevier.com/content/abstract/scopus_id/84897094087,"The effects of electrical parameters (field strength E, total specific energy input WT and pulse frequency) and product composition on the release of the main metallic elements (Fe, Cr, Ni and Mn) of stainless steel (type 316L) electrodes of a continuous flow parallel plate PEF chamber into the treatment medium were investigated. Experiments were carried out by subjecting two different buffer solutions (McIlvaine and Trizma-HCl) with the same values of pH (7) and electrical conductivity (σ=2mS/cm) to PEF treatments (mono-polar exponential decay pulses, lasting 3.1μs) at different intensities (E=12–21–31kV/cm, WT
                     =20–60–100J/mL) and flow rates (2–3–4L/h). The results showed that, for each field strength applied, the concentration of metallic elements increased upon increasing the total specific energy input. At constant total energy input, it was noticed that the metal concentration decreased upon increasing the field strength applied. These results were mainly attributed to the key role played by the pulse frequency in the charging process of the double layer capacitors at the electrode–solution interface. Moreover, it was shown that the amount of metal released from the electrodes markedly depended on the presence of halides in the composition of the processed product.
               
                  
                     Industrial relevance
                  
                  Electrochemical reactions at the electrode solution interfaces are unavoidable when typical conditions for PEF processing are applied. For the acceptability of PEF processing as a non-thermal method for liquid food pasteurization, the occurrence of these reactions should be avoided or minimized since they may determine undesired phenomenon of contamination of the food product, electrode-fouling and electrode corrosion. In this paper, electrode corrosion was studied, for the first time, in a continuous flow parallel plate PEF treatment chamber. The present investigation contributes to clarifying the effects of some electrical parameters and food composition on electrode corrosion or release of electrode materials under real PEF treatment conditions.",industry
10.1016/j.ijar.2013.03.006,Journal,International Journal of Approximate Reasoning,scopus,2014-01-01,sciencedirect,Relational approach to knowledge engineering for POMDP-based assistance systems as a translation of a psychological model,https://api.elsevier.com/content/abstract/scopus_id/84889574803,"Assistive systems for persons with cognitive disabilities (e.g., dementia) are difficult to build due to the wide range of different approaches people can take to accomplishing the same task, and the significant uncertainties that arise from both the unpredictability of client’s behaviours and from noise in sensor readings. Partially observable Markov decision process (POMDP) models have been used successfully as the reasoning engine behind such assistive systems for small multi-step tasks such as hand washing. POMDP models are a powerful, yet flexible framework for modelling assistance that can deal with uncertainty and utility. Unfortunately, POMDPs usually require a very labour intensive, manual procedure for their definition and construction. Our previous work has described a knowledge driven method for automatically generating POMDP activity recognition and context sensitive prompting systems for complex tasks. We call the resulting POMDP a SNAP (SyNdetic Assistance Process). The spreadsheet-like result of the analysis does not correspond to the POMDP model directly and the translation to a formal POMDP representation is required. To date, this translation had to be performed manually by a trained POMDP expert. In this paper, we formalise and automate this translation process using a probabilistic relational model (PRM) encoded in a relational database. The database encodes the relational skeleton of the PRM, and includes the goals, action preconditions, environment states, cognitive model, client and system actions (i.e., the outcome of the SNAP analysis), as well as relevant sensor models. The database is easy to approach for someone who is not an expert in POMDPs, allowing them to fill in the necessary details of a task using a simple and intuitive procedure. The database, when filled, implicitly defines a ground instance of the relational skeleton, which we extract using an automated procedure, thus generating a POMDP model of the assistance task. A strength of the database is that it allows constraints to be specified, such that we can verify the POMDP model is, indeed, valid for the task given the analysis. We demonstrate the method by eliciting three assistance tasks from non-experts: handwashing, and toothbrushing for elderly persons with dementia, and on a factory assembly task for persons with a cognitive disability. We validate the resulting POMDP models using case-based simulations to show that they are reasonable for the domains. We also show a complete case study of a designer specifying one database, including an evaluation in a real-life experiment with a human actor.",industry
10.1016/j.eswa.2013.08.003,Journal,Expert Systems with Applications,scopus,2014-01-01,sciencedirect,Intelligent business processes composition based on multi-agent systems,https://api.elsevier.com/content/abstract/scopus_id/84888360250,"This paper proposes a novel model for automatic construction of business processes called IPCASCI (Intelligent business Processes Composition based on multi-Agent systems, Semantics and Cloud Integration). The software development industry requires agile construction of new products able to adapt to the emerging needs of a changing market. In this context, we present a method of software component reuse as a model (or methodology), which facilitates the semi-automatic reuse of web services on a cloud computing environment, leading to business process composition. The proposal is based on web service technology, including: (i) Automatic discovery of web services; (ii) Semantics description of web services; (iii) Automatic composition of existing web services to generate new ones; (iv) Automatic invocation of web services. As a result of this proposal, we have presented its implementation (as a tool) on a real case study. The evaluation of the case study and its results are proof of the reliability of IPCASCI.",industry
10.1016/j.asoc.2013.05.017,Journal,Applied Soft Computing Journal,scopus,2014-01-01,sciencedirect,A hybrid noise suppression filter for accuracy enhancement of commercial speech recognizers in varying noisy conditions,https://api.elsevier.com/content/abstract/scopus_id/84888294149,"Commercial speech recognizers have made possible many speech control applications such as wheelchair, tone-phone, multifunctional robotic arms and remote controls, for the disabled and paraplegic. However, they have a limitation in common in that recognition errors are likely to be produced when background noise surrounds the spoken command, thereby creating potential dangers for the disabled if recognition errors exist in the control systems. In this paper, a hybrid noise suppression filter is proposed to interface with the commercial speech recognizers in order to enhance the recognition accuracy under variant noisy conditions. It intends to decrease the recognition errors when the commercial speech recognizers are working under a noisy environment. It is based on a sigmoid function which can effectively enhance noisy speech using simple computational operations, while a robust estimator based on an adaptive-network-based fuzzy inference system is used to determine the appropriate operational parameters for the sigmoid function in order to produce effective speech enhancement under variant noisy conditions. The proposed hybrid noise suppression filter has the following advantages for commercial speech recognizers: (i) it is not possible to tune the inbuilt parameters on the commercial speech recognizers in order to obtain better accuracy; (ii) existing noise suppression filters are too complicated to be implemented for real-time speech recognition; and (iii) existing sigmoid function based filters can operate only in a single-noisy condition, but not under varying noisy conditions. The performance of the hybrid noise suppression filter was evaluated by interfacing it with a commercial speech recognizer, commonly used in electronic products. Experimental results show that improvement in terms of recognition accuracy and computational time can be achieved by the hybrid noise suppression filter when the commercial recognizer is working under various noisy environments in factories.",industry
10.1016/j.artint.2013.10.003,Journal,Artificial Intelligence,scopus,2014-01-01,sciencedirect,Algorithm runtime prediction: Methods &amp; evaluation,https://api.elsevier.com/content/abstract/scopus_id/84887848457,"Perhaps surprisingly, it is possible to predict how long an algorithm will take to run on a previously unseen input, using machine learning techniques to build a model of the algorithmʼs runtime as a function of problem-specific instance features. Such models have important applications to algorithm analysis, portfolio-based algorithm selection, and the automatic configuration of parameterized algorithms. Over the past decade, a wide variety of techniques have been studied for building such models. Here, we describe extensions and improvements of existing models, new families of models, and—perhaps most importantly—a much more thorough treatment of algorithm parameters as model inputs. We also comprehensively describe new and existing features for predicting algorithm runtime for propositional satisfiability (SAT), travelling salesperson (TSP) and mixed integer programming (MIP) problems. We evaluate these innovations through the largest empirical analysis of its kind, comparing to a wide range of runtime modelling techniques from the literature. Our experiments consider 11 algorithms and 35 instance distributions; they also span a very wide range of SAT, MIP, and TSP instances, with the least structured having been generated uniformly at random and the most structured having emerged from real industrial applications. Overall, we demonstrate that our new models yield substantially better runtime predictions than previous approaches in terms of their generalization to new problem instances, to new algorithms from a parameterized space, and to both simultaneously.",industry
10.1016/j.advengsoft.2013.09.003,Journal,Advances in Engineering Software,scopus,2014-01-01,sciencedirect,Software architecture knowledge for intelligent light maintenance,https://api.elsevier.com/content/abstract/scopus_id/84885359031,"The maintenance management plays an important role in the monitoring of business activities. It ensures a certain level of services in industrial systems by improving the ability to function in accordance with prescribed procedures. This has a decisive impact on the performance of these systems in terms of operational efficiency, reliability and associated intervention costs. To support the maintenance processes of a wide range of industrial services, a knowledge-based component is useful to perform the intelligent monitoring. In this context we propose a generic model for supporting and generating industrial lights maintenance processes. The modeled intelligent approach involves information structuring and knowledge sharing in the industrial setting and the implementation of specialized maintenance management software in the target information system. As a first step we defined computerized procedures from the conceptual structure of industrial data to ensure their interoperability and effective use of information and communication technologies in the software dedicated to the management of maintenance (E-candela). The second step is the implementation of this software architecture with specification of business rules, especially by organizing taxonomical information of the lighting systems, and applying intelligence-based operations and analysis to capitalize knowledge from maintenance experiences. Finally, the third step is the deployment of the software with contextual adaptation of the user interface to allow the management of operations, editions of the balance sheets and real-time location obtained through geolocation data. In practice, these computational intelligence-based modes of reasoning involve an engineering framework that facilitates the continuous improvement of a comprehensive maintenance regime.",industry
10.1016/j.ultras.2013.07.018,Journal,Ultrasonics,scopus,2014-01-01,sciencedirect,Ultrasonic sensor based defect detection and characterisation of ceramics,https://api.elsevier.com/content/abstract/scopus_id/84884211045,"Ceramic tiles, used in body armour systems, are currently inspected visually offline using an X-ray technique that is both time consuming and very expensive. The aim of this research is to develop a methodology to detect, locate and classify various manufacturing defects in Reaction Sintered Silicon Carbide (RSSC) ceramic tiles, using an ultrasonic sensing technique. Defects such as free silicon, un-sintered silicon carbide material and conventional porosity are often difficult to detect using conventional X-radiography. An alternative inspection system was developed to detect defects in ceramic components using an Artificial Neural Network (ANN) based signal processing technique. The inspection methodology proposed focuses on pre-processing of signals, de-noising, wavelet decomposition, feature extraction and post-processing of the signals for classification purposes. This research contributes to developing an on-line inspection system that would be far more cost effective than present methods and, moreover, assist manufacturers in checking the location of high density areas, defects and enable real time quality control, including the implementation of accept/reject criteria.",industry
10.1016/j.ijpe.2013.01.028,Journal,International Journal of Production Economics,scopus,2013-12-01,sciencedirect,Hybrid flow shop scheduling considering machine electricity consumption cost,https://api.elsevier.com/content/abstract/scopus_id/84886724001,"Hybrid flow shop (HFS) scheduling has been extensively examined and the main objective has been to improve production efficiency. However, limited attention has been paid to the consideration of energy consumption with the advent of green manufacturing. This paper proposes a new ant colony optimization (MOACO) meta-heuristic considering not only production efficiency but also electric power cost (EPC) with the presence of time-of-use (TOU) electricity prices. The solution is encoded as a permutation of jobs. A list schedule algorithm is applied to construct the sequence by artificial ants and generate a complete schedule. A right-shift procedure is then used to adjust the start time of operations aiming to minimize the EPC for the schedule. In terms of theoretical research aspect, the results from computational experiments indicate that the efficiency and effectiveness of the proposed MOACO are comparable to NSGA-II and SPEA2. In terms of practical application aspect, the guideline about how to set preference over multiple objectives has been studied. This result has significant managerial implications in real life production. The parameter analysis also shows that durations of TOU periods and processing speed of machines have great influence on scheduling results as longer off-peak period and use of faster machines provide more flexibility for shifting high-energy operations to off-peak periods.",industry
10.1016/j.sna.2013.09.021,Journal,"Sensors and Actuators, A: Physical",scopus,2013-11-14,sciencedirect,Feasibility study of Hierarchical Temporal Memories applied to welding diagnostics,https://api.elsevier.com/content/abstract/scopus_id/84887294247,"Defect classification in on-line welding quality monitoring systems is an active area of research with a significant relevance to several industrial sectors where welding processes are extensively employed. Approaches based on some artificial intelligence implementations, like Artificial Neural Networks or Fuzzy Logic have been attempted, but their impact in real industrial scenarios is nowadays rather modest. In this paper a new approach based on Hierarchical Temporal Memories and the acquired plasma spectra is explored and analyzed by means of several arc-welding experimental tests. Results show the ability of the proposed solution to perform a suitable classification among several weld perturbations. The search for an optimal configuration of the algorithm and the usefulness of both spatial (spectral) and temporal identification of patterns will be also discussed, and the results will be compared with those provided by a solution based on feature selection and neural networks, exhibiting the better performance of the HTM model in terms of performance and handling of the input data.",industry
10.1016/j.jprocont.2013.09.014,Journal,Journal of Process Control,scopus,2013-10-28,sciencedirect,A multilayer-perceptron based method for variable selection in soft sensor design,https://api.elsevier.com/content/abstract/scopus_id/84886080853,"The paper proposes a new method for variable selection for prediction settings and soft sensors applications. The new variable selection method is based on the multi-layer perceptron (MLP) neural network model, where the network is trained a single time, maintaining low computational cost. The proposed method was successfully applied, and compared with four state-of-the-art methods in one artificial dataset and three real-world datasets, two publicly available datasets (Box–Jenkins gas furnace and gas mileage), and a dataset of a problem where the objective is to estimate the fluoride concentration in the effluent of a real urban water treatment plant (WTP). The proposed method presents similar or better approximation performance when compared to the other four methods. In the experiments, among all the five methods, the proposed method selects the lowest number of variables and variables-delays pairs to achieve the best solution. In soft sensors applications having a lower number of variables is a positive factor for decreasing implementation costs, or even making the soft sensor feasible at all.",industry
10.1016/j.neucom.2013.02.018,Journal,Neurocomputing,scopus,2013-10-22,sciencedirect,A review of parameter estimators and controllers for induction motors based on artificial neural networks,https://api.elsevier.com/content/abstract/scopus_id/84881233620,"Induction motors (IMs) are the most used electromechanic machines in industrial applications. Their control has become the subject of many studies since the 70s, and there have been several approaches to achieve high-performance adjustable speed drivers (ASDs). The review presented in this article can support the state of some related researches, since it deals with current state-of-the-art of Artificial Neural Networks (ANNs) oriented to experiments that perform motion control with induction motors. It summarizes many previous works focused on IM and can help the reader to have a starting point to begin their own research on choosing a correct type of Neural Network (NN). The paper provides a list of ANNs used to improve the ASD-control, extending the IM-driver life and achieving proper motor operation, their size and performance. A good match between IM parameter values and the data that the controller needs for the induction machine is imperative. Artificial Intelligence (AI) is a helpful tool to achieve this. The summary will also present an overview of different ANN-based drive approaches.",industry
10.1016/j.neucom.2013.02.039,Journal,Neurocomputing,scopus,2013-10-22,sciencedirect,Point and prediction interval estimation for electricity markets with machine learning techniques and wavelet transforms,https://api.elsevier.com/content/abstract/scopus_id/84881221196,"A growing number of countries all over the world are switching over to deregulated or the market structure of electricity sector with a view to enhance productivity, efficiency and to lower the prices. Barring a few cases, the deregulated structure is doing quite well in most of the countries. However a persistent issue that plagues the involved parties such as producers, traders, retailers etc., is the uncertainty that prevails in the system. Due to a number of known, unknown factors, the electricity prices exhibit fluctuating characteristics which is difficult to control as well as predict. Several forecasting techniques have been developed and successfully implemented for existing markets around the world with comparable performance. However, the uncertainty aspect of the point forecasts has not been analyzed significantly. In this work, an attempt is made to quantify such uncertainties existing in the market using statistical techniques like prediction intervals. Hybrid models using neural networks and Extreme Learning machines with wavelets as preprocessors are developed and applied for point as well as prediction interval forecasting for Ontario Electricity Market, PJM Day-Ahead and Real time markets.",industry
10.1016/j.engappai.2013.04.006,Journal,Engineering Applications of Artificial Intelligence,scopus,2013-09-01,sciencedirect,Post-design analysis for building and refining AI planning systems,https://api.elsevier.com/content/abstract/scopus_id/84880771590,"The growth of industrial applications of artificial intelligence has raised the need for design tools to aid in the conception and implementation of such complex systems. The design of automated planning systems faces several engineering challenges including the proper modeling of the domain knowledge: the creation of a model that represents the problem to be solved, the world that surrounds the system, and the ways the system can interact with and change the world in order to solve the problem. Knowledge modeling in AI planning is a hard task that involves acquiring the system requirements and making design decisions that can determine the behavior and performance of the resulting system. In this paper we investigate how knowledge acquired during a post-design phase of modeling can be used to improve the prospective model. A post-design framework is introduced which combines a knowledge engineering tool and a virtual prototyping environment for the analysis and simulation of plans. This framework demonstrates that post-design analysis supports the discovery of missing requirements and can guide the model refinement cycle. We present three case studies using benchmark domains and eight state-of-the-art planners. Our results demonstrate that significant improvements in plan quality and an increase in planning speed of up to three orders of magnitude can be achieved through a careful post-design process. We argue that such a process is critical for the deployment of AI planning technology in real-world engineering applications.",industry
10.1016/j.engappai.2013.03.011,Journal,Engineering Applications of Artificial Intelligence,scopus,2013-08-01,sciencedirect,Solving the forward kinematics problem in parallel robots using Support Vector Regression,https://api.elsevier.com/content/abstract/scopus_id/84878108083,"The Stewart platform, a representative of the class of parallel manipulators, has been successfully used in a wide variety of fields and industries, from medicine to automotive. Parallel robots have key benefits over serial structures regarding stability and positioning capability. At the same time, they present challenges and open problems which need to be addressed in order to take full advantage of their utility. In this paper, we propose a new approach for solving one of these key aspects: the solution to the forward kinematics in real-time, an under-defined problem with a high-degree nonlinear formulation, using a popular machine learning method for classification and regression, the Support Vector Machines. Instead of solving a numerical problem, the proposed method involves applying Support Vector Regression to model the behavior of a platform in a given region or partition of the pose space. It consists of two phases, an off-line preprocessing step and a fast on-line evaluation phase. The experiments made have yielded a good approximation to the analytical solution, and have shown its suitability for real-time application.",industry
10.1016/j.jsr.2013.04.005,Journal,Journal of Safety Research,scopus,2013-06-24,sciencedirect,Transferability and robustness of real-time freeway crash risk assessment,https://api.elsevier.com/content/abstract/scopus_id/84879088842,"Introduction
                  This study examines the data from single loop detectors on northbound (NB) US-101 in San Jose, California to estimate real-time crash risk assessment models.
               
                  Method
                  The classification tree and neural network based crash risk assessment models developed with data from NB US-101 are applied to data from the same freeway, as well as to the data from nearby segments of the SB US-101, NB I-880, and SB I-880 corridors. The performance of crash risk assessment models on these nearby segments is the focus of this research.
               
                  Results
                  The model applications show that it is in fact possible to use the same model for multiple freeways, as the underlying relationships between traffic data and crash risk remain similar.
               
                  Impact on Industry
                  The framework provided here may be helpful to authorities for freeway segments with newly installed traffic surveillance apparatuses, since the real-time crash risk assessment models from nearby freeways with existing infrastructure would be able to provide a reasonable estimate of crash risk. The robustness of the model output is also assessed by location, time of day, and day of week. The analysis shows that on some locations the models may require further learning due to higher than expected false positive (e.g., the I-680/I-280 interchange on US-101 NB) or false negative rates. The approach for post-processing the results from the model provides ideas to refine the model prior to or during the implementation.",industry
10.1016/j.neucom.2012.04.033,Journal,Neurocomputing,scopus,2013-06-03,sciencedirect,Applying soft computing techniques to optimise a dental milling process,https://api.elsevier.com/content/abstract/scopus_id/84875966713,"This study presents a novel soft computing procedure based on the application of artificial neural networks, genetic algorithms and identification systems, which makes it possible to optimise the implementation conditions in the manufacturing process of high precision parts, including finishing precision, while saving both time and financial costs and/or energy. This novel intelligent procedure is based on the following phases. Firstly, a neural model extracts the internal structure and the relevant features of the data set representing the system. Secondly, the dynamic system performance of different variables is specifically modelled using a supervised neural model and identification techniques. This constitutes the model for the fitness function of the production process, using relevant features of the data set. Finally, a genetic algorithm is used to optimise the machine parameters from a non parametric fitness function. The proposed novel approach was tested under real dental milling processes using a high-precision machining centre with five axes, requiring high finishing precision of measures in micrometres with a large number of process factors to analyse. The results of the experiment, which validate the performance of the proposed approach, are presented in this study.",industry
10.1016/j.engappai.2012.11.009,Journal,Engineering Applications of Artificial Intelligence,scopus,2013-05-01,sciencedirect,An intelligent system for wafer bin map defect diagnosis: An empirical study for semiconductor manufacturing,https://api.elsevier.com/content/abstract/scopus_id/84876945059,"Wafer bin maps (WBMs) that show specific spatial patterns can provide clue to identify process failures in the semiconductor manufacturing. In practice, most companies rely on experienced engineers to visually find the specific WBM patterns. However, as wafer size is enlarged and integrated circuit (IC) feature size is continuously shrinking, WBM patterns become complicated due to the differences of die size, wafer rotation, the density of failed dies and thus human judgments become inconsistent and unreliable. To fill the gaps, this study aims to develop a knowledge-based intelligent system for WBMs defect diagnosis for yield enhancement in wafer fabrication. The proposed system consisted of three parts: graphical user interface, the WBM clustering solution, and the knowledge database. In particular, the developed WBM clustering approach integrates spatial statistics test, cellular neural network (CNN), adaptive resonance theory (ART) neural network, and moment invariant (MI) to cluster different patterns effectively. In addition, an interactive converse interface is developed to present the possible root causes in the order of similarity matching and record the diagnosis know-how from the domain experts into the knowledge database. To validate the proposed WBM clustering solution, twelve different WBM patterns collected in real settings are used to demonstrate the performance of the proposed method in terms of purity, diversity, specificity, and efficiency. The results have shown the validity and practical viability of the proposed system. Indeed, the developed solution has been implemented in a leading semiconductor manufacturing company in Taiwan. The proposed WBM intelligent system can recognize specific failure patterns efficiently and also record the assignable root causes verified by the domain experts to enhance troubleshooting effectively.",industry
10.1016/j.robot.2012.12.005,Journal,Robotics and Autonomous Systems,scopus,2013-05-01,sciencedirect,A survey of bio-inspired robotics hands implementation: New directions in dexterous manipulation,https://api.elsevier.com/content/abstract/scopus_id/84875695547,"Recently, significant advances have been made in ROBOTICS, ARTIFICIAL INTELLIGENCE and other COGNITIVE related fields, allowing to make much sophisticated biomimetic robotics systems. In addition, enormous number of robots have been designed and assembled, explicitly realize biological oriented behaviors. Towards much skill behaviors and adequate grasping abilities (i.e. ARTICULATION and DEXTEROUS MANIPULATION), a new phase of dexterous hands have been developed recently with biomimetically oriented and bio-inspired functionalities. In this respect, this manuscript brings a detailed survey of biomimetic based dexterous robotics multi-fingered hands. The aim of this survey, is to find out the state of the art on dexterous robotics end-effectors, known in literature as (ROBOTIC HANDS) or (DEXTEROUS MULTI-FINGERED) robot hands. Hence, this review finds such biomimetic approaches using a framework that permits for a common description of biological and technical based hand manipulation behavior. In particular, the manuscript focuses on a number of developments that have been taking place over the past two decades, and some recent developments related to this biomimetic field of research. In conclusions, the study found that, there are rich research efforts in terms of KINEMATICS, DYNAMICS, MODELING and CONTROL methodologies. The survey is also indicating that, the topic of biomimetic inspired robotics systems make significant contributions to robotics hand design, in four main directions for future research. First, they provide a genuine world test of models of biologically inspired hand designs and dexterous manipulation behaviors. Second, they provide novel manipulation articulations and mechanisms available for industrial and domestic uses, most notably in the field of human like hand design and real world applications. Third, this survey has also indicated that, there are quite large number of attempts to acquire biologically inspired hands. These attempts were almost successful, where they exposed more novel ideas for further developments. Such inspirations were directed towards a number of topics related (HAND MECHANICS AND DESIGN), (HAND TACTILE SENSING), (HAND FORCE SENSING), (HAND SOFT ACTUATION) and (HAND CONFIGURATION AND TOPOLOGY). FOURTH, in terms of employing AI related sciences and cognitive thinking, it was also found that, rare and exceptional research attempts were directed towards the employment of biologically inspired thinking, i.e. (AI, BRAIN AND COGNITIVE SCIENCES) for hand upper control and towards much sophisticated dexterous movements. Throughout the study, it has been found there are number of efforts in terms of mechanics and hand designs, tactical sensing, however, for hand soft actuation, it seems this area of research is still far away from having a realistic muscular type fingers and hand movements.",industry
10.1016/j.dss.2013.01.026,Journal,Decision Support Systems,scopus,2013-04-01,sciencedirect,A multivariate intelligent decision-making model for retail sales forecasting,https://api.elsevier.com/content/abstract/scopus_id/84877779441,"A sales forecasting problem in the retail industry is addressed based on early sales. An effective multivariate intelligent decision-making (MID) model is developed to provide effective forecasts for this problem by integrating a data preparation and preprocessing module, a harmony search-wrapper-based variable selection (HWVS) module and a multivariate intelligent forecaster (MIF) module. The HWVS module selects out the optimal input variable subset from given candidate inputs as the inputs of MIF. The MIF is established to model the relationship between the selected input variables and the sales volumes of retail products, and then utilized to forecast the sales volumes of retail products. Extensive experiments were conducted to validate the proposed MID model in terms of extensive typical sales datasets from real-world retail industry. Experimental results show that it is statistically significant that the proposed MID model can generate much better forecasts than extreme learning machine-based model and generalized linear model do.",industry
10.1016/j.compind.2012.11.005,Journal,Computers in Industry,scopus,2013-04-01,sciencedirect,IMAQCS: Design and implementation of an intelligent multi-agent system for monitoring and controlling quality of cement production processes,https://api.elsevier.com/content/abstract/scopus_id/84875245342,"In cement plant, since all processes are chemical and irreversible, monitoring and control is a critical factor. If the process is not controlled at any stage, the final product can be damaged or lost. Thus, in such environments, considering the quality of the product at each state is essential. Also, to control the process, communication among different parts of production line is essential. The wasted time in production line has a direct effect on process correction time and cement production performance. Here, a model of a new intelligent multi-agent quality control system (IMAQCS) for controlling the quality of cement production processes is suggested. This model, using of rule-based artificial intelligence technique, concentrates on relationship between departments in cement production line to monitor multi-attribute quality factors. With the presence of agents for controlling the quality of cement processes, real-time analyzing and decision making in a fault condition will be provided. In order to validate the proposed model, IMAQCS is deployed in real plants of a cement industries complex in Iran. The ability of the system in the process production environment is assessed. The effectiveness and efficiency of the system are demonstrated by reducing the process correction time and increasing the cement production performance. Finally, this system can effectively impact on factory resources and cost saving.",industry
10.1016/j.eswa.2012.09.010,Journal,Expert Systems with Applications,scopus,2013-04-01,sciencedirect,Neural network Reinforcement Learning for visual control of robot manipulators,https://api.elsevier.com/content/abstract/scopus_id/84872011415,"It is known that most of the key problems in visual servo control of robots are related to the performance analysis of the system considering measurement and modeling errors. In this paper, the development and performance evaluation of a novel intelligent visual servo controller for a robot manipulator using neural network Reinforcement Learning is presented. By implementing machine learning techniques into the vision based control scheme, the robot is enabled to improve its performance online and to adapt to the changing conditions in the environment. Two different temporal difference algorithms (Q-learning and SARSA) coupled with neural networks are developed and tested through different visual control scenarios. A database of representative learning samples is employed so as to speed up the convergence of the neural network and real-time learning of robot behavior. Moreover, the visual servoing task is divided into two steps in order to ensure the visibility of the features: in the first step centering behavior of the robot is conducted using neural network Reinforcement Learning controller, while the second step involves switching control between the traditional Image Based Visual Servoing and the neural network Reinforcement Learning for enabling approaching behavior of the manipulator. The correction in robot motion is achieved with the definition of the areas of interest for the image features independently in both control steps. Various simulations are developed in order to present the robustness of the developed system regarding calibration error, modeling error, and image noise. In addition, a comparison with the traditional Image Based Visual Servoing is presented. Real world experiments on a robot manipulator with the low cost vision system demonstrate the effectiveness of the proposed approach.",industry
10.1016/j.engappai.2012.12.007,Journal,Engineering Applications of Artificial Intelligence,scopus,2013-03-01,sciencedirect,Design of a robust layout with information uncertainty increasing over time: A fuzzy evolutionaryapproach,https://api.elsevier.com/content/abstract/scopus_id/84873992819,"One of the problems encountered in the design of manufacturing systems is how to arrange the machines on the surface of the workshop, which is commonly referred to as a layout problem. Such a problem has been widely investigated in the literature. Most approaches use optimization technique to determine the position of each facility, assuming that the required data is available. Unfortunately, this assumption is often unrealistic, since the study design of a workshop is obviously conducted much before it is operating, so that data related to customer demands, for example, is generally not known with enough precision. Indeed, if good forecasts about what is to be produced in the next weeks can be available, they will obviously become more and more unreliable as the considered period of time will increase, so that layout found using classical approaches can turn out not to be relevant on the medium or long term. We propose an approach to design a robust layout in a context where the certainty of the information available decreases over time, which is usually the case for real applications. We propose a resolution approach based on a fuzzy evolutionary algorithm, which includes uncertain customer demands for each product. We show how this problem can be stated as a fuzzy dynamic layout problem with growing uncertainty over time. We suggest an evolutionary algorithm with adapted operators. Their performances are first tested using 2crisp layout problems already published. Then the impact of increasing uncertainty is studied using a suggested benchmark. The results of our experiments show the importance of considering the degradation of the information for designing robust layouts.",industry
10.1016/j.chb.2012.04.020,Journal,Computers in Human Behavior,scopus,2013-03-01,sciencedirect,Investigation of effects of virtual reality environments on learning performance of technical skills,https://api.elsevier.com/content/abstract/scopus_id/84861441335,"Practical training is what brings imagination and creativity to fruition, which relies significantly on the relevant technical skills needed. Thus, the current study has placed its emphasis on strengthening the learning of technical skills with emerging innovations in technology, while studying the effects of employing such technologies at the same time. As for the students who participated in the study, technical skills had been cultivated in the five dimensions of knowledge, comprehension, simulation, application, and creativity, in accordance to the set teaching objectives and the taxonomy for students learning outcome, while the virtual reality learning environment (VRLE) has also been developed to meet different goals as the various technical skills were being examined. In terms of the nature of technology, operation of machines, selection of process parameters, and process planning in technical skills, VRLE has also designed the six modules of “learning resource”, “digital content”, “collaborative learning”, “formative evaluation”, “simulation of manufacturing process”, and “practical exercise” in particular for providing students with assistance in the development on their technical skills on a specific, gradual basis. After assessing the technical skills that have been developed for the time period of one semester, the students have reported finding VRLE to be a significantly effective method when considering the three dimensions of “operation of machines”, “selection of process parameter”, and “process planning”, though not so much so when it came to the dimension of “nature of technology”. Among the six modules, “simulation of manufacturing process” and “practical exercise” were the two that were most preferred by students for the three dimensions considered.",industry
10.1016/j.vetmic.2012.08.026,Journal,Veterinary Microbiology,scopus,2013-02-22,sciencedirect,Quantitative real-time PCR and culture examination of Mycobacterium avium subsp. paratuberculosis at farm level,https://api.elsevier.com/content/abstract/scopus_id/84872178191,"Mycobacterium avium subsp. paratuberculosis (MAP) causes Johne's disease in ruminants and may contribute to Crohn's disease in humans. The aim of this study was to determine the occurrence and quantity of MAP in cattle feces and milk in the Iranian context. In addition, we evaluated the effect of cattle age as well as farming system as risk factors contributing to MAP load. For this, a total sample of 373 consisting of 150 cattle feces (CF), 150 individual cow's milk (ICM), as well as 73 bulk-tank milk (BTM) was collected randomly and regardless of the cattle health status. The samples were assayed using F57 quantitative real-time PCR (qPCR) and culture method. According to the results of qPCR which was found ∼10 times more sensitive than culture assay, MAP was detected in 68.66% (103/150) of the CF, 12% (18/150) of the ICM and 52.05% (38/73) of the BTM samples. In contrast to the previous reports, the quantity of MAP in the BTM (2.03–5.97 log cfu/50ml) was statistically (p
                     <0.01) higher than the ICM (0.90–1.97 log cfu/50ml). Data suggested a direct relation (p
                     <0.01) between the cattle age and the quantity of MAP in the CF samples, while the relation was not statistically significant (p
                     >0.05) for the ICM. In addition, MAP load in the BTM samples obtained from traditional farms was significantly (p
                     <0.01) higher than that of the industrial ones, while the differences in CF and ICM was not significant (p
                     >0.05).",industry
10.1016/j.epsr.2013.01.011,Journal,Electric Power Systems Research,scopus,2013-02-21,sciencedirect,FPGA-based neural network harmonic estimation for continuous monitoring of the power line in industrial applications,https://api.elsevier.com/content/abstract/scopus_id/84873945333,"Manufacturing cells are present in almost all the industrial sector. Unfortunately, all machine tools into the manufacturing cell are connected to the same power line, implying that their operation adds nonlinear loads such as harmonics and interharmonics that affect the general machine-tool condition. A novel NN-based methodology for harmonic monitoring through time in transient and stationary signals that satisfies the IEC61000-4-7 standard is presented, as well as its implementation into a field programmable gate array (FPGA) for continuous and online monitoring. The proposed method and the developed instrument have been tested in a real manufacturing cell.",industry
10.1016/j.heares.2012.11.006,Journal,Hearing Research,scopus,2013-02-01,sciencedirect,"Effects of passive, moderate-level sound exposure on the mature auditory cortex: Spectral edges, spectrotemporal density, and real-world noise",https://api.elsevier.com/content/abstract/scopus_id/84872762363,"Persistent, passive exposure of adult cats to bandlimited tone pip ensembles or sharply-filtered white noise at moderate levels (∼70 dB SPL) leads to a long-term suppression of spontaneous and sound-evoked activity in the region(s) of primary auditory cortex (AI) normally tuned to the exposure spectrum, and to an enhancement of activity in one or more neighboring regions of AI, all in the apparent absence of hearing loss. Here, we first examined the effects of passive exposure to a more structured, real-world noise, consisting of a mix of power tool and construction sounds. This “factory noise” had less pronounced effects on adult cat AI than our previous random tone pip ensembles and white noise, and these effects appeared limited to the region of AI tuned to frequencies near the sharp factory noise cutoff at 16 kHz. To further investigate the role of sharp spectral edges in passive exposure-induced cortical plasticity, a second group of adult cats was exposed to a tone pip ensemble with a flat spectrum between 2 and 4 kHz and shallow cutoff slopes (12 dB/oct) on either side. Compared to our previous ensemble with the same power in the 2–4 kHz band but very steep slopes, exposure to the overall more intense, sloped stimulus had much weaker effects on AI. Finally, we explored the issue of exposure stimulus spectrotemporal density and found that low aggregate tone pip presentation rates of about one per second sufficed to induce changes in the adult AI similar to those characteristic of our previous, much denser exposures. These results are discussed in light of the putative mechanisms underlying exposure-induced auditory cortical plasticity, and the potential adverse consequences of working or living in moderately noisy environments.",industry
10.1016/j.rcim.2012.07.006,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2013-02-01,sciencedirect,An artificial neural network approach to the problem of wireless sensors network localization,https://api.elsevier.com/content/abstract/scopus_id/84865660003,"One of the imperative problems in the realm of wireless sensor networks is the problem of wireless sensors localization. Despite the fact that much research has been conducted in this area, many of the proposed approaches produce unsatisfactory results when exposed to the harsh, uncertain, noisy conditions of a manufacturing environment. In this study, we develop an artificial neural network approach to moderate the effect of the miscellaneous noise sources and harsh factory conditions on the localization of the wireless sensors. Special attention is given to investigate the effect of blockage and ambient conditions on the accuracy of mobile node localization. A simulator, simulating the noisy and dynamic shop conditions of manufacturing environments, is employed to examine the neural network proposed. The neural network performance is also validated through some actual experiments in real-world environment prone to different sources of noise and signal attenuation. The simulation and experimental results demonstrate the effectiveness and accuracy of the proposed methodology.",industry
10.1533/9780857093967.1.208,Book,Joining Textiles: Principles and Applications,scopus,2013-01-01,sciencedirect,Intelligent sewing systems for garment automation and robotics,https://api.elsevier.com/content/abstract/scopus_id/84903011824,"Sewing machine interactions at different speeds have been used to construct qualitative rules mapping fabric properties to optimum sewing machine settings for intelligent sewing machines. the inference procedures of fuzzy logic have been implemented in a neural network to allow for optimisation of output membership functions and, subsequently, self-learning. the technique is successfully applied to develop intelligent sewing machines and further implemented in textile and garment manufacturing. An intelligent manufacturing environment has been put forward in which fabric properties predict the sewability of any fabric, determine the minimum change of fabric properties required, and control in real time the stitching of a garment by using the feedback closed loop of the Neuro-Fuzzy model. the system has been successfully tried in an industrial setting. optimum settings were achieved under static and dynamic machine conditions, including for the properties of difficult fabrics and compensation for mishandling by the operator over the speed range of the sewing machine.",industry
10.1016/j.procs.2013.09.249,Conference Proceeding,Procedia Computer Science,scopus,2013-01-01,sciencedirect,Fast and reliable detection of hockey players,https://api.elsevier.com/content/abstract/scopus_id/84896994720,"Current popularity of augmented reality (AR) stems from its ability to enhance the perceived environment in real- time with additional information of semantic context, such as sports scores shown on TV during match broadcasting. Its other application areas range from industry and medicine to military, commerce and entertainment. Advanced AR technologies obviously rely on accurate, yet fast enough algorithms for multimedia processing and object recognition. In this paper, we will study the possibility of using convolutional neural networks (CNNs) for real-time detection of hockey players from video streams of broadcasted ice-hockey matches. Supporting experiments performed so far yield sufficient accuracy for this task (above 98.5%), while maintaining reasonable computational demands and acceptable robustness both with regard to noise and minor image transformations like translation, rotation and scaling.",industry
10.1016/j.procs.2013.09.226,Conference Proceeding,Procedia Computer Science,scopus,2013-01-01,sciencedirect,Using multi-agent systems to pursue autonomy with automated components,https://api.elsevier.com/content/abstract/scopus_id/84896911861,"Humans have used tools to transform raw resources into valued outputs ever since society harnessed fire. The type of tool, amount of effort and form of energy required depends on the output or object being created. As tools evolved into machines, they enhanced operator productivity. Hence, industry continues to invest heavily in machines to assist people to do more with less physical control and/or interaction. This involves automating functions previously completed manually. Taylorism and the Hawthorn experiments all contributed to optimising industrial outputs and value engineers continue to promote a mecha- nized workforce in order to minimise business variations in human performance and their behaviour. Researchers have also pursued this goal using Computational Intelligence (CI) techniques. This process of transforming cognitive functionality into machine actionable form has encompassed many careers. Machine Intelligence (MI) is becoming more aspirational, with Artificial Intelligence (AI) enabling the achievement of numerous goals. More recently, Multi-Agent Systems (MASs) have been employed to provide a flexible framework for research and development. These frameworks facilitate the development of component interoperability, with coordination and cooperation techniques needed to solve real-world problems. However problems typically manifest in complex, dynamic and often hostile environments. Based on the effort to seek or facilitate human-like decision making within machines, it is clear that further research is required. This paper discusses one possible avenue. It involves future research, aimed at achieving a cognitive sub-system for use on-board platforms. The framework is introduced by describing the human-machine relationship, followed by the theoretic background into cognitive architectures and a conceptual mechanism that could be used to implement a virtual mind. One which could be used to improve automation, achieve greater independence and enable more autonomous behaviour within control systems.",industry
10.1016/j.procir.2013.09.042,Conference Proceeding,Procedia CIRP,scopus,2013-01-01,sciencedirect,An enabling digital foundation towards smart machining,https://api.elsevier.com/content/abstract/scopus_id/84886789550,"Today's major challenges for manufacturing companies in the aerospace and automotive industries are clear: global cooperation with multiple supply chain partners, production optimization, management and tracking of information so as to meet new requirements in terms of traceability, security and sustainability. The need for a data exchange standard that allows disparate entities and their associated devices in a manufacturing system to share data seamlessly is clearly obvious. And the first expected impact is the ‘next generation’ smart controller that could really enable an intelligent machining process based on real-time monitoring and diagnosis, self-learning decision and adaptive optimization. The four-year project titled FoFdation envisions a ‘Digital and Smart Factory’ architecture and implementation. This has the potential to achieve significant benefits in earlier visibility of manufacturing issues, faster production ramp-up time, faster time to volume production and subsequently shorter time to market, reduced manufacturing costs and improved product quality, as well as sustainability objectives like low energy consumption and waste reduction. The present paper describes the on-going work with specific focus on the definition and implementation of the FoFdation Smart Machine Controller (SMC) in an adaptable architecture that satisfies both commercial and open source CNC controllers. It highlights the project's end use validation framework as well as sets a strong Manufacturing Information System foundation on which process optimization and control as well as sustainable practices can be based. It presents the general vision of the target solution for the SMC developed in the FoFdation project. It is based on efforts past and present both by academia and industry in various capacities and proposes tentative implementations based on the STEP-NC standard to define the machine controller of the future.",industry
10.3182/20130825-4-US-2038.00105,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2013-01-01,sciencedirect,An on-line training simulator built on dynamic simulations of crushing plants,https://api.elsevier.com/content/abstract/scopus_id/84885800887,"Crushing plants are widely used around the world as a pre-processing step in the mineral and mining industries or as standalone processing plants for final products in the aggregates industry. Despite automation and different types of advanced model predictive control, many the processes are still managed by operators. The skill of the operators influences the process performance and thus production yield. Therefore, it is important to train the operators so they know how to behave in different situations and to make them able to operate the process in the best possible way.
                  Different types of models for crushers and other production units have been developed during the years and the latest improvement is the addition of dynamic behavior which gives the crushing plants a time dependent behavior and performance. This can be used as a simulator for operators training. By connecting an Internet based Human Machine Interface (WebHMI) to a dynamic simulator with the models incorporated, an on-line training environment for operators can be achieved.
                  In this paper, a dynamic crushing plant simulator implemented in MATLAB/SIMULINK has been connected to a WebHMI. The WebHMI is accessible via the Internet, thus creating a realistic control room for operators’ training. In the created training environment, the operators can be trained under realistic conditions. Simple training scenarios and how they could be simulated are discussed. Apart from the increased level of knowledge and experience among the operators, the time aspect is an important factor. While a real crushing plant is still being built, the operators to be can already be trained, saving a lot of the commissioning and ramp up time.",industry
10.3182/20130828-3-UK-2039.00025,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2013-01-01,sciencedirect,A new extensive source for web-based control education - Contlab.eu,https://api.elsevier.com/content/abstract/scopus_id/84885206555,"Modern technologies allow to create a networked control system with off-the-shelf mobile devices. As such, there is the possibility of having the role of who offers and who uses a “remote” laboratory played by the same people. Extending recently published ideas, the paper presents a first nucleus of functionalities allowing one to create process simulators and controllers which run on a mobile application, and then share them with others. Some words are also spent on some of the possibilities opened by the proposal, sketching out some interesting didactic activities to propose to the students.",industry
10.1016/j.biortech.2013.07.023,Journal,Bioresource Technology,scopus,2013-01-01,sciencedirect,Enhancement of lipid productivity of Rhodosporidium toruloides in distillery wastewater by increasing cell density,https://api.elsevier.com/content/abstract/scopus_id/84882653049,"This study is to improve the process of producing lipid convertible to biodiesel, from distillery wastewater while simultaneously removing organics and nutrients efficiently by inoculating oleaginous yeast Rhodosporidium toruloides in the presence of indigenous microorganisms. The lipid productivity of R. toruloides was studied using real wastewater obtained from distillery and local municipal wastewater treatment plants. Under the conditions of mix rate of 1:1 with domestic wastewater, initial soluble chemical oxygen demand (SCOD) over 20,000mg/L and initial cell density of 2×107
                     cells/mL at 30°C, lipid content and lipid yield achieved were 43.65±1.74% and 3.54±0.04g/L, with the associated removal efficiencies for COD, total nitrogen (TN), and total phosphorus (TP), 86.11±0.41%, 57.81±0.29%, and 67.69±0.73%, respectively, after three days of cultivation in real distillery wastewater without pH adjustment. The pH of wastewater increased from 3.71 to over 8 in 7days of cultivation.",industry
10.1016/j.asoc.2012.05.031,Journal,Applied Soft Computing Journal,scopus,2013-01-01,sciencedirect,Optimal design of laser solid freeform fabrication system and real-time prediction of melt pool geometry using intelligent evolutionary algorithms,https://api.elsevier.com/content/abstract/scopus_id/84881665462,"With the rapid growth of laser applications and the introduction of high efficiency lasers (e.g. fiber lasers), laser material processing has gained increasing importance in a variety of industries. Among the applications of laser technology, laser cladding has received significant attention due to its high potential for material processing such as metallic coating, high value component repair, prototyping, and even low-volume manufacturing. In this paper, two optimization methods have been applied to obtain optimal operating parameters of Laser Solid Freeform Fabrication Process (LSFF) as a real world engineering problem. First, Particle Swarm Optimization (PSO) algorithm was implemented for real-time prediction of melt pool geometry. Then, a hybrid evolutionary algorithm called Self-organizing Pareto based Evolutionary Algorithm (SOPEA) was proposed to find the optimal process parameters. For further assurance on the performance of the proposed optimization technique, it was compared to some well-known vector optimization algorithms such as Non-dominated Sorting Genetic Algorithm (NSGA-II) and Strength Pareto Evolutionary Algorithm (SPEA 2). Thereafter, it was applied for simultaneous optimization of clad height and melt pool depth in LSFF process. Since there is no exact mathematical model for the clad height (deposited layer thickness) and the melt pool depth, the authors developed two Adaptive Neuro-Fuzzy Inference Systems (ANFIS) to estimate these two process parameters. Optimization procedure being done, the archived non-dominated solutions were surveyed to find the appropriate ranges of process parameters with acceptable dilutions. Finally, the selected optimal ranges were used to find a case with the minimum rapid prototyping time. The results indicate the acceptable potential of evolutionary strategies for controlling and optimization of LSFF process as a complicated engineering problem.",industry
10.1016/j.riai.2013.05.002,Journal,RIAI - Revista Iberoamericana de Automatica e Informatica Industrial,scopus,2013-01-01,sciencedirect,Identification and wavenet control of AC motor,https://api.elsevier.com/content/abstract/scopus_id/84880211449,"En el presente artículo se muestra un esquema de identificación y control que sintoniza en línea las ganancias proporcional, integral y derivativa de un controlador PID discreto aplicado a un sistema dinámico SISO. Esto se logra empleando una red neuronal de base radial con funciones de activación wavelet hijas Morlet (wavenet) adicionalmente en cascada un filtro de respuesta infinita al impulso (IIR). Dicho esquema es aplicado en tiempo real para controlar la velocidad de un motor de inducción de CA trifásico del tipo jaula de ardilla (MIJA) alimentado con un variador de frecuencia trifásico, de esta forma se muestra cómo este esquema de identificación y control en línea, puede ser implementado en este tipo de plantas que son ampliamente utilizadas en la industria, sin la necesidad de obtener los parámetros del modelo matemático del conjunto variador de frecuencia-motor de inducción trifásico. Se presentan los resultados obtenidos en simulación numérica y experimentales, empleando para esto la plataforma de LabVIEW.
               
                  This paper presents a control scheme to tune online the proportional, integral and derivative gains of a discrete PID controller, through the identification and control of a SISO stable and minimum phase dynamic system. This is accomplished using a radial basis network neural with daughter Morlet wavelets activation functions in cascaded with an infinite impulse response (IIR) filter. This scheme is applied in real time to control the speed of an AC three-phase induction motor supplied with a three-phase inverter. So in this way we show how the identification and control scheme can be implemented in this type of plants that are widely used in industry, without the need of mathematical model parameters of the induction motor. We present numerical simulation and experimental results.",industry
10.1016/j.measurement.2013.02.018,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2013-01-01,sciencedirect,Real time monitoring weld quality of small scale resistance spot welding for titanium alloy,https://api.elsevier.com/content/abstract/scopus_id/84875396538,"Titanium and its alloys have been identified as one of the best engineering metals for application in industrial fields. Whereas, there is limited research work on monitoring and controlling the small scale resistance spot welding (SSRSW) of titanium alloy. This paper performed a systematic research on the voltage curve, which turned out to be an indication for weld quality of SSRSW. It was obtained through clipping two leads onto the electrodes during SSRSW process. As the common equipment in SSRSW, the high frequency (HF) power supply and constant current mode were employed in this study. First voltage curves at different welding parameters were analyzed and then a probabilistic neural network (PNN) model using three factors extracted from the voltage curve was employed in order to classify the weld quality, and satisfied experiment results were acquired. It was demonstrated that the dynamic voltage during a welding process could be identified as a good signature for weld quality monitoring purpose.",industry
10.1016/j.dss.2012.08.006,Journal,Decision Support Systems,scopus,2012-12-01,sciencedirect,Sales forecasting for computer wholesalers: A comparison of multivariate adaptive regression splines and artificial neural networks,https://api.elsevier.com/content/abstract/scopus_id/84868667879,"Artificial neural networks (ANNs) have been found to be useful for sales/demand forecasting. However, one of the main shortcomings of ANNs is their inability to identify important forecasting variables. This study uses multivariate adaptive regression splines (MARS), a nonlinear and non-parametric regression methodology, to construct sales forecasting models for computer wholesalers. Through the outstanding variable screening ability of MARS, important sales forecasting variables for computer wholesalers can be obtained to enable them to make better sales management decisions. Two sets of real sales data collected from Taiwanese computer wholesalers are used to evaluate the performance of MARS. The experimental results show that the MARS model outperforms backpropagation neural networks, a support vector machine, a cerebellar model articulation controller neural network, an extreme learning machine, an ARIMA model, a multivariate linear regression model, and four two-stage forecasting schemes across various performance criteria. Moreover, the MARS forecasting results provide useful information about the relationships between the forecasting variables selected and sales amounts through the basis functions, important predictor variables, and the MARS prediction function obtained, and hence they have important implications for the implementation of appropriate sales decisions or strategies.",industry
10.1016/j.nima.2012.07.046,Journal,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",scopus,2012-11-21,sciencedirect,Development of transportable gamma-ray tomographic system for industrial application,https://api.elsevier.com/content/abstract/scopus_id/84865277796,"This paper introduces a gamma-ray tomographic system which is transportable and can be used for on-line systems such as a pipeline operation. In a previous study, a feasibility study on a gamma-ray tomographic system with a scanning geometry of Electron Beam CT was carried out by Monte Carlo simulation. This paper contains a successive work on a previous study by developing and evaluating a real system. To construct a gamma-ray CT, 137Cs was used as a gamma-ray source and radiation measurement system with 72 channel CsI detectors whose crystal is a 12mm×12mm×20mm rectangular parallelepiped was developed to operate jointly with a motion control system. ML-EM algorithm was used for image reconstruction of experimental data. Using the developed transportable gamma-ray system, laboratory and field experiments were carried out successfully. The field experiment results show that a gamma-ray CT with an Electron Beam CT scanning geometry can be a transportable gantry for objects which are parts of processes.",industry
10.1016/j.asoc.2012.07.015,Journal,Applied Soft Computing Journal,scopus,2012-11-01,sciencedirect,Modeling of input-output relationships for a plasma spray coating process using soft computing tools,https://api.elsevier.com/content/abstract/scopus_id/84865850677,"To automate any manufacturing process, its input–output relationships are to be known in both forward and reverse directions. The present work aims to correlate input process parameters with various responses of a plasma spray coating process. Statistical regression analysis had been carried out previously for this process based on the data collected through central composite design of experiments to establish input–output relationships in forward direction. However, the said relationships could not be accurately determined in reverse direction using the obtained regression equations due to the presence of a non-square transformation matrix. Soft computing-based approaches had been developed to model the process in both forward as well as reverse directions. The performances of the developed approaches had been tested on different cases obtained through real experiments. A comparative study had been made of these developed approaches in terms of accuracy in predictions.",industry
10.1016/j.neucom.2012.01.038,Journal,Neurocomputing,scopus,2012-11-01,sciencedirect,Quantile based decision making rule of the neural networks committee for ill-posed approximation problems,https://api.elsevier.com/content/abstract/scopus_id/84864377639,"In this paper a multidimensional function approximation problem is stated. This problem is characterized by the strong influence of arguments measurement errors on the accuracy of the function estimation and a small amount of train data. A neural networks based solution is used for this problem.
                  To improve the accuracy of the approximation model it is proposed to use a neural networks committee with an original decision making rule for the construction of the generalized function estimate. The developed rule is based on a specially introduced indirect accuracy measure and 
                        α
                        -
                        quantile
                      calculation of its probability level. The decision making rule is trained on a set of patterns and uses statistical properties of each pattern's processing by the committee's networks.
                  The computational scheme of the proposed approximation model and the effectiveness of the proposed approach are demonstrated on a simple model example. The developed method was successfully applied to a real industrial problem of metal's hardness characteristics estimation on the basis of kinetic indentation data. The results of modeling experiments are discussed.",industry
10.1016/j.talanta.2012.04.019,Journal,Talanta,scopus,2012-08-15,sciencedirect,Optimization of solid-phase extraction using artificial neural networks and response surface methodology in combination with experimental design for determination of gold by atomic absorption spectrometry in industrial wastewater samples,https://api.elsevier.com/content/abstract/scopus_id/84864331273,"Solid-phase extraction (SPE) is often used for preconcentration and determination of metal ions from industrial and natural samples. A traditional single variable approach (SVA) is still often carried out for optimization in analytical chemistry. Since there is always a risk of not finding the real optimum by single variation method, more advanced optimization approaches such as multivariable approach (MVA) should be applied. Applying MVA optimization can save both time and chemical materials, and consequently decrease analytical costs. Nowadays, using artificial neural network (ANN) and response surface methodology (RSM) in combination with experimental design (MVA) are rapidly developing. After prediction of model equation in RSM and training of artificial neurons in ANNs, the products were used for estimation of the response of the 27 experimental runs. In the present work, the optimization of SPE using single variation method and optimization by ANN and RSM in combination with central composite design (CCD) are compared and the latter approach is practically illustrated.",industry
10.1016/j.ymssp.2012.01.021,Journal,Mechanical Systems and Signal Processing,scopus,2012-07-01,sciencedirect,FPGA-based entropy neural processor for online detection of multiple combined faults on induction motors,https://api.elsevier.com/content/abstract/scopus_id/84860217701,"For industry, a faulty induction motor signifies production reduction and cost increase. Real-world induction motors can have one or more faults present at the same time that can mislead to a wrong decision about its operational condition. The detection of multiple combined faults is a demanding task, difficult to accomplish even with computing intensive techniques. This work introduces information entropy and artificial neural networks for detecting multiple combined faults by analyzing the 3-axis startup vibration signals of the rotating machine. A field programmable gate array implementation is developed for automatic online detection of single and combined faults in real time.",industry
10.1016/j.conengprac.2012.03.003,Journal,Control Engineering Practice,scopus,2012-06-01,sciencedirect,A MKL based on-line prediction for gasholder level in steel industry,https://api.elsevier.com/content/abstract/scopus_id/84862789304,"The real-time prediction for gasholder level is significant for gas scheduling in steel enterprises. In this study, we extended the least squares support vector regression (LSSVR) to multiple kernel learning (MKL) based on reduced gradient method. The MKL based LSSVR, using the optimal linear combination of kernels, improves the generalization of the model and reduces the training time. The experiments using the classical non-flat function and the practical problem shows that the proposed method achieves well performance and high computational efficiency. And, an application system based on the approach is developed and applied to the practice of Shanghai Baosteel Co. Ltd.",industry
10.1016/j.commatsci.2012.03.008,Journal,Computational Materials Science,scopus,2012-06-01,sciencedirect,Back propagation neural network based calculation model for predicting wear of fine-blanking die during its whole lifetime,https://api.elsevier.com/content/abstract/scopus_id/84859850016,"Die wear during fine-blanking process greatly influences the lifetime of die as well as the quality of products. It is a known fact that wear of die is nonlinearly related to blanking times during its whole service life. To illustrate this phenomenon effectively and precisely, a calculation model for predicting wear of fine-blanking die during its whole lifetime was established based on Back Propagation (BP) Neural Network, Finite Element Method (FEM) and experiments. The inherent law between wear of fine-blanking die and its working parameters was revealed by utilizing the BP neural network. Based on the obtained function and the variation of the working parameters, a calculation model was established to predict die wear at any blanking times during fine-blanking process. To verify the efficiency and validity of the proposed calculation model, a fine-blanked part was utilized in this paper. Tool wear of the bottom die was investigated. Pressure-pad force, ejector force, blanking speed, blanking clearance, fillet radius of bottom and hardness of bottom die were specified to be the key process parameters contributing to the wear condition of bottom die. The process parameters’ coupled influence on die wear during fine-blanking process was obtained by a trained neural network. And the die–wear-curve predicted by the calculation model is in good agreement with the real manufacture, which confirms the validity of the proposed BP neural network based calculation model.",industry
10.1016/j.cirp.2012.03.065,Journal,CIRP Annals - Manufacturing Technology,scopus,2012-04-23,sciencedirect,Decision support systems for effective maintenance operations,https://api.elsevier.com/content/abstract/scopus_id/84861592241,"To compete successfully in the market place, leading manufacturing companies are pursuing effective maintenance operations. Existing computerized maintenance management systems (CMMS) can no longer meet the needs of dynamic maintenance operations. This paper describes newly developed decision support tools for effective maintenance operations: (1) data-driven short-term throughput bottleneck identification, (2) estimation of maintenance windows of opportunity, (3) prioritization of maintenance tasks, (4) joint production and maintenance scheduling systems, and (5) maintenance staff management. Mathematical algorithms and simulation tools are utilized to illustrate the concepts of these decision support systems. Results from real implementations in automotive manufacturing are presented to demonstrate the effectiveness of these tools.",industry
10.1016/j.jmsy.2011.09.002,Journal,Journal of Manufacturing Systems,scopus,2012-04-01,sciencedirect,Intelligent evaluation of supplier bids using a hybrid technique in distributed supply chains,https://api.elsevier.com/content/abstract/scopus_id/84858340427,"The main idea of this research is to devise the smart module to pick the best supplier bid(s) automatically. The hybrid model is composed of three useful tools: fuzzy logic, AHP, and QFD. The approach has been carefully implemented and verified via a real-world case study in a medium-to-large industry manufacturing vehicle tires and other rubber products. A collection of 12 assessment criteria classified into two categories have been considered. Eight factors are derived from customer suggestions and the other four are design specifications required to manufacture the product. The main outcomes are: a hybrid autonomous model to evaluate supplier bids without direct human intervention; devising a hybrid three-module method and overcoming complexity of computations in resulting algorithm by means of agents; outlining the best criteria to assess suppliers; evaluating the suppliers based on voice of customer during all stages of the process; and discussing analysis, design, and implementation issues of the evaluation agent. The paper includes implications for development of an integrated total system for supply chain coordination. The most important advantages of this work over earlier researches on supplier selection are: implementation of an autonomous assessment mechanism using intelligent agents for the first time, making the best out of three widely applied methodologies all at once, evaluation process mainly based on features of customer order, coordination of supply job based on a bidding system, and portal-mediated operation and control.",industry
10.1016/j.conengprac.2011.06.009,Journal,Control Engineering Practice,scopus,2012-04-01,sciencedirect,Data reconciliation and optimal management of hydrogen networks in a petrol refinery,https://api.elsevier.com/content/abstract/scopus_id/84857191932,"This paper describes the main problems associated to the management of hydrogen networks in petrol refineries and presents an approach to deal with them with the aim of operating the installation in the most profitable way. In particular, the problems of data reconciliation, economic optimization and interaction with the underlying basic control system are reviewed. The paper provides also a proposal for the implementation of the system and illustrates the approach with results obtained using real data from an industrial site.",industry
10.1016/j.eswa.2011.11.112,Journal,Expert Systems with Applications,scopus,2012-04-01,sciencedirect,A multi-agent-based decision support system for bankruptcy contagion effects,https://api.elsevier.com/content/abstract/scopus_id/84855900478,"With the increasing interdependence of marketing participants, distress experienced by a specific entity may cause other connecting firms to encounter financial difficulties, leading to a negative impact on their stock valuations. At the same time, individual investors have a great need to gain relevant information for portfolio risk management. The monitoring vision cannot be limited to investors’ portfolios but must take into account any potential candidates affected. Based on the ontological knowledge model of inter-firm relationships, the proposed multi-agent decision support system continuously observes real-time news reports and forecasts their potential impact on the corresponding stock price. After identifying relating companies for which significant market reactions can be expected, a wireless push-based message service promptly supplies information. A case study is used to illustrate the multi-agent-based decision support system (MAB-DSS) implementation and its use. The example shows that the MAB-DSS can automate the solution for intricate and dynamic valuation effects among interdependent firms and provide constructive advice for individual investors.",industry
10.1016/j.ejor.2011.09.024,Journal,European Journal of Operational Research,scopus,2012-03-01,sciencedirect,On a learning precedence graph concept for the automotive industry,https://api.elsevier.com/content/abstract/scopus_id/80755188220,"Assembly line balancing problems (ALBP) consist in assigning the total workload for manufacturing a product to stations of an assembly line as typically applied in automotive industry. The assignment of tasks to stations is due to restrictions which can be expressed in a precedence graph. However, (automotive) manufacturers usually do not have sufficient information on their precedence graphs. As a consequence, the elaborate solution procedures for different versions of ALBP developed by more than 50years of intensive research are often not applicable in practice.
                  Unfortunately, the known approaches for precedence graph generation are not suitable for the conditions in the automotive industry. Therefore, we describe a new graph generation approach that is based on learning from past feasible production sequences and forms a sufficient precedence graph that guarantees feasible line balances. Computational experiments indicate that the proposed procedure is able to approximate the real precedence graph sufficiently well to detect optimal or nearly optimal solutions for a well-known benchmark data set. Even for additional large instances with up to 1,000 tasks, considerable improvements of line balances are possible. Thus, the new approach seems to be a major step to close the gap between theoretical line balancing research and practice of assembly line planning.",industry
10.1016/j.compeleceng.2012.05.013,Journal,Computers and Electrical Engineering,scopus,2012-01-01,sciencedirect,Automatic network intrusion detection: Current techniques and open issues,https://api.elsevier.com/content/abstract/scopus_id/84866355973,"Automatic network intrusion detection has been an important research topic for the last 20years. In that time, approaches based on signatures describing intrusive behavior have become the de-facto industry standard. Alternatively, other novel techniques have been used for improving automation of the intrusion detection process. In this regard, statistical methods, machine learning and data mining techniques have been proposed arguing higher automation capabilities than signature-based approaches. However, the majority of these novel techniques have never been deployed on real-life scenarios. The fact is that signature-based still is the most widely used strategy for automatic intrusion detection. In the present article we survey the most relevant works in the field of automatic network intrusion detection. In contrast to previous surveys, our analysis considers several features required for truly deploying each one of the reviewed approaches. This wider perspective can help us to identify the possible causes behind the lack of acceptance of novel techniques by network security experts.",industry
10.3182/20120403-3-DE-3010.00082,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2012-01-01,sciencedirect,Web monitoring system and gateway for serial communication PLC,https://api.elsevier.com/content/abstract/scopus_id/84866084543,"An industrial process requires interacting with the rest of the plant, being able to exchange data with other devices and monitoring systems in order to optimize production, reporting information and providing control capabilities to distant users. Internet, and, especially web browsers are an excellent tool to provide information for remote users, allowing not only monitoring but also controlling the industrial process as an SCADA software or HMI system. The proposed system does not need specific proprietary software and its associated license costs. In this work, a webserver system is implemented under a Freescale microcontroller, acting as a gateway for a simple PLC with single RS232 communication capabilities. The webserver is modular, providing independent access to single I/O PLC locations. Different webpage design can offer different monitoring capabilities by combining the required I/O modules according to the required application without any change in the microcontroller programming. This capability is close to SCADA software or industrial HMI systems where custom screens can be made. This proposal offers a low cost and flexible monitoring solution to old or basic industrial processes controlled by PLC with low communication capabilities. Using a web browser, the system can be monitored from any internet capable device: PC, tablet, smartphone, etc. An example for a pneumatic PID levitation control system is given.",industry
10.1016/j.asoc.2011.05.011,Journal,Applied Soft Computing Journal,scopus,2011-12-01,sciencedirect,Credit risk evaluation using neural networks: Emotional versus conventional models,https://api.elsevier.com/content/abstract/scopus_id/80053571498,"Credit scoring and evaluation is one of the key analytical techniques in credit risk evaluation which has been an active research area in financial risk management. Artificial neural networks (NNs) have been considered to be accurate tools for credit analysis among others in the credit industry. Lately, emotional neural networks (EmNNs) have been suggested and applied successfully for pattern recognition. In this paper we investigate the efficiency of EmNNs and compare their performance to conventional NNs when applied to credit risk evaluation. In total 12 neural networks; based equally on emotional and conventional neural models; are arbitrated under three learning schemes to classify whether a credit application is approved or declined. The learning schemes differ in the ratio of training-to-validation data used during training and testing the neural networks. The emotional and conventional neural models are trained using real world credit application cases from the Australian credit approval datasets which has 690 cases; each case with 14 numerical attributes; based on which an application is accepted or rejected. The performance of the 12 neural networks will be evaluated using certain criteria. Experimental results suggest that both emotional and conventional neural models can be used effectively for credit risk evaluations, however the emotional models outperform their conventional counterparts in decision making speed and accuracy, thus, making them ideal for implementation in fast automatic processing of credit applications.",industry
10.1016/j.ijthermalsci.2011.06.020,Journal,International Journal of Thermal Sciences,scopus,2011-12-01,sciencedirect,A simplified method to evaluate the energy performance of CO<inf>2</inf> heat pump units,https://api.elsevier.com/content/abstract/scopus_id/80052736833,"The prediction of the performances of CO2 transcritical heat pumps demands accurate calculation methods, where a particular effort is devoted to the gas cooler modelling, as the correlation between high pressure and gas cooler outlet temperature strongly affects the cycle performance. The above-mentioned methods require a large amount of input data and calculation power. As a consequence they are often useless for the full characterisation of heat pumps which are sold on the market.
                  A simplified numerical method for the performance prediction of vapour compression heat pumps working in a transcritical cycle is presented, based only on performance data at the nominal rating conditions. The proposed procedure was validated against experimental data of two different tap water heat pumps. For the considered units, simulation results are in good agreement with the experimental ones. The deviations range from −6.4% to +1.7% and from −3.8% to +5.8% for the COPH
                      of the air/water heat pump and the water/water heat pump, respectively. The heating capacity deviations stayed within −5.5% and +1.7% range and within −5.0% and +7.9% range for the same units.
                  The proposed mathematical model appears to be a reliable tool to be used by the refrigeration industry or to be implemented into dynamic building-plant energy simulation codes. Finally, it represents a useful instrument for the definition of tailored approximated optimal high pressure curve considering the operating characteristics of the specific CO2 transcritical unit. It could also be implemented on board of a real unit control system where it could be used as model coupled to computational intelligence algorithms for pressure optimisation.",industry
10.1016/j.ejor.2011.05.052,Journal,European Journal of Operational Research,scopus,2011-12-01,sciencedirect,"Semiconductor final test scheduling with Sarsa(λ, k) algorithm",https://api.elsevier.com/content/abstract/scopus_id/80051799845,"Semiconductor test scheduling problem is a variation of reentrant unrelated parallel machine problems considering multiple resource constraints, intricate {product, tester, kit, enabler assembly} eligibility constraints, sequence-dependant setup times, etc. A multi-step reinforcement learning (RL) algorithm called Sarsa(λ,
                     k) is proposed and applied to deal with the scheduling problem with throughput related objective. Allowing enabler reconfiguration, the production capacity of the test facility is expanded and scheduling optimization is performed at the bottom level. Two forms of Sarsa(λ,
                     k), i.e. forward view Sarsa(λ,
                     k) and backward view Sarsa(λ,
                     k), are constructed and proved equivalent in off-line updating. The upper bound of the error of the action-value function in tabular Sarsa(λ,
                     k) is provided when solving deterministic problems. In order to apply Sarsa(λ,
                     k), the scheduling problem is transformed into an RL problem by representing states, constructing actions, the reward function and the function approximator. Sarsa(λ,
                     k) achieves smaller mean scheduling objective value than the Industrial Method (IM) by 68.59% and 76.89%, respectively for real industrial problems and randomly generated test problems. Computational experiments show that Sarsa(λ,
                     k) outperforms IM and any individual action constructed with the heuristics derived from the existing heuristics or scheduling rules.",industry
10.1016/j.ajodo.2011.05.019,Journal,American Journal of Orthodontics and Dentofacial Orthopedics,scopus,2011-11-01,sciencedirect,Real-time cell analysis of the cytotoxicity of the components of orthodontic acrylic materials on gingival fibroblasts,https://api.elsevier.com/content/abstract/scopus_id/80155206881,"Introduction
                  The aim of this study was to evaluate the cytotoxicity of 3 orthodontic acrylic materials and 2 manipulation methods.
               
                  Methods
                  The orthodontic acrylic materials Orthocryl EQ (Dentaurum, Ispringen, Germany), Orthoplast (Vertex Dental, Zeist, The Netherlands), and O-80 (Imicryl, Konya, Turkey) were prepared with 2 polymerization methods (doughing and spray on). Totally, 60 cylinders (5 × 2 mm), fabricated by using a different acrylic and method, were divided into 6 groups. Gingival fibroblasts were isolated from gingival connective tissue of systemically healthy subjects. Materials were incubated in Dulbecco's modified eagle's medium culture medium (Biological Industries, Beit Haemek, Israel) for 72 hours according to ISO 10993-5 standards (surface area to volume ratio of the specimen to cell-culture medium: 3 cm2/mL). Gingival fibroblasts were maintained with Dulbecco’s modified eagle medium containing 10% fetal bovine serum. A real-time cell analyzer (RT-CES, xCELLigence; Roche Applied Science, Mannheim, Germany, and ACEA Biosciences, San Diego, Calif) was used to evaluate cell survival. After seeding 200 μL of the cell suspensions into the wells (20,000 cells/well) of the E-plate 96, gingival fibroblasts were treated with bioactive components released by the acrylic materials (1/1 and 1/2 dilutions) and monitored every 15 minutes for 121 hours. For the proliferation experiments, the statistical analyses used were 1-way analysis of variance (ANOVA) and Tukey-Kramer multiple comparisons tests.
               
                  Results
                  There was no significant difference between the cell indexes of the control and study groups for the 1/1 and 1/2 dilutions at 21 and 32 hours. When evaluated at 68 hours, all 1/2 dilutions of acrylic materials showed statistically insignificant differences (P >0.05) except for Orthoplast (P <0.05). But all acrylic materials were different from the control group in the 1/1 dilutions (P <0.001). At 121 hours, all test groups were significantly different from the untreated control group (P <0.001).
               
                  Conclusions
                  The results indicate that the long cycle increased the cytotoxicity of the tested materials, and there was no significant difference between the spray-on and doughing methods on cytotoxicity.",industry
10.1016/j.neucom.2011.06.027,Journal,Neurocomputing,scopus,2011-11-01,sciencedirect,Neural network based controller for Cr<sup>6+</sup>-Fe<sup>2+</sup> batch reduction process,https://api.elsevier.com/content/abstract/scopus_id/80053311549,An automated pilot plant has been designed and commissioned to carry out online/real-time data acquisition and control for the Cr6+–Fe2+ reduction process. Simulated data from the Cr6+–Fe2+ model derived are validated with online data and laboratory analysis using ICP-AES analysis method. The distinctive trend or patterns exhibited in the ORP profiles for the non-equilibrium model derived have been utilized to train neural network-based controllers for the process. The implementation of this process control is to ensure sufficient Fe2+ solution is dosed into the wastewater sample in order to reduce all Cr6+–Cr3+. The neural network controller has been utilized to compare the capability of set-point tracking with a PID controller in this process. For this process neural network-based controller dosed in less Fe2+ solution compared to the PID controller which hence reduces wastage of chemicals. Industrial Cr6+ wastewater samples obtained from an electro-plating factory has also been tested on the pilot plant using the neural network-based controller to determine its effectiveness to control the reduction process for a real plant. The results indicate the proposed controller is capable of fully reducing the Cr6+–Cr3+ in the batch treatment process with minimal dosage of Fe2+.,industry
10.1016/j.envsoft.2011.04.002,Journal,Environmental Modelling and Software,scopus,2011-10-01,sciencedirect,Application of the Analytic Hierarchy Process and the Analytic Network Process for the assessment of different wastewater treatment systems,https://api.elsevier.com/content/abstract/scopus_id/79957865817,"Multicriteria analyses (MCAs) are used to make comparative assessments of alternative projects or heterogeneous measures and allow several criteria to be taken into account simultaneously in a complex situation. The paper shows the application of different MCA techniques to a real decision problem concerning the choice of the most sustainable wastewater treatment (WWT) technology, namely Anaerobic digestion, Phytoremediation and Composting, for small cheese factories. Particularly, the Analytic Hierarchy Process (AHP) and its recent implementation, the Analytic Network Process (ANP), have been considered for prioritizing the different technologies. The models enable all the elements of the decision process to be considered, namely environmental aspects, technological factors and economic costs, and to compare them to find the best alternative. The AHP and ANP techniques are applied through specific software packages with user-friendly interfaces called Expertchoice and Superdecision, respectively. A comparison of the merits obtained from the different models shows that Phytoremediation results as the most sustainable WWT technology for small cheese factories and that the use of the ANP method, which allows more sophisticated analysis to be made, succeeds in offering better results.",industry
10.1016/j.eswa.2011.04.012,Journal,Expert Systems with Applications,scopus,2011-09-15,sciencedirect,Fast defect detection in homogeneous flat surface products,https://api.elsevier.com/content/abstract/scopus_id/79958015915,"This paper introduces a novel hybrid approach for both defect detection and localization in homogeneous flat surface products. Real time defect detection in industrial products is a challenging problem. Fast production speeds and the variable nature of production defects complicate the process of automating the defect detection task. Speeding up the detection process is achieved in this paper by implementing a hybrid approach that is based on the statistical decision theory, multi-scale and multi-directional analysis and a neural network implementation of the optimal Bayesian classifier. The coefficient of variation is first used as a homogeneity measure for approximate defect localization. Second, features are extracted from the log Gabor filter bank response to accurately localize and detect the defect while reducing the complexity of Gabor based inspection approaches. A probabilistic neural network (PNN) is used for fast defect classification based on the maximum posterior probability of the Log-Gabor based statistical features. Experimental results show a major performance enhancement over existing defect detection approaches.",industry
10.1016/j.neucom.2010.12.043,Journal,Neurocomputing,scopus,2011-09-01,sciencedirect,SELM: Semi-supervised ELM with application in sparse calibrated location estimation,https://api.elsevier.com/content/abstract/scopus_id/80051590438,"Indoor location estimation based on Wi-Fi has attracted more and more attention from both research and industry fields. It brings two significant challenges. One is requiring a vast amount of labeled calibration data. The other is real-time training and testing for location estimation task. Traditional machine learning methods cannot get high performance in both aspects. This paper proposed a novel semi-supervised learning method SELM (semi-supervised extreme learning machine) and applied it to sparse calibrated location estimation. There are two advantages of the proposed SELM. First, it employs graph Laplacian regularization to import large number of unlabeled samples which can dramatically reduce labeled calibration samples. Second, it inherits the good property of ELM on extreme training and testing speed. Comparative experiments show that with same number of labeled samples, our method outperforms original ELM and back propagation (BP) network, especially in the case that the calibration data is very sparse.",industry
10.1016/j.vetpar.2011.03.021,Journal,Veterinary Parasitology,scopus,2011-08-25,sciencedirect,Loop-mediated isothermal amplification test for Trypanosoma vivax based on satellite repeat DNA,https://api.elsevier.com/content/abstract/scopus_id/79960844007,"Trypanosoma vivax is major cause of animal trypanosomiasis and responsible for enormous economic burden in Africa and South America animal industry. T. vivax infections mostly run low parasitaemia with no apparent clinical symptoms, making diagnosis a challenge. This work reports the design and evaluation of a loop-mediated isothermal amplification (LAMP) test for detecting T. vivax DNA based on the nuclear satellite repeat sequence. The assay is rapid with results obtained within 35min. The analytical sensitivity is ∼1trypanosome/ml while that of the classical PCR tests ranged from 10 to 103
                     trypanosomes/ml. The T. vivax LAMP test reported here is simple, robust and has future potential in diagnosis of animal trypanosomiasis in the field.",industry
10.1016/j.ces.2011.03.041,Journal,Chemical Engineering Science,scopus,2011-08-01,sciencedirect,Successive approximate model based multi-objective optimization for an industrial straight grate iron ore induration process using evolutionary algorithm,https://api.elsevier.com/content/abstract/scopus_id/79958723405,"Multi-objective optimization of any complex industrial process using first principle computationally expensive models often demands a substantially higher computation time for evolutionary algorithms making it less amenable for real time implementation. A combination of the above-mentioned first principle model and approximate models based on artificial neural network (ANN) successively learnt in due course of optimization using the data obtained from first principle models can be intelligently used for function evaluation and thereby reduce the aforementioned computational burden to a large extent. In this work, a multi-objective optimization task (simultaneous maximization of throughput and Tumble index) of an industrial iron ore induration process has been studied to improve the operation of the process using the above-mentioned metamodeling approach. Different pressure and temperature values at different points of the furnace bed, grate speed and bed height have been used as decision variables whereas the bounds on cold compression strength, abrasion index, maximum pellet temperature and burn-through point temperature have been treated as constraints. A popular evolutionary multi-objective algorithm, NSGA II, amalgamated with the first principle model of the induration process and its successively improving approximation model based on ANN, has been adopted to carry out the task. The optimization results show that as compared to the PO solutions obtained using only the first principle model, (i) similar or better quality PO solutions can be achieved by this metamodeling procedure with a close to 50% savings in function evaluation and thereby computation time and (ii) by keeping the total number of function evaluations same, better quality PO solutions can be obtained.",industry
10.1016/j.rcim.2011.01.004,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2011-08-01,sciencedirect,Neuro-adaptive motion control with velocity observer in operational space formulation,https://api.elsevier.com/content/abstract/scopus_id/79955667317,"In this paper, a neuro-adaptive motion control with velocity observer is developed and validated in real-time experiment using a 6 DOF PUMA 560 robot. The controller is constructed for the operational space formulation, such that dynamic terms and the generalized force descriptions in this algorithm are expressed in the task space. The proposed strategy assumes no prior knowledge of the robot dynamics, and is formulated without assuming the availability of joint velocity feedback. As such, the controller takes only position feedback. This is an important feature as industrial robots are often fitted only with joint displacement sensors, not joint rate sensors. Stability analysis of the algorithm is analysed and presented in the paper. Real-time experiments on a 6 degrees of freedom (DOF) PUMA 560 manipulator were carried out to evaluate the effectiveness of the proposed NN adaptive control strategy with velocity observer and to compare the performance with the conventional inverse-dynamics control and a similar NN adaptive strategy using filtered velocity feedback, obtained through the backward difference of the displacement feedback. It should be noted that the experimental platform, PUMA 560, provides only joint displacement feedback through its joint mounted encoders. The results show a comparable results between the proposed strategy and the inverse-dynamics control law, without the need to perform dynamics identification procedures.",industry
10.1016/j.eswa.2011.01.051,Journal,Expert Systems with Applications,scopus,2011-08-01,sciencedirect,Recommendation system for localized products in vending machines,https://api.elsevier.com/content/abstract/scopus_id/79953690190,"This paper proposes a framework of localized product recommendation system for automatic vending machines applications. The goal is to offer suitable recommendations of localized products to customers in distinct locations. We develop a hybrid technique that combines a meta-heuristic approach, clustering technique, classification, and statistical method. In the approach, an intelligent system is implemented to analyze product attributes and determine localized products based on the transaction data. To prove the feasibility and effectiveness of proposed approach, we implemented the system in several automatic vending machines owned by an information service company of Taiwan. Nine machines were selected and compared from two locations: living lab by Institute for Information Industry of Taiwan at Song-shan District and business office building at Nei-hu District in Taipei. The real life experiments showed that the profit of vending machine increases after applying our system.",industry
10.1016/j.jchromb.2011.03.059,Journal,Journal of Chromatography B: Analytical Technologies in the Biomedical and Life Sciences,scopus,2011-06-01,sciencedirect,Influence of different spacer arms on Mimetic Ligand <sup>™</sup> A2P and B14 membranes for human IgG purification,https://api.elsevier.com/content/abstract/scopus_id/79955910197,"Microporous membranes are an attractive alternative to circumvent the typical drawbacks associated to bead-based chromatography. In particular, the present work intends to evaluate different affinity membranes for antibody capture, to be used as an alternative to Protein A resins. To this aim, two Mimetic Ligands™ A2P and B14, were coupled onto different epoxide and azide group activated membrane supports using different spacer arms and immobilization chemistries. The spacer chemistries investigated were 1,2-diaminoethane (2LP), 3,6-dioxa-1,8-octanedithiol (DES) and [1,2,3] triazole (TRZ). These new mimetic membrane materials were investigated by static and by dynamic binding capacity studies, using pure polyclonal human immunoglobulin G (IgG) solutions as well as a real cell culture supernatant containing monoclonal IgG1. The best results were obtained by combining the new B14 ligand with a TRZ-spacer and an improved Epoxy 2 membrane support material. The new B14-TRZ-Epoxy 2 membrane adsorbent provided binding capacities of approximately 3.1mg/mL, besides (i) a good selectivity towards IgG, (ii) high IgG recoveries of above 90%, (iii) a high Pluronic-F68 tolerance and (iv) no B14-ligand leakage under harsh cleaning-in-place conditions (0.6M sodium hydroxide). Furthermore, foreseeable improvements in binding capacity will promote the implementation of membrane adsorbers in antibody manufacturing.",industry
10.1016/j.matdes.2011.01.058,Journal,Materials and Design,scopus,2011-06-01,sciencedirect,A hybrid of back propagation neural network and genetic algorithm for optimization of injection molding process parameters,https://api.elsevier.com/content/abstract/scopus_id/79953161387,"This paper presents a hybrid optimization method for optimizing the process parameters during plastic injection molding (PIM). This proposed method combines a back propagation (BP) neural network method with an intelligence global optimization algorithm, i.e. genetic algorithm (GA). A multi-objective optimization model is established to optimize the process parameters during PIM on the basis of the finite element simulation software Moldflow, Orthogonal experiment method, BP neural network as well as Genetic algorithm. Optimization goals and design variables (process parameters during PIM) are specified by the requirement of manufacture. A BP artificial neural network model is developed to obtain the mathematical relationship between the optimization goals and process parameters. Genetic algorithm is applied to optimize the process parameters that would result in optimal solution of the optimization goals. A case study of a plastic article is presented. Warpage as well as clamp force during PIM are investigated as the optimization objectives. Mold temperature, melt temperature, packing pressure, packing time and cooling time are considered to be the design variables. The case study demonstrates that the proposed optimization method can adjust the process parameters accurately and effectively to satisfy the demand of real manufacture.",industry
10.1016/j.eswa.2010.12.089,Journal,Expert Systems with Applications,scopus,2011-06-01,sciencedirect,An intelligent fast sales forecasting model for fashion products,https://api.elsevier.com/content/abstract/scopus_id/79951578472,"Sales forecasting is crucial in fashion business because of all the uncertainty associated with demand and supply. Many models for forecasting fashion products are proposed in the literature over the past few decades. With the emergence of artificial intelligence models, artificial neural networks (ANN) are widely used in forecasting. ANN models have been revealed to be more efficient and effective than many traditional statistical forecasting models. Despite the reported advantages, it is relatively more time-consuming for ANN to perform forecasting. In the fashion industry, sales forecasting is challenging because there are so many product varieties (i.e., SKUs) and prompt forecasting result is needed. As a result, the existing ANN models would become inadequate. In this paper, a new model which employs both the extreme learning machine (ELM) and the traditional statistical methods is proposed. Experiments with real data sets are conducted. A comparison with other traditional methods has shown that this ELM fast forecasting (ELM-FF) model is quick and effective.",industry
10.1016/j.autcon.2010.10.005,Journal,Automation in Construction,scopus,2011-05-01,sciencedirect,Using affective human-machine interface to increase the operation performance in virtual construction crane training system: A novel approach,https://api.elsevier.com/content/abstract/scopus_id/79952624201,"In the construction industry, some progress have been achieved by researchers to design and implement environments for task training using VR technology and its derivatives such as Augmented and Mixed Reality. Although, these developments have been well recognized at the application level, however crucial to the virtual training system is the effective and reliable measurement of training performance of the particular skill and handling the experiment for long-run. It is known that motor skills cannot be measured directly, but only inferred by observing behaviour or performance measures. The typical way of measuring performance is through measuring task completion time and accuracy, but can be supported by indirect measurement of some other factors. In this paper, a virtual crane training system has been developed which can be controlled using control commands extracted from facial gestures and is capable to lift up loads/materials in the virtual construction sites. Then, we integrate affective computing concept into the conventional VR training platform for measuring the cognitive load and level of satisfaction during performance using human's forehead bioelectric-signals. By employing the affective measures and our novel control scheme, the designed interface could be adapted to user's affective status during the performance in real-time. This adaptable user interface approach helps the trainee to cope with the training for long-run performance, leads to gaining more expertise and provides more effective transfer of learning to other operation environments. The detailed methodology of the affective control is presented in the paper. The results and future applications of the proposed method for disabled users, especially from neck down are discussed.",industry
10.1016/j.dss.2010.12.002,Journal,Decision Support Systems,scopus,2011-04-01,sciencedirect,A hybrid SARIMA wavelet transform method for sales forecasting,https://api.elsevier.com/content/abstract/scopus_id/79951508907,"Time series forecasting, as an important tool in many decision support systems, has been extensively studied and applied for sales forecasting over the past few decades. There are many well-established and widely-adopted forecasting methods such as linear extrapolation and SARIMA. However, their performance is far from perfect and it is especially true when the sales pattern is highly volatile. In this paper, we propose a hybrid forecasting scheme which combines the classic SARIMA method and wavelet transform (SW). We compare the performance of SW with (i) pure SARIMA, (ii) a forecasting scheme based on linear extrapolation with seasonal adjustment (CSD+LESA), and (iii) evolutionary neural networks (ENN). We illustrate the significance of SW and establish the conditions that SW outperforms pure SARIMA and CSD+LESA. We further study the time series features which influence the forecasting accuracy, and we propose a method for conducting sales forecasting based on the features of the given sales time series. Experiments are conducted by using real sales data, hypothetical data, and publicly available data sets. We believe that the proposed hybrid method is highly applicable for forecasting sales in the industry.",industry
10.1016/j.aca.2011.01.041,Journal,Analytica Chimica Acta,scopus,2011-03-18,sciencedirect,Biodiesel classification by base stock type (vegetable oil) using near infrared spectroscopy data,https://api.elsevier.com/content/abstract/scopus_id/79952487365,"The use of biofuels, such as bioethanol or biodiesel, has rapidly increased in the last few years. Near infrared (near-IR, NIR, or NIRS) spectroscopy (>4000cm−1) has previously been reported as a cheap and fast alternative for biodiesel quality control when compared with infrared, Raman, or nuclear magnetic resonance (NMR) methods; in addition, NIR can easily be done in real time (on-line). In this proof-of-principle paper, we attempt to find a correlation between the near infrared spectrum of a biodiesel sample and its base stock. This correlation is used to classify fuel samples into 10 groups according to their origin (vegetable oil): sunflower, coconut, palm, soy/soya, cottonseed, castor, Jatropha, etc. Principal component analysis (PCA) is used for outlier detection and dimensionality reduction of the NIR spectral data. Four different multivariate data analysis techniques are used to solve the classification problem, including regularized discriminant analysis (RDA), partial least squares method/projection on latent structures (PLS-DA), K-nearest neighbors (KNN) technique, and support vector machines (SVMs). Classifying biodiesel by feedstock (base stock) type can be successfully solved with modern machine learning techniques and NIR spectroscopy data. KNN and SVM methods were found to be highly effective for biodiesel classification by feedstock oil type. A classification error (E) of less than 5% can be reached using an SVM-based approach. If computational time is an important consideration, the KNN technique (E
                     =6.2%) can be recommended for practical (industrial) implementation. Comparison with gasoline and motor oil data shows the relative simplicity of this methodology for biodiesel classification.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
10.1016/j.asoc.2010.09.007,Journal,Applied Soft Computing Journal,scopus,2011-03-01,sciencedirect,Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm,https://api.elsevier.com/content/abstract/scopus_id/78751613501,"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits.",industry
10.1016/j.cma.2010.11.014,Journal,Computer Methods in Applied Mechanics and Engineering,scopus,2011-02-01,sciencedirect,Multi-objective optimization of turbomachinery using improved NSGA-II and approximation model,https://api.elsevier.com/content/abstract/scopus_id/78650612499,"Coupled optimization methods based on multi-objective genetic algorithms and approximation models are widely used in engineering optimizations. In the present paper, a similar framework is proposed for the aerodynamic optimization of turbomachinery by coupling the well known multi-objective genetic algorithm—NSGA-II and back propagation neural network. The verification results of mathematical problems show that the coupled method with the origin NSGA-II cannot get the real Pareto front due to the prediction error of BPNN. A modified crowding distance is proposed in cooperation with a coarse-to-fine approaching strategy based on the iterations between NSGA-II and BPNN. The results of mathematical model problems show the effect of these improving strategies. An industrial application case is implemented on a transonic axial compressor. The optimization objectives are to maximize efficiencies of two working points and to minimize the variation of the choked mass flow. CFD simulation is employed to provide the performance evaluation of initial training samples for BPNN. The optimized results are compared with optimization results of a single objective optimization based on weighting function. The comparison shows that the present framework can provide not only better solutions than the single objective optimization, but also various alternative solutions. The increase of computational costs is acceptable especially when approximation models are used.",industry
10.3182/20110828-6-IT-1002.02080,Conference Proceeding,IFAC Proceedings Volumes (IFAC-PapersOnline),scopus,2011-01-01,sciencedirect,A LEGO Mindstorms multi-robot setup in the Automatic Control Telelab,https://api.elsevier.com/content/abstract/scopus_id/84866106157,"Abstract
                  This paper presents an experimental setup for multi-robot systems based on the LEGO Mindstorms NXT technology. The team of mobile robots is supervised by a vision system, which allows one to simulate different types of sensors and communication architectures. The whole setup is embedded in the Automatic Control Telelab (http://act.dii.unisi.itact.dii.unisi.it), a remote lab featuring several educational experiences in control. Remote users can design control laws for the multi-agent system in the Matlab environment and test them by performing real experiments in the proposed setup. The paper presents some experiments showing how this remote lab can stimulate students’ interest in mobile robotics.",industry
10.1016/j.procs.2011.08.020,Conference Proceeding,Procedia Computer Science,scopus,2011-01-01,sciencedirect,Model development of a virtual learning environment to enhance lean education,https://api.elsevier.com/content/abstract/scopus_id/84856459118,"Modern day industry is becoming leaner by the day. This demands engineers with an in-depth understanding of lean philosophies. Current methods for teaching lean include hands-on projects and simulation. However, simulation games available in the market lack simplicity, ability to store the results, and modeling power. The goal of this research is to develop a virtual simulation platform which would enable students to perform various experiments by applying lean concepts. The design addresses these deficiencies through the use of VE-Suite, a virtual engineering software. The design includes user-friendly dialogue boxes, graphical models of machines, performance display gauges, and an editable layout. The platform uses laws of operations management such as Little's law, economic order quantity (EOQ) models, and cycle time. These laws enable students to implement various lean concepts such as pull system, just-in-time (JIT), single piece flow, single minute exchange of dies (SMED), kaizen, kanban, U-layout, by modifying the process parameters such as process times, setup times, layout, number, and placement of machines. The simulation begins with a traditional push type mass production line and the students improve the line by implementing lean techniques. Thus, students experience the advantages of lean real time while facing the real life problems encountered in implementing it.",industry
10.1016/j.jngse.2011.08.002,Journal,Journal of Natural Gas Science and Engineering,scopus,2011-01-01,sciencedirect,An implementation of a distributed artificial intelligence architecture to the integrated production management,https://api.elsevier.com/content/abstract/scopus_id/84855498917,"The oil production process is highly complex and requires the combination of several disciplines and technological tools for its management. System integration and the automation of the workflows required to develop oil production operations are two main problems nowadays at the oil and gas production industry. This work approaches these problems through the implementation of distributed artificial intelligence architecture, designed for the automated production management. The architecture comprises a standardized schema to access information sources, a production ontological framework and an intelligent workflow mechanism based on multi-agent systems and electronic institution. Our architecture present several novelties: the incorporation of the semantic integration, the extension of the agents theory through the electronic institutions paradigm to solve the real-time decision problems typical in the industry, the Holon-Agent hybrid model used to make more feasible its implementation, among others. An oil production management case study is presented in order to demonstrate the applicability of the proposed architecture.",industry
