doi,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1109/TITS.2019.2962338,to_check,IEEE Transactions on Intelligent Transportation Systems,IEEE,2021-02-01 00:00:00,ieeexplore,A Survey of Deep Learning Applications to Autonomous Vehicle Control,https://ieeexplore.ieee.org/document/8951131/,"Designing a controller for autonomous vehicles capable of providing adequate performance in all driving scenarios is challenging due to the highly complex environment and inability to test the system in the wide variety of scenarios which it may encounter after deployment. However, deep learning methods have shown great promise in not only providing excellent performance for complex and non-linear control problems, but also in generalising previously learned rules to new scenarios. For these reasons, the use of deep learning for vehicle control is becoming increasingly popular. Although important advancements have been achieved in this field, these works have not been fully summarised. This paper surveys a wide range of research works reported in the literature which aim to control a vehicle through deep learning methods. Although there exists overlap between control and perception, the focus of this paper is on vehicle control, rather than the wider perception problem which includes tasks such as semantic segmentation and object detection. The paper identifies the strengths and limitations of available deep learning methods through comparative analysis and discusses the research challenges in terms of computation, architecture selection, goal specification, generalisation, verification and validation, as well as safety. Overall, this survey brings timely and topical information to a rapidly evolving field relevant to intelligent transportation systems.",autonomous vehicle
10.1109/GlobalSIP45357.2019.8969382,to_check,2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP),IEEE,2019-11-14 00:00:00,ieeexplore,Machine Learning-Based Roadside Vehicular Traffic Localization via Opportunistic Wireless Sensing,https://ieeexplore.ieee.org/document/8969382/,"Comprehensive Situational Awareness (SA) in mixed traffic environments (i.e., both autonomous and human-operated platforms) is a critical requirement in addressing some of the challenges that hinder the deployment of autonomous vehicle (AV) systems onto roadways. In this paper, a novel framework that leverages machine learning techniques for utilizing Signals of Opportunity (SoO) for robust localization of all vehicles operating along a stretch of roadway is presented. By making use of ubiquitous wireless emissions from vehicles, the presented approach performs vehicle localization without any active participation/assistance from vehicles thus making it a suitable candidate for SA in mixed traffic environments. Our simulation results show that given the road shape and number of vehicles present, observed 2D localization estimates generated by an arbitrary algorithm whose error is described by a Gaussian bivariate distribution with 10 meters covariance yields unbiased vehicle centroid estimates with less than one meter mean squared error by eight Kalman Filter (KF) iterations. A set of KFs for each vehicle are used to leverage the filtering of multiple estimates per vehicle per filter step to reduce measurement noise by averaging, while a clustering algorithm performs the dual role of forming KF set priors and classifying location estimates to their correct vehicle.",autonomous vehicle
10.1109/ITSC48978.2021.9564712,to_check,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),IEEE,2021-09-22 00:00:00,ieeexplore,OdoViz: A 3D Odometry Visualization and Processing Tool,https://ieeexplore.ieee.org/document/9564712/,"OdoViz is a reactive web-based tool for 3D visualization and processing of autonomous vehicle datasets designed to support common tasks in visual place recognition research. The system includes functionality for loading, inspecting, visualizing, and processing GPS/INS poses, point clouds and camera images. It supports a number of commonly used driving datasets and can be adapted to load custom datasets with minimal effort. OdoViz's design consists of a slim server to serve the datasets coupled with a rich client frontend. This design supports multiple deployment configurations including single user stand-alone installations, research group installations serving datasets internally across a lab, or publicly accessible web-frontends for providing online interfaces for exploring and interacting with datasets. The tool allows viewing complete vehicle trajectories traversed at multiple different time periods simultaneously, facilitating tasks such as sub-sampling, comparing and finding pose correspondences both across and within sequences. This significantly reduces the effort required in creating subsets of data from existing datasets for machine learning tasks. Further to the above, the system also supports adding custom extensions and plugins to extend the capabilities of the software for other potential data management, visualization and processing tasks. The platform has been open-sourced to promote its use and encourage further contributions from the research community.",autonomous vehicle
10.1109/IVS.1994.639471,to_check,Proceedings of the Intelligent Vehicles '94 Symposium,IEEE,1994-10-26 00:00:00,ieeexplore,The development of a fully autonomous ground vehicle (FAGV),https://ieeexplore.ieee.org/document/639471/,"As a first step toward the creation of a fully autonomous vehicle that operates in a real world environment, we are currently developing a prototype autonomous ground vehicle (AGV) for use in factories and other industrial/business sites based on behavior-based artificial intelligence (AI) control. This flexible and fully autonomous AGV (FAGV) is expected to operate efficiently in a normal industrial environment without any external guidance. The crucial technique employed is a non-Cartesian way of organizing software agents for the creation of a highly responsive control program. The resulting software is considerably reduced in size. Through numerous experiments using mobile robots we confirmed that these new control programs excel in functionality, efficiency, flexibility and robustness. The second key technique in the planning stage is evolutionary computation, of which genetic algorithms are a principal technique. An online, real-time evolution of the control program will be incorporated in later phases of the project to make FAGVs adaptable to any given operational environment after deployment. The first prototype FAGV has an active vision and behaviour-based control system.",autonomous vehicle
10.1109/ISOCC50952.2020.9333071,to_check,2020 International SoC Design Conference (ISOCC),IEEE,2020-10-24 00:00:00,ieeexplore,A Distance-Aware Technique for Object Detection Used in Self-Driving Vehicles,https://ieeexplore.ieee.org/document/9333071/,"Object detection obtains huge improvement after adopting deep learning technique. However, deep learning technique requires extremely high computation complexity and heavy DRAM (Dynamic Random Access Memory) bandwidth requirements, which blocks the deployment over various kinds of platforms. This paper provides a distance-aware technique for object detection that can adjust the required computation complexity and DRAM access amount according to several different searching distances. According to our analysis, the perception system can save up to 34.2% and 21.5% of computation complexity and DRAM access amount, respectively, for detecting near field objects when compared to the full range detection, without sacrificing any detection accuracy.",autonomous vehicle
10.1109/BigData.2018.8622371,to_check,2018 IEEE International Conference on Big Data (Big Data),IEEE,2018-12-13 00:00:00,ieeexplore,Robustness of Compressed Convolutional Neural Networks,https://ieeexplore.ieee.org/document/8622371/,"Advancements in deep neural networks have revolutionized the way how we conduct our day-to-day activities ranging from how we unlock our phones to self-driving cars. Convolutional Neural Networks (CNN) play the principal role in learning high level feature representations from visual inputs. It is crucial to know how reliable those neural networks are as human lives can be at stake. Recent experiments on the robustness of CNNs show that they are highly susceptible to small adversarial perturbations. Due to the increasing popularity of mobile devices, there is a significant demand for CNN models which are smaller enough to run on a mobile device without sacrificing the accuracy. Although recent researches have been successful at achieving smaller models with comparable accuracy on standard image datasets, their robustness to adversarial attacks has not been studied. However, massive deployment of smaller models on millions of mobile devices stresses importance of their robustness. In this work, we study how robust such models are with respect to state-of-the-art compression techniques such as quantization. Our contributions are summarized as follows: (1) insights to achieve smaller and robust models (2) a compression framework which is adversarial-aware. Our findings reveal that compressed models are naturally more robust than compact models. This provides an incentive to perform compression rather than designing compact models. Additionally, the latter provides benefits of increased accuracy and higher compression rate, up to 90Ã—.",autonomous vehicle
10.1109/CRV.2018.00024,to_check,2018 15th Conference on Computer and Robot Vision (CRV),IEEE,2018-05-10 00:00:00,ieeexplore,A Hierarchical Deep Architecture and Mini-batch Selection Method for Joint Traffic Sign and Light Detection,https://ieeexplore.ieee.org/document/8575742/,"Traffic light and sign detectors on autonomous cars are integral for road scene perception. The literature is abundant with deep learning networks that detect either lights or signs, not both, which makes them unsuitable for real-life deployment due to the limited graphics processing unit (GPU) memory and power available on embedded systems. The root cause of this issue is that no public dataset contains both traffic light and sign labels, which leads to difficulties in developing a joint detection framework. We present a deep hierarchical architecture in conjunction with a mini-batch proposal selection mechanism that allows a network to detect both traffic lights and signs from training on separate traffic light and sign datasets. Our method solves the overlapping issue where instances from one dataset are not labelled in the other dataset. We are the first to present a network that performs joint detection on traffic lights and signs. We measure our network on the Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small Traffic Lights benchmark for traffic light detection and show it outperforms the existing Bosch Small Traffic light state-of-the-art method. We focus on autonomous car deployment and show our network is more suitable than others because of its low memory footprint and real-time image processing time. Qualitative results can be viewed at https://youtu.be/ YmogPzBXOw.",autonomous vehicle
10.1109/AICAI.2019.8701414,to_check,2019 Amity International Conference on Artificial Intelligence (AICAI),IEEE,2019-02-06 00:00:00,ieeexplore,Modeling and Deployment of an Autonomous Cart Pickup and Delivery System,https://ieeexplore.ieee.org/document/8701414/,"Our research provides a novel hardware/software autonomous car model that can be effectively deployed to carry out intelligent pickup and delivery missions. We develop a model of a Cooperative Autonomous Reactive Taxi System (CARTS) that contributes to solving the unsustainable urban traffic gridlock in large cities. Our model formulation is inspired by general the pickup/delivery problem (GPDP). Given dynamic stochastic variables that include a set of cars, a set of customers, a set of stations (e.g., bus stop), and a set of transport missions, devise autonomous intelligent carts capable of effectively carrying out these missions to satisfy the quality of service requirements and any associated constraints. Our model integrates novel capabilities, such as decentralized architecture, cooperative decision-making, autonomy, and intelligent navigation, as well as a transport requests logistics model. Our deployment prototype is a laboratory experimental set-up using autonomous robots and relevant infrastructure that demonstrate the feasibility of our pickup and delivery model. Analysis of collected data from the simulation and the physical implementation demonstrates the effectiveness of our model.",autonomous vehicle
10.1109/EMPDP.2019.8671589,to_check,"2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)",IEEE,2019-02-15 00:00:00,ieeexplore,Catalina: In-Storage Processing Acceleration for Scalable Big Data Analytics,https://ieeexplore.ieee.org/document/8671589/,"Cloud applications are increasingly playing a crucial role in big data analytics. New use cases such as autonomous cars and edge computing call for novel approaches mixing heterogeneous computing and machine learning. These applications typically process petabyte-scale datasets, therefore, requiring low-power and scalable storage providing low-latency and high-throughput data access. While data centers have been focusing on migrating from legacy HDDs and SATA SSDs by deploying high-throughput and low-latency NVMe SSDs, the data bottlenecks appear as capacity scales. One approach to tackle this problem is to enable processing to happen within the storage device -in-storage processing (ISP)- eliminating the need to move the data. In this paper, we investigated the deployment of storage units with embedded low-power application processors along with FPGA-based reconfigurable hardware accelerators to address both performance and energy efficiency. To this purpose, we developed a high-capacity solid-state drive (SSD) named Catalina equipped with a quad-core ARM A53 processor running a Linux operating system along with a highly efficient FPGA accelerator for running applications in-place. We evaluated our proposed approach on a case study application for a similarity search library called Faiss.",autonomous vehicle
10.1109/ICCC49849.2020.9238795,to_check,2020 IEEE/CIC International Conference on Communications in China (ICCC),IEEE,2020-08-11 00:00:00,ieeexplore,3D Deployment with Machine Learning and System Performance Analysis of UAV-Enabled Networks,https://ieeexplore.ieee.org/document/9238795/,"Exploring the base station (BS) placement in both horizontal and vertical directions is beneficial but challenging for unmanned aerial vehicle (UAV)-enabled wireless network. In this paper, we propose a three dimensional (3D) deployment approach for UAVs and analyze the system performance of finite UAV-enabled networks in which UAVs are equipped with BS. By modeling UAVs as a deep reinforcement learning (DRL) agent, we propose a novel framework to deploy UAVs in 3D space to maximize the network utility. Then utilizing tools from stochastic geometry, we model the locations of UAVs as binomial point process (BPP) and derive exact expressions of coverage probability for directional antennas and omnidirectional antennas equipped UAVs. The expressions are functions of UAVs' altitudes and sector angles. The analysis is meaningful for setting UAVs' altitude and sector angle of directional antennas. Simulation results show that 3D deployment of UAVs achieves a remarkable system performance and the analysis provides useful performance trends.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9348040,to_check,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Distributional Reinforcement Learning for mmWave Communications with Intelligent Reflectors on a UAV,https://ieeexplore.ieee.org/document/9348040/,"In this paper, a novel communication framework that uses an unmanned aerial vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In order to maximize the downlink sum-rate, the optimal precoding matrix (at the base station) and reflection coefficient (at the IR) are jointly derived. Next, to address the uncertainty of mmWave channels and maintain line-of-sight links in a realtime manner, a distributional reinforcement learning approach, based on quantile regression optimization, is proposed to learn the propagation environment of mmWave communications, and, then, optimize the location of the UAV-IR so as to maximize the long-term downlink communication capacity. Simulation results show that the proposed learning-based deployment of the UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a static IR, and a direct transmission schemes, in terms of the average data rate and the achievable line-of-sight probability of downlink mmWave communications.",autonomous vehicle
10.1109/ISAECT50560.2020.9523700,to_check,2020 International Symposium on Advanced Electrical and Communication Technologies (ISAECT),IEEE,2020-11-27 00:00:00,ieeexplore,Edge-Cloud Architectures Using UAVs Dedicated To Industrial IoT Monitoring And Control Applications,https://ieeexplore.ieee.org/document/9523700/,"The deployment of new technologies to ease the control and management of a massive data volume and its uncertainty is a very significant challenge in the industry. Under the name ""Smart Factory"", the Industrial Internet of Things (IoT) aims to send data from systems that monitor and control the physical world to data processing systems for which cloud computing has proven to be an important tool to meet processing needs. unmanned aerial vehicles (UAVs) are now being introduced as part of IIoT and can perform important tasks. UAVs are now considered one of the best remote sensing techniques for collecting data over large areas. In the field of fog and edge computing, the IoT gateway connects various objects and sensors to the Internet. It function as a common interface for different networks and support different communication protocols. Edge intelligence is expected to replace Deep Learning (DL) computing in the cloud, providing a variety of distributed, low-latency and reliable intelligent services. In this paper, An unmanned aerial vehicle is automatically integrated into an industrial control system through an IoT gateway platform. Rather than sending photos from the UAV to the cloud for processing, an AI cloud trained model is deployed in the IoT gateway and used to process the taken photos. This model is designed to overcome the latency channels of the cloud computing architecture. The results show that the monitoring and tracking process using advanced computing in the IoT gateway is significantly faster than in the cloud.",autonomous vehicle
10.23919/APNOMS50412.2020.9236987,to_check,2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS),IEEE,2020-09-25 00:00:00,ieeexplore,Optimized Deployment of Multi-UAV based on Machine Learning in UAV-HST Networking,https://ieeexplore.ieee.org/document/9236987/,"A new communications infrastructure is needed for users to experience the contents of 5G-based VR/AR in High-Speed Train (HST). Therefore, it is proposed that the Unmanned Aerial Vehicle (UAV) can be used as a communication equipment on behalf of the general Rail-side Units (RSUs) supporting the communication of the HST. To maintain reliable communications, initial deployment and trajectory considered altitude and direction of UAV are determined. Also, limited energy in UAV is an important constraint on trajectory optimization. Thus, this paper proposes initial deployment and trajectory optimization techniques for stable communication between HST and Multi-UAV with the energy constraints of UAV. This paper uses Soft Actor-Critic (SAC), one of the methods of reinforcement learning, as a way to optimize the UAV trajectory. It also uses the Support Vector Machine to carry out optimal initial deployment based on data on the maximum UAV communication distance according to the speed of HST and the energy of UAV, which is the result of trajectory optimization. As a result, this study quickly and accurately derives the optimal trajectory of Multi-Uav according to the speed of HST and the energy of UAV and also maintain stable communication by optimal initial deployment.",autonomous vehicle
10.1109/GLOBECOM38437.2019.9013626,to_check,2019 IEEE Global Communications Conference (GLOBECOM),IEEE,2019-12-13 00:00:00,ieeexplore,Reflections in the Sky: Millimeter Wave Communication with UAV-Carried Intelligent Reflectors,https://ieeexplore.ieee.org/document/9013626/,"In this paper, a novel approach that uses an unmanned aerial vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance the performance of millimeter wave (mmW) networks. In particular, the UAV-IR is used to intelligently reflect mmW beamforming signals from a base station towards a mobile outdoor user, while harvesting energy from mmW signals to power the IR. To maintain a line-of-sight (LOS) channel, a reinforcement learning (RL) approach, based on Q- learning and neural networks, is proposed to model the propagation environment, such that the location and reflection coefficient of the UAV-IR can be optimized to maximize the downlink transmission capacity. Simulation results show a significant advantage for using a UAV-IR over a static IR, in terms of the average data rate and the achievable downlink LOS probability. The results also show that the RL-based deployment of the UAV-IR further improves the network performance, relative to a scheme without learning.",autonomous vehicle
10.1109/WCNC45663.2020.9120668,to_check,2020 IEEE Wireless Communications and Networking Conference (WCNC),IEEE,2020-05-28 00:00:00,ieeexplore,Trajectory Design and Generalization for UAV Enabled Networks:A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9120668/,"In this paper, an unmanned aerial vehicle (UAV) flies as a base station (BS) to provide wireless communication service. We propose two algorithms for designing the trajectory of the UAV and analyze the impact of different training approaches on transferring to new environments. When the UAV is used to track users that move along some specific paths, we propose a proximal policy optimization (PPO) -based algorithm to maximize the instantaneous sum rate (MSR-PPO). The UAV is modeled as a deep reinforcement learning (DRL) agent to learn how to move by interacting with the environment. When the UAV serves users along unknown paths for emergencies, we propose a random training proximal policy optimization (RT-PPO) algorithm which can transfer the pre-trained model to new tasks to achieve quick deployment. Unlike classical DRL algorithms that the agent is trained on the same task to learn its actions, RT-PPO randomizes the features of tasks to get the ability to transfer to new tasks. Numerical results reveal that MSR-PPO achieves a remarkable improvement and RT-PPO shows an effective generalization performance.",autonomous vehicle
10.1109/VTC2020-Spring48590.2020.9128613,to_check,2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring),IEEE,2020-05-28 00:00:00,ieeexplore,UAV-assisted Online Video Downloading in Vehicular Networks: A Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9128613/,"Online video becomes a significant service in daily life, and it usually adopts a caching and playing mechanism. Due to high mobility and changeable topology, challenges of video downloading still exist in vehicular networks, especially in areas where the roadside units (RSUs) are not fully covered. The flexible deployment of the unmanned aerial vehicle (UAVs) compensate for the lack of RSU coverage, and thus this paper considers that a cyclic flight UAV to assist RSUs in providing video download services for vehicles. With the help of UAV, seamless communication coverage and stable transmission links ensure better service quality for vehicles. In addition, we propose a model-free algorithm based on a deep Q network to find the optimal UAV decision policy to achieve the minimized stalling time. Finally, the simulation results are given to demonstrate that the proposed solution can effectively maintain a high-quality user experience.",autonomous vehicle
10.1109/DeSE.2016.34,to_check,2016 9th International Conference on Developments in eSystems Engineering (DeSE),IEEE,2016-09-02 00:00:00,ieeexplore,UAVs Deployment in Disaster Scenarios Based on Global and Local Search Optimization Algorithms,https://ieeexplore.ieee.org/document/7930647/,"The advancements in Unmanned Aerial Vehicle (UAV) related technologies and wireless communications pave the way for the deployment of wireless mesh networks in the air. These air mesh networks can be suitable for providing communication services in disaster scenarios to ground nodes such as victims and first responders. However, the optimal deployment of UAVs is not an easy as the number of possible scenarios to position the UAVs may reach a computationally challenging level. The combination of global and local search optimization algorithms can be considered as a powerful way for dealing with the massive number of possible solutions. We propose a deployment approach based on a global search algorithm such as the genetic algorithm and a local search algorithm namely the hill climbing algorithm. We show that the combination of both optimization techniques provides promising results for optimal positioning of UAVs in disaster scenarios based on simulation examples.",autonomous vehicle
10.1109/ACCESS.2019.2960314,to_check,IEEE Access,IEEE,2019-01-01 00:00:00,ieeexplore,Deployment Optimization of UAV Relays for Collecting Data From Sensors: A Potential Game Approach,https://ieeexplore.ieee.org/document/8935341/,"Due to the high maneuverability of unmanned aerial vehicle (UAV), a cluster of UAVs is considered used to collect sensing data from the sensors that distributed randomly in an area without the terrestrial infrastructure. The cluster members work as relays to forward the sensing data from sensors to the cluster head. For the reason that the relay deployment impacts the transmission rate and coverage area directly, we are going to optimize the deployment of the UAV relays, aiming to maximize the total capacity of the network. The problem of multi-relay deployment is intractable for two reasons. On one hand, because of the interactional and coupled relationship among the UAV relays, when the deployment of any given relay changes, the deployment optimization of other relays will be affected. On the other hand, on account of that the exact positions of the sensors are unknown, the deployment optimization of the UAV relays cannot be completed directly because of lacking parameters. In order to tackle the coupled relationship among the UAV relays, the problem of multi-relay deployment is modeled as a local interaction game. We prove that the multi-relay deployment game is an exact potential game that has at least one Nash equilibrium (NE) point. Then, the better reply-based relay deployment approach, which is an online learning approach that does not demand the information of the exact positions of sensors, is proposed to search the NE point. The simulation results show that the network capacity is significantly enhanced with the proposed relays deployment approach.",autonomous vehicle
10.1109/PIMRC48278.2020.9217205,to_check,"2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications",IEEE,2020-09-03 00:00:00,ieeexplore,A Fast Deployment Strategy for UAV Enabled Network Based on Deep Learning,https://ieeexplore.ieee.org/document/9217205/,"In this paper, a fast deployment strategy of unmanned aerial vehicles (UAVs) served as base stations (BSs) in an object region is investigated. To be specific, it solves a problem of how to find proper BSs position for multi-UAV as quickly as possible, and it also achieves the goal of maximizing the sum of downlink rates in a communication network. For this purpose, we design a geographical position information learning (GPI-Learning) algorithm to learn the GPI relationship between users and UAVs. This approach consumes less time by avoiding calculation of exact channels and fills a gap existed in the scenario of setting multi-UAV rapidly to serve multi-user. Without loss of generality, we apply GPI-Learning in different scenarios, such as changes in user number or area size. As for different area size, simulation reveals that a proper size is adequate to any smaller size on condition that the smaller size is included in training set. Numerical results witness the good performance of our proposed algorithm.",autonomous vehicle
10.1109/ATNAC.2018.8615400,to_check,2018 28th International Telecommunication Networks and Applications Conference (ITNAC),IEEE,2018-11-23 00:00:00,ieeexplore,A Reinforcement Learning Based User Association Algorithm for UAV Networks,https://ieeexplore.ieee.org/document/8615400/,"There have been increasing interests in employing unmanned aerial vehicles (UAVs) such as drones for telecommunication purpose. In such networks, UAVs act as base stations and provide downloading service to users. Compared with conventional terrestrial base stations, such UAV-BSs can dynamically adjust their locations to improve network performance. However, there exists two important issues in UAV networks, handoff overhead and UAV deployment. The handoff overhead issue is particularly important for UAVs because UAV BSs are connected to cellular BSs via wireless backhaul links, which are costly in terms of spectrum usage and energy consumption. Hence, it is highly desirable to eliminate any unnecessary handoff to minimise the waste of wireless backhaul. The UAV deployment, on the other hand, introduces a new tool for radio resource management, since BS positions are open for network optimisation. In this paper, a smart user association algorithm, named reinforcement learning handoff (RLH), is devised to reduce redundant handoffs in UAV networks and two methods of UAV mobility control are designed to co-operate with the proposed RLH algorithm to optimise the system throughput. In the RLH algorithm, users perform handoffs according to the reward of a reinforcement learning process. In UAV deployment two UAV mobility control methods are proposed respectively base on the SNR estimation and based on the K-Means approach. According to our simulation results, the RLH algorithm can reduce the number of handoffs by 75%.",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348512,to_check,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,Adaptive Deployment of UAV-Aided Networks Based on Hybrid Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9348512/,"Unmanned aerial vehicles (UAVs) can be used as air base stations to provide fast wireless connections for ground users. Due to their constraints on both mobility and energy consumption, a key problem is how to deploy UAVs adaptively in a geographic area with changing traffic demand of mobile users, while meeting the aforemetioned constraints. In this paper, we propose an adaptive deployment strategy for UAV-aided networks based on hybrid deep reinforcement learning, where a UAV can adjust its movement direction and distance to serve users who move randomly in the target area. Through hybrid deep reinforcement learning, UAVs can be trained offline to obtain the global state information and learn a completely distributed control strategy, with which each UAV only needs to take actions based on its observed state in the real deployment to be fully adaptive. Moreover, in order to improve the speed and effect of learning, we improve hybrid reinforcement learning, by adding genetic algorithms and TD-error-based resampling optimization mechanism. Simulation results show that the hybrid deep reinforcement learning algorithm has better efficiency and robustness in multi-UAV control, and has better performance in terms of coverage, energy consumption and average throughput, by which average throughput can be increased by 20% to 60%.",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348719,to_check,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,BLOCK-ML: Blockchain and Machine Learning for UAV-BSs Deployment,https://ieeexplore.ieee.org/document/9348719/,"Unmanned aerial vehicles (UAVs) are expected to be extensively used as an integral part in the future generations of communication networks, to provide ubiquitous connectivity. The mobile nature of UAVs make them a tempting candidate to provide seamless connectivity in environments where the installation of conventional terrestrial base stations (BS) is not feasible. Nonetheless, there are major deployment issues related to optimal placement of UAV-mounted base stations (UAV-BSs) due to limited number of UAV-BSs, limited energy availability and trade-off between coverage area and its altitude. In this paper, we address UAV-BSs placement issues by proposing a novel Machine learning (ML) based intelligent deployment mechanism. More specifically, for intelligent deployment of UAV-BSs based on energy, computational power, nature of available data and criticality of the scenario, we use two different approaches: Support Vector Machine (SVM) and Deep Learning (DL), which is composed of sequential time series learning process. Moreover, to address the security and privacy challenges emanating from the wireless connectivity and untrusted broadcast nature of UAV-BSs, we propose a Blockchain-based novel information-sharing scheme. To evaluate the performance of our combined secure and intelligent proposed approach, we have improved energy consumption by almost twice in contrast with the normal deployment of UAV-BSs.",autonomous vehicle
10.1109/AECT47998.2020.9194188,to_check,2019 International Conference on Advances in the Emerging Computing Technologies (AECT),IEEE,2020-02-10 00:00:00,ieeexplore,Clustering Based UAV Base Station Positioning for Enhanced Network Capacity,https://ieeexplore.ieee.org/document/9194188/,"Unmanned aerial vehicles (UAVs) are expected to be deployed in a variety of applications in future mobile networks due to several advantages they bring over the deployment of ground base stations. However, despite the recent interest in UAVs in mobile networks, some issues still remain, such as determining the placement of multiple UAVs in different scenarios. In this paper we propose a solution to determine the optimal 3D position of multiple UAVs in a capacity enhancement use-case, or in other words, when the ground network cannot cope with the user traffic demand. For this scenario, real data from the city of Milan, provided by Telecom Italia is utilized to simulate an event. Based on that, a solution based on k-means, a machine learning technique, to position multiple UAVs is proposed and it is compared with two other baseline methods. Results demonstrate that the proposed solution is able to significantly outperform other methods in terms of users covered and quality of service.",autonomous vehicle
10.1109/GLOCOMW.2018.8644345,to_check,2018 IEEE Globecom Workshops (GC Wkshps),IEEE,2018-12-13 00:00:00,ieeexplore,Deployment and Movement for Multiple Aerial Base Stations by Reinforcement Learning,https://ieeexplore.ieee.org/document/8644345/,"A novel framework for Quality of experience (QoE)-driven deployment and movement of multiple unmanned aerial vehicles (UAVs) is proposed. The problem of joint non-concave 3D deployment and dynamic movement for maximizing the sum mean opinion score (MOS) of users is formulated, which is proved to be NP-hard. In an effort to solve this problem, we proposed a three-step approach to obtain 3D deployment and dynamic movement of multiple UAVs. More specifically, in the first step, GAK-means algorithm is invoked to obtain the cell partitioning of ground users. Secondly, Q-learning based deployment algorithm is proposed, in which each UAV is considered as an agent, making its own decision to obtain 3D position. In contrast to conventional genetic algorithm based learning algorithms, the proposed algorithm is capable of training the policy of making decision offline. Thirdly, Q-learning algorithm is invoked when the ground users roam. Unlike the other trajectory obtaining algorithms, the proposed approach enables each UAV learn its movement gradually through trials and errors, and updates the direction selection strategy until it reaches convergence. Numerical results reveal that the proposed 3D deployment scheme outperforms K-means algorithm and IGK algorithm with low complexity. Additionally, with the aid of proposed approach, 3D real-time dynamic movement of UAVs is obtained.",autonomous vehicle
10.1109/AICAS48895.2020.9073885,to_check,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),IEEE,2020-09-02 00:00:00,ieeexplore,Efficient Embedded Deep Neural-Network-based Object Detection Via Joint Quantization and Tiling,https://ieeexplore.ieee.org/document/9073885/,"Embedded visual AI is a growing trend in applications requiring low latency, real-time decision support, increased robustness and security. Visual object detection, a key task in visual data analytics, has enjoyed significant improvements in terms of capabilities and accuracy due to the emergence of Convolutional Neural Networks (CNNs). However, such complex paradigms require heavy computational resources that prevent their deployment on resource-constrained devices, and in particular, impose significant constraints in possible hardware accelerators geared towards such applications. In this work therefore, we investigate how a combination of techniques can lead to efficient visual AI pipelines for resource-constrained object detection. In particular we leverage an efficient search strategy based on a combination of pre-processing mechanisms, that reduce the processing demands of deep network as a counter measure for potential accuracy reduction caused by quantization. The proposed approach enables the detection of objects in higher resolution frames using quantized models, while maintaining the accuracy of full-precision CNN-based object detectors. We illustrate the impact on the accuracy and average processing time using quantization techniques and different tiling approaches on efficient object detection architectures; as a case study, we focus on Unmanned-Aerial- Vehicles (UAVs). Through the proposed methodology, hardware accelerator demands are thereby reduced, leading to both performance benefits and associated power savings.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322292,to_check,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Energy-Efficient UAV Deployment and IoT Device Association in Fixed-Wing Multi-UAV Networks,https://ieeexplore.ieee.org/document/9322292/,"This work examines the deployment of multiple fixed-wing unmanned aerial vehicles (UAVs) for data-gathering from ground IoT devices, and the corresponding device association policy. Each UAV is assumed to hover above its associated devices following a circular trajectory. The device association and the UAVs' trajectory centers and radii are jointly optimized to maximize the energy-savings relative to a constant transmission power scheme. Given the trajectory centers and radii, the device association problem is modeled as a multiple 0-1 knapsack problem, taking into consideration the load demands of different devices as well as UAVs' service capacities. A two-stage maximum energy-saving device association policy is proposed, where each UAV first solves a single knapsack problem based on all connectable devices, and then resolves conflict with others by a maximum profit assignment. Moreover, given the device association, the UAVs' trajectory centers and radii are optimized by an iterative load-balancing algorithm, where the trajectory centers are chosen as a load-dependent weighted sum of the associated devices' locations. The device association and the UAV deployment are optimized in turn until convergence. Simulation results show that our proposed schemes outperform candidate algorithms in terms of the total energy-savings of IoT devices.",autonomous vehicle
10.1109/GLOBECOM38437.2019.9014310,to_check,2019 IEEE Global Communications Conference (GLOBECOM),IEEE,2019-12-13 00:00:00,ieeexplore,Gated Recurrent Units Learning for Optimal Deployment of Visible Light Communications Enabled UAVs,https://ieeexplore.ieee.org/document/9014310/,"In this paper, the problem of optimizing the deployment of unmanned aerial vehicles (UAVs) equipped with visible light communication (VLC) capabilities is studied. In the studied model, the UAVs can simultaneously provide communications and illumination to service ground users. Ambient illumination increases the interference over VLC links while reducing the illumination threshold of the UAVs. Therefore, it is necessary to consider the illumination distribution of the target area for UAV deployment optimization. This problem is formulated as an optimization problem whose goal is to minimize the total transmit power while meeting the illumination and communication requirements of users. To solve this problem, an algorithm based on the machine learning framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can model the longterm historical illumination distribution and predict the future illumination distribution. In order to reduce the complexity of the prediction algorithm while accurately predicting the illumination distribution, a Gaussian mixture model (GMM) is used to fit the illumination distribution of the target area at each time slot. Based on the predicted illumination distribution, the optimization problem is proved to be a convex optimization problem that can be solved by using duality. Simulations using real data from the Earth observations group (EOG) at NOAA/NCEI show that the proposed approach can achieve up to 22.1% reduction in transmit power compared to a conventional optimal UAV deployment that does not consider the illumination distribution. The results also show that UAVs must hover at areas having strong illumination, thus providing useful guidelines on the deployment of VLCenabled UAVs.",autonomous vehicle
10.1109/IROS40897.2019.8967722,to_check,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2019-11-08 00:00:00,ieeexplore,Informed Region Selection for Efficient UAV-based Object Detectors: Altitude-aware Vehicle Detection with CyCAR Dataset,https://ieeexplore.ieee.org/document/8967722/,"Deep Learning-based object detectors enhance the capabilities of remote sensing platforms, such as Unmanned Aerial Vehicles (UAVs), in a wide spectrum of machine vision applications. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such algorithms in scenarios that impose low-latency constraints during inference, in order to make mission-critical decisions in real-time. In this paper, we address the challenge of efficient deployment of region-based object detectors in aerial imagery, by introducing an informed methodology for extracting candidate detection regions (proposals). Our approach considers information from the UAV on-board sensors, such as flying altitude and light-weight computer vision filters, along with prior domain knowledge to intelligently decrease the number of region proposals by eliminating false-positives at an early stage of the computation, reducing significantly the computational workload while sustaining the detection accuracy. We apply and evaluate the proposed approach on the task of vehicle detection. Our experiments demonstrate that state-of-the-art detection models can achieve up to 2.6x faster inference by employing our altitude-aware data-driven methodology. Alongside, we introduce and provide to the community a novel vehicle-annotated and altitude-stamped dataset of real UAV imagery, captured at numerous flying heights under a wide span of traffic scenarios.",autonomous vehicle
10.1109/PIMRC48278.2020.9217381,to_check,"2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications",IEEE,2020-09-03 00:00:00,ieeexplore,Learning in the Sky: Towards Efficient 3D Placement of UAVs,https://ieeexplore.ieee.org/document/9217381/,"Deployment of unmanned aerial vehicles (UAVs) as aerial base stations to support cellular networks can deliver a fast and flexible solution for serving high and varying traffic demand. In order to adequately leverage the benefit of UAVs deployment, their efficient placement is of utmost importance, and requires to intelligently adapt to the environment changes. In this paper, we propose novel learning-based mechanisms for the three-dimensional deployment of UAVs assisting terrestrial networks in the downlink for overloaded situations. The problem is modeled as a game among UAVs. To solve the game, we utilize tools from reinforcement learning, and develop low complexity algorithms based on the multi-armed bandit and satisfaction methods to learn UAVs' locations. Simulation results reveal that the proposed satisfaction based UAV placement algorithm can yield significant performance gains up to about 50% and 41% in terms of throughput and the number of outage users, respectively, compared to a learning based benchmark algorithm.",autonomous vehicle
10.1109/ICCE.2018.8326145,to_check,2018 IEEE International Conference on Consumer Electronics (ICCE),IEEE,2018-01-14 00:00:00,ieeexplore,Optimized vision-directed deployment of UAVs for rapid traffic monitoring,https://ieeexplore.ieee.org/document/8326145/,"The flexibility and cost efficiency of traffic monitoring using Unmanned Aerial Vehicles (UAVs) has made such a proposition an attractive topic of research. To date, the main focus was placed on the types of sensors used to capture the data, and the alternative data processing options to achieve good monitoring performance. In this work we move a step further, and explore the deployment strategies that can be realized for rapid traffic monitoring over particular regions of the transportation network by considering a monitoring scheme that captures data from a visual sensor on-board the UAV, and subsequently analyzes it through a specific vision processing pipeline to extract network state information. These innovative deployment strategies can be used in real-time to assess traffic conditions, while for longer periods, to validate the underlying mobility models that characterise traffic patterns.",autonomous vehicle
10.1109/GCWkshps45667.2019.9024648,to_check,2019 IEEE Globecom Workshops (GC Wkshps),IEEE,2019-12-13 00:00:00,ieeexplore,Optimum Aerial Base Station Deployment for UAV Networks: A Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9024648/,"The boom of unmanned aerial vehicles (UAVs) is projected to fundamentally shift paradigms of transportations, logistics, agricultures, and public safety as a dominating unmanned application in following decades. To optimally process assigned tasks, each UAV requires prompt and ubiquitous information provisioning regarding the varying operation conditions, which renders exploiting base stations (BSs) of existing wireless infrastructures a tractable solution. To receive services from a BS, a UAV should stay within the coverage area of a BS, which however limits the operation range of a UAV. This obstacle thus drives the deployment of a special sort of UAV, known as an aerial base station (ABS), to relay signals between a BS and a UAV. Based on different flight paths of UAVs, an ABS should autonomously decide its own flight trajectory so as to maximize the number of UAVs which can receive wireless services. However, the inherently non-stationary environment renders the optimum autonomous deployment of an ABS a challenging issue. Inspired by the merit of interacting with the environment, we consequently propose a reinforcement learning scheme to optimize the flight trajectory of an ABS. To eliminate the engineering concern in the conventional Q-learning scheme that most state-action pairs may not be fully visited in the deployment of an ABS, in this paper, a state-amount-reduction (SAR) k-step Q-learning scheme is proposed to avoid the issue in the conventional Q-learning, so as to maximize the number of UAVs receiving services from an ABS. Through providing analytical foundations and simulation studies, outstanding performance of the proposed schemes is demonstrated as compared with that of the conventional reinforcement learning based ABS deployment.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322234,to_check,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,UAV Path Planning for Wireless Data Harvesting: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9322234/,"Autonomous deployment of unmanned aerial vehicles (UAVs) supporting next-generation communication networks requires efficient trajectory planning methods. We propose a new end-to-end reinforcement learning (RL) approach to UAV-enabled data collection from Internet of Things (IoT) devices in an urban environment. An autonomous drone is tasked with gathering data from distributed sensor nodes subject to limited flying time and obstacle avoidance. While previous approaches, learning and non-learning based, must perform expensive recomputations or relearn a behavior when important scenario parameters such as the number of sensors, sensor positions, or maximum flying time, change, we train a double deep Q-network (DDQN) with combined experience replay to learn a UAV control policy that generalizes over changing scenario parameters. By exploiting a multi-layer map of the environment fed through convolutional network layers to the agent, we show that our proposed network architecture enables the agent to make movement decisions for a variety of scenario parameters that balance the data collection goal with flight time efficiency and safety constraints. Considerable advantages in learning efficiency from using a map centered on the UAV's position over a non-centered map are also illustrated.",autonomous vehicle
10.1109/ACCESS.2019.2947546,to_check,IEEE Access,IEEE,2019-01-01 00:00:00,ieeexplore,A Two-Step Environment-Learning-Based Method for Optimal UAV Deployment,https://ieeexplore.ieee.org/document/8869876/,"Unmanned aerial vehicles (UAVs) can be used as low-altitude flight base stations to satisfy the coverage requirements of wireless users in various scenarios. In practical applications, since the transmitted power and energy resources of the UAVs are limited and the propagation environments are complicated and time-variant, it is challenging to control a group of UAVs to ensure coverage performance while preserving the connectivity and safety of the UAV networks. To this end, a two-step environment-learning-based method is proposed for the intelligent deployment of the UAVs. First, a machine learning algorithm is used to establish an accurate prediction model of the link qualities from the UAVs to the users under a specific scenario for the next step. Then, a modified deep deterministic policy gradient (DDPG) algorithm is employed to control the movements of the UAVs according to the predicted link qualities and to maximize the proportion of covered users. The prioritized experience replay mechanism is introduced to the standard DDPG algorithm to accelerate the deployment procedure. The coverage performance is analyzed in both the interference-free situation and the situation with co-channel interference. Simulation results have shown that the proposed method has a higher convergence speed than the standard DDPG method. Additionally, the proposed deployment method can achieve higher coverage performance and better adaptability to the dynamic environment than three commonly used methods, the random method, the K-means-based method, and the statistical-channel-model-based method.",autonomous vehicle
10.1109/TWC.2020.3007804,to_check,IEEE Transactions on Wireless Communications,IEEE,2020-11-01 00:00:00,ieeexplore,Deep Learning for Optimal Deployment of UAVs With Visible Light Communications,https://ieeexplore.ieee.org/document/9140367/,"In this paper, the problem of dynamical deployment of unmanned aerial vehicles (UAVs) equipped with visible light communication (VLC) capabilities for optimizing the energy efficiency of UAV-enabled networks is studied. In the studied model, the UAVs can simultaneously provide communications and illumination to service ground users. Since ambient illumination increases the interference over VLC links while reducing the illumination threshold of the UAVs, it is necessary to consider the illumination distribution of the target area for UAV deployment optimization. This problem is formulated as an optimization problem which jointly optimizes UAV deployment, user association, and power efficiency while meeting the illumination and communication requirements of users. To solve this problem, an algorithm that combines the machine learning framework of gated recurrent units (GRUs) with convolutional neural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the long-term historical illumination distribution and predict the future illumination distribution. Given the prediction of illumination distribution, the original nonconvex optimization problem can be divided into two sub-problems and is then solved using a low-complexity, iterative algorithm. Then, the proposed algorithm enables UAVs to determine the their deployment and user association to minimize the total transmit power. Simulation results using real data from the Earth observations group (EOG) at NOAA/NCEI show that the proposed approach can achieve up to 68.9% reduction in total transmit power compared to a conventional optimal UAV deployment that does not consider the illumination distribution and user association.",autonomous vehicle
10.1109/TVT.2019.2947078,to_check,IEEE Transactions on Vehicular Technology,IEEE,2019-12-01 00:00:00,ieeexplore,Deployment Optimization of UAV Relay for Malfunctioning Base Station: Model-Free Approaches,https://ieeexplore.ieee.org/document/8867956/,"Due to the advantages of high mobility, high maneuverability and high probability of line of sight (LoS) transmission, unmanned aerial vehicles (UAVs) have attracted much interest in assisting wireless communication systems. This paper considers a set of ground users cannot receive service from the base station because of a sudden base station malfunction, a UAV is deployed in the air to work as a relay to establish communication links between uncovered users and the neighboring base station. We are going to optimize the UAV relay deployment, aiming to maximize the capacity of the relay network. Considering the channel model and exact positions of ground users are priori unknown, the problem of deployment optimization can't be solved directly because of lacking parameters. Thus, considering multiple detecting UAVs are available and only one is available, model-free online deployment approaches are respectively proposed to solve this challenging problem. The optimal relay deployment is acquired via online learning and iteration without the knowledge of channel model and exact positions of the users but with the real-time measurement of relay capacity, thus the proposed model-free deployment approaches can be adaptive to the practical communication environment compared to the model-based optimization. Simulation results show that with the proposed model-free deployment approaches, relay network capacities are close to the optimum.",autonomous vehicle
10.1109/JSTARS.2020.2969809,to_check,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,IEEE,2020-01-01 00:00:00,ieeexplore,EmergencyNet: Efficient Aerial Image Classification for Drone-Based Emergency Monitoring Using Atrous Convolutional Feature Fusion,https://ieeexplore.ieee.org/document/9050881/,"Deep learning-based algorithms can provide state-of-the-art accuracy for remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones, potentially enhancing their remote sensing capabilities for many emergency response and disaster management applications. In particular, UAVs equipped with camera sensors can operating in remote and difficult to access disaster-stricken areas, analyze the image and alert in the presence of various calamities such as collapsed buildings, flood, or fire in order to faster mitigate their effects on the environment and on human population. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such deep neural networks in many scenarios that impose low-latency constraints on inference, in order to make mission-critical decisions in real time. To this end, this article focuses on the efficient aerial image classification from on-board a UAV for emergency response/monitoring applications. Specifically, a dedicated Aerial Image Database for Emergency Response applications is introduced and a comparative analysis of existing approaches is performed. Through this analysis a lightweight convolutional neural network architecture is proposed, referred to as EmergencyNet, based on atrous convolutions to process multiresolution features and capable of running efficiently on low-power embedded platforms achieving upto 20Ã— higher performance compared to existing models with minimal memory requirements with less than 1% accuracy drop compared to state-of-the-art models.",autonomous vehicle
10.1109/TVT.2019.2922849,to_check,IEEE Transactions on Vehicular Technology,IEEE,2019-08-01 00:00:00,ieeexplore,Reinforcement Learning in Multiple-UAV Networks: Deployment and Movement Design,https://ieeexplore.ieee.org/document/8736350/,"A novel framework is proposed for quality of experience driven deployment and dynamic movement of multiple unmanned aerial vehicles (UAVs). The problem of joint non-convex three-dimensional (3-D) deployment and dynamic movement of the UAVs is formulated for maximizing the sum mean opinion score of ground users, which is proved to be NP-hard. In the aim of solving this pertinent problem, a three-step approach is proposed for attaining 3-D deployment and dynamic movement of multiple UAVs. First, a genetic algorithm based K-means (GAK-means) algorithm is utilized for obtaining the cell partition of the users. Second, Q-learning based deployment algorithm is proposed, in which each UAV acts as an agent, making their own decision for attaining 3-D position by learning from trial and mistake. In contrast to the conventional genetic algorithm based learning algorithms, the proposed algorithm is capable of training the direction selection strategy offline. Third, Q-learning based movement algorithm is proposed in the scenario that the users are roaming. The proposed algorithm is capable of converging to an optimal state. Numerical results reveal that the proposed algorithms show a fast convergence rate after a small number of iterations. Additionally, the proposed Q-learning based deployment algorithm outperforms K-means algorithms and Iterative-GAKmean algorithms with low complexity.",autonomous vehicle
10.1007/s11276-021-02789-7,to_check,Wireless Networks,Springer,2021-10-12 00:00:00,springer,Energy-efficient UAV-enabled computation offloading for industrial internet of things: a deep reinforcement learning approach,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11276-021-02789-7,"Industrial Internet of Things (IIoT) has been envisioned as a killer application of 5G and beyond. However, due to the shortness of computation ablility and batery capacity, it is challenging for IIoT devices to process latency-sensitive and resource-sensitive tasks. Moblie Edge Computing (MEC), as a promising paradigm for handling tasks with high quality of service (QoS) requirement and for energy-constrained IIoT devices, allows IIoT devices to offload their tasks to MEC servers, which can significantly reduce the task process delay and energy consumptions. However, the deployment of the MEC servers rely heavily on communication infrastructure, which greatly reduce the flexibility. Toward this end, in this paper, we consider multiple Unmanned Aerial Vehicles (UAV) eqqipped with transceivers as aerial MEC servers to provide IIoT devices computation offloading opportunities due to their high controbility. IIoT devices can choose to offload the tasks to UAVs through air-ground links, or to offload the tasks to the remote cloud center through ground cellular network, or to process the tasks locally. We formulate the multi-UAV-Enabled computation offloading problem as a mixed integer non-linear programming (MINLP) problem and prove its NP-hardness. To obtain the energy-efficient and low complexity solution, we propose an intelligent computation offloading algorithm called multi-agent deep Q-learning with stochastic prioritized replay (MDSPR). Numerical results show that the proposed MDSPR converges fast and outperforms the benchmark algorithms, including random method, deep Q-learning method and double deep Q-learning method in terms of energy efficiency and task successful rate.",autonomous vehicle
http://arxiv.org/abs/2009.11722v1,to_check,arxiv,arxiv,2020-09-23 09:23:29+00:00,arxiv,"Cloud2Edge Elastic AI Framework for Prototyping and Deployment of AI
  Inference Engines in Autonomous Vehicles",http://arxiv.org/abs/2009.11722v1,"Self-driving cars and autonomous vehicles are revolutionizing the automotive
sector, shaping the future of mobility altogether. Although the integration of
novel technologies such as Artificial Intelligence (AI) and Cloud/Edge
computing provides golden opportunities to improve autonomous driving
applications, there is the need to modernize accordingly the whole prototyping
and deployment cycle of AI components. This paper proposes a novel framework
for developing so-called AI Inference Engines for autonomous driving
applications based on deep learning modules, where training tasks are deployed
elastically over both Cloud and Edge resources, with the purpose of reducing
the required network bandwidth, as well as mitigating privacy issues. Based on
our proposed data driven V-Model, we introduce a simple yet elegant solution
for the AI components development cycle, where prototyping takes place in the
cloud according to the Software-in-the-Loop (SiL) paradigm, while deployment
and evaluation on the target ECUs (Electronic Control Units) is performed as
Hardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework
is demonstrated using two real-world use-cases of AI inference engines for
autonomous vehicles, that is environment perception and most probable path
prediction.",autonomous vehicle
http://arxiv.org/abs/2011.07699v1,to_check,arxiv,arxiv,2020-11-16 02:56:13+00:00,arxiv,"Efficient falsification approach for autonomous vehicle validation using
  a parameter optimisation technique based on reinforcement learning",http://arxiv.org/abs/2011.07699v1,"The widescale deployment of Autonomous Vehicles (AV) appears to be imminent
despite many safety challenges that are yet to be resolved. It is well-known
that there are no universally agreed Verification and Validation (VV)
methodologies guarantee absolute safety, which is crucial for the acceptance of
this technology. The uncertainties in the behaviour of the traffic participants
and the dynamic world cause stochastic reactions in advanced autonomous
systems. The addition of ML algorithms and probabilistic techniques adds
significant complexity to the process for real-world testing when compared to
traditional methods. Most research in this area focuses on generating
challenging concrete scenarios or test cases to evaluate the system performance
by looking at the frequency distribution of extracted parameters as collected
from the real-world data. These approaches generally employ Monte-Carlo
simulation and importance sampling to generate critical cases. This paper
presents an efficient falsification method to evaluate the System Under Test.
The approach is based on a parameter optimisation problem to search for
challenging scenarios. The optimisation process aims at finding the challenging
case that has maximum return. The method applies policy-gradient reinforcement
learning algorithm to enable the learning. The riskiness of the scenario is
measured by the well established RSS safety metric, euclidean distance, and
instance of a collision. We demonstrate that by using the proposed method, we
can more efficiently search for challenging scenarios which could cause the
system to fail in order to satisfy the safety requirements.",autonomous vehicle
http://arxiv.org/abs/1912.10773v1,to_check,arxiv,arxiv,2019-12-23 12:50:32+00:00,arxiv,A Survey of Deep Learning Applications to Autonomous Vehicle Control,http://arxiv.org/abs/1912.10773v1,"Designing a controller for autonomous vehicles capable of providing adequate
performance in all driving scenarios is challenging due to the highly complex
environment and inability to test the system in the wide variety of scenarios
which it may encounter after deployment. However, deep learning methods have
shown great promise in not only providing excellent performance for complex and
non-linear control problems, but also in generalising previously learned rules
to new scenarios. For these reasons, the use of deep learning for vehicle
control is becoming increasingly popular. Although important advancements have
been achieved in this field, these works have not been fully summarised. This
paper surveys a wide range of research works reported in the literature which
aim to control a vehicle through deep learning methods. Although there exists
overlap between control and perception, the focus of this paper is on vehicle
control, rather than the wider perception problem which includes tasks such as
semantic segmentation and object detection. The paper identifies the strengths
and limitations of available deep learning methods through comparative analysis
and discusses the research challenges in terms of computation, architecture
selection, goal specification, generalisation, verification and validation, as
well as safety. Overall, this survey brings timely and topical information to a
rapidly evolving field relevant to intelligent transportation systems.",autonomous vehicle
http://arxiv.org/abs/1908.03271v2,to_check,arxiv,arxiv,2019-08-08 21:44:26+00:00,arxiv,"Reflections in the Sky: Millimeter Wave Communication with UAV-Carried
  Intelligent Reflectors",http://arxiv.org/abs/1908.03271v2,"In this paper, a novel approach that uses an unmanned aerial vehicle
(UAV)-carried intelligent reflector (IR) is proposed to enhance the performance
of millimeter wave (mmW) networks. In particular, the UAV-IR is used to
intelligently reflect mmW beamforming signals from a base station towards a
mobile outdoor user, while harvesting energy from mmW signals to power the IR.
To maintain a line-of-sight (LOS) channel, a reinforcement learning (RL)
approach, based on Q-learning and neural networks, is proposed to model the
propagation environment, such that the location and reflection coefficient of
the UAV-IR can be optimized to maximize the downlink transmission capacity.
Simulation results show a significant advantage for using a UAV-IR over a
static IR, in terms of the average data rate and the achievable downlink LOS
probability. The results also show that the RL-based deployment of the UAV-IR
further improves the network performance, relative to a scheme without
learning.",autonomous vehicle
http://arxiv.org/abs/2110.06775v1,to_check,arxiv,arxiv,2021-10-11 19:38:24+00:00,arxiv,"Using UAVs for vehicle tracking and collision risk assessment at
  intersections",http://arxiv.org/abs/2110.06775v1,"Assessing collision risk is a critical challenge to effective traffic safety
management. The deployment of unmanned aerial vehicles (UAVs) to address this
issue has shown much promise, given their wide visual field and movement
flexibility. This research demonstrates the application of UAVs and V2X
connectivity to track the movement of road users and assess potential
collisions at intersections. The study uses videos captured by UAVs. The
proposed method combines deep-learning based tracking algorithms and
time-to-collision tasks. The results not only provide beneficial information
for vehicle's recognition of potential crashes and motion planning but also
provided a valuable tool for urban road agencies and safety management
engineers.",autonomous vehicle
http://arxiv.org/abs/2104.14006v1,to_check,arxiv,arxiv,2021-04-28 20:24:10+00:00,arxiv,"EmergencyNet: Efficient Aerial Image Classification for Drone-Based
  Emergency Monitoring Using Atrous Convolutional Feature Fusion",http://arxiv.org/abs/2104.14006v1,"Deep learning-based algorithms can provide state-of-the-art accuracy for
remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones,
potentially enhancing their remote sensing capabilities for many emergency
response and disaster management applications. In particular, UAVs equipped
with camera sensors can operating in remote and difficult to access
disaster-stricken areas, analyze the image and alert in the presence of various
calamities such as collapsed buildings, flood, or fire in order to faster
mitigate their effects on the environment and on human population. However, the
integration of deep learning introduces heavy computational requirements,
preventing the deployment of such deep neural networks in many scenarios that
impose low-latency constraints on inference, in order to make mission-critical
decisions in real time. To this end, this article focuses on the efficient
aerial image classification from on-board a UAV for emergency
response/monitoring applications. Specifically, a dedicated Aerial Image
Database for Emergency Response applications is introduced and a comparative
analysis of existing approaches is performed. Through this analysis a
lightweight convolutional neural network architecture is proposed, referred to
as EmergencyNet, based on atrous convolutions to process multiresolution
features and capable of running efficiently on low-power embedded platforms
achieving upto 20x higher performance compared to existing models with minimal
memory requirements with less than 1% accuracy drop compared to
state-of-the-art models.",autonomous vehicle
http://arxiv.org/abs/2108.10748v1,to_check,arxiv,arxiv,2021-08-23 16:10:14+00:00,arxiv,"Federated Learning for UAV Swarms Under Class Imbalance and Power
  Consumption Constraints",http://arxiv.org/abs/2108.10748v1,"The usage of unmanned aerial vehicles (UAVs) in civil and military
applications continues to increase due to the numerous advantages that they
provide over conventional approaches. Despite the abundance of such advantages,
it is imperative to investigate the performance of UAV utilization while
considering their design limitations. This paper investigates the deployment of
UAV swarms when each UAV carries a machine learning classification task. To
avoid data exchange with ground-based processing nodes, a federated learning
approach is adopted between a UAV leader and the swarm members to improve the
local learning model while avoiding excessive air-to-ground and ground-to-air
communications. Moreover, the proposed deployment framework considers the
stringent energy constraints of UAVs and the problem of class imbalance, where
we show that considering these design parameters significantly improves the
performances of the UAV swarm in terms of classification accuracy, energy
consumption and availability of UAVs when compared with several baseline
algorithms.",autonomous vehicle
http://arxiv.org/abs/2012.10706v4,to_check,arxiv,arxiv,2020-12-19 14:53:56+00:00,arxiv,Siamese Anchor Proposal Network for High-Speed Aerial Tracking,http://arxiv.org/abs/2012.10706v4,"In the domain of visual tracking, most deep learning-based trackers highlight
the accuracy but casting aside efficiency. Therefore, their real-world
deployment on mobile platforms like the unmanned aerial vehicle (UAV) is
impeded. In this work, a novel two-stage Siamese network-based method is
proposed for aerial tracking, \textit{i.e.}, stage-1 for high-quality anchor
proposal generation, stage-2 for refining the anchor proposal. Different from
anchor-based methods with numerous pre-defined fixed-sized anchors, our
no-prior method can 1) increase the robustness and generalization to different
objects with various sizes, especially to small, occluded, and fast-moving
objects, under complex scenarios in light of the adaptive anchor generation, 2)
make calculation feasible due to the substantial decrease of anchor numbers. In
addition, compared to anchor-free methods, our framework has better performance
owing to refinement at stage-2. Comprehensive experiments on three benchmarks
have proven the superior performance of our approach, with a speed of around
200 frames/s.",autonomous vehicle
http://arxiv.org/abs/2107.13869v2,to_check,arxiv,arxiv,2021-07-29 10:11:36+00:00,arxiv,"Autonomous UAV Base Stations for Next Generation Wireless Networks: A
  Deep Learning Approach",http://arxiv.org/abs/2107.13869v2,"To address the ever-growing connectivity demands of wireless communications,
the adoption of ingenious solutions, such as Unmanned Aerial Vehicles (UAVs) as
mobile Base Stations (BSs), is imperative. In general, the location of a UAV
Base Station (UAV-BS) is determined by optimization algorithms, which have high
computationally complexities and place heavy demands on UAV resources. In this
paper, we show that a Convolutional Neural Network (CNN) model can be trained
to infer the location of a UAV-BS in real time. In so doing, we create a
framework to determine the UAV locations that considers the deployment of
Mobile Users (MUs) to generate labels by using the data obtained from an
optimization algorithm. Performance evaluations reveal that once the CNN model
is trained with the given labels and locations of MUs, the proposed approach is
capable of approximating the results given by the adopted optimization
algorithm with high fidelity, outperforming Reinforcement Learning (RL)-based
approaches. We also explore future research challenges and highlight key
issues.",autonomous vehicle
http://arxiv.org/abs/1912.00752v3,to_check,arxiv,arxiv,2019-11-28 03:03:24+00:00,arxiv,"Deep Learning for Optimal Deployment of UAVs with Visible Light
  Communications",http://arxiv.org/abs/1912.00752v3,"In this paper, the problem of dynamical deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities
for optimizing the energy efficiency of UAV-enabled networks is studied. In the
studied model, the UAVs can simultaneously provide communications and
illumination to service ground users. Since ambient illumination increases the
interference over VLC links while reducing the illumination threshold of the
UAVs, it is necessary to consider the illumination distribution of the target
area for UAV deployment optimization. This problem is formulated as an
optimization problem which jointly optimizes UAV deployment, user association,
and power efficiency while meeting the illumination and communication
requirements of users. To solve this problem, an algorithm that combines the
machine learning framework of gated recurrent units (GRUs) with convolutional
neural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the
long-term historical illumination distribution and predict the future
illumination distribution. Given the prediction of illumination distribution,
the original nonconvex optimization problem can be divided into two
sub-problems and is then solved using a low-complexity, iterative algorithm.
Then, the proposed algorithm enables UAVs to determine the their deployment and
user association to minimize the total transmit power. Simulation results using
real data from the Earth observations group (EOG) at NOAA/NCEI show that the
proposed approach can achieve up to 68.9% reduction in total transmit power
compared to a conventional optimal UAV deployment that does not consider the
illumination distribution and user association.",autonomous vehicle
http://arxiv.org/abs/1907.12650v2,to_check,arxiv,arxiv,2019-07-30 15:41:01+00:00,arxiv,"Beyond Safety Drivers: Staffing a Teleoperations System for Autonomous
  Vehicles",http://arxiv.org/abs/1907.12650v2,"Driverless vehicles promise a host of societal benefits including
dramatically improved safety, increased accessibility, greater productivity,
and higher quality of life. As this new technology approaches widespread
deployment, both industry and government are making provisions for
teleoperations systems, in which remote human agents provide assistance to
driverless vehicles. This assistance can involve real-time remote operation and
even ahead-of-time input via human-in-the-loop artificial intelligence systems.
In this paper, we address the problem of staffing such a remote support center.
Our analysis focuses on the tradeoffs between the total number of remote
agents, the reliability of the remote support system, and the resulting safety
of the driverless vehicles. By establishing a novel connection between queues
with large batch arrivals and storage processes, we determine the probability
of the system exceeding its service capacity. This connection drives our
staffing methodology. We also develop a numerical method to compute the exact
staffing level needed to achieve various performance measures. This moment
generating function based technique may be of independent interest, and our
overall staffing analysis may be of use in other applications that combine
human expertise and automated systems.",autonomous vehicle
http://arxiv.org/abs/2007.00544v2,to_check,arxiv,arxiv,2020-07-01 15:14:16+00:00,arxiv,"UAV Path Planning for Wireless Data Harvesting: A Deep Reinforcement
  Learning Approach",http://arxiv.org/abs/2007.00544v2,"Autonomous deployment of unmanned aerial vehicles (UAVs) supporting
next-generation communication networks requires efficient trajectory planning
methods. We propose a new end-to-end reinforcement learning (RL) approach to
UAV-enabled data collection from Internet of Things (IoT) devices in an urban
environment. An autonomous drone is tasked with gathering data from distributed
sensor nodes subject to limited flying time and obstacle avoidance. While
previous approaches, learning and non-learning based, must perform expensive
recomputations or relearn a behavior when important scenario parameters such as
the number of sensors, sensor positions, or maximum flying time, change, we
train a double deep Q-network (DDQN) with combined experience replay to learn a
UAV control policy that generalizes over changing scenario parameters. By
exploiting a multi-layer map of the environment fed through convolutional
network layers to the agent, we show that our proposed network architecture
enables the agent to make movement decisions for a variety of scenario
parameters that balance the data collection goal with flight time efficiency
and safety constraints. Considerable advantages in learning efficiency from
using a map centered on the UAV's position over a non-centered map are also
illustrated.",autonomous vehicle
http://arxiv.org/abs/2011.01840v1,to_check,arxiv,arxiv,2020-11-03 16:50:37+00:00,arxiv,"Distributional Reinforcement Learning for mmWave Communications with
  Intelligent Reflectors on a UAV",http://arxiv.org/abs/2011.01840v1,"In this paper, a novel communication framework that uses an unmanned aerial
vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance
multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In
order to maximize the downlink sum-rate, the optimal precoding matrix (at the
base station) and reflection coefficient (at the IR) are jointly derived. Next,
to address the uncertainty of mmWave channels and maintain line-of-sight links
in a real-time manner, a distributional reinforcement learning approach, based
on quantile regression optimization, is proposed to learn the propagation
environment of mmWave communications, and, then, optimize the location of the
UAV-IR so as to maximize the long-term downlink communication capacity.
Simulation results show that the proposed learning-based deployment of the
UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a
static IR, and a direct transmission schemes, in terms of the average data rate
and the achievable line-of-sight probability of downlink mmWave communications.",autonomous vehicle
http://arxiv.org/abs/1810.09729v1,to_check,arxiv,arxiv,2018-10-23 08:51:54+00:00,arxiv,"Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A
  Comprehensive Survey, and Future Directions",http://arxiv.org/abs/1810.09729v1,"Unmanned Aerial Vehicles (UAVs) have recently rapidly grown to facilitate a
wide range of innovative applications that can fundamentally change the way
cyber-physical systems (CPSs) are designed. CPSs are a modern generation of
systems with synergic cooperation between computational and physical potentials
that can interact with humans through several new mechanisms. The main
advantages of using UAVs in CPS application is their exceptional features,
including their mobility, dynamism, effortless deployment, adaptive altitude,
agility, adjustability, and effective appraisal of real-world functions anytime
and anywhere. Furthermore, from the technology perspective, UAVs are predicted
to be a vital element of the development of advanced CPSs. Therefore, in this
survey, we aim to pinpoint the most fundamental and important design challenges
of multi-UAV systems for CPS applications. We highlight key and versatile
aspects that span the coverage and tracking of targets and infrastructure
objects, energy-efficient navigation, and image analysis using machine learning
for fine-grained CPS applications. Key prototypes and testbeds are also
investigated to show how these practical technologies can facilitate CPS
applications. We present and propose state-of-the-art algorithms to address
design challenges with both quantitative and qualitative methods and map these
challenges with important CPS applications to draw insightful conclusions on
the challenges of each application. Finally, we summarize potential new
directions and ideas that could shape future research in these areas.",autonomous vehicle
http://arxiv.org/abs/1910.13538v1,to_check,arxiv,arxiv,2019-10-29 21:16:50+00:00,arxiv,"Machine-Learning Beam Tracking and Weight Optimization for mmWave
  Multi-UAV Links",http://arxiv.org/abs/1910.13538v1,"Millimeter-wave (mmWave) hybrid analog-digital beamforming is a promising
approach to satisfy the low-latency constraint in multiple unmanned aerial
vehicles (UAVs) systems, which serve as network infrastructure for flexible
deployment. However, in highly dynamic multi-UAV environments, analog beam
tracking becomes a critical challenge. The overhead of additional pilot
transmission at the price of spectral efficiency is shown necessary to achieve
high resilience in operation. An efficient method to deal with high dynamics of
UAVs applies machine learning, particularly Q-learning, to analog beam
tracking. The proposed Q-learning-based beam tracking scheme uses current/past
observations to design rewards from environments to facilitate prediction,
which significantly increases the efficiency of data transmission and beam
switching. Given the selected analog beams, the goal of digital beamforming is
to maximize the SINR. The received pilot signals are utilized to approximate
the desired signal and interference power, which yield the SINR measurements as
well as the optimal digital weights. Since the selected analog beams based on
the received power do not guarantee the hybrid beamforming achieving the
maximization SINR, we therefore reserve additional analog beams as candidates
during the beam tracking. The combination of analog beams with their digital
weights achieving the maximum SINR consequently provides the optimal solution
to the hybrid beamforming.",autonomous vehicle
http://arxiv.org/abs/2106.07314v1,to_check,arxiv,arxiv,2021-06-14 11:38:13+00:00,arxiv,"Computer Vision Tool for Detection, Mapping and Fault Classification of
  PV Modules in Aerial IR Videos",http://arxiv.org/abs/2106.07314v1,"Increasing deployment of photovoltaics (PV) plants demands for cheap and fast
inspection. A viable tool for this task is thermographic imaging by unmanned
aerial vehicles (UAV). In this work, we develop a computer vision tool for the
semi-automatic extraction of PV modules from thermographic UAV videos. We use
it to curate a dataset containing 4.3 million IR images of 107842 PV modules
from thermographic videos of seven different PV plants. To demonstrate its use
for automated PV plant inspection, we train a ResNet-50 to classify ten common
module anomalies with more than 90 % test accuracy. Experiments show that our
tool generalizes well to different PV plants. It successfully extracts PV
modules from 512 out of 561 plant rows. Failures are mostly due to an
inappropriate UAV trajectory and erroneous module segmentation. Including all
manual steps our tool enables inspection of 3.5 MW p to 9 MW p of PV
installations per day, potentially scaling to multi-gigawatt plants due to its
parallel nature. While we present an effective method for automated PV plant
inspection, we are also confident that our approach helps to meet the growing
demand for large thermographic datasets for machine learning tasks, such as
power prediction or unsupervised defect identification.",autonomous vehicle
http://arxiv.org/abs/2102.13253v1,to_check,arxiv,arxiv,2021-02-26 01:31:28+00:00,arxiv,"On the Visual-based Safe Landing of UAVs in Populated Areas: a Crucial
  Aspect for Urban Deployment",http://arxiv.org/abs/2102.13253v1,"Autonomous landing of Unmanned Aerial Vehicles (UAVs) in crowded scenarios is
crucial for successful deployment of UAVs in populated areas, particularly in
emergency landing situations where the highest priority is to avoid hurting
people. In this work, a new visual-based algorithm for identifying Safe Landing
Zones (SLZ) in crowded scenarios is proposed, considering a camera mounted on
an UAV, where the people in the scene move with unknown dynamics. To do so, a
density map is generated for each image frame using a Deep Neural Network, from
where a binary occupancy map is obtained aiming to overestimate the people's
location for security reasons. Then, the occupancy map is projected to the
head's plane, and the SLZ candidates are obtained as circular regions in the
head's plane with a minimum security radius. Finally, to keep track of the SLZ
candidates, a multiple instance tracking algorithm is implemented using Kalman
Filters along with the Hungarian algorithm for data association. Several
scenarios were studied to prove the validity of the proposed strategy,
including public datasets and real uncontrolled scenarios with people moving in
public squares, taken from an UAV in flight. The study showed promising results
in the search of preventing the UAV from hurting people during emergency
landing.",autonomous vehicle
http://arxiv.org/abs/1909.07554v1,to_check,arxiv,arxiv,2019-09-17 02:22:09+00:00,arxiv,"Gated Recurrent Units Learning for Optimal Deployment of Visible Light
  Communications Enabled UAVs",http://arxiv.org/abs/1909.07554v1,"In this paper, the problem of optimizing the deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities is
studied. In the studied model, the UAVs can simultaneously provide
communications and illumination to service ground users. Ambient illumination
increases the interference over VLC links while reducing the illumination
threshold of the UAVs. Therefore, it is necessary to consider the illumination
distribution of the target area for UAV deployment optimization. This problem
is formulated as an optimization problem whose goal is to minimize the total
transmit power while meeting the illumination and communication requirements of
users. To solve this problem, an algorithm based on the machine learning
framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can
model the long-term historical illumination distribution and predict the future
illumination distribution. In order to reduce the complexity of the prediction
algorithm while accurately predicting the illumination distribution, a Gaussian
mixture model (GMM) is used to fit the illumination distribution of the target
area at each time slot. Based on the predicted illumination distribution, the
optimization problem is proved to be a convex optimization problem that can be
solved by using duality. Simulations using real data from the Earth
observations group (EOG) at NOAA/NCEI show that the proposed approach can
achieve up to 22.1% reduction in transmit power compared to a conventional
optimal UAV deployment that does not consider the illumination distribution.
The results also show that UAVs must hover at areas having strong illumination,
thus providing useful guidelines on the deployment of VLC-enabled UAVs.",autonomous vehicle
http://arxiv.org/abs/2008.07371v1,to_check,arxiv,arxiv,2020-07-20 22:23:50+00:00,arxiv,Artificial Intelligence is stupid and causal reasoning won't fix it,http://arxiv.org/abs/2008.07371v1,"Artificial Neural Networks have reached Grandmaster and even super-human
performance across a variety of games: from those involving perfect-information
(such as Go) to those involving imperfect-information (such as Starcraft). Such
technological developments from AI-labs have ushered concomitant applications
across the world of business - where an AI brand tag is fast becoming
ubiquitous. A corollary of such widespread commercial deployment is that when
AI gets things wrong - an autonomous vehicle crashes; a chatbot exhibits racist
behaviour; automated credit scoring processes discriminate on gender etc. -
there are often significant financial, legal and brand consequences and the
incident becomes major news. As Judea Pearl sees it, the underlying reason for
such mistakes is that, 'all the impressive achievements of deep learning amount
to just curve fitting'. The key, Judea Pearl suggests, is to replace reasoning
by association with causal-reasoning - the ability to infer causes from
observed phenomena. It is a point that was echoed by Gary Marcus and Ernest
Davis in a recent piece for the New York Times: 'we need to stop building
computer systems that merely get better and better at detecting statistical
patterns in data sets - often using an approach known as Deep Learning - and
start building computer systems that from the moment of their assembly innately
grasp three basic concepts: time, space and causality'. In this paper,
foregrounding what in 1949 Gilbert Ryle termed a category mistake, I will offer
an alternative explanation for AI errors: it is not so much that AI machinery
cannot grasp causality, but that AI machinery - qua computation - cannot
understand anything at all.",autonomous vehicle
http://arxiv.org/abs/1711.05934v1,to_check,arxiv,arxiv,2017-11-16 05:37:14+00:00,arxiv,Enhanced Attacks on Defensively Distilled Deep Neural Networks,http://arxiv.org/abs/1711.05934v1,"Deep neural networks (DNNs) have achieved tremendous success in many tasks of
machine learning, such as the image classification. Unfortunately, researchers
have shown that DNNs are easily attacked by adversarial examples, slightly
perturbed images which can mislead DNNs to give incorrect classification
results. Such attack has seriously hampered the deployment of DNN systems in
areas where security or safety requirements are strict, such as autonomous
cars, face recognition, malware detection. Defensive distillation is a
mechanism aimed at training a robust DNN which significantly reduces the
effectiveness of adversarial examples generation. However, the state-of-the-art
attack can be successful on distilled networks with 100% probability. But it is
a white-box attack which needs to know the inner information of DNN. Whereas,
the black-box scenario is more general. In this paper, we first propose the
epsilon-neighborhood attack, which can fool the defensively distilled networks
with 100% success rate in the white-box setting, and it is fast to generate
adversarial examples with good visual quality. On the basis of this attack, we
further propose the region-based attack against defensively distilled DNNs in
the black-box setting. And we also perform the bypass attack to indirectly
break the distillation defense as a complementary method. The experimental
results show that our black-box attacks have a considerable success rate on
defensively distilled networks.",autonomous vehicle
http://arxiv.org/abs/2106.04823v1,to_check,arxiv,arxiv,2021-06-09 05:56:42+00:00,arxiv,Practical Machine Learning Safety: A Survey and Primer,http://arxiv.org/abs/2106.04823v1,"The open-world deployment of Machine Learning (ML) algorithms in
safety-critical applications such as autonomous vehicles needs to address a
variety of ML vulnerabilities such as interpretability, verifiability, and
performance limitations. Research explores different approaches to improve ML
dependability by proposing new models and training techniques to reduce
generalization error, achieve domain adaptation, and detect outlier examples
and adversarial attacks. In this paper, we review and organize practical ML
techniques that can improve the safety and dependability of ML algorithms and
therefore ML-based software. Our organization maps state-of-the-art ML
techniques to safety strategies in order to enhance the dependability of the ML
algorithm from different aspects, and discuss research gaps as well as
promising solutions.",autonomous vehicle
http://arxiv.org/abs/1806.07987v2,to_check,arxiv,arxiv,2018-06-20 21:12:43+00:00,arxiv,"A Hierarchical Deep Architecture and Mini-Batch Selection Method For
  Joint Traffic Sign and Light Detection",http://arxiv.org/abs/1806.07987v2,"Traffic light and sign detectors on autonomous cars are integral for road
scene perception. The literature is abundant with deep learning networks that
detect either lights or signs, not both, which makes them unsuitable for
real-life deployment due to the limited graphics processing unit (GPU) memory
and power available on embedded systems. The root cause of this issue is that
no public dataset contains both traffic light and sign labels, which leads to
difficulties in developing a joint detection framework. We present a deep
hierarchical architecture in conjunction with a mini-batch proposal selection
mechanism that allows a network to detect both traffic lights and signs from
training on separate traffic light and sign datasets. Our method solves the
overlapping issue where instances from one dataset are not labelled in the
other dataset. We are the first to present a network that performs joint
detection on traffic lights and signs. We measure our network on the
Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small
Traffic Lights benchmark for traffic light detection and show it outperforms
the existing Bosch Small Traffic light state-of-the-art method. We focus on
autonomous car deployment and show our network is more suitable than others
because of its low memory footprint and real-time image processing time.
Qualitative results can be viewed at https://youtu.be/_YmogPzBXOw",autonomous vehicle
http://arxiv.org/abs/2003.01886v1,to_check,arxiv,arxiv,2020-03-04 04:35:22+00:00,arxiv,"Efficient statistical validation with edge cases to evaluate Highly
  Automated Vehicles",http://arxiv.org/abs/2003.01886v1,"The widescale deployment of Autonomous Vehicles (AV) seems to be imminent
despite many safety challenges that are yet to be resolved. It is well known
that there are no universally agreed Verification and Validation (VV)
methodologies to guarantee absolute safety, which is crucial for the acceptance
of this technology. Existing standards focus on deterministic processes where
the validation requires only a set of test cases that cover the requirements.
Modern autonomous vehicles will undoubtedly include machine learning and
probabilistic techniques that require a much more comprehensive testing regime
due to the non-deterministic nature of the operating design domain. A rigourous
statistical validation process is an essential component required to address
this challenge. Most research in this area focuses on evaluating system
performance in large scale real-world data gathering exercises (number of miles
travelled), or randomised test scenarios in simulation.
  This paper presents a new approach to compute the statistical characteristics
of a system's behaviour by biasing automatically generated test cases towards
the worst case scenarios, identifying potential unsafe edge cases.We use
reinforcement learning (RL) to learn the behaviours of simulated actors that
cause unsafe behaviour measured by the well established RSS safety metric. We
demonstrate that by using the method we can more efficiently validate a system
using a smaller number of test cases by focusing the simulation towards the
worst case scenario, generating edge cases that correspond to unsafe
situations.",autonomous vehicle
http://arxiv.org/abs/2110.01232v1,to_check,arxiv,arxiv,2021-10-04 07:52:23+00:00,arxiv,Benchmarking Safety Monitors for Image Classifiers with Machine Learning,http://arxiv.org/abs/2110.01232v1,"High-accurate machine learning (ML) image classifiers cannot guarantee that
they will not fail at operation. Thus, their deployment in safety-critical
applications such as autonomous vehicles is still an open issue. The use of
fault tolerance mechanisms such as safety monitors is a promising direction to
keep the system in a safe state despite errors of the ML classifier. As the
prediction from the ML is the core information directly impacting safety, many
works are focusing on monitoring the ML model itself. Checking the efficiency
of such monitors in the context of safety-critical applications is thus a
significant challenge. Therefore, this paper aims at establishing a baseline
framework for benchmarking monitors for ML image classifiers. Furthermore, we
propose a framework covering the entire pipeline, from data generation to
evaluation. Our approach measures monitor performance with a broader set of
metrics than usually proposed in the literature. Moreover, we benchmark three
different monitor approaches in 79 benchmark datasets containing five
categories of out-of-distribution data for image classifiers: class novelty,
noise, anomalies, distributional shifts, and adversarial attacks. Our results
indicate that these monitors are no more accurate than a random monitor. We
also release the code of all experiments for reproducibility.",autonomous vehicle
http://arxiv.org/abs/2006.04734v3,to_check,arxiv,arxiv,2020-06-08 16:40:12+00:00,arxiv,Reinforcement Learning Under Moral Uncertainty,http://arxiv.org/abs/2006.04734v3,"An ambitious goal for machine learning is to create agents that behave
ethically: The capacity to abide by human moral norms would greatly expand the
context in which autonomous agents could be practically and safely deployed,
e.g. fully autonomous vehicles will encounter charged moral decisions that
complicate their deployment. While ethical agents could be trained by rewarding
correct behavior under a specific moral theory (e.g. utilitarianism), there
remains widespread disagreement about the nature of morality. Acknowledging
such disagreement, recent work in moral philosophy proposes that ethical
behavior requires acting under moral uncertainty, i.e. to take into account
when acting that one's credence is split across several plausible ethical
theories. This paper translates such insights to the field of reinforcement
learning, proposes two training methods that realize different points among
competing desiderata, and trains agents in simple environments to act under
moral uncertainty. The results illustrate (1) how such uncertainty can help
curb extreme behavior from commitment to single theories and (2) several
technical complications arising from attempting to ground moral philosophy in
RL (e.g. how can a principled trade-off between two competing but incomparable
reward functions be reached). The aim is to catalyze progress towards
morally-competent agents and highlight the potential of RL to contribute
towards the computational grounding of moral philosophy.",autonomous vehicle
http://arxiv.org/abs/2009.14349v3,to_check,arxiv,arxiv,2020-09-30 00:01:54+00:00,arxiv,"Computing Systems for Autonomous Driving: State-of-the-Art and
  Challenges",http://arxiv.org/abs/2009.14349v3,"The recent proliferation of computing technologies (e.g., sensors, computer
vision, machine learning, and hardware acceleration), and the broad deployment
of communication mechanisms (e.g., DSRC, C-V2X, 5G) have pushed the horizon of
autonomous driving, which automates the decision and control of vehicles by
leveraging the perception results based on multiple sensors. The key to the
success of these autonomous systems is making a reliable decision in real-time
fashion. However, accidents and fatalities caused by early deployed autonomous
vehicles arise from time to time. The real traffic environment is too
complicated for current autonomous driving computing systems to understand and
handle. In this paper, we present state-of-the-art computing systems for
autonomous driving, including seven performance metrics and nine key
technologies, followed by twelve challenges to realize autonomous driving. We
hope this paper will gain attention from both the computing and automotive
communities and inspire more research in this direction.",autonomous vehicle
http://arxiv.org/abs/1712.02294v4,to_check,arxiv,arxiv,2017-12-06 17:20:21+00:00,arxiv,Joint 3D Proposal Generation and Object Detection from View Aggregation,http://arxiv.org/abs/1712.02294v4,"We present AVOD, an Aggregate View Object Detection network for autonomous
driving scenarios. The proposed neural network architecture uses LIDAR point
clouds and RGB images to generate features that are shared by two subnetworks:
a region proposal network (RPN) and a second stage detector network. The
proposed RPN uses a novel architecture capable of performing multimodal feature
fusion on high resolution feature maps to generate reliable 3D object proposals
for multiple object classes in road scenes. Using these proposals, the second
stage detection network performs accurate oriented 3D bounding box regression
and category classification to predict the extents, orientation, and
classification of objects in 3D space. Our proposed architecture is shown to
produce state of the art results on the KITTI 3D object detection benchmark
while running in real time with a low memory footprint, making it a suitable
candidate for deployment on autonomous vehicles. Code is at:
https://github.com/kujason/avod",autonomous vehicle
http://arxiv.org/abs/2109.02529v2,to_check,arxiv,arxiv,2021-09-06 15:12:17+00:00,arxiv,"ViSTA: a Framework for Virtual Scenario-based Testing of Autonomous
  Vehicles",http://arxiv.org/abs/2109.02529v2,"In this paper, we present ViSTA, a framework for Virtual Scenario-based
Testing of Autonomous Vehicles (AV), developed as part of the 2021 IEEE
Autonomous Test Driving AI Test Challenge. Scenario-based virtual testing aims
to construct specific challenges posed for the AV to overcome, albeit in
virtual test environments that may not necessarily resemble the real world.
This approach is aimed at identifying specific issues that arise safety
concerns before an actual deployment of the AV on the road. In this paper, we
describe a comprehensive test case generation approach that facilitates the
design of special-purpose scenarios with meaningful parameters to form test
cases, both in automated and manual ways, leveraging the strength and
weaknesses of either. Furthermore, we describe how to automate the execution of
test cases, and analyze the performance of the AV under these test cases.",autonomous vehicle
http://arxiv.org/abs/2001.00048v1,to_check,arxiv,arxiv,2019-12-31 19:41:59+00:00,arxiv,"MIR-Vehicle: Cost-Effective Research Platform for Autonomous Vehicle
  Applications",http://arxiv.org/abs/2001.00048v1,"This paper illustrates the MIR (Mobile Intelligent Robotics) Vehicle: a
feasible option of transforming an electric ride-on-car into a modular Graphics
Processing Unit (GPU) powered autonomous platform equipped with the capability
that supports test and deployment of various intelligent autonomous vehicles
algorithms. To use a platform for research, two components must be provided:
perception and control. The sensors such as incremental encoders, an Inertial
Measurement Unit (IMU), a camera, and a LIght Detection And Ranging (LIDAR)
must be able to be installed on the platform to add the capability of
environmental perception. A microcontroller-powered control box is designed to
properly respond to the environmental changes by regulating drive and steering
motors. This drive-by-wire capability is controlled by a GPU powered laptop
computer where high-level perception algorithms are processed and complex
actions are generated by various methods including behavior cloning using deep
neural networks. The main goal of this paper is to provide an adequate and
comprehensive approach for fabricating a cost-effective platform that would
contribute to the research quality from the wider community. The proposed
platform is to use a modular and hierarchical software architecture where the
lower and simpler motor controls are taken care of by microcontroller programs,
and the higher and complex algorithms are processed by a GPU powered laptop
computer. The platform uses the Robot Operating System (ROS) as middleware to
maintain the modularity of the perceptions and decision-making modules. It is
expected that the level three and above autonomous vehicle systems and Advanced
Driver Assistance Systems (ADAS) can be tested on and deployed to the platform
with a decent real-time system behavior due to the capabilities and
affordability of the proposed platform.",autonomous vehicle
http://arxiv.org/abs/1607.08289v4,to_check,arxiv,arxiv,2016-07-28 01:22:26+00:00,arxiv,Mammalian Value Systems,http://arxiv.org/abs/1607.08289v4,"Characterizing human values is a topic deeply interwoven with the sciences,
humanities, art, and many other human endeavors. In recent years, a number of
thinkers have argued that accelerating trends in computer science, cognitive
science, and related disciplines foreshadow the creation of intelligent
machines which meet and ultimately surpass the cognitive abilities of human
beings, thereby entangling an understanding of human values with future
technological development. Contemporary research accomplishments suggest
sophisticated AI systems becoming widespread and responsible for managing many
aspects of the modern world, from preemptively planning users' travel schedules
and logistics, to fully autonomous vehicles, to domestic robots assisting in
daily living. The extrapolation of these trends has been most forcefully
described in the context of a hypothetical ""intelligence explosion,"" in which
the capabilities of an intelligent software agent would rapidly increase due to
the presence of feedback loops unavailable to biological organisms. The
possibility of superintelligent agents, or simply the widespread deployment of
sophisticated, autonomous AI systems, highlights an important theoretical
problem: the need to separate the cognitive and rational capacities of an agent
from the fundamental goal structure, or value system, which constrains and
guides the agent's actions. The ""value alignment problem"" is to specify a goal
structure for autonomous agents compatible with human values. In this brief
article, we suggest that recent ideas from affective neuroscience and related
disciplines aimed at characterizing neurological and behavioral universals in
the mammalian class provide important conceptual foundations relevant to
describing human values. We argue that the notion of ""mammalian value systems""
points to a potential avenue for fundamental research in AI safety and AI
ethics.",autonomous vehicle
http://arxiv.org/abs/2107.07557v1,to_check,arxiv,arxiv,2021-07-15 18:37:19+00:00,arxiv,OdoViz: A 3D Odometry Visualization and Processing Tool,http://arxiv.org/abs/2107.07557v1,"OdoViz is a reactive web-based tool for 3D visualization and processing of
autonomous vehicle datasets designed to support common tasks in visual place
recognition research. The system includes functionality for loading,
inspecting, visualizing, and processing GPS/INS poses, point clouds and camera
images. It supports a number of commonly used driving datasets and can be
adapted to load custom datasets with minimal effort. OdoViz's design consists
of a slim server to serve the datasets coupled with a rich client frontend.
This design supports multiple deployment configurations including single user
stand-alone installations, research group installations serving datasets
internally across a lab, or publicly accessible web-frontends for providing
online interfaces for exploring and interacting with datasets. The tool allows
viewing complete vehicle trajectories traversed at multiple different time
periods simultaneously, facilitating tasks such as sub-sampling, comparing and
finding pose correspondences both across and within sequences. This
significantly reduces the effort required in creating subsets of data from
existing datasets for machine learning tasks. Further to the above, the system
also supports adding custom extensions and plugins to extend the capabilities
of the software for other potential data management, visualization and
processing tasks. The platform has been open-sourced to promote its use and
encourage further contributions from the research community.",autonomous vehicle
10.1016/j.knosys.2020.106685,to_check,Knowledge-Based Systems,sciencedirect,2021-02-28,sciencedirect,Explainability in deep reinforcement learning,https://api.elsevier.com/content/article/pii/S0950705120308145,"
                  A large set of the explainable Artificial Intelligence (XAI) literature is emerging on feature relevance techniques to explain a deep neural network (DNN) output or explaining models that ingest image source data. However, assessing how XAI techniques can help understand models beyond classification tasks, e.g. for reinforcement learning (RL), has not been extensively studied. We review recent works in the direction to attain Explainable Reinforcement Learning (XRL), a relatively new subfield of Explainable Artificial Intelligence, intended to be used in general public applications, with diverse audiences, requiring ethical, responsible and trustable algorithms. In critical situations where it is essential to justify and explain the agentâ€™s behaviour, better explainability and interpretability of RL models could help gain scientific insight on the inner workings of what is still considered a black box. We evaluate mainly studies directly linking explainability to RL, and split these into two categories according to the way the explanations are generated: transparent algorithms and post-hoc explainability. We also review the most prominent XAI works from the lenses of how they could potentially enlighten the further deployment of the latest advances in RL, in the demanding present and future of everyday problems.
               ",autonomous vehicle
10.1016/j.adhoc.2021.102667,to_check,Ad Hoc Networks,sciencedirect,2021-12-01,sciencedirect,"Machine learning for 5G security: Architecture, recent advances, and challenges",https://api.elsevier.com/content/article/pii/S1570870521001785,"
                  The granularization of crucial network functions implementation using software-centric, and virtualized approaches in 5G networks have brought forth unprecedented security challenges in general and privacy concerns. Moreover, these software componentsâ€™ premature deployment and compromised supply chain put the individual network components at risk and have a ripple effect for the rest of the network. Some of the novel threats to 5G assets include tampering in identity and access management, supply-chain poisoning, masquerade and bot attacks, loop-holes in source codes. Machine learning (ML) in this context can help to provide heavily dynamic and robust security mechanisms for the software-centric architecture of 5G Networks. ML modelsâ€™ development and implementation also rely on programmable environments; hence, they can play a vital role in designing, modelling, and automating efficient security protocols. This article presents the threat landscape across 5G networks and discusses the feasibility and architecture of different ML-based models to counter these threats. Also, we present the architecture for automated threat intelligence using cooperative and coordinated ML to secure 5G assets and infrastructure. We also present the summary of closely related existing works along with future research challenges.
               ",autonomous vehicle
10.1016/j.comnet.2020.107478,to_check,Computer Networks,sciencedirect,2020-12-09,sciencedirect,UAVs joint optimization problems and machine learning to improve the 5G and Beyond communication,https://api.elsevier.com/content/article/pii/S1389128620311518,"
                  Recently, unmanned aerial vehicles (UAVs) have gained notable interest in various applications such as wireless coverage, aerial surveillance, precision agriculture, construction, power lines monitoring and blood delivery, etc. The UAVs implicit attributes e.g., rapid deployment, quick mobility, increase in flight duration, improvements in payload capacities, etc. , place it as an effective candidate for many applications in 5G and Beyond communications. The UAVs-assisted next-generation communications are determined to be highly influenced by various techniques and technologies like artificial intelligence (AI), machine learning (ML), deep reinforcement learning (DRL), mobile edge computing (MEC), and software-defined networks (SDN). In this article, we develop a review to investigate the UAVs joint optimization problems to enhance system efficiency. We classify the joint optimization problems based on the number of parameters used in proposed optimization problems. Moreover, we explore the impact of AI, ML, DRL, MEC, and SDN over UAVs joint optimization problems and present future research challenges and directions.
               ",autonomous vehicle
10.1016/j.dcan.2021.10.007,to_check,Digital Communications and Networks,sciencedirect,2021-10-28,sciencedirect,Machine learning in vehicular networking: an overview,https://api.elsevier.com/content/article/pii/S2352864821000870,"As vehicle complexity and road congestion increase, combined with the emergence of electric vehicles, the need for intelligent transportation systems to improve on-road safety and transportation efficiency using vehicular networks has become essential. The evolution of high mobility wireless networks will provide improved support for connected vehicles through highly dynamic heterogeneous networks. Particularly, 5G deployment introduces new features and technologies that enable operators to capitalize on emerging infrastructure capabilities. Machine Learning (ML), a powerful methodology for adaptive and predictive system development, has emerged in both vehicular and conventional wireless networks. Adopting data-centric methods enables ML to address highly dynamic vehicular network issues faced by conventional solutions, such as traditional control loop design and optimization techniques. This article provides a short survey of ML applications in vehicular networks from the networking aspect. Research topics covered in this article include network control containing handover management and routing decision making, resource management, and energy efficiency in vehicular networks. The findings of this paper suggest more attention should be paid to network forming/deforming decision making. ML applications in vehicular networks should focus on researching multi-agent cooperated oriented methods and overall complexity reduction while utilizing enabling technologies, such as mobile edge computing for real-world deployment. Research datasets, simulation environment standardization, and method interpretability also require more research attention.",autonomous vehicle
10.1016/j.procs.2019.06.016,to_check,Procedia Computer Science,sciencedirect,2019-12-31,sciencedirect,Deep Learning-Based Power Usage Forecast Modeling and Evaluation,https://api.elsevier.com/content/article/pii/S1877050919307859,"The growing Internet of Things (IoT) provides significant resources to be integrated with critical infrastructures to enable cyber-physical systems. More specifically, the deployment of smart meters for electricity usage monitoring in the smart grid can provide granular and detailed information from which power load forecasting can be carried out. However, the accurate prediction of long-term power usage remains a challenging issue. In light of many recent advances, deep learning has the potential to significantly improve the ability to assess data and make predictions, and is already rapidly changing the world we live in. As such, in this paper, we consider the use of deep learning, via Recursive Neural Network (RNN) and Long Short-Term Memory layers, for the long-term prediction of localized power consumption. In particular, we consider the optimization of both data feature sets and neural network models, developing three model-feature combinations to maximize prediction accuracy and minimize error. Through detailed experimental evaluation, our results demonstrate the ability to achieve highly accurate predictions over periods as large as 21 days through the integration of correlated features.",autonomous vehicle
10.1016/j.bdr.2018.04.002,to_check,Big Data Research,sciencedirect,2018-12-31,sciencedirect,A Dynamic Neural Network Architecture with Immunology Inspired Optimization for Weather Data Forecasting,https://api.elsevier.com/content/article/pii/S2214579617303696,"
                  Recurrent neural networks are dynamical systems that provide for memory capabilities to recall past behaviour, which is necessary in the prediction of time series. In this paper, a novel neural network architecture inspired by the immune algorithm is presented and used in the forecasting of naturally occurring signals, including weather big data signals. Big Data Analysis is a major research frontier, which attracts extensive attention from academia, industry and government, particularly in the context of handling issues related to complex dynamics due to changing weather conditions. Recently, extensive deployment of IoT, sensors, and ambient intelligence systems led to an exponential growth of data in the climate domain. In this study, we concentrate on the analysis of big weather data by using the Dynamic Self Organized Neural Network Inspired by the Immune Algorithm. The learning strategy of the network focuses on the local properties of the signal using a self-organised hidden layer inspired by the immune algorithm, while the recurrent links of the network aim at recalling previously observed signal patterns. The proposed network exhibits improved performance when compared to the feedforward multilayer neural network and state-of-the-art recurrent networks, e.g., the Elman and the Jordan networks. Three non-linear and non-stationary weather signals are used in our experiments. Firstly, the signals are transformed into stationary, followed by 5-steps ahead prediction. Improvements in the prediction results are observed with respect to the mean value of the error (RMS) and the signal to noise ratio (SNR), however to the expense of additional computational complexity, due to presence of recurrent links.
               ",autonomous vehicle
10.1016/j.jpdc.2020.07.008,to_check,Journal of Parallel and Distributed Computing,sciencedirect,2020-12-31,sciencedirect,"Intelligently modeling, detecting, and scheduling elephant flows in software defined energy cloud: A survey",https://api.elsevier.com/content/article/pii/S0743731520303373,"
                  Elephant flows (elephants) refer to the sequences of packets that contribute only 10% of the total volume but consume over 90% of the network bandwidth. They often cause network congestion and should be efficiently managed. Present cloud data centers often involve host- and switch-based approaches to detect and schedule elephants, but suffer (1) each host and switch in the network needs to be customized, and (2) dynamic models and advanced policies are difficult to be applied. Software Defined Cloud (SDC) addresses these issues by enabling controller-based approaches. With the aid of Machine Learning (ML) technologies, SDC can achieve learning-based models, flexible deployment, and early detection and schedule of elephants for the optimization of network performance and energy usage in a dynamic and intelligent manner. On this purpose, this article emphases the significance of models describing elephants, surveys the mechanisms that may apply to model, detect, and schedule elephants for SDC to optimize the network performance and energy usage. To the best of our knowledge, this work is the first effort that reviews the techniques in all these related subtopics simultaneously in the context of energy cloud.
               ",autonomous vehicle
10.1016/B978-0-12-820028-5.00010-2,to_check,Smart Manufacturing,sciencedirect,2020-12-31,sciencedirect,Chapter 10: Smart manufacturing in industrial gas production: A digital transformation,https://api.elsevier.com/content/article/pii/B9780128200285000102,"
               This chapter shows, from the experience of Air Liquide in its digital transformation through the development and implementation of its Smart Innovative Operations (SIO) program, that enterprise-wide industrial deployment of smart manufacturing solutions requires strong methodology, organization, and communication to provide the expected benefits in operational excellence (e.g., efficiency and reliability). This is true whether the smart manufacturing solution is fully internally developed, completely commercial-off-the-shelf (COTS), or a hybrid, as is the case for both SIO.Predict (anomaly detection) and SIO.Optim (mathematical programming optimization) as discussed in this chapter. Both SIO.Predict and SIO.Optim implement COTS software as a platform to both enable and be enabled by a strong internal organization within Air Liquide, including a variety of backgrounds, roles, and expertise. Such software platforms enable further innovation, including the implementation of the latest mathematical algorithms developed and demonstrated by industrial and academic researchers.
            ",autonomous vehicle
10.1016/j.comcom.2020.02.065,to_check,Computer Communications,scopus,2020-03-15,scopus,Amateur Drones Detection: A machine learning approach utilizing the acoustic signals in the presence of strong interference,https://api.elsevier.com/content/abstract/scopus_id/85080874387,"
                  Owing to small size, sensing capabilities and autonomous nature, the Unmanned Air Vehicles (UAVs) have enormous applications in various areas e.g., remote sensing, navigation, archaeology, journalism, environmental science, and agriculture. However, the un-monitored deployment of UAVs called the amateur drones (AmDr) can lead to serious security threats and risk to human life and infrastructure. Therefore, timely detection of the AmDr is essential for the protection and security of sensitive organizations, human life and other vital infrastructure. AmDrs can be detected using different techniques based on sound, video, thermal, and radio frequencies. However, the performance of these techniques is limited in sever atmospheric conditions. In this paper, we propose an efficient un-supervise machine learning approach of independent component analysis (ICA) to detect various acoustic signals i.e., sounds of bird, airplanes, thunderstorm, rain, wind and the UAVs in practical scenario. After unmixing the signals, the features like Mel Frequency Cepstral Coefficients (MFCC), the power spectral density (PSD) and the Root Mean Square Value (RMS) of the PSD are extracted by using ICA. The PSD and the RMS of PSD signals are extracted by first passing the signals from octave band filter banks. Based on the above features the signals are classified using Support Vector Machines (SVM)and K Nearest Neighbour (KNN)to detect the presence or absence of AmDr. Unique feature of the proposed technique is the detection of a single or multiple AmDrs at a time in the presence of multiple acoustic interfering signals. The proposed technique is verified through extensive simulations and it is observed that the RMS values of PSD with KNN performs better than the MFCC with KNN and SVM.
               ",autonomous vehicle
http://arxiv.org/abs/1801.05086v1,to_check,arxiv,arxiv,2018-01-16 01:14:12+00:00,arxiv,Autonomous UAV Navigation Using Reinforcement Learning,http://arxiv.org/abs/1801.05086v1,"Unmanned aerial vehicles (UAV) are commonly used for missions in unknown
environments, where an exact mathematical model of the environment may not be
available. This paper provides a framework for using reinforcement learning to
allow the UAV to navigate successfully in such environments. We conducted our
simulation and real implementation to show how the UAVs can successfully learn
to navigate through an unknown environment. Technical aspects regarding to
applying reinforcement learning algorithm to a UAV system and UAV flight
control were also addressed. This will enable continuing research using a UAV
with learning capabilities in more important applications, such as wildfire
monitoring, or search and rescue missions.",autonomous vehicle
10.1109/ICICCS51141.2021.9432186,to_check,2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS),IEEE,2021-05-08 00:00:00,ieeexplore,Pothole and Object Detection for an Autonomous Vehicle Using YOLO,https://ieeexplore.ieee.org/document/9432186/,"Object Detection is an key software and a fundamental task for an autonomous driving system that provides remarkable change in computer vision. Ä°n recent years, company's are planning to launch autonomous vehicle in an full swing that's the most important ascpets for object detection and one of most challenging task for locating specific object from from multiple objects in a specific scenario. The computer vision and machine learning algorithm is the important tool for detecting objects in and around the environment. In this paper, which consists of two parts The first part is implemented on object detection in the surrounding with Yolo (You Only Look Once)Algorithm provides exact classification and position which is configured on newly created datasets for classes of object: a car, a person, a truck, a bus, traffic light, motorcycle, pothole, wetland uses the Convolutional Neural Network and max-polling layer for prediction that improves detecting of small target and these deep learning technique provides a high accuracy for detecting real world. Detecting potholes in Indian road help the autonomous vehicle to move smoothly without getting struck in the potholes. In part two of the proposed method is implemented on Raspberry pi4 a popular embedded computer board explores suitability for the running objects. That solves the real world problems and improves the impact on detecting objects. Knowing pothole and wetland detection for self-driving vehicle is needed badly to solve the road lay problems like: accident, slowing down the transport system these are solved by deep learning.",autonomous vehicle
10.1109/ICVES.2016.7548165,to_check,2016 IEEE International Conference on Vehicular Electronics and Safety (ICVES),IEEE,2016-07-12 00:00:00,ieeexplore,A new hopfield-type neural network approach to multi-goal vehicle navigation in unknown environments,https://ieeexplore.ieee.org/document/7548165/,"A Hopfield-type neural networks (HNN) algorithm associated with histogram navigation method is proposed in this paper for real-time map building and path planning for multiple goals applications. In real world applications such as rescue robots, service robots, mining mobile robots, and mine searching robots, etc., an autonomous vehicle needs to reach multiple goals with a shortest path that, in this paper, is capable of being implemented by a HNN method with minimized overall distance. Once a global trajectory is planned, a foraging-enabled trail is created to guide the vehicle to the multiple goals. A histogram-based local navigation algorithm is employed to plan a collision-free path along the trail planned by the global path planner. A re-planning-based algorithm aims to generate trajectory while an autonomous vehicle explores through a terrain with map building in unknown environments. In this paper, simulation and experimental results demonstrate that the real-time concurrent mapping and multi-goal navigation of an autonomous vehicle is successfully performed under unknown environments.",autonomous vehicle
10.1109/ITSC45102.2020.9294368,to_check,2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC),IEEE,2020-09-23 00:00:00,ieeexplore,Formal Scenario-Based Testing of Autonomous Vehicles: From Simulation to the Real World,https://ieeexplore.ieee.org/document/9294368/,"We present a new approach to automated scenario-based testing of the safety of autonomous vehicles, especially those using advanced artificial intelligence-based components, spanning both simulation-based evaluation as well as testing in the real world. Our approach is based on formal methods, combining formal specification of scenarios and safety properties, algorithmic test case generation using formal simulation, test case selection for track testing, executing test cases on the track, and analyzing the resulting data. Experiments with a real autonomous vehicle at an industrial testing facility support our hypotheses that (i) formal simulation can be effective at identifying test cases to run on the track, and (ii) the gap between simulated and real worlds can be systematically evaluated and bridged.",autonomous vehicle
10.1109/ITSC48978.2021.9565009,to_check,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),IEEE,2021-09-22 00:00:00,ieeexplore,PandaSet: Advanced Sensor Suite Dataset for Autonomous Driving,https://ieeexplore.ieee.org/document/9565009/,"The accelerating development of autonomous driving technology has placed greater demands on obtaining large amounts of high-quality data. Representative, labeled, real world data serves as the fuel for training deep learning networks, critical for improving self-driving perception algorithms. In this paper, we introduce PandaSet, the first dataset produced by a complete, high-precision autonomous vehicle sensor kit with a no-cost commercial license. The dataset was collected using one 360Â° mechanical spinning LiDAR, one forward-facing, long-range LiDAR, and 6 cameras. The dataset contains more than 100 scenes, each of which is 8 seconds long, and provides 28 types of labels for object classification and 37 types of labels for semantic segmentation. We provide baselines for LiDAR-only 3D object detection, LiDAR-camera fusion 3D object detection and LiDAR point cloud segmentation. For more details about PandaSet and the development kit, see https://scale.com/open-datasets/pandaset.",autonomous vehicle
10.1109/SIMPAR.2018.8376285,to_check,"2018 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)",IEEE,2018-05-19 00:00:00,ieeexplore,The sleepwalker framework: Verification and validation of autonomous vehicles by mixed reality LiDAR stimulation,https://ieeexplore.ieee.org/document/8376285/,"Verification and validation of autonomous mobile systems, such as autonomous vehicles, is indispensable, since conflicts and serious incidents are rarely acceptable when human beings are involved. Although integrative simulation frameworks are commonly applied to test these systems, such simulations are usually too idealistic, while real world tests are both, expensive and not reproducible. To overcome this problem, we present the framework Sleepwalker for verifying and validating autonomous vehicles: Similar to a human sleepwalker, our framework stimulates the automated driving function at a sensor close level with virtual laserscans mixed with sensor data from the real environment. Thus, the autonomous driving function explicitely builds up a mixed reality environment model as a basis for the subsequent components and therefore enables an overall performance assessment. The instantiation of the framework is adaptable so it to can be balanced between the required result's plausibility and scenario criticality. We demonstrate the distinguished benefits of our framework by different instantiations stimulating an autonomous vehicle and conclude with further research questions.",autonomous vehicle
10.1109/JSAC.2021.3087248,to_check,IEEE Journal on Selected Areas in Communications,IEEE,2021-08-01 00:00:00,ieeexplore,Effective Communications: A Joint Learning and Communication Framework for Multi-Agent Reinforcement Learning Over Noisy Channels,https://ieeexplore.ieee.org/document/9466501/,"We propose a novel formulation of the â€œeffectiveness problemâ€ in communications, put forth by Shannon and Weaver in their seminal work â€œ<italic>The Mathematical Theory of Communication</italic>â€, by considering multiple agents communicating over a noisy channel in order to achieve better coordination and cooperation in a multi-agent reinforcement learning (MARL) framework. Specifically, we consider a multi-agent partially observable Markov decision process (MA-POMDP), in which the agents, in addition to interacting with the environment, can also communicate with each other over a noisy communication channel. The noisy communication channel is considered explicitly as part of the dynamics of the environment, and the message each agent sends is part of the action that the agent can take. As a result, the agents learn not only to collaborate with each other but also to communicate â€œeffectivelyâ€ over a noisy channel. This framework generalizes both the traditional communication problem, where the main goal is to convey a message reliably over a noisy channel, and the â€œlearning to communicateâ€ framework that has received recent attention in the MARL literature, where the underlying communication channels are assumed to be error-free. We show via examples that the joint policy learned using the proposed framework is superior to that where the communication is considered separately from the underlying MA-POMDP. This is a very powerful framework, which has many real world applications, from autonomous vehicle planning to drone swarm control, and opens up the rich toolbox of deep reinforcement learning for the design of multi-user communication systems.",autonomous vehicle
10.1109/FormaliSE.2019.00012,to_check,2019 IEEE/ACM 7th International Conference on Formal Methods in Software Engineering (FormaliSE),IEEE,2019-05-27 00:00:00,ieeexplore,Parallelizable Reachability Analysis Algorithms for Feed-Forward Neural Networks,https://ieeexplore.ieee.org/document/8807491/,"Artificial neural networks (ANN) have displayed considerable utility in a wide range of applications such as image processing, character and pattern recognition, self-driving cars, evolutionary robotics, and non-linear system identification and control. While ANNs are able to carry out complicated tasks efficiently, they are susceptible to unpredictable and errant behavior due to irregularities that emanate from their complex non-linear structure. As a result, there have been reservations about incorporating them into safety-critical systems. In this paper, we present a reachability analysis method for feed-forward neural networks (FNN) that employ rectified linear units (ReLUs) as activation functions. The crux of our approach relies on three reachable-set computation algorithms, namely exact schemes, lazy-approximate schemes, and mixing schemes. The exact scheme computes an exact reachable set for FNN, while the lazy-approximate and mixing schemes generate an over-approximation of the exact reachable set. All schemes are designed efficiently to run on parallel platforms to reduce the computation time and enhance the scalability. Our methods are implemented in a toolbox called, NNV, and is evaluated using a set of benchmarks that consist of realistic neural networks with sizes that range from tens to a thousand neurons. Notably, NNV successfully computes and visualizes the exact reachable sets of the real world ACAS Xu deep neural networks (DNNs), which are a variant of a family of novel airborne collision detection systems known as the ACAS System X, using a representation of tens to hundreds of polyhedra.",autonomous vehicle
10.1109/ICCCNT.2018.8493745,to_check,"2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)",IEEE,2018-07-12 00:00:00,ieeexplore,Synthetic to Real World Image Translation Using Generative Adversarial Networks,https://ieeexplore.ieee.org/document/8493745/,In this paper we perform synthetic to real world image translation using Cycle Consistent Adversarial Networks and further provide insights as to how the translation can be utilized to build a framework that can solve a plethora of domain adaptation tasks by reducing the same to a supervised problem via image generation and label transfer from a source domain (synthetic images) to a target domain (real world images) thereby eliminating the need for a labeled target domain dataset. We run experiments taking the (GTA) dataset as the source domain and the Cityscape dataset as the target domain and provide a comprehensive evaluation of the experiments. We also provide analysis and visualization of existing domain adaptation techniques and evaluate their pros and cons. A potential application of the concept is in training of self-driving cars as it is difficult to obtain an extensive labeled dataset for every geographical region.,autonomous vehicle
10.1109/IROS.2018.8594090,to_check,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2018-10-05 00:00:00,ieeexplore,End to End Vehicle Lateral Control Using a Single Fisheye Camera,https://ieeexplore.ieee.org/document/8594090/,"Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348690,to_check,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,Fully Convolutional Neural Networks for Automotive Radar Interference Mitigation,https://ieeexplore.ieee.org/document/9348690/,"The interest of the automotive industry has progressively focused on subjects related to driver assistance systems as well as autonomous cars. Cars combine a variety of sensors to perceive their surroundings robustly. Among them, radar sensors are indispensable because of their independence of lighting conditions and the possibility to directly measure velocity. However, radar interference is an issue that becomes prevalent with the increasing amount of radar systems in automotive scenarios. In this paper, we address this issue for frequency modulated continuous wave (FMCW) radars with fully convolutional neural networks (FCNs), a state-of-the-art deep learning technique. We propose two FCNs that take spectrograms of the beat signals as input, and provide the corresponding clean range profiles as output. We propose two architectures for interference mitigation which outperform the classical zeroing technique. Moreover, considering the lack of databases for this task, we release as open source a large scale data set that closely replicates real world automotive scenarios for single-interference cases, allowing others to objectively compare their future work in this domain. The data set is available for download at: http://github.com/ristea/arim.",autonomous vehicle
10.1109/3DV50981.2020.00113,to_check,2020 International Conference on 3D Vision (3DV),IEEE,2020-11-28 00:00:00,ieeexplore,MaskNet: A Fully-Convolutional Network to Estimate Inlier Points,https://ieeexplore.ieee.org/document/9320103/,"Point clouds have grown in importance in the way computers perceive the world. From LIDAR sensors in autonomous cars and drones to the time of flight and stereo vision systems in our phones, point clouds are everywhere. Despite their ubiquity, point clouds in the real world are often missing points because of sensor limitations or occlusions, or contain extraneous points from sensor noise or artifacts. These problems challenge algorithms that require computing correspondences between a pair of point clouds. Therefore, this paper presents a fully-convolutional neural network that identifies which points in one point cloud are most similar (inliers) to the points in another. We show improvements in learning-based and classical point cloud registration approaches when retrofitted with our network. We demonstrate these improvements on synthetic and real-world datasets. Finally, our network produces impressive results on test datasets that were unseen during training, thus exhibiting generalizability. Code and videos are available at https://github.com/vinits5/masknet.",autonomous vehicle
10.1109/ICCC51575.2020.9345035,to_check,2020 IEEE 6th International Conference on Computer and Communications (ICCC),IEEE,2020-12-14 00:00:00,ieeexplore,Artificial Intelligence Security Issues and Responses,https://ieeexplore.ieee.org/document/9345035/,"As a current disruptive and transformative technology, artificial intelligence is constantly infiltrating all aspects of production and life. However, with the in-depth development and application of artificial intelligence, the security challenges it faces have become more and more prominent. In the real world, attacks against intelligent systems such as the Internet of Things, smart homes, and driverless cars are constantly appearing, and incidents of artificial intelligence being used in cyber-attacks and cybercrimes frequently occur. This article aims to discuss artificial intelligence security issues and propose some countermeasures.",autonomous vehicle
10.1109/ICRAE48301.2019.9043821,to_check,2019 4th International Conference on Robotics and Automation Engineering (ICRAE),IEEE,2019-11-24 00:00:00,ieeexplore,An Improved Method Based on Deep Reinforcement Learning for Target Searching,https://ieeexplore.ieee.org/document/9043821/,"Unmanned Aerial Vehicle (UAV), due to their high mobility and the ability to cover areas of different heights and locations at relatively low cost, are increasingly used for disaster monitoring and detecting. However, developing and testing UAVs in real world is an expensive task, especially in the domain of search and rescue, most of the previous systems are developed on the basis of greedy or potential-based heuristics without neural network. On the basis of the recent development of deep neural network architecture and deep reinforcement learning (DRL), in this research we improved the probability of success rate of searching target in an unstructured environment by combining image processing algorithms and reinforcement learning methods (RL). This paper aims at the deficiency of target tracking in unstructured environment, trying to propose an algorithm of stationary target positioning of UAV based on computer vision system. Firstly, a new input source is formed by acquiring depth information image of current environment and combining segmentation image. Secondly, the DQN algorithm is used to regulate the reinforcement learning model, and the specific flight response can be independently selected by the UAV through training. This paper utilizes open-source Microsoft UAV simulator AirSim as training and test environment based with Keras a machine learning framework. The main approach investigated in this research is modifying the network of Deep Q-Network, which designs the moving target tracking experiment of UAV in simulation scene. The experimental results demonstrate that this method has better tracking effect.",autonomous vehicle
10.1109/ICUAS51884.2021.9476867,to_check,2021 International Conference on Unmanned Aircraft Systems (ICUAS),IEEE,2021-06-18 00:00:00,ieeexplore,RF Detection and Classification of Unmanned Aerial Vehicles in Environments with Wireless Interference,https://ieeexplore.ieee.org/document/9476867/,"Unmanned Aerial Vehicle (UAV) detection and classification methods include the use of audio, video, thermal, RADAR and radio frequency (RF) signals. RF signals have the ability to detect UAVs at longer ranges but interference from other signals in the same frequency band such as Bluetooth and Wi-Fi at 2.4GHz is a known limitation. The experiments in this paper evaluate the effect of real world Bluetooth and Wi-Fi signal interference on UAV detection and classification, using transfer learning via Convolutional Neural Network (CNN) feature extraction and machine learning classifiers Logistic Regression (LR) and k Nearest Neighbour (kNN). 2 class UAV detection, 4 class UAV type and 10 class flight mode classification are evaluated with graphical representation from the time and frequency domain. Flight modes evaluated included mode 1 - switched on and connected to the controller, mode 2 - hovering and mode 3 - flying. Results show that Bluetooth signals are more likely to interfere with detection and classification accuracy than Wi-Fi signals but that accuracy can be maintained at over 96% by using frequency domain features with LR as the classifier. Time domain features were shown to be less robust than frequency domain features when interefence signals were introduced. In the presence of Bluetooth or Wi-Fi signals, 2 class UAV detection produced 100% accuracy, 4 class UAV type classification produced 99.9% (+/- 0.1%) and 10 class UAV flight mode classification produced 96.4% (+/- 0.5%) accuracy. Overall we have shown frequency domain features extracted from a CNN to be more robust than time domain features in the presence of interference and that high accuracy can be maintained using LR as a classifier with CNN derived features.",autonomous vehicle
http://arxiv.org/abs/2005.13976v1,to_check,arxiv,arxiv,2020-05-22 19:00:38+00:00,arxiv,"Towards Automated Safety Coverage and Testing for Autonomous Vehicles
  with Reinforcement Learning",http://arxiv.org/abs/2005.13976v1,"The kind of closed-loop verification likely to be required for autonomous
vehicle (AV) safety testing is beyond the reach of traditional test
methodologies and discrete verification. Validation puts the autonomous vehicle
system to the test in scenarios or situations that the system would likely
encounter in everyday driving after its release. These scenarios can either be
controlled directly in a physical (closed-course proving ground) or virtual
(simulation of predefined scenarios) environment, or they can arise
spontaneously during operation in the real world (open-road testing or
simulation of randomly generated scenarios).
  In AV testing, simulation serves primarily two purposes: to assist the
development of a robust autonomous vehicle and to test and validate the AV
before release. A challenge arises from the sheer number of scenario variations
that can be constructed from each of the above sources due to the high number
of variables involved (most of which are continuous). Even with continuous
variables discretized, the possible number of combinations becomes practically
infeasible to test. To overcome this challenge we propose using reinforcement
learning (RL) to generate failure examples and unexpected traffic situations
for the AV software implementation. Although reinforcement learning algorithms
have achieved notable results in games and some robotic manipulations, this
technique has not been widely scaled up to the more challenging real world
applications like autonomous driving.",autonomous vehicle
http://arxiv.org/abs/2010.05436v1,to_check,arxiv,arxiv,2020-10-12 03:52:10+00:00,arxiv,"Leveraging the Capabilities of Connected and Autonomous Vehicles and
  Multi-Agent Reinforcement Learning to Mitigate Highway Bottleneck Congestion",http://arxiv.org/abs/2010.05436v1,"Active Traffic Management strategies are often adopted in real-time to
address such sudden flow breakdowns. When queuing is imminent, Speed
Harmonization (SH), which adjusts speeds in upstream traffic to mitigate
traffic showckwaves downstream, can be applied. However, because SH depends on
driver awareness and compliance, it may not always be effective in mitigating
congestion. The use of multiagent reinforcement learning for collaborative
learning, is a promising solution to this challenge. By incorporating this
technique in the control algorithms of connected and autonomous vehicle (CAV),
it may be possible to train the CAVs to make joint decisions that can mitigate
highway bottleneck congestion without human driver compliance to altered speed
limits. In this regard, we present an RL-based multi-agent CAV control model to
operate in mixed traffic (both CAVs and human-driven vehicles (HDVs)). The
results suggest that even at CAV percent share of corridor traffic as low as
10%, CAVs can significantly mitigate bottlenecks in highway traffic. Another
objective was to assess the efficacy of the RL-based controller vis-\`a-vis
that of the rule-based controller. In addressing this objective, we duly
recognize that one of the main challenges of RL-based CAV controllers is the
variety and complexity of inputs that exist in the real world, such as the
information provided to the CAV by other connected entities and sensed
information. These translate as dynamic length inputs which are difficult to
process and learn from. For this reason, we propose the use of Graphical
Convolution Networks (GCN), a specific RL technique, to preserve information
network topology and corresponding dynamic length inputs. We then use this,
combined with Deep Deterministic Policy Gradient (DDPG), to carry out
multi-agent training for congestion mitigation using the CAV controllers.",autonomous vehicle
http://arxiv.org/abs/2009.14551v2,to_check,arxiv,arxiv,2020-09-30 10:40:44+00:00,arxiv,Explainable Deep Reinforcement Learning for UAV Autonomous Navigation,http://arxiv.org/abs/2009.14551v2,"Autonomous navigation in unknown complex environment is still a hard problem,
especially for small Unmanned Aerial Vehicles (UAVs) with limited computation
resources. In this paper, a neural network-based reactive controller is
proposed for a quadrotor to fly autonomously in unknown outdoor environment.
The navigation controller makes use of only current sensor data to generate the
control signal without any optimization or configuration space searching, which
reduces both memory and computation requirement. The navigation problem is
modelled as a Markov Decision Process (MDP) and solved using deep reinforcement
learning (DRL) method. Specifically, to get better understanding of the trained
network, some model explanation methods are proposed. Based on the feature
attribution, each decision making result during flight is explained using both
visual and texture explanation. Moreover, some global analysis are also
provided for experts to evaluate and improve the trained neural network. The
simulation results illustrated the proposed method can make useful and
reasonable explanation for the trained model, which is beneficial for both
non-expert users and controller designer. Finally, the real world tests shown
the proposed controller can navigate the quadrotor to goal position
successfully and the reactive controller performs much faster than some
conventional approach under the same computation resource.",autonomous vehicle
http://arxiv.org/abs/2007.11102v1,to_check,arxiv,arxiv,2020-07-21 21:33:26+00:00,arxiv,"Fully Convolutional Neural Networks for Automotive Radar Interference
  Mitigation",http://arxiv.org/abs/2007.11102v1,"The interest of the automotive industry has progressively focused on subjects
related to driver assistance systems as well as autonomous cars. Cars combine a
variety of sensors to perceive their surroundings robustly. Among them, radar
sensors are indispensable because of their independence of lighting conditions
and the possibility to directly measure velocity. However, radar interference
is an issue that becomes prevalent with the increasing amount of radar systems
in automotive scenarios. In this paper, we address this issue for frequency
modulated continuous wave (FMCW) radars with fully convolutional neural
networks (FCNs), a state-of-the-art deep learning technique. We propose two
FCNs that take spectrograms of the beat signals as input, and provide the
corresponding clean range profiles as output. We propose two architectures for
interference mitigation which outperform the classical zeroing technique.
Moreover, considering the lack of databases for this task, we release as open
source a large scale data set that closely replicates real world automotive
scenarios for single-interference cases, allowing others to objectively compare
their future work in this domain. The data set is available for download at:
http://github.com/ristea/arim.",autonomous vehicle
http://arxiv.org/abs/1808.06940v1,to_check,arxiv,arxiv,2018-08-20 09:25:30+00:00,arxiv,End to End Vehicle Lateral Control Using a Single Fisheye Camera,http://arxiv.org/abs/1808.06940v1,"Convolutional neural networks are commonly used to control the steering angle
for autonomous cars. Most of the time, multiple long range cameras are used to
generate lateral failure cases. In this paper we present a novel model to
generate this data and label augmentation using only one short range fisheye
camera. We present our simulator and how it can be used as a consistent metric
for lateral end-to-end control evaluation. Experiments are conducted on a
custom dataset corresponding to more than 10000 km and 200 hours of open road
driving. Finally we evaluate this model on real world driving scenarios, open
road and a custom test track with challenging obstacle avoidance and sharp
turns. In our simulator based on real-world videos, the final model was capable
of more than 99% autonomy on urban road",autonomous vehicle
http://arxiv.org/abs/2010.09185v1,to_check,arxiv,arxiv,2020-10-19 03:18:35+00:00,arxiv,MaskNet: A Fully-Convolutional Network to Estimate Inlier Points,http://arxiv.org/abs/2010.09185v1,"Point clouds have grown in importance in the way computers perceive the
world. From LIDAR sensors in autonomous cars and drones to the time of flight
and stereo vision systems in our phones, point clouds are everywhere. Despite
their ubiquity, point clouds in the real world are often missing points because
of sensor limitations or occlusions, or contain extraneous points from sensor
noise or artifacts. These problems challenge algorithms that require computing
correspondences between a pair of point clouds. Therefore, this paper presents
a fully-convolutional neural network that identifies which points in one point
cloud are most similar (inliers) to the points in another. We show improvements
in learning-based and classical point cloud registration approaches when
retrofitted with our network. We demonstrate these improvements on synthetic
and real-world datasets. Finally, our network produces impressive results on
test datasets that were unseen during training, thus exhibiting
generalizability. Code and videos are available at
https://github.com/vinits5/masknet",autonomous vehicle
http://arxiv.org/abs/2011.05617v1,to_check,arxiv,arxiv,2020-11-11 08:17:08+00:00,arxiv,Sim-To-Real Transfer for Miniature Autonomous Car Racing,http://arxiv.org/abs/2011.05617v1,"Sim-to-real, a term that describes where a model is trained in a simulator
then transferred to the real world, is a technique that enables faster deep
reinforcement learning (DRL) training. However, differences between the
simulator and the real world often cause the model to perform poorly in the
real world. Domain randomization is a way to bridge the sim-to-real gap by
exposing the model to a wide range of scenarios so that it can generalize to
real-world situations. However, following domain randomization to train an
autonomous car racing model with DRL can lead to undesirable outcomes. Namely,
a model trained with randomization tends to run slower; a higher completion
rate on the testing track comes at the expense of longer lap times. This paper
aims to boost the robustness of a trained race car model without compromising
racing lap times. For a training track and a testing track having the same
shape (and same optimal paths), but with different lighting, background, etc.,
we first train a model (teacher model) that overfits the training track, moving
along a near optimal path. We then use this model to teach a student model the
correct actions along with randomization. With our method, a model with 18.4\%
completion rate on the testing track is able to help teach a student model with
52\% completion. Moreover, over an average of 50 trials, the student is able to
finish a lap 0.23 seconds faster than the teacher. This 0.23 second gap is
significant in tight races, with lap times of about 10 to 12 seconds.",autonomous vehicle
http://arxiv.org/abs/2003.07739v2,to_check,arxiv,arxiv,2020-03-17 14:17:52+00:00,arxiv,"Formal Scenario-Based Testing of Autonomous Vehicles: From Simulation to
  the Real World",http://arxiv.org/abs/2003.07739v2,"We present a new approach to automated scenario-based testing of the safety
of autonomous vehicles, especially those using advanced artificial
intelligence-based components, spanning both simulation-based evaluation as
well as testing in the real world. Our approach is based on formal methods,
combining formal specification of scenarios and safety properties, algorithmic
test case generation using formal simulation, test case selection for track
testing, executing test cases on the track, and analyzing the resulting data.
Experiments with a real autonomous vehicle at an industrial testing facility
support our hypotheses that (i) formal simulation can be effective at
identifying test cases to run on the track, and (ii) the gap between simulated
and real worlds can be systematically evaluated and bridged.",autonomous vehicle
http://arxiv.org/abs/2107.11762v1,to_check,arxiv,arxiv,2021-07-25 09:15:46+00:00,arxiv,"DR2L: Surfacing Corner Cases to Robustify Autonomous Driving via Domain
  Randomization Reinforcement Learning",http://arxiv.org/abs/2107.11762v1,"How to explore corner cases as efficiently and thoroughly as possible has
long been one of the top concerns in the context of deep reinforcement learning
(DeepRL) autonomous driving. Training with simulated data is less costly and
dangerous than utilizing real-world data, but the inconsistency of parameter
distribution and the incorrect system modeling in simulators always lead to an
inevitable Sim2real gap, which probably accounts for the underperformance in
novel, anomalous and risky cases that simulators can hardly generate. Domain
Randomization(DR) is a methodology that can bridge this gap with little or no
real-world data. Consequently, in this research, an adversarial model is put
forward to robustify DeepRL-based autonomous vehicles trained in simulation to
gradually surfacing harder events, so that the models could readily transfer to
the real world.",autonomous vehicle
http://arxiv.org/abs/2101.10369v2,to_check,arxiv,arxiv,2021-01-02 10:43:41+00:00,arxiv,"Effective Communications: A Joint Learning and Communication Framework
  for Multi-Agent Reinforcement Learning over Noisy Channels",http://arxiv.org/abs/2101.10369v2,"We propose a novel formulation of the ""effectiveness problem"" in
communications, put forth by Shannon and Weaver in their seminal work [2], by
considering multiple agents communicating over a noisy channel in order to
achieve better coordination and cooperation in a multi-agent reinforcement
learning (MARL) framework. Specifically, we consider a multi-agent partially
observable Markov decision process (MA-POMDP), in which the agents, in addition
to interacting with the environment can also communicate with each other over a
noisy communication channel. The noisy communication channel is considered
explicitly as part of the dynamics of the environment and the message each
agent sends is part of the action that the agent can take. As a result, the
agents learn not only to collaborate with each other but also to communicate
""effectively"" over a noisy channel. This framework generalizes both the
traditional communication problem, where the main goal is to convey a message
reliably over a noisy channel, and the ""learning to communicate"" framework that
has received recent attention in the MARL literature, where the underlying
communication channels are assumed to be error-free. We show via examples that
the joint policy learned using the proposed framework is superior to that where
the communication is considered separately from the underlying MA-POMDP. This
is a very powerful framework, which has many real world applications, from
autonomous vehicle planning to drone swarm control, and opens up the rich
toolbox of deep reinforcement learning for the design of multi-user
communication systems.",autonomous vehicle
http://arxiv.org/abs/2007.02203v6,to_check,arxiv,arxiv,2020-07-04 23:00:52+00:00,arxiv,"Accuracy-Efficiency Trade-Offs and Accountability in Distributed ML
  Systems",http://arxiv.org/abs/2007.02203v6,"Trade-offs between accuracy and efficiency pervade law, public health, and
other non-computing domains, which have developed policies to guide how to
balance the two in conditions of uncertainty. While computer science also
commonly studies accuracy-efficiency trade-offs, their policy implications
remain poorly examined. Drawing on risk assessment practices in the US, we
argue that, since examining these trade-offs has been useful for guiding
governance in other domains, we need to similarly reckon with these trade-offs
in governing computer systems. We focus our analysis on distributed machine
learning systems. Understanding the policy implications in this area is
particularly urgent because such systems, which include autonomous vehicles,
tend to be high-stakes and safety-critical. We 1) describe how the trade-off
takes shape for these systems, 2) highlight gaps between existing US risk
assessment standards and what these systems require to be properly assessed,
and 3) make specific calls to action to facilitate accountability when
hypothetical risks concerning the accuracy-efficiency trade-off become realized
as accidents in the real world. We close by discussing how such accountability
mechanisms encourage more just, transparent governance aligned with public
values.",autonomous vehicle
http://arxiv.org/abs/2010.04331v3,to_check,arxiv,arxiv,2020-10-09 02:31:34+00:00,arxiv,"Targeted Physical-World Attention Attack on Deep Learning Models in Road
  Sign Recognition",http://arxiv.org/abs/2010.04331v3,"Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.",autonomous vehicle
http://arxiv.org/abs/2012.10672v2,to_check,arxiv,arxiv,2020-12-19 12:26:06+00:00,arxiv,RMT: Rule-based Metamorphic Testing for Autonomous Driving Models,http://arxiv.org/abs/2012.10672v2,"Deep neural network models are widely used for perception and control in
autonomous driving. Recent work uses metamorphic testing but is limited to
using equality-based metamorphic relations and does not provide expressiveness
for defining inequality-based metamorphic relations. To encode real world
traffic rules, domain experts must be able to express higher order relations
e.g., a vehicle should decrease speed in certain ratio, when there is a vehicle
x meters ahead and compositionality e.g., a vehicle must have a larger
deceleration, when there is a vehicle ahead and when the weather is rainy and
proportional compounding effect to the test outcome. We design RMT, a
declarative rule-based metamorphic testing framework. It provides three
components that work in concert:(1) a domain specific language that enables an
expert to express higher-order, compositional metamorphic relations, (2)
pluggable transformation engines built on a variety of image and graphics
processing techniques, and (3) automated test generation that translates a
human-written rule to a corresponding executable, metamorphic relation and
synthesizes meaningful inputs.Our evaluation using three driving models shows
that RMT can generate meaningful test cases on which 89% of erroneous
predictions are found by enabling higher-order metamorphic relations.
Compositionality provides further aids for generating meaningful, synthesized
inputs-3012 new images are generated by compositional rules. These detected
erroneous predictions are manually examined and confirmed by six human judges
as meaningful traffic rule violations. RMT is the first to expand automated
testing capability for autonomous vehicles by enabling easy mapping of traffic
regulations to executable metamorphic relations and to demonstrate the benefits
of expressivity, customization, and pluggability.",autonomous vehicle
10.1016/j.inffus.2021.09.017,to_check,Information Fusion,sciencedirect,2022-02-28,sciencedirect,"On the use of information fusion techniques to improve information quality: Taxonomy, opportunities and challenges",https://api.elsevier.com/content/article/pii/S1566253521001925,"
                  The information fusion field has recently been attracting a lot of interest within the scientific community, as it provides, through the combination of different sources of heterogeneous information, a fuller and/or more precise understanding of the real world than can be gained considering the above sources separately. One of the fundamental aims of computer systems, and especially decision support systems, is to assure that the quality of the information they process is high. There are many different approaches for this purpose, including information fusion. Information fusion is currently one of the most promising methods. It is particularly useful under circumstances where quality might be compromised, for example, either intrinsically due to imperfect information (vagueness, uncertainty, â€¦) or because of limited resources (energy, time, â€¦). In response to this goal, a wide range of research has been undertaken over recent years. To date, the literature reviews in this field have focused on problem-specific issues and have been circumscribed to certain system types. Therefore, there is no holistic and systematic knowledge of the state of the art to help establish the steps to be taken in the future. In particular, aspects like what impact different information fusion methods have on information quality, how information quality is characterised, measured and evaluated in different application domains depending on the problem data type or whether fusion is designed as a flexible process capable of adapting to changing system circumstances and their intrinsically limited resources have not been addressed. This paper aims precisely to review the literature on research into the use of information fusion techniques specifically to improve information quality, analysing the above issues in order to identify a series of challenges and research directions, which are presented in this paper.
               ",autonomous vehicle
10.1145/3125503.3125568,to_check,2017 International Conference on Embedded Software (EMSOFT),IEEE,2017-10-20 00:00:00,ieeexplore,Work-in-progress: testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks,https://ieeexplore.ieee.org/document/8094374/,Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional filters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator.,autonomous vehicle
10.1109/ICComm.2018.8484837,to_check,2018 International Conference on Communications (COMM),IEEE,2018-06-16 00:00:00,ieeexplore,Modelling Smart Mobile Robotic Networks from a Cyber Physical System Perspective,https://ieeexplore.ieee.org/document/8484837/,"Mobile robotic network (MRN) consists of a group of robotic nodes (such as mobile sensors, unmanned vehicles, UAVs and mobile robots) that can communicate with each other for collaboration, in which motion control and communication will both play crucial roles. With recent advances in artificial intelligence, robotic nodes are becoming smart with more powerful computational capability. Therefore, there appears a strong trend to integrally design MRNs from these three aspects: motion control, communication and computation. Cyber physical system that bridges the cyber world of communication and computation with the physical world of motion control provides us a new perspective to MRNs. In this research, we analyze the tight integration and coupling of these cyber physical aspects in MRNs, and provide a framework to specify the effect of each aspect and the transitions among them in terms of their contributions to the network performance. We use illustrative examples of flock motion, topology motion and ad hoc networking in MRNs to demonstrate the framework.",autonomous vehicle
10.1007/978-3-030-60467-7_7,to_check,Innovation and Research,Springer,2021-01-01 00:00:00,springer,Intelligent and Autonomous Guidance Through a Geometric Model for Conventional Vehicles,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60467-7_7,"Cyber-physical systems (CPS) in the automobile industry are facing major challenges related to the use and validation of these CPS, which entails high costs in the implementation and training tests in the physical world, thus limiting research. Therefore, there is a need to shorten the validation times of these CPS with the use of 3D simulation software. This research article proposes to simulate a CPS in the simulation software Webots, with the aim of emulating the autonomous movement of conventional vehicles by integrating a GPS sensor and a compass sensor which provide information on location and orientation, these data are used for the implementation of a geometric model by vectors, the same one that is developed in a controller that allows to take actions on the vehicles in the simulation software in order to emulate an urban traffic. Finally, a series of configurations have been made to evaluate the geometric model, managing to maintain the default speed of 94.194% with curves greater than 90 degrees. In addition, the validation of this system in a real environment through the instrumentation in land vehicles is drawn as future lines.",autonomous vehicle
http://arxiv.org/abs/1812.10812v1,to_check,arxiv,arxiv,2018-12-27 19:55:54+00:00,arxiv,"DeepBillboard: Systematic Physical-World Testing of Autonomous Driving
  Systems",http://arxiv.org/abs/1812.10812v1,"Deep Neural Networks (DNNs) have been widely applied in many autonomous
systems such as autonomous driving. Recently, DNN testing has been intensively
studied to automatically generate adversarial examples, which inject
small-magnitude perturbations into inputs to test DNNs under extreme
situations. While existing testing techniques prove to be effective, they
mostly focus on generating digital adversarial perturbations (particularly for
autonomous driving), e.g., changing image pixels, which may never happen in
physical world. There is a critical missing piece in the literature on
autonomous driving testing: understanding and exploiting both digital and
physical adversarial perturbation generation for impacting steering decisions.
In this paper, we present DeepBillboard, a systematic physical-world testing
approach targeting at a common and practical driving scenario: drive-by
billboards. DeepBillboard is capable of generating a robust and resilient
printable adversarial billboard, which works under dynamic changing driving
conditions including viewing angle, distance, and lighting. The objective is to
maximize the possibility, degree, and duration of the steering-angle errors of
an autonomous vehicle driving by the generated adversarial billboard. We have
extensively evaluated the efficacy and robustness of DeepBillboard through
conducting both digital and physical-world experiments. Results show that
DeepBillboard is effective for various steering models and scenes. Furthermore,
DeepBillboard is sufficiently robust and resilient for generating
physical-world adversarial billboard tests for real-world driving under various
weather conditions. To the best of our knowledge, this is the first study
demonstrating the possibility of generating realistic and continuous
physical-world tests for practical autonomous driving systems.",autonomous vehicle
