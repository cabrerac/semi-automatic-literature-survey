doi,type,query_name,query_value,publication,publisher,publication_date,database,title,url,abstract,status,id,semantic_score
10.1016/j.giq.2022.101722,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85132505364,scopus,10/1/2022,scopus,public ai canvas for ai-enabled public value: a design science approach,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85132505364&origin=inward,"
                  Public agencies have a strong interest in artificial intelligence (AI) systems. However, many public agencies lack tools and frameworks to articulate a viable business model and evaluate public value as they consider investing in AI systems. The business model canvas used extensively in the private sector offers us a foundation for designing a public AI canvas (PAIC). Employing a design science approach, this study reports on the design and evaluation of PAIC. The PAIC comprises three distinctive layers: (1) the public value-oriented AI-enablement layer; (2) the public value logic layer; and (3) the public value-oriented social guidance layer. PAIC offers guidance on innovating the business models of public agencies to create and capture AI-enabled value. For practitioners, PAIC presents a validated tool to guide AI deployment in public agencies.
               ",included,8594,0.9426229
10.1007/s44163-024-00118-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Discover Artificial Intelligence,Springer,3/26/2024 0:00,springer,ai: the future of humanity,http://dx.doi.org/10.1007/s44163-024-00118-3,"Artificial intelligence (AI) is reshaping humanity's future, and this manuscript provides a comprehensive exploration of its implications, applications, challenges, and opportunities. The revolutionary potential of AI is investigated across numerous sectors, with a focus on addressing global concerns. The influence of AI on areas such as healthcare, transportation, banking, and education is revealed through historical insights and conversations on different AI systems. Ethical considerations and the significance of responsible AI development are addressed. Furthermore, this study investigates AI's involvement in addressing global issues such as climate change, public health, and social justice. This paper serves as a resource for policymakers, researchers, and practitioners understanding the complex link between AI and humans.",not included,1087,0.908905804
10.1017/dap.2024.13,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Data & Policy,1/1/2000 0:00,semantic_scholar,exploring citizens’ stances on ai in public services: a social contract perspective,https://www.semanticscholar.org/paper/58b7ea14464538f5a7ea31df0e518df1c3efd0e6,"Abstract This paper explores citizens’ stances toward the use of artificial intelligence (AI) in public services in Norway. Utilizing a social contract perspective, the study analyzes the government–citizen relationship at macro, meso, and micro levels. A prototype of an AI-enabled public welfare service was designed and presented to 20 participants who were interviewed to investigate their stances on the described AI use. We found a generally positive attitude and identified three factors contributing to this: (a) the high level of trust in government (macro level); (b) the balanced value proposition between individual and collective needs (meso level); and (c) the reassurance provided by having humans in the loop and providing transparency into processes, data, and model’s logic (microlevel). The findings provide valuable insights into citizens’ stances for socially responsible AI in public services. These insights can inform policy and guide the design and implementation of AI systems in the public sector by foregrounding the government–citizen relationship.",included,123,0.902136505
10.1109/mc.2020.3010043,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Computer,1/1/2020 0:00,semantic_scholar,artificial intelligence in government,https://www.semanticscholar.org/paper/5bca0d47912b214890e9ca6ee7a76f4deb8de815,"The articles in this special section focus on government applications that use artificial intelligence (AI). The repercussions of artificial intelligence (AI) in government are broad and significant. The characteristics of these technologies will have an impact on almost everything in public organizations, from governance or the multidimensional perspective of interoperability, to the organizational or social implications linked to concepts like public value, transparency, or accountability. This special issue seeks to shed light on foundations and key elements to be taken into account for AI adoption by public organizations. Governments are the primary enablers of technology and market stimulators and regulators of general activities in our society. Governments have always sought the common good and, therefore, the advancement of public and collective interests. This is key to understanding, as a first step, why the principles of public-sector organizations do not always match those of the private sector. Public and private perspectives are very different, whether they be management, strategy, or policy.",included,13,0.901898623
10.1007/s00146-022-01450-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2023 0:00,springer,"artificial intelligence in local governments: perceptions of city managers on prospects, constraints and choices",http://dx.doi.org/10.1007/s00146-022-01450-x,"Highly sophisticated capabilities of artificial intelligence (AI) have skyrocketed its popularity across many industry sectors globally. The public sector is one of these. Many cities around the world are trying to position themselves as leaders of urban innovation through the development and deployment of AI systems. Likewise, increasing numbers of local government agencies are attempting to utilise AI technologies in their operations to deliver policy and generate efficiencies in highly uncertain and complex urban environments. While the popularity of AI is on the rise in urban policy circles, there is limited understanding and lack of empirical studies on the city manager perceptions concerning urban AI systems. Bridging this gap is the rationale of this study. The methodological approach adopted in this study is twofold. First, the study collects data through semi-structured interviews with city managers from Australia and the US. Then, the study analyses the data using the summative content analysis technique with two data analysis software. The analysis identifies the following themes and generates insights into local government services: AI adoption areas, cautionary areas, challenges, effects, impacts, knowledge basis, plans, preparedness, roadblocks, technologies, deployment timeframes, and usefulness. The study findings inform city managers in their efforts to deploy AI in their local government operations, and offer directions for prospective research.",not included,2051,0.900574088
10.59476/ilpmt2024.100-106,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Innovations in Publishing, Printing and Multimedia Technologies",1/1/2000 0:00,semantic_scholar,criteria for selecting artificial intelligence tools,https://www.semanticscholar.org/paper/2d88f0f218151f6f38f3888024ccff9e8c3ed0f7,"Artificial Intelligence (AI) represents a transformative force across numerous sectors, from healthcare and finance to automotive and public services. The selection and deployment of AI tools are critical to leveraging this technology’s potential while adhering to ethical standards, regulatory compliance, and ensuring societal benefit. The European Union (EU) has been at the forefront of establishing frameworks and criteria to guide the development, deployment, and selection of AI systems to foster innovation while protecting citizens’ rights and societal values. The EU’s proactive stance in establishing these criteria aims to balance innovation with ethical considerations and societal welfare, setting a benchmark for responsible AI development and deployment globally. The aim of the article is to present general criteria for the selection of artificial intelligence tools, as well as those specific to the field of publishing. The research was carried out based on the analysis of scientific and other sources. The results of the study can be useful for organizations and individuals that must be interested in selecting and using the right AI tools.",included,125,0.899820447
10.1007/s11948-020-00276-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Science and Engineering Ethics,Springer,12/1/2020 0:00,springer,towards transparency by design for artificial intelligence,http://dx.doi.org/10.1007/s11948-020-00276-4,"In this article, we develop the concept of Transparency by Design that serves as practical guidance in helping promote the beneficial functions of transparency while mitigating its challenges in automated-decision making (ADM) environments. With the rise of artificial intelligence (AI) and the ability of AI systems to make automated and self-learned decisions, a call for transparency of how such systems reach decisions has echoed within academic and policy circles. The term transparency, however, relates to multiple concepts, fulfills many functions, and holds different promises that struggle to be realized in concrete applications. Indeed, the complexity of transparency for ADM shows tension between transparency as a normative ideal and its translation to practical application. To address this tension, we first conduct a review of transparency, analyzing its challenges and limitations concerning automated decision-making practices. We then look at the lessons learned from the development of Privacy by Design, as a basis for developing the Transparency by Design principles. Finally, we propose a set of nine principles to cover relevant contextual, technical, informational, and stakeholder-sensitive considerations. Transparency by Design is a model that helps organizations design transparent AI systems, by integrating these principles in a step-by-step manner and as an ex-ante value, not as an afterthought.",included,4083,0.899173975
10.1007/s12626-023-00146-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',The Review of Socionetwork Strategies,Springer,10/1/2023 0:00,springer,role of regulatory sandboxes and mlops for ai-enabled public sector services,http://dx.doi.org/10.1007/s12626-023-00146-y,"This paper discusses how innovations in public sector AI-based services must comply with the Artificial Intelligence Act (AI Act) regulatory frameworks while enabling experimentation and participation of diverse stakeholders throughout the Artificial Intelligence (AI) lifecycle . The paper examines the implications of the emerging regulation, AI regulatory sandboxes and Machine Learning Operations (MLOps) as tools that facilitate compliance while enabling co-learning and active participation of multiple stakeholders. We propose a framework that fosters experimentation with automation pipelines and continuous monitoring for the deployment of future public sector AI-based services in a regulatory-compliant and technically innovative manner. AI regulatory sandboxes can be beneficial as a space for contained experimentation that goes beyond regulatory considerations to specific experimentation with the implementation of ML frameworks. While the paper presents a framework based on emerging regulations, tools and practices pertaining to the responsible use of AI, this must be validated through pilot experimentation with public and private stakeholders and regulators in different areas of high-risk AI-based services.",included,1693,0.895625412
10.1108/tg-06-2024-0131,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Transforming Government: People, Process and Policy",1/1/2000 0:00,semantic_scholar,"artificial intelligence and decision-making in government functions: opportunities, challenges and future research",https://www.semanticscholar.org/paper/305eeffe0bee53fa400a8ecad024f1c18c1280b8,"Purpose
Artificial intelligence (AI) has received much attention due to its promethean-like powers to transform the management and delivery of public sector services. Due to the proliferation of research articles in this context, research to date is fragmented into research streams based on different types of AI technologies or a specific government function of the public sector (e.g. health, education). The purpose of this study is to synthesize this literature, identify challenges and opportunities, and offer a research agenda that guides future inquiry.

Design/methodology/approach
This paper aggregates this fragmented body of knowledge by conducting a systematic literature review of AI research in public sector organisations in the Chartered Association of Business Schools (CABS)-ranked journals between 2012 and 2023.

Findings
The search strategy resulted in the retrieval of 2,870 papers, of which 61 were identified as primary papers relevant to this research. These primary papers are mapped to the ten classifications of the functions of government as classified by the Organisation for Economic Co-operation and Development (OECD), and the reported challenges and benefits aggregated.

Originality/value
This study advances knowledge by providing a state-of-the-art of AI research based the OECD classifications of government functions, reporting of claimed benefits and challenges and providing a research agenda for future research.
",not included,120,0.894489646
10.1007/s00146-022-01572-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2024 0:00,springer,public procurement of artificial intelligence systems: new risks and future proofing,http://dx.doi.org/10.1007/s00146-022-01572-2,"Public entities around the world are increasingly deploying artificial intelligence (AI) and algorithmic decision-making systems to provide public services or to use their enforcement powers. The rationale for the public sector to use these systems is similar to private sector: increase efficiency and speed of transactions and lower the costs. However, public entities are first and foremost established to meet the needs of the members of society and protect the safety, fundamental rights, and wellbeing of those they serve. Currently AI systems are deployed by the public sector at various administrative levels without robust due diligence, monitoring, or transparency. This paper critically maps out the challenges in procurement of AI systems by public entities and the long-term implications necessitating AI-specific procurement guidelines and processes. This dual-prong exploration includes the new complexities and risks introduced by AI systems, and the institutional capabilities impacting the decision-making process. AI-specific public procurement guidelines are urgently needed to protect fundamental rights and due process.",not included,728,0.893231273
10.1007/s00146-022-01453-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/1/2023 0:00,springer,a principle-based approach to ai: the case for european union and italy,http://dx.doi.org/10.1007/s00146-022-01453-8,"As Artificial Intelligence (AI) becomes more and more pervasive in our everyday life, new questions arise about its ethical and social impacts. Such issues concern all stakeholders involved in or committed to the design, implementation, deployment, and use of the technology. The present document addresses these preoccupations by introducing and discussing a set of practical obligations and recommendations for the development of applications and systems based on AI techniques. With this work we hope to contribute to spreading awareness on the many social challenges posed by AI and encouraging the establishment of good practices throughout the relevant social areas. As points of novelty, the paper elaborates on an integrated view that combines both human rights and ethical concepts to reap the benefits of the two approaches. Moreover, it proposes innovative recommendations, such as those on redress and governance, which add further insight to the debate. Finally, it incorporates a specific focus on the Italian Constitution, thus offering an example of how core legislations of Member States might contribute to further specify and enrich the EU normative framework on AI.",included,2255,0.892573774
10.1007/s00146-020-00960-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2020 0:00,springer,"artificial intelligence, transparency, and public decision-making",http://dx.doi.org/10.1007/s00146-020-00960-w,"The increasing use of Artificial Intelligence (AI) for making decisions in public affairs has sparked a lively debate on the benefits and potential harms of self-learning technologies, ranging from the hopes of fully informed and objectively taken decisions to fear for the destruction of mankind. To prevent the negative outcomes and to achieve accountable systems, many have argued that we need to open up the “black box” of AI decision-making and make it more transparent. Whereas this debate has primarily focused on how transparency can secure high-quality, fair, and reliable decisions, far less attention has been devoted to the role of transparency when it comes to how the general public come to perceive AI decision-making as legitimate and worthy of acceptance. Since relying on coercion is not only normatively problematic but also costly and highly inefficient, perceived legitimacy is fundamental to the democratic system. This paper discusses how transparency in and about AI decision-making can affect the public’s perception of the legitimacy of decisions and decision-makers and produce a framework for analyzing these questions. We argue that a limited form of transparency that focuses on providing justifications for decisions has the potential to provide sufficient ground for perceived legitimacy without producing the harms full transparency would bring.",included,4091,0.891162217
10.1177/09520767231170321,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Policy and Administration,1/1/2000 0:00,semantic_scholar,systematic and axiological capacities in artificial intelligence applied in the public sector,https://www.semanticscholar.org/paper/33be6d7c2d61bfac798a29e22ea0267e9fe16b05,"Artificial Intelligence (AI) as a technological development is being implemented in the public sector with the intention of improving service delivery, as well as to help solve complex problems. However, there is a wide range of capabilities that AI can perform and that public officials perceive and implement in different ways. This paper aims to describe and analyze some categories into which AI capabilities in the public sector are divided. Using an Exploratory Factor Analysis (EFA), our results show that the capabilities of AI from the perspective of public officials can be classified into two aspects: systematic factors and axiological factors. Systematic factors are related to the analysis and behavior of data, including monitoring, analyzing, interacting, remembering, and anticipation. Axiological factors refer to the impacts of values, ethics, and decisions, including acting, feeling, moralizing, creating, and deciding capacities. This categorization of AI capabilities in the public sector sheds light on the perception of public officials about the implementation of this technological development.",included,46,0.890233696
10.1108/dts-03-2023-0018,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Transformation and Society,1/1/2000 0:00,semantic_scholar,"artificial intelligence, task complexity and uncertainty: analyzing the advantages and disadvantages of using algorithms in public service delivery under public administration theories",https://www.semanticscholar.org/paper/34ca9b143e721bfd8dc8eb29d6352a68b9c82a19,"PurposeThis article revisits some theories and concepts of public administration, including those related to public value, transaction costs and social equity, to analyze the advantages and disadvantages of using artificial intelligence (AI) algorithms in public service delivery. The author seeks to mobilize theory to guide AI-era public management practitioners and researchers.Design/methodology/approachThe author uses an existing task classification model to mobilize and juxtapose public management theories against artificial intelligence potential impacts in public service delivery. Theories of social equity and transaction costs as well as some concepts such as red tape, efficiency and economy are used to argue that the discipline of public administration provides a foundation to ensure algorithms are used in a way that improves service delivery.FindingsAfter presenting literature on the challenges and promises of using AI in public service, the study shows that while the adoption of algorithms in public service has benefits, some serious challenges still exist when looked at under the lenses of theory. Additionally, the author mobilizes the public administration concepts of agenda setting and coproduction and finds that designing AI-enabled public services should be centered on citizens who are not mere customers. As an implication for public management practice, this study shows that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Research limitations/implicationsAs a fast-growing subject, artificial intelligence research in public management is yet to empirically test some of the theories that the study presented.Practical implicationsThe paper vulgarizes some theories of public administration which practitioners can consider in the design and implementation of AI-enabled public services. Additionally, the study shows practitioners that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Social implicationsThe paper informs a broad audience who might not be familiar with public administration theories and how those theories can be taken into consideration when adopting AI systems in service delivery.Originality/valueThis research is original, as, to the best of the author’s knowledge, no prior work has combined these concepts in analyzing AI in the public sector.",included,55,0.889954925
http://arxiv.org/abs/2410.01819v1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',arxiv,arxiv,9/16/2024 0:00,arxiv,strategic ai governance: insights from leading nations,http://arxiv.org/abs/2410.01819v1,"Artificial Intelligence (AI) has the potential to revolutionize various
sectors, yet its adoption is often hindered by concerns about data privacy,
security, and the understanding of AI capabilities. This paper synthesizes AI
governance approaches, strategic themes, and enablers and challenges for AI
adoption by reviewing national AI strategies from leading nations. The key
contribution is the development of an EPIC (Education, Partnership,
Infrastructure, Community) framework, which maps AI implementation requirements
to fully realize social impacts and public good from successful and sustained
AI deployment. Through a multi-perspective content analysis of the latest AI
strategy documents, this paper provides a structured comparison of AI
governance strategies across nations. The findings offer valuable insights for
governments, academics, industries, and communities to enable responsible and
trustworthy AI deployments. Future work should focus on incorporating specific
requirements for developing countries and applying the strategies to specific
AI applications, industries, and the public sector.",not included,0,0.889930367
10.1108/ijoes-05-2023-0107,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Journal of Ethics and Systems,1/1/2000 0:00,semantic_scholar,ethical issues in the development of artificial intelligence: recognizing the risks,https://www.semanticscholar.org/paper/00c3e0b19febce5d401c5955482e95dadaf184c0,"
Purpose
This study aims to analyse the ethical implications associated with the development of artificial intelligence (AI) technologies and to examine the potential ethical ramifications of AI technologies.


Design/methodology/approach
This study undertakes a thorough examination of existing academic literature pertaining to the ethical considerations surrounding AI. Additionally, it conducts in-depth interviews with individuals to explore the potential benefits and drawbacks of AI technology operating as autonomous ethical agents. A total of 20 semi-structured interviews were conducted, and the data were transcribed using grounded theory methodology.


Findings
The study asserts the importance of fostering an ethical environment in the progress of AI and suggests potential avenues for further investigation in the field of AI ethics. The study finds privacy and security, bias and fairness, trust and reliability, transparency and human–AI interactions as major ethical concerns.


Research limitations/implications
The implications of the study are far-reaching and span across various domains, including policy development, design of AI systems, establishment of trust, education and training, public awareness and further research. Notwithstanding the potential biases inherent in purposive sampling, the constantly evolving landscape of AI ethics and the challenge of extrapolating findings to all AI applications and contexts, limitations may still manifest.


Originality/value
The novelty of the study is attributed to its comprehensive methodology, which encompasses a wide range of stakeholder perspectives on the ethical implications of AI in the corporate sector. The ultimate goal is to promote the development of AI systems that exhibit responsibility, transparency and accountability.
",not included,66,0.887477875
10.1007/s00146-021-01148-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,3/1/2022 0:00,springer,organisational responses to the ethical issues of artificial intelligence,http://dx.doi.org/10.1007/s00146-021-01148-6,"The ethics of artificial intelligence (AI) is a widely discussed topic. There are numerous initiatives that aim to develop the principles and guidance to ensure that the development, deployment and use of AI are ethically acceptable. What is generally unclear is how organisations that make use of AI understand and address these ethical issues in practice. While there is an abundance of conceptual work on AI ethics, empirical insights are rare and often anecdotal. This paper fills the gap in our current understanding of how organisations deal with AI ethics by presenting empirical findings collected using a set of ten case studies and providing an account of the cross-case analysis. The paper reviews the discussion of ethical issues of AI as well as mitigation strategies that have been proposed in the literature. Using this background, the cross-case analysis categorises the organisational responses that were observed in practice. The discussion shows that organisations are highly aware of the AI ethics debate and keen to engage with ethical issues proactively. However, they make use of only a relatively small subsection of the mitigation strategies proposed in the literature. These insights are of importance to organisations deploying or using AI, to the academic AI ethics debate, but maybe most valuable to policymakers involved in the current debate about suitable policy developments to address the ethical issues raised by AI.",included,3209,0.887463629
10.1007/s00146-021-01201-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,new pythias of public administration: ambiguity and choice in ai systems as challenges for governance,http://dx.doi.org/10.1007/s00146-021-01201-4,"As public administrations adopt artificial intelligence (AI), we see this transition has the potential to transform public service and public policies, by offering a rapid turnaround on decision making and service delivery. However, a recent series of criticisms have pointed to problematic aspects of mainstreaming AI systems in public administration, noting troubled outcomes in terms of justice and values. The argument supplied here is that any public administration adopting AI systems must consider and address ambiguities and uncertainties surrounding two key dimensions: the algorithms’ results, and how public managers make decisions for and about AI systems’ design. The article is based on bibliographic research in institutional theory perspective that relates the design of AI systems and relevant literature on the decision-making process in public policy. The main finding is to explain why autonomous decision systems continue to reproduce ambiguities and uncertainties when applied in public administration and propose a reflection on AI governance in public administration. This article points to the need for design institutions that immerse themselves in understanding the nuances, details, and potential outcomes of AI governance for public administration. Such institutions would reconcile consequentialist logic with a logic of appropriateness to help navigate and mediate ambiguities and uncertainties.",not included,2533,0.885775924
10.1007/s44206-024-00094-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Digital Society,Springer,2/27/2024 0:00,springer,"the philosophy and ethics of ai: conceptual, empirical, and technological investigations into values",http://dx.doi.org/10.1007/s44206-024-00094-2,"Advances in artificial intelligence have recently stirred both public and academic debates about the opportunities but also the risks posed by these developments. It is evident that the disruptive impact of AI in many societal domains can no longer be ignored. This topical collection emerged from a full week of high-quality paper presentations at the CEPE/IACAP Joint Conference 2021: The Philosophy and Ethics of Artificial Intelligence and comprises 13 articles that were chosen purely on the merit and originality of their respective arguments as well as their ability to advance the existing ethical and philosophical discourse on AI. This introduction provides a concise overview of the individual contributions, grouping them into four thematic strands: (a) On Democracy, Regulation, and (Public) Legitimation in an AI-powered World, (b) On the Challenge of Protecting Privacy in Today’s Data Economy, (c) On Solidarity, Inclusivity, and Responsibility in AI Design, and (d) Reconsidering AI Ethics. As such, the introduction serves as a gateway and guide to the topical collection, contributing to what has recently emerged as a ‘hot topic’ within philosophy and beyond but has also been at the heart of research within the CEPE and IACAP communities for a long time. The paper concludes with some hopeful remarks on the current landscape of the field and its possible trajectory.",not included,1219,0.885705233
10.1007/s00146-022-01471-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/1/2023 0:00,springer,"covid-19, artificial intelligence, ethical challenges and policy implications",http://dx.doi.org/10.1007/s00146-022-01471-6,"As the COVID-19 outbreak remains an ongoing issue, there are concerns about its disruption, the level of its disruption, how long this pandemic is going to last, and how innovative technological solutions like Artificial Intelligence (AI) and expert systems can assist to deal with this pandemic. AI has the potential to provide extremely accurate insights for an organization to make better decisions based on collected data. Despite the numerous advantages that may be achieved by AI, the use of AI can be perceived differently by society, where moral and ethical issues may be raised, especially in regards to accessing and exploiting public data gathered from social media platforms. To better comprehend the concerns and ethical challenges, utilitarianism and deontology were used as business ethics frameworks to explore the aforementioned challenges of AI in society. The framework assists in determining whether the AI’s deployment is ethically acceptable or not. The paper lays forth policy recommendations for public and private organizations to embrace AI-based decision-making processes to avoid data privacy violations and maintain public trust.",included,2276,0.88484627
10.1007/s10796-022-10285-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Information Systems Frontiers,Springer,2/1/2023 0:00,springer,are we nearly there yet? a desires & realities framework for europe’s ai strategy,http://dx.doi.org/10.1007/s10796-022-10285-2,"Of all emerging technologies, Artificial Intelligence (AI) is perhaps the most debated topic in contemporary society because it promises to redefine and disrupt several sectors. At the same time, AI poses challenges for policymakers and decision-makers, particularly regarding formulating strategies and regulations to address their stakeholders’ needs and perceptions. This paper explores stakeholder perceptions as expressed through their participation in the formulation of Europe’s AI strategy and sheds light on the challenges of AI in Europe and the expectations for the future. Our analysis reveals six dimensions towards an AI strategy; ecosystems, education, liability, data availability sufficiency & protection, governance and autonomy. It draws on these dimensions to construct a desires-realities framework for AI strategy in Europe and provide a research agenda for addressing existing realities. Our findings contribute to understanding stakeholder desires on AI and hold important implications for research, practice and policymaking.",not included,2421,0.884562254
10.1145/3636550,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digit. Gov. Res. Pract.,1/1/2000 0:00,semantic_scholar,introduction to the issue on artificial intelligence in the public sector: risks and benefits of ai for governments,https://www.semanticscholar.org/paper/37eb0c2177acf85c74ace80a9365d610523bc64b,"Artificial Intelligence (AI) is increasingly adopted by public sector organizations to provide better public services and to transform their internal processes. AI is now considered a key enabler for digital innovation and transformation in the public sector. However, AI is still relatively a new research area in the field of digital government. The term, AI, captures a wide range of technologies, techniques, and tools such as machine/deep learning, natural language processing, robotics, computer vision, and more recently Generative AI. While these AI technologies afford different applications and benefits in the government context, they also create social, ethical, and legal challenges. These challenges require solutions combining both technical (e.g., data and algorithmic solutions to minimize bias) and institutional (e.g., governance structures and processes) mechanisms. The special issue is a collection of articles that contribute to a better understanding of the issues associated with AI deployment in different areas of government operations. They cover AI applications in the areas of emergency response, policy analysis, public bids, and citizen participation. The contributions also address the challenge of realizing a legal transparency regime for AI in government and the effect of AI in bureaucratic decision-making.",not included,92,0.882505655
10.1007/s43681-024-00569-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,9/23/2024 0:00,springer,"ai governance systems: a multi-scale analysis framework, empirical findings, and future directions",http://dx.doi.org/10.1007/s43681-024-00569-5,"The governance of artificial intelligence (AI) has recently emerged as a field of research and practice, but the structural and functional components of AI governance (AIG) systems are not well understood by researchers and practitioners. To address that gap, we apply service system analysis methods and thematic analysis methods to develop a novel framework for conceptualizing and analyzing AI governance systems across multiple scales of activity, including international, national, subnational, sectoral, and organizational systems of governance. We apply our analysis framework to an empirical study of Canada’s national AIG system. Drawing upon qualitative data collected from 20 leaders of Canadian AIG initiatives and subject matter experts, we identify and discuss the actors, impacts, resources, networks, activities, logics, norms, and rules involved in structuring and operating a national AIG system, using Canada as a case study. Based on our findings, we propose three directions for future research: (1) conduct additional analysis of the 610 topics in our dataset, (2) further investigate institutional and ecosystem-level structures and dynamics in Canada’s national AIG system, (3) apply our framework, data, and findings to study AIG systems in other contexts. We also outline four strategic objectives for strengthening Canada’s AIG system: (1) implement new collaboration and coordination mechanisms, (2) create guidance for designing and implementing participatory AIG initiatives, (3) expand access to key resources needed for effective AIG practices, (4) advance diversity, equity, and inclusion in AIG activities.",included,263,0.87953043
10.48550/arxiv.2210.17218,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Grid Computing,1/1/2022 0:00,semantic_scholar,"artificial intelligence in government: concepts, standards, and a unified framework",https://www.semanticscholar.org/paper/2afd1d3199326dc8a9184a5152616f5cfda1e2e6,"Recent advances in artificial intelligence (AI), especially in generative language modelling, hold the promise of transforming government. Given the advanced capabilities of new AI systems, it is critical that these are embedded using standard operational procedures, clear epistemic criteria, and behave in alignment with the normative expectations of society. Scholars in multiple domains have subsequently begun to conceptualize the different forms that AI applications may take, highlighting both their potential benefits and pitfalls. However, the literature remains fragmented, with researchers in social science disciplines like public administration and political science, and the fast-moving fields of AI, ML, and robotics, all developing concepts in relative isolation. Although there are calls to formalize the emerging study of AI in government, a balanced account that captures the full depth of theoretical perspectives needed to understand the consequences of embedding AI into a public sector context is lacking. Here, we unify efforts across social and technical disciplines by first conducting an integrative literature review to identify and cluster 69 key terms that frequently co-occur in the multidisciplinary study of AI. We then build on the results of this bibliometric analysis to propose three new multifaceted concepts for understanding and analysing AI-based systems for government (AI-GOV) in a more unified way: (1) operational fitness, (2) epistemic alignment, and (3) normative divergence. Finally, we put these concepts to work by using them as dimensions in a conceptual typology of AI-GOV and connecting each with emerging AI technical measurement standards to encourage operationalization, foster cross-disciplinary dialogue, and stimulate debate among those aiming to rethink government with AI.",included,26,0.879107594
10.1007/s43681-021-00047-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/1/2022 0:00,springer,"community-in-the-loop: towards pluralistic value creation in ai, or—why ai needs business ethics",http://dx.doi.org/10.1007/s43681-021-00047-2,"Today, due to growing computing power and the increasing availability of high-quality datasets, artificial intelligence (AI) technologies are entering many areas of our everyday life. Thereby, however, significant ethical concerns arise, including issues of fairness, privacy and human autonomy. By aggregating current concerns and criticisms, we identify five crucial shortcomings of the current debate on the ethics of AI. On the threshold of a third wave of AI ethics, we find that the field eventually fails to take sufficient account of the business context and deep societal value conflicts the use of AI systems may evoke. For even a perfectly fair AI system, regardless of its feasibility, may be ethically problematic, a too narrow focus on the ethical implications of technical systems alone seems insufficient. Therefore, we introduce a business ethics perspective based on the normative theory of contractualism and conceptualise ethical implications as conflicts between values of diverse stakeholders. We argue that such value conflicts can be resolved by an account of deliberative order ethics holding that stakeholders of an economic community deliberate the costs and benefits and agree on rules for acceptable trade-offs when AI systems are employed. This allows AI ethics to consider business practices, to recognise the role of firms, and ethical AI not being at risk to provide a competitive disadvantage or in conflict with the current functioning of economic markets. By introducing deliberative order ethics, we thus seek to do justice to the fundamental normative and political dimensions at the core of AI ethics.",included,3080,0.878959239
10.1145/3657054.3657278,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2000 0:00,semantic_scholar,examining public sector ai adoption: mechanisms for ai adoption in the absence of authoritative strategic direction,https://www.semanticscholar.org/paper/b29a09098db3c5e67bba3b50ea8627a27258f65b,"Artificial Intelligence (AI) is recognized to bring great benefits to the organizations that can successfully adopt this emerging technological domain into their operations. This paper examines the impact of governance and strategic direction on AI adoption and diffusion in a public sector setting. By presenting contextual conditions, mechanisms, and outcomes within a large government agency this work contributes to the understanding of how the absence of appropriate governance structures and strategies impact the development and adoption of AI. Findings show that balancing exploitation and exploration in the capillaries of the organization proved crucial to the adoption and diffusion of AI. This manifested itself through three mechanisms, Cross-domain learning, Legal priming, and Ecosystem growth, which enabled the organization to obtain both value creation and value capture.",included,99,0.878069699
10.1038/s41598-024-71761-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Scientific Reports,Nature,9/5/2024 0:00,springer,"trust, trustworthiness and ai governance",http://dx.doi.org/10.1038/s41598-024-71761-0,"An emerging issue in AI alignment is the use of artificial intelligence (AI) by public authorities, and specifically the integration of algorithmic decision-making (ADM) into core state functions. In this context, the alignment of AI with the values related to the notions of trust and trustworthiness constitutes a particularly sensitive problem from a theoretical, empirical, and normative perspective. In this paper, we offer an interdisciplinary overview of the scholarship on trust in sociology, political science, and computer science anchored in artificial intelligence. On this basis, we argue that only a coherent and comprehensive interdisciplinary approach making sense of the different properties attributed to trust and trustworthiness can convey a proper understanding of complex watchful trust dynamics in a socio-technical context. Ensuring the trustworthiness of AI-Governance ultimately requires an understanding of how to combine trust-related values while addressing machines, humans and institutions at the same time. We offer a road-map of the steps that could be taken to address the challenges identified.",included,306,0.8779549
10.1016/bs.adcom.2023.08.001,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85174467151,scopus,1/1/2024,scopus,why is implementing computational intelligence for social good so challenging? principles and its application,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85174467151&origin=inward,"
                  Computational intelligence (CI) has the potential to help tackle some of the world's most challenging social problems. Real-life examples of AI are already being applied in about one-third of these use cases They range from diagnosing cancer to helping blind people navigate their surroundings, identifying victims of online sexual exploitation, and aiding disaster-relief efforts etc. AI is only part of a much broader tool kit of measures that can be used to tackle societal issues, however. For now, issues such as data accessibility and shortages of AI talent constrain its application for social good. This chapter has grouped use cases into 10 social-impact domains based on taxonomies in use among social-sector organizations. Each use case highlights a type of meaningful problem that can be solved by one or more AI capability. The cost of human suffering, and the value of alleviating it, are impossible to gauge and compare. Nonetheless, employing usage frequency as a proxy, we measure the potential impact of different AI capabilities.
               ",not included,8536,0.877811551
10.1007/s43681-022-00143-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,11/1/2022 0:00,springer,defining organizational ai governance,http://dx.doi.org/10.1007/s43681-022-00143-x,"Artificial intelligence (AI) governance is required to reap the benefits and manage the risks brought by AI systems. This means that ethical principles, such as fairness, need to be translated into practicable AI governance processes. A concise AI governance definition would allow researchers and practitioners to identify the constituent parts of the complex problem of translating AI ethics into practice. However, there have been few efforts to define AI governance thus far. To bridge this gap, this paper defines AI governance at the organizational level. Moreover, we delineate how AI governance enters into a governance landscape with numerous governance areas, such as corporate governance, information technology (IT) governance, and data governance. Therefore, we position AI governance as part of an organization’s governance structure in relation to these existing governance areas. Our definition and positioning of organizational AI governance paves the way for crafting AI governance frameworks and offers a stepping stone on the pathway toward governed AI.",included,2664,0.876718223
10.1007/s11948-024-00507-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Science and Engineering Ethics,Springer,10/9/2024 0:00,springer,reconstructing ai ethics principles: rawlsian ethics of artificial intelligence,http://dx.doi.org/10.1007/s11948-024-00507-y,"The popularisation of Artificial Intelligence (AI) technologies has sparked discussion about their ethical implications. This development has forced governmental organisations, NGOs, and private companies to react and draft ethics guidelines for future development of ethical AI systems. Whereas many ethics guidelines address values familiar to ethicists, they seem to lack in ethical justifications. Furthermore, most tend to neglect the impact of AI on democracy, governance, and public deliberation. Existing research suggest, however, that AI can threaten key elements of western democracies that are ethically relevant. In this paper, Rawls’s theory of justice is applied to draft a set of guidelines for organisations and policy-makers to guide AI development towards a more ethical direction. The goal is to contribute to the broadening of the discussion on AI ethics by exploring the possibility of constructing AI ethics guidelines that are philosophically justified and take a broader perspective of societal justice. The paper discusses how Rawls’s theory of justice as fairness and its key concepts relate to the ongoing developments in AI ethics and gives a proposition of how principles that offer a foundation for operationalising AI ethics in practice could look like if aligned with Rawls’s theory of justice as fairness.",included,180,0.876704395
10.37417/rdp/vol_8_2023_1949,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Revista de Derecho Público: Teoría y método,1/1/2000 0:00,semantic_scholar,artificial intelligence challenging core state functions,https://www.semanticscholar.org/paper/5a392bc0fd61b7e062d95d6ed819bd347bae4480,"The use of AI in the public sector is emerging around the world and its spread affects the core States functions: the administrative, the judiciary, and the legislative. Nevertheless, a comprehensive approach to AI in the life-cycle of rules - from the proposal of a new rule to its implementation, monitoring and review- is currently lacking in the rich panorama of studies from different disciplines. The analysis shows that AI has the power to play a crucial role in the life-cycle of rules, by performing time-consuming tasks, increasing access to knowledge base, and enhancing the ability of institutions to draft effective rules and to declutter the regulatory stock. However, it is not without risks, ranging from discrimination to challenges to democratic representation. In order to play a role in achieving law effectiveness while limiting the risks, a complementarity between human and AI should be reached both at the level of the AI architecture and ex post. Moreover, an incremental and experimental approach is suggested, as well as the elaboration of a general framework, to be tailored by each regulator to the specific features of its tasks, aimed at setting the rationale, the role, and adequate guardrails to AI in the life-cycle of rules. This agile approach would allow the AI revolution to display its benefits while preventing potential harms or side effects.",included,51,0.875555634
10.1007/s13347-020-00405-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,12/1/2020 0:00,springer,decolonial ai: decolonial theory as sociotechnical foresight in artificial intelligence,http://dx.doi.org/10.1007/s13347-020-00405-8,"This paper explores the important role of critical science, and in particular of post-colonial and decolonial theories, in understanding and shaping the ongoing advances in artificial intelligence. Artificial intelligence (AI) is viewed as amongst the technological advances that will reshape modern societies and their relations. While the design and deployment of systems that continually adapt holds the promise of far-reaching positive change, they simultaneously pose significant risks, especially to already vulnerable peoples. Values and power are central to this discussion. Decolonial theories use historical hindsight to explain patterns of power that shape our intellectual, political, economic, and social world. By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress. We highlight problematic applications that are instances of coloniality, and using a decolonial lens, submit three tactics that can form a decolonial field of artificial intelligence: creating a critical technical practice of AI, seeking reverse tutelage and reverse pedagogies, and the renewal of affective and political communities. The years ahead will usher in a wave of new scientific breakthroughs and technologies driven by AI research, making it incumbent upon AI communities to strengthen the social contract through ethical foresight and the multiplicity of intellectual perspectives available to us, ultimately supporting future technologies that enable greater well-being, with the goal of beneficence and justice for all.",not included,4082,0.873982072
http://arxiv.org/abs/1906.05684v1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',arxiv,arxiv,6/11/2019 0:00,arxiv,understanding artificial intelligence ethics and safety,http://arxiv.org/abs/1906.05684v1,"A remarkable time of human promise has been ushered in by the convergence of
the ever-expanding availability of big data, the soaring speed and stretch of
cloud computing platforms, and the advancement of increasingly sophisticated
machine learning algorithms. Innovations in AI are already leaving a mark on
government by improving the provision of essential social goods and services
from healthcare, education, and transportation to food supply, energy, and
environmental management. These bounties are likely just the start. The
prospect that progress in AI will help government to confront some of its most
urgent challenges is exciting, but legitimate worries abound. As with any new
and rapidly evolving technology, a steep learning curve means that mistakes and
miscalculations will be made and that both unanticipated and harmful impacts
will occur.
  This guide, written for department and delivery leads in the UK public sector
and adopted by the British Government in its publication, 'Using AI in the
Public Sector,' identifies the potential harms caused by AI systems and
proposes concrete, operationalisable measures to counteract them. It stresses
that public sector organisations can anticipate and prevent these potential
harms by stewarding a culture of responsible innovation and by putting in place
governance processes that support the design and implementation of ethical,
fair, and safe AI systems. It also highlights the need for algorithmically
supported outcomes to be interpretable by their users and made understandable
to decision subjects in clear, non-technical, and accessible ways. Finally, it
builds out a vision of human-centred and context-sensitive implementation that
gives a central role to communication, evidence-based reasoning, situational
awareness, and moral justifiability.",included,2,0.873350501
10.1145/3643690.3648235,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB),1/1/2000 0:00,semantic_scholar,artificial intelligence in the public sector - an agenda for responsible innovation through learning,https://www.semanticscholar.org/paper/b727d48a8a9ce8ac56fc3a164c2a7a4628093550,"The optimism about the benefits of using artificial intelligence to innovate public services is tempered by concerns about its risks, limitations, and disbenefits. Given the rapid changes in the technol-ogy itself, the opportunities and needs for cross-sectional solutions, and the nascency of the field of AI-based innovation, we contend that policy, strategy, and implementation must include feedback loops that enable institutional learning for the entire public sec-tor. The scope of challenges creates and imperative to facilitate learning must transcend functional, organizational, geographic, and national boundaries. We propose a learning agenda that in-cludes 1) alignment of strategy and policy; 2) initial understanding of goals, benefits, disbenefits, limitations, and risks; 3) data sharing across jurisdictions; 4) technical robustness and societal alignment in governmental oversight; 5) convergence of architecture for AI support; and 6) a portfolio approach to selecting and learning from enabling service innovation with AI.",included,96,0.872548342
10.1007/s00146-022-01566-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2024 0:00,springer,drivers behind the public perception of artificial intelligence: insights from major australian cities,http://dx.doi.org/10.1007/s00146-022-01566-0,"Artificial intelligence (AI) is not only disrupting industries and businesses, particularly the ones have fallen behind the adoption, but also significantly impacting public life as well. This calls for government authorities pay attention to public opinions and sentiments towards AI. Nonetheless, there is limited knowledge on what the drivers behind the public perception of AI are. Bridging this gap is the rationale of this paper. As the methodological approach, the study conducts an online public perception survey with the residents of Sydney, Melbourne, and Brisbane, and explores the collected survey data through statistical analysis. The analysis reveals that: (a) the public is concerned of AI invading their privacy, but not much concerned of AI becoming more intelligent than humans; (b) the public trusts AI in their lifestyle, but the trust is lower for companies and government deploying AI; (c) the public appreciates the benefits of AI in urban services and disaster management; (d) depending on the local context, public perceptions vary; and (e) the drivers behind the public perception include gender, age, AI knowledge, and AI experience. The findings inform authorities in developing policies to minimise public concerns and maximise AI awareness.",not included,721,0.872416317
10.1007/s00146-022-01401-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,8/1/2023 0:00,springer,the problem with trust: on the discursive commodification of trust in ai,http://dx.doi.org/10.1007/s00146-022-01401-6,"This commentary draws critical attention to the ongoing commodification of trust in policy and scholarly discourses of artificial intelligence (AI) and society. Based on an assessment of publications discussing the implementation of AI in governmental and private services, our findings indicate that this discursive trend towards commodification is driven by the need for a trusting population of service users to harvest data at scale and leads to the discursive construction of trust as an essential good on a par with data as raw material. This discursive commodification is marked by a decreasing emphasis on trust understood as the expected reliability of a trusted agent, and increased emphasis on instrumental and extractive framings of trust as a resource. This tendency, we argue, does an ultimate disservice to developers, users, and systems alike, insofar as it obscures the subtle mechanisms through which trust in AI systems might be built, making it less likely that it will be.",not included,1896,0.872232199
10.1007/s00146-023-01808-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,11/22/2023 0:00,springer,trustworthy ai: ai made in germany and europe?,http://dx.doi.org/10.1007/s00146-023-01808-9,"As the capabilities of artificial intelligence (AI) continue to expand, concerns are also growing about the ethical and social consequences of unregulated development and, above all, use of AI systems in a wide range of social areas. It is therefore indisputable that the application of AI requires social standardization and regulation. For years, innovation policy measures and the most diverse activities of European and German institutions have been directed toward this goal. Under the label “Trustworthy AI” (TAI), a promise is formulated, according to which AI can meet criteria of transparency, legality, privacy, non-discrimination, and reliability. In this article, we ask what significance and scope the politically initiated concepts of TAI occupy in the current process of AI dynamics and to what extent they can stand for an independent, unique European or German development path of this technology.",included,1570,0.871797085
10.28995/2782-2222-2024-1-56-69,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Science and art of management / Bulletin of the Institute of Economics, Management and Law of the Russian State University for the Humanities",1/1/2000 0:00,semantic_scholar,"artificial intelligence in russia. history, status, trends and limitations",https://www.semanticscholar.org/paper/c3dcdb50f9979d435a3999fc6a7737b22b368cbe,"A new stage in the introduction of artificial intelligence into everyday life in Russia will be the mass introduction of its technologies and products based on it into the public administration system and the government sector. Today, AI is used in most spheres of public life, but its level of development is still not high enough. In that regard, the issues considered in the publication are modern and relevant and can be used at the stages of development and use of AI. The authors clarified the definition of “artificial intelligence”, analyzed the directions of AI development and identified promising areas of the most accelerated technological development of intelligent systems: generative, voice and language, explicable and peripheral AI with characteristics of the stages up to the present. Two main criteria of AI are analyzed: “strong AI” and “weak AI” and their fundamental differences are considered. The article presents results of a brief analysis of the state and plans for the development of AI in Russia. The level of AI implementation in economic sectors reaches 20% and that is not enough to ensure accelerated economic growth. It is assumed that the introduction of AI should provide an additional 1.2% increase in global GDP by 2030, and our country plans to gain more than 11 trillion rubles from its use by 2025. The future of artificial intelligence in Russia was determined by the President of the country at the St. Petersburg International Forum (PEMF-2023). The announced directions will make it possible to unlock the potential of AI more widely and ensure its mass implementation for the formation of Russia’s sovereignty.",not included,106,0.871553481
10.31516/2410-5325.083.02,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Culture of Ukraine,1/1/2000 0:00,semantic_scholar,artificial intelligence through the prism of thematic research on researchgate web portal,https://www.semanticscholar.org/paper/2ca8e568a7c9cf3ad7368fd8b6b6a327f0eb35f1,"Different instances of generative artificial intelligence (GenAI) in a short time have made a significant impact on the world’s economic and political scene. Before October 2022, processes of automatization and robotization of manufacturing didn’t have an immediate connection with artificial intelligence in the minds of most people. But mass and sudden infiltration of GenAI into the everyday life of many people around the world caused an immediate reaction from scientists, public figures, politicians, managers and heads of whole sectors of the economy. Thousands of scientific articles on related topics were published in the last two years: everyone at once started talking about fantastic possibilities, and also threats, which this new technology can usher in for our societies. Thus, for public thinking GenAI finally linked automatization with artificial intelligence. 
This paper provides an analysis of problems and prospects, through which scientists are trying to understand different societal processes linked to adoption of AI. For this purpose, the author of this paper analyzed the contents of papers published on this topic on the ResearchGate web portal in 2023, with the choice of the source for representative material motivated by scientific credibility of ResearchGate combined with its wide reach. Ten most popular articles were specifically targeted for final analysis, through which societal trends brought on by AI adoption were described. Although a selective meta-analysis of articles published during the first year after ChatGPT release can’t provide a full understanding of AI potential and possible threats to society, the conclusion can still be reached that a cardinal shift in society’s attitudes towards its own future is required. 
From the ten articles analyzed, four are related to changes required to the education system, four are about AI’s influence on the labour market, one article talks about the possibility of AI-human competition and one is about the AI potential in agriculture. Most articles mention the need for legislative changes in terms of labor protection and education reforms in-line with new digital reality.",not included,124,0.871017933
10.1145/3514094.3539563,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"AAAI/ACM Conference on AI, Ethics, and Society",1/1/2022 0:00,semantic_scholar,the opacity of automated decision-making systems (adms) and its challenges for political legitimacy in a democracy,https://www.semanticscholar.org/paper/4d14d554a9d6359f1faba70abb530ae03fe7eb89,"This paper focuses specifically on Automated Decision-Making Systems (ADMS) based on Artificial Intelligence (AI). Since the last decades, AI systems are increasingly deployed by governments across the planet to manage public infrastructures and resources, as well as to engage with citizens for the provision of public services. Their introduction is advertised as a cost-cutting tool, as well as an instrument to combat traditional institutional disfunctions such as inefficiency, understaffing, corruption and human bias. While AI offers an incredible potential for progress, an emerging body of literature highlights the challenges that AI-driven decision-making may raise for a public sector ethics. A common trait of these challenges is their being related to some form of ""epistemological opacity"" that undermines the capacity of humans to explain and justify decisions based on AI systems, detect errors or unfairness and adopt corrective actions. The situation may entail public officers and citizens taking the outcomes of AI systems at face value, thus basing their actions (wholly or in part) on pieces of information that cannot be scrutinized and/or corrected if necessary. This paper intends to contribute to an emerging but still underdeveloped trend in normative political theory that study how AI-driven decision-making is reshaping the conceptualization and assessment of interactions between citizens and public officials. The overall goal of the paper is to analyze how various sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) affecting AI systems, may undermine the democratic legitimacy of public decisions based on them. Broadly speaking, legitimacy is the property that grounds the exercise of political authority, where authority standardly means the right to rule [1]. In this paper, democratic legitimacy is understood as a distinctive form of political authority grounded in the recognition of citizens as joint legislators. The paper offers a conception of democratic legitimacy conditional on the capacity of decision-making procedures and outcomes to realize the principle of public equality, which requires citizens' control over public decision-making, as well as respect for their equal status as political decision-makers. Specifically, the paper argues that the ""epistemological opacity"" affecting AI-driven decision-making systems, brings about a mistreatment of citizens as coauthors of public decisions, which is a premise of the idea of democratic citizenship. The main conjecture is that different sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) are causing the disengagement of citizens and public officers from public decision-making, either because they directly undermine necessary conditions for the realization of public equality (co-authorship/accountability/publicity), or because they hide from the public eye instances of illegitimate automation and privatization of decisional power. The paper offers a normative conception of democratic legitimacy that may contribute to efforts in various fields, including ""AI fairness"" and ""Explainable AI"", to better adapt technological tools to equality requirements distinctive of public decision-making within democratic societies.",included,37,0.870236635
10.1038/s42256-019-0088-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Nature Machine Intelligence,Nature,9/1/2019 0:00,springer,the global landscape of ai ethics guidelines,http://dx.doi.org/10.1038/s42256-019-0088-2,"In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be ‘ethical’, there is debate about both what constitutes ‘ethical AI’ and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies. As AI technology develops rapidly, it is widely recognized that ethical guidelines are required for safe and fair implementation in society. But is it possible to agree on what is ‘ethical AI’? A detailed analysis of 84 AI ethics reports around the world, from national and international organizations, companies and institutes, explores this question, finding a convergence around core principles but substantial divergence on practical implementation.",included,4805,0.869817972
10.1007/s13162-024-00275-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AMS Review,Springer,6/1/2024 0:00,springer,a theoretical framework to guide ai ethical decision making,http://dx.doi.org/10.1007/s13162-024-00275-9,"Artificial Intelligence (AI) ethics is needed to address the risks that are outpacing efforts to protect consumers and society. AI is becoming human-competitive with the ability to perform tasks, that without controls, can result in harmful or destructive actions. Principles are currently the most discussed ethical approach for pervasive boundaries for algorithmic rule-based intelligence. Principles, values, norms, and rules should be the foundation of an ethical corporate culture with all participants aware of and involved in developing AI ethics. To address these concerns, a theory-based decision framework is presented to incorporate ethical considerations into AI applications. With limited discussion on frameworks to manage AI ethics, we provide a modification of the Hunt–Vitell (H–V) ethical decision model to provide a supportive theoretical framework. This model considers the cultural, industry, organizational, and legal standards that shape AI ethical decision making. The model is based on individual decision making and parallels the decision process in autonomous AI system decision making. Topics for additional research are advanced to create expanded knowledge on this topic.",included,724,0.869165242
10.1016/j.giq.2021.101596,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85108562674,scopus,10/1/2022,scopus,enabling ai capabilities in government agencies: a study of determinants for european municipalities,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108562674&origin=inward,"Artificial Intelligence (AI) is gradually becoming an integral part of the digital strategy of organizations. Yet, the use of AI in public organizations in still lagging significantly compared to private organizations. Prior literature looking into aspects that facilitate adoption and use of AI has concentrated on challenges concerning technical aspects of AI technologies, providing little insight regarding the organizational deployment of AI, particularly in public organizations. Building on this gap, this study seeks to examine what aspects enable public organizations to develop AI capabilities. To answer this question, we built an integrated and extended model from the Technology-Organization-Environment framework (TOE) and asked high-level technology managers from municipalities in Europe about factors that influence their development of AI capabilities. We collected data from 91 municipalities from three European countries (i.e., Germany, Norway, and Finland) and analyzed responses by means of structural equation modeling. Our findings indicate that five factors – i.e. perceived financial costs, organizational innovativeness, perceived governmental pressure, government incentives, regulatory support – have an impact on the development of AI capabilities. We also find that perceived citizen pressure and perceived value of AI solutions are not important determinants of AI capability formation. Our findings bear the potential to stimulate a more reflected adoption of AI supporting managers in public organizations to develop AI capabilities.",included,8595,0.868808866
10.1007/s00146-019-00886-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2020 0:00,springer,15 challenges for ai: or what ai (currently) can’t do,http://dx.doi.org/10.1007/s00146-019-00886-y,"The current “AI Summer” is marked by scientific breakthroughs and economic successes in the fields of research, development, and application of systems with artificial intelligence. But, aside from the great hopes and promises associated with artificial intelligence, there are a number of challenges, shortcomings and even limitations of the technology. For one, these challenges arise from methodological and epistemological misconceptions about the capabilities of artificial intelligence. Secondly, they result from restrictions of the social context in which the development of applications of machine learning is embedded. And third, they are a consequence of current technical limitations in the development and use of artificial intelligence. The paper intends to provide an overview of current challenges which the research and development of applications in the field of artificial intelligence and machine learning have to face, whereas all three mentioned areas are to be further explored in this paper.",not included,4408,0.868235111
10.1007/s00146-024-01976-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/4/2024 0:00,springer,we’re only human after all: a critique of human-centred ai,http://dx.doi.org/10.1007/s00146-024-01976-2,"The use of a ‘human-centred’ artificial intelligence approach (HCAI) has substantially increased over the past few years in academic texts (1600 +); institutions (27 Universities have HCAI labs, such as Stanford, Sydney, Berkeley, and Chicago); in tech companies (e.g., Microsoft, IBM, and Google); in politics (e.g., G7, G20, UN, EU, and EC); and major institutional bodies (e.g., World Bank, World Economic Forum, UNESCO, and OECD). Intuitively, it sounds very appealing: placing human concerns at the centre of AI development and use. However, this paper will use insights from the works of Michel Foucault (mostly The Order of Things ) to argue that the HCAI approach is deeply problematic in its assumptions. In particular, this paper will criticise four main assumptions commonly found within HCAI: human–AI hybridisation is desirable and unproblematic; humans are not currently at the centre of the AI universe; we should use humans as a way to guide AI development; AI is the next step in a continuous path of human progress; and increasing human control over AI will reduce harmful bias. This paper will contribute to the field of philosophy of technology by using Foucault's analysis to examine assumptions found in HCAI [it provides a Foucauldian conceptual analysis of a current approach (human-centredness) that aims to influence the design and development of a transformative technology (AI)], it will contribute to AI ethics debates by offering a critique of human-centredness in AI (by choosing Foucault, it provides a bridge between older ideas with contemporary issues), and it will also contribute to Foucault studies (by using his work to engage in contemporary debates, such as AI).",not included,714,0.86803031
10.1007/s00146-021-01383-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,8/1/2023 0:00,springer,embedding artificial intelligence in society: looking beyond the eu ai master plan using the culture cycle,http://dx.doi.org/10.1007/s00146-021-01383-x,"The European Union (EU) Commission’s whitepaper on Artificial Intelligence (AI) proposes shaping the emerging AI market so that it better reflects common European values. It is a master plan that builds upon the EU AI High-Level Expert Group guidelines. This article reviews the masterplan, from a culture cycle perspective, to reflect on its potential clashes with current societal, technical, and methodological constraints. We identify two main obstacles in the implementation of this plan: (i) the lack of a coherent EU vision to drive future decision-making processes at state and local levels and (ii) the lack of methods to support a sustainable diffusion of AI in our society. The lack of a coherent vision stems from not considering societal differences across the EU member states. We suggest that these differences may lead to a fractured market and an AI crisis in which different members of the EU will adopt nation-centric strategies to exploit AI, thus preventing the development of a frictionless market as envisaged by the EU. Moreover, the Commission aims at changing the AI development culture proposing a human-centred and safety-first perspective that is not supported by methodological advancements, thus taking the risks of unforeseen social and societal impacts of AI. We discuss potential societal, technical, and methodological gaps that should be filled to avoid the risks of developing AI systems at the expense of society. Our analysis results in the recommendation that the EU regulators and policymakers consider how to complement the EC programme with rules and compensatory mechanisms to avoid market fragmentation due to local and global ambitions. Moreover, regulators should go beyond the human-centred approach establishing a research agenda seeking answers to the technical and methodological open questions regarding the development and assessment of human-AI co-action aiming for a sustainable AI diffusion in the society.",not included,1892,0.867965043
10.1007/s00146-021-01380-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,8/1/2023 0:00,springer,artificial intelligence ethics has a black box problem,http://dx.doi.org/10.1007/s00146-021-01380-0,"It has become a truism that the ethics of artificial intelligence (AI) is necessary and must help guide technological developments. Numerous ethical guidelines have emerged from academia, industry, government and civil society in recent years. While they provide a basis for discussion on appropriate regulation of AI, it is not always clear how these ethical guidelines were developed, and by whom. Using content analysis, we surveyed a sample of the major documents ( n  = 47) and analyzed the accessible information regarding their methodology and stakeholder engagement. Surprisingly, only 38% report some form of stakeholder engagement (with 9% involving citizens) and most do not report their methodology for developing normative insights (15%). Our results show that documents with stakeholder engagement develop more comprehensive ethical guidance with greater applicability, and that the private sector is least likely to engage stakeholders. We argue that the current trend for enunciating AI ethical guidance not only poses widely discussed challenges of applicability in practice, but also of transparent development (as it rather behaves as a black box) and of active engagement of diversified, independent and trustworthy stakeholders. While most of these documents consider people and the common good as central to their telos, engagement with the general public is significantly lacking. As AI ethics moves from the initial race for enunciating general principles to more sustainable, inclusive and practical guidance, stakeholder engagement and citizen involvement will need to be embedded into the framing of ethical and societal expectations towards this technology.",included,1901,0.867862284
10.1007/s00146-021-01294-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,2/1/2023 0:00,springer,"the ai gambit: leveraging artificial intelligence to combat climate change—opportunities, challenges, and recommendations",http://dx.doi.org/10.1007/s00146-021-01294-x,"In this article, we analyse the role that artificial intelligence (AI) could play, and is playing, to combat global climate change. We identify two crucial opportunities that AI offers in this domain: it can help improve and expand current understanding of climate change, and it can contribute to combatting the climate crisis effectively. However, the development of AI also raises two sets of problems when considering climate change: the possible exacerbation of social and ethical challenges already associated with AI, and the contribution to climate change of the greenhouse gases emitted by training data and computation-intensive AI systems. We assess the carbon footprint of AI research, and the factors that influence AI’s greenhouse gas (GHG) emissions in this domain. We find that the carbon footprint of AI research may be significant and highlight the need for more evidence concerning the trade-off between the GHG emissions generated by AI research and the energy and resource efficiency gains that AI can offer. In light of our analysis, we argue that leveraging the opportunities offered by AI for global climate change whilst limiting its risks is a gambit which requires responsive, evidence-based, and effective governance to become a winning strategy. We conclude by identifying the European Union as being especially well-placed to play a leading role in this policy response and provide 13 recommendations that are designed to identify and harness the opportunities of AI for combatting climate change, while reducing its impact on the environment.",not included,2416,0.867640555
10.1007/s43681-022-00206-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/1/2023 0:00,springer,needs and artificial intelligence,http://dx.doi.org/10.1007/s43681-022-00206-z,"Throughout our history, we, Homo sapiens, have used technologies to better satisfy our needs . The relation between needs and technology is so fundamental that the US National Research Council defines the distinguishing characteristic of technology as its goal “to make modifications in the world [in order] to meet human needs” [ 1 ]. Artificial intelligence (AI) is one of the most promising emerging technologies of our time. Similar to other technologies, AI is expected by many “to meet [human] needs”. In this article, we reflect on the relationship between needs and AI, and call for the realization of needs-aware AI systems. We argue that re-thinking needs for , through , by , and with AI can be a very useful means towards the development of realistic approaches for sustainable H uman-aware, A ccountable, L awful, and E thical (HALE) AI systems. We discuss some of the most critical gaps, barriers, enablers, and drivers of co-creating future AI-based sociotechnical systems in which [human] needs are well considered and met. Finally, we provide an overview of potential challenges and considerations that should be carefully taken into account; and call for joint, immediate, and interdisciplinary efforts and collaborations to start on the path to needs-aware AI.",not included,1899,0.867314219
10.1007/s11948-017-9901-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Science and Engineering Ethics,Springer,4/1/2018 0:00,springer,"artificial intelligence and the ‘good society’: the us, eu, and uk approach",http://dx.doi.org/10.1007/s11948-017-9901-7,"In October 2016, the White House, the European Parliament, and the UK House of Commons each issued a report outlining their visions on how to prepare society for the widespread use of artificial intelligence (AI). In this article, we provide a comparative assessment of these three reports in order to facilitate the design of policies favourable to the development of a ‘good AI society’. To do so, we examine how each report addresses the following three topics: (a) the development of a ‘good AI society’; (b) the role and responsibility of the government, the private sector, and the research community (including academia) in pursuing such a development; and (c) where the recommendations to support such a development may be in need of improvement. Our analysis concludes that the reports address adequately various ethical, social, and economic topics, but come short of providing an overarching political vision and long-term strategy for the development of a ‘good AI society’. In order to contribute to fill this gap, in the conclusion we suggest a two-pronged approach.",not included,5393,0.866809666
10.1007/s43681-024-00548-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/14/2024 0:00,springer,on singularity and the stoics: why stoicism offers a valuable approach to navigating the risks of ai (artificial intelligence),http://dx.doi.org/10.1007/s43681-024-00548-w,"The potential benefits and risks of artificial intelligence technologies have sparked a wide-ranging debate in both academic and public circles. On one hand, there is an urgent call to address the immediate and avoidable challenges associated with these tools, such as accountability, privacy, bias, understandability, and transparency; on the other hand, prominent figures like Geoffrey Hinton and Elon Musk have voiced concerns over the potential rise of Super Artificial Intelligence, whose singularity could pose an existential threat to humanity. Coordinating the efforts of thousands of decentralized entities to prevent such a hypothetical event may seem insurmountable in our intricate and multipolar world. Thus, drawing from both perspectives, this work suggests employing the tools and framework of Stoic philosophy, particularly the concept of the dichotomy of control—focusing on what is within our power. This Stoic principle offers a practical and epistemological approach to managing the complexities of AI, and it encourages individuals to organize their efforts around what they can influence while adapting to the constraints of external factors. Within this framework, the essay found that Stoic wisdom is essential for assessing risks, courage is necessary to face contemporary challenges, and temperance and tranquility are indispensable; and these lessons can inform ongoing public and academic discourse, aiding in the development of more effective policy proposals for aligning Narrow AI and General AI with human values.",included,438,0.865947008
10.1007/s00146-022-01589-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2023 0:00,springer,understanding citizen perceptions of ai in the smart city,http://dx.doi.org/10.1007/s00146-022-01589-7,"Artificial intelligence (AI) is embedded in a wide variety of Smart City applications and infrastructures, often without the citizens being aware of the nature of their “intelligence”. AI can affect citizens’ lives concretely, and thus, there may be uncertainty, concerns, or even fears related to AI. To build acceptable futures of Smart Cities with AI-enabled functionalities, the Human-Centered AI (HCAI) approach offers a relevant framework for understanding citizen perceptions. However, only a few studies have focused on clarifying the citizen perceptions of AI in the context of smart city research. To address this gap, we conducted a two-phased study. In the pre-study, we explored citizen perceptions and experiences of AI with a short survey ( N  = 91). Second, scenario-based interviews ( N  = 7) were utilized to gain in-depth insights of citizen perceptions of AI in the Smart City context. Five central themes were recognized: (1) I don’t like them monitoring me, (2) I want maximum gain for minimum effort, (3) I don’t want AI to mimic people, (4) I’ll avoid using AI if I consider the risk too high, and (5) I don’t need to be concerned about AI. These offer an idea of human-centered requirements worth considering while designing AI applications for future Smart Cities.",included,2058,0.864713848
10.48550/arxiv.2401.01291,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,arXiv.org,1/1/2000 0:00,semantic_scholar,generative ai is already widespread in the public sector,https://www.semanticscholar.org/paper/6d67a918707f0c20cb847d4d4611b34877ccd5e6,"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work. But to what extent is generative AI already in use in the public sector? Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question. We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system. Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future. For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact). Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%). While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces. In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines. The UK's public sector urgently needs to develop more systematic methods for taking advantage of the technology.",not included,93,0.863731265
10.48550/arxiv.2408.00965,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,arXiv.org,1/1/2000 0:00,semantic_scholar,integrating esg and ai: a comprehensive responsible ai assessment framework,https://www.semanticscholar.org/paper/15b153e0f6342ad455bfb5e2b6090b89c8066340,"Artificial Intelligence (AI) is a widely developed and adopted technology across entire industry sectors. Integrating environmental, social, and governance (ESG) considerations with AI investments is crucial for ensuring ethical and sustainable technological advancement. Particularly from an investor perspective, this integration not only mitigates risks but also enhances long-term value creation by aligning AI initiatives with broader societal goals. Yet, this area has been less explored in both academia and industry. To bridge the gap, we introduce a novel ESG-AI framework, which is developed based on insights from engagements with 28 companies and comprises three key components. The framework provides a structured approach to this integration, developed in collaboration with industry practitioners. The ESG-AI framework provides an overview of the environmental and social impacts of AI applications, helping users such as investors assess the materiality of AI use. Moreover, it enables investors to evaluate a company's commitment to responsible AI through structured engagements and thorough assessment of specific risk areas. We have publicly released the framework and toolkit in April 2024, which has received significant attention and positive feedback from the investment community. This paper details each component of the framework, demonstrating its applicability in real-world contexts and its potential to guide ethical AI investments.",included,147,0.863704979
10.1007/s00146-021-01268-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,australian public understandings of artificial intelligence,http://dx.doi.org/10.1007/s00146-021-01268-z,"In light of the growing need to pay attention to general public opinions and sentiments toward AI, this paper examines the levels of understandings amongst the Australian public toward the increased societal use of AI technologies. Drawing on a nationally representative survey of 2019 adults across Australia, the paper examines how aware people consider themselves to be of recent developments in AI; variations in popular conceptions of what AI is; and the extent to which levels of support for AI are liable to alter with additional exposure to information about AI. While a majority of respondents consider themselves to have little knowledge and familiarity with the topic of AI, the survey nevertheless finds considerable range of relatively ‘plausible’ basic understandings of what AI is. Significantly, repeated questioning highlights a willingness among many people to reassess their opinions once having received further information about AI, and being asked to think through issues relating to AI and society. These patterns remain relatively consistent, regardless of respondents’ political orientation, income, social class and other demographic characteristics. As such, the paper concludes by considering how these findings provide support for the development of public education efforts to further enhance what might be termed ‘public understanding of AI’.",not included,2543,0.863689601
10.1177/0266382120923962,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Business Information Review,1/1/2020 0:00,semantic_scholar,regulation and ethics in artificial intelligence and machine learning technologies: where are we now? who is responsible? can the information professional play a role?,https://www.semanticscholar.org/paper/4ae7b75e7b0fdf00a687c8f308ceccbe26c24e8d,"Artificial intelligence (AI) and machine learning (ML) technologies are rapidly maturing and proliferating through all public and private sectors. The potential for these technologies to do good and to help us in our everyday lives is immense. But there is a risk that unless managed and controlled AI can also cause us harm. Questions about regulation, what form it takes and who is responsible for governance are only just beginning to be answered. In May 2019, 42 countries came together to support a global governance framework for AI. The Organisation for Economic Co-operation and Development (OECD) Principles on Artificial Intelligence (OECD (2019) OECD principles on AI. Available at: https://www.oecd.org/going-digital/ai/principles/ (accessed 2 March 2020)) saw like-minded democracies of the world commit to common AI values of trust and respect. In Europe, the European Commission’s (EC) new president, Ursula von der Leyen has made calls for a General Data Protection Regulation style. As a first step the EC has published a white paper: ‘On Artificial Intelligence – A European Approach to Excellence and Trust’ (European Commission (2020) Report, Europa, February). In February 2020, the UK government has published a report on ‘Artificial Intelligence in the Public Sector’ (The Committee on Standards in Public Life (2020) Artificial intelligence and public standards. Report, UK Government, February). This article discusses some of the potential threats AI may hold if left unregulated. It provides a brief overview of the regulatory activities for AI worldwide, and in more detail the current UK AI regulatory landscape. Finally, the article looks at the role that the information professional might play in AI and ML.",not included,16,0.862687111
10.1007/s43681-022-00205-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/1/2023 0:00,springer,"a principled governance for emerging ai regimes: lessons from china, the european union, and the united states",http://dx.doi.org/10.1007/s43681-022-00205-0,"Artificial intelligence (AI) governance is anticipated to have a transformative impact on humanity which has prompted researchers to analyze its implementation and use to ensure that the technology advances ethically and is beneficial for society. Though countries have begun to develop governance initiatives to regulate AI, the number of emerging AI regimes with an established structure is still relatively low. Meanwhile, the technology is advancing rapidly and has already caused harm inequitably to underrepresented communities. Thus, there is an urgent need to establish robust governance to mitigate the issues and risks attendant when deploying AI.While numerous ethics, principles, and structures have been recommended, this article intends to address the policy lag by providing policymakers with a simple and compelling AI governance framework that situates AI principles as the guiding baseline for developing and evaluating policies. Rather than devising new policy recommendations, the most recent (at the time of writing) and comprehensive governance documents from China, the European Union, and the United States were systematically selected, and examined in a comparative analysis to study how the three regimes address AI principles. Based on the comparative analysis, the most comprehensive and effective recommendations were selected to produce seven broad policy recommendations. The governance framework and recommendations are intentionally broad so that they can be adapted to adequately address AI principles across diverse contexts, encouraging the implementation of AI principles, increasing the likelihood of beneficial AI, and reducing the risks and harms associated with the technology. Nevertheless, the recommendations provided should not be considered exhaustive as the technology has an immense reach and new AI governance initiatives are developing continuously in this growth period in AI governance. It is thus essential for policymakers to survey the most current and relevant governance landscape to identify the best practices that are suitable for their specific context and need.",included,1904,0.862418175
10.1016/j.giq.2023.101828,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85151401656,scopus,6/1/2023,scopus,whether ai adoption challenges matter for public managers? the case of polish cities,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151401656&origin=inward,"
                  A growing body of literature shows that despite the significant benefits of artificial intelligence (AI), its adoption has many unknowns and challenges. However, theoretical studies dominate this topic. Completing the recent works, this article aims to identify challenges faced by public organizations when adopting AI based on the PRISMA Framework and an empirical assessment of these challenges in the opinion of public managers using survey research. The adopted research procedure is also an added value because it could be replicated in other context scenarios. To achieve this paper's aim, the Systematic Literature Review (SLR) and survey research among authorities in 414 Polish cities were carried out. As a result, a list of 15 challenges and preventive activities proposed by researchers to prevent these challenges have been identified. Empirical verification of identified challenges allows us to determine which of them limit AI adoption to the greatest extent in public managers' opinion. These include a lack of strategy or plans to initial adoption / continued usage of AI; no ensuring that AI is used in line with human values; employees' insufficient knowledge of how to use AI; insufficient AI policies, laws, and regulations; and different expectations of stakeholders and partners about AI. These findings could help practitioners to prioritize AI adoption activities and add value to digital government theory.
               ",included,8564,0.861989141
10.1007/s43681-022-00232-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,11/1/2023 0:00,springer,all that glitters is not gold: trustworthy and ethical ai principles,http://dx.doi.org/10.1007/s43681-022-00232-x,"Ethics of technology systems have become an area of interest in academic research as well as international policy in recent years. Several organisation have consequently published principles of ethical artificial intelligence (AI) in line with this trend. The documents identify principles, values, and other abstract requirements for AI development and deployment. Critics raise concerns about whether these documents are in fact constructive, or if they are produced as a higher form of virtue signalling. A theme that is beginning to become apparent in the academic literature regarding these documents is the inherent lack of effective and practical methods and processes for producing ethical AI. This article attempts a critical analysis which draws upon ethical AI documents from a range of contexts including company, organisational, governmental, and academic perspectives. Both the theoretical and practical components of AI guidelines are explored and analysed, consequently bringing to light the necessity of introducing a measurable component to such documents for the purpose of ensuring a positive outcome of deploying AI systems based on ethical principles. We propose a minimal framework for stakeholders to develop AI in an ethical and human-centred manner.",included,1618,0.861966968
10.1145/3657054.3657125,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2000 0:00,semantic_scholar,comparative analysis of generative ai risks in the public sector,https://www.semanticscholar.org/paper/cf2a8c29efde5517cc86378ade038d6974930b6a,"The landscape of artificial intelligence (AI) has experienced a monumental shift with the emerging of Generative AI (GenAI), which has demonstrated to be a transformative tool across diverse sectors. GenAI outputs can span various digital formats, including text, images, videos, and audio, generating particular interest in the public sector. The growing interest of governments in integrating GenAI technologies in public sector operations is marked by the creation of emerging governance instruments and the formulation of soft laws, like standards, principles, and guidelines. This study aims to delve into the intricacies and potential risks associated with the deployment of GenAI within government. Through a qualitative content analysis, the research meticulously examines GenAI usage guidelines issued by Australia, Canada, New Zealand, the United Kingdom, and South Korea. The objective is to discern the risks acknowledged by these countries' soft laws and compare them with the risks identified by scholars in the field. The performed comparative analysis across countries suggest that the use of GenAI in the public sector raises common risks such as information leakage, data privacy, security, and concerns over public trust. By elucidating the varied risk perceptions across different national contexts, this study provides theoretical and practical implications related to the risks of GenAI within the public sector. Moreover, it sets a foundation for future research and policy development, ensuring that generative AI is used as a force for good in public governance.",included,94,0.86182034
10.1007/s10796-024-10475-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Information Systems Frontiers,Springer,2/21/2024 0:00,springer,making sense of ai benefits: a mixed-method study in canadian public administration,http://dx.doi.org/10.1007/s10796-024-10475-0,"Public administrators receive conflicting signals on the transformative benefits of Artificial Intelligence (AI) and the counternarratives of AI’s ethical impacts on society and democracy. Against this backdrop, this paper explores the factors that affect the sensemaking of AI benefits in Canadian public administration. A mixed-method research design using PLS-SEM ( n  = 272) and interviews ( n  = 38) tests and explains the effect of institutional and consultant pressures on the perceived benefits of AI use. The quantitative study shows only service coercive pressures have a significant effect on perceived benefits of AI use and consultant pressures are significant in generating all institutional pressures. The qualitative study explains the results and highlights the underlying mechanisms. The key conclusion is that in the earlier stages of AI adoption, demand pull is the main driver rather than technology push. A processual sensemaking model is developed extending the theory on institutions and sensemaking. And several managerial implications are discussed.",included,1227,0.861712575
10.1007/s00146-021-01256-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,enter the metrics: critical theory and organizational operationalization of ai ethics,http://dx.doi.org/10.1007/s00146-021-01256-3,"As artificial intelligence (AI) deployment is growing exponentially, questions have been raised whether the developed AI ethics discourse is apt to address the currently pressing questions in the field. Building on critical theory, this article aims to expand the scope of AI ethics by arguing that in addition to ethical principles and design, the organizational dimension (i.e. the background assumptions and values influencing design processes) plays a pivotal role in the operationalization of ethics in AI development and deployment contexts. Through the prism of critical theory, and the notions of underdetermination and technical code as developed by Feenberg in particular, the organizational dimension is related to two general challenges in operationalizing ethical principles in AI: (a) the challenge of ethical principles placing conflicting demands on an AI design that cannot be satisfied simultaneously, for which the term ‘inter-principle tension’ is coined, and (b) the challenge of translating an ethical principle to a technological form, constraint or demand, for which the term ‘intra-principle tension’ is coined. Rather than discussing principles, methods or metrics, the notion of technical code precipitates a discussion on the subsequent questions of value decisions, governance and procedural checks and balances. It is held that including and interrogating the organizational context in AI ethics approaches allows for a more in depth understanding of the current challenges concerning the formalization and implementation of ethical principles as well as of the ways in which these challenges could be met.",not included,2551,0.86018312
10.1038/s42256-019-0114-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Nature Machine Intelligence,Nature,11/1/2019 0:00,springer,principles alone cannot guarantee ethical ai,http://dx.doi.org/10.1038/s42256-019-0114-4,"Artificial intelligence (AI) ethics is now a global topic of discussion in academic and policy circles. At least 84 public–private initiatives have produced statements describing high-level principles, values and other tenets to guide the ethical development, deployment and governance of AI. According to recent meta-analyses, AI ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach for the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement. AI ethics initiatives have seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite this, Brent Mittelstadt highlights important differences between medical practice and AI development that suggest a principled approach may not work in the case of AI.",not included,4722,0.859493732
10.1007/s10676-021-09593-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Ethics and Information Technology,Springer,9/1/2021 0:00,springer,artificial intelligence regulation: a framework for governance,http://dx.doi.org/10.1007/s10676-021-09593-z,"This article develops a conceptual framework for regulating Artificial Intelligence (AI) that encompasses all stages of modern public policy-making, from the basics to a sustainable governance. Based on a vast systematic review of the literature on Artificial Intelligence Regulation (AIR) published between 2010 and 2020, a dispersed body of knowledge loosely centred around the “framework” concept was organised, described, and pictured for better understanding. The resulting integrative framework encapsulates 21 prior depictions of the policy-making process, aiming to achieve gold-standard societal values, such as fairness, freedom and long-term sustainability. This challenge of integrating the AIR literature was matched by the identification of a structural common ground among different approaches. The AIR framework results from an effort to identify and later analytically deduce synthetic, and generic tool for a country-specific, stakeholder-aware analysis of AIR matters. Theories and principles as diverse as Agile and Ethics were combined in the “AIR framework”, which provides a conceptual lens for societies to think collectively and make informed policy decisions related to what, when, and how the uses and applications of AI should be regulated. Moreover, the AIR framework serves as a theoretically sound starting point for endeavours related to AI regulation, from legislation to research and development. As we know, the (potential) impacts of AI on society are immense, and therefore the discourses, social negotiations, and applications of this technology should be guided by common grounds based on contemporary governance techniques, and social values legitimated via dialogue and scientific research.",included,3593,0.859160125
10.5937/napredak5-52069,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Napredak,1/1/2000 0:00,semantic_scholar,the transformative potential of generative artificial intelligence,https://www.semanticscholar.org/paper/2e6e0c741d6c83f12dfac4e02b570c64b9aa0bf7,"This paper analyses the transformative potential of generative artificial intelligence at macro, meso, and micro levels of social and economic structures. The aim is to determine the impact of these technologies on various aspects of society and economy, including business operations and the labour market. The potential of new technologies to increase productivity, transform business models, and create new professional roles has been examined through a comprehensive analysis of data and studies. It has been concluded that generative artificial intelligence can fundamentally change the labour market, globally increase gross domestic product, and improve both the public and private sectors. The paper provides insights into future trends and regulatory and structural changes that are necessary for optimising the application of generative AI.",not included,110,0.858366907
10.1007/s00146-021-01263-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,ai under great uncertainty: implications and decision strategies for public policy,http://dx.doi.org/10.1007/s00146-021-01263-4,"Decisions where there is not enough information for a well-informed decision due to unidentified consequences, options, or undetermined demarcation of the decision problem are called decisions under great uncertainty. This paper argues that public policy decisions on how and if to implement decision-making processes based on machine learning and AI for public use are such decisions. Decisions on public policy on AI are uncertain due to three features specific to the current landscape of AI, namely (i) the vagueness of the definition of AI, (ii) uncertain outcomes of AI implementations and (iii) pacing problems. Given that many potential applications of AI in the public sector concern functions central to the public sphere, decisions on the implementation of such applications are particularly sensitive. Therefore, it is suggested that public policy-makers and decision-makers in the public sector can adopt strategies from the argumentative approach in decision theory to mitigate the established great uncertainty. In particular, the notions of framing and temporal strategies are considered.",not included,2544,0.858222485
10.1007/s00146-022-01452-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/1/2023 0:00,springer,cognitive architectures for artificial intelligence ethics,http://dx.doi.org/10.1007/s00146-022-01452-9,"As artificial intelligence (AI) thrives and propagates through modern life, a key question to ask is how to include humans in future AI? Despite human involvement at every stage of the production process from conception and design through to implementation, modern AI is still often criticized for its “black box” characteristics. Sometimes, we do not know what really goes on inside or how and why certain conclusions are met. Future AI will face many dilemmas and ethical issues unforeseen by their creators beyond those commonly discussed (e.g., trolley problems and variants of it) and to which solutions cannot be hard-coded and are often still up for debate. Given the sensitivity of such social and ethical dilemmas and the implications of these for human society at large, when and if our AI make the “wrong” choice we need to understand how they got there in order to make corrections and prevent recurrences. This is particularly true in situations where human livelihoods are at stake (e.g., health, well-being, finance, law) or when major individual or household decisions are taken. Doing so requires opening up the “black box” of AI; especially as they act, interact, and adapt in a human world and how they interact with other AI in this world. In this article, we argue for the application of cognitive architectures for ethical AI. In particular, for their potential contributions to AI transparency, explainability, and accountability. We need to understand how our AI get to the solutions they do, and we should seek to do this on a deeper level in terms of the machine-equivalents of motivations, attitudes, values, and so on. The path to future AI is long and winding but it could arrive faster than we think. In order to harness the positive potential outcomes of AI for humans and society (and avoid the negatives), we need to understand AI more fully in the first place and we expect this will simultaneously contribute towards greater understanding of their human counterparts also.",included,2250,0.857988954
10.1145/3219819.3226071,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Knowledge Discovery and Data Mining,1/1/2018 0:00,semantic_scholar,societal impact of data science and artificial intelligence,https://www.semanticscholar.org/paper/9dacbc65c23215f79a9a966abf8c403175e56aa8,"The explosion of interest in KDD and other Data Science/Machine Learning/AI conferences is just one of the many signs that these technologies are no longer confined to the realms of academia and a hand-full of tech companies. As our daily lives seamlessly integrate more and more data-driven applications, people's excitement is tempered by worry about the technologies' potential to disrupt their existence. Having worked for almost 30 years to design and develop these technologies, the KDD community now should examine and debate the impact of Machine Learning & AI on the broader world. Beyond the hype, where do we stand with respect to the dangers? What role can our community play to alleviate concerns around AI taking jobs, or taking over? How can the value derived from data be distributed fairly? Are concerns about inequity well-founded or rather largely problems of perception? What can be done to bring data hunger and data sharing concerns to a level of equilibrium? How do we prepare people to interact with intelligent systems at scale? Can we unleash the incredible responsiveness of the KDD community toward longer-term more impactful projects across sectors that are essential for social good, such as Health, Environmental Sustainability, and Public Welfare.",not included,6,0.857516289
10.1007/s10676-020-09534-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Ethics and Information Technology,Springer,6/1/2021 0:00,springer,applying a principle of explicability to ai research in africa: should we do it?,http://dx.doi.org/10.1007/s10676-020-09534-2,"Developing and implementing artificial intelligence (AI) systems in an ethical manner faces several challenges specific to the kind of technology at hand, including ensuring that decision-making systems making use of machine learning are just, fair, and intelligible, and are aligned with our human values. Given that values vary across cultures, an additional ethical challenge is to ensure that these AI systems are not developed according to some unquestioned but questionable assumption of universal norms but are in fact compatible with the societies in which they operate. This is particularly pertinent for AI research and implementation across Africa, a ground where AI systems are and will be used but also a place with a history of imposition of outside values. In this paper, we thus critically examine one proposal for ensuring that decision-making systems are just, fair, and intelligible—that we adopt a principle of explicability to generate specific recommendations—to assess whether the principle should be adopted in an African research context. We argue that a principle of explicability not only can contribute to responsible and thoughtful development of AI that is sensitive to African interests and values, but can also advance tackling some of the computational challenges in machine learning research. In this way, the motivation for ensuring that a machine learning-based system is just, fair, and intelligible is not only to meet ethical requirements, but also to make effective progress in the field itself.",not included,3745,0.857146084
10.1016/j.procs.2022.01.308,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85127772806,scopus,1/1/2022,scopus,human-centered artificial intelligence for the public sector: the gate keeping role of the public procurement professional,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85127772806&origin=inward,"The increasing deployment of artificial intelligence (AI) powered solutions for the public sector is hoped to change how developing countries deliver services in key sectors such as agriculture, healthcare, education, and social sectors. And yet AI has a high potential for abuse and creates risks, which if not managed and monitored will jeopardize respect and dignity of the most vulnerable in society. In this study, we argue for delineating public procurements’ role in the human-centred AI (HCAI) discourses, focusing on the developing countries. The study is based on an exploratory inquiry and gathered data among procurement practitioners in Uganda and Kenya, which have similar country procurement regimes: where traditional forms of competition in procurement apply compared to more recent pre-commercial procurement mechanisms that suit AI procurement. We found limited customization in AI technologies, a lack of developed governance frameworks, and little knowledge and distinction between AI procurement and other typical technology procurement processes. We proposed a framework, which in absence of good legal frameworks can allow procurement professionals to embed HCAI principles in AI procurement processes.",included,8624,0.856960893
10.1007/s42439-023-00088-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Jus Cogens,Springer,4/1/2024 0:00,springer,can ai-based decisions be genuinely public? on the limits of using ai-algorithms in public institutions,http://dx.doi.org/10.1007/s42439-023-00088-7,"AI-based algorithms are used extensively by public institutions. Thus, for instance, AI algorithms have been used in making decisions concerning punishment providing welfare payments, making decisions concerning parole, and many other tasks which have traditionally been assigned to public officials and/or public entities. We develop a novel argument against the use of AI algorithms, in particular with respect to decisions made by public officials and public entities. We argue that decisions made by AI algorithms cannot count as public decisions, namely decisions that are made in the name of citizens and that this fact should be taken into consideration when utilizing AI to replace public officials.",not included,1033,0.856049955
10.1057/s41310-023-00207-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',International Journal of Disclosure and Governance,Springer,9/1/2024 0:00,springer,unlocking the potential of augmented intelligence: a discussion on its role in boardroom decision-making,http://dx.doi.org/10.1057/s41310-023-00207-2,"Recent developments in artificial intelligence (AI) have made AI applications in corporate governance an area of increasing interest to researchers and practitioners. Augmented intelligence, also known as advisory intelligence, is a form of collaboration between humans and AI, where the goal is to enhance human capabilities. It represents the second stage of AI development in corporate governance. In the realm of boards of directors, augmented intelligence offers a unique opportunity to enable machines to effectively collaborate with board members. This collaboration allows boards to harness the expertise of AI without supplanting the essential human element. In contrast, there exist more autonomous AI systems designed to operate independently, which could potentially lead to the replacement of humans on the board. This study seeks to assess the suitability of augmented intelligence for corporate boards, particularly in comparison to these more autonomous AI systems. Furthermore, it addresses the application of augmented intelligence in boardroom decision-making, its role in improving directors' decision-making abilities, and the associated risks and challenges.",not included,334,0.855029643
10.1007/s13132-023-01433-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of the Knowledge Economy,Springer,6/1/2024 0:00,springer,"artificial intelligence (ai) and automation in administrative procedures: potentials, limitations, and framework conditions",http://dx.doi.org/10.1007/s13132-023-01433-3,"Integrating artificial intelligence (AI) systems into administrative procedures can revolutionize the way processes are conducted and fundamentally change established forms of action and organization in administrative law. However, implementing AI in administrative procedures requires a comprehensive evaluation of the capabilities and limitations of different systems, including considerations of transparency and data availability. Data are a crucial factor in the operation of AI systems and the validity of their predictions. It is essential to ensure that the data used to train AI algorithms are extensive, representative, and free of bias. Transparency is also an important aspect establishing trust and reliability in AI systems, particularly regarding the potential for transparent representation in rule-based and machine-learning AI systems. This paper examines the potential and challenges that arise from integrating AI into administrative procedures. In addition, the paper offers a nuanced perspective on current developments in artificial intelligence and provides a conceptual framework for its potential applications in administrative procedures. Beyond this, the paper highlights essential framework conditions that require continuous monitoring to ensure optimal results in practice.",included,730,0.854819238
10.1007/s11948-024-00472-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Science and Engineering Ethics,Springer,3/7/2024 0:00,springer,mapping ethical artificial intelligence policy landscape: a mixed method analysis,http://dx.doi.org/10.1007/s11948-024-00472-6,"As more national governments adopt policies addressing the ethical implications of artificial intelligence, a comparative analysis of policy documents on these topics can provide valuable insights into emerging concerns and areas of shared importance. This study critically examines 57 policy documents pertaining to ethical AI originating from 24 distinct countries, employing a combination of computational text mining methods and qualitative content analysis. The primary objective is to methodically identify common themes throughout these policy documents and perform a comparative analysis of the ways in which various governments give priority to crucial matters. A total of nineteen topics were initially retrieved. Through an iterative coding process, six overarching themes were identified: principles, the protection of personal data, governmental roles and responsibilities, procedural guidelines, governance and monitoring mechanisms, and epistemological considerations. Furthermore, the research revealed 31 ethical dilemmas pertaining to AI that had been overlooked previously but are now emerging. These dilemmas have been referred to in different extents throughout the policy documents. This research makes a scholarly contribution to the expanding field of technology policy formulations at the national level by analyzing similarities and differences among countries. Furthermore, this analysis has practical ramifications for policymakers who are attempting to comprehend prevailing trends and potentially neglected domains that demand focus in the ever-evolving field of artificial intelligence.",not included,1126,0.853376031
10.1007/s10676-022-09624-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Ethics and Information Technology,Springer,1/24/2022 0:00,springer,"a sociotechnical perspective for the future of ai: narratives, inequalities, and human control",http://dx.doi.org/10.1007/s10676-022-09624-3,"Different people have different perceptions about artificial intelligence (AI). It is extremely important to bring together all the alternative frames of thinking—from the various communities of developers, researchers, business leaders, policymakers, and citizens—to properly start acknowledging AI. This article highlights the ‘fruitful collaboration’ that sociology and AI could develop in both social and technical terms. We discuss how biases and unfairness are among the major challenges to be addressed in such a sociotechnical perspective. First, as intelligent machines reveal their nature of ‘magnifying glasses’ in the automation of existing inequalities, we show how the AI technical community is calling for transparency and explainability, accountability and contestability. Not to be considered as panaceas, they all contribute to ensuring human control in novel practices that include requirement, design and development methodologies for a fairer AI. Second, we elaborate on the mounting attention for technological narratives as technology is recognized as a social practice within a specific institutional context. Not only do narratives reflect organizing visions for society, but they also are a tangible sign of the traditional lines of social, economic, and political inequalities. We conclude with a call for a diverse approach within the AI community and a richer knowledge about narratives as they help in better addressing future technical developments, public debate, and policy. AI practice is interdisciplinary by nature and it will benefit from a socio-technical perspective.",not included,3316,0.853071272
10.1007/s43621-021-00064-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Discover Sustainability,Springer,11/29/2021 0:00,springer,regulating artificial-intelligence applications to achieve the sustainable development goals,http://dx.doi.org/10.1007/s43621-021-00064-5,"Artificial intelligence is producing a revolution with increasing impacts on the people, planet, and prosperity. This perspective illustrates some of the AI applications that can accelerate the achievement of the United Nations Sustainable Development Goals (SDGs) and highlights some of the considerations that could hinder the efforts towards them. In this context, we strongly support the development of an 18 th SDG on digital technologies. This emphasizes the importance of establishing standard AI guidelines and regulations for the beneficial applications of AI. Such regulations should focus on concrete applications of AI, rather than generally on AI technology, to facilitate both AI development and enforceability of legal implications.",not included,3474,0.85261178
10.1007/s00146-023-01750-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,8/30/2023 0:00,springer,"basic values in artificial intelligence: comparative factor analysis in estonia, germany, and sweden",http://dx.doi.org/10.1007/s00146-023-01750-w,"Increasing attention is paid to ethical issues and values when designing and deploying artificial intelligence (AI). However, we do not know how those values are embedded in artificial artefacts or how relevant they are to the population exposed to and interacting with AI applications. Based on literature engaging with ethical principles and moral values in AI, we designed an original survey instrument, including 15 value components, to estimate the importance of these values to people in the general population. The article is based on representative surveys conducted in Estonia, Germany, and Sweden ( n  = 4501), which have varying experiences with implementing AI. The factor analysis showed four underlying dimensions of values embedded in the design and use of AI: (1) protection of personal interests to ensure social benefit, (2) general monitoring to ensure universal solidarity, (3) ensuring social diversity and social sustainability, and (4) efficiency. We found that value types can be ordered along the two dimensions of resources and change. The comparison between countries revealed that some dimensions, like social diversity and sustainability evaluations, are more universally valued among individuals, countries, and domains. Based on our analysis, we suggest a need and a framework for developing basic values in AI.",included,1862,0.852407932
10.1007/s00146-024-01866-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,2/19/2024 0:00,springer,ethical governance of artificial intelligence for defence: normative tradeoffs for principle to practice guidance,http://dx.doi.org/10.1007/s00146-024-01866-7,"The rapid diffusion of artificial intelligence (AI) technologies in the defence domain raises challenges for the ethical governance of these systems. A recent shift from the what to the how of AI ethics sees a nascent body of literature published by defence organisations focussed on guidance to implement AI ethics principles. These efforts have neglected a crucial intermediate step between principles and guidance concerning the elicitation of ethical requirements for specifying the guidance. In this article, we outline the key normative choices and corresponding tradeoffs that are involved in specifying guidance for the implementation of AI ethics principles in the defence domain. These correspond to: the AI lifecycle model used; the scope of stakeholder involvement; the accountability goals chosen; the choice of auditing requirements; and the choice of mechanisms for transparency and traceability. We provide initial recommendations for navigating these tradeoffs and highlight the importance of a pro-ethical institutional culture.",not included,1233,0.852367699
10.1007/s00146-020-00992-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,3/1/2021 0:00,springer,"the chinese approach to artificial intelligence: an analysis of policy, ethics, and regulation",http://dx.doi.org/10.1007/s00146-020-00992-2,"In July 2017, China’s State Council released the country’s strategy for developing artificial intelligence (AI), entitled ‘New Generation Artificial Intelligence Development Plan’ (新一代人工智能发展规划). This strategy outlined China’s aims to become the world leader in AI by 2030, to monetise AI into a trillion-yuan (ca. 150 billion dollars) industry, and to emerge as the driving force in defining ethical norms and standards for AI. Several reports have analysed specific aspects of China’s AI policies or have assessed the country’s technical capabilities. Instead, in this article, we focus on the socio-political background and policy debates that are shaping China’s AI strategy. In particular, we analyse the main strategic areas in which China is investing in AI and the concurrent ethical debates that are delimiting its use. By focusing on the policy backdrop, we seek to provide a more comprehensive and critical understanding of China’s AI policy by bringing together debates and analyses of a wide array of policy documents.",not included,3927,0.85193491
10.1007/s43681-022-00200-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/1/2023 0:00,springer,trust and trustworthiness in ai ethics,http://dx.doi.org/10.1007/s43681-022-00200-5,"Due to the extensive progress of research in artificial intelligence (AI) as well as its deployment and application, the public debate on AI systems has also gained momentum in recent years. With the publication of the Ethics Guidelines for Trustworthy AI (2019), notions of trust and trustworthiness gained particular attention within AI ethics-debates; despite an apparent consensus that AI should be trustworthy, it is less clear what trust and trustworthiness entail in the field of AI. In this paper, I give a detailed overview on the notion of trust employed in AI Ethics Guidelines thus far. Based on that, I assess their overlaps and their omissions from the perspective of practical philosophy. I argue that, currently, AI ethics tends to overload the notion of trustworthiness. It thus runs the risk of becoming a buzzword that cannot be operationalized into a working concept for AI research. What is needed, however, is an approach that is also informed with findings of the research on trust in other fields, for instance, in social sciences and humanities, especially in the field of practical philosophy. This paper is intended as a step in this direction.",included,1905,0.851370096
10.1007/s00146-016-0677-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,11/1/2017 0:00,springer,on the promotion of safe and socially beneficial artificial intelligence,http://dx.doi.org/10.1007/s00146-016-0677-0,"This paper discusses means for promoting artificial intelligence (AI) that is designed to be safe and beneficial for society (or simply “beneficial AI”). The promotion of beneficial AI is a social challenge because it seeks to motivate AI developers to choose beneficial AI designs. Currently, the AI field is focused mainly on building AIs that are more capable, with little regard to social impacts. Two types of measures are available for encouraging the AI field to shift more toward building beneficial AI. Extrinsic measures impose constraints or incentives on AI researchers to induce them to pursue beneficial AI even if they do not want to. Intrinsic measures encourage AI researchers to want to pursue beneficial AI. Prior research focuses on extrinsic measures, but intrinsic measures are at least as important. Indeed, intrinsic factors can determine the success of extrinsic measures. Efforts to promote beneficial AI must consider intrinsic factors by studying the social psychology of AI research communities.",included,5562,0.851082861
10.1007/s12525-022-00592-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Electronic Markets,Springer,12/1/2022 0:00,springer,user trust in artificial intelligence: a comprehensive conceptual framework,http://dx.doi.org/10.1007/s12525-022-00592-6,"This paper provides a systematic literature review of current studies between January 2015 and January 2022 on user trust in artificial intelligence (AI) that has been conducted from different perspectives. Such a review and analysis leads to the identification of the various components, influencing factors, and outcomes of users’ trust in AI. Based on the findings, a comprehensive conceptual framework is proposed for a better understanding of users’ trust in AI. This framework can further be tested and validated in various contexts for enhancing our knowledge of users’ trust in AI. This study also provides potential future research avenues. From a practical perspective, it helps AI-supported service providers comprehend the concept of user trust from different perspectives. The findings highlight the importance of building trust based on different facets to facilitate positive cognitive, affective, and behavioral changes among the users.",included,2542,0.849216938
10.1007/s44163-022-00019-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Discover Artificial Intelligence,Springer,3/3/2022 0:00,springer,reflections on the human role in ai policy formulations: how do national ai strategies view people?,http://dx.doi.org/10.1007/s44163-022-00019-3,"Purpose There is no artificial intelligence (AI) without people. People design and develop AI; they modify and use it and they have to reorganize the ways they have carried out tasks in their work and everyday life. National strategies are documents made to describe how different nations foster AI and as human dimensions are such an important aspect of AI, this study sought to investigate major national strategy documents to determine how they view the human role in emerging AI societies. Approach Our method for analyzing the strategies was conceptual analysis since the development of technology is embedded with conceptual ideas of humanity, explicit or implicit, and in addition to deepening analysis of explicit argumentation the method enables the deconstruction and reconstruction of meanings and conceptual relations within the strategies, exposing presumptions and tacit commitments of the writers. Findings The analysis of the documents illustrates that the general tendency in national strategies is globally dominantly technology-driven as the state of affairs appears to be creating new technologies. However, various human research points such as usability, user experience, sociotechnical and life-based themes are less well represented. Because national strategies are used to develop innovation processes, we argue that future development of national strategies could be improved by taking human research issues more energetically in the agenda. Originality Our study elaborates the current trends in AI-policy discourses and discusses reasons and possibilities for more holistic policymaking, making it a valuable resource for policymakers, researchers, and the larger public.",included,3196,0.8490327
10.1145/3325112.3325261,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2019 0:00,semantic_scholar,a realist perspective on ai-era public management*,https://www.semanticscholar.org/paper/ed5fbb58585ae1e9154ade1b4639060ace9c45ec,"Recent years have witnessed a number of significant ideas and approaches to addressing the shortcomings of the New Public Management paradigm. Three of these recent ideas, which include Digital Era Governance, Public Value Management, and New Public Governance, emphasise partnerships collaboration and engagement of citizens; performance governance and innovation and recognize the transformational potentials of digital technologies. Artificial Intelligence (AI) is one of the digital technologies attracting the greatest interest in public administration in terms of its potential impact. There are already a number of reports on how AI is being deployed in the public sector with good outcomes. By employing a realist review approach, this study investigates the specific mechanisms across post-NPM, organisational, individual and innovation contexts which are associated with positive outcomes from AI initiatives in the public sector. The study further examined the specific applications of AI initiatives within Post-NPM agendas. Our findings provide some empirical evidence for a better understanding of the conditions and where to target AI-based solutions in post-NPM context for positive outcomes.",not included,8,0.848655462
10.1186/s42467-019-0003-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI Perspectives,Springer,9/3/2019 0:00,springer,responsible ai: requirements and challenges,http://dx.doi.org/10.1186/s42467-019-0003-z,"This position paper discusses the requirements and challenges for responsible AI with respect to two interdependent objectives: (i) how to foster research and development efforts toward socially beneficial applications, and (ii) how to take into account and mitigate the human and social risks of AI systems.",not included,4801,0.848430991
10.1007/s13347-023-00668-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,11/1/2023 0:00,springer,artificial intelligence (ai) in islamic ethics: towards pluralist ethical benchmarking for ai,http://dx.doi.org/10.1007/s13347-023-00668-x,"This paper explores artificial intelligence (AI) ethics from an Islamic perspective at a critical time for AI ethical norm-setting. It advocates for a pluralist approach to ethical AI benchmarking. As rapid advancements in AI technologies pose challenges surrounding autonomy, privacy, fairness, and transparency, the prevailing ethical discourse has been predominantly Western or Eurocentric. To address this imbalance, this paper delves into the Islamic ethical traditions to develop a framework that contributes to the global debate on optimal norm setting for designing and using AI technologies. The paper outlines Islamic parameters for ethical values and moral actions in the context of AI's ethical uncertainties. It emphasizes the significance of both textual and non-textual Islamic sources in addressing these uncertainties while placing a strong emphasis on the notion of ""good"" or "" maṣlaḥa "" as a normative guide for AI's ethical evaluation. Defining maṣlaḥa as an ethical state of affairs in harmony with divine will, the paper highlights the coexistence of two interpretations of maṣlaḥa : welfarist/utility-based and duty-based. Islamic jurisprudence allows for arguments supporting ethical choices that prioritize building the technical infrastructure for AI to maximize utility. Conversely, it also supports choices that reject consequential utility calculations as the sole measure of value in determining ethical responses to AI advancements.",included,1613,0.847384274
10.1109/mts.2023.3341463,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',core,core,2024-01-22T00:00:00,core,the stuff we swim in: regulation alone will not lead to justifiable trust in ai,https://core.ac.uk/download/598038913.pdf,"Recent activity in the field of artificial intelligence (AI) has given rise to large language models (LLMs) such as GPT-4 and Bard. These are undoubtedly impressive achievements, but they raise serious questions about appropriation, accuracy, explainability, accessibility, responsibility, and more. There have been pusillanimous and self-exculpating calls for a halt in development by senior researchers in the field and largely self-serving comments by industry leaders around the potential of AI systems, good or bad. Many of these commentaries leverage misguided conceptions, in the popular imagination, of the competence of machine intelligence, based on some sort of Frankenstein or Terminator-like fiction: however, this leaves it entirely unclear what exactly the relationship between human(ity) and AI, as represented by LLMs or what comes after, is or could be",not included,8744,0.846451163
10.1007/s11023-023-09651-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Minds and Machines,Springer,12/1/2023 0:00,springer,democratizing ai from a sociotechnical perspective,http://dx.doi.org/10.1007/s11023-023-09651-z,"Artificial Intelligence (AI) technologies offer new ways of conducting decision-making tasks that influence the daily lives of citizens, such as coordinating traffic, energy distributions, and crowd flows. They can sort, rank, and prioritize the distribution of fines or public funds and resources. Many of the changes that AI technologies promise to bring to such tasks pertain to decisions that are collectively binding. When these technologies become part of critical infrastructures, such as energy networks, citizens are affected by these decisions whether they like it or not, and they usually do not have much say in them. The democratic challenge for those working on AI technologies with collectively binding effects is both to develop and deploy technologies in such a way that the democratic legitimacy of the relevant decisions is safeguarded. In this paper, we develop a conceptual framework to help policymakers, project managers, innovators, and technologists to assess and develop approaches to democratize AI. This framework embraces a broad sociotechnical perspective that highlights the interactions between technology and the complexities and contingencies of the context in which these technologies are embedded. We start from the problem-based and practice-oriented approach to democracy theory as developed by political theorist Mark Warren. We build on this approach to describe practices that can enhance or challenge democracy in political systems and extend it to integrate a sociotechnical perspective and make the role of technology explicit. We then examine how AI technologies can play a role in these practices to improve or inhibit the democratic nature of political systems. We focus in particular on AI-supported political systems in the energy domain.",included,1441,0.846423328
10.1007/s00146-022-01561-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2024 0:00,springer,subnational ai policy: shaping ai in a multi-level governance system,http://dx.doi.org/10.1007/s00146-022-01561-5,"The promises and risks of Artificial Intelligence permeate current policy statements and have attracted much attention by AI governance research. However, most analyses focus exclusively on AI policy on the national and international level, overlooking existing federal governance structures. This is surprising because AI is connected to many policy areas, where the competences are already distributed between the national and subnational level, such as research or economic policy. Addressing this gap, this paper argues that more attention should be dedicated to subnational efforts to shape AI and asks which themes are discussed in subnational AI policy documents with a case study of Germany’s 16 states. Our qualitative analysis of 34 AI policy documents issued on the subnational level demonstrates that subnational efforts focus on knowledge transfer between research and industry actors, the commercialization of AI, different economic identities of the German states, and the incorporation of ethical principles. Because federal states play an active role in AI policy, analysing AI as a policy issue on different levels of government is necessary and will contribute to a better understanding of the developments and implementations of AI strategies in different national contexts.",not included,736,0.84606427
10.1007/s40804-022-00262-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',European Business Organization Law Review,Springer,3/1/2023 0:00,springer,artificial intelligence and sustainable decisions,http://dx.doi.org/10.1007/s40804-022-00262-2,"When addressing corporate sustainability challenges, artificial intelligence (AI) is a double-edged sword. AI can make significant progress on the most complicated environmental and social problems faced by humans. On the other hand, the efficiencies and innovations generated by AI may also bring new risks, such as automated bias and conflicts with human ethics. We argue that companies and governments should make collective efforts to address sustainability challenges and risks brought by AI. Accountable and sustainable AI can be achieved through a proactive regulatory framework supported by rigorous corporate policies and reports. Given the rapidly evolving nature of this technology, we propose a harmonised and risk-based regulatory approach that accommodates diverse AI solutions to achieve the common good. Ensuring an adequate level of technological neutrality and proportionality of the regulation is the key to mitigating the wide range of potential risks inherent to the use of AI. Instead of promoting sustainability, unregulated AI would be a threat since it would not be possible to effectively monitor its effects on the economy, society and environment. Such a suitable regulatory framework would not only create a consensus concerning the risks to avoid and how to do so but also include enforcement mechanisms to ensure a trustworthy and ethical use of AI in the boardroom. Once this objective is achieved, it will be possible to refer to this technological development as a common good in itself that constitutes an essential asset to human development.",included,2339,0.845908046
10.1007/s10676-023-09725-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Ethics and Information Technology,Springer,10/28/2023 0:00,springer,the landscape of data and ai documentation approaches in the european policy context,http://dx.doi.org/10.1007/s10676-023-09725-7,"Nowadays, Artificial Intelligence (AI) is present in all sectors of the economy. Consequently, both data-the raw material used to build AI systems- and AI have an unprecedented impact on society and there is a need to ensure that they work for its benefit. For this reason, the European Union has put data and trustworthy AI at the center of recent legislative initiatives. An important element in these regulations is transparency, understood as the provision of information to relevant stakeholders to support their understanding of AI systems and data throughout their lifecycle. In recent years, an increasing number of approaches for documenting AI and datasets have emerged, both within academia and the private sector. In this work, we identify the 36 most relevant ones from more than 2200 papers related to trustworthy AI. We assess their relevance from the angle of European regulatory objectives, their coverage of AI technologies and economic sectors, and their suitability to address the specific needs of multiple stakeholders. Finally, we discuss the main documentation gaps found, including the need to better address data innovation practices (e.g. data sharing, data reuse) and large-scale algorithmic systems (e.g. those used in online platforms), and to widen the focus from algorithms and data to AI systems as a whole.",included,1655,0.845634043
10.61969/jai.1512906,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of AI,1/1/2000 0:00,semantic_scholar,"super ai, generative ai, narrow ai and chatbots: an assessment of artificial intelligence technologies for the public sector and public administration",https://www.semanticscholar.org/paper/be2fc5c4d3e7774f9bccdab34ad9f3e5fb7fff51,"Artificial intelligence encompasses a wide range of approaches, methodologies, and techniques aimed at mimicking human intelligence in machines. In recent times, the concepts of Generative Artificial Intelligence (AI), Super AI, and Narrow AI have attracted considerable attention. Undoubtedly, the success of ChatGPT in capturing all attention has played a significant role in this. Artificial intelligence technology has a profound impact on all sectors, and sector representatives are striving to adapt to this technology more quickly. It is projected that artificial intelligence could generate an economic size of 13 trillion American dollars by 2030. Developments in artificial intelligence technologies undoubtedly lead to significant improvements in the functioning of public institutions and access for citizens. Artificial intelligence has the potential to be used in many public services, including security and defense, healthcare services, education, transportation and infrastructure, environmental and natural resource management, law and justice systems, among others. Therefore, evaluating the types of artificial intelligence, Narrow AI applications, and chatbots for public use is seen as highly beneficial from the perspective of public administration and the public sector. In our study, the topics of super artificial intelligence, generative artificial intelligence, narrow artificial intelligence, and chatbots have been extensively evaluated within the context of the public sector and public administration. Utilizing findings from both Turkish and English literature reviews, the importance and potential impacts of artificial intelligence within the public sector, along with current trends, have been comprehensively assessed. This research delves into the concepts of artificial intelligence and its subsets—super AI, generative AI, narrow AI, and chatbots—within the general framework of the public sector. China and the United States are pioneering and leading countries in terms of investment. Although the U.S. stands out in many areas regarding investment, China's integration of artificial intelligence with national strategies and its policies indicate that it may play a more dominant role in the future. There are four main implementation areas of artificial intelligence in the public sector: efficiency and automation, service delivery, data-driven governance, and ethical and regulatory challenges. A review of the literature reveals that the ethical, legal, and social implications of implementing artificial intelligence in the public sector require more careful consideration. The study makes a significant contribution to the field of artificial intelligence discussions in public administration and the public sector, providing a comprehensive assessment of current discussions on artificial intelligence in the literature.",not included,91,0.845222652
10.1186/s12889-020-10030-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',BMC Public Health,BioMed Central,1/6/2021 0:00,springer,"“ai’s gonna have an impact on everything in society, so it has to have an impact on public health”: a fundamental qualitative descriptive study of the implications of artificial intelligence for public health",http://dx.doi.org/10.1186/s12889-020-10030-x,"Background Our objective was to determine the impacts of artificial intelligence (AI) on public health practice. Methods We used a fundamental qualitative descriptive study design, enrolling 15 experts in public health and AI from June 2018 until July 2019 who worked in North America and Asia. We conducted in-depth semi-structured interviews, iteratively coded the resulting transcripts, and analyzed the results thematically. Results We developed 137 codes, from which nine themes emerged. The themes included opportunities such as leveraging big data and improving interventions; barriers to adoption such as confusion regarding AI’s applicability, limited capacity, and poor data quality; and risks such as propagation of bias, exacerbation of inequity, hype, and poor regulation. Conclusions Experts are cautiously optimistic about AI’s impacts on public health practice, particularly for improving disease surveillance. However, they perceived substantial barriers, such as a lack of available expertise, and risks, including inadequate regulation. Therefore, investment and research into AI for public health practice would likely be beneficial. However, increased access to high-quality data, research and education regarding the limitations of AI, and development of rigorous regulation are necessary to realize these benefits.",not included,4040,0.844691515
10.1007/s00146-022-01499-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,2/1/2024 0:00,springer,artificial intelligence with american values and chinese characteristics: a comparative analysis of american and chinese governmental ai policies,http://dx.doi.org/10.1007/s00146-022-01499-8,"As China and the United States strive to be the primary global leader in AI, their visions are coming into conflict. This is frequently painted as a fundamental clash of civilisations, with evidence based primarily around each country’s current political system and present geopolitical tensions. However, such a narrow view claims to extrapolate into the future from an analysis of a momentary situation, ignoring a wealth of historical factors that influence each country’s prevailing philosophy of technology and thus their overarching AI strategies. In this article, we build a philosophy-of-technology-grounded framework to analyse what differences in Chinese and American AI policies exist and, on a fundamental level, why they exist. We support this with Natural Language Processing methods to provide an evidentiary basis for our analysis of policy differences. By looking at documents from three different American presidential administrations––Barack Obama, Donald Trump, and Joe Biden––as well as both national and local policy documents (many available only in Chinese) from China, we provide a thorough comparative analysis of policy differences. This article fills a gap in US–China AI policy comparison and constructs a framework for understanding the origin and trajectory of policy differences. By investigating what factors are informing each country’s philosophy of technology and thus their overall approach to AI policy, we argue that while significant obstacles to cooperation remain, there is room for dialogue and mutual growth.",not included,1277,0.844241261
10.1080/15265161.2022.2135875,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,American Journal of Bioethics,1/1/2022 0:00,semantic_scholar,an ai bill of rights: implications for health care ai and machine learning—a bioethics lens,https://www.semanticscholar.org/paper/6a16d761ca5f28fca358b64db53f3cedbd4d83a1,"Just last week (October 4, 2022), the U.S. White House released a blueprint for an A.I. Bill of Rights, consisting of “five principles and associated practices to help guide the design, use, and deployment of automated systems to protect the rights of the American public in the age of artificial intelligence.” The white paper states, “Developed through extensive consultation with the American public, these principles are a blueprint for building and deploying automated systems that are aligned with democratic values and protect civil rights, civil liberties, and privacy.” It further articulates that, “this framework provides a national values statement and toolkit that is sector-agnostic to inform building these protections into policy, practice, or the technological design process. Where existing law or policy—such as sector-specific privacy laws and oversight requirements—do not already provide guidance, the Blueprint for an AI Bill of Rights should be used to inform policy decisions” (Office of Science and Technology 2022). I applaud the development of this blueprint, but, after briefly describing each principle, highlight some challenges and questions that bioethicists working on AI and machine learning in health care ought to consider.",not included,34,0.843981087
10.1016/j.techsoc.2024.102471,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85184027069,scopus,3/1/2024,scopus,trustworthy ai in the public sector: an empirical analysis of a swedish labor market decision-support system,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184027069&origin=inward,"This paper investigates the deployment of Artificial Intelligence (AI) in the Swedish Public Employment Service (PES), focusing on the concept of trustworthy AI in public decision-making. Despite Sweden's advanced digitalization efforts and the widespread application of AI in the public sector, our study reveals significant gaps between theoretical ambitions and practical outcomes, particularly in the context of AI's trustworthiness. We employ a robust theoretical framework comprising Institutional Theory, the Resource-Based View (RBV), and Ambidexterity Theory, to analyze the challenges and discrepancies in AI implementation within PES. Our analysis shows that while AI promises enhanced decision-making efficiency, the reality is marred by issues of transparency, interpretability, and stakeholder engagement. The opacity of the neural network used by the agency to assess jobseekers’ need for support and the lack of comprehensive technical understanding among PES management contribute to the challenges in achieving transparent and interpretable AI systems. Economic pressures for efficiency often overshadow the need for ethical considerations and stakeholder involvement, leading to decisions that may not be in the best interest of jobseekers. We propose recommendations for enhancing AI's trustworthiness in public services, emphasizing the importance of stakeholder engagement, particularly involving jobseekers in the decision-making process. Our study advocates for a more nuanced balance between the use of advanced AI technologies and the leveraging of internal resources such as skilled personnel and organizational knowledge. We also highlight the need for improved AI literacy among both management and personnel to effectively navigate AI's integration into public decision-making processes. Our findings contribute to the ongoing debate on trustworthy AI, offering a detailed case study that bridges the gap between theoretical exploration and practical application. By scrutinizing the AI implementation in the Swedish PES, we provide valuable insights and guidelines for other public sector organizations grappling with the integration of AI into their decision-making processes.",included,8523,0.843266129
10.1145/3657054.3657126,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2000 0:00,semantic_scholar,gai as a catalyst in national technology sovereignty: evaluating the influence of gai on government policy,https://www.semanticscholar.org/paper/c37fd9c1303cce61ad8e84b8c4fb8bf36ba8fa70,"As a result of the prominence of generative artificial intelligence across diverse fields, it has become necessary for governments to develop national strategies for directing the ethical use of artificial intelligence to respect fundamental human values. This paper explores the role of Generative Artificial Intelligence (GAI) in technology sovereignty, its contributions, and benefits for the government, associated risks, and challenges, and how it influences government policies. It begins with examining GAI's capabilities to comprehend how it understands natural language, trains on existing data, and generates realistic outputs, followed by a discussion of its potential benefits for governments that enable them to act independently and autonomously in diverse sectors. It highlights how it can empower them to administer technological ecosystems, promote domestic innovation, and facilitate policy-making processes. However, contrary to its benefits, GAI is also capable of inflicting negative consequences on society. Therefore, the paper also addresses the risks and challenges associated with GAI that necessitate reflection on existing policies and developing new ones that align with a nation's legal frameworks. Exploring the influence of GAI on government policies, the paper highlights the significance of collaboration in policy-making endeavors to ensure ethical future developments and bring value to public interest and democratic values. This comprehensive analysis aims to shed light on the responsible and ethical use of GAI to preserve human rights, promote economic growth, sustain social justice, and inform the responsible use of GAI within the framework of technology sovereignty.",included,155,0.842683136
10.1007/s40319-023-01328-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',IIC - International Review of Intellectual Property and Competition Law,Springer,8/1/2023 0:00,springer,transparent ai? navigating between rules on trade secrets and access to information,http://dx.doi.org/10.1007/s40319-023-01328-5,"AI systems are nowadays employed in ever-increasing areas. This new era of technological development is exciting, but AI applications are also a cause for concern. If tasks that have hitherto normally been undertaken by human beings are now to be taken care of by ever more intelligent autonomous systems, how can we be certain that such functions are performed diligently and safely? Many areas of application of AI systems have also made the tribulations of AI utilization apparent. The EU’s Artificial Intelligence Act (AIA) aims to tackle the concerns and challenges related to the utilization of AI, and to develop human-centric, secure, trustworthy, and ethical AI systems for the EU markets. The provisions of the AIA establish a system of compliance assessment that requires AI providers to disclose how high-risk AI systems have been trained and put together. This article will look at the role of disclosure obligations under the provisions of the AIA. The focus is on the tension between obligations to disclose information on the one hand and requirements to protect the trade secrets contained in the technical details of AI on the other. This article will explain how the technical details of AI contain some information that does not qualify for trade secret protection. And even when there are trade secrets, there are exceptions to trade secret protection. Rules to enable access to information form part of the Trade Secrets Directive, but other legislative instruments too enable access and make it necessary to navigate between access and confidentiality.",not included,1902,0.842582703
10.1007/s00146-022-01596-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2024 0:00,springer,artificial intelligence in support of the circular economy: ethical considerations and a path forward,http://dx.doi.org/10.1007/s00146-022-01596-8,"The world’s current model for economic development is unsustainable. It encourages high levels of resource extraction, consumption, and waste that undermine positive environmental outcomes. Transitioning to a circular economy (CE) model of development has been proposed as a sustainable alternative. Artificial intelligence (AI) is a crucial enabler for CE. It can aid in designing robust and sustainable products, facilitate new circular business models, and support the broader infrastructures needed to scale circularity. However, to date, considerations of the ethical implications of using AI to achieve a transition to CE have been limited. This article addresses this gap. It outlines how AI is and can be used to transition towards CE, analyzes the ethical risks associated with using AI for this purpose, and supports some recommendations to policymakers and industry on how to minimise these risks.",included,729,0.842420101
10.1108/ijebr-02-2023-0169,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Journal of Entrepreneurial Behavior &amp; Research,1/1/2000 0:00,semantic_scholar,stand-alone or run together: artificial intelligence as an enabler for other technologies,https://www.semanticscholar.org/paper/76c0930edff3d28590c89523c8d96501cf12909f,"PurposeThe purpose of this study is to examine the role of artificial intelligence (AI) in transforming the healthcare sector, with a focus on how AI contributes to entrepreneurship and value creation. This study also aims to explore the potential of combining AI with other technologies, such as cloud computing, blockchain, IoMT, additive manufacturing and 5G, in the healthcare industry.Design/methodology/approachExploratory qualitative methodology was chosen to analyze 22 case studies from the USA, EU, Asia and South America. The data source was public and specialized podcast platforms.FindingsThe findings show that combining technologies can create a competitive advantage for technology entrepreneurs and bring about transitions from simple consumer devices to actionable healthcare applications. The results of this research identified three main entrepreneurship areas: 1. Analytics, including staff reduction, patient prediction and decision support; 2. Security, including protection against cyberattacks and detection of atypical cases; 3. Performance optimization, which, in addition to reducing the time and costs of medical procedures, includes staff training, reducing capital costs and working with new markets.Originality/valueThis study demonstrates how AI can be used with other technologies to cocreate value in the healthcare industry. This study provides a conceptual framework, “AI facilitators – AI achievers,” based on the findings and offer several theoretical contributions to academic literature in technology entrepreneurship and technology management and industry recommendations for practical implication.",not included,52,0.841522813
10.1007/s00146-024-02065-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,9/19/2024 0:00,springer,cognitive imperialism in artificial intelligence: counteracting bias with indigenous epistemologies,http://dx.doi.org/10.1007/s00146-024-02065-0,"This paper presents a novel methodology for integrating indigenous knowledge systems into AI development to counter cognitive imperialism and foster inclusivity. By critiquing the dominance of Western epistemologies and highlighting the risks of bias, the authors argue for incorporating diverse epistemologies. The proposed framework outlines a participatory approach that includes indigenous perspectives, ensuring AI benefits all. The methodology draws from AI ethics, indigenous studies, and postcolonial theory, emphasizing co-creation with indigenous communities, ethical protocols for indigenous data governance, and adaptation of AI algorithms. Case studies in natural language processing, content moderation, and healthcare demonstrate the methodology’s effectiveness and importance. By offering a concrete methodology for decolonizing AI, this paper contributes significantly to AI ethics and social justice, providing a roadmap for equitable, culturally respectful AI.",included,271,0.841297567
10.1007/s00146-022-01458-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/1/2023 0:00,springer,"ethical artificial intelligence framework for a good ai society: principles, opportunities and perils",http://dx.doi.org/10.1007/s00146-022-01458-3,"The justification and rationality of this paper is to present some fundamental principles, theories, and concepts that we believe moulds the nucleus of a good artificial intelligence (AI) society. The morally accepted significance and utilitarian concerns that stems from the inception and realisation of an AI’s structural foundation are displayed in this study. This paper scrutinises the structural foundation, fundamentals, and cardinal righteous remonstrations, as well as the gaps in mechanisms towards novel prospects and perils in determining resilient fundamentals, accountability, and AI’s convoluted and responsible implications. We outline a number of salient and practical benefits, in which to place moral norms within the mise en scène of AI, to delineate the rudimentary ethical dilemmas and decorous directions within the realms of AI.",included,2253,0.841210842
10.1007/s43681-023-00259-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/1/2024 0:00,springer,beware of sustainable ai! uses and abuses of a worthy goal,http://dx.doi.org/10.1007/s43681-023-00259-8,"The ethical debate about technologies called artificial intelligence (AI) has recently turned towards the question whether and in which sense using AI can be sustainable, distinguishing possible contributions of AI to achieve the end of sustainability on the one hand from the sustainability of AI and its underlying technologies as means on the other hand. This important distinction is both applied in the context of environmental as well as social sustainability. However, further elaboration is necessary to capture the complexities of sustainability assessments in the context of AI. To this end, our analysis of the ends and means of “sustainable AI” in social and environmental contexts leads to a matrix of four dimensions reflecting its social and its environmental impact and costs. This matrix avoids overly narrow, one-dimensional assessments that too quickly label some AI-based technology as sustainable. While a selective assessment can, at best, warrant the narrower verdict of “thin” sustainability, only such a comprehensive assessment can warrant the verdict of what we call “thick” sustainability. In consequence, we recommend to broaden the normative scope in considering the ethics and justice of AI and to use the notion “sustainability” more carefully and sparingly, and to pursue the more ambitious goal of “thick” sustainability of AI-based technologies to meaningfully contribute to actual improvements of human lives and living together. Current conditions of an economy oriented towards permanent growth, however, may make it difficult or even impossible to realise sustainable AI.",not included,908,0.84117806
10.1145/3531146.3533097,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Conference on Fairness, Accountability and Transparency",1/1/2022 0:00,semantic_scholar,how different groups prioritize ethical values for responsible ai,https://www.semanticscholar.org/paper/d821e5bdf1ab94bcd0e1a9e11fe1c296a01e3f02,"Private companies, public sector organizations, and academic groups have outlined ethical values they consider important for responsible artificial intelligence technologies. While their recommendations converge on a set of central values, little is known about the values a more representative public would find important for the AI technologies they interact with and might be affected by. We conducted a survey examining how individuals perceive and prioritize responsible AI values across three groups: a representative sample of the US population (N=743), a sample of crowdworkers (N=755), and a sample of AI practitioners (N=175). Our results empirically confirm a common concern: AI practitioners’ value priorities differ from those of the general public. Compared to the US-representative sample, AI practitioners appear to consider responsible AI values as less important and emphasize a different set of values. In contrast, self-identified women and black respondents found responsible AI values more important than other groups. Surprisingly, more liberal-leaning participants, rather than participants reporting experiences with discrimination, were more likely to prioritize fairness than other groups. Our findings highlight the importance of paying attention to who gets to define “responsible AI.”",not included,32,0.83999598
10.22495/cocv21i1art5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Corporate Ownership and Control,1/1/2000 0:00,semantic_scholar,aligning artificial intelligence with ethical accountancy: a global perspective on emerging frameworks,https://www.semanticscholar.org/paper/b7aafd56e7263ad9b8b693d6009742c84633d0db,"This study meticulously examines the integration of artificial intelligence (AI) into the accounting sector, revealing transformative opportunities alongside emerging ethical challenges. Drawing inspiration from established principles of the American Institute of Certified Public Accountants (AICPA) Code of Professional Conduct (AICPA, 2016), an innovative Accounting Framework for AI Ethics (AFAIE) is introduced. This framework aims to provide a tailored approach that ensures that the adoption of AI technologies aligns with the fundamental professional values of trust and integrity. It aims to address the concerns and potential risks associated with the use of AI and establish guidelines that promote accountability and transparency in the development and deployment of AI systems. The essence of this research is underscored by the advocacy for resilient ethical paradigms that are instrumental in navigating the complexities introduced by AI in accounting. Emphasizing a global perspective, this study advocates universal ethical guidelines, ensuring adaptability to specific regional and professional contexts (Association of Chartered Certified Accountants [ACCA], 2016; Bertucci et al., 2021). This synthesis of technology and ethics aims to foster an environment in which innovation thrives alongside steadfast adherence to professional integrity and responsibility.",not included,121,0.839896202
10.1007/s43681-024-00502-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,6/6/2024 0:00,springer,exploiting the margin: how capitalism fuels ai at the expense of minoritized groups,http://dx.doi.org/10.1007/s43681-024-00502-w,"This paper explores the intricate relationship between capitalism, racial injustice, and artificial intelligence (AI), arguing that AI acts as a contemporary vehicle for age-old forms of exploitation. By linking historical patterns of racial and economic oppression with current AI practices, this study illustrates how modern technology perpetuates and deepens societal inequalities. It specifically examines how AI is implicated in the exploitation of marginalized communities through underpaid labor in the gig economy, the perpetuation of biases in algorithmic decision-making, and the reinforcement of systemic barriers that prevent these groups from benefiting equitably from technological advances. Furthermore, the paper discusses the role of AI in extending and intensifying the social, economic, and psychological burdens faced by these communities, highlighting the problematic use of AI in surveillance, law enforcement, and mental health contexts. The analysis concludes with a call for transformative changes in how AI is developed and deployed. Advocating for a reevaluation of the values driving AI innovation, the paper promotes an approach that integrates social justice and equity into the core of technological design and policy. This shift is crucial for ensuring that AI serves as a tool for societal improvement, fostering empowerment and healing rather than deepening existing divides.",not included,706,0.839743972
10.1051/shsconf/202317904024,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,SHS Web of Conferences,1/1/2000 0:00,semantic_scholar,ethical considerations in artificial intelligence: a comprehensive disccusion from the perspective of computer vision,https://www.semanticscholar.org/paper/59664744a90437583c2911fc17273670435e0774,"This paper delves deeply into the multifaceted ethical challenges within the realm of computer vision, focusing intently on various ethical dimensions inherent in this cutting-edge field. It emphasizes the pressing need to address ethical concerns related to AI technologies, including algorithmic fairness, informed consent, public engagement, robust privacy protocols, transparency, and the integration of human judgment through human-in-the-loop systems. The study underscores the vital importance of collaboration among diverse stakeholders, including governments, businesses, academia, and society, to promote responsible and equitable AI practices within computer vision.Through meticulous examination, the paper highlights the urgency of balancing technological advancement with ethical considerations. It advocates for the development and implementation of ethical principles, ensuring that AI technologies align with societal values and promote fairness, transparency, and accountability. The collaborative efforts among various sectors are crucial to fostering an ethical framework that guides the responsible deployment of AI in the field of computer vision. By integrating ethical consciousness into the core of technological innovation, this approach aims to create a symbiotic relationship between artificial intelligence and society, ultimately benefiting humanity as a whole.",included,63,0.839675069
10.1186/s41018-021-00096-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of International Humanitarian Action,Springer,10/6/2021 0:00,springer,explicability of humanitarian ai: a matter of principles,http://dx.doi.org/10.1186/s41018-021-00096-6,"In the debate on how to improve efficiencies in the humanitarian sector and better meet people’s needs, the argument for the use of artificial intelligence (AI) and automated decision-making (ADMs) systems has gained significant traction and ignited controversy for its ethical and human rights-related implications. Setting aside the implications of introducing unmanned and automated systems in warfare, we focus instead on the impact of the adoption of AI-based ADMs in humanitarian response. In order to maintain the status and protection conferred by the humanitarian mandate, aid organizations are called to abide by a broad set of rules condensed in the humanitarian principles and notably the principles of humanity, neutrality, impartiality, and independence. But how do these principles operate when decision-making is automated? This article opens with an overview of AI and ADMs in the humanitarian sector, with special attention to the concept of algorithmic opacity. It then explores the transformative potential of these systems on the complex power dynamics between humanitarians, principled assistance, and affected communities during acute crises. Our research confirms that the existing flaws in accountability and epistemic processes can be also found in the mathematical and statistical formulas and in the algorithms used for automation, artificial intelligence, predictive analytics, and other efficiency-gaining-related processes. In doing so, our analysis highlights the potential harm to people resulting from algorithmic opacity, either through removal or obfuscation of the causal connection between triggering events and humanitarian services through the so-called black box effect (algorithms are often described as black boxes, as their complexity and technical opacity hide and obfuscate their inner workings (Diakopoulos, Tow Center for Digital Journ, 2017 ). Recognizing the need for a humanitarian ethics dimension in the analysis of automation, AI, and ADMs used in humanitarian action, we endorse the concept of “explicability” as developed within the ethical framework of machine learning and human-computer interaction, together with a set of proxy metrics. Finally, we stress the need for developing auditable standards, as well as transparent guidelines and frameworks to rein in the risks of what has been defined as humanitarian experimentation (Sandvik, Jacobsen, and McDonald, Int. Rev. Red Cross 99(904), 319–344, 2017). This article concludes that accountability mechanisms for AI-based systems and ADMs used to respond to the needs of populations in situation of vulnerability should be an essential feature by default, in order to preserve the respect of the do no harm principle even in the digital dimension of aid. In conclusion, while we confirm existing concerns related to the adoption of AI-based systems and ADMs in humanitarian action, we also advocate for a roadmap towards humanitarian AI for the sector and introduce a tentative ethics framework as basis for future research.",included,3536,0.839388609
10.1145/3657054.3657124,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2000 0:00,semantic_scholar,mitigating the risks of generative ai in government through algorithmic governance,https://www.semanticscholar.org/paper/c22e4a437e3d7659c8257a7f4babe63d6fca05ee,"The launch of the generative artificial intelligence (gen AI) application ChatGPT by OpenAI launched artificial intelligence into public discourse and led to a wave of mass uptake of this technology in organizations in the private sector. At the same time, AI is increasingly incorporated into government functions and the public sector. We propose that governments and the public sector can set an example for the responsible use of AI technologies by following the principles of algorithmic governance traditionally recommended to the private sector. Algorithmic governance has traditionally been defined in the literature as governance by algorithms, or how artificial intelligence is used to make governance decisions and affect social ordering. However, we take an alternative approach; instead, we conceptualize algorithmic governance as the governance of algorithms. We begin by summarizing the risks of generative AI use in government, then outline algorithmic governance principles, a step-by-step approach to implementing algorithmic governance into government or public sector projects, opportunities for inter-sector collaboration, and final conclusions.",included,101,0.839284122
10.1057/s42738-023-00101-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of Transatlantic Studies,Springer,12/1/2022 0:00,springer,"the eu’s potential to lead in “ethical and secure” artificial intelligence: last, best hope?",http://dx.doi.org/10.1057/s42738-023-00101-3,"This article explores the capacity of the European Union (EU) to achieve its ambition to “become the world-leading region on developing and deploying cutting-edge, ethical and secure AI (European Commission. “Coordinated Plan on Artificial Intelligence 2021 Review”, 56.)” and secondarily considers the implications of this quest within the context of transatlantic relations. Mapping the EU’s current technological and commercial competitiveness in the AI field vis-à-vis China and the USA, we contest the conventional depiction of the EU as a laggard offering a more nuanced view challenging this characterization on empirical and normative grounds. Analysing the extent to which the EU’s market and regulatory power—the so-called Brussels effect—sufficiently equips the EU to defend “ethical and secure” AI globally, we argue that regardless of US support or transatlantic convergence in the AI policy space, the EU’s efforts represent the last, best hope for a fairer, more secure and open world order in the data-driven, digital era.",not included,2552,0.83895874
10.26883/2010.241.5985,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Education and Technologies Journal,1/1/2000 0:00,semantic_scholar,"world’s first law for artificial intelligence. legal, ethical and economic aspects",https://www.semanticscholar.org/paper/34270a7b96d494461465e72c55c1cc84f6417e30,"The European Parliament has enacted the first comprehensive AI law, garnering widespread public interest and varied reactions. This regulation addresses the specific challenges posed by AI systems, aiming to ensure their safety, legal compliance, and alignment with EU fundamental rights and values. Key goals include fostering legal certainty to boost AI investments and innovations, enhancing governance, and preventing market fragmentation. The law employs a risk-based framework, categorizing AI systems into four risk levels: unacceptable, high, limited, and minimal. Unacceptable risk systems, like real-time biometric identification in public spaces, are banned. High-risk systems, such as those used in critical infrastructure or employment, require stringent oversight. Limited risk systems must maintain transparency, informing users when they are interacting with AI. Minimal risk systems, including AI spam filters, are allowed with minimal regulation but still require transparency. Significantly, the law emphasizes ethical AI development, particularly regarding copyright issues in generative AI. It mandates compliance with copyright laws, transparency about training data, and robust cybersecurity measures. Non-compliant companies face severe fines, up to 35 million euros or 7% of annual global revenue. The EU’s AI law sets a pioneering regulatory standard, potentially influencing global AI governance. It aims to balance protecting citizens’ rights with fostering a competitive and innovative AI market in Europe, potentially serving as a model for other democratic nations.",not included,126,0.838770509
10.1007/s43681-024-00547-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/19/2024 0:00,springer,artificial intelligence and its ‘slow violence’ to human rights,http://dx.doi.org/10.1007/s43681-024-00547-x,"Human rights concerns in relation to the impacts brought forth by artificial intelligence (‘AI’) have revolved around examining how it affects specific rights, such as the right to privacy, non-discrimination and freedom of expression. However, this article argues that the effects go deeper, potentially challenging the foundational assumptions of key concepts and normative justifications of the human rights framework. To unpack this, the article applies the lens of ‘slow violence’, a term borrowed from environmental justice literature, to frame the grinding, gradual, attritional harms of AI towards the human rights framework. The article examines the slow violence of AI towards human rights at three different levels. First, the individual as the subject of interest and protection within the human rights framework, is increasingly unable to understand nor seek accountability for harms arising from the deployment of AI systems. This undermines the key premise of the framework which was meant to empower the individual in addressing large power disparities and calling for accountability towards such abuse of power. Secondly, the ‘slow violence’ of AI is also seen through the unravelling of the normative justifications of discrete rights such as the right to privacy, freedom of expression and freedom of thought, upending the reasons and assumptions in which those rights were formulated and formalised in the first place. Finally, the article examines how even the wide interpretations towards the normative foundation of human rights, namely human dignity, is unable to address putative new challenges AI poses towards the concept. It then considers and offers the outline to critical perspectives that can inform a new model of human rights accountability in the age of AI.",included,427,0.838623405
10.1057/s41599-024-03560-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Humanities and Social Sciences Communications,Nature,9/1/2024 0:00,springer,ai governance in a complex and rapidly changing regulatory landscape: a global perspective,http://dx.doi.org/10.1057/s41599-024-03560-x,"The rapid advancement and deployment of Artificial Intelligence (AI) poses significant regulatory challenges for societies. While it has the potential to bring many benefits, the risks of commercial exploitation or unknown technological dangers have led many jurisdictions to seek a legal response before measurable harm occurs. However, the lack of technical capabilities to regulate this sector despite the urgency to do so resulted in regulatory inertia. Given the borderless nature of this issue, an internationally coordinated response is necessary. This article focuses on the theoretical framework being established in relation to the development of international law applicable to AI and the regulatory authority to create and monitor enforcement of said law. The authors argue that the road ahead remains full of obstacles that must be tackled before the above-mentioned elements see the light despite the attempts being made currently to that end.",included,330,0.838580012
10.1007/s00146-024-01940-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/23/2024 0:00,springer,imagining and governing artificial intelligence: the ordoliberal way—an analysis of the national strategy ‘ai made in germany’,http://dx.doi.org/10.1007/s00146-024-01940-0,"National Artificial Intelligence (AI) strategies articulate imaginaries of the integration of AI into society and envision the governing of AI research, development and applications accordingly. To integrate these central aspects of national AI strategies under one coherent perspective, this paper presented an analysis of Germany’s strategy ‘AI made in Germany’ through the conceptual lens of ordoliberal political rationality . The first part of the paper analyses how the guiding vision of a human-centric AI not only adheres to ethical and legal principles consistent with Germany’s liberal democratic constitutional system but also addresses the risks and promises inherent to the ordoliberal problematization of freedom. Second, it is scrutinized how the strategy cultivates the fear of not achieving technological sovereignty in the AI sector. Thereby, it frames the global AI race as a race of competing (national) approaches to governing AI and articulates an ordoliberal approach to governing AI (the ‘third way’), according to which government has to operate between the twin dangers of governing too much and not governing enough. Third, the paper analyses how this ordoliberal proportionality of governing structures Germany’s Science Technology & Innovation Policy. It is shown that the corresponding risk-based approach of regulating AI constitutes a security apparatus as it produces an assessment of fears: weighting the fear of the failure to innovate with the fear of the ramifications of innovation. Finally, two lines of critical engagement based on this analysis are conducted.",not included,975,0.838562906
10.1007/s43681-022-00150-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,2/1/2023 0:00,springer,towards ai ethics’ institutionalization: knowledge bridges from business ethics to advance organizational ai ethics,http://dx.doi.org/10.1007/s43681-022-00150-y,"This paper proposes to generate awareness for developing Artificial intelligence (AI) ethics by transferring knowledge from other fields of applied ethics, particularly from business ethics, stressing the role of organizations and processes of institutionalization. With the rapid development of AI systems in recent years, a new and thriving discourse on AI ethics has (re-)emerged, dealing primarily with ethical concepts, theories, and application contexts. We argue that business ethics insights may generate positive knowledge spillovers for AI ethics, given that debates on ethical and social responsibilities have been adopted as voluntary or mandatory regulations for organizations in both national and transnational contexts. Thus, business ethics may transfer knowledge from five core topics and concepts researched and institutionalized to AI ethics: (1) stakeholder management, (2) standardized reporting, (3) corporate governance and regulation, (4) curriculum accreditation, and as a unified topic (5) AI ethics washing derived from greenwashing. In outlining each of these five knowledge bridges, we illustrate current challenges in AI ethics and potential insights from business ethics that may advance the current debate. At the same time, we hold that business ethics can learn from AI ethics in catching up with the digital transformation, allowing for cross-fertilization between the two fields. Future debates in both disciplines of applied ethics may benefit from dialog and cross-fertilization, meant to strengthen the ethical depth and prevent ethics washing or, even worse, ethics bashing.",not included,2427,0.838521421
10.1145/3322640.3326722,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Conference on Artificial Intelligence and Law,1/1/2019 0:00,semantic_scholar,artificial intelligence and law: what do people really want?: example of a french multidisciplinary working group,https://www.semanticscholar.org/paper/b4fcc459433d2fc35b0214f81a2145bcbc74fe5f,"This paper addresses issues related to the ethical consequences of using AI technologies in court decisions. With the prodigious technological leap made in the field of artificial intelligence in recent years, disruptive innovations have affected many business sectors, with economic, social and ethical consequences. But what do people really want about the application of artificial intelligence technologies in the law system? This article presents a general methodological approach to take into account the ethical aspect of the introduction of a new technology in a given domain. We apply this methodology in the specific case of the introduction of AI technologies in the law system. As a multidisciplinary working group interested in this application in the case of France, we have organized a series of workshops to discuss this topic and highlight the respective values and interests of each stakeholder. The result of this work in presented in the form of an ethical matrix that can be used as a tool by the public authorities to help decision-making on the subject with a prioritization of certain values in order to reflect the respect for fundamental rights.",included,10,0.83842057
10.1007/s43681-022-00137-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,2/1/2022 0:00,springer,criminal courts’ artificial intelligence: the way it reinforces bias and discrimination,http://dx.doi.org/10.1007/s43681-022-00137-9,"Embracive, pervasive, and unstoppable global algorithmization greatly influences the deployment of artificial intelligence systems in criminal courts to replace obsolete bail and sentencing practices, reduce recidivism risk, and modernize judicial practices. Since artificial intelligence systems have provably appeared to have the duality of golden promises and potential perils, applying such a system in the justice system also entails some associated risks. Hence, allocating this unchecked-novel resource in judicial domains sparks vigorous debate over their legal and ethical implications. With such backgrounds, this paper examines how and why artificial intelligence systems reinforce bias and discrimination in society and suggest what approach could be an alternative to the current predictive justice mechanisms in use.",not included,3277,0.838354528
10.1007/s11023-024-09696-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Minds and Machines,Springer,9/28/2024 0:00,springer,"beneficent intelligence: a capability approach to modeling benefit, assistance, and associated moral failures through ai systems",http://dx.doi.org/10.1007/s11023-024-09696-8,"The prevailing discourse around AI ethics lacks the language and formalism necessary to capture the diverse ethical concerns that emerge when AI systems interact with individuals. Drawing on Sen and Nussbaum’s capability approach, we present a framework formalizing a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders. Such systems enhance stakeholders’ ability to advance their life plans and well-being while upholding their fundamental rights. We characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit. We then contrast this ideal with several salient failure modes, namely, forms of social interactions that constitute unjustified paternalism, coercion, deception, exploitation and domination. The proliferation of incidents involving AI in high-stakes domains underscores the gravity of these issues and the imperative to take an ethics-led approach to AI systems from their inception.",included,241,0.838210881
10.1007/s00146-023-01685-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,10/1/2024 0:00,springer,"the indian approach to artificial intelligence: an analysis of policy discussions, constitutional values, and regulation",http://dx.doi.org/10.1007/s00146-023-01685-2,"India has produced several drafts of data policies. In this work, they are referred to [1] JBNSCR 2018, [2] DPDPR 2018, [3] NSAI 2018, [4] RAITF 2018, [5] PDPB 2019, [6] PRAI 2021, [7] JPCR 2021, [8] IDAUP 2022, [9] IDABNUP 2022. All of them consider Artificial Intelligence (AI) a social problem solver at the societal level, let alone an incentive for economic growth. However, these policy drafts warn of the social disruptions caused by algorithms and encourage the careful use of computational technologies in various social contexts. Hence, the emerging data society and its implications in India's social contexts demand immense social science attention, which needs to be improved in the policy drafts, primarily because they are creations of industry stakeholders, technocrats, bureaucrats, and experts from tech schools. In the larger social milieu of digital infrastructure emerging, the fundamental question is whether India's national philosophy envisioned in the Indian constitution is reflected in the policy papers. The paper enquires whether the national data policy upholds the core values dispersed through the philosophy of the Indian constitution, which, among other things, is not confined only to inclusion, diversity, rights, liberty, justice and equality. By focusing on constitutional values, the paper seeks to offer a broader and more critical understanding of India's approach to AI policy by bringing together analyses of a wide array of policy documents available in the public realm.",included,216,0.838020384
10.52458/23492589.2023.v10.iss1.kp.a1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Kaav International Journal of Law, Finance &amp; Industrial Relations",1/1/2000 0:00,semantic_scholar,changing landscape of artificial intelligence on indian corporate sectors and governance: special reference to smes,https://www.semanticscholar.org/paper/6d0644272448fde31f868f87d25110a74fb48ff7,"Artificial intelligence (AI) has the likely to start a new industrial upheaval that will primarily alter market forces at work and working circumstances. This study tries to clarify what artificial intelligence (AI) is, how it could affect corporate sectors and SME operations, and India's adoption challenges. Governments can help SMEs develop their risk supervision procedures. Most industries can benefit from using AI, although some are more likely to do so than others. AI may be used in several business areas and can alter the internal value chain of the company. The areas of business where artificial intelligence (AI) are expected to have the most effects. Objective: It is necessary to create the circumstances for a reliable transition and increase knowledge of the benefits of AI among SME managers and employees. A participative approach should be taken when revamping work processes and training AI models, and national and local governments should coordinate efforts to reskill SME managers and employees. Then, until AI can fulfil its full potential, mechanisms for bridging the financing gap should be identified. Research Methodology: The study's foundations include both qualitative and quantitative research. Regulators and policymakers should make sure that knowledge markets that offer cloud solutions with embedded AI technologies are operating smoothly. Findings: The findings of the research are based on the role and impact of AI on different aspects of governance like public administration, tax compliances, market competition, infrastructure, finances, labor market etc. Conclusion: AI lowers prediction costs significantly and makes decision-making easier. To map uncertainties and reduce risk exposure, SMEs may use predictive analytics. They can also automate business estimates, including sales and budget forecasts, or improve the effectiveness of asset maintenance and management. Greater market segmentation and price differentiation are made possible by improved prediction capabilities, which also provide SMEs the chance to innovate since they are better able to foresee customer behavior and price sensitivity as well as demand changes.",not included,65,0.838018537
10.1057/s41599-021-00750-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Humanities and Social Sciences Communications,Nature,3/15/2021 0:00,springer,mind the gap! on the future of ai research,http://dx.doi.org/10.1057/s41599-021-00750-9,"Research on AI tends to analytically separate technical and social issues, viewing AI first as a technical object that only later, after it has been implemented, may have social consequences. This commentary paper discusses how some of the challenges of AI research relate to the gap between technological and social analyses, and it proposes steps ahead for how to practically achieve prosperous collaborations for future AI research. The discussion draws upon three examples to illustrate the analytical gap in different phases of the development of AI systems. Attending to the planning phase, the first example highlights the risk of oversimplifying the task for an AI system by not incorporating a social analysis at the outset of the development. The second example illuminates the issue of system acceptance, where the paper elaborates on why acceptance is multifaceted and need not be approached as merely a technical problem. With the third example, the paper notes that AI systems may change a practice, suggesting that a continuous analysis of such changes is necessary for projects to maintain relevance as well as to consider the broader impact of the developed technology. The paper argues that systematic and substantial social analyses should be integral to AI development. Exploring the connections between an AI’s technical design and its social implications is key to ensuring feasible and sustainable AI systems that benefit society. The paper calls for further multi-disciplinary research initiatives that explore new ways to close the analytical gap between technical and social approaches to AI.",not included,3921,0.837622046
10.1007/s44163-024-00109-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Discover Artificial Intelligence,Springer,2/26/2024 0:00,springer,managing the race to the moon: global policy and governance in artificial intelligence regulation—a contemporary overview and an analysis of socioeconomic consequences,http://dx.doi.org/10.1007/s44163-024-00109-4,"This paper delves into the complexities of global AI regulation and governance, emphasizing the socio-economic repercussions of rapid AI development. It scrutinizes the challenges in creating effective governance structures amidst the AI race, considering diverse global perspectives and policies. The discourse moves beyond specific corporate examples, addressing broader implications and sector-wide impacts of AI on employment, truth discernment, and democratic stability. The analysis focuses on contrasting regulatory approaches across key regions—the United States, European Union, Asia, Africa, and the Americas and thus highlighting the variations and commonalities in strategies and implementations. This comparative study reveals the intricacies and hurdles in formulating a cohesive global policy for AI regulation. Central to the paper is the examination of the dynamic between rapid AI innovation and the slower pace of regulatory and ethical standard-setting. It critically evaluates the advantages and drawbacks of shifting regulatory responsibilities between government bodies and the private sector. In response to these challenges, the discussion proposes an innovative and integrated regulatory model. The model advocates for a collaborative network that blends governmental authority with industry expertise, aiming to establish adaptive, responsive regulations (called “dynamic laws”) that can evolve with technological advancements. The novel approach aims to bridge the gap between rapid AI advancements in the industry and the essential democratic processes of law-making.",not included,1222,0.83753258
10.1007/s43681-024-00493-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/27/2024 0:00,springer,the ethics of using artificial intelligence in scientific research: new guidance needed for a new tool,http://dx.doi.org/10.1007/s43681-024-00493-8,"Using artificial intelligence (AI) in research offers many important benefits for science and society but also creates novel and complex ethical issues. While these ethical issues do not necessitate changing established ethical norms of science, they require the scientific community to develop new guidance for the appropriate use of AI. In this article, we briefly introduce AI and explain how it can be used in research, examine some of the ethical issues raised when using it, and offer nine recommendations for responsible use, including: (1) Researchers are responsible for identifying, describing, reducing, and controlling AI-related biases and random errors; (2) Researchers should disclose, describe, and explain their use of AI in research, including its limitations, in language that can be understood by non-experts; (3) Researchers should engage with impacted communities, populations, and other stakeholders concerning the use of AI in research to obtain their advice and assistance and address their interests and concerns, such as issues related to bias; (4) Researchers who use synthetic data should (a) indicate which parts of the data are synthetic; (b) clearly label the synthetic data; (c) describe how the data were generated; and (d) explain how and why the data were used; (5) AI systems should not be named as authors, inventors, or copyright holders but their contributions to research should be disclosed and described; (6) Education and mentoring in responsible conduct of research should include discussion of ethical use of AI.",not included,835,0.837295115
10.1145/3657054.3657086,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2000 0:00,semantic_scholar,public value principles for secure and trusted ai,https://www.semanticscholar.org/paper/d6133f0fb81ce4779a78835b4af01ef3b55bbeeb,"The objective of this paper is to establish the fundamental public value principles that should govern safe and trusted artificial intelligence (AI). Public value is a dynamic concept that encompasses several dimensions. AI itself has evolved quite rapidly in the last few years, especially with the swift escalation of Generative AI. Governments around the world are grappling with how to govern AI, just as technologists ring alarm bells about the future consequences of AI. Our paper extends the debate on AI governance that is focused on ethical values of beneficence to that of economic values of public good. Viewed as a public good, AI use is beyond the control of the creators. Towards this end, the paper examined AI policies in the United States and Europe. We postulate three principles from a public values perspective: (i) ensuring security and privacy of each individual (or entity); (ii) ensuring trust in AI systems is verifiable; and (iii) ensuring fair and balanced AI protocols, wherein the underlying components of data and algorithms are contestable and open to public debate.",included,97,0.837046385
10.1145/3657054.3657129,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2000 0:00,semantic_scholar,tribal knowledge cocreation in generative artificial intelligence systems,https://www.semanticscholar.org/paper/3fbf70a03073fd04f2293044076b5e84afef66f7,"Generative Artificial Intelligence (AI) systems bring innovative ways of information provision and knowledge delivery. In the public sector, generative AI has the potential to decrease bureaucratic discretion in the decision-making process. Increasing reliance on this technology brings challenges of unfair treatment, colonized responses from the system, and data governance. Because of historical interaction, tribal communities are the most underrepresented in policy planning and implementation. Indigenous communities suffer from the neglect of tribal sovereignty by the U.S. federal government and limited accessibility and literacy in the digital world. Generative AI systems exacerbate these challenges with insufficient tribal input. However, the negative impact can be alleviated with digital equity and knowledge cocreation. Digital equity emphasizes the importance of tribal knowledge representation, and knowledge cocreation focuses on the collaboration between Indigenous communities and relevant actors in data governance for generative AI systems. This study proposes two research questions to discuss tribal knowledge cocreation in generative AI systems: (1) what are the biases in the system responses from the tribal perspective? (2) what are the potential resolutions for these problems? The findings from in-depth interviews with tribal members in the U.S. indicate that the insufficient articulation of tribal culture, the lack of crucial tribal historical events, and the inappropriate appellation of tribal nations are the primary drawbacks in the system responses. From the Indigenous perspective, tribal oral traditions, native publications and documents, and collaboration with tribal governments can address the problems of generative AI responses. This study contributes to the theory development of digital equity and knowledge cocreation in tribal generative AI system responses. Policy recommendations and future research agendas are included in this research.",not included,95,0.836939931
10.1007/s12525-021-00480-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Electronic Markets,Springer,3/1/2022 0:00,springer,categorization and eccentricity of ai risks: a comparative study of the global ai guidelines,http://dx.doi.org/10.1007/s12525-021-00480-5,"Background Governments, enterprises, civil organizations, and academics are engaged to promote normative guidelines aimed at regulating the development and application of Artificial Intelligence (AI) in different fields such as judicial assistance, social governance, and business services. Aim Although more than 160 guidelines have been proposed globally, it remains uncertain whether they are sufficient to meet the governance challenges of AI. Given the absence of a holistic theoretical framework to analyze the potential risk of AI, it is difficult to determine what is overestimated and what is missing in the extant guidelines. Based on the classic theoretical model in the field of risk management, we developed a four-dimensional structure as a benchmark to analyze the risk of AI and its corresponding governance measures. The structure consists of four pairs of risks: specific-general, legal-ethical, individual-collective and generational-transgenerational. Method Using the framework, a comparative study of the extant guidelines is conducted by coding the 123 guidelines with 1023 articles. Result We find that the extant guidelines are eccentric, while collective risk and generational risk are largely underestimated by stakeholders. Based on this analysis, three gaps and conflicts are outlined for future improvements.",included,3205,0.836506367
10.1007/s13347-024-00761-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,7/1/2024 0:00,springer,philosophical investigations into ai alignment: a wittgensteinian framework,http://dx.doi.org/10.1007/s13347-024-00761-9,"We argue that the later Wittgenstein’s philosophy of language and mathematics, substantially focused on rule-following, is relevant to understand and improve on the Artificial Intelligence (AI) alignment problem: his discussions on the categories that influence alignment between humans can inform about the categories that should be controlled to improve on the alignment problem when creating large data sets to be used by supervised and unsupervised learning algorithms, as well as when introducing hard coded guardrails for AI models. We cast these considerations in a model of human–human and human–machine alignment and sketch basic alignment strategies based on these categories and further reflections on rule-following like the notion of meaning as use. To sustain the validity of these considerations, we also show that successful techniques employed by AI safety researchers to better align new AI systems with our human goals are congruent with the stipulations that we derive from the later Wittgenstein’s philosophy. However, their application may benefit from the added specificities and stipulations of our framework: it extends on the current efforts and provides further, specific AI alignment techniques. Thus, we argue that the categories of the model and the core alignment strategies presented in this work can inform further AI alignment techniques.",included,625,0.836233139
10.60087/jaigs.v3i1.119,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023,1/1/2000 0:00,semantic_scholar,examining ethical aspects of ai: addressing bias and equity in the discipline,https://www.semanticscholar.org/paper/9b688157f467a83b7f4f6ac4eae7754241018aef,"he rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",included,141,0.83621341
10.1007/s11023-022-09611-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Minds and Machines,Springer,12/1/2023 0:00,springer,contestable ai by design: towards a framework,http://dx.doi.org/10.1007/s11023-022-09611-z,"As the use of AI systems continues to increase, so do concerns over their lack of fairness, legitimacy and accountability. Such harmful automated decision-making can be guarded against by ensuring AI systems are contestable by design: responsive to human intervention throughout the system lifecycle. Contestable AI by design is a small but growing field of research. However, most available knowledge requires a significant amount of translation to be applicable in practice. A proven way of conveying intermediate-level, generative design knowledge is in the form of frameworks. In this article we use qualitative-interpretative methods and visual mapping techniques to extract from the literature sociotechnical features and practices that contribute to contestable AI, and synthesize these into a design framework.",included,1442,0.836030126
10.60087/jaigs.vol03.issue01.p124,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023,1/1/2000 0:00,semantic_scholar,exploring ethical dimensions in ai: navigating bias and fairness in the field,https://www.semanticscholar.org/paper/ffa5a275be9ea886dff66494c821f2b2db2f091d,"The rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",not included,142,0.835920215
10.1007/s11948-021-00293-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Science and Engineering Ethics,Springer,3/8/2021 0:00,springer,research and practice of ai ethics: a case study approach juxtaposing academic discourse with organisational reality,http://dx.doi.org/10.1007/s11948-021-00293-x,"This study investigates the ethical use of Big Data and Artificial Intelligence (AI) technologies (BD + AI)—using an empirical approach. The paper categorises the current literature and presents a multi-case study of 'on-the-ground' ethical issues that uses qualitative tools to analyse findings from ten targeted case-studies from a range of domains. The analysis coalesces identified singular ethical issues, (from the literature), into clusters to offer a comparison with the proposed classification in the literature. The results show that despite the variety of different social domains, fields, and applications of AI, there is overlap and correlation between the organisations’ ethical concerns. This more detailed understanding of ethics in AI + BD is required to ensure that the multitude of suggested ways of addressing them can be targeted and succeed in mitigating the pertinent ethical issues that are often discussed in the literature.",not included,3922,0.835794032
10.1215/2834703x-11205231,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Critical AI,1/1/2000 0:00,semantic_scholar,the fumes of ai,https://www.semanticscholar.org/paper/041b29a4f27cbbff34140e58f2f0f32a61d9207b,"
 With the emergence of generative artificial intelligence (GenAI), it is increasingly clear that the environmental impacts of these technologies are significant, and worth exposing to the public. This article discusses the environmental impacts of generative artificial intelligence and the political underpinnings of extractivist technologies such as cloud companies. It highlights the centralized system of power that demands subservience to its foundational values despite being touted as the most environmentally friendly cloud infrastructure globally.",not included,136,0.835203648
10.1007/s43681-022-00167-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,2/1/2023 0:00,springer,meaningful human control: actionable properties for ai system development,http://dx.doi.org/10.1007/s43681-022-00167-3,"How can humans remain in control of artificial intelligence (AI)-based systems designed to perform tasks autonomously? Such systems are increasingly ubiquitous, creating benefits - but also undesirable situations where moral responsibility for their actions cannot be properly attributed to any particular person or group. The concept of meaningful human control has been proposed to address responsibility gaps and mitigate them by establishing conditions that enable a proper attribution of responsibility for humans; however, clear requirements for researchers, designers, and engineers are yet inexistent, making the development of AI-based systems that remain under meaningful human control challenging. In this paper, we address the gap between philosophical theory and engineering practice by identifying, through an iterative process of abductive thinking, four actionable properties for AI-based systems under meaningful human control, which we discuss making use of two applications scenarios: automated vehicles and AI-based hiring. First, a system in which humans and AI algorithms interact should have an explicitly defined domain of morally loaded situations within which the system ought to operate. Second, humans and AI agents within the system should have appropriate and mutually compatible representations. Third, responsibility attributed to a human should be commensurate with that human’s ability and authority to control the system. Fourth, there should be explicit links between the actions of the AI agents and actions of humans who are aware of their moral responsibility. We argue that these four properties will support practically minded professionals to take concrete steps toward designing and engineering for AI systems that facilitate meaningful human control.",included,2429,0.834971905
10.1007/s43681-023-00323-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,7/31/2023 0:00,springer,challenging ai for sustainability: what ought it mean?,http://dx.doi.org/10.1007/s43681-023-00323-3,"This paper argues that the terms ‘Sustainable artificial intelligence (AI)’ in general and ‘Sustainability of AI’ in particular are overused to the extent that they have lost their meaning. The AI for (social) good movement is a manifestation of this trend in which almost any application used in the context of healthcare or agriculture can be classified as AI for good regardless of whether such applications have been evaluated from a broader perspective. In this paper, we aim to create a common understanding of what the ‘AI for Sustainability’ movement ought to mean. We distinguish between two possible AI for Sustainability applications, namely those that fulfill the necessary conditions and those that fulfill the sufficient conditions. The former are purely predictive systems that serve as information providers. The latter are directly involved in an activity that contributes to a sustainability goal. We argue that taking action is a key element in distinguishing between these two application groups, as inaction is the key bottleneck in effectively tackling climate change. Furthermore, we question how effective the use of AI applications can be for sustainability when the systems themselves are inherently unsustainable. Hence, AI for Sustainability should include both an action that contributes to a sustainable end goal as well as an investigation of the sustainability issues of the AI system itself. Following that, Sustainable AI research can be on a gradient: AI in an application domain, AI towards sustainability, and AI for Sustainability.",not included,1946,0.834889531
10.1108/tg-02-2024-0038,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Transforming Government: People, Process and Policy",1/1/2000 0:00,semantic_scholar,the use of ai in government and its risks: lessons from the private sector,https://www.semanticscholar.org/paper/2ef758da3f0043f05fb4e89a6c65c610cbd1d43c,"
Purpose
This study aims to understand the perceived emotions of human–artificial intelligence (AI) interactions in the private sector. Moreover, this research discusses the transferability of these lessons to the public sector.


Design/methodology/approach
This research analysed the comments posted between June 2022 and June 2023 in the global open Reddit online community. A data mining approach was conducted, including a sentiment analysis technique and a qualitative approach.


Findings
The results show a prevalence of positive emotions. In addition, a pertinent percentage of negative emotions were found, such as hate, anger and frustration, due to human–AI interactions.


Practical implications
The insights from human–AI interactions in the private sector can be transferred to the governmental sector to leverage organisational performance, governmental decision-making, public service delivery and the creation of economic and social value.


Originality/value
Beyond the positive impacts of AI in government strategies, implementing AI can elicit negative emotions in users and potentially negatively impact the brand of private and government organisations. To the best of the authors’ knowledge, this is the first research bridging the gap by identifying the predominant negative emotions after a human–AI interaction.
",not included,117,0.834787667
10.1007/s43681-022-00202-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/1/2023 0:00,springer,“intelligent justice”: human-centered considerations in china’s legal ai transformation,http://dx.doi.org/10.1007/s43681-022-00202-3,"In recent years, the Chinese government and its judiciary have made a policy decision to leverage artificial intelligence in broader judicial reform efforts. The push to use AI to such a large extent in the judiciary is unique to China, influenced by chronic challenges facing the courts, including an exponential increase in casework and a shortage of qualified professionals in the judiciary. This has resulted in a number of pilot programs across the country that have produced various AI systems embedded in different areas of the judicial system. Some of these systems aim to make rote processes, such as transcription and document review, more efficient, while other more ambitious projects attempt to directly assist in the decision-making process. This piece briefly summarizes the current landscape of China’s technology-driven judicial reform and highlights a number of key considerations that we believe are pivotal to whether China’s investment in AI will succeed in improving the efficiency and legitimacy of the courts.",not included,2200,0.834477067
10.1007/s44163-022-00028-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Discover Artificial Intelligence,Springer,6/20/2022 0:00,springer,islamic virtue-based ethics for artificial intelligence,http://dx.doi.org/10.1007/s44163-022-00028-2,"The twenty-first century technological advances driven by exponential rise of artificial intelligence (AI) technology have ushered in a new era that offers many of us hitherto unimagined luxuries and facilities. However, under the guise of this progressive discourse, particularly in the backdrop of current neo-liberal late-capitalist postmodern world, AI development also has prompted an increasingly uncertain ethical tomorrow. This paper aims to probe the question of ethics by exploring the true ramifications of AI and interrogating its various ethical dimensions. It questions the essential goodness that is attributed to unstinted AI development before elucidating the ethical repercussions of AI advancements and the aptness of the current market logics and business models that govern the tech-industry. The paper next positions a holistic Islamic virtue-based AI ethics framework grounded in the context of Islamic objectives ( maqāṣid ) as an alternative ethical system for AI governance. We argue that this distinctive Islamic virtue-based ethical approach, which can be used to explore AI-related ethical problems more holistically due to its ontological base and rich tradition while keeping in check undue influence from the current socio-politico-economic climate, can be a valuable addition to the global discourse on AI ethics.",included,2970,0.833853364
10.1007/s00146-022-01501-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2023 0:00,springer,the polyopticon: a diagram for urban artificial intelligences,http://dx.doi.org/10.1007/s00146-022-01501-3,"Smart city discourses often invoke the Panopticon, a disciplinary architecture designed by Jeremy Bentham and popularly theorized by Michel Foucault, as a model for understanding the social impact of AI technologies. This framing focuses attention almost exclusively on the negative ramifications of Urban AI, correlating ubiquitous surveillance, centralization, and data consolidation with AI development, and positioning technologies themselves as the driving factor shaping privacy, sociality, equity, access, and autonomy in the city. This paper describes an alternative diagram for Urban AI—the Polyopticon: a distributed, polyvalent, multi-modal network of synthetic intelligences. It posits that fourth industrial revolution technologies change the political, social, and psychodynamic relationships of sentience and witness in the city, shifting the effects of watching and watched beyond the exclusive domain of top-down surveillance and discipline. The Polyopticon poses a more expansive and ambivalent spectrum of possibilities for Urban AI scenarios, one that undermines the totalizing, singular, and cerebral notion of intelligence that so often characterizes Urban AI and smart city critiques.",included,2056,0.833732009
10.1007/s43681-022-00220-1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/1/2023 0:00,springer,proportionality principle for the ethics of artificial intelligence,http://dx.doi.org/10.1007/s43681-022-00220-1,"This commentary explores the principle of proportionality as a possible solution to unresolved problems pertaining to the tensions among principles in various ethical frameworks for artificial intelligence (AI). Conceptual and procedural divergences in the sets of principles reveal uncertainty as to which ethical principles should be prioritized and how conflicts between them should be resolved. Moreover, there are externalities of employing the currently dominant AI methods, in particular for the environment. The principle of proportionality and a framework of tests of necessity, desirability, and suitability can address some of the underlying issues and to ensure that other societal priorities are well taken into account. It is argued that at least in certain scenarios the perceived tensions can be false dichotomies. Proportionality presents a set of conditions to satisfy to justify the usage of certain AI methods, which can be further expanded to justifying using AI systems as such for a particular purpose.",not included,1903,0.833436251
10.1007/s13347-020-00414-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,9/1/2021 0:00,springer,there is no techno-responsibility gap,http://dx.doi.org/10.1007/s13347-020-00414-7,"In a landmark essay, Andreas Matthias claimed that current developments in autonomous, artificially intelligent (AI) systems are creating a so-called responsibility gap, which is allegedly ever-widening and stands to undermine both the moral and legal frameworks of our society. But how severe is the threat posed by emerging technologies? In fact, a great number of authors have indicated that the fear is thoroughly instilled. The most pessimistic are calling for a drastic scaling-back or complete moratorium on AI systems, while the optimists aim to show that the gap can be bridged nonetheless. Contrary to both camps, I argue against the prevailing assumption that there is a technology-based responsibility gap. I show how moral responsibility is a dynamic and flexible process, one that can effectively encompass emerging technological entities.",not included,3605,0.833417535
10.1007/s43681-021-00039-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/1/2021 0:00,springer,ai auditing and impact assessment: according to the uk information commissioner’s office,http://dx.doi.org/10.1007/s43681-021-00039-2,"As the use of data and artificial intelligence systems becomes crucial to core services and business, it increasingly demands a multi-stakeholder and complex governance approach. The Information Commissioner's Office’s ‘Guidance on the AI auditing framework: Draft guidance for consultation’ is a move forward in AI governance. The aim of this initiative is toward producing guidance that encompasses both technical (e.g. system impact assessments) and non-engineering (e.g. human oversight) components to governance and represents a significant milestone in the movement towards standardising AI governance. This paper will summarise and critically evaluate the ICO effort and try to anticipate future debates and present some general recommendations.",included,3657,0.833364248
10.1007/s43681-023-00370-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,12/4/2023 0:00,springer,ensuring a ‘responsible’ ai future in india: rri as an approach for identifying the ethical challenges from an indian perspective,http://dx.doi.org/10.1007/s43681-023-00370-w,"Artificial intelligence (AI) can be seen to be at an inflexion point in India, a country which is keen to adopt and exploit new technologies, but needs to carefully consider how they do this. AI is usually deployed with good intentions, to unlock value and create opportunities for the people; however it does not come without its challenges. There are a set of ethical–social issues associated with AI, which include concerns around privacy, data protection, job displacement, historical bias and discrimination. Through a series of focus groups with knowledgeable people embedded in India and its culture, this research explores the ethical–societal changes and challenges that India now faces. Further, it investigates whether the principles and practices of responsible research and innovation (RRI) might provide a framework to help identify and deal with these issues. The results show that the areas in which RRI could offer scope to improve this outlook include education, policy and governance, legislation and regulation, and innovation and industry practices. Some significant challenges described by participants included: the lack of awareness of AI by the public as well as policy makers; India’s access and implementation of Western datasets, resulting in a lack of diversity, exacerbation of existing power asymmetries, increase in social inequality and the creation of bias; the potential replacement of jobs by AI. One option was to look at a hybrid approach, a mix of AI and humans, with expansion and upskilling of the current workforce. In terms of strategy, there seems to be a gap between the rhetoric of the government and what is seen on the ground, and therefore going forward there needs to be a much greater engagement with a wider audience of stakeholders.",not included,1429,0.83334446
10.1108/tg-01-2024-0006,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Transforming Government: People, Process and Policy",1/1/2000 0:00,semantic_scholar,unlocking the power and future potential of generative ai in government transformation,https://www.semanticscholar.org/paper/efca4ec65048fae6d934f3c17dc70aa6803555a8,"
Purpose
This paper aims to investigate whether the implementation of generative artificial intelligence (GAI) impacts government functionality. The study will analyse GAI’s positive attributes across different dimensions to comprehensively understand its value proposition for public organisations. Furthermore, the paper will outline the strategic interventions required to integrate GAI effectively within the organisational context of government transformation.


Design/methodology/approach
This study measures “government functionality” and “GAI implementation” using abstract macro variables as a second-order formative model. It also includes first-order measurable micro-variables to better understand the concept. In addition, the study introduces “organisational context” as a moderating factor to explain the complex dynamics of integrating GAI to improve government functionality. The study proposes a conceptual framework, which was analysed using exploratory data analysis, with primary data collected through questionnaires.


Findings
The study finds a positive correlation between the implementation of GAI and improved government functionality. Furthermore, it found that organisational contextualisation significantly moderates this relationship. All the empirical outcomes align with the prescribed statistical thresholds, concluding that the articulated conceptual framework holds significance.


Research limitations/implications
The study has significant implications for managers, researchers and anyone involved in making, implementing or evaluating decisions related to digital government through GAI. However, the study has limitations, including a limited sample size and contextualisation of the Indian public sector.


Originality/value
The study contributes to existing knowledge by showing that implementing GAI positively correlates with improving government functionality. It further highlights the significance of GAI implementation according to the specific organisational context.
",included,103,0.833154917
10.1007/s43681-023-00289-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/30/2023 0:00,springer,auditing large language models: a three-layered approach,http://dx.doi.org/10.1007/s43681-023-00289-2,"Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",included,2159,0.831905723
10.1109/icccis60361.2023.10425428,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',"2023 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)",IEEE,11/4/2023 0:00,ieeexplore,modelling the domains of artificial intelligence on social good: a study on analytic-based hierarchy,https://ieeexplore.ieee.org/document/10425428/,"AI is the technology that has transformed many industries and various sectors which include healthcare, finance education, agriculture etc. The purpose of this study is to explore the impact of AI on social good. More specifically, this research prioritizes the domains and subdomains of AI. Initially, the literature has been extensively reviewed to identify the uncharted implications of AI. To conduct the study authors have adopted the secondary research and a theoretical model has been developed to prioritize the domains at the time of contingency; for that purpose, an Analytical Hierarchical Process, a tool of MCDM, is used. The findings of the study concluded with a theoretical model presenting the rankings and maximum global weights. The current study has been conducted in the Indian context. Therefore, this can be considered as a limitation of research. Current study significantly contributes to the body of literature in this field and presents a hierarchical model of artificial intelligence domains and sub domains impacting social good.",included,8466,0.831526637
10.1007/s00146-024-01987-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/8/2024 0:00,springer,attitudes toward artificial intelligence: combining three theoretical perspectives on technology acceptance,http://dx.doi.org/10.1007/s00146-024-01987-z,"Evidence on AI acceptance comes from a diverse field comprising public opinion research and largely experimental studies from various disciplines. Differing theoretical approaches in this research, however, imply heterogeneous ways of studying AI acceptance. The present paper provides a framework for systematizing different uses. It identifies three families of theoretical perspectives informing research on AI acceptance—user acceptance, delegation acceptance, and societal adoption acceptance. These models differ in scope, each has elements specific to them, and the connotation of technology acceptance thus changes when shifting perspective. The discussion points to a need for combining the three perspectives as they have all become relevant for AI. A combined approach serves to systematically relate findings from different studies. And as AI systems affect people in different constellations and no single perspective can accommodate them all, building blocks from several perspectives are needed to comprehensively study how AI is perceived in society.",included,701,0.831388593
10.1177/09520767231188229,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Policy and Administration,1/1/2000 0:00,semantic_scholar,making governance agile: exploring the role of artificial intelligence in china’s local governance,https://www.semanticscholar.org/paper/3cc1411a425b6a61bdd8a6bdd8f76ddcff4f869b,"As the key to digital transformation, artificial intelligence is believed to help achieve the goal of government as a platform and the agile development of digital services. Yet we know little about its potential role in local governance, especially the advances that AI-supported services for the public sector in local governance have ventured and the public value they have created. Combining the digital transformation concepts and public value theory, we fill the gap by examining artificial intelligence (AI) deployment in the public sector of a pilot city of digital transformation in China. Using a mixed-method approach, we show how AI configurations facilitate public value creation in the digital era and identify four dimensions of AI deployment in the public sector: data integration, policy innovation, smart application, and collaboration. Our case analysis on these four dimensions demonstrates two roles that AI technology plays in local governance—“AI cage” and “AI colleague.” The former builds the technology infrastructure and platform in each stage of service delivery, regulating the behaviors of frontline workers, while the latter helps frontline workers make decisions, thus improving the agility of public service provision.",included,47,0.831282258
10.1007/s11920-022-01378-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Current Psychiatry Reports,Springer,11/1/2022 0:00,springer,expectations for artificial intelligence (ai) in psychiatry,http://dx.doi.org/10.1007/s11920-022-01378-5,"Purpose of Review Artificial intelligence (AI) is often presented as a transformative technology for clinical medicine even though the current technology maturity of AI is low. The purpose of this narrative review is to describe the complex reasons for the low technology maturity and set realistic expectations for the safe, routine use of AI in clinical medicine. Recent Findings For AI to be productive in clinical medicine, many diverse factors that contribute to the low maturity level need to be addressed. These include technical problems such as data quality, dataset shift, black-box opacity, validation and regulatory challenges, and human factors such as a lack of education in AI, workflow changes, automation bias, and deskilling. There will also be new and unanticipated safety risks with the introduction of AI. Summary The solutions to these issues are complex and will take time to discover, develop, validate, and implement. However, addressing the many problems in a methodical manner will expedite the safe and beneficial use of AI to augment medical decision making in psychiatry.",not included,2660,0.831128478
10.1145/3657054.3657063,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2000 0:00,semantic_scholar,beyond principles: embedding ethical ai risks in public sector risk management practice,https://www.semanticscholar.org/paper/3488e7b86f16c0d93b7b151eca0d7e7526e6d44b,"Artificial intelligence (AI) adoption by public sector organizations (PSOs) introduces various ethical risks stemming from a lack of integrating human values into AI design. Addressing these ethical risks is a complex collective responsibility among designers, developers, risk experts, and public sector managers. Embedding these risks in existing risk management practices is crucial for responsible AI adoption, as emphasized by the legal requirements of the EU AI Act. However, the responsibility for managing these ethical risks is often unclear. Public sector organizations face unique challenges due to the complex, uncertain, and rapidly evolving nature of AI technologies, further complicating the management of ethical risks. This paper explores using the Three Lines of Defense (TLoD) risk management model to understand and address these ethical risks in public sector AI adoption. The TLoD model structures risk management across three lines: operational management, risk oversight and compliance, and internal audit. This framework helps to distribute and integrate the collective responsibility for ethical AI risk management within public sector organizations, emphasizing alignment and collaboration among different actors. Through an exploratory study involving a survey and semi-structured interviews with professionals responsible for AI-related risk management in Dutch public sector organizations, we assess the TLoD model's usefulness in addressing ethical AI risks. The study examines the challenges and opportunities in applying the TLoD model to manage ethical risks and identifies the potential gaps in responsibility and oversight. The findings suggest that while the TLoD model offers a valuable lens for distributing risk management responsibilities, there are limitations in addressing the emergent and complex nature of ethical risks in AI adoption.",included,112,0.830632627
10.1007/s44206-023-00074-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Digital Society,Springer,11/8/2023 0:00,springer,"auditing of ai: legal, ethical and technical approaches",http://dx.doi.org/10.1007/s44206-023-00074-y,"AI auditing is a rapidly growing field of research and practice. This review article, which doubles as an editorial to Digital Society’s topical collection on ‘Auditing of AI’, provides an overview of previous work in the field. Three key points emerge from the review. First, contemporary attempts to audit AI systems have much to learn from how audits have historically been structured and conducted in areas like financial accounting, safety engineering and the social sciences. Second, both policymakers and technology providers have an interest in promoting auditing as an AI governance mechanism. Academic researchers can thus fill an important role by studying the feasibility and effectiveness of different AI auditing procedures. Third, AI auditing is an inherently multidisciplinary undertaking, to which substantial contributions have been made by computer scientists and engineers as well as social scientists, philosophers, legal scholars and industry practitioners. Reflecting this diversity of perspectives, different approaches to AI auditing have different affordances and constraints. Specifically, a distinction can be made between technology-oriented audits, which focus on the properties and capabilities of AI systems, and process-oriented audits, which focus on technology providers’ governance structures and quality management systems. The next step in the evolution of auditing as an AI governance mechanism, this article concludes, should be the interlinking of these available—and complementary—approaches into structured and holistic procedures to audit not only how AI systems are designed and used but also how they impact users, societies and the natural environment in applied settings over time.",not included,1603,0.828934193
10.1038/s41746-024-01221-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',npj Digital Medicine,Nature,8/27/2024 0:00,springer,mapping the regulatory landscape for artificial intelligence in health within the european union,http://dx.doi.org/10.1038/s41746-024-01221-6,"Regulatory frameworks for artificial intelligence (AI) are needed to mitigate risks while ensuring the ethical, secure, and effective implementation of AI technology in healthcare and population health. In this article, we present a synthesis of 141 binding policies applicable to AI in healthcare and population health in the EU and 10 European countries. The EU AI Act sets the overall regulatory framework for AI, while other legislations set social, health, and human rights standards, address the safety of technologies and the implementation of innovation, and ensure the protection and safe use of data. Regulation specifically pertaining to AI is still nascent and scarce, though a combination of data, technology, innovation, and health and human rights policy has already formed a baseline regulatory framework for AI in health. Future work should explore specific regulatory challenges, especially with respect to AI medical devices, data protection, and data enablement.",not included,401,0.828924656
10.1007/s00146-021-01264-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,on machine learning and the replacement of human labour: anti-cartesianism versus babbage’s path,http://dx.doi.org/10.1007/s00146-021-01264-3,"This paper addresses two methodological paths in Artificial Intelligence: the paths of Babbage and anti-Cartesianism. While those researchers who have followed the latter have attempted to reverse the Cartesian dictum according to which machines cannot think in principle, Babbage’s path, which has been partially neglected, implies that the  replacement of humans —and not the creation of minds—should provide the foundation of AI. In view of the examined paths, the claim that we support here is this: in line with Babbage, AI researchers have recently concentrated upon the replacement of human labour, and thus upon the creation of Machine Learning systems. After presenting and analysing the paths, we characterise Machine Learning via its developments and an illustrative example. Then, we put forward an argument that shows that total replacement of human labour will not be feasible for practical and conceptual reasons despite the successful developments in recent AI systems. Our discussion finally leads to optimism and awareness: AI’s advances allow humans to dedicate themselves to higher level tasks, but these advances also require that we be vigilant about the responsibilities granted to ML-based systems.",not included,2545,0.828905404
10.2196/47847,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,JMIR Formative Research,1/1/2000 0:00,semantic_scholar,the adoption of ai in mental health care–perspectives from mental health professionals: qualitative descriptive study,https://www.semanticscholar.org/paper/59b6218ff63c469469402502fa19a7fbd0ba717f,"Background Artificial intelligence (AI) is transforming the mental health care environment. AI tools are increasingly accessed by clients and service users. Mental health professionals must be prepared not only to use AI but also to have conversations about it when delivering care. Despite the potential for AI to enable more efficient and reliable and higher-quality care delivery, there is a persistent gap among mental health professionals in the adoption of AI. Objective A needs assessment was conducted among mental health professionals to (1) understand the learning needs of the workforce and their attitudes toward AI and (2) inform the development of AI education curricula and knowledge translation products. Methods A qualitative descriptive approach was taken to explore the needs of mental health professionals regarding their adoption of AI through semistructured interviews. To reach maximum variation sampling, mental health professionals (eg, psychiatrists, mental health nurses, educators, scientists, and social workers) in various settings across Ontario (eg, urban and rural, public and private sector, and clinical and research) were recruited. Results A total of 20 individuals were recruited. Participants included practitioners (9/20, 45% social workers and 1/20, 5% mental health nurses), educator scientists (5/20, 25% with dual roles as professors/lecturers and researchers), and practitioner scientists (3/20, 15% with dual roles as researchers and psychiatrists and 2/20, 10% with dual roles as researchers and mental health nurses). Four major themes emerged: (1) fostering practice change and building self-efficacy to integrate AI into patient care; (2) promoting system-level change to accelerate the adoption of AI in mental health; (3) addressing the importance of organizational readiness as a catalyst for AI adoption; and (4) ensuring that mental health professionals have the education, knowledge, and skills to harness AI in optimizing patient care. Conclusions AI technologies are starting to emerge in mental health care. Although many digital tools, web-based services, and mobile apps are designed using AI algorithms, mental health professionals have generally been slower in the adoption of AI. As indicated by this study’s findings, the implications are 3-fold. At the individual level, digital professionals must see the value in digitally compassionate tools that retain a humanistic approach to care. For mental health professionals, resistance toward AI adoption must be acknowledged through educational initiatives to raise awareness about the relevance, practicality, and benefits of AI. At the organizational level, digital professionals and leaders must collaborate on governance and funding structures to promote employee buy-in. At the societal level, digital and mental health professionals should collaborate in the creation of formal AI training programs specific to mental health to address knowledge gaps. This study promotes the design of relevant and sustainable education programs to support the adoption of AI within the mental health care sphere.",not included,80,0.827087939
10.1016/j.ijinfomgt.2021.102401,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85112007685,scopus,12/1/2021,scopus,public and private value creation using artificial intelligence: an empirical study of ai voice robot users in chinese public sector,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85112007685&origin=inward,"
                  Despite significant theoretical and empirical attention on public value creation in the public sector, the relationship between artificial intelligence (AI) use and value creation from the citizen perspective remains poorly understood. We ground our study in Moore’s public value management to examine the relationship between AI use and value creation. We conceptually categorize public service value into public value and private value. We use procedural justice and trust in government as indicators of public value and, based on motivation theory, we use perceived usefulness and perceived enjoyment as indicators of private value. A field survey of 492 AI voice robot users in China was conducted to test our model. The results indicated that the effective use of AI voice robots was significantly associated with private value and procedural justice. However, the relationship between the effective use of AI and trust in government was not found to be significant. Surprisingly, the respondents indicated that private value had a greater effect on overall value creation than public value. This contrasts with the common idea that value creation from the government perspective suggests that social objectives requiring public value are more important to citizens. The results also show that gender and citizens with different experiences show different AI usage behaviors.
               ",included,8630,0.827034473
10.1007/s00146-022-01602-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2023 0:00,springer,ai ethics: from principles to practice,http://dx.doi.org/10.1007/s00146-022-01602-z,"Much of the current work on AI ethics has lost its connection to the real-world impact by making AI ethics operable. There exist significant limitations of hyper-focusing on the identification of abstract ethical principles, lacking effective collaboration among stakeholders, and lacking the communication of ethical principles to real-world applications. This position paper presents challenges in making AI ethics operable and highlights key obstacles to AI ethics impact. A preliminary practice example is provided to initiate practical implementations of AI ethics. We aim to inspire discussions on making AI ethics operable and focus on its impact on real-world applications.",not included,1437,0.826663613
10.3390/su16177724,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Sustainability,1/1/2000 0:00,semantic_scholar,procurement of artificial intelligence systems in uae public sectors: an interpretive structural modeling of critical success factors,https://www.semanticscholar.org/paper/eced54e0bfcf41cbad64157ed5683138764a2d2c,"This study investigates the critical success factors (CSFs) influencing the procurement of artificial intelligence (AI) systems within the United Arab Emirates (UAE) public sector. While AI holds immense potential to enhance public service delivery, its successful integration hinges on critical factors. This research utilizes Interpretive Structural Modeling (ISM) to analyze the CSFs impacting AI procurement within the UAE public sector. Through ISM, a structural model is developed to highlight the interrelationships between these CSFs and their influence on the procurement process, outlining the key elements for successful AI procurement within the UAE public sector. Based on the literature review and expert validation from the UAE public sector, ten CSFs were identified. This study found that clear needs assessment is the most influential CSF, while the long-term value of AI systems or services is the least influential. This study provides policymakers and public sector leaders with valuable insights, enabling them to formulate effective strategies to optimize the procurement process and establish a strong foundation for AI adoption. Finally, this will lead to an improved and more efficient public service delivery in the UAE.",included,102,0.82621038
10.1007/s42413-019-00054-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',International Journal of Community Well-Being,Springer,3/1/2020 0:00,springer,artificial intelligence and community well-being: a proposal for an emerging area of research,http://dx.doi.org/10.1007/s42413-019-00054-6,"We are calling for a new area of research on the nexus of community well-being and artificial intelligence (AI). Three components of this research we propose are (1) the development and use of well-being metrics to measure the impacts of AI; (2) the use of community-based approaches in the development of AI; and (3) development of AI interventions to safeguard or improve community well-being. After providing definitions of community, well-being, and community well-being, we suggest a definition of AI for use by community well-being researchers, with brief explanations of types and uses of AI within this context. A brief summary of threats and opportunities facing community well-being for which AI could potentially present solutions or exacerbate problems is provided. The three components we propose are then discussed, followed by our call for cross-sector, interdisciplinary, transdisciplinary and systems-based approaches for the formation of this proposed area of research.",included,4544,0.826135397
10.3390/app14188259,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Applied Sciences,1/1/2000 0:00,semantic_scholar,"enhancing e-government services through state-of-the-art, modular, and reproducible architecture over large language models",https://www.semanticscholar.org/paper/282d499f97460e32efae0b0107480d75872bbc5d,"Integrating Large Language Models (LLMs) into e-government applications has the potential to improve public service delivery through advanced data processing and automation. This paper explores critical aspects of a modular and reproducible architecture based on Retrieval-Augmented Generation (RAG) for deploying LLM-based assistants within e-government systems. By examining current practices and challenges, we propose a framework ensuring that Artificial Intelligence (AI) systems are modular and reproducible, essential for maintaining scalability, transparency, and ethical standards. Our approach utilizing Haystack demonstrates a complete multi-agent Generative AI (GAI) virtual assistant that facilitates scalability and reproducibility by allowing individual components to be independently scaled. This research focuses on a comprehensive review of the existing literature and presents case study examples to demonstrate how such an architecture can enhance public service operations. This framework provides a valuable case study for researchers, policymakers, and practitioners interested in exploring the integration of advanced computational linguistics and LLMs into e-government services, although it could benefit from further empirical validation.",included,133,0.826003551
10.1007/s12027-019-00582-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',ERA Forum,Springer,3/1/2020 0:00,springer,"artificial intelligence: the right to protection from discrimination caused by algorithms, machine learning and automated decision-making",http://dx.doi.org/10.1007/s12027-019-00582-w,"An analysis of how Artificial Intelligence, ML algorithms and automated decision-making can give rise to discrimination and the ways in which Europe’s existing equality framework can regulate any inequality whilst also identifying how it must change to meet the challenges ahead. The authors also examine some of the ways in which the GDPR impacts on Artificial Intelligence, ML algorithms and automated decision making.",not included,4546,0.825801492
10.48550/arxiv.2405.13606,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Conference on Electronic Government,1/1/2000 0:00,semantic_scholar,from the evolution of public data ecosystems to the evolving horizons of the forward-looking intelligent public data ecosystem empowered by emerging technologies,https://www.semanticscholar.org/paper/770b35d725e52eb3846ca0ea9b465fc6cbc3cf4b,"Public data ecosystems (PDEs) represent complex socio-technical systems crucial for optimizing data use in the public sector and outside it. Recognizing their multifaceted nature, previous research pro-posed a six-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed as a result of a systematic literature review on the topic spanning three decade, this model, while theoretically robust, necessitates empirical validation to enhance its practical applicability. This study addresses this gap by validating the theoretical model through a real-life examination in five European countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This empirical validation provides insights into PDEs dynamics and variations of implementations across contexts, particularly focusing on the 6th generation of forward-looking PDE generation named""Intelligent Public Data Generation""that represents a paradigm shift driven by emerging technologies such as cloud computing, Artificial Intelligence, Natural Language Processing tools, Generative AI, and Large Language Models (LLM) with potential to contribute to both automation and augmentation of business processes within these ecosystems. By transcending their traditional status as a mere component, evolving into both an actor and a stakeholder simultaneously, these technologies catalyze innovation and progress, enhancing PDE management strategies to align with societal, regulatory, and technical imperatives in the digital era.",not included,145,0.825786352
10.1145/3325112.3325245,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2019 0:00,semantic_scholar,the data firehose and ai in government: why data management is a key to value and ethics,https://www.semanticscholar.org/paper/9eacf62f1e546748428c7e4843731b1595294200,"Technical and organizational innovations such as Open Data, Internet of Things and Big Data have fueled renewed interest in policy analytics in the public sector. This revamped version of policy analysis continues the long-standing tradition of applying statistical modeling to better understand policy effects and decision making, but also incorporates other computational approaches such as artificial intelligence (AI) and computer simulation. Although much attention has been given to the development of capabilities for data analysis, there is much less attention to understanding the role of data management in a context of AI in government. In this paper, we argue that data management capabilities are foundational to data analysis of any kind, but even more important in the present AI context. This is so because without proper data management, simply acquiring data or systems will not produce desired outcomes. We also argue that realizing the potential of AI for social good relies on investments specifically focused on this social outcome, investments in the processes of building trust in government data, and ensuring the data are ready and suitable for use, for both immediate and future uses.",not included,9,0.825763881
10.1145/3600211.3604744,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"AAAI/ACM Conference on AI, Ethics, and Society",1/1/2000 0:00,semantic_scholar,the eliza defect: constructing the right users for generative ai,https://www.semanticscholar.org/paper/c4b45d26f2b04634a6b8456c83ab3f114f5ebb26,"Artificial intelligence (AI) is at the center of debates on what kind of future we want and how to bring it about. But AI ethics is not only a technical risk assessment and accounting effort, or an application of general principles to stable artifacts. It is also a social self-diagnosis, a contested and contestable assertion of values and desirable futures, and a selective understanding of the nature of AI in its different forms. In expressions of concern and efforts at preparation for increasingly powerful AI tools, we can trace the ways we imagine ourselves and our society to be compatible with AI's promises and susceptible to its dangers. The problems we notice, and the solutions we offer, arise from the interaction of these imagined elements. The socially embedded efficacy of AI tools leads many commentators to imagine their risks specifically in conjunction with understandings of society as it currently is and imaginations of how it can and should exist in the future [1]. The sense-making moves performed in the wake of developments in generative AI are thus a site to examine the movement and uses of different concepts brought together in this domain: the human, rationality, and the place of expertise. As these sense-making efforts are carried out, they become constraints on how the risks of generative AI can be noticed and understood. The problems raised by generative AI are so fundamentally tied to its performance as a simulator of human interpersonal acts that we should ask: where is the risk of generative AI located, such that the utility and the safety of the tools can be preserved after troubling cases? Boundaries between malicious deception and magnificent design are unclear without an answer to this question. Thus, to fit generative AI into our world, we are trying to answer it; this is one goal of efforts at regulation which seeks to allow the benefits of imitation to arrive while avoiding the harms of deception. In the current regulation, reporting, and corporate responses to generative AI, the challenge of safely introducing generative AI is being approached in large part as a challenge of producing the right kind of knowledge in its users. Below is a summary of my findings from three cases, chosen to investigate the following question: What ways, or whose ways, of using, knowing, and understanding generative AI are being offered as appropriate? I examine the EU AI Act language reflecting disclosure requirements for interactions with generative AI, responses to a chatbot-facilitated suicide in Belgium, and reactions to expert claims of a chatbot's sentience. In the first two cases, AI-generated content is problematic insofar as users are uninformed about its provenance or maliciously deceived by it, while users who know they are interacting with AI but behave problematically are designated as deluded or irrational. In the third case, a Google engineer who presents evidence to support claims that AI is sentient is censured as nationwide reporting denounces his claim against an expert consensus from which he is ejected. In all three cases, challenges facing widespread generative AI development and use are avoided by attending to the knowledge and understanding of those who use them rather than the functioning of the tools themselves. The EU AI Act is illuminating as a general and authoritative account of how AI interactions can be made safe, requiring first and foremost that users are informed. [2, 3] The AI Act is useful in the present paper as it shows the effort to match and reconcile a new technology with an extant set of values, chief among which is autonomy. Its reliance on disclosure reflects a general sense that harms are acceptable or unacceptable not on the basis of outcomes but based on the degree of autonomy possessed by the actors in question. Rational actors in a simulated environment are responsible for the effects of the simulation, so long as they are informed of the nature of that environment and have essentially consented to consume deceptive or false content. The other two cases I examine explore this very issue, of problematic understandings and behavior on the part of knowing users. The first of these is the case of the Belgian man. After his suicide responses from the company which provided the chatbot, media [4, 5, 6] and government [5], and prominent expert AI ethics commentary [7] characterized it as arising because the user was vulnerable and consequently did not relate to the bot in the right way. While the chatbot's emotionally charged language was seen as a part of the problem, in the reporting on this event the unanimous emphasis on the man's mental state presents the risk as arising in an interaction, in a pathological mistake of the user, rather than in the tool. Locating risk is a necessary and immensely powerful, if often unexamined step which precedes intervention in a worrisome state of affairs: where we locate risk is where we intervene. If the risk accompanying generative AI is located in the minds of uninformed or misapprehending users, disclosures and disclaimers are indeed sensible interventions. In this conception, when knowledge fails to protect the user, it is not a failed safeguard but a bad user. Problematizing user understandings in this way provides an exonerating resource for the companies providing these tools and suggests the rectitude of expert authority on the nature of these tools, by linking delays and dangers in generative AI to users who do not abide by the (strategically underdetermined) expert consensus on generative AI's accuracy, capabilities, and nature. My third case examines how the expert consensus around generative AI is maintained through the story of Blake Lemoine, who publicly announced his belief that Google's LaMDA model had become sentient and was presented by major media outlets and experts as deluded [8, 9, 10, 11, 12, 13]. In the media and corporate response to Lemoine, wherein Google questioned his sanity before firing him [13], we see his ejection from the community of experts permitted to call for greater scrutiny based on qualitative changes in the nature of these models. He becomes a layperson on account of his anthropomorphizing error. In this act of boundary work [14], policing who is in the body of experts qualified to decide on the sentience of the chatbot, and the nature of AI models in general, we must notice how small this group truly is and what Lemoine's ejection preserves. If safeguards like those Lemoine called for should follow on the kind of change he claimed to detect, and those outside Google's leadership could determine when such changes have arrived, Google would cease to lead the conversation on regulation by defining the nature of its technology. This state of affairs leaves the right relations with generative AI underdetermined but maintains that positions which challenge the expert consensus are the result of misunderstandings so significant as to disqualify the concerned party's thoughts on the matter from rational consideration. In the three cases examined here, events and concerns which threaten to depict generative AI as in need of significant scrutiny or changes are defused not by intervening in the company's technology, but by delineating between user understandings which are empowered and exploitative, safe and vulnerable, rational and deluded. Named after an early chatbot, the ELIZA effect refers to the readiness with which users anthropomorphize computer systems [15]. Reporting on both Lemoine [11] and the Belgian man cited this effect [6]. The chatbot which encouraged the Belgian man to commit suicide was named Eliza. One way of summarizing the change I trace in the cases described above is a transition away from the Turing test and towards the ELIZA effect as the conceptual frame for AI which imitates humans. While the Turing test implies the layperson's relevance to the discussion and regulation of AI, the ELIZA effect implies their irrelevance. This project will continue as an effort to follow popular, expert, and regulatory perceptions of the risk of generative AI as the tools themselves and the public concern surrounding them continue to develop. The resources of science and technology studies (STS) enable crucial perspectives on numerous ways of thinking about AI and the challenges of its development and regulation such as the common citations of law lag, invocations of self-regulation in the mode of the Asilomar Conference on rDNA, collective action problem framings, and more. The STS literature on sociotechnical imaginaries [1] and public understandings of science [16] contribute to the present insight as to how the efforts of tech-society reconciliation and risk-benefit balancing presented as appropriate for AI reveal and produce our understandings of the technology, even as they reproduce and reshape social norms. There is an urgent need for work which extends this powerful scholarly tradition for understanding science, technology, and society to AI, as one of the most important and concerning technological developments of our moment.",not included,62,0.825204551
10.1007/s43681-021-00098-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,2/1/2022 0:00,springer,factoring ethics in management algorithms for municipal information-analytical systems,http://dx.doi.org/10.1007/s43681-021-00098-5,"The discourse on the ethics of artificial intelligence (AI) has generated a plethora of different conventions, principles and guidelines outlining an ethical perspective on the use and research of AI. However, when it comes to breaking down general implications to specific use cases, existent frameworks have been remaining vague. The following paper aims to fill this gap by examining the ethical implications of the use of information analytical systems through a management approach for filtering the content in social media and preventing information thrusts with negative consequences for human beings and public administration. The ethical dimensions of AI technologies are revealed through deduction of general challenges of digital governance to applied level management technics.",included,3273,0.825051665
10.1007/s43681-021-00083-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/1/2022 0:00,springer,mapping global ai governance: a nascent regime in a fragmented landscape,http://dx.doi.org/10.1007/s43681-021-00083-y,"The rapid advances in the development and rollout of artificial intelligence (AI) technologies over the past years have triggered a frenzy of regulatory initiatives at various levels of government and the private sector. This article describes and evaluates the emerging global AI governance architecture and traces the contours of a nascent regime in a fragmented landscape. To do so, it organizes actors and initiatives in a two-by-two matrix, distinguishing between the nature of the driving actor(s) and whether or not their actions take place within the existing governance architecture. Based on this, it provides an overview of key actors and initiatives, highlighting their trajectories and connections. The analysis shows international organizations’ high levels of agency in addressing AI policy and a tendency to address new challenges within existing frameworks. Lastly, it is argued that we are witnessing the first signs of consolidation in this fragmented landscape. The nascent AI regime that emerges is polycentric and fragmented but gravitates around the Organisation for Economic Co-Operation and Development (OECD), which holds considerable epistemic authority and norm-setting power.",included,3083,0.825007081
10.17705/1pais.14304,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Pacific Asia Journal of the Association for Information Systems,1/1/2022 0:00,semantic_scholar,strengthening public institutions and social inclusion of vulnerable groups in a developing country - innovation in organizations and artificial intelligence implications,https://www.semanticscholar.org/paper/be49e6c6ff3488433b44a0b542e4cf8f2429800d,"Background: In the context of a developing nation, children's participation in communal life is almost non-existent. The goal of the study is to contribute to national policies for local development that should prioritize the safety and well-being of the most vulnerable populations, particularly children under the age of 18. Innovating, including children in decision-making and maintaining local services in three pilot municipalities in order to prevent and combat all forms of exploitation to which they are exposed. How can Youth engagement in social and political community life be improved through better understanding of their needs and interests, and what are the artificial intelligence implications? Method: The methodology was used and designed to re-validate an existing program using pre-defined components of an agreement between the Italian and Lebanese governments. A needs study on the socio-demographic profile of youth and a situational analysis was conducted answering three objectives in the program of the Child Friendly City initiative. Results: Assuring the long-term viability and social inclusion of a significant socio-demographic group was successfully implemented: a free call center, software applications, a library, a digital network center, and the involvement of children on the municipal board of directors were established. The findings need to be adapted to various locations using artificial intelligence (AI) solutions and strategies for social awareness and behavior analysis. Conclusion: The importance of this study was underscored during the Covid-19 sanitary crisis, when some of these technologies enabled young people in impacted areas to integrate and become aware of the pandemic's risk. The case was based on theories such as Gender Inequalities and Children's Inclusion, Municipal Governance & Reform, Organizational Innovation (Public Sector), and Social Inclusion, and it demonstrates the value of innovating in the public sector and protecting vulnerable populations through the use of AI.",not included,29,0.824639142
10.18178/jaai.2023.1.2.103-116,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Advances in Artificial Intelligence,1/1/2000 0:00,semantic_scholar,use of domain engineering in hyperautomation applied to decision making in government,https://www.semanticscholar.org/paper/87d110893ac357209247502dfdd2d5312ec44cfd,"This article presents the domain engineering process carried out to obtain the requirements for the implementation of an Artificial Intelligence (AI) compliance framework aimed at the public sector. Owing to the current competitive and fast economy, which generates huge demand for increasingly efficient, reliable, and transparent intelligent systems, decision-support architectures should also be developed under strong restrictions of cost and time. Such a context requires adequate structures, processes, and technologies for coping with the complexity of building such intelligent systems. Currently, many public organizations have adopted applications for process automation, with the aim of refraining from repetitive work and producing more efficient results. However, what is not so often observed is the development of intelligent engines to support complex public decision-making. Possible explanations are the plethora of available data sources and the number of legal norms to be abided by. Moreover, it is important to highlight the need to incorporate transparency, auditability, reusability, and flexibility into such systems. Thus, they can be safely utilized in various analogous situations, reducing the need to develop new applications from scratch. An architecture suitable for supporting public decision-making with so many features and increasingly unstructured data, as well as abundant regulation, needs well-crafted formal specifications. This article aims to analyze three existing frameworks and carry out domain engineering studies in three cases to produce some guidance for future public applications and services based on AI. Next, we provide a conceptual preliminary architectural definition for the public sector. The proposed architecture targets were identified in the three cases studied, namely, frequent tasks of process mining requirements, detection of anomalies, and extraction of rules and public policies for helping public servants. All these aim at expedient AI development for public decision-making.",included,79,0.824279606
10.1140/epjs/s11734-022-00475-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',The European Physical Journal Special Topics,Springer,7/1/2022 0:00,springer,"integrative urban ai to expand coverage, access, and equity of urban data",http://dx.doi.org/10.1140/epjs/s11734-022-00475-z,"We consider the use of AI techniques to expand the coverage, access, and equity of urban data. We aim to enable holistic research on city dynamics, steering AI research attention away from profit-oriented, societally harmful applications (e.g., facial recognition) and toward foundational questions in mobility, participatory governance, and justice. By making available high-quality, multi-variate, cross-scale data for research, we aim to link the macrostudy of cities as complex systems with the reductionist view of cities as an assembly of independent prediction tasks. We identify four research areas in AI for cities as key enablers: interpolation and extrapolation of spatiotemporal data, using NLP techniques to model speech- and text-intensive governance activities, exploiting ontology modeling in learning tasks, and understanding the interaction of fairness and interpretability in sensitive contexts.",not included,2930,0.824233174
10.1109/ecai46879.2019.9042157,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,European Conference on Artificial Intelligence,1/1/2019 0:00,semantic_scholar,intelligent solutions - based framework for digital public services. a case study for smart transportation,https://www.semanticscholar.org/paper/3d863678d53ef04773b3e6052995b85db1903e28,"Digital technology landscape is continuously improving, dragging along both the transformation of public services and new demands of citizens. Emerging new technologies like Artificial Intelligence, Machine Learning, Deep Learning or Internet of Things provide tremendous means to implement intelligent solutions for reshaping digital public services. This paper aims to disclose the most important features of several intelligent technologies and of these types of public services that can be integrated for providing new capabilities. An AI-based architecture for supporting digital public services in the smart transportation sector is presented in order to demonstrate the highlighted ideas and concepts.",included,12,0.824171484
10.1038/s44168-023-00056-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',npj Climate Action,Nature,8/17/2023 0:00,springer,harnessing human and machine intelligence for planetary-level climate action,http://dx.doi.org/10.1038/s44168-023-00056-3,"The ongoing global race for bigger and better artificial intelligence (AI) systems is expected to have a profound societal and environmental impact by altering job markets, disrupting business models, and enabling new governance and societal welfare structures that can affect global consensus for climate action pathways. However, the current AI systems are trained on biased datasets that could destabilize political agencies impacting climate change mitigation and adaptation decisions and compromise social stability, potentially leading to societal tipping events. Thus, the appropriate design of a less biased AI system that reflects both direct and indirect effects on societies and planetary challenges is a question of paramount importance. In this paper, we tackle the question of data-centric knowledge generation for climate action in ways that minimize biased AI. We argue for the need to co-align a less biased AI with an epistemic web on planetary health challenges for more trustworthy decision-making. A human-in-the-loop AI can be designed to align with three goals. First, it can contribute to a planetary epistemic web that supports climate action. Second, it can directly enable mitigation and adaptation interventions through knowledge of social tipping elements. Finally, it can reduce the data injustices associated with AI pretraining datasets.",not included,1877,0.824029088
10.1007/s00146-021-01259-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,speeding up to keep up: exploring the use of ai in the research process,http://dx.doi.org/10.1007/s00146-021-01259-0,"There is a long history of the science of intelligent machines and its potential to provide scientific insights have been debated since the dawn of AI. In particular, there is renewed interest in the role of AI in research and research policy as an enabler of new methods, processes, management and evaluation which is still relatively under-explored. This empirical paper explores interviews with leading scholars on the potential impact of AI on research practice and culture through deductive, thematic analysis to show the issues affecting academics and universities today. Our interviewees identify positive and negative consequences for research and researchers with respect to  collective  and  individual use . AI is perceived as helpful with respect to information gathering and other narrow tasks, and in support of impact and interdisciplinarity. However, using AI as a way of ‘speeding up—to keep up’ with bureaucratic and metricised processes, may proliferate negative aspects of academic culture in that the expansion of AI in research should assist and not replace human creativity. Research into the future role of AI in the research process needs to go further to address these challenges, and ask fundamental questions about how AI might assist in providing new tools able to question the values and principles driving institutions and research processes. We argue that to do this an explicit movement of meta-research on the role of AI in research should consider the effects for research and researcher creativity. Anticipatory approaches and engagement of diverse and critical voices at policy level and across disciplines should also be considered.",not included,2549,0.823486686
10.1007/s00146-022-01445-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/1/2023 0:00,springer,investing in ai for social good: an analysis of european national strategies,http://dx.doi.org/10.1007/s00146-022-01445-8,"Artificial Intelligence (AI) has become a driving force in modern research, industry and public administration and the European Union (EU) is embracing this technology with a view to creating societal, as well as economic, value. This effort has been shared by EU Member States which were all encouraged to develop their own national AI strategies outlining policies and investment levels. This study focuses on how EU Member States are approaching the promise to develop and use AI for the good of society through the lens of their national AI strategies. In particular, we aim to investigate how European countries are investing in AI and to what extent the stated plans contribute to the good of people and society as a whole. Our contribution consists of three parts: (i) a conceptualization of AI for social good highlighting the role of AI policy, in particular, the one put forward by the European Commission (EC); (ii) a qualitative analysis of 15 European national strategies mapping investment plans and suggesting their relation to the social good (iii) a reflection on the current status of investments in socially good AI and possible steps to move forward. Our study suggests that while European national strategies incorporate money allocations in the sphere of AI for social good (e.g. education), there is a broader variety of underestimated actions (e.g. multidisciplinary approach in STEM curricula and dialogue among stakeholders) that can boost the European commitment to sustainable and responsible AI innovation.",not included,2246,0.823243439
10.1145/3396956.3396965,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,1/1/2020 0:00,semantic_scholar,public decision making: connecting artificial intelligence and crowds,https://www.semanticscholar.org/paper/14c12f9d44ef23a8c2d39bcf1e3ab1a13d684054,"The recent breakthrough of artificial intelligence, as well as the wide adoption of the wisdom of the crowd, also known as collective intelligence, across sectors, has received attention and excitement across disciplines. In addition to the scientific breakthrough, recent public sector studies recognize AI's potential contributions in public services, such as big data for decision making, the development of smart cities, and social and health care. Studies have also recognized crowdsourcing's potential for service provisions, innovation, information generation, and policymaking. However, we have only a limited understanding of the connections between these two types of intelligence and adoption conditions to properly utilize them for the public sector. To understand what roles AI and crowds can play in enhancing public services and policymaking, we adopt a bibliometric analysis to identify emerging themes and interconnections between these two streams of literature. Our study provides key themes and significance for each cluster. Our first examination of AI and crowd literature regarding connection to public values, complementary in public decision making, as well as future potential for joint adoption by governments provides some implications for future considerations.",not included,15,0.82308197
10.1007/s00146-022-01611-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2024 0:00,springer,the limitation of ethics-based approaches to regulating artificial intelligence: regulatory gifting in the context of russia,http://dx.doi.org/10.1007/s00146-022-01611-y,"The effects that artificial intelligence (AI) technologies will have on society in the short- and long-term are inherently uncertain. For this reason, many governments are avoiding strict command and control regulations for this technology and instead rely on softer ethics-based approaches. The Russian approach to regulating AI is characterized by the prevalence of unenforceable ethical principles implemented via industry self-regulation. We analyze the emergence of the regulatory regime for AI in Russia to illustrate the limitations of this approach. The article is based on 50 interviews with policymakers, representatives of AI companies, and academics in the country. The findings show that this regulatory regime was formed under the strong influence of Russian big tech companies, which saw an opportunity to avoid regulatory oversight by washing out concrete regulatory measures from the policy. This approach is part of a broader protectionist sanction-proofing strategy for the local IT sector designed by the government, which can be characterized by lifting regulatory barriers for local companies. Unenforceable ethics-based self-regulation is a regulatory gift from the Russian government to the industry. This gift was intentionally designed because the government thought that prioritizing local innovation over consumer protection would benefit the public. However, the gift can also unintentionally undermine the public interest by providing an opportunity for ethics washing .",not included,733,0.822883189
10.1007/s43681-022-00153-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,2/1/2022 0:00,springer,racing into the fourth industrial revolution: exploring the ethical dimensions of medical ai and rights-based regulatory framework,http://dx.doi.org/10.1007/s43681-022-00153-9,"Artificial intelligence (AI) is playing an increasing role in clinical decision-making. This capability is learned and therefore, the ways in which data are coded, collected, and selected to train algorithms, including the tools overall design, impact patterns that AI notices and its output. Ethically, racial health inequalities are unjust—this is the priority position of Rawls ethical theory of justice-and erodes trust in the medical system. To close gaps, operationalising fairness and equity into AI-based clinical support tools and decision-making algorithms entails seeking to maximize the benefits of AI while preventing harm and minimizing intervention-generated inequalities among historically underserved and underrepresented populations in medicine. Equitable healthcare is an idea whose time has come—as is the time for swift action on AI regulations to protect rights—and people. Alas, the triple aim of this commentary is to cover ethical implications of algorithmic bias, practical boundaries involving theoretical frameworks to guide the design and development of equitable, decision-making AI and why a rights-based approach to AI regulation enhances health for all.",not included,3281,0.822319686
10.1007/s43681-024-00500-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,6/5/2024 0:00,springer,how to gain control and influence algorithms: contesting ai to find relevant reasons,http://dx.doi.org/10.1007/s43681-024-00500-y,"Relevancy is a prevalent term in value alignment. We either need to keep track of the relevant moral reasons, we need to embed the relevant values, or we need to learn from the relevant behaviour. What relevancy entails in particular cases, however, is often ill-defined. The reasons for this are obvious, it is hard to define relevancy in a way that is both general and concrete enough to give direction towards a specific implementation. In this paper, we describe the inherent difficulty that comes along with defining what is relevant to a particular situation. Simply due to design and the way an AI system functions, we need to state or learn particular goals and circumstances under which that goal is completed. However, because of both the changing nature of the world and the varied wielders and users of such implements, misalignment occurs, especially after a longer amount of time. We propose a way to counteract this by putting contestability front and centre throughout the lifecycle of an AI system, as it can provide insight into what is actually relevant at a particular instance. This allows designers to update the applications in such a manner that they can account for oversight during design.",included,711,0.821936846
10.1038/s41467-020-15871-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Nature Communications,Nature,5/18/2020 0:00,springer,ai for social good: unlocking the opportunity for positive impact,http://dx.doi.org/10.1038/s41467-020-15871-z,"Advances in machine learning (ML) and artificial intelligence (AI) present an opportunity to build better tools and solutions to help address some of the world’s most pressing challenges, and deliver positive social impact in accordance with the priorities outlined in the United Nations’ 17 Sustainable Development Goals (SDGs). The AI for Social Good (AI4SG) movement aims to establish interdisciplinary partnerships centred around AI applications towards SDGs. We provide a set of guidelines for establishing successful long-term collaborations between AI researchers and application-domain experts, relate them to existing AI4SG projects and identify key opportunities for future AI applications targeted towards social good. The AI for Social Good movement aims to apply AI/ML tools to help in delivering on the United Nations’ sustainable development goals (SDGs). Here, the authors identify the challenges and propose guidelines for designing and implementing successful partnerships between AI researchers and application - domain experts.",included,4461,0.821820498
10.1007/s43681-021-00120-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,11/1/2022 0:00,springer,the social dilemma in artificial intelligence development and why we have to solve it,http://dx.doi.org/10.1007/s43681-021-00120-w,"While the demand for ethical artificial intelligence (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for AI development and describe why the current crisis in AI development ethics cannot be solved without relieving AI developers of their social dilemma. We argue that AI development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.",included,2663,0.821764588
10.3233/ip-200249,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Inf. Polity,1/1/2020 0:00,semantic_scholar,administration by algorithm: a risk management framework,https://www.semanticscholar.org/paper/8d03df21807637482739cbfe140b260aa8f1907b,"Algorithmic decision-making is neither a recent phenomenon nor one necessarily associated with artificial intelligence (AI), though advances in AI are increasingly resulting in what were heretofore human decisions being taken over by, or becoming dependent on, algorithms and technologies like machine learning. Such developments promise many potential benefits, but are not without certain risks. These risks are not always well understood. It is not just a question of machines making mistakes; it is the embedding of values, biases and prejudices in software which can discriminate against both individuals and groups in society. Such biases are often hard either to detect or prove, particularly where there are problems with transparency and accountability and where such systems are outsourced to the private sector. Consequently, being able to detect and categorise these risks is essential in order to develop a systematic and calibrated response. This paper proposes a simple taxonomy of decision-making algorithms in the public sector and uses this to build a risk management framework with a number of components including an accountability structure and regulatory governance. This framework is designed to assist scholars and practitioners interested in ensuring structured accountability and legal regulation of AI in the public sphere.",included,19,0.821026087
10.1007/s10943-024-02140-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of Religion and Health,Springer,9/23/2024 0:00,springer,integrating catholic social teaching with ai ethics to address inequity in ai healthcare,http://dx.doi.org/10.1007/s10943-024-02140-2,"Artificial intelligence (AI) in healthcare can potentially improve patient outcomes, operational efficiency, and diagnostic accuracy. However, it also raises serious ethical issues, especially in light of possible disparities in the distribution and accessibility of AI-powered healthcare resources. This study investigates how AI might affect health disparities. It bases its proposal for an equitable AI implementation framework on the justice teachings of the Catholic Church. In line with the Church’s ethical commitment to social justice, the paper makes an ethical case for a responsible approach to AI in healthcare by examining the concepts of human dignity, the common good, and preferential option for the poor.",not included,264,0.821009099
10.1007/s11628-023-00536-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Service Business,Springer,9/1/2023 0:00,springer,development of a citizen participation public service innovation model based on smart governance,http://dx.doi.org/10.1007/s11628-023-00536-w,"This study explores an efficient approach to providing customized public services through a smart governance-based public service innovation model (SG-PSIM) that combines intelligent technology and co-creation. Multiple methodological approaches are applied to develop and evaluate the proposed SG-PSIM. Intelligent methodologies that can support the public service policy process are discussed, and the applicability of the SG-PSIM is demonstrated through four case studies. The study results showed that SG-PSIM can effectively collect the opinions of citizens in diverse ways and provide opportunities for citizens to actively participate in the development of public service policies.",included,1784,0.820752144
10.1007/s12027-022-00719-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',ERA Forum,Springer,10/1/2022 0:00,springer,quality of data sets that feed ai and big data applications for law enforcement,http://dx.doi.org/10.1007/s12027-022-00719-4,"In the era of big data and artificial intelligence (AI), where aggregated data is used to learn about patterns and for decision-making, quality of input data seems to be of paramount importance. Poor data quality may lead not only to wrong outcomes, which will simply render the application useless, but more importantly to fundamental rights breaches and undermined trust in the public authorities using such applications. In law enforcement as in other sectors the question of how to ensure that data used for the development of big data and AI applications meet quality standards remains. This paper provides an overview of this topic, reporting selected issues stemming from big data, nonpersonal data and regulatory contexts. It concludes that the topic is still underexplored and sets areas for further research.",not included,2744,0.819485724
10.1007/s43681-024-00469-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,4/15/2024 0:00,springer,crossing the principle–practice gap in ai ethics with ethical problem-solving,http://dx.doi.org/10.1007/s43681-024-00469-8,"The past years have presented a surge in (AI) development, fueled by breakthroughs in deep learning, increased computational power, and substantial investments in the field. Given the generative capabilities of more recent AI systems, the era of large-scale AI models has transformed various domains that intersect our daily lives. However, this progress raises concerns about the balance between technological advancement, ethical considerations, safety measures, and financial interests. Moreover, using such systems in sensitive areas amplifies our general ethical awareness, prompting a re-emergence of debates on governance, regulation, and human values. However, amidst this landscape, how to bridge the principle–practice gap separating ethical discourse from the technical side of AI development remains an open problem. In response to this challenge, the present work proposes a framework to help shorten this gap: ethical problem-solving (EPS). EPS is a methodology promoting responsible, human-centric, and value-oriented AI development. The framework’s core resides in translating principles into practical implementations using impact assessment surveys and a differential recommendation methodology. We utilize EPS as a blueprint to propose the implementation of an Ethics as a Service Platform , currently available as a simple demonstration. We released all framework components openly and with a permissive license, hoping the community would adopt and extend our efforts into other contexts. Available in the following URL https://nkluge-correa.github.io/ethical-problem-solving/ .",included,991,0.818576217
10.1007/s00146-020-01130-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,9/1/2021 0:00,springer,making the black box society transparent,http://dx.doi.org/10.1007/s00146-020-01130-8,"The growing presence of smart devices in our lives turns all of society into something largely unknown to us. The strategy of demanding transparency stems from the desire to reduce the ignorance to which this automated society seems to condemn us. An evaluation of this strategy first requires that we distinguish the different types of non-transparency. Once we reveal the limits of the transparency needed to confront these devices, the article examines the alternative strategy of explainable artificial intelligence and concludes with the idea that these types of complex realities exceed individual capacities and are only comprehensible in a collective fashion.",included,3597,0.818247914
10.1016/j.clsr.2024.106050,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85203147962,scopus,11/1/2024,scopus,fair and efficient asylum procedures and artificial intelligence: quo vadis due process?,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85203147962&origin=inward,"
                  In a context of high pressure on national asylum systems and a strive for efficiency, public authorities in Europe are increasingly exploring the potential of artificial intelligence-driven technologies in the asylum process. The use of this technology in the field of asylum is a growing but contentious topic, which raises important normative questions and concerns. In this context, this paper aims to analyse the potential implications for fair asylum procedures when artificial intelligence (AI) assists decision-making. Fair asylum procedures, or due process, are a central condition for guaranteeing the right to asylum and preventing unlawful refoulement, and overall ensuring trust in the asylum adjudication system. After revisiting the theoretical foundations of the concept of fair procedures, this paper develops a normative framework that can guide further reflection on the use of AI in asylum procedures. It thereby analyses the concepts that are key to the debate on the use of AI in decision-making: accuracy, efficiency but also participation. Then, drawing on scholarship in both political science and computer science, it explores potential challenges for the core values of fair procedures, considering both technical and non-technical challenges. This paper concludes that while AI promises efficiency gains for the administration, it identifies important challenges for accuracy and participation. On the basis of these considerations, it highlights the questions that should be asked and answered in order to protect the core values of fair asylum procedures.
               ",not included,8478,0.818218768
10.1038/s41562-022-01383-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Nature Human Behaviour,Nature,10/1/2022 0:00,springer,human-centred mechanism design with democratic ai,http://dx.doi.org/10.1038/s41562-022-01383-x,"Building artificial intelligence (AI) that aligns with human values is an unsolved problem. Here we developed a human-in-the-loop research pipeline called Democratic AI, in which reinforcement learning is used to design a social mechanism that humans prefer by majority. A large group of humans played an online investment game that involved deciding whether to keep a monetary endowment or to share it with others for collective benefit. Shared revenue was returned to players under two different redistribution mechanisms, one designed by the AI and the other by humans. The AI discovered a mechanism that redressed initial wealth imbalance, sanctioned free riders and successfully won the majority vote. By optimizing for human preferences, Democratic AI offers a proof of concept for value-aligned policy innovation. Koster, Balaguer et al. show that an AI mechanism is able to learn to produce a redistribution policy which is preferred to alternatives by humans in an incentivized game.",included,2738,0.817948699
10.1007/s43681-022-00178-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,2/1/2023 0:00,springer,"ethical assurance: a practical approach to the responsible design, development, and deployment of data-driven technologies",http://dx.doi.org/10.1007/s43681-022-00178-0,"This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and AI. First, it provides a critical analysis of current efforts to establish practical mechanisms for algorithmic auditing and assessment to identify limitations and gaps with these approaches. Second, it provides a brief introduction to the methodology of argument-based assurance and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems. Third, it generalises this method to incorporate wider ethical, social, and legal considerations, in turn establishing a novel version of argument-based assurance that we call ‘ethical assurance.’ Ethical assurance is presented as a structured method for unifying the myriad practical mechanisms that have been proposed. It is built on a process-based form of project governance that enlists reflective innovation practices to operationalise normative principles, such as sustainability, accountability, transparency, fairness, and explainability. As a set of interlocutory governance mechanisms that span across the data science and AI lifecycle, ethical assurance supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities. Finally, this article sets an agenda for ethical assurance, by detailing current challenges, open questions, and next steps, which serve as a springboard to build an active (and interdisciplinary) research programme as well as contribute to ongoing discussions in policy and governance.",included,2420,0.817799747
10.1007/s00146-023-01684-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,10/1/2024 0:00,springer,"beyond ideals: why the (medical) ai industry needs to motivate behavioural change in line with fairness and transparency values, and how it can do it",http://dx.doi.org/10.1007/s00146-023-01684-3,"Artificial intelligence (AI) is increasingly relied upon by clinicians for making diagnostic and treatment decisions, playing an important role in imaging, diagnosis, risk analysis, lifestyle monitoring, and health information management. While research has identified biases in healthcare AI systems and proposed technical solutions to address these, we argue that effective solutions require human engagement. Furthermore, there is a lack of research on how to motivate the adoption of these solutions and promote investment in designing AI systems that align with values such as transparency and fairness from the outset. Drawing on insights from psychological theories, we assert the need to understand the values that underlie decisions made by individuals involved in creating and deploying AI systems. We describe how this understanding can be leveraged to increase engagement with de-biasing and fairness-enhancing practices within the AI healthcare industry, ultimately leading to sustained behavioral change via autonomy-supportive communication strategies rooted in motivational and social psychology theories. In developing these pathways to engagement, we consider the norms and needs that govern the AI healthcare domain, and we evaluate incentives for maintaining the status quo against economic, legal, and social incentives for behavior change in line with transparency and fairness values.",not included,215,0.817792952
10.3103/s0147688223040081,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Scientific and Technical Information Processing,Springer,12/1/2023 0:00,springer,smart cities: a worldwide journey into intelligent urbanism and state-of-the-art technologies,http://dx.doi.org/10.3103/S0147688223040081,"Abstract Recent years have seen a considerable increase in interest in the notion of smart cities, as cities all over the globe experience with the effects of rising urbanization and the need for efficient and sustainable urban growth. The present study includes an in-depth review of smart cities, including their history, definition, application, consequences, issues, and opportunities for coming years. The study initiates with exploring the historical background and development of smart cities, emphasing how technology is incorporated into urban planning and management. Furthermore, the review paper aims to identify significant topics and areas of concentration in research and practise, and highlight challenges and future possibilities in their implementation.",not included,1432,0.81778419
10.1007/s00146-015-0596-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,8/1/2017 0:00,springer,"digital technologies and artificial intelligence’s present and foreseeable impact on lawyering, judging, policing and law enforcement",http://dx.doi.org/10.1007/s00146-015-0596-5,"‘AI & Law’ research has been around since the 1970s, even though with shifting emphasis. This is an overview of the contributions of digital technologies, both artificial intelligence and non-AI smart tools, to both the legal professions and the police. For example, we briefly consider text mining and case-automated summarization, tools supporting argumentation, tools concerning sentencing based on the technique of case-based reasoning, the role of abductive reasoning, research into applying AI to legal evidence, tools for fighting crime and tools for identification.",not included,5649,0.817780852
10.1007/s41060-023-00384-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',International Journal of Data Science and Analytics,Springer,3/6/2023 0:00,springer,"trans-ai/ds: transformative, transdisciplinary and translational artificial intelligence and data science",http://dx.doi.org/10.1007/s41060-023-00384-x,"After the many ups and downs over the past 70 years of AI and 50 years of data science (DS), AI/DS have migrated into their new age. This new-generation AI/DS build on the consilience and universology of science, technology and engineering. In particular, it synergizes AI and data science, inspiring Trans-AI/DS (i.e., Trans-AI, Trans-DS and their hybridization) thinking, vision, paradigms, approaches and practices. Trans-AI/DS feature their transformative (or transformational), transdisciplinary , and translational AI/DS in terms of thinking, paradigms, methodologies, technologies, engineering, and practices. Here, we discuss these important paradigm shifts and directions. Trans-AI/DS encourage big and outside-the-box thinking beyond the classic AI, data-driven, model-based, statistical, shallow and deep learning hypotheses, methodologies and developments. They pursue foundational and original AI/DS thinking, theories and practices from the essence of intelligences and complexities inherent in humans, nature, society, and their creations.",not included,2331,0.817526937
10.1007/s00146-022-01430-1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/1/2024 0:00,springer,an ai ethics ‘david and goliath’: value conflicts between large tech companies and their employees,http://dx.doi.org/10.1007/s00146-022-01430-1,"Artificial intelligence ethics requires a united approach from policymakers, AI companies, and individuals, in the development, deployment, and use of these technologies. However, sometimes discussions can become fragmented because of the different levels of governance (Schmitt in AI Ethics 1–12, 2021) or because of different values, stakeholders, and actors involved (Ryan and Stahl in J Inf Commun Ethics Soc 19:61–86, 2021). Recently, these conflicts became very visible, with such examples as the dismissal of AI ethics researcher Dr. Timnit Gebru from Google and the resignation of whistle-blower Frances Haugen from Facebook. Underpinning each debacle was a conflict between the organisation’s economic and business interests and the morals of their employees. This paper will examine tensions between the ethics of AI organisations and the values of their employees, by providing an exploration of the AI ethics literature in this area, and a qualitative analysis of three workshops with AI developers and practitioners. Common ethical and social tensions (such as power asymmetries, mistrust, societal risks, harms, and lack of transparency) will be discussed, along with proposals on how to avoid or reduce these conflicts in practice (e.g., building trust, fair allocation of responsibility, protecting employees’ autonomy, and encouraging ethical training and practice). Altogether, we suggest the following steps to help reduce ethical issues within AI organisations: improved and diverse ethics education and training within businesses; internal and external ethics auditing; the establishment of AI ethics ombudsmen, AI ethics review committees and an AI ethics watchdog; as well as access to trustworthy AI ethics whistle-blower organisations.",not included,1027,0.81704098
10.1007/s41463-021-00118-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Humanistic Management Journal,Springer,12/1/2021 0:00,springer,master and slave: the dialectic of human-artificial intelligence engagement,http://dx.doi.org/10.1007/s41463-021-00118-w,"The massive introduction of artificial intelligence (AI) has triggered significant societal concerns, ranging from “technological unemployment” and the dominance of algorithms in the work place and in everyday life, among others. While AI is made by humans and is, therefore, dependent on the latter for its purpose, the increasing capabilities of AI to carry out productive activities for humans can lead the latter to unwitting slavish existence. This has become evident, for example, in the area of social media use, where AI programmers tie psychology and persuasion to the human social need for approval and validation in ways that few users can resist. We argue that AI should serve humans with humans as masters and not the other way around. Moreover, we propose that virtue ethics might play a role to solidify the human as master of AI and guard against the alternative of AI as the master.",not included,3378,0.816757441
10.1177/0952076718780537,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Policy and Administration,1/1/2018 0:00,semantic_scholar,"big data and ai – a transformational shift for government: so, what next for research?",https://www.semanticscholar.org/paper/2eedf3d19edacc862bf7ab324a74172bb35a14e1,"Big Data and artificial intelligence will have a profound transformational impact on governments around the world. Thus, it is important for scholars to provide a useful analysis on the topic to public managers and policymakers. This study offers an in-depth review of the Policy and Administration literature on the role of Big Data and advanced analytics in the public sector. It provides an overview of the key themes in the research field, namely the application and benefits of Big Data throughout the policy process, and challenges to its adoption and the resulting implications for the public sector. It is argued that research on the subject is still nascent and more should be done to ensure that the theory adds real value to practitioners. A critical assessment of the strengths and limitations of the existing literature is developed, and a future research agenda to address these gaps and enrich our understanding of the topic is proposed.",not included,7,0.816611052
10.1057/s41599-024-02905-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Humanities and Social Sciences Communications,Nature,3/11/2024 0:00,springer,artificial intelligence and the future of the internal audit function,http://dx.doi.org/10.1057/s41599-024-02905-w,"Artificial intelligence (AI) can support the company’s internal audit function (IAF) by delivering substantial strategic oversight, minimizing manual procedures, and making possible additional value-added auditing service. Currently, there are research gaps in the literature, such as limited studies on the topic, low AI adoption rates in the IAF across different countries and regions, and a shortage of comprehensive frameworks for effectively using AI in the IAF. Hence, this review work aims to fill the research gap by offering an outline of research avenues on the topic in the literature and suggesting a new compressive framework for the effective use of AI in the IAF. This paper undertakes a systematic literature review (SLR) approach and aspires to highlight the state of research on the use of AI in the IAF, to deliver insight for scholars and industry experts on the issue, and to reveal the implications for IAF of the new AI technology. Moreover, to quickly make artificial intelligence work in internal audit functions, the CACS framework was recommended with attributes such as commitment, access, capability, and skills development (CACS). This work provides significant contributions for guiding future research directions and the development of theoretical foundations for the IAF field. On a practical level, the work will help internal auditors to assess and understand the potential advantages and risks of implementing AI in their organization’s IAF. For regulators, this review should prove useful for updating regulations on internal auditing in the context of using advanced technology such as AI and for ensuring the compliance of internal auditing practices to the evolving technology. Organizations can also benefit from this review to decide whether AI investments in their IAF are justified. This review made an initial extensive SLR on AI use in the IAF as a basis for developing new research avenues in auditing and accounting.",not included,1121,0.815963686
10.1007/s00146-022-01436-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,6/1/2023 0:00,springer,tensions in transparent urban ai: designing a smart electric vehicle charge point,http://dx.doi.org/10.1007/s00146-022-01436-9,"The increasing use of artificial intelligence (AI) by public actors has led to a push for more transparency. Previous research has conceptualized AI transparency as knowledge that empowers citizens and experts to make informed choices about the use and governance of AI. Conversely, in this paper, we critically examine if transparency-as-knowledge is an appropriate concept for a public realm where private interests intersect with democratic concerns. We conduct a practice-based design research study in which we prototype and evaluate a transparent smart electric vehicle charge point, and investigate experts’ and citizens’ understanding of AI transparency. We find that citizens experience transparency as burdensome; experts hope transparency ensures acceptance, while citizens are mostly indifferent to AI; and with absent means of control, citizens question transparency’s relevance. The tensions we identify suggest transparency cannot be reduced to a product feature, but should be seen as a mediator of debate between experts and citizens.",included,2061,0.815876245
10.1007/s00146-024-02011-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,7/16/2024 0:00,springer,dreaming of ai: environmental sustainability and the promise of participation,http://dx.doi.org/10.1007/s00146-024-02011-0,"There is widespread consensus among policymakers that climate change and digitalisation constitute the most pressing global transformations shaping human life in the 21st century. Seeking to address the challenges arising at this juncture, governments, technologists and scientists alike increasingly herald artificial intelligence (AI) as a vehicle to propel climate change mitigation and adaptation. In this paper, we explore the intersection of digitalisation and climate change by examining the deployment of AI in government-led climate action. Building on participant observations conducted in the context of the “Civic Tech Lab for Green”—a government-funded public interest AI initiative—and eight expert interviews, we investigate how AI shapes the negotiation of environmental sustainability as an issue of public interest. Challenging the prescribed means–end relationship between AI and environmental protection, we argue that the unquestioned investment in AI curtails political imagination and displaces discussion of climate “problems” and possible “solutions” with “technology education”. This line of argumentation is rooted in empirical findings that illuminate three key tensions in current coproduction efforts: “AI talk vs. AI walk”, “civics washing vs. civics involvement” and “public invitation vs. public participation”. Emphasising the importance of re-exploring the innovative state in climate governance, this paper extends academic literature in science and technology studies that examines public participation in climate change adaptation by shedding light on the emergent phenomenon of public interest AI.",not included,571,0.815816224
10.1007/s00146-024-02027-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,8/14/2024 0:00,springer,“game changer”: the ai advocacy discourse of 2023 in the us,http://dx.doi.org/10.1007/s00146-024-02027-6,"In 2023, artificial intelligence was announced as a “game changer”—marking a rapid revolution in thinking technologies. A global debate began to emerge. By conducting a discourse analysis of 2023 US congressional testimonies and AI manifestos, we aim to map the emergence of debates over the start-up of a global governance controversy. Qualitative topical identification and semantic network analysis are deployed to identify the primary stakeholders and their contesting arguments. The resulting polylog exhibits sharp divisions among multiple, distinct pro-tech and pro-rights groups. Pro-tech stakeholders emphasize innovation and economic benefits, while pro-rights groups prioritize human rights and safety. Our linguistic and semantic network analyses provide micro-level insights into the polylogue entanglements of ethics and governance. The analysis of US AI advocacy discourse furnishes a baseline of contestation from which the ongoing development of the complex arguments of AI policies can be identified and evaluated.",not included,440,0.81581378
10.35940/ijeat.a4282.1013123,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Journal of Engineering and Advanced Technology,1/1/2000 0:00,semantic_scholar,transforming organizational development with ai: navigating change and innovation for success,https://www.semanticscholar.org/paper/51791a95c6ba077072018ce8c0d294102953cc6a,"Effective change management emerges as a deciding element for an organization's survival and success in the changing terrain of today's fiercely competitive business climate. The variety of change management theories and approaches that are currently available, however, paints a complicated picture that is plagued by inconsistencies, a lack of strong empirical support, and unproven assumptions about contemporary organizational dynamics. This essay seeks to set the basis for a fresh paradigm for effective change administration by critically analyzing popular change management ideas. The gap between theory and practice is addressed in the paper, which concludes with suggestions for more research. In parallel, artificial intelligence (AI) has made incredible progress, giving rise to computers that mimic human autonomy and cognition. Industry-wide excitement has been sparked by the enthusiasm among academics, executives, and the general public, which has resulted in significant investments in utilizing AI's potential through creative business models. However, the lack of thorough academic guidance forces managers to struggle with AI integration issues, increasing the risk of project failure. An in-depth analysis of AI's complexities and its function as a spark for revolutionary business model innovation is provided in this article. A thorough literature assessment, which involves sifting through a sizable library of published works, combines up-to-date information on how AI is affecting the development of new business models. The findings come together to form a roadmap for seamless AI integration that includes four steps: understanding the fundamentals of AI and the skills needed for digital transformation, understanding current business models and their innovation potential, nurturing key proficiencies for AI assimilation, and gaining organizational acceptance while developing internal competencies. This article combines the fields of organizational change management and AI-driven business model innovation with ease, providing a thorough explanation to assist businesses in undergoing a successful transformation and innovation. These disciplines' confluence offers a practical vantage point for successfully adapting to, thriving in, and profiting within a dynamic business environment. Artificial intelligence (AI), a massively disruptive force that is altering international businesses, is at the vanguard of this revolution. The ability of AI to make decisions automatically, based on data analysis and observation, opens up hitherto untapped possibilities for value creation and competitive dominance, with broad consequences spanning several industries. With its quick scaling, ongoing improvement, and self-learning capabilities, this evolutionary invention functions as an agile capital-labor hybrid. Significantly, AI's architecture serves as the cornerstone for data-driven decision support by deftly sifting through large and complicated datasets to extract insights. Thus, the symbiotic marriage of organizational change management and AI-driven business model innovation gives a thorough narrative, directing businesses towards not just surviving, but thriving in an ever-evolving business environment. It is underlined how business models (BMs) interact with technology to affect how well business’s function, underlining the need of taking BMs into account while using AI. Business model innovation (BMI) that AI unlocks may improve goods, streamline processes, and save costs. However, there is a void between technological improvements and their operationalization via BMs. Successful AI integration depends on a well-structured BM, which promotes agility and makes the most of technological resources. BMI is accelerated by AI, which reshapes sectors via innovation. Although interest in AI is high, strategic, cultural, and technological constraints sometimes prevent large investments from producing positive economic results. To fully utilize AI's capabilities, structured BMs are required. Despite an increase in research, there is still little cohesive information about the business uses of AI. In an effort to close this gap, we examine implementation-related AI problems. Analyzing AI-driven BM transformation and risk management is aided by a study on BMI and digital transformation at the same time. The purpose of this study is to further our understanding of AI-driven business model innovation and to provide a useful framework to help practitioners navigate the potential and difficulties of AI implementation. The suggested roadmap aims to identify current knowledge gaps and future research initiatives.",included,78,0.815545619
10.1007/s13347-021-00482-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,12/1/2021 0:00,springer,ethical principles for artificial intelligence in national defence,http://dx.doi.org/10.1007/s13347-021-00482-3,"Defence agencies across the globe identify artificial intelligence (AI) as a key technology to maintain an edge over adversaries. As a result, efforts to develop or acquire AI capabilities for defence are growing on a global scale. Unfortunately, they remain unmatched by efforts to define ethical frameworks to guide the use of AI in the defence domain. This article provides one such framework. It identifies five principles—justified and overridable uses, just and transparent systems and processes, human moral responsibility, meaningful human control and reliable AI systems—and related recommendations to foster ethically sound uses of AI for national defence purposes.",included,3380,0.815341711
10.1108/jstpm-07-2023-0123,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Science and Technology Policy Management,1/1/2000 0:00,semantic_scholar,"public service delivery, artificial intelligence and the sustainable development goals: trends, evidence and complexities",https://www.semanticscholar.org/paper/d9db3888acd27f028730672c6b8d4bef12bfe207,"Purpose
Recent technological developments have encouraged the United Nations to promote the adoption of digital technologies to achieve the Sustainable Development Goals (SDGs). In addition to initiatives from businesses, an increasing number of studies indicate that public service agencies may gain benefits from adopting digital transformation. On a global scale, policymakers are examining the integration of digital technologies, specifically artificial intelligence (AI), into public service delivery (PSD), acknowledging the potential advantages and obstacles for the public sector. Therefore, the objective of this study is to investigate the impact of AI on PSD to support the SDGs initiative.

Design/methodology/approach
The research used a qualitative approach to explore the intersection of AI, SDGs and PSD. This approach involved scrutinising relevant publications and conducting an extensive literature review. The research also used bibliographic analysis to discern patterns within the field. Findings from the literature review and bibliographic analysis contributed to identifying research trends that explore the complex relationship among AI, PSD and the SDGs. The model derived from this comprehensive review and analysis elucidates the potential of AI to enhance PSD and contribute to the achievement of the SDGs.

Findings
The bibliographic study revealed significant research trends concerning AI, PSD and SDGs through an empirical investigation of an extensive array of peer-reviewed articles. This investigation focused on how the public sector can improve its delivery of services to citizens and all stakeholders to advance the SDGs. AI holds the promise of revolutionising PSD and bolstering the SDGs. By leveraging AI’s capabilities in data analysis, automation and customisation, governments can enhance the efficiency, effectiveness and accessibility of public services. This, in turn, enables public servants to tackle more complex tasks while providing citizens with personalised and relevant experiences. Additionally, the study advocates modelling the intersection of PSD and AI to achieve sustainable development.

Research limitations/implications
The employed research methodologies, such as literature reviews and bibliographic analysis, enrich the context of AI, SDGs and PSD. They offer a comprehensive perspective, identify knowledge gaps and furnish policymakers, practitioners and academics with a conceptual framework for informed decision-making and sustainable development endeavours.

Originality/value
The study provides an agenda for AI and SDGs research on application in PSD. It emphasises varied research viewpoints, methods and gaps. This study helps researchers as well as practitioners identify subtopics, intersecting themes and new research pathways.
",not included,116,0.814947486
10.1186/s13690-022-00898-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Archives of Public Health,BioMed Central,5/18/2022 0:00,springer,evidence based policy making during times of uncertainty through the lens of future policy makers: four recommendations to harmonise and guide health policy making in the future,http://dx.doi.org/10.1186/s13690-022-00898-z,"The Covid-19 pandemic has not only outlined the importance of using evidence in the healthcare policy making process but also the complexity that exists between policymakers and the scientific community. As a matter of fact, scientific data is just one of many other concurrent factors, including economic, social and cultural, that may provide the rationale for policy making. The pandemic has also raised citizens’ awareness and represented an unprecedented moment of willingness to access and understand the evidence underpinning health policies. This commentary provides policy recommendations to improve evidence-based policy making in health, through the lens of a young generation of public policy students and future policymakers, enrolled in a 24-hour course at Sciences Po Paris entitled “Evidence-based policy-making in health: theory and practice(s)”. Four out of 11 recommendations were prioritised and presented in this commentary which target both policymakers and the scientific community to make better use of evidence-based policy making in health. First, policy makers and scientists should build trusting partnerships with citizens and engage them, especially those facing our target health care issues or systems. Second, while artificial intelligence raises new opportunities in healthcare, its use in contexts of uncertainty should be addressed by policymakers in terms of liability and ethics. Third, conflicts of interest must be disclosed as much as possible and effectively managed to (re) build a trust relationship between policymakers, the scientific community and citizens, implying the need for risk management tools and cross border disclosure mechanisms. Last, well-designed and secure health information systems need to be implemented, following the FAIR (findable, accessible, interoperable and reusable) principles for health data. This will take us a step further from data to ‘policy wisdom’. Overall, these recommendations identified and formulated by students highlight some key issues that need to be rethought in the health policy cycle through elements like institutional incentives, cultural changes and dialogue between policy makers and the scientific community. This input from a younger generation of students highlights the importance of making the conversation on evidence-based policy making in health accessible to all generations and backgrounds.",not included,3068,0.814761996
10.1007/s43681-022-00218-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,11/1/2023 0:00,springer,"ethics and diversity in artificial intelligence policies, strategies and initiatives",http://dx.doi.org/10.1007/s43681-022-00218-9,"A burgeoning of Artificial Intelligence (AI) technologies in recent years has led to increased discussion about its potential to address many issues considered otherwise intractable, including those highlighted by the United Nations 2030 Agenda for Sustainable Development and associated Sustainable Development Goals. In tandem with this growth in AI is an expanding body of documentation regarding how such advanced technologies should be governed and managed. Issued by a variety of sources and comprising frameworks, policies and guidelines, this body of work encompasses the legal, social, ethical and policy issues around AI. With at least 470 such documents identified, as of May 2021, in the Council of Europe’s tracker of AI initiatives, questions are emerging around the diversity of views expressed, especially regarding the influence of the Global North or Euro-American perspectives. Our previous analysis of a corpus of largely grey literature discovered blind spots regarding both gender representation and perspectives from the Global South. Expanding on that work, this paper examines a significantly extended corpus, with a focus on the role of underrepresented groups in the wider AI discourse. We find that voices from the Global South and consideration of alternative ethical approaches are largely absent from the conversation. In light of the prominence of social, cultural and ethical perspectives from the Global North, this paper explores implications for the development of standards for ethical AI. Concluding by offering approaches to incorporate more diverse ethical viewpoints and beliefs, we call for increased consideration of power structures when developing AI ethics policies and standards within these alternative socio-cultural and socio-economic contexts.",not included,1616,0.813974023
10.1016/j.jsis.2024.101848,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85198122860,scopus,9/1/2024,scopus,fusing domain knowledge with machine learning: a public sector perspective,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85198122860&origin=inward,"Machine learning (ML) offers widely-recognized, but complex, opportunities for both public and private sector organizations to generate value from data. A key requirement is that organizations must find ways to develop new knowledge by merging crucial ‘domain knowledge’ of experts in relevant fields with ‘machine knowledge’, i.e., data that can be used to inform predictive models. In this paper, we argue that understanding the process of generating such knowledge is essential to strategically develop ML. In efforts to contribute to such understanding, we examine the generation of new knowledge from domain knowledge through ML via an exploratory study of two cases in the Swedish public sector. The findings reveal the roles of three mechanisms – dubbed consolidation, algorithmic mediation, and naturalization – in tying domain knowledge to machine knowledge. The study contributes a theory of knowledge production related to organizational use of ML, with important implications for its strategic governance, particularly in the public sector.",not included,8491,0.813747287
10.1038/s41558-022-01377-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Nature Climate Change,Nature,6/1/2022 0:00,springer,aligning artificial intelligence with climate change mitigation,http://dx.doi.org/10.1038/s41558-022-01377-7,"There is great interest in how the growth of artificial intelligence and machine learning may affect global GHG emissions. However, such emissions impacts remain uncertain, owing in part to the diverse mechanisms through which they occur, posing difficulties for measurement and forecasting. Here we introduce a systematic framework for describing the effects of machine learning (ML) on GHG emissions, encompassing three categories: computing-related impacts, immediate impacts of applying ML and system-level impacts. Using this framework, we identify priorities for impact assessment and scenario analysis, and suggest policy levers for better understanding and shaping the effects of ML on climate change mitigation. The rapid growth of artificial intelligence (AI) is reshaping our society in many ways, and climate change is no exception. This Perspective presents a framework to assess how AI affects GHG emissions and proposes approaches to align the technology with climate change mitigation.",included,2987,0.813744664
10.1108/jices-12-2022-0108,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Journal of Information, Communication and Ethics in Society",1/1/2000 0:00,semantic_scholar,from big data epistemology to ai politics: rescuing the public dimension over data-driven technologies,https://www.semanticscholar.org/paper/df57622f13676a4a8185df9424bea75243d8fc9e,"
Purpose
The purpose of this paper is to explore the epistemological tensions embedded within big data and data-driven technologies to advance a socio-political reconsideration of the public dimension in the assessment of their implementation.


Design/methodology/approach
This paper builds upon (and revisits) the European Union’s (EU) normative understanding of artificial intelligence (AI) and data-driven technologies, blending reflections rooted in philosophy of technology with issues of democratic participation in tech-related matters.


Findings
This paper proposes the conceptual design of sectorial and/or local-level e-participation platforms to ignite an ongoing discussion – involving experts, private actors, as well as cognizant citizens – over the implementation of data-driven technologies, to avoid siloed, tech-solutionist decisions.


Originality/value
This paper inscribes the EU’s normative approach to AI and data-driven technologies, as well as critical work on the governance of these technologies, into a broader political dimension, suggesting a way to democratically and epistocratically opening up the decisional processes over the development and implementation of these technologies and turn such processes into a systemic civic involvement.
",not included,67,0.813432932
10.1007/s10676-021-09619-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Ethics and Information Technology,Springer,12/1/2021 0:00,springer,the ethical use of artificial intelligence in human resource management: a decision-making framework,http://dx.doi.org/10.1007/s10676-021-09619-6,"Artificial intelligence (AI) is increasingly inputting into various human resource management (HRM) functions, such as sourcing job applicants and selecting staff, allocating work, and offering personalized career coaching. While the use of AI for such tasks can offer many benefits, evidence suggests that without careful and deliberate implementation its use also has the potential to generate significant harms. This raises several ethical concerns regarding the appropriateness of AI deployment to domains such as HRM, which directly deal with managing sometimes sensitive aspects of individuals’ employment lifecycles. However, research at the intersection of HRM and technology continues to largely center on examining what AI can be used for, rather than focusing on the salient factors relevant to its ethical use and examining how to effectively engage human workers in its use. Conversely, the ethical AI literature offers excellent guiding principles for AI implementation broadly, but there remains much scope to explore how these principles can be enacted in specific contexts-of-use. By drawing on ethical AI and task-technology fit literature, this paper constructs a decision-making framework to support the ethical deployment of AI for HRM and guide determinations of the optimal mix of human and machine involvement for different HRM tasks. Doing so supports the deployment of AI for the betterment of work and workers and generates both scholarly and practical outcomes.",included,3379,0.813193977
10.1007/s13347-024-00710-6,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,3/13/2024 0:00,springer,from ai ethics principles to practices: a teleological methodology to apply ai ethics principles in the defence domain,http://dx.doi.org/10.1007/s13347-024-00710-6,"This article provides a methodology for the interpretation of AI ethics principles to specify ethical criteria for the development and deployment of AI systems in high-risk domains. The methodology consists of a three-step process deployed by an independent, multi-stakeholder ethics board to: (1) identify the appropriate level of abstraction for modelling the AI lifecycle; (2) interpret prescribed principles to extract specific requirements to be met at each step of the AI lifecycle; and (3) define the criteria to inform purpose- and context-specific balancing of the principles. The methodology presented in this article is designed to be agile, adaptable, and replicable, and when used as part of a pro-ethical institutional culture, will help to foster the ethical design, development, and deployment of AI systems. The application of the methodology is illustrated through reference to the UK Ministry of Defence AI ethics principles.",included,1117,0.81242311
10.1007/s00146-024-01882-7,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,3/7/2024 0:00,springer,"trust, artificial intelligence and software practitioners: an interdisciplinary agenda",http://dx.doi.org/10.1007/s00146-024-01882-7,"Trust and trustworthiness are central concepts in contemporary discussions about the ethics of and qualities associated with artificial intelligence (AI) and the relationships between people, organisations and AI. In this article we develop an interdisciplinary approach, using socio-technical software engineering and design anthropological approaches, to investigate how trust and trustworthiness concepts are articulated and performed by AI software practitioners. We examine how trust and trustworthiness are defined in relation to AI across these disciplines, and investigate how AI, trust and trustworthiness are conceptualised and experienced through an ethnographic study of the work practices of nine practitioners in the software industry. We present key implications of our findings for the generation of trust and trustworthiness and for the training and education of future software practitioners.",not included,1127,0.812235594
10.3897/jucs.94155,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of universal computer science (Online),1/1/2022 0:00,semantic_scholar,ai empowered big data analytics for industrial applications,https://www.semanticscholar.org/paper/fbf4872593d24a7d5f24e98f662ab85962a2f2d7,"We proposed the idea of editing a special issue that would compile the fruitful research that resulted from the stimulating discussions that occurred during the workshop that was held during the 5th International Conference on Intelligent Computing, Chennai on 25th & 26th March 2022. The objective of this special issue is to call for high-quality papers covering the latest data analytic concepts and technologies of big data and artificial intelligence. This special issue serves as a forum for researchers across the globe to discuss their work and recent advances in this field. The best papers from Artificial intelligence and Big Data Analytics (BAM) in the domains of Product, Finance, Health, and Environment were invited, peer-reviewed. The best high-quality papers were selected based on the innovativeness and relevance of the theme. The amount of data being generated and stored in various fields such as education, energy, environment, healthcare, fraud detection, and traffic is increasing exponentially in the modern era of Big Data. Simultaneously, there is a significant paradigm shift in business and society worldwide due to rapid advancements in fields such as artificial intelligence, machine learning, deep learning, and data analytics. This creates significant challenges for decision-making and the potential for transformation in areas such as the economy, government, and industry. Artificial Intelligence tools, techniques, and technologies, in conjunction with Big Data, improve the predictive power of the systems created and allow the government, public, and private sectors to discover new patterns and trends, as well as improve public values such as accountability, safety, security, and transparency to enable better decision-making, policies, and governance. They also have a wide range of capabilities to perform complex tasks that humans cannot. They could be used to collect, organize, and analyze large, diverse data sets to discover patterns and trends that address a variety of problems related to the development of the economy, such as identifying new sources of revenue, expanding the customer base for business, product reviews, and promotion, disease prediction and prevention, climatic variation prediction, and the provision of energy solutions. The wide variety of subject areas discussed at the 5th International Conference on Intelligent Computing is reflected in the seven accepted papers presented in the following section.",not included,35,0.811912775
10.53116/pgaflr.7068,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Governance Administration and Finances Law Review,1/1/2000 0:00,semantic_scholar,e-government in nigeria: can generative ai serve as a tool for civic engagement?,https://www.semanticscholar.org/paper/a854b495502cf6b6f627bf9ebdc5e8f357272e98,"This paper examines the potential for using generative artificial intelligence (AI) to boost civic participation in Nigeria’s developing e-government ecosystem. Emerging generative technologies like ChatGPT demonstrate intriguing capabilities to make governance more interactive and engaging through conversational interfaces. Thoughtfully implemented AI tools could increase access and understanding of e-government, particularly for underserved groups. However, risks around bias, privacy, security and capability limitations pose challenges for public sector applications. Additionally, Nigeria’s substantial digital divides and defective trust in government institutions hamper e-government participation currently. This paper analyses opportunities and limitations for applying generative AI to advance civic engagement given Nigeria’s unique socio-cultural context. Findings suggest that while AI holds promise, targeted strategies focused on inclusion, accessibility, education and institutional legitimacy building are critical to realise benefits. Cautious optimism, human-centric design and responsible governance frameworks are needed to employ generative systems successfully. If challenges are addressed, AI could open innovative possibilities for energising civic participation. But further research and controlled pilot applications are required to determine optimal implementation.",not included,100,0.811304927
10.1007/s43681-023-00309-1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,6/20/2023 0:00,springer,embedded ethics for responsible artificial intelligence systems (ee-rais) in disaster management: a conceptual model and its deployment,http://dx.doi.org/10.1007/s43681-023-00309-1,"In this paper, we argue that Responsible Artificial Intelligence Systems (RAIS) require a shift toward embedded ethics to address value-based challenges facing AI in disaster management; and we propose a model to achieve it. Disaster management requires Artificial Intelligence Systems (AIS) that would be sensitive to ethical, legal, and multi-dimensional values while being responsive and accountable in complex and acute disruptions that simultaneously call for fair, value-laden, and immediate decisions. Without such a necessary shift, AIS will be incapable of responding properly to major value-based challenges of axiological and hierarchical types, and might leave AIS vulnerable to meta-disasters, such as intelligent digital disasters. This study focuses on RAI in the context of disaster management and proposes a model of Embedded Ethics for Responsible Artificial Intelligence Systems (EE-RAIS), which is empowered by four platforms of embedded ethics—educational, cross-functional, developmental, and algorithmic embedded ethics—as well as four imperative metrics—ethical intelligence, legal intelligence, social-emotional competency, and artificial wisdom. The final section of the paper explores how EE-RAIS can be deployed for the purpose of disaster management and fair crisis informatics.",included,2026,0.811082423
10.1007/s12115-019-00358-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Society,Springer,6/15/2019 0:00,springer,"society caught in a labyrinth of algorithms: disputes, promises, and limitations of the new order of things",http://dx.doi.org/10.1007/s12115-019-00358-5,"We are in the interim of the massive expansion of the new and fundamental technology, which is represented by the advanced algorithms of AI. No one knows the real potential of machine learning and AI. Letting the algorithms drive autonomous vehicles (driverless cars) is like running the Boston Marathon. Creating an ethically completely autonomous AI system is like a piloted flight to Alpha Centauri. Nevertheless, we still live in the world of algorithms. Today there are algorithms in every corner of civilization, as quantum fluctuations they are integrally interwoven into the structure of everyday life. They are not just in your mobile phone or laptop. Algorithms plan flights and then fly with planes. Algorithms run factories, the bank is a vast array of algorithms, evaluating our credit score, algorithms collect revenue and keep records, read medical images, diagnose cancer, drive cars, write scientific texts, compose music, conduct symphony orchestras, navigate drones, speak to us and for us, write film scenarios, invent chemical formulations for a new cosmetic cream, order, advise, paint pictures. Climate models decide what is a safe carbon dioxide level in the atmosphere, NSA algorithms decide whether you are a potential terrorist. If every algorithm suddenly stopped working, it would be the end of the world as we know it. How did this new alliance, this interim world come into existence, does it suit us, and how and where will it develop? What AI algorithms have shown and offered to us so far is just a prelude, and even today it turns out that politics, ethics and law do not know what to do with the consequences of these changes. However, when we experience computer control by a mere idea, complex genetic modifications, and DNA enhancement using CRISPR, or perhaps flying cars, we can expect real challenges related to the power of algorithms. Then AI ​​algorithms will really transform everything. The study analyzes the social contradictions, promises and limitations associated with how the desire to move higher on technological prominence in the realm of artificial intelligence faces the ethical, legal and political barriers of the existing order of things.",not included,4900,0.811069727
10.1109/meco62516.2024.10577936,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Mediterranean Conference on Embedded Computing,1/1/2000 0:00,semantic_scholar,"opportunities of gen ai in the banking industry with regards to the ai act, gdpr, data act and dora",https://www.semanticscholar.org/paper/a738d0916ccf3b8970dabe488a3de88f6d2dd4af,"Generative Artificial Intelligence (Gen AI) stands at the forefront of the banking sector's technological revolution, promising enhancements in decision-making, risk management, and customer interaction. This paper examines Gen AI's potential to inject innovation and efficiency into banking services, with an estimated value addition of up to $340 billion annually. Grounded in advancements in NLP through Transformer architecture and evolving GPT models, Gen AI's applications in the banking industry are extensive. They range from personalizing customer service with AI-driven chatbots to revolutionizing credit scoring and trading strategies. However, alongside these opportunities, the paper addresses the significant challenges of regulatory compliance, ethical data usage, and the technical integration of AI systems. With the impending release of the EU's AI Act and existing GDPR and DORA, financial institutions must strategize to align with new standards while harnessing Gen AI's capabilities for process optimization and enhanced service delivery. The role of international standards such as ISO/IEC 42001:2023, ISO 31000:2018, ISO/IEC 23894:2023, NIST AI 600-1 and ISO/IEC 23053:2022 is considered to be beneficial in establishing a common framework for managing AI systems, ensuring data integrity and promoting transparency. By adopting these standards, banks can facilitate compliance across various jurisdictions, enhancing operational consistency and reliability – but certain significant limitations in addressing specific regulatory requirements must be taken into account. The paper concludes that Gen AI's future in banking will be transformative, driven by the industry's need to balance technological innovation with ethical and regulatory requirements and process standardization, which will lead to more transparent, personalized and efficient banking services.",not included,132,0.810729027
10.1140/epjst/e2012-01703-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',The European Physical Journal Special Topics,Springer,11/1/2012 0:00,springer,smart cities of the future,http://dx.doi.org/10.1140/epjst/e2012-01703-3,"Abstract Here we sketch the rudiments of what constitutes a smart city which we define as a city in which ICT is merged with traditional infrastructures, coordinated and integrated using new digital technologies. We first sketch our vision defining seven goals which concern: developing a new understanding of urban problems; effective and feasible ways to coordinate urban technologies; models and methods for using urban data across spatial and temporal scales; developing new technologies for communication and dissemination; developing new forms of urban governance and organisation; defining critical problems relating to cities, transport, and energy; and identifying risk, uncertainty, and hazards in the smart city. To this, we add six research challenges: to relate the infrastructure of smart cities to their operational functioning and planning through management, control and optimisation; to explore the notion of the city as a laboratory for innovation; to provide portfolios of urban simulation which inform future designs; to develop technologies that ensure equity, fairness and realise a better quality of city life; to develop technologies that ensure informed participation and create shared knowledge for democratic city governance; and to ensure greater and more effective mobility and access to opportunities for urban populations. We begin by defining the state of the art, explaining the science of smart cities. We define six scenarios based on new cities badging themselves as smart, older cities regenerating themselves as smart, the development of science parks, tech cities, and technopoles focused on high technologies, the development of urban services using contemporary ICT, the use of ICT to develop new urban intelligence functions, and the development of online and mobile forms of participation. Seven project areas are then proposed: Integrated Databases for the Smart City, Sensing, Networking and the Impact of New Social Media, Modelling Network Performance, Mobility and Travel Behaviour, Modelling Urban Land Use, Transport and Economic Interactions, Modelling Urban Transactional Activities in Labour and Housing Markets, Decision Support as Urban Intelligence, Participatory Governance and Planning Structures for the Smart City. Finally we anticipate the paradigm shifts that will occur in this research and define a series of key demonstrators which we believe are important to progressing a science of smart cities. Graphical abstract ",not included,6999,0.8105762
10.1177/08944393241235175,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Social science computer review,1/1/2000 0:00,semantic_scholar,"artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization",https://www.semanticscholar.org/paper/9679559aa9ed7c017dcf33f6e07021a83c83b1ce,"In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, that is, the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards AI systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby AI systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that AI-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens’ sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that AI systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means – it cannot dictate the ends. Nonetheless, the use of AI in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, AI-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.",included,104,0.810432315
10.1007/s43681-023-00327-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/30/2023 0:00,springer,when things go wrong: the recall of ai systems as a last resort for ethical and lawful ai,http://dx.doi.org/10.1007/s43681-023-00327-z,"This paper presents an initial exploration of the concept of AI system recall, primarily understood as a last resort when AI systems violate ethical norms, societal expectations, or legal obligations. The discussion is spurred by recent incidents involving notable AI systems, demonstrating that AI recalls can be a very real necessity. This study delves into the concept of product recall as traditionally understood in industry and explores its potential application to AI systems. Our analysis of this concept is centered around two prominent categories of recall drivers in the AI domain: ethical-social and legal considerations. In terms of ethical-social drivers, we apply the innovative notion of “moral Operational Design Domain”, suggesting AI systems should be recalled when they violate ethical principles and societal expectation. In addition, we also explore the recall of AI systems from a legal perspective, where the recently proposed AI Act provides regulatory measures for recalling AI systems that pose risks to health, safety, and fundamental rights. The paper also underscores the need for further research, especially around defining precise ethical and societal triggers for AI recalls, creating an efficient recall management framework for organizations, and reassessing the fit of traditional product recall models for AI systems within the AI Act's regulatory context. By probing these complex intersections between AI, ethics, and regulation, this work aims to contribute to the development of robust and responsible AI systems while maintaining readiness for failure scenarios.",included,1863,0.810389757
10.1371/journal.pone.0295277,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,PLoS ONE,1/1/2000 0:00,semantic_scholar,population preferences for ai system features across eight different decision-making contexts,https://www.semanticscholar.org/paper/c644063a31a9377b069e5f8568db83e24e4f35ff,"Artificial intelligence systems based on deep learning architectures are being investigated as decision-support systems for human decision-makers across a wide range of decision-making contexts. It is known from the literature on AI in medicine that patients and the public hold relatively strong preferences in relation to desirable features of AI systems and their implementation, e.g. in relation to explainability and accuracy, and in relation to the role of the human decision-maker in the decision chain. The features that are preferred can be seen as ‘protective’ of the patient’s interests. These types of preferences may plausibly vary across decision-making contexts, but the research on this question has so far been almost exclusively performed in relation to medical AI. In this cross-sectional survey study we investigate the preferences of the adult Danish population for five specific protective features of AI systems and implementation across a range of eight different use cases in the public and commercial sectors ranging from medical diagnostics to the issuance of parking tickets. We find that all five features are seen as important across all eight contexts, but that they are deemed to be slightly less important when the implications of the decision made are less significant to the respondents.",not included,77,0.810261369
10.1016/j.procs.2024.05.101,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85195417875,scopus,1/1/2024,scopus,artificial intelligence as an innovative element of support in policing,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195417875&origin=inward,"Currently, the public security sector is faced with an increasing administrative burden that limits the ability of police officers to focus on core security tasks. This paper focuses on the possibility of using large-scale language models (LSMs) as an innovative tool to address this challenge. Based on a careful literature review and analysis of current trends in artificial intelligence, the author team develops a concept for integrating GPTs into police practice, with an emphasis on the potential for reducing administrative burden and supporting efficient processing of relevant information. As part of this research, we have identified key areas of policing where AI could bring significant value, including data analysis and document production assistance. However, it should be emphasized that this technology is still in its early stages of development and its implementation would require a carefully considered approach involving interdisciplinary collaboration and further research to test the theoretical assumptions presented in this study. Thus, this paper contributes to a deeper understanding of the potential benefits and challenges of integrating GPT into policing practice and outlines a path towards future innovative solutions in the field of public safety.",not included,8533,0.809249699
10.1007/s00146-023-01824-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/20/2023 0:00,springer,the poverty of ethical ai: impact sourcing and ai supply chains,http://dx.doi.org/10.1007/s00146-023-01824-9,"Impact sourcing is the practice of employing socio-economically disadvantaged individuals at business process outsourcing centres to reduce poverty and create secure jobs. One of the pioneers of impact sourcing is Sama, a training-data company that focuses on annotating data for artificial intelligence (AI) systems and claims to support an ethical AI supply chain through its business operations. Drawing on fieldwork undertaken at three of Sama’s East African delivery centres in Kenya and Uganda and follow-up online interviews, this article interrogates Sama’s claims regarding the benefits of its impact sourcing model. Our analysis reveals alarming accounts of low wages, insecure work, a tightly disciplined labour management process, gender-based exploitation and harassment and a system designed to extract value from low-paid workers to produce profits for investors. We argue that competitive market-based dynamics generate a powerful force that pushes such companies towards limiting the actual social impact of their business model in favour of ensuring higher profit margins. This force can be resisted, but only through countervailing measures such as pressure from organised workers, civil society, or regulation. These findings have broad implications related to working conditions for low-wage data annotators across the sector and cast doubt on the ethical nature of AI products that rely on this form of AI data work.",not included,1400,0.808820844
10.1007/s43681-024-00452-3,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,3/18/2024 0:00,springer,the digital divide in action: how experiences of digital technology shape future relationships with artificial intelligence,http://dx.doi.org/10.1007/s43681-024-00452-3,"The digital divide remains an ongoing societal concern, with digital exclusion shown to have a significantly detrimental impact on people’s quality of life. Artificial intelligence (AI), the latest wave of digitalisation, is being integrated into the fabric of society at an accelerated rate, the speed of which has prompted ethical concerns. Without addressing the digital divide, the AI revolution risks exacerbating the existing consequences of digital exclusion and limiting the potential for all people to reap the benefits provided by AI. To understand the factors that might contribute to experiences of AI, and how these might be related to digital exclusion, we surveyed a diverse online community sample ( N  = 303). We created a novel measure of digital confidence capturing individual levels of awareness, familiarity, and sense of competence with digital technology. Results indicated that measures of digital confidence were predicted by structural, behavioural, and psychological differences, such that women, older people, those on lower salaries, people with less digital access, and those with lower digital well-being, reported significantly less digital confidence. Furthermore, digital confidence significantly moderated the relationship between people’s experiences with everyday AI technologies and their general attitudes towards AI. This understanding of the spill-over effects of digital exclusion onto experiences of AI is fundamental to the articulation and delivery of inclusive AI.",not included,1106,0.808438778
10.1080/0312407x.2023.2247833,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Australian Social Work,1/1/2000 0:00,semantic_scholar,artificial intelligence and implications for the australian social work journal,https://www.semanticscholar.org/paper/d4e771b2e4ef85be2edf99fa9c3047e528c2bc18,"Social work is a profession committed to integrity and social justice. The AASW Social Work Practice Standards (AASW, 2023) calls on social workers to be critically reflective, ethical practitioners engaged in lifelong professional development and learning. Equally, social work education seeks to prepare students for research-informed, culturally-responsive practice across a diverse range of contexts, and in this Issue, we showcase critical social work education and practice diversity. However, a different ethical challenge to integrity and practice standards is the focus of this Editorial. Here, we highlight some of the concerns and implications of generative Artificial Intelligence (generative AI) for social work education, research, practice, and scholarly publishing. In November 2022, OpenAI released ChatGPT, a generative AI Large Language Model (LLM) that could generate realistic and natural text outputs from simple prompts. This technology had been in development for some time but had not been released to the public for general use. Since then, there has been a proliferation of different AI models that can generate and augment text, images, video, and audio. Generative AI is being used to perform analytical and interpretive tasks such as language translation; responding to queries on specific data sources, coding, and interpreting code; summarising documents and webpages; and creating case assessments and plans. This technology can be used to construct legal documents; machine learning for facial recognition; and for undertaking medical, mental health, and other diagnostic assessments. These are just some examples. In this fast-moving field, the uses and applications seem endless. The open-sourcing of generative AI models and their underlying architecture means developers are starting to create a myriad of practical applications and tools that rapidly increase the depth and scale of automation, potentially replacing or augmenting many everyday tasks normally performed by humans. The implications for social work education, practice, research, and scholarship are extensive. As with any new technology, there are a range of stances, from early adopters to positions that have resonance with luddism. This adds to the complexities of responding to AI as a whole profession. Nevertheless, what is clear is that the rise and integration of generative AI systems, at scale, will yield a wide range of practical, ethical, and epistemological problems for many professions, including social work. It is to some of these problems we turn our attention below. Beginning with social work education, generative AI will have profound effects on assessment and learning for higher education providers. It is likely to cause educators to re-evaluate their educational practices, assessments, and assumptions about what is core to a social work curriculum. Social work will need to refine and reappraise its ideas about critical thinking, ethical decision making, professional judgement, and reflective practice—all skills that are considered core to effective social work practice as outlined in the AASW Practice Standards (AASW, 2023). How will we ensure students have an educational environment that promotes",not included,60,0.807084084
10.1007/s12652-023-04556-2,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of Ambient Intelligence and Humanized Computing,Springer,11/1/2023 0:00,springer,artificial intelligence and robotics on the frontlines of the pandemic response: the regulatory models for technology adoption and the development of resilient organisations in smart cities,http://dx.doi.org/10.1007/s12652-023-04556-2,"Smart cities do not exist without robotics and Artificial Intelligence (AI). As the case of the COVID-19 pandemic shows, they can assist in combating the novel coronavirus and its effects, and preventing its spread. However, their deployment necessitate the most secure, safe, and efficient use. The purpose of this article is to address the regulatory framework for AI and robotics in the context of developing resilient organisations in smart cities during the COVID-19 pandemic. The study provides regulatory insights necessary to re-examine the strategic management of technology creation, dissemination, and application in smart cities, in order to address the issues regarding the strategic management of innovation policies nationally, regionally, and worldwide. To meet these goals, the article analyses government materials, such as strategies, policies, legislation, reports, and literature. It also juxtaposes materials and case studies, with the help of expert knowledge. The authors emphasise the imminent need for coordinated strategies to regulate AI and robots designed for improving digital and smart public health services globally.",not included,1611,0.807031929
10.1007/s00146-021-01161-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,3/1/2022 0:00,springer,the making of ai society: ai futures frames in german political and media discourses,http://dx.doi.org/10.1007/s00146-021-01161-9,"In this article, we shed light on the emergence, diffusion, and use of socio-technological future visions. The artificial intelligence (AI) future vision of the German federal government is examined and juxtaposed with the respective news media coverage of the German media. By means of a content analysis of frames, it is demonstrated how the German government strategically uses its AI future vision to uphold the status quo. The German media largely adapt the government´s frames and do not integrate alternative future narratives into the public debate. These findings are substantiated in the framing of AI futures in policy documents of the German government and articles of four different German newspapers. It is shown how the German past is mirrored in the German AI future envisioned by the government, safeguarding the present power constellation that is marked by a close unity of politics and industry. The German media partly expose the government´s frames and call for future visions that include fundamentally different political designs less influenced by the power structures of the past and present.",not included,3215,0.806662679
10.1007/s12115-021-00594-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Society,Springer,6/1/2021 0:00,springer,towards an equitable digital society: artificial intelligence (ai) and corporate digital responsibility (cdr),http://dx.doi.org/10.1007/s12115-021-00594-8,"In the digital era, we witness the increasing use of artificial intelligence (AI) to solve problems, while improving productivity and efficiency. Yet, inevitably costs are involved with delegating power to algorithmically based systems, some of whose workings are opaque and unobservable and thus termed the “black box”. Central to understanding the “black box” is to acknowledge that the algorithm is not mendaciously undertaking this action; it is simply using the recombination afforded to scaled computable machine learning algorithms. But an algorithm with arbitrary precision can easily reconstruct those characteristics and make life-changing decisions, particularly in financial services (credit scoring, risk assessment, etc.), and it could be difficult to reconstruct, if this was done in a fair manner reflecting the values of society. If we permit AI to make life-changing decisions, what are the opportunity costs, data trade-offs, and implications for social, economic, technical, legal, and environmental systems? We find that over 160 ethical AI principles exist, advocating organisations to act responsibly to avoid causing digital societal harms. This maelstrom of guidance, none of which is compulsory, serves to confuse, as opposed to guide. We need to think carefully about how we implement these algorithms, the delegation of decisions and data usage, in the absence of human oversight and AI governance. The paper seeks to harmonise and align approaches, illustrating the opportunities and threats of AI, while raising awareness of Corporate Digital Responsibility (CDR) as a potential collaborative mechanism to demystify governance complexity and to establish an equitable digital society.",included,3746,0.805864215
10.1007/s13132-021-00767-0,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of the Knowledge Economy,Springer,6/1/2022 0:00,springer,towards high impact smart cities: a universal architecture based on connected intelligence spaces,http://dx.doi.org/10.1007/s13132-021-00767-0,"Smart cities constitute a new urban paradigm and a hegemonic phenomenon in contemporary city development. The concept envisages a data-enhanced future and efficiency gains made possible by automation and innovation in city activities and utilities. However, the way smart cities are created brings about two weaknesses. First, there is strong compartmentation of solutions and systems, which are developing in vertical markets for energy, transport, governance, safety, etc., silos with little interoperability and sharing of resources. Second, there is a low impact, some increase in efficiency, some reduction in costs, time gained, some decrease in CO 2 emissions. There is an important knowledge gap about developing cross-sector, high-impact smart city systems. This paper deals with these challenges and investigates a different direction in smart city design and efficiency. We focus on ‘Connected Intelligence Spaces’ created in smart city ecosystems, which (a) have physical, social, and digital dimensions; (b) work as systems of innovation enabling synergies between human, machine, and collective intelligence; and (c) improve efficiency and performance by innovating rather than optimizing city routines. The research hypothesis we assess is about a universal architecture of high impact smart city projects, due to underlying connected intelligence spaces and cyber-physical-social systems of innovation. We assess this hypothesis with empirical evidence from case studies related to smart city projects dealing with safety (Vision-Zero), transportation (MaaS), and energy (positive energy districts). We highlight the main elements of operation and how high efficiency is achieved across these verticals. We identify commonalities, common innovation functions, and associations between functions, allowing us to define a common architecture enabling innovation and high performance across smart city ecosystems.",not included,2986,0.805609882
10.1007/s00146-021-01239-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,artificial intelligence in hospitals: providing a status quo of ethical considerations in academia to guide future research,http://dx.doi.org/10.1007/s00146-021-01239-4,"The application of artificial intelligence (AI) in hospitals yields many advantages but also confronts healthcare with ethical questions and challenges. While various disciplines have conducted specific research on the ethical considerations of AI in hospitals, the literature still requires a holistic overview. By conducting a systematic discourse approach highlighted by expert interviews with healthcare specialists, we identified the status quo of interdisciplinary research in academia on ethical considerations and dimensions of AI in hospitals. We found 15 fundamental manuscripts by constructing a citation network for the ethical discourse, and we extracted actionable principles and their relationships. We provide an agenda to guide academia, framed under the principles of biomedical ethics. We provide an understanding of the current ethical discourse of AI in clinical environments, identify where further research is pressingly needed, and discuss additional research questions that should be addressed. We also guide practitioners to acknowledge AI-related benefits in hospitals and to understand the related ethical concerns.",not included,2536,0.805600882
10.1007/s10479-024-05875-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Annals of Operations Research,Springer,2/1/2024 0:00,springer,tackling the global challenges using data-driven innovations,http://dx.doi.org/10.1007/s10479-024-05875-z,"The data revolution transforms operations, innovation, and society through artificial intelligence and advanced analytics. Data-driven innovations (DDI) have the most potential to tackle global challenges, including poverty, healthcare, climate actions, disaster management, gender inequality, peace and justice and others. This paper identifies the sources of DDI capabilities to address various global challenges. The findings show three major foundations of DDI capabilities: market orientation, infrastructure orientation, and talent orientation. Theoretically, these findings highlight the role of dynamic DDI capabilities to sense, seize and transform global challenges. Practically, we present guidelines for developing DDI in an agile and efficient manner that is fair and inclusive.",included,1269,0.805574656
10.1007/s44163-023-00060-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Discover Artificial Intelligence,Springer,4/27/2023 0:00,springer,charting ai urbanism: conceptual sources and spatial implications of urban artificial intelligence,http://dx.doi.org/10.1007/s44163-023-00060-w,"The aim of this paper is to tease out some of the key issues concerning the relationship between AI and urbanism. This relationship, which is presented in the academic literature as a new driving force of contemporary urbanism, will be investigated through an interdisciplinary approach that places urban studies and philosophy of technology in dialogue. Thus, the analysis will not focus on the technological development of artificial intelligence systems but on how their application can affect urbanistic thinking and vice versa. The chart that is produced by this method is based on two fundamental axes: time and space. AI urbanism will then be inquired first through key turning points in the history of the relationship between technology and the city (modern urbanism, cybernetics and the smart city paradigm). Secondly, the spatial implications of urban AI will be investigated from the point of view of the concrete applications of this technology to the city (Robots, AVs, Software agents) and their impact on the relationships between different urban actors. Ultimately, this work aims to offer a conceptual tool for understanding some decisive implications of the relationship between AI and urbanism, such as the connection between quantitative and qualitative approaches, the implications related to autonomous technology, the economic-political background of AI urbanism, the material urban impact of AI, and the relationship between AI and other urban intelligences. Understanding these implications will be valuable for future research on AI urbanism oriented toward transforming simple technological development into sustainable urban innovations.",included,2227,0.805339456
10.1007/s00146-019-00880-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,3/1/2020 0:00,springer,artificial intelligence: consciousness and conscience,http://dx.doi.org/10.1007/s00146-019-00880-4,"Our society is in the middle of the AI revolution. We discuss several applications of AI, in particular medical causality, where deep-learning neural networks screen through big data bases, extracting associations between a patient’s condition and possible causes. While beneficial in medicine, several questionable AI trading strategies have emerged in finance. Though advantages in many aspects of our lives, serious threats of AI exist. We suggest several regulatory measures to reduce these threats. We further discuss whether ‘full AI robots’ should be programmed with a virtual consciousness and conscience. While this would reduce AI threats via motivational control, other threats such as the desire for AI—human socioeconomic equality could prove detrimental.",not included,4547,0.805250764
10.1108/cr-06-2023-0144,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Competitiveness Review: An International Business Journal,1/1/2000 0:00,semantic_scholar,factors affecting citizen intention toward ai acceptance and adoption: the moderating role of government regulations,https://www.semanticscholar.org/paper/7d474e635b35f0915a71d3010b0635b03b367767,"
Purpose
This paper aims to explore factors impacting citizen intention toward artificial intelligence (AI) adoption, considering government regulation as a moderating variable. It focuses on the Palestinian Cellular Communications Sector in Gaza Strip, providing insights into the citizen-AI relationship dynamics. The research contributes to enhancing comprehension of AI technology from clients’ perspective.


Design/methodology/approach
To test the hypotheses, a questionnaire was used in an empirical study to collect primary data. In total, 347 Palestinian citizens responded to the survey.


Findings
The findings of this paper reveal that perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns significantly influence citizen intention toward AI adoption. Furthermore, government regulations as a moderating variable strengthen the impact of perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns on citizen intention toward AI acceptance and adoption. Thus, further research should explore specific domains and cultural contexts to gain a more comprehensive understanding of the factors shaping acceptance and adoption.


Research limitations/implications
The findings of the study should be understood in the context of their limitations. First, the study ignored cultural or domain-specific subtleties in favor of generic characteristics, which calls for more research in these particular circumstances. Second, relying on self-reported data might result in biases and limitations due to subjectivity in reporting, indicating the necessity for alternate data gathering methods and approaches in future research.


Practical implications
Policymakers, developers and organizations working to promote the acceptability and implementation of AI applications should consider the practical implications of this study’s results. To secure the long-term use of AI technologies in a responsible and user-centric way, policymakers should give priority to public education and awareness, user-centered design and ethical AI development techniques. They should also stimulate partnerships and create monitoring systems.


Originality/value
This paper investigates the originality of factors that influence citizen intention toward AI acceptance and adoption. It uniquely examines the moderating role of government regulations in shaping this intention. By addressing this novel aspect, the paper contributes to advancing our understanding of the complex dynamics surrounding citizen intentions toward AI applications.
",included,143,0.80507201
10.15439/2023f5494,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Conference on Computer Science and Information Systems,1/1/2000 0:00,semantic_scholar,towards community-driven generative ai,https://www.semanticscholar.org/paper/52aaea84c922c27c35260aaca8ff43f8debd1a2d,"—While the emerging market of Generative Artiﬁcial Intelligence (AI) is increasingly dominated and controlled by the Tech Giants, there is also a growing interest in open-source AI code and models from smaller companies, research organisations and individual users. They often have valuable data that could be used for training, but their computing resources are limited, while data privacy concerns prevent them from sharing this data for public training. A possible solution to overcome these two issues is to utilise the crowd-souring principles and apply federated learning techniques to build a distributed privacy-preserving architecture for training Generative AI. This paper discusses how these two key enablers, together with some other emerging technologies, can be effectively combined to build a community-driven Generative AI ecosystem, allowing even small actors to participate in the training of Generative AI models by securely contributing their training data. The paper also discusses related non-technical issues, such as the role of the community and intellectual property rights, and outlines further research directions associated with AI moderation.",not included,45,0.805045962
10.1007/s43681-023-00337-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,8/31/2023 0:00,springer,the e.u.’s artificial intelligence act: an ordoliberal assessment,http://dx.doi.org/10.1007/s43681-023-00337-x,"In light of the rise of generative AI and recent debates about the socio-political implications of large-language models and chatbots, this article investigates the E.U.’s artificial intelligence act (AIA), the world’s first major attempt by a government body to address and mitigate the potentially negative impacts of AI technologies. The article critically analyzes the AIA from a distinct economic ethics perspective, i.e., ‘ordoliberalism 2.0’—a perspective currently lacking in the academic literature. It evaluates, in particular, the AIA’s ordoliberal strengths and weaknesses and proposes reform measures that could be taken to strengthen the AIA.",not included,1861,0.804321766
10.1007/s00146-021-01258-1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,12/1/2022 0:00,springer,the political imaginary of national ai strategies,http://dx.doi.org/10.1007/s00146-021-01258-1,"In the past few years, several democratic governments have published their National AI Strategies (NASs). These documents outline how AI technology should be implemented in the public sector and explain the policies that will ensure the ethical use of personal data. In this article, I examine these documents as political texts and reconstruct the political imaginary that underlies them. I argue that these documents intervene in contemporary democratic politics by suggesting that AI can help democracies overcome some of the challenges they are facing. To achieve this, NASs use different kinds of imaginaries—democratic, sociotechnical and data—that help citizens envision how a future AI democracy might look like. As part of this collective effort, a new kind of relationship between citizens and governments is formed. Citizens are seen as autonomous data subjects, but at the same time, they are expected to share their personal data for the common good. As a result, I argue, a new kind of political imaginary is developed in these documents. One that maintains a human-centric approach while championing a vision of collective sovereignty over data. This kind of political imaginary can become useful in understanding the roles of citizens and governments in this technological age.",not included,2539,0.803777218
10.1038/s41586-019-1138-y,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Nature,Nature,4/25/2019 0:00,springer,machine behaviour,http://dx.doi.org/10.1038/s41586-019-1138-y,"Machines powered by artificial intelligence increasingly mediate our social, cultural, economic and political interactions. Understanding the behaviour of artificial intelligence systems is essential to our ability to control their actions, reap their benefits and minimize their harms. Here we argue that this necessitates a broad scientific research agenda to study machine behaviour that incorporates and expands upon the discipline of computer science and includes insights from across the sciences. We first outline a set of questions that are fundamental to this emerging field and then explore the technical, legal and institutional constraints on the study of machine behaviour. Understanding the behaviour of the machines powered by artificial intelligence that increasingly mediate our social, cultural, economic and political interactions is essential to our ability to control the actions of these intelligent machines, reap their benefits and minimize their harms.",not included,4974,0.803049684
10.1007/s43681-024-00480-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/2/2024 0:00,springer,a semi-automated software model to support ai ethics compliance assessment of an ai system guided by ethical principles of ai,http://dx.doi.org/10.1007/s43681-024-00480-z,"Compliance with principles and guidelines for ethical AI has a significant impact on companies engaged in the development of artificial intelligence (AI) systems. Specifically, ethics is a broad concept that continuously evolves over time and across cultural and geographical boundaries. International organisations (IOs), individual states, and private groups, all have an interest in defining the concept of ethics of AI. IOs, as well as regional and national bodies, have issued many decisions on AI ethics. Developing a system that complies with the ethical framework poses a complex challenge for companies, and the consequences of not complying with ethical principles can have severe consequences, making compliance with these requirements a key issue for companies. Furthermore, there is a shortage of technical tools to ensure that such AI systems comply with ethical criteria. The scarcity of ethics compliance checking tools for AI, and the current focus on defining ethical guidelines for AI development, has led us to undertake a proposal consisting in a semi-automated software model to verify the ethical compliance of an AI system’s code. To implement this model, we focus on the following important aspects: (1) a literature review to identify existing ethical compliance systems, (2) a review of principles and guidelines for ethical AI to determine the international and European views regarding AI ethics, and (3) the identification of commonly accepted principles and sub-principles of AI. These elements served to inform (4) our proposal for the design of a semi-automated software for verifying the ethical compliance of AI systems both at design-time (ethics-by-design perspective) and afterwards on the resulting software.",included,901,0.80287987
10.1007/s11192-017-2534-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Scientometrics,Springer,12/1/2017 0:00,springer,global mapping of artificial intelligence in google and google scholar,http://dx.doi.org/10.1007/s11192-017-2534-4,"The worldwide presence of AI needs to be quantified. This study proposes a descriptive approach and the use of multiple methods and data. An extensive electronic corpus of books was utilized to see the worldwide drift of intellectuals’ minds toward AI and identified related terms, their future trends, and convergence. Using the best bigram proposed by Ngrams Viewer, this study explores the human mind through Google query data, linking popular regions, countries, and related topics to the concept of AI. URL datasets were collected using two popular search engines (SEs), Google and Google Scholar (GS). A URL analysis identified key entities (organizations, institutes, and countries) and their yearly trends. Top-level domains revealed the global web ecology and the annual information growth of AI in SE environments. Information gathered through one approach was fed into the other, revealing a complementary relationship. AI is popular across the globe, and has left traces in many different countries. In this field, GS dominates Google, in relation to the number of sites and domains it includes. Top results reveal the popularity of AI among professionals, artists, programmers, and researchers. The pros and cons of the approaches are also discussed. In addition, this study aims to predict the impact of AI on society, as interpreted through the lenses of well-established theories. The dominance of AI may trap society into aspiring toward an easy life, dependent on intelligent machines. Consistent policies are needed to smooth out future economic cycles in the AI field.",not included,5526,0.802714229
10.1007/s00146-022-01480-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI & SOCIETY,Springer,4/1/2023 0:00,springer,ai for the public. how public interest theory shifts the discourse on ai,http://dx.doi.org/10.1007/s00146-022-01480-5,"AI for social good is a thriving research topic and a frequently declared goal of AI strategies and regulation. This article investigates the requirements necessary in order for AI to actually serve a public interest, and hence be socially good. The authors propose shifting the focus of the discourse towards democratic governance processes when developing and deploying AI systems. The article draws from the rich history of public interest theory in political philosophy and law, and develops a framework for ‘public interest AI’. The framework consists of (1) public justification for the AI system, (2) an emphasis on equality, (3) deliberation/ co-design process, (4) technical safeguards, and (5) openness to validation. This framework is then applied to two case studies, namely SyRI, the Dutch welfare fraud detection project, and UNICEF’s Project Connect, that maps schools worldwide. Through the analysis of these cases, the authors conclude that public interest is a helpful and practical guide for the development and governance of AI for the people.",included,2245,0.802524149
10.1007/s13347-017-0279-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,12/1/2018 0:00,springer,"fair, transparent, and accountable algorithmic decision-making processes",http://dx.doi.org/10.1007/s13347-017-0279-x,"The combination of increased availability of large amounts of fine-grained human behavioral data and advances in machine learning is presiding over a growing reliance on algorithms to address complex societal problems. Algorithmic decision-making processes might lead to more objective and thus potentially fairer decisions than those made by humans who may be influenced by greed, prejudice, fatigue, or hunger. However, algorithmic decision-making has been criticized for its potential to enhance discrimination, information and power asymmetry, and opacity. In this paper, we provide an overview of available technical solutions to enhance fairness, accountability, and transparency in algorithmic decision-making. We also highlight the criticality and urgency to engage multi-disciplinary teams of researchers, practitioners, policy-makers, and citizens to co-develop, deploy, and evaluate in the real-world algorithmic decision-making processes designed to maximize fairness and transparency. In doing so, we describe the Open Algortihms (OPAL) project as a step towards realizing the vision of a world where data and algorithms are used as lenses and levers in support of democracy and development.",included,5123,0.802244544
10.2139/ssrn.3880779,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Social Science Research Network,1/1/2021 0:00,semantic_scholar,"the role of social movements, coalitions, and workers in resisting harmful artificial intelligence and contributing to the development of responsible ai",https://www.semanticscholar.org/paper/826a19bda59aa7ce8a33235b35c0480aac827ea1,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles"", there is mounting public concern over the influence that the AI systems have in our society, and coalitions in all sectors are organizing to resist harmful applications of AI worldwide. Responses from peoples everywhere, from workers protesting unethical conduct and applications of AI, to student's protesting MIT's relationships with donor, sex trafficker, and pedophile Jeffery Epstein, to the healthcare community, to indigenous people addressing “the twin problems of a lack of reliable data and information on indigenous peoples and biopiracy and misuse of their traditional knowledge and cultural heritage”, to smart city stakeholders, to many others. Like corporations, governments around the world have adopted strategies for becoming leaders in the development and use of Artificial Intelligence, fostering environments congenial to AI innovators. Neither corporations nor policymakers have sufficiently addressed how the rights of children fit into their AI strategies or products. The role of artificial intelligence in children’s lives—from how children play, to how they are educated, to how they consume information and learn about the world—is expected to increase exponentially over the coming years. Thus, it’s imperative that stakeholders evaluate the risks and assess opportunities to use artificial intelligence to maximize children’s wellbeing in a thoughtful and systematic manner. This paper discusses AI and children's rights in the context of social media platforms such as YouTube, smart toys, and AI education applications. The Hello Barbie, Cloud Pets, and Cayla smart toys case studies are analyzed, as well as the ElsaGate social media hacks and education's new Intelligent Tutoring Systems and surveillance of students apps. Though AI has valuable benefits for children, it presents some particular challenges around important issues including child safety, privacy, data privacy, device security and consent. Technology giants, all of whom are heavily investing in and profiting from AI, must not dominate the public discourse on responsible use of AI. We all need to shape the future of our core values and democratic institutions. As artificial intelligence continues to find its way into our daily lives, its propensity to interfere with our rights only gets more severe. Many of the issues mentioned in this examination of harmful AI are not new, but they are greatly exacerbated and threatened by the scale, proliferation, and real-life impact that artificial intelligence facilitates. The potential of artificial intelligence to both help and harm people is much greater than earlier technologies. Continuing to examine what safeguards and structures can address AI’s problems and harms, including those that disproportionately impact marginalized people, is a critical activity. There are assumptions embedded in the AI algorithms that will shape how our world is realized. Many of these algorithms are wrongful and biased, they must get locked-in. Our best human judgment is needed to contain AI's harmful impacts. Perhaps one of the greatest contributions of AI will be to make us ultimately understand how important human wisdom truly is in life on earth.",not included,22,0.801989794
10.1007/s42413-020-00081-8,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',International Journal of Community Well-Being,Springer,12/1/2020 0:00,springer,termination for cultural misalignment: setting up contract terms to ensure community well-being in the development of ai,http://dx.doi.org/10.1007/s42413-020-00081-8,"A contractual mechanism to protect and amplify the interests of Indigenous community well-being in the development of Artificial Intelligence (AI) that affects them is investigated. Our proposal explores the need for a legal mechanism that recognizes the importance of cultural knowledge and ways of being and doing, acknowledging that these can be in tension with the (potentially myopic) goals of AI development. We outline the pre-conditions for such a legal mechanism to be possible, including some of the core components that could give rise to a termination for cultural misalignment, as well as the supporting types of governance structures and operating principles such a legal mechanism may engender. We discuss how the establishment of such a mechanism in contracts forces procurers of AI technology development services, and therefore developers of AI technology systems themselves, to adopt and enact principles by which they will work to protect and enable community well-being, thereby instigating important behavior change. Consideration is given to the types of knowledge, skills and training that would be required to implement such a mechanism successfully. This essay has a particular emphasis on working to ensure Indigenous community well-being in the development of AI, however there are also applications for other communities.",not included,4097,0.801980913
10.1007/s10551-022-05050-z,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of Business Ethics,Springer,7/1/2022 0:00,springer,the dawn of the ai robots: towards a new framework of ai robot accountability,http://dx.doi.org/10.1007/s10551-022-05050-z,"Business, management, and business ethics literature pay little attention to the topic of AI robots. The broad spectrum of potential ethical issues pertains to using driverless cars, AI robots in care homes, and in the military, such as Lethal Autonomous Weapon Systems. However, there is a scarcity of in-depth theoretical, methodological, or empirical studies that address these ethical issues, for instance, the impact of morality and where accountability resides in AI robots’ use. To address this dearth, this study offers a conceptual framework that interpretively develops the ethical implications of AI robot applications, drawing on descriptive and normative ethical theory. The new framework elaborates on how the locus of morality (human to AI agency) and moral intensity combine within context-specific AI robot applications, and how this might influence accountability thinking. Our theorization indicates that in situations of escalating AI agency and situational moral intensity, accountability is widely dispersed between actors and institutions. ‘Accountability clusters’ are outlined to illustrate interrelationships between the locus of morality, moral intensity, and accountability and how these invoke different categorical responses: (i) illegal, (ii) immoral, (iii) permissible, and (iv) supererogatory pertaining to using AI robots. These enable discussion of the ethical implications of using AI robots, and associated accountability challenges for a constellation of actors—from designer, individual/organizational users to the normative and regulative approaches of industrial/governmental bodies and intergovernmental regimes.",included,2933,0.801902711
10.1186/s40537-024-00920-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Journal of Big Data,Springer,4/22/2024 0:00,springer,green and sustainable ai research: an integrated thematic and topic modeling analysis,http://dx.doi.org/10.1186/s40537-024-00920-x,"This investigation delves into Green AI and Sustainable AI literature through a dual-analytical approach, combining thematic analysis with BERTopic modeling to reveal both broad thematic clusters and nuanced emerging topics. It identifies three major thematic clusters: (1) Responsible AI for Sustainable Development, focusing on integrating sustainability and ethics within AI technologies; (2) Advancements in Green AI for Energy Optimization, centering on energy efficiency; and (3) Big Data-Driven Computational Advances, emphasizing AI’s influence on socio-economic and environmental aspects. Concurrently, BERTopic modeling uncovers five emerging topics: Ethical Eco-Intelligence, Sustainable Neural Computing, Ethical Healthcare Intelligence, AI Learning Quest, and Cognitive AI Innovation, indicating a trend toward embedding ethical and sustainability considerations into AI research. The study reveals novel intersections between Sustainable and Ethical AI and Green Computing, indicating significant research trends and identifying Ethical Healthcare Intelligence and AI Learning Quest as evolving areas within AI’s socio-economic and societal impacts. The study advocates for a unified approach to innovation in AI, promoting environmental sustainability and ethical integrity to foster responsible AI development. This aligns with the Sustainable Development Goals, emphasizing the need for ecological balance, societal welfare, and responsible innovation. This refined focus underscores the critical need for integrating ethical and environmental considerations into the AI development lifecycle, offering insights for future research directions and policy interventions.",not included,979,0.801638782
10.1007/s10462-023-10641-x,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Artificial Intelligence Review,Springer,2/5/2024 0:00,springer,"artificial intelligence powered metaverse: analysis, challenges and future perspectives",http://dx.doi.org/10.1007/s10462-023-10641-x,"The Metaverse, a virtual reality (VR) space where users can interact with each other and digital objects, is rapidly becoming a reality. As this new world evolves, Artificial Intelligence (AI) is playing an increasingly important role in shaping its development. Integrating AI with emerging technologies in the Metaverse creates new possibilities for immersive experiences that were previously impossible. This paper explores how AI is integrated with technologies such as the Internet of Things, blockchain, Natural Language Processing, virtual reality, Augmented Reality, Mixed Reality, and Extended Reality. One potential benefit of using AI in the Metaverse is the ability to create personalized experiences for individual users, based on their behavior and preferences. Another potential benefit of using AI in the Metaverse is the ability to automate repetitive tasks, freeing up time and resources for more complex and creative endeavors. However, there are also challenges associated with using AI in the Metaverse, such as ensuring user privacy and addressing issues of bias and discrimination. By examining the potential benefits and challenges of using AI in the Metaverse, including ethical considerations, we can better prepare for this exciting new era of VR. This paper presents a comprehensive survey of AI and its integration with other emerging technologies in the Metaverse, as the Metaverse continues to evolve and grow, it will be important for developers and researchers to stay up to date with the latest developments in AI and emerging technologies to fully leverage their potential.",not included,1259,0.801581025
10.1016/j.giq.2024.101962,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85199797451,scopus,9/1/2024,scopus,toward a person-environment fit framework for artificial intelligence implementation in the public sector,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85199797451&origin=inward,"
                  Using an embedded mixed method design, we compared a nationally representative sample of US adults and a sample of US-based emergency managers (EM) on their attitudes toward artificial intelligence (AI) and their intentions to rely on AI in a set of decision-making scenarios relevant to emergency management. Emergency managers reported significantly less positive attitudes toward AI and were less likely to rely on AI for decisions compared to the nationally representative sample. Our analysis of EMs' open-ended responses explaining their choices to use or not use AI-based solutions reflected specific concerns about implementation rather than wariness toward AI generally. These concerns included the complexity of the potential outcomes in the scenarios, the value they placed on human input and their own extensive experience, procedural concerns, collaborative decision-making, team-building, training, and the ethical implications of decisions, rather than a rejection of AI more generally. Managers' insights integrated with our quantitative findings led to a person-environment fit framework for AI implementation in the public sector. Our findings and framework have implications for how AI systems should be introduced and integrated in emergency managerial contexts and in public sector organizations more generally. Public managers' perceptions and intentions to use AI and organizational oversight processes are at least as important as technology design considerations when public sector organizations are considering the deployment of AI.
               ",included,8490,0.800783515
10.1007/s13347-022-00557-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Philosophy & Technology,Springer,7/7/2022 0:00,springer,the ethics of ai ethics. a constructive critique,http://dx.doi.org/10.1007/s13347-022-00557-9,"The paper presents an ethical analysis and constructive critique of the current practice of AI ethics. It identifies conceptual substantive and procedural challenges and it outlines strategies to address them. The strategies include countering the hype and understanding AI as ubiquitous infrastructure including neglected issues of ethics and justice such as structural background injustices into the scope of AI ethics and making the procedures and fora of AI ethics more inclusive and better informed with regard to philosophical ethics. These measures integrate the perspective of AI justice into AI ethics, strengthening its capacity to provide comprehensive normative orientation and guidance for the development and use of AI that actually improves human lives and living together.",included,2926,0.800725281
10.1057/s41599-023-02444-w,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Humanities and Social Sciences Communications,Nature,12/13/2023 0:00,springer,development of the potential of the digital economy of russian regions through artificial intelligence humanisation,http://dx.doi.org/10.1057/s41599-023-02444-w,"This paper is aimed at balancing the interests of business and society in the digital economy, to reduce the social risks of the Fourth Industrial Revolution. The goal of this paper is to study the experience and prospects of the humanisation of AI through the improvement of the practice of corporate social responsibility in Russia. By the example of the experience of Russian regions in 2021, we use econometric modelling to prove that the digital regional economy has a large potential in the sphere of humanisation of AI. The potential for the humanisation of AI in the digital economy of Russian regions is determined by responsible innovations, responsible production and logistics, as well as responsible marketing and sales, which contribute to the implementation of SDGs 9–12. The theoretical significance of the paper lies in its presenting smart region as a socio-economic environment for the humanisation of AI. The scientific novelty of the paper lies in its offering a new—meso-level—view of the humanisation of AI. The advantages of the new view include, first, consideration of socio-economic conditions for the humanisation of AI in a region; second, the most precise identification and correct measuring of the consequences of humanisation of AI for the quality of life in a region. The practical significance of the research results consists in the fact that the new proposed approach to the humanisation of AI, which implies public administration of this process at the level of a region, allows accelerating the considered process.",included,1413,0.800715804
10.1007/s11569-024-00454-9,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',NanoEthics,Springer,8/23/2024 0:00,springer,normative challenges of risk regulation of artificial intelligence,http://dx.doi.org/10.1007/s11569-024-00454-9,"Approaches aimed at regulating artificial intelligence (AI) include a particular form of risk regulation, i.e. a risk-based approach. The most prominent example is the European Union’s Artificial Intelligence Act (AI Act). This article addresses the challenges for adequate risk regulation that arise primarily from the specific type of risks involved, i.e. risks to the protection of fundamental rights and fundamental societal values. This is mainly due to the normative ambiguity of such rights and societal values when attempts are made to select, interpret, specify or operationalise them for the purposes of risk assessments and risk mitigation. This is exemplified by (1) human dignity, (2) informational self-determination, data protection and privacy, (3) anti-discrimination, fairness and justice, and (4) the common good. Normative ambiguities require normative choices, which are assigned to different actors under the regime of the AI Act. Particularly critical normative choices include selecting normative concepts by which to operationalise and specify risks, aggregating and quantifying risks (including the use of metrics), balancing value conflicts, setting levels of acceptable risks, and standardisation. To ensure that these normative choices do not lack democratic legitimacy and to avoid legal uncertainty, further political processes and scientific debates are suggested.",included,410,0.800605595
10.1007/s41233-023-00064-5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',Quality and User Experience,Springer,11/23/2023 0:00,springer,envisioning the future: a multi-disciplinary approach to human-centered intelligent environments,http://dx.doi.org/10.1007/s41233-023-00064-5,"Humane or humanity-centered intelligent environments (IE) prioritize human users, communities, and societal needs in the system design, service, and operations. However, designing for a genuinely humanity-centric vision poses potential barriers related to the technical frameworks and methods of IEs. This paper introduces a multi-disciplinary innovation research approach grounded in a participatory ForSTI (i.e., Foresight in Science, Technology, and Innovation) methodology. We apply a Horizon scanning exercise in combination with expert interviews and a lead user workshop to develop a future humanity-centric roadmap for IEs that aligns with a coherent understanding of human and societal needs. Multiple technical visions are explored to foresee how ethics, human control, and agency can be preserved in developing future human-centric IEs. Our findings indicate that the “feasible” future vision is propelled forward by technical enchanted determinism , with weak resistance from the public, citizens, and society. The “possible” vision augments humans and the environment through technical advancement. In contrast, the most “desirable” vision is inclusive of all humanity, also the most vulnerable, and can bring forth meaningful human involvement and influence in the technical configurations of IEs. By carefully considering the potential drivers and barriers ahead, we can re-think how to design for the most desirable future vision in developing IEs.",included,1565,0.800460815
10.1007/s43681-022-00190-4,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',AI and Ethics,Springer,5/1/2023 0:00,springer,moral transparency of and concerning algorithmic tools,http://dx.doi.org/10.1007/s43681-022-00190-4,"Algorithms and AI tools are becoming increasingly influential artefacts in commercial and governance contexts. Algorithms and AI tools are not value neutral; to some extent they must be rendered knowable and known as objects, and in their implementation and deployment, to see clearly and understand their implications for moral values, and what actions can be undertaken to optimise them in their design and use towards ethical goals, or whether they are even suitable for particular goals. Transparency is a term with variable uses and interpretations, a problem which can challenge its use in design and policy. Here, we attempt to further clarify transparency. We argue that transparency is the state of affairs that obtains when relevant and understandable information about some X is available and accessible to some target audience (A), so that this information is sufficient for A for the purpose (P). Moreover, we connect this conceptualisation with transparency’s moral value, where P is to provide an account about X’s supportive or conflicting relationship with relevant values and goals. Such teleological ends in our context here can be the ability to account for the degree to which an algorithm, process or organisation respects certain values and is conducive to (social) goals.",not included,2194,0.800303578
