id,status,doi,publisher,database,query_name,query_value,url,publication_date,title,abstract,semantic_score
1,excluded,10.1007/s13347-021-00482-3,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13347-021-00482-3,2021-12-01 00:00:00,ethical principles for artificial intelligence in national defence,"Defence agencies across the globe identify artificial intelligence (AI) as a key technology to maintain an edge over adversaries. As a result, efforts to develop or acquire AI capabilities for defence are growing on a global scale. Unfortunately, they remain unmatched by efforts to define ethical frameworks to guide the use of AI in the defence domain. This article provides one such framework. It identifies five principles—justified and overridable uses, just and transparent systems and processes, human moral responsibility, meaningful human control and reliable AI systems—and related recommendations to foster ethically sound uses of AI for national defence purposes.",0.8153417110443115
2,excluded,10.1007/s40804-022-00262-2,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s40804-022-00262-2,2023-03-01 00:00:00,artificial intelligence and sustainable decisions,"When addressing corporate sustainability challenges, artificial intelligence (AI) is a double-edged sword. AI can make significant progress on the most complicated environmental and social problems faced by humans. On the other hand, the efficiencies and innovations generated by AI may also bring new risks, such as automated bias and conflicts with human ethics. We argue that companies and governments should make collective efforts to address sustainability challenges and risks brought by AI. Accountable and sustainable AI can be achieved through a proactive regulatory framework supported by rigorous corporate policies and reports. Given the rapidly evolving nature of this technology, we propose a harmonised and risk-based regulatory approach that accommodates diverse AI solutions to achieve the common good. Ensuring an adequate level of technological neutrality and proportionality of the regulation is the key to mitigating the wide range of potential risks inherent to the use of AI. Instead of promoting sustainability, unregulated AI would be a threat since it would not be possible to effectively monitor its effects on the economy, society and environment. Such a suitable regulatory framework would not only create a consensus concerning the risks to avoid and how to do so but also include enforcement mechanisms to ensure a trustworthy and ethical use of AI in the boardroom. Once this objective is achieved, it will be possible to refer to this technological development as a common good in itself that constitutes an essential asset to human development.",0.8459080457687378
3,excluded,10.37417/rdp/vol_8_2023_1949,Revista de Derecho Público: Teoría y método,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/5a392bc0fd61b7e062d95d6ed819bd347bae4480,2000-01-01 00:00:00,artificial intelligence challenging core state functions,"The use of AI in the public sector is emerging around the world and its spread affects the core States functions: the administrative, the judiciary, and the legislative. Nevertheless, a comprehensive approach to AI in the life-cycle of rules - from the proposal of a new rule to its implementation, monitoring and review- is currently lacking in the rich panorama of studies from different disciplines. The analysis shows that AI has the power to play a crucial role in the life-cycle of rules, by performing time-consuming tasks, increasing access to knowledge base, and enhancing the ability of institutions to draft effective rules and to declutter the regulatory stock. However, it is not without risks, ranging from discrimination to challenges to democratic representation. In order to play a role in achieving law effectiveness while limiting the risks, a complementarity between human and AI should be reached both at the level of the AI architecture and ex post. Moreover, an incremental and experimental approach is suggested, as well as the elaboration of a general framework, to be tailored by each regulator to the specific features of its tasks, aimed at setting the rationale, the role, and adequate guardrails to AI in the life-cycle of rules. This agile approach would allow the AI revolution to display its benefits while preventing potential harms or side effects.",0.8755556344985962
4,excluded,10.1007/s13347-017-0279-x,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13347-017-0279-x,2018-12-01 00:00:00,"fair, transparent, and accountable algorithmic decision-making processes","The combination of increased availability of large amounts of fine-grained human behavioral data and advances in machine learning is presiding over a growing reliance on algorithms to address complex societal problems. Algorithmic decision-making processes might lead to more objective and thus potentially fairer decisions than those made by humans who may be influenced by greed, prejudice, fatigue, or hunger. However, algorithmic decision-making has been criticized for its potential to enhance discrimination, information and power asymmetry, and opacity. In this paper, we provide an overview of available technical solutions to enhance fairness, accountability, and transparency in algorithmic decision-making. We also highlight the criticality and urgency to engage multi-disciplinary teams of researchers, practitioners, policy-makers, and citizens to co-develop, deploy, and evaluate in the real-world algorithmic decision-making processes designed to maximize fairness and transparency. In doing so, we describe the Open Algortihms (OPAL) project as a step towards realizing the vision of a world where data and algorithms are used as lenses and levers in support of democracy and development.",0.8022445440292358
5,excluded,10.1057/s41599-023-02444-w,Nature,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1057/s41599-023-02444-w,2023-12-13 00:00:00,development of the potential of the digital economy of russian regions through artificial intelligence humanisation,"This paper is aimed at balancing the interests of business and society in the digital economy, to reduce the social risks of the Fourth Industrial Revolution. The goal of this paper is to study the experience and prospects of the humanisation of AI through the improvement of the practice of corporate social responsibility in Russia. By the example of the experience of Russian regions in 2021, we use econometric modelling to prove that the digital regional economy has a large potential in the sphere of humanisation of AI. The potential for the humanisation of AI in the digital economy of Russian regions is determined by responsible innovations, responsible production and logistics, as well as responsible marketing and sales, which contribute to the implementation of SDGs 9–12. The theoretical significance of the paper lies in its presenting smart region as a socio-economic environment for the humanisation of AI. The scientific novelty of the paper lies in its offering a new—meso-level—view of the humanisation of AI. The advantages of the new view include, first, consideration of socio-economic conditions for the humanisation of AI in a region; second, the most precise identification and correct measuring of the consequences of humanisation of AI for the quality of life in a region. The practical significance of the research results consists in the fact that the new proposed approach to the humanisation of AI, which implies public administration of this process at the level of a region, allows accelerating the considered process.",0.8007158041000366
6,excluded,10.60087/jaigs.v3i1.119,Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/9b688157f467a83b7f4f6ac4eae7754241018aef,2000-01-01 00:00:00,examining ethical aspects of ai: addressing bias and equity in the discipline,"he rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",0.8362134099006653
7,excluded,10.1007/s43681-021-00120-w,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-021-00120-w,2022-11-01 00:00:00,the social dilemma in artificial intelligence development and why we have to solve it,"While the demand for ethical artificial intelligence (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for AI development and describe why the current crisis in AI development ethics cannot be solved without relieving AI developers of their social dilemma. We argue that AI development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.",0.8217645883560181
8,included,10.1007/s10676-021-09619-6,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s10676-021-09619-6,2021-12-01 00:00:00,the ethical use of artificial intelligence in human resource management: a decision-making framework,"Artificial intelligence (AI) is increasingly inputting into various human resource management (HRM) functions, such as sourcing job applicants and selecting staff, allocating work, and offering personalized career coaching. While the use of AI for such tasks can offer many benefits, evidence suggests that without careful and deliberate implementation its use also has the potential to generate significant harms. This raises several ethical concerns regarding the appropriateness of AI deployment to domains such as HRM, which directly deal with managing sometimes sensitive aspects of individuals’ employment lifecycles. However, research at the intersection of HRM and technology continues to largely center on examining what AI can be used for, rather than focusing on the salient factors relevant to its ethical use and examining how to effectively engage human workers in its use. Conversely, the ethical AI literature offers excellent guiding principles for AI implementation broadly, but there remains much scope to explore how these principles can be enacted in specific contexts-of-use. By drawing on ethical AI and task-technology fit literature, this paper constructs a decision-making framework to support the ethical deployment of AI for HRM and guide determinations of the optimal mix of human and machine involvement for different HRM tasks. Doing so supports the deployment of AI for the betterment of work and workers and generates both scholarly and practical outcomes.",0.8131939768791199
9,excluded,10.1145/3643690.3648235,2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB),semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/b727d48a8a9ce8ac56fc3a164c2a7a4628093550,2000-01-01 00:00:00,artificial intelligence in the public sector - an agenda for responsible innovation through learning,"The optimism about the benefits of using artificial intelligence to innovate public services is tempered by concerns about its risks, limitations, and disbenefits. Given the rapid changes in the technol-ogy itself, the opportunities and needs for cross-sectional solutions, and the nascency of the field of AI-based innovation, we contend that policy, strategy, and implementation must include feedback loops that enable institutional learning for the entire public sec-tor. The scope of challenges creates and imperative to facilitate learning must transcend functional, organizational, geographic, and national boundaries. We propose a learning agenda that in-cludes 1) alignment of strategy and policy; 2) initial understanding of goals, benefits, disbenefits, limitations, and risks; 3) data sharing across jurisdictions; 4) technical robustness and societal alignment in governmental oversight; 5) convergence of architecture for AI support; and 6) a portfolio approach to selecting and learning from enabling service innovation with AI.",0.8725483417510986
10,excluded,10.1007/s43681-024-00548-w,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-024-00548-w,2024-08-14 00:00:00,on singularity and the stoics: why stoicism offers a valuable approach to navigating the risks of ai (artificial intelligence),"The potential benefits and risks of artificial intelligence technologies have sparked a wide-ranging debate in both academic and public circles. On one hand, there is an urgent call to address the immediate and avoidable challenges associated with these tools, such as accountability, privacy, bias, understandability, and transparency; on the other hand, prominent figures like Geoffrey Hinton and Elon Musk have voiced concerns over the potential rise of Super Artificial Intelligence, whose singularity could pose an existential threat to humanity. Coordinating the efforts of thousands of decentralized entities to prevent such a hypothetical event may seem insurmountable in our intricate and multipolar world. Thus, drawing from both perspectives, this work suggests employing the tools and framework of Stoic philosophy, particularly the concept of the dichotomy of control—focusing on what is within our power. This Stoic principle offers a practical and epistemological approach to managing the complexities of AI, and it encourages individuals to organize their efforts around what they can influence while adapting to the constraints of external factors. Within this framework, the essay found that Stoic wisdom is essential for assessing risks, courage is necessary to face contemporary challenges, and temperance and tranquility are indispensable; and these lessons can inform ongoing public and academic discourse, aiding in the development of more effective policy proposals for aligning Narrow AI and General AI with human values.",0.8659470081329346
11,excluded,10.1007/s12626-023-00146-y,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s12626-023-00146-y,2023-10-01 00:00:00,role of regulatory sandboxes and mlops for ai-enabled public sector services,"This paper discusses how innovations in public sector AI-based services must comply with the Artificial Intelligence Act (AI Act) regulatory frameworks while enabling experimentation and participation of diverse stakeholders throughout the Artificial Intelligence (AI) lifecycle . The paper examines the implications of the emerging regulation, AI regulatory sandboxes and Machine Learning Operations (MLOps) as tools that facilitate compliance while enabling co-learning and active participation of multiple stakeholders. We propose a framework that fosters experimentation with automation pipelines and continuous monitoring for the deployment of future public sector AI-based services in a regulatory-compliant and technically innovative manner. AI regulatory sandboxes can be beneficial as a space for contained experimentation that goes beyond regulatory considerations to specific experimentation with the implementation of ML frameworks. While the paper presents a framework based on emerging regulations, tools and practices pertaining to the responsible use of AI, this must be validated through pilot experimentation with public and private stakeholders and regulators in different areas of high-risk AI-based services.",0.8956254124641418
12,excluded,10.1007/s13132-023-01433-3,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13132-023-01433-3,2024-06-01 00:00:00,"artificial intelligence (ai) and automation in administrative procedures: potentials, limitations, and framework conditions","Integrating artificial intelligence (AI) systems into administrative procedures can revolutionize the way processes are conducted and fundamentally change established forms of action and organization in administrative law. However, implementing AI in administrative procedures requires a comprehensive evaluation of the capabilities and limitations of different systems, including considerations of transparency and data availability. Data are a crucial factor in the operation of AI systems and the validity of their predictions. It is essential to ensure that the data used to train AI algorithms are extensive, representative, and free of bias. Transparency is also an important aspect establishing trust and reliability in AI systems, particularly regarding the potential for transparent representation in rule-based and machine-learning AI systems. This paper examines the potential and challenges that arise from integrating AI into administrative procedures. In addition, the paper offers a nuanced perspective on current developments in artificial intelligence and provides a conceptual framework for its potential applications in administrative procedures. Beyond this, the paper highlights essential framework conditions that require continuous monitoring to ensure optimal results in practice.",0.8548192381858826
13,excluded,10.1038/s41558-022-01377-7,Nature,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1038/s41558-022-01377-7,2022-06-01 00:00:00,aligning artificial intelligence with climate change mitigation,"There is great interest in how the growth of artificial intelligence and machine learning may affect global GHG emissions. However, such emissions impacts remain uncertain, owing in part to the diverse mechanisms through which they occur, posing difficulties for measurement and forecasting. Here we introduce a systematic framework for describing the effects of machine learning (ML) on GHG emissions, encompassing three categories: computing-related impacts, immediate impacts of applying ML and system-level impacts. Using this framework, we identify priorities for impact assessment and scenario analysis, and suggest policy levers for better understanding and shaping the effects of ML on climate change mitigation. The rapid growth of artificial intelligence (AI) is reshaping our society in many ways, and climate change is no exception. This Perspective presents a framework to assess how AI affects GHG emissions and proposes approaches to align the technology with climate change mitigation.",0.8137446641921997
14,excluded,10.1017/dap.2024.13,Data & Policy,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/58b7ea14464538f5a7ea31df0e518df1c3efd0e6,2000-01-01 00:00:00,exploring citizens’ stances on ai in public services: a social contract perspective,"Abstract This paper explores citizens’ stances toward the use of artificial intelligence (AI) in public services in Norway. Utilizing a social contract perspective, the study analyzes the government–citizen relationship at macro, meso, and micro levels. A prototype of an AI-enabled public welfare service was designed and presented to 20 participants who were interviewed to investigate their stances on the described AI use. We found a generally positive attitude and identified three factors contributing to this: (a) the high level of trust in government (macro level); (b) the balanced value proposition between individual and collective needs (meso level); and (c) the reassurance provided by having humans in the loop and providing transparency into processes, data, and model’s logic (microlevel). The findings provide valuable insights into citizens’ stances for socially responsible AI in public services. These insights can inform policy and guide the design and implementation of AI systems in the public sector by foregrounding the government–citizen relationship.",0.902136504650116
15,excluded,10.1007/s43681-022-00167-3,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-022-00167-3,2023-02-01 00:00:00,meaningful human control: actionable properties for ai system development,"How can humans remain in control of artificial intelligence (AI)-based systems designed to perform tasks autonomously? Such systems are increasingly ubiquitous, creating benefits - but also undesirable situations where moral responsibility for their actions cannot be properly attributed to any particular person or group. The concept of meaningful human control has been proposed to address responsibility gaps and mitigate them by establishing conditions that enable a proper attribution of responsibility for humans; however, clear requirements for researchers, designers, and engineers are yet inexistent, making the development of AI-based systems that remain under meaningful human control challenging. In this paper, we address the gap between philosophical theory and engineering practice by identifying, through an iterative process of abductive thinking, four actionable properties for AI-based systems under meaningful human control, which we discuss making use of two applications scenarios: automated vehicles and AI-based hiring. First, a system in which humans and AI algorithms interact should have an explicitly defined domain of morally loaded situations within which the system ought to operate. Second, humans and AI agents within the system should have appropriate and mutually compatible representations. Third, responsibility attributed to a human should be commensurate with that human’s ability and authority to control the system. Fourth, there should be explicit links between the actions of the AI agents and actions of humans who are aware of their moral responsibility. We argue that these four properties will support practically minded professionals to take concrete steps toward designing and engineering for AI systems that facilitate meaningful human control.",0.8349719047546387
16,excluded,10.1145/3514094.3539563,"AAAI/ACM Conference on AI, Ethics, and Society",semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/4d14d554a9d6359f1faba70abb530ae03fe7eb89,2022-01-01 00:00:00,the opacity of automated decision-making systems (adms) and its challenges for political legitimacy in a democracy,"This paper focuses specifically on Automated Decision-Making Systems (ADMS) based on Artificial Intelligence (AI). Since the last decades, AI systems are increasingly deployed by governments across the planet to manage public infrastructures and resources, as well as to engage with citizens for the provision of public services. Their introduction is advertised as a cost-cutting tool, as well as an instrument to combat traditional institutional disfunctions such as inefficiency, understaffing, corruption and human bias. While AI offers an incredible potential for progress, an emerging body of literature highlights the challenges that AI-driven decision-making may raise for a public sector ethics. A common trait of these challenges is their being related to some form of ""epistemological opacity"" that undermines the capacity of humans to explain and justify decisions based on AI systems, detect errors or unfairness and adopt corrective actions. The situation may entail public officers and citizens taking the outcomes of AI systems at face value, thus basing their actions (wholly or in part) on pieces of information that cannot be scrutinized and/or corrected if necessary. This paper intends to contribute to an emerging but still underdeveloped trend in normative political theory that study how AI-driven decision-making is reshaping the conceptualization and assessment of interactions between citizens and public officials. The overall goal of the paper is to analyze how various sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) affecting AI systems, may undermine the democratic legitimacy of public decisions based on them. Broadly speaking, legitimacy is the property that grounds the exercise of political authority, where authority standardly means the right to rule [1]. In this paper, democratic legitimacy is understood as a distinctive form of political authority grounded in the recognition of citizens as joint legislators. The paper offers a conception of democratic legitimacy conditional on the capacity of decision-making procedures and outcomes to realize the principle of public equality, which requires citizens' control over public decision-making, as well as respect for their equal status as political decision-makers. Specifically, the paper argues that the ""epistemological opacity"" affecting AI-driven decision-making systems, brings about a mistreatment of citizens as coauthors of public decisions, which is a premise of the idea of democratic citizenship. The main conjecture is that different sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) are causing the disengagement of citizens and public officers from public decision-making, either because they directly undermine necessary conditions for the realization of public equality (co-authorship/accountability/publicity), or because they hide from the public eye instances of illegitimate automation and privatization of decisional power. The paper offers a normative conception of democratic legitimacy that may contribute to efforts in various fields, including ""AI fairness"" and ""Explainable AI"", to better adapt technological tools to equality requirements distinctive of public decision-making within democratic societies.",0.8702366352081299
17,excluded,10.1007/s43681-021-00047-2,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-021-00047-2,2022-05-01 00:00:00,"community-in-the-loop: towards pluralistic value creation in ai, or—why ai needs business ethics","Today, due to growing computing power and the increasing availability of high-quality datasets, artificial intelligence (AI) technologies are entering many areas of our everyday life. Thereby, however, significant ethical concerns arise, including issues of fairness, privacy and human autonomy. By aggregating current concerns and criticisms, we identify five crucial shortcomings of the current debate on the ethics of AI. On the threshold of a third wave of AI ethics, we find that the field eventually fails to take sufficient account of the business context and deep societal value conflicts the use of AI systems may evoke. For even a perfectly fair AI system, regardless of its feasibility, may be ethically problematic, a too narrow focus on the ethical implications of technical systems alone seems insufficient. Therefore, we introduce a business ethics perspective based on the normative theory of contractualism and conceptualise ethical implications as conflicts between values of diverse stakeholders. We argue that such value conflicts can be resolved by an account of deliberative order ethics holding that stakeholders of an economic community deliberate the costs and benefits and agree on rules for acceptable trade-offs when AI systems are employed. This allows AI ethics to consider business practices, to recognise the role of firms, and ethical AI not being at risk to provide a competitive disadvantage or in conflict with the current functioning of economic markets. By introducing deliberative order ethics, we thus seek to do justice to the fundamental normative and political dimensions at the core of AI ethics.",0.8789592385292053
18,excluded,10.1007/s11948-020-00276-4,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s11948-020-00276-4,2020-12-01 00:00:00,towards transparency by design for artificial intelligence,"In this article, we develop the concept of Transparency by Design that serves as practical guidance in helping promote the beneficial functions of transparency while mitigating its challenges in automated-decision making (ADM) environments. With the rise of artificial intelligence (AI) and the ability of AI systems to make automated and self-learned decisions, a call for transparency of how such systems reach decisions has echoed within academic and policy circles. The term transparency, however, relates to multiple concepts, fulfills many functions, and holds different promises that struggle to be realized in concrete applications. Indeed, the complexity of transparency for ADM shows tension between transparency as a normative ideal and its translation to practical application. To address this tension, we first conduct a review of transparency, analyzing its challenges and limitations concerning automated decision-making practices. We then look at the lessons learned from the development of Privacy by Design, as a basis for developing the Transparency by Design principles. Finally, we propose a set of nine principles to cover relevant contextual, technical, informational, and stakeholder-sensitive considerations. Transparency by Design is a model that helps organizations design transparent AI systems, by integrating these principles in a step-by-step manner and as an ex-ante value, not as an afterthought.",0.8991739749908447
19,excluded,10.1007/s43681-021-00039-2,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-021-00039-2,2021-08-01 00:00:00,ai auditing and impact assessment: according to the uk information commissioner’s office,"As the use of data and artificial intelligence systems becomes crucial to core services and business, it increasingly demands a multi-stakeholder and complex governance approach. The Information Commissioner's Office’s ‘Guidance on the AI auditing framework: Draft guidance for consultation’ is a move forward in AI governance. The aim of this initiative is toward producing guidance that encompasses both technical (e.g. system impact assessments) and non-engineering (e.g. human oversight) components to governance and represents a significant milestone in the movement towards standardising AI governance. This paper will summarise and critically evaluate the ICO effort and try to anticipate future debates and present some general recommendations.",0.8333642482757568
20,excluded,10.35940/ijeat.a4282.1013123,International Journal of Engineering and Advanced Technology,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/51791a95c6ba077072018ce8c0d294102953cc6a,2000-01-01 00:00:00,transforming organizational development with ai: navigating change and innovation for success,"Effective change management emerges as a deciding element for an organization's survival and success in the changing terrain of today's fiercely competitive business climate. The variety of change management theories and approaches that are currently available, however, paints a complicated picture that is plagued by inconsistencies, a lack of strong empirical support, and unproven assumptions about contemporary organizational dynamics. This essay seeks to set the basis for a fresh paradigm for effective change administration by critically analyzing popular change management ideas. The gap between theory and practice is addressed in the paper, which concludes with suggestions for more research. In parallel, artificial intelligence (AI) has made incredible progress, giving rise to computers that mimic human autonomy and cognition. Industry-wide excitement has been sparked by the enthusiasm among academics, executives, and the general public, which has resulted in significant investments in utilizing AI's potential through creative business models. However, the lack of thorough academic guidance forces managers to struggle with AI integration issues, increasing the risk of project failure. An in-depth analysis of AI's complexities and its function as a spark for revolutionary business model innovation is provided in this article. A thorough literature assessment, which involves sifting through a sizable library of published works, combines up-to-date information on how AI is affecting the development of new business models. The findings come together to form a roadmap for seamless AI integration that includes four steps: understanding the fundamentals of AI and the skills needed for digital transformation, understanding current business models and their innovation potential, nurturing key proficiencies for AI assimilation, and gaining organizational acceptance while developing internal competencies. This article combines the fields of organizational change management and AI-driven business model innovation with ease, providing a thorough explanation to assist businesses in undergoing a successful transformation and innovation. These disciplines' confluence offers a practical vantage point for successfully adapting to, thriving in, and profiting within a dynamic business environment. Artificial intelligence (AI), a massively disruptive force that is altering international businesses, is at the vanguard of this revolution. The ability of AI to make decisions automatically, based on data analysis and observation, opens up hitherto untapped possibilities for value creation and competitive dominance, with broad consequences spanning several industries. With its quick scaling, ongoing improvement, and self-learning capabilities, this evolutionary invention functions as an agile capital-labor hybrid. Significantly, AI's architecture serves as the cornerstone for data-driven decision support by deftly sifting through large and complicated datasets to extract insights. Thus, the symbiotic marriage of organizational change management and AI-driven business model innovation gives a thorough narrative, directing businesses towards not just surviving, but thriving in an ever-evolving business environment. It is underlined how business models (BMs) interact with technology to affect how well business’s function, underlining the need of taking BMs into account while using AI. Business model innovation (BMI) that AI unlocks may improve goods, streamline processes, and save costs. However, there is a void between technological improvements and their operationalization via BMs. Successful AI integration depends on a well-structured BM, which promotes agility and makes the most of technological resources. BMI is accelerated by AI, which reshapes sectors via innovation. Although interest in AI is high, strategic, cultural, and technological constraints sometimes prevent large investments from producing positive economic results. To fully utilize AI's capabilities, structured BMs are required. Despite an increase in research, there is still little cohesive information about the business uses of AI. In an effort to close this gap, we examine implementation-related AI problems. Analyzing AI-driven BM transformation and risk management is aided by a study on BMI and digital transformation at the same time. The purpose of this study is to further our understanding of AI-driven business model innovation and to provide a useful framework to help practitioners navigate the potential and difficulties of AI implementation. The suggested roadmap aims to identify current knowledge gaps and future research initiatives.",0.8155456185340881
21,excluded,10.1145/3657054.3657125,Digital Government Research,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/cf2a8c29efde5517cc86378ade038d6974930b6a,2000-01-01 00:00:00,comparative analysis of generative ai risks in the public sector,"The landscape of artificial intelligence (AI) has experienced a monumental shift with the emerging of Generative AI (GenAI), which has demonstrated to be a transformative tool across diverse sectors. GenAI outputs can span various digital formats, including text, images, videos, and audio, generating particular interest in the public sector. The growing interest of governments in integrating GenAI technologies in public sector operations is marked by the creation of emerging governance instruments and the formulation of soft laws, like standards, principles, and guidelines. This study aims to delve into the intricacies and potential risks associated with the deployment of GenAI within government. Through a qualitative content analysis, the research meticulously examines GenAI usage guidelines issued by Australia, Canada, New Zealand, the United Kingdom, and South Korea. The objective is to discern the risks acknowledged by these countries' soft laws and compare them with the risks identified by scholars in the field. The performed comparative analysis across countries suggest that the use of GenAI in the public sector raises common risks such as information leakage, data privacy, security, and concerns over public trust. By elucidating the varied risk perceptions across different national contexts, this study provides theoretical and practical implications related to the risks of GenAI within the public sector. Moreover, it sets a foundation for future research and policy development, ensuring that generative AI is used as a force for good in public governance.",0.8618203401565552
22,excluded,10.1007/s00146-022-01471-6,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01471-6,2023-04-01 00:00:00,"covid-19, artificial intelligence, ethical challenges and policy implications","As the COVID-19 outbreak remains an ongoing issue, there are concerns about its disruption, the level of its disruption, how long this pandemic is going to last, and how innovative technological solutions like Artificial Intelligence (AI) and expert systems can assist to deal with this pandemic. AI has the potential to provide extremely accurate insights for an organization to make better decisions based on collected data. Despite the numerous advantages that may be achieved by AI, the use of AI can be perceived differently by society, where moral and ethical issues may be raised, especially in regards to accessing and exploiting public data gathered from social media platforms. To better comprehend the concerns and ethical challenges, utilitarianism and deontology were used as business ethics frameworks to explore the aforementioned challenges of AI in society. The framework assists in determining whether the AI’s deployment is ethically acceptable or not. The paper lays forth policy recommendations for public and private organizations to embrace AI-based decision-making processes to avoid data privacy violations and maintain public trust.",0.8848462700843811
23,excluded,10.1177/09520767231188229,Public Policy and Administration,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/3cc1411a425b6a61bdd8a6bdd8f76ddcff4f869b,2000-01-01 00:00:00,making governance agile: exploring the role of artificial intelligence in china’s local governance,"As the key to digital transformation, artificial intelligence is believed to help achieve the goal of government as a platform and the agile development of digital services. Yet we know little about its potential role in local governance, especially the advances that AI-supported services for the public sector in local governance have ventured and the public value they have created. Combining the digital transformation concepts and public value theory, we fill the gap by examining artificial intelligence (AI) deployment in the public sector of a pilot city of digital transformation in China. Using a mixed-method approach, we show how AI configurations facilitate public value creation in the digital era and identify four dimensions of AI deployment in the public sector: data integration, policy innovation, smart application, and collaboration. Our case analysis on these four dimensions demonstrates two roles that AI technology plays in local governance—“AI cage” and “AI colleague.” The former builds the technology infrastructure and platform in each stage of service delivery, regulating the behaviors of frontline workers, while the latter helps frontline workers make decisions, thus improving the agility of public service provision.",0.8312822580337524
24,excluded,10.1016/j.giq.2023.101828,scopus,scopus,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151401656&origin=inward,2023-06-01,whether ai adoption challenges matter for public managers? the case of polish cities,"
                  A growing body of literature shows that despite the significant benefits of artificial intelligence (AI), its adoption has many unknowns and challenges. However, theoretical studies dominate this topic. Completing the recent works, this article aims to identify challenges faced by public organizations when adopting AI based on the PRISMA Framework and an empirical assessment of these challenges in the opinion of public managers using survey research. The adopted research procedure is also an added value because it could be replicated in other context scenarios. To achieve this paper's aim, the Systematic Literature Review (SLR) and survey research among authorities in 414 Polish cities were carried out. As a result, a list of 15 challenges and preventive activities proposed by researchers to prevent these challenges have been identified. Empirical verification of identified challenges allows us to determine which of them limit AI adoption to the greatest extent in public managers' opinion. These include a lack of strategy or plans to initial adoption / continued usage of AI; no ensuring that AI is used in line with human values; employees' insufficient knowledge of how to use AI; insufficient AI policies, laws, and regulations; and different expectations of stakeholders and partners about AI. These findings could help practitioners to prioritize AI adoption activities and add value to digital government theory.
               ",0.8619891405105591
25,excluded,10.1007/s41233-023-00064-5,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s41233-023-00064-5,2023-11-23 00:00:00,envisioning the future: a multi-disciplinary approach to human-centered intelligent environments,"Humane or humanity-centered intelligent environments (IE) prioritize human users, communities, and societal needs in the system design, service, and operations. However, designing for a genuinely humanity-centric vision poses potential barriers related to the technical frameworks and methods of IEs. This paper introduces a multi-disciplinary innovation research approach grounded in a participatory ForSTI (i.e., Foresight in Science, Technology, and Innovation) methodology. We apply a Horizon scanning exercise in combination with expert interviews and a lead user workshop to develop a future humanity-centric roadmap for IEs that aligns with a coherent understanding of human and societal needs. Multiple technical visions are explored to foresee how ethics, human control, and agency can be preserved in developing future human-centric IEs. Our findings indicate that the “feasible” future vision is propelled forward by technical enchanted determinism , with weak resistance from the public, citizens, and society. The “possible” vision augments humans and the environment through technical advancement. In contrast, the most “desirable” vision is inclusive of all humanity, also the most vulnerable, and can bring forth meaningful human involvement and influence in the technical configurations of IEs. By carefully considering the potential drivers and barriers ahead, we can re-think how to design for the most desirable future vision in developing IEs.",0.8004608154296875
26,excluded,10.1007/s43681-021-00098-5,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-021-00098-5,2022-02-01 00:00:00,factoring ethics in management algorithms for municipal information-analytical systems,"The discourse on the ethics of artificial intelligence (AI) has generated a plethora of different conventions, principles and guidelines outlining an ethical perspective on the use and research of AI. However, when it comes to breaking down general implications to specific use cases, existent frameworks have been remaining vague. The following paper aims to fill this gap by examining the ethical implications of the use of information analytical systems through a management approach for filtering the content in social media and preventing information thrusts with negative consequences for human beings and public administration. The ethical dimensions of AI technologies are revealed through deduction of general challenges of digital governance to applied level management technics.",0.8250516653060913
27,excluded,10.1038/s41467-020-15871-z,Nature,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1038/s41467-020-15871-z,2020-05-18 00:00:00,ai for social good: unlocking the opportunity for positive impact,"Advances in machine learning (ML) and artificial intelligence (AI) present an opportunity to build better tools and solutions to help address some of the world’s most pressing challenges, and deliver positive social impact in accordance with the priorities outlined in the United Nations’ 17 Sustainable Development Goals (SDGs). The AI for Social Good (AI4SG) movement aims to establish interdisciplinary partnerships centred around AI applications towards SDGs. We provide a set of guidelines for establishing successful long-term collaborations between AI researchers and application-domain experts, relate them to existing AI4SG projects and identify key opportunities for future AI applications targeted towards social good. The AI for Social Good movement aims to apply AI/ML tools to help in delivering on the United Nations’ sustainable development goals (SDGs). Here, the authors identify the challenges and propose guidelines for designing and implementing successful partnerships between AI researchers and application - domain experts.",0.8218204975128174
28,excluded,10.1007/s00146-022-01436-9,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01436-9,2023-06-01 00:00:00,tensions in transparent urban ai: designing a smart electric vehicle charge point,"The increasing use of artificial intelligence (AI) by public actors has led to a push for more transparency. Previous research has conceptualized AI transparency as knowledge that empowers citizens and experts to make informed choices about the use and governance of AI. Conversely, in this paper, we critically examine if transparency-as-knowledge is an appropriate concept for a public realm where private interests intersect with democratic concerns. We conduct a practice-based design research study in which we prototype and evaluate a transparent smart electric vehicle charge point, and investigate experts’ and citizens’ understanding of AI transparency. We find that citizens experience transparency as burdensome; experts hope transparency ensures acceptance, while citizens are mostly indifferent to AI; and with absent means of control, citizens question transparency’s relevance. The tensions we identify suggest transparency cannot be reduced to a product feature, but should be seen as a mediator of debate between experts and citizens.",0.8158762454986572
29,excluded,10.1007/s43681-023-00289-2,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-023-00289-2,2023-05-30 00:00:00,auditing large language models: a three-layered approach,"Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",0.831905722618103
30,excluded,10.1016/j.ijinfomgt.2021.102401,scopus,scopus,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85112007685&origin=inward,2021-12-01,public and private value creation using artificial intelligence: an empirical study of ai voice robot users in chinese public sector,"
                  Despite significant theoretical and empirical attention on public value creation in the public sector, the relationship between artificial intelligence (AI) use and value creation from the citizen perspective remains poorly understood. We ground our study in Moore’s public value management to examine the relationship between AI use and value creation. We conceptually categorize public service value into public value and private value. We use procedural justice and trust in government as indicators of public value and, based on motivation theory, we use perceived usefulness and perceived enjoyment as indicators of private value. A field survey of 492 AI voice robot users in China was conducted to test our model. The results indicated that the effective use of AI voice robots was significantly associated with private value and procedural justice. However, the relationship between the effective use of AI and trust in government was not found to be significant. Surprisingly, the respondents indicated that private value had a greater effect on overall value creation than public value. This contrasts with the common idea that value creation from the government perspective suggests that social objectives requiring public value are more important to citizens. The results also show that gender and citizens with different experiences show different AI usage behaviors.
               ",0.8270344734191895
31,included,10.1007/s12525-021-00480-5,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s12525-021-00480-5,2022-03-01 00:00:00,categorization and eccentricity of ai risks: a comparative study of the global ai guidelines,"Background Governments, enterprises, civil organizations, and academics are engaged to promote normative guidelines aimed at regulating the development and application of Artificial Intelligence (AI) in different fields such as judicial assistance, social governance, and business services. Aim Although more than 160 guidelines have been proposed globally, it remains uncertain whether they are sufficient to meet the governance challenges of AI. Given the absence of a holistic theoretical framework to analyze the potential risk of AI, it is difficult to determine what is overestimated and what is missing in the extant guidelines. Based on the classic theoretical model in the field of risk management, we developed a four-dimensional structure as a benchmark to analyze the risk of AI and its corresponding governance measures. The structure consists of four pairs of risks: specific-general, legal-ethical, individual-collective and generational-transgenerational. Method Using the framework, a comparative study of the extant guidelines is conducted by coding the 123 guidelines with 1023 articles. Result We find that the extant guidelines are eccentric, while collective risk and generational risk are largely underestimated by stakeholders. Based on this analysis, three gaps and conflicts are outlined for future improvements.",0.8365063667297363
32,excluded,10.1007/s43681-022-00205-0,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-022-00205-0,2023-08-01 00:00:00,"a principled governance for emerging ai regimes: lessons from china, the european union, and the united states","Artificial intelligence (AI) governance is anticipated to have a transformative impact on humanity which has prompted researchers to analyze its implementation and use to ensure that the technology advances ethically and is beneficial for society. Though countries have begun to develop governance initiatives to regulate AI, the number of emerging AI regimes with an established structure is still relatively low. Meanwhile, the technology is advancing rapidly and has already caused harm inequitably to underrepresented communities. Thus, there is an urgent need to establish robust governance to mitigate the issues and risks attendant when deploying AI.While numerous ethics, principles, and structures have been recommended, this article intends to address the policy lag by providing policymakers with a simple and compelling AI governance framework that situates AI principles as the guiding baseline for developing and evaluating policies. Rather than devising new policy recommendations, the most recent (at the time of writing) and comprehensive governance documents from China, the European Union, and the United States were systematically selected, and examined in a comparative analysis to study how the three regimes address AI principles. Based on the comparative analysis, the most comprehensive and effective recommendations were selected to produce seven broad policy recommendations. The governance framework and recommendations are intentionally broad so that they can be adapted to adequately address AI principles across diverse contexts, encouraging the implementation of AI principles, increasing the likelihood of beneficial AI, and reducing the risks and harms associated with the technology. Nevertheless, the recommendations provided should not be considered exhaustive as the technology has an immense reach and new AI governance initiatives are developing continuously in this growth period in AI governance. It is thus essential for policymakers to survey the most current and relevant governance landscape to identify the best practices that are suitable for their specific context and need.",0.8624181747436523
33,excluded,10.1007/s00146-021-01380-0,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-021-01380-0,2023-08-01 00:00:00,artificial intelligence ethics has a black box problem,"It has become a truism that the ethics of artificial intelligence (AI) is necessary and must help guide technological developments. Numerous ethical guidelines have emerged from academia, industry, government and civil society in recent years. While they provide a basis for discussion on appropriate regulation of AI, it is not always clear how these ethical guidelines were developed, and by whom. Using content analysis, we surveyed a sample of the major documents ( n  = 47) and analyzed the accessible information regarding their methodology and stakeholder engagement. Surprisingly, only 38% report some form of stakeholder engagement (with 9% involving citizens) and most do not report their methodology for developing normative insights (15%). Our results show that documents with stakeholder engagement develop more comprehensive ethical guidance with greater applicability, and that the private sector is least likely to engage stakeholders. We argue that the current trend for enunciating AI ethical guidance not only poses widely discussed challenges of applicability in practice, but also of transparent development (as it rather behaves as a black box) and of active engagement of diversified, independent and trustworthy stakeholders. While most of these documents consider people and the common good as central to their telos, engagement with the general public is significantly lacking. As AI ethics moves from the initial race for enunciating general principles to more sustainable, inclusive and practical guidance, stakeholder engagement and citizen involvement will need to be embedded into the framing of ethical and societal expectations towards this technology.",0.8678622841835022
34,excluded,10.1007/s10676-023-09725-7,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s10676-023-09725-7,2023-10-28 00:00:00,the landscape of data and ai documentation approaches in the european policy context,"Nowadays, Artificial Intelligence (AI) is present in all sectors of the economy. Consequently, both data-the raw material used to build AI systems- and AI have an unprecedented impact on society and there is a need to ensure that they work for its benefit. For this reason, the European Union has put data and trustworthy AI at the center of recent legislative initiatives. An important element in these regulations is transparency, understood as the provision of information to relevant stakeholders to support their understanding of AI systems and data throughout their lifecycle. In recent years, an increasing number of approaches for documenting AI and datasets have emerged, both within academia and the private sector. In this work, we identify the 36 most relevant ones from more than 2200 papers related to trustworthy AI. We assess their relevance from the angle of European regulatory objectives, their coverage of AI technologies and economic sectors, and their suitability to address the specific needs of multiple stakeholders. Finally, we discuss the main documentation gaps found, including the need to better address data innovation practices (e.g. data sharing, data reuse) and large-scale algorithmic systems (e.g. those used in online platforms), and to widen the focus from algorithms and data to AI systems as a whole.",0.8456340432167053
35,excluded,10.1007/s00146-016-0677-0,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-016-0677-0,2017-11-01 00:00:00,on the promotion of safe and socially beneficial artificial intelligence,"This paper discusses means for promoting artificial intelligence (AI) that is designed to be safe and beneficial for society (or simply “beneficial AI”). The promotion of beneficial AI is a social challenge because it seeks to motivate AI developers to choose beneficial AI designs. Currently, the AI field is focused mainly on building AIs that are more capable, with little regard to social impacts. Two types of measures are available for encouraging the AI field to shift more toward building beneficial AI. Extrinsic measures impose constraints or incentives on AI researchers to induce them to pursue beneficial AI even if they do not want to. Intrinsic measures encourage AI researchers to want to pursue beneficial AI. Prior research focuses on extrinsic measures, but intrinsic measures are at least as important. Indeed, intrinsic factors can determine the success of extrinsic measures. Efforts to promote beneficial AI must consider intrinsic factors by studying the social psychology of AI research communities.",0.8510828614234924
36,excluded,10.1145/3657054.3657126,Digital Government Research,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/c37fd9c1303cce61ad8e84b8c4fb8bf36ba8fa70,2000-01-01 00:00:00,gai as a catalyst in national technology sovereignty: evaluating the influence of gai on government policy,"As a result of the prominence of generative artificial intelligence across diverse fields, it has become necessary for governments to develop national strategies for directing the ethical use of artificial intelligence to respect fundamental human values. This paper explores the role of Generative Artificial Intelligence (GAI) in technology sovereignty, its contributions, and benefits for the government, associated risks, and challenges, and how it influences government policies. It begins with examining GAI's capabilities to comprehend how it understands natural language, trains on existing data, and generates realistic outputs, followed by a discussion of its potential benefits for governments that enable them to act independently and autonomously in diverse sectors. It highlights how it can empower them to administer technological ecosystems, promote domestic innovation, and facilitate policy-making processes. However, contrary to its benefits, GAI is also capable of inflicting negative consequences on society. Therefore, the paper also addresses the risks and challenges associated with GAI that necessitate reflection on existing policies and developing new ones that align with a nation's legal frameworks. Exploring the influence of GAI on government policies, the paper highlights the significance of collaboration in policy-making endeavors to ensure ethical future developments and bring value to public interest and democratic values. This comprehensive analysis aims to shed light on the responsible and ethical use of GAI to preserve human rights, promote economic growth, sustain social justice, and inform the responsible use of GAI within the framework of technology sovereignty.",0.8426831364631653
37,excluded,10.1108/dts-03-2023-0018,Digital Transformation and Society,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/34ca9b143e721bfd8dc8eb29d6352a68b9c82a19,2000-01-01 00:00:00,"artificial intelligence, task complexity and uncertainty: analyzing the advantages and disadvantages of using algorithms in public service delivery under public administration theories","PurposeThis article revisits some theories and concepts of public administration, including those related to public value, transaction costs and social equity, to analyze the advantages and disadvantages of using artificial intelligence (AI) algorithms in public service delivery. The author seeks to mobilize theory to guide AI-era public management practitioners and researchers.Design/methodology/approachThe author uses an existing task classification model to mobilize and juxtapose public management theories against artificial intelligence potential impacts in public service delivery. Theories of social equity and transaction costs as well as some concepts such as red tape, efficiency and economy are used to argue that the discipline of public administration provides a foundation to ensure algorithms are used in a way that improves service delivery.FindingsAfter presenting literature on the challenges and promises of using AI in public service, the study shows that while the adoption of algorithms in public service has benefits, some serious challenges still exist when looked at under the lenses of theory. Additionally, the author mobilizes the public administration concepts of agenda setting and coproduction and finds that designing AI-enabled public services should be centered on citizens who are not mere customers. As an implication for public management practice, this study shows that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Research limitations/implicationsAs a fast-growing subject, artificial intelligence research in public management is yet to empirically test some of the theories that the study presented.Practical implicationsThe paper vulgarizes some theories of public administration which practitioners can consider in the design and implementation of AI-enabled public services. Additionally, the study shows practitioners that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Social implicationsThe paper informs a broad audience who might not be familiar with public administration theories and how those theories can be taken into consideration when adopting AI systems in service delivery.Originality/valueThis research is original, as, to the best of the author’s knowledge, no prior work has combined these concepts in analyzing AI in the public sector.",0.8899549245834351
38,included,10.1007/s10676-021-09593-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s10676-021-09593-z,2021-09-01 00:00:00,artificial intelligence regulation: a framework for governance,"This article develops a conceptual framework for regulating Artificial Intelligence (AI) that encompasses all stages of modern public policy-making, from the basics to a sustainable governance. Based on a vast systematic review of the literature on Artificial Intelligence Regulation (AIR) published between 2010 and 2020, a dispersed body of knowledge loosely centred around the “framework” concept was organised, described, and pictured for better understanding. The resulting integrative framework encapsulates 21 prior depictions of the policy-making process, aiming to achieve gold-standard societal values, such as fairness, freedom and long-term sustainability. This challenge of integrating the AIR literature was matched by the identification of a structural common ground among different approaches. The AIR framework results from an effort to identify and later analytically deduce synthetic, and generic tool for a country-specific, stakeholder-aware analysis of AIR matters. Theories and principles as diverse as Agile and Ethics were combined in the “AIR framework”, which provides a conceptual lens for societies to think collectively and make informed policy decisions related to what, when, and how the uses and applications of AI should be regulated. Moreover, the AIR framework serves as a theoretically sound starting point for endeavours related to AI regulation, from legislation to research and development. As we know, the (potential) impacts of AI on society are immense, and therefore the discourses, social negotiations, and applications of this technology should be guided by common grounds based on contemporary governance techniques, and social values legitimated via dialogue and scientific research.",0.8591601252555847
39,included,10.1007/s43681-022-00178-0,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-022-00178-0,2023-02-01 00:00:00,"ethical assurance: a practical approach to the responsible design, development, and deployment of data-driven technologies","This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and AI. First, it provides a critical analysis of current efforts to establish practical mechanisms for algorithmic auditing and assessment to identify limitations and gaps with these approaches. Second, it provides a brief introduction to the methodology of argument-based assurance and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems. Third, it generalises this method to incorporate wider ethical, social, and legal considerations, in turn establishing a novel version of argument-based assurance that we call ‘ethical assurance.’ Ethical assurance is presented as a structured method for unifying the myriad practical mechanisms that have been proposed. It is built on a process-based form of project governance that enlists reflective innovation practices to operationalise normative principles, such as sustainability, accountability, transparency, fairness, and explainability. As a set of interlocutory governance mechanisms that span across the data science and AI lifecycle, ethical assurance supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities. Finally, this article sets an agenda for ethical assurance, by detailing current challenges, open questions, and next steps, which serve as a springboard to build an active (and interdisciplinary) research programme as well as contribute to ongoing discussions in policy and governance.",0.8177997469902039
40,excluded,10.1007/s13347-022-00557-9,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13347-022-00557-9,2022-07-07 00:00:00,the ethics of ai ethics. a constructive critique,"The paper presents an ethical analysis and constructive critique of the current practice of AI ethics. It identifies conceptual substantive and procedural challenges and it outlines strategies to address them. The strategies include countering the hype and understanding AI as ubiquitous infrastructure including neglected issues of ethics and justice such as structural background injustices into the scope of AI ethics and making the procedures and fora of AI ethics more inclusive and better informed with regard to philosophical ethics. These measures integrate the perspective of AI justice into AI ethics, strengthening its capacity to provide comprehensive normative orientation and guidance for the development and use of AI that actually improves human lives and living together.",0.8007252812385559
41,excluded,10.1038/s42256-019-0088-2,Nature,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1038/s42256-019-0088-2,2019-09-01 00:00:00,the global landscape of ai ethics guidelines,"In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be ‘ethical’, there is debate about both what constitutes ‘ethical AI’ and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies. As AI technology develops rapidly, it is widely recognized that ethical guidelines are required for safe and fair implementation in society. But is it possible to agree on what is ‘ethical AI’? A detailed analysis of 84 AI ethics reports around the world, from national and international organizations, companies and institutes, explores this question, finding a convergence around core principles but substantial divergence on practical implementation.",0.8698179721832275
42,excluded,10.1007/s11569-024-00454-9,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s11569-024-00454-9,2024-08-23 00:00:00,normative challenges of risk regulation of artificial intelligence,"Approaches aimed at regulating artificial intelligence (AI) include a particular form of risk regulation, i.e. a risk-based approach. The most prominent example is the European Union’s Artificial Intelligence Act (AI Act). This article addresses the challenges for adequate risk regulation that arise primarily from the specific type of risks involved, i.e. risks to the protection of fundamental rights and fundamental societal values. This is mainly due to the normative ambiguity of such rights and societal values when attempts are made to select, interpret, specify or operationalise them for the purposes of risk assessments and risk mitigation. This is exemplified by (1) human dignity, (2) informational self-determination, data protection and privacy, (3) anti-discrimination, fairness and justice, and (4) the common good. Normative ambiguities require normative choices, which are assigned to different actors under the regime of the AI Act. Particularly critical normative choices include selecting normative concepts by which to operationalise and specify risks, aggregating and quantifying risks (including the use of metrics), balancing value conflicts, setting levels of acceptable risks, and standardisation. To ensure that these normative choices do not lack democratic legitimacy and to avoid legal uncertainty, further political processes and scientific debates are suggested.",0.8006055951118469
43,included,10.1186/s41018-021-00096-6,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1186/s41018-021-00096-6,2021-10-06 00:00:00,explicability of humanitarian ai: a matter of principles,"In the debate on how to improve efficiencies in the humanitarian sector and better meet people’s needs, the argument for the use of artificial intelligence (AI) and automated decision-making (ADMs) systems has gained significant traction and ignited controversy for its ethical and human rights-related implications. Setting aside the implications of introducing unmanned and automated systems in warfare, we focus instead on the impact of the adoption of AI-based ADMs in humanitarian response. In order to maintain the status and protection conferred by the humanitarian mandate, aid organizations are called to abide by a broad set of rules condensed in the humanitarian principles and notably the principles of humanity, neutrality, impartiality, and independence. But how do these principles operate when decision-making is automated? This article opens with an overview of AI and ADMs in the humanitarian sector, with special attention to the concept of algorithmic opacity. It then explores the transformative potential of these systems on the complex power dynamics between humanitarians, principled assistance, and affected communities during acute crises. Our research confirms that the existing flaws in accountability and epistemic processes can be also found in the mathematical and statistical formulas and in the algorithms used for automation, artificial intelligence, predictive analytics, and other efficiency-gaining-related processes. In doing so, our analysis highlights the potential harm to people resulting from algorithmic opacity, either through removal or obfuscation of the causal connection between triggering events and humanitarian services through the so-called black box effect (algorithms are often described as black boxes, as their complexity and technical opacity hide and obfuscate their inner workings (Diakopoulos, Tow Center for Digital Journ, 2017 ). Recognizing the need for a humanitarian ethics dimension in the analysis of automation, AI, and ADMs used in humanitarian action, we endorse the concept of “explicability” as developed within the ethical framework of machine learning and human-computer interaction, together with a set of proxy metrics. Finally, we stress the need for developing auditable standards, as well as transparent guidelines and frameworks to rein in the risks of what has been defined as humanitarian experimentation (Sandvik, Jacobsen, and McDonald, Int. Rev. Red Cross 99(904), 319–344, 2017). This article concludes that accountability mechanisms for AI-based systems and ADMs used to respond to the needs of populations in situation of vulnerability should be an essential feature by default, in order to preserve the respect of the do no harm principle even in the digital dimension of aid. In conclusion, while we confirm existing concerns related to the adoption of AI-based systems and ADMs in humanitarian action, we also advocate for a roadmap towards humanitarian AI for the sector and introduce a tentative ethics framework as basis for future research.",0.8393886089324951
44,excluded,10.1007/s42413-019-00054-6,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s42413-019-00054-6,2020-03-01 00:00:00,artificial intelligence and community well-being: a proposal for an emerging area of research,"We are calling for a new area of research on the nexus of community well-being and artificial intelligence (AI). Three components of this research we propose are (1) the development and use of well-being metrics to measure the impacts of AI; (2) the use of community-based approaches in the development of AI; and (3) development of AI interventions to safeguard or improve community well-being. After providing definitions of community, well-being, and community well-being, we suggest a definition of AI for use by community well-being researchers, with brief explanations of types and uses of AI within this context. A brief summary of threats and opportunities facing community well-being for which AI could potentially present solutions or exacerbate problems is provided. The three components we propose are then discussed, followed by our call for cross-sector, interdisciplinary, transdisciplinary and systems-based approaches for the formation of this proposed area of research.",0.8261353969573975
45,excluded,10.1038/s41598-024-71761-0,Nature,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1038/s41598-024-71761-0,2024-09-05 00:00:00,"trust, trustworthiness and ai governance","An emerging issue in AI alignment is the use of artificial intelligence (AI) by public authorities, and specifically the integration of algorithmic decision-making (ADM) into core state functions. In this context, the alignment of AI with the values related to the notions of trust and trustworthiness constitutes a particularly sensitive problem from a theoretical, empirical, and normative perspective. In this paper, we offer an interdisciplinary overview of the scholarship on trust in sociology, political science, and computer science anchored in artificial intelligence. On this basis, we argue that only a coherent and comprehensive interdisciplinary approach making sense of the different properties attributed to trust and trustworthiness can convey a proper understanding of complex watchful trust dynamics in a socio-technical context. Ensuring the trustworthiness of AI-Governance ultimately requires an understanding of how to combine trust-related values while addressing machines, humans and institutions at the same time. We offer a road-map of the steps that could be taken to address the challenges identified.",0.87795490026474
46,excluded,10.1007/s00146-021-01148-6,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-021-01148-6,2022-03-01 00:00:00,organisational responses to the ethical issues of artificial intelligence,"The ethics of artificial intelligence (AI) is a widely discussed topic. There are numerous initiatives that aim to develop the principles and guidance to ensure that the development, deployment and use of AI are ethically acceptable. What is generally unclear is how organisations that make use of AI understand and address these ethical issues in practice. While there is an abundance of conceptual work on AI ethics, empirical insights are rare and often anecdotal. This paper fills the gap in our current understanding of how organisations deal with AI ethics by presenting empirical findings collected using a set of ten case studies and providing an account of the cross-case analysis. The paper reviews the discussion of ethical issues of AI as well as mitigation strategies that have been proposed in the literature. Using this background, the cross-case analysis categorises the organisational responses that were observed in practice. The discussion shows that organisations are highly aware of the AI ethics debate and keen to engage with ethical issues proactively. However, they make use of only a relatively small subsection of the mitigation strategies proposed in the literature. These insights are of importance to organisations deploying or using AI, to the academic AI ethics debate, but maybe most valuable to policymakers involved in the current debate about suitable policy developments to address the ethical issues raised by AI.",0.8874636292457581
47,excluded,10.1007/s44163-022-00019-3,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s44163-022-00019-3,2022-03-03 00:00:00,reflections on the human role in ai policy formulations: how do national ai strategies view people?,"Purpose There is no artificial intelligence (AI) without people. People design and develop AI; they modify and use it and they have to reorganize the ways they have carried out tasks in their work and everyday life. National strategies are documents made to describe how different nations foster AI and as human dimensions are such an important aspect of AI, this study sought to investigate major national strategy documents to determine how they view the human role in emerging AI societies. Approach Our method for analyzing the strategies was conceptual analysis since the development of technology is embedded with conceptual ideas of humanity, explicit or implicit, and in addition to deepening analysis of explicit argumentation the method enables the deconstruction and reconstruction of meanings and conceptual relations within the strategies, exposing presumptions and tacit commitments of the writers. Findings The analysis of the documents illustrates that the general tendency in national strategies is globally dominantly technology-driven as the state of affairs appears to be creating new technologies. However, various human research points such as usability, user experience, sociotechnical and life-based themes are less well represented. Because national strategies are used to develop innovation processes, we argue that future development of national strategies could be improved by taking human research issues more energetically in the agenda. Originality Our study elaborates the current trends in AI-policy discourses and discusses reasons and possibilities for more holistic policymaking, making it a valuable resource for policymakers, researchers, and the larger public.",0.8490327000617981
48,excluded,10.1145/3657054.3657278,Digital Government Research,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/b29a09098db3c5e67bba3b50ea8627a27258f65b,2000-01-01 00:00:00,examining public sector ai adoption: mechanisms for ai adoption in the absence of authoritative strategic direction,"Artificial Intelligence (AI) is recognized to bring great benefits to the organizations that can successfully adopt this emerging technological domain into their operations. This paper examines the impact of governance and strategic direction on AI adoption and diffusion in a public sector setting. By presenting contextual conditions, mechanisms, and outcomes within a large government agency this work contributes to the understanding of how the absence of appropriate governance structures and strategies impact the development and adoption of AI. Findings show that balancing exploitation and exploration in the capillaries of the organization proved crucial to the adoption and diffusion of AI. This manifested itself through three mechanisms, Cross-domain learning, Legal priming, and Ecosystem growth, which enabled the organization to obtain both value creation and value capture.",0.8780696988105774
49,excluded,10.1007/s44163-022-00028-2,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s44163-022-00028-2,2022-06-20 00:00:00,islamic virtue-based ethics for artificial intelligence,"The twenty-first century technological advances driven by exponential rise of artificial intelligence (AI) technology have ushered in a new era that offers many of us hitherto unimagined luxuries and facilities. However, under the guise of this progressive discourse, particularly in the backdrop of current neo-liberal late-capitalist postmodern world, AI development also has prompted an increasingly uncertain ethical tomorrow. This paper aims to probe the question of ethics by exploring the true ramifications of AI and interrogating its various ethical dimensions. It questions the essential goodness that is attributed to unstinted AI development before elucidating the ethical repercussions of AI advancements and the aptness of the current market logics and business models that govern the tech-industry. The paper next positions a holistic Islamic virtue-based AI ethics framework grounded in the context of Islamic objectives ( maqāṣid ) as an alternative ethical system for AI governance. We argue that this distinctive Islamic virtue-based ethical approach, which can be used to explore AI-related ethical problems more holistically due to its ontological base and rich tradition while keeping in check undue influence from the current socio-politico-economic climate, can be a valuable addition to the global discourse on AI ethics.",0.8338533639907837
50,excluded,10.1007/s00146-023-01750-w,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-023-01750-w,2023-08-30 00:00:00,"basic values in artificial intelligence: comparative factor analysis in estonia, germany, and sweden","Increasing attention is paid to ethical issues and values when designing and deploying artificial intelligence (AI). However, we do not know how those values are embedded in artificial artefacts or how relevant they are to the population exposed to and interacting with AI applications. Based on literature engaging with ethical principles and moral values in AI, we designed an original survey instrument, including 15 value components, to estimate the importance of these values to people in the general population. The article is based on representative surveys conducted in Estonia, Germany, and Sweden ( n  = 4501), which have varying experiences with implementing AI. The factor analysis showed four underlying dimensions of values embedded in the design and use of AI: (1) protection of personal interests to ensure social benefit, (2) general monitoring to ensure universal solidarity, (3) ensuring social diversity and social sustainability, and (4) efficiency. We found that value types can be ordered along the two dimensions of resources and change. The comparison between countries revealed that some dimensions, like social diversity and sustainability evaluations, are more universally valued among individuals, countries, and domains. Based on our analysis, we suggest a need and a framework for developing basic values in AI.",0.8524079322814941
51,excluded,10.1177/08944393241235175,Social science computer review,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/9679559aa9ed7c017dcf33f6e07021a83c83b1ce,2000-01-01 00:00:00,"artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization","In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, that is, the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards AI systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby AI systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that AI-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens’ sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that AI systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means – it cannot dictate the ends. Nonetheless, the use of AI in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, AI-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.",0.8104323148727417
52,excluded,10.1007/s00146-023-01685-2,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-023-01685-2,2024-10-01 00:00:00,"the indian approach to artificial intelligence: an analysis of policy discussions, constitutional values, and regulation","India has produced several drafts of data policies. In this work, they are referred to [1] JBNSCR 2018, [2] DPDPR 2018, [3] NSAI 2018, [4] RAITF 2018, [5] PDPB 2019, [6] PRAI 2021, [7] JPCR 2021, [8] IDAUP 2022, [9] IDABNUP 2022. All of them consider Artificial Intelligence (AI) a social problem solver at the societal level, let alone an incentive for economic growth. However, these policy drafts warn of the social disruptions caused by algorithms and encourage the careful use of computational technologies in various social contexts. Hence, the emerging data society and its implications in India's social contexts demand immense social science attention, which needs to be improved in the policy drafts, primarily because they are creations of industry stakeholders, technocrats, bureaucrats, and experts from tech schools. In the larger social milieu of digital infrastructure emerging, the fundamental question is whether India's national philosophy envisioned in the Indian constitution is reflected in the policy papers. The paper enquires whether the national data policy upholds the core values dispersed through the philosophy of the Indian constitution, which, among other things, is not confined only to inclusion, diversity, rights, liberty, justice and equality. By focusing on constitutional values, the paper seeks to offer a broader and more critical understanding of India's approach to AI policy by bringing together analyses of a wide array of policy documents available in the public realm.",0.838020384311676
53,included,10.1007/s00146-024-01987-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-024-01987-z,2024-06-08 00:00:00,attitudes toward artificial intelligence: combining three theoretical perspectives on technology acceptance,"Evidence on AI acceptance comes from a diverse field comprising public opinion research and largely experimental studies from various disciplines. Differing theoretical approaches in this research, however, imply heterogeneous ways of studying AI acceptance. The present paper provides a framework for systematizing different uses. It identifies three families of theoretical perspectives informing research on AI acceptance—user acceptance, delegation acceptance, and societal adoption acceptance. These models differ in scope, each has elements specific to them, and the connotation of technology acceptance thus changes when shifting perspective. The discussion points to a need for combining the three perspectives as they have all become relevant for AI. A combined approach serves to systematically relate findings from different studies. And as AI systems affect people in different constellations and no single perspective can accommodate them all, building blocks from several perspectives are needed to comprehensively study how AI is perceived in society.",0.8313885927200317
54,excluded,10.1177/09520767231170321,Public Policy and Administration,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/33be6d7c2d61bfac798a29e22ea0267e9fe16b05,2000-01-01 00:00:00,systematic and axiological capacities in artificial intelligence applied in the public sector,"Artificial Intelligence (AI) as a technological development is being implemented in the public sector with the intention of improving service delivery, as well as to help solve complex problems. However, there is a wide range of capabilities that AI can perform and that public officials perceive and implement in different ways. This paper aims to describe and analyze some categories into which AI capabilities in the public sector are divided. Using an Exploratory Factor Analysis (EFA), our results show that the capabilities of AI from the perspective of public officials can be classified into two aspects: systematic factors and axiological factors. Systematic factors are related to the analysis and behavior of data, including monitoring, analyzing, interacting, remembering, and anticipation. Axiological factors refer to the impacts of values, ethics, and decisions, including acting, feeling, moralizing, creating, and deciding capacities. This categorization of AI capabilities in the public sector sheds light on the perception of public officials about the implementation of this technological development.",0.8902336955070496
55,excluded,10.1108/cr-06-2023-0144,Competitiveness Review: An International Business Journal,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/7d474e635b35f0915a71d3010b0635b03b367767,2000-01-01 00:00:00,factors affecting citizen intention toward ai acceptance and adoption: the moderating role of government regulations,"
Purpose
This paper aims to explore factors impacting citizen intention toward artificial intelligence (AI) adoption, considering government regulation as a moderating variable. It focuses on the Palestinian Cellular Communications Sector in Gaza Strip, providing insights into the citizen-AI relationship dynamics. The research contributes to enhancing comprehension of AI technology from clients’ perspective.


Design/methodology/approach
To test the hypotheses, a questionnaire was used in an empirical study to collect primary data. In total, 347 Palestinian citizens responded to the survey.


Findings
The findings of this paper reveal that perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns significantly influence citizen intention toward AI adoption. Furthermore, government regulations as a moderating variable strengthen the impact of perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns on citizen intention toward AI acceptance and adoption. Thus, further research should explore specific domains and cultural contexts to gain a more comprehensive understanding of the factors shaping acceptance and adoption.


Research limitations/implications
The findings of the study should be understood in the context of their limitations. First, the study ignored cultural or domain-specific subtleties in favor of generic characteristics, which calls for more research in these particular circumstances. Second, relying on self-reported data might result in biases and limitations due to subjectivity in reporting, indicating the necessity for alternate data gathering methods and approaches in future research.


Practical implications
Policymakers, developers and organizations working to promote the acceptability and implementation of AI applications should consider the practical implications of this study’s results. To secure the long-term use of AI technologies in a responsible and user-centric way, policymakers should give priority to public education and awareness, user-centered design and ethical AI development techniques. They should also stimulate partnerships and create monitoring systems.


Originality/value
This paper investigates the originality of factors that influence citizen intention toward AI acceptance and adoption. It uniquely examines the moderating role of government regulations in shaping this intention. By addressing this novel aspect, the paper contributes to advancing our understanding of the complex dynamics surrounding citizen intentions toward AI applications.
",0.805072009563446
56,excluded,10.1007/s00146-022-01480-5,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01480-5,2023-04-01 00:00:00,ai for the public. how public interest theory shifts the discourse on ai,"AI for social good is a thriving research topic and a frequently declared goal of AI strategies and regulation. This article investigates the requirements necessary in order for AI to actually serve a public interest, and hence be socially good. The authors propose shifting the focus of the discourse towards democratic governance processes when developing and deploying AI systems. The article draws from the rich history of public interest theory in political philosophy and law, and develops a framework for ‘public interest AI’. The framework consists of (1) public justification for the AI system, (2) an emphasis on equality, (3) deliberation/ co-design process, (4) technical safeguards, and (5) openness to validation. This framework is then applied to two case studies, namely SyRI, the Dutch welfare fraud detection project, and UNICEF’s Project Connect, that maps schools worldwide. Through the analysis of these cases, the authors conclude that public interest is a helpful and practical guide for the development and governance of AI for the people.",0.8025241494178772
57,included,10.1109/ecai46879.2019.9042157,European Conference on Artificial Intelligence,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/3d863678d53ef04773b3e6052995b85db1903e28,2019-01-01 00:00:00,intelligent solutions - based framework for digital public services. a case study for smart transportation,"Digital technology landscape is continuously improving, dragging along both the transformation of public services and new demands of citizens. Emerging new technologies like Artificial Intelligence, Machine Learning, Deep Learning or Internet of Things provide tremendous means to implement intelligent solutions for reshaping digital public services. This paper aims to disclose the most important features of several intelligent technologies and of these types of public services that can be integrated for providing new capabilities. An AI-based architecture for supporting digital public services in the smart transportation sector is presented in order to demonstrate the highlighted ideas and concepts.",0.8241714835166931
58,included,10.1016/j.giq.2022.101722,scopus,scopus,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85132505364&origin=inward,2022-10-01,public ai canvas for ai-enabled public value: a design science approach,"
                  Public agencies have a strong interest in artificial intelligence (AI) systems. However, many public agencies lack tools and frameworks to articulate a viable business model and evaluate public value as they consider investing in AI systems. The business model canvas used extensively in the private sector offers us a foundation for designing a public AI canvas (PAIC). Employing a design science approach, this study reports on the design and evaluation of PAIC. The PAIC comprises three distinctive layers: (1) the public value-oriented AI-enablement layer; (2) the public value logic layer; and (3) the public value-oriented social guidance layer. PAIC offers guidance on innovating the business models of public agencies to create and capture AI-enabled value. For practitioners, PAIC presents a validated tool to guide AI deployment in public agencies.
               ",0.9426229000091552
59,excluded,10.1145/3657054.3657086,Digital Government Research,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/d6133f0fb81ce4779a78835b4af01ef3b55bbeeb,2000-01-01 00:00:00,public value principles for secure and trusted ai,"The objective of this paper is to establish the fundamental public value principles that should govern safe and trusted artificial intelligence (AI). Public value is a dynamic concept that encompasses several dimensions. AI itself has evolved quite rapidly in the last few years, especially with the swift escalation of Generative AI. Governments around the world are grappling with how to govern AI, just as technologists ring alarm bells about the future consequences of AI. Our paper extends the debate on AI governance that is focused on ethical values of beneficence to that of economic values of public good. Viewed as a public good, AI use is beyond the control of the creators. Towards this end, the paper examined AI policies in the United States and Europe. We postulate three principles from a public values perspective: (i) ensuring security and privacy of each individual (or entity); (ii) ensuring trust in AI systems is verifiable; and (iii) ensuring fair and balanced AI protocols, wherein the underlying components of data and algorithms are contestable and open to public debate.",0.8370463848114014
60,excluded,10.1007/s13347-023-00668-x,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13347-023-00668-x,2023-11-01 00:00:00,artificial intelligence (ai) in islamic ethics: towards pluralist ethical benchmarking for ai,"This paper explores artificial intelligence (AI) ethics from an Islamic perspective at a critical time for AI ethical norm-setting. It advocates for a pluralist approach to ethical AI benchmarking. As rapid advancements in AI technologies pose challenges surrounding autonomy, privacy, fairness, and transparency, the prevailing ethical discourse has been predominantly Western or Eurocentric. To address this imbalance, this paper delves into the Islamic ethical traditions to develop a framework that contributes to the global debate on optimal norm setting for designing and using AI technologies. The paper outlines Islamic parameters for ethical values and moral actions in the context of AI's ethical uncertainties. It emphasizes the significance of both textual and non-textual Islamic sources in addressing these uncertainties while placing a strong emphasis on the notion of ""good"" or "" maṣlaḥa "" as a normative guide for AI's ethical evaluation. Defining maṣlaḥa as an ethical state of affairs in harmony with divine will, the paper highlights the coexistence of two interpretations of maṣlaḥa : welfarist/utility-based and duty-based. Islamic jurisprudence allows for arguments supporting ethical choices that prioritize building the technical infrastructure for AI to maximize utility. Conversely, it also supports choices that reject consequential utility calculations as the sole measure of value in determining ethical responses to AI advancements.",0.8473842740058899
61,excluded,10.1007/s43681-024-00469-8,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-024-00469-8,2024-04-15 00:00:00,crossing the principle–practice gap in ai ethics with ethical problem-solving,"The past years have presented a surge in (AI) development, fueled by breakthroughs in deep learning, increased computational power, and substantial investments in the field. Given the generative capabilities of more recent AI systems, the era of large-scale AI models has transformed various domains that intersect our daily lives. However, this progress raises concerns about the balance between technological advancement, ethical considerations, safety measures, and financial interests. Moreover, using such systems in sensitive areas amplifies our general ethical awareness, prompting a re-emergence of debates on governance, regulation, and human values. However, amidst this landscape, how to bridge the principle–practice gap separating ethical discourse from the technical side of AI development remains an open problem. In response to this challenge, the present work proposes a framework to help shorten this gap: ethical problem-solving (EPS). EPS is a methodology promoting responsible, human-centric, and value-oriented AI development. The framework’s core resides in translating principles into practical implementations using impact assessment surveys and a differential recommendation methodology. We utilize EPS as a blueprint to propose the implementation of an Ethics as a Service Platform , currently available as a simple demonstration. We released all framework components openly and with a permissive license, hoping the community would adopt and extend our efforts into other contexts. Available in the following URL https://nkluge-correa.github.io/ethical-problem-solving/ .",0.8185762166976929
62,excluded,10.1051/shsconf/202317904024,SHS Web of Conferences,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/59664744a90437583c2911fc17273670435e0774,2000-01-01 00:00:00,ethical considerations in artificial intelligence: a comprehensive disccusion from the perspective of computer vision,"This paper delves deeply into the multifaceted ethical challenges within the realm of computer vision, focusing intently on various ethical dimensions inherent in this cutting-edge field. It emphasizes the pressing need to address ethical concerns related to AI technologies, including algorithmic fairness, informed consent, public engagement, robust privacy protocols, transparency, and the integration of human judgment through human-in-the-loop systems. The study underscores the vital importance of collaboration among diverse stakeholders, including governments, businesses, academia, and society, to promote responsible and equitable AI practices within computer vision.Through meticulous examination, the paper highlights the urgency of balancing technological advancement with ethical considerations. It advocates for the development and implementation of ethical principles, ensuring that AI technologies align with societal values and promote fairness, transparency, and accountability. The collaborative efforts among various sectors are crucial to fostering an ethical framework that guides the responsible deployment of AI in the field of computer vision. By integrating ethical consciousness into the core of technological innovation, this approach aims to create a symbiotic relationship between artificial intelligence and society, ultimately benefiting humanity as a whole.",0.8396750688552856
63,excluded,10.1016/j.procs.2022.01.308,scopus,scopus,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85127772806&origin=inward,2022-01-01,human-centered artificial intelligence for the public sector: the gate keeping role of the public procurement professional,"The increasing deployment of artificial intelligence (AI) powered solutions for the public sector is hoped to change how developing countries deliver services in key sectors such as agriculture, healthcare, education, and social sectors. And yet AI has a high potential for abuse and creates risks, which if not managed and monitored will jeopardize respect and dignity of the most vulnerable in society. In this study, we argue for delineating public procurements’ role in the human-centred AI (HCAI) discourses, focusing on the developing countries. The study is based on an exploratory inquiry and gathered data among procurement practitioners in Uganda and Kenya, which have similar country procurement regimes: where traditional forms of competition in procurement apply compared to more recent pre-commercial procurement mechanisms that suit AI procurement. We found limited customization in AI technologies, a lack of developed governance frameworks, and little knowledge and distinction between AI procurement and other typical technology procurement processes. We proposed a framework, which in absence of good legal frameworks can allow procurement professionals to embed HCAI principles in AI procurement processes.",0.8569608926773071
64,excluded,10.1007/s12115-021-00594-8,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s12115-021-00594-8,2021-06-01 00:00:00,towards an equitable digital society: artificial intelligence (ai) and corporate digital responsibility (cdr),"In the digital era, we witness the increasing use of artificial intelligence (AI) to solve problems, while improving productivity and efficiency. Yet, inevitably costs are involved with delegating power to algorithmically based systems, some of whose workings are opaque and unobservable and thus termed the “black box”. Central to understanding the “black box” is to acknowledge that the algorithm is not mendaciously undertaking this action; it is simply using the recombination afforded to scaled computable machine learning algorithms. But an algorithm with arbitrary precision can easily reconstruct those characteristics and make life-changing decisions, particularly in financial services (credit scoring, risk assessment, etc.), and it could be difficult to reconstruct, if this was done in a fair manner reflecting the values of society. If we permit AI to make life-changing decisions, what are the opportunity costs, data trade-offs, and implications for social, economic, technical, legal, and environmental systems? We find that over 160 ethical AI principles exist, advocating organisations to act responsibly to avoid causing digital societal harms. This maelstrom of guidance, none of which is compulsory, serves to confuse, as opposed to guide. We need to think carefully about how we implement these algorithms, the delegation of decisions and data usage, in the absence of human oversight and AI governance. The paper seeks to harmonise and align approaches, illustrating the opportunities and threats of AI, while raising awareness of Corporate Digital Responsibility (CDR) as a potential collaborative mechanism to demystify governance complexity and to establish an equitable digital society.",0.8058642148971558
65,included,10.1007/s00146-022-01452-9,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01452-9,2023-04-01 00:00:00,cognitive architectures for artificial intelligence ethics,"As artificial intelligence (AI) thrives and propagates through modern life, a key question to ask is how to include humans in future AI? Despite human involvement at every stage of the production process from conception and design through to implementation, modern AI is still often criticized for its “black box” characteristics. Sometimes, we do not know what really goes on inside or how and why certain conclusions are met. Future AI will face many dilemmas and ethical issues unforeseen by their creators beyond those commonly discussed (e.g., trolley problems and variants of it) and to which solutions cannot be hard-coded and are often still up for debate. Given the sensitivity of such social and ethical dilemmas and the implications of these for human society at large, when and if our AI make the “wrong” choice we need to understand how they got there in order to make corrections and prevent recurrences. This is particularly true in situations where human livelihoods are at stake (e.g., health, well-being, finance, law) or when major individual or household decisions are taken. Doing so requires opening up the “black box” of AI; especially as they act, interact, and adapt in a human world and how they interact with other AI in this world. In this article, we argue for the application of cognitive architectures for ethical AI. In particular, for their potential contributions to AI transparency, explainability, and accountability. We need to understand how our AI get to the solutions they do, and we should seek to do this on a deeper level in terms of the machine-equivalents of motivations, attitudes, values, and so on. The path to future AI is long and winding but it could arrive faster than we think. In order to harness the positive potential outcomes of AI for humans and society (and avoid the negatives), we need to understand AI more fully in the first place and we expect this will simultaneously contribute towards greater understanding of their human counterparts also.",0.8579889535903931
66,excluded,10.1007/s13347-024-00710-6,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13347-024-00710-6,2024-03-13 00:00:00,from ai ethics principles to practices: a teleological methodology to apply ai ethics principles in the defence domain,"This article provides a methodology for the interpretation of AI ethics principles to specify ethical criteria for the development and deployment of AI systems in high-risk domains. The methodology consists of a three-step process deployed by an independent, multi-stakeholder ethics board to: (1) identify the appropriate level of abstraction for modelling the AI lifecycle; (2) interpret prescribed principles to extract specific requirements to be met at each step of the AI lifecycle; and (3) define the criteria to inform purpose- and context-specific balancing of the principles. The methodology presented in this article is designed to be agile, adaptable, and replicable, and when used as part of a pro-ethical institutional culture, will help to foster the ethical design, development, and deployment of AI systems. The application of the methodology is illustrated through reference to the UK Ministry of Defence AI ethics principles.",0.8124231100082397
67,excluded,10.1007/s00146-023-01808-9,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-023-01808-9,2023-11-22 00:00:00,trustworthy ai: ai made in germany and europe?,"As the capabilities of artificial intelligence (AI) continue to expand, concerns are also growing about the ethical and social consequences of unregulated development and, above all, use of AI systems in a wide range of social areas. It is therefore indisputable that the application of AI requires social standardization and regulation. For years, innovation policy measures and the most diverse activities of European and German institutions have been directed toward this goal. Under the label “Trustworthy AI” (TAI), a promise is formulated, according to which AI can meet criteria of transparency, legality, privacy, non-discrimination, and reliability. In this article, we ask what significance and scope the politically initiated concepts of TAI occupy in the current process of AI dynamics and to what extent they can stand for an independent, unique European or German development path of this technology.",0.8717970848083496
68,excluded,10.1007/s13347-024-00761-9,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13347-024-00761-9,2024-07-01 00:00:00,philosophical investigations into ai alignment: a wittgensteinian framework,"We argue that the later Wittgenstein’s philosophy of language and mathematics, substantially focused on rule-following, is relevant to understand and improve on the Artificial Intelligence (AI) alignment problem: his discussions on the categories that influence alignment between humans can inform about the categories that should be controlled to improve on the alignment problem when creating large data sets to be used by supervised and unsupervised learning algorithms, as well as when introducing hard coded guardrails for AI models. We cast these considerations in a model of human–human and human–machine alignment and sketch basic alignment strategies based on these categories and further reflections on rule-following like the notion of meaning as use. To sustain the validity of these considerations, we also show that successful techniques employed by AI safety researchers to better align new AI systems with our human goals are congruent with the stipulations that we derive from the later Wittgenstein’s philosophy. However, their application may benefit from the added specificities and stipulations of our framework: it extends on the current efforts and provides further, specific AI alignment techniques. Thus, we argue that the categories of the model and the core alignment strategies presented in this work can inform further AI alignment techniques.",0.8362331390380859
69,excluded,10.1007/s11023-024-09696-8,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s11023-024-09696-8,2024-09-28 00:00:00,"beneficent intelligence: a capability approach to modeling benefit, assistance, and associated moral failures through ai systems","The prevailing discourse around AI ethics lacks the language and formalism necessary to capture the diverse ethical concerns that emerge when AI systems interact with individuals. Drawing on Sen and Nussbaum’s capability approach, we present a framework formalizing a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders. Such systems enhance stakeholders’ ability to advance their life plans and well-being while upholding their fundamental rights. We characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit. We then contrast this ideal with several salient failure modes, namely, forms of social interactions that constitute unjustified paternalism, coercion, deception, exploitation and domination. The proliferation of incidents involving AI in high-stakes domains underscores the gravity of these issues and the imperative to take an ethics-led approach to AI systems from their inception.",0.8382108807563782
70,excluded,10.1007/s12525-022-00592-6,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s12525-022-00592-6,2022-12-01 00:00:00,user trust in artificial intelligence: a comprehensive conceptual framework,"This paper provides a systematic literature review of current studies between January 2015 and January 2022 on user trust in artificial intelligence (AI) that has been conducted from different perspectives. Such a review and analysis leads to the identification of the various components, influencing factors, and outcomes of users’ trust in AI. Based on the findings, a comprehensive conceptual framework is proposed for a better understanding of users’ trust in AI. This framework can further be tested and validated in various contexts for enhancing our knowledge of users’ trust in AI. This study also provides potential future research avenues. From a practical perspective, it helps AI-supported service providers comprehend the concept of user trust from different perspectives. The findings highlight the importance of building trust based on different facets to facilitate positive cognitive, affective, and behavioral changes among the users.",0.8492169380187988
71,excluded,10.1007/s00146-022-01596-8,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01596-8,2024-06-01 00:00:00,artificial intelligence in support of the circular economy: ethical considerations and a path forward,"The world’s current model for economic development is unsustainable. It encourages high levels of resource extraction, consumption, and waste that undermine positive environmental outcomes. Transitioning to a circular economy (CE) model of development has been proposed as a sustainable alternative. Artificial intelligence (AI) is a crucial enabler for CE. It can aid in designing robust and sustainable products, facilitate new circular business models, and support the broader infrastructures needed to scale circularity. However, to date, considerations of the ethical implications of using AI to achieve a transition to CE have been limited. This article addresses this gap. It outlines how AI is and can be used to transition towards CE, analyzes the ethical risks associated with using AI for this purpose, and supports some recommendations to policymakers and industry on how to minimise these risks.",0.8424201011657715
72,included,10.1007/s43681-022-00143-x,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-022-00143-x,2022-11-01 00:00:00,defining organizational ai governance,"Artificial intelligence (AI) governance is required to reap the benefits and manage the risks brought by AI systems. This means that ethical principles, such as fairness, need to be translated into practicable AI governance processes. A concise AI governance definition would allow researchers and practitioners to identify the constituent parts of the complex problem of translating AI ethics into practice. However, there have been few efforts to define AI governance thus far. To bridge this gap, this paper defines AI governance at the organizational level. Moreover, we delineate how AI governance enters into a governance landscape with numerous governance areas, such as corporate governance, information technology (IT) governance, and data governance. Therefore, we position AI governance as part of an organization’s governance structure in relation to these existing governance areas. Our definition and positioning of organizational AI governance paves the way for crafting AI governance frameworks and offers a stepping stone on the pathway toward governed AI.",0.8767182230949402
73,included,10.1016/j.giq.2024.101962,scopus,scopus,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85199797451&origin=inward,2024-09-01,toward a person-environment fit framework for artificial intelligence implementation in the public sector,"
                  Using an embedded mixed method design, we compared a nationally representative sample of US adults and a sample of US-based emergency managers (EM) on their attitudes toward artificial intelligence (AI) and their intentions to rely on AI in a set of decision-making scenarios relevant to emergency management. Emergency managers reported significantly less positive attitudes toward AI and were less likely to rely on AI for decisions compared to the nationally representative sample. Our analysis of EMs' open-ended responses explaining their choices to use or not use AI-based solutions reflected specific concerns about implementation rather than wariness toward AI generally. These concerns included the complexity of the potential outcomes in the scenarios, the value they placed on human input and their own extensive experience, procedural concerns, collaborative decision-making, team-building, training, and the ethical implications of decisions, rather than a rejection of AI more generally. Managers' insights integrated with our quantitative findings led to a person-environment fit framework for AI implementation in the public sector. Our findings and framework have implications for how AI systems should be introduced and integrated in emergency managerial contexts and in public sector organizations more generally. Public managers' perceptions and intentions to use AI and organizational oversight processes are at least as important as technology design considerations when public sector organizations are considering the deployment of AI.
               ",0.8007835149765015
74,excluded,10.1007/s11628-023-00536-w,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s11628-023-00536-w,2023-09-01 00:00:00,development of a citizen participation public service innovation model based on smart governance,"This study explores an efficient approach to providing customized public services through a smart governance-based public service innovation model (SG-PSIM) that combines intelligent technology and co-creation. Multiple methodological approaches are applied to develop and evaluate the proposed SG-PSIM. Intelligent methodologies that can support the public service policy process are discussed, and the applicability of the SG-PSIM is demonstrated through four case studies. The study results showed that SG-PSIM can effectively collect the opinions of citizens in diverse ways and provide opportunities for citizens to actively participate in the development of public service policies.",0.8207521438598633
75,excluded,10.1145/3657054.3657124,Digital Government Research,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/c22e4a437e3d7659c8257a7f4babe63d6fca05ee,2000-01-01 00:00:00,mitigating the risks of generative ai in government through algorithmic governance,"The launch of the generative artificial intelligence (gen AI) application ChatGPT by OpenAI launched artificial intelligence into public discourse and led to a wave of mass uptake of this technology in organizations in the private sector. At the same time, AI is increasingly incorporated into government functions and the public sector. We propose that governments and the public sector can set an example for the responsible use of AI technologies by following the principles of algorithmic governance traditionally recommended to the private sector. Algorithmic governance has traditionally been defined in the literature as governance by algorithms, or how artificial intelligence is used to make governance decisions and affect social ordering. However, we take an alternative approach; instead, we conceptualize algorithmic governance as the governance of algorithms. We begin by summarizing the risks of generative AI use in government, then outline algorithmic governance principles, a step-by-step approach to implementing algorithmic governance into government or public sector projects, opportunities for inter-sector collaboration, and final conclusions.",0.8392841219902039
76,excluded,10.1007/s43681-024-00547-x,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-024-00547-x,2024-08-19 00:00:00,artificial intelligence and its ‘slow violence’ to human rights,"Human rights concerns in relation to the impacts brought forth by artificial intelligence (‘AI’) have revolved around examining how it affects specific rights, such as the right to privacy, non-discrimination and freedom of expression. However, this article argues that the effects go deeper, potentially challenging the foundational assumptions of key concepts and normative justifications of the human rights framework. To unpack this, the article applies the lens of ‘slow violence’, a term borrowed from environmental justice literature, to frame the grinding, gradual, attritional harms of AI towards the human rights framework. The article examines the slow violence of AI towards human rights at three different levels. First, the individual as the subject of interest and protection within the human rights framework, is increasingly unable to understand nor seek accountability for harms arising from the deployment of AI systems. This undermines the key premise of the framework which was meant to empower the individual in addressing large power disparities and calling for accountability towards such abuse of power. Secondly, the ‘slow violence’ of AI is also seen through the unravelling of the normative justifications of discrete rights such as the right to privacy, freedom of expression and freedom of thought, upending the reasons and assumptions in which those rights were formulated and formalised in the first place. Finally, the article examines how even the wide interpretations towards the normative foundation of human rights, namely human dignity, is unable to address putative new challenges AI poses towards the concept. It then considers and offers the outline to critical perspectives that can inform a new model of human rights accountability in the age of AI.",0.8386234045028687
77,excluded,10.1007/s11023-023-09651-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s11023-023-09651-z,2023-12-01 00:00:00,democratizing ai from a sociotechnical perspective,"Artificial Intelligence (AI) technologies offer new ways of conducting decision-making tasks that influence the daily lives of citizens, such as coordinating traffic, energy distributions, and crowd flows. They can sort, rank, and prioritize the distribution of fines or public funds and resources. Many of the changes that AI technologies promise to bring to such tasks pertain to decisions that are collectively binding. When these technologies become part of critical infrastructures, such as energy networks, citizens are affected by these decisions whether they like it or not, and they usually do not have much say in them. The democratic challenge for those working on AI technologies with collectively binding effects is both to develop and deploy technologies in such a way that the democratic legitimacy of the relevant decisions is safeguarded. In this paper, we develop a conceptual framework to help policymakers, project managers, innovators, and technologists to assess and develop approaches to democratize AI. This framework embraces a broad sociotechnical perspective that highlights the interactions between technology and the complexities and contingencies of the context in which these technologies are embedded. We start from the problem-based and practice-oriented approach to democracy theory as developed by political theorist Mark Warren. We build on this approach to describe practices that can enhance or challenge democracy in political systems and extend it to integrate a sociotechnical perspective and make the role of technology explicit. We then examine how AI technologies can play a role in these practices to improve or inhibit the democratic nature of political systems. We focus in particular on AI-supported political systems in the energy domain.",0.846423327922821
78,excluded,10.1038/s41562-022-01383-x,Nature,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1038/s41562-022-01383-x,2022-10-01 00:00:00,human-centred mechanism design with democratic ai,"Building artificial intelligence (AI) that aligns with human values is an unsolved problem. Here we developed a human-in-the-loop research pipeline called Democratic AI, in which reinforcement learning is used to design a social mechanism that humans prefer by majority. A large group of humans played an online investment game that involved deciding whether to keep a monetary endowment or to share it with others for collective benefit. Shared revenue was returned to players under two different redistribution mechanisms, one designed by the AI and the other by humans. The AI discovered a mechanism that redressed initial wealth imbalance, sanctioned free riders and successfully won the majority vote. By optimizing for human preferences, Democratic AI offers a proof of concept for value-aligned policy innovation. Koster, Balaguer et al. show that an AI mechanism is able to learn to produce a redistribution policy which is preferred to alternatives by humans in an incentivized game.",0.8179486989974976
79,excluded,10.1007/s10479-024-05875-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s10479-024-05875-z,2024-02-01 00:00:00,tackling the global challenges using data-driven innovations,"The data revolution transforms operations, innovation, and society through artificial intelligence and advanced analytics. Data-driven innovations (DDI) have the most potential to tackle global challenges, including poverty, healthcare, climate actions, disaster management, gender inequality, peace and justice and others. This paper identifies the sources of DDI capabilities to address various global challenges. The findings show three major foundations of DDI capabilities: market orientation, infrastructure orientation, and talent orientation. Theoretically, these findings highlight the role of dynamic DDI capabilities to sense, seize and transform global challenges. Practically, we present guidelines for developing DDI in an agile and efficient manner that is fair and inclusive.",0.8055746555328369
80,included,10.3390/app14188259,Applied Sciences,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/282d499f97460e32efae0b0107480d75872bbc5d,2000-01-01 00:00:00,"enhancing e-government services through state-of-the-art, modular, and reproducible architecture over large language models","Integrating Large Language Models (LLMs) into e-government applications has the potential to improve public service delivery through advanced data processing and automation. This paper explores critical aspects of a modular and reproducible architecture based on Retrieval-Augmented Generation (RAG) for deploying LLM-based assistants within e-government systems. By examining current practices and challenges, we propose a framework ensuring that Artificial Intelligence (AI) systems are modular and reproducible, essential for maintaining scalability, transparency, and ethical standards. Our approach utilizing Haystack demonstrates a complete multi-agent Generative AI (GAI) virtual assistant that facilitates scalability and reproducibility by allowing individual components to be independently scaled. This research focuses on a comprehensive review of the existing literature and presents case study examples to demonstrate how such an architecture can enhance public service operations. This framework provides a valuable case study for researchers, policymakers, and practitioners interested in exploring the integration of advanced computational linguistics and LLMs into e-government services, although it could benefit from further empirical validation.",0.8260035514831543
81,included,10.1007/s43681-023-00309-1,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-023-00309-1,2023-06-20 00:00:00,embedded ethics for responsible artificial intelligence systems (ee-rais) in disaster management: a conceptual model and its deployment,"In this paper, we argue that Responsible Artificial Intelligence Systems (RAIS) require a shift toward embedded ethics to address value-based challenges facing AI in disaster management; and we propose a model to achieve it. Disaster management requires Artificial Intelligence Systems (AIS) that would be sensitive to ethical, legal, and multi-dimensional values while being responsive and accountable in complex and acute disruptions that simultaneously call for fair, value-laden, and immediate decisions. Without such a necessary shift, AIS will be incapable of responding properly to major value-based challenges of axiological and hierarchical types, and might leave AIS vulnerable to meta-disasters, such as intelligent digital disasters. This study focuses on RAI in the context of disaster management and proposes a model of Embedded Ethics for Responsible Artificial Intelligence Systems (EE-RAIS), which is empowered by four platforms of embedded ethics—educational, cross-functional, developmental, and algorithmic embedded ethics—as well as four imperative metrics—ethical intelligence, legal intelligence, social-emotional competency, and artificial wisdom. The final section of the paper explores how EE-RAIS can be deployed for the purpose of disaster management and fair crisis informatics.",0.8110824227333069
82,excluded,10.1109/mc.2020.3010043,Computer,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/5bca0d47912b214890e9ca6ee7a76f4deb8de815,2020-01-01 00:00:00,artificial intelligence in government,"The articles in this special section focus on government applications that use artificial intelligence (AI). The repercussions of artificial intelligence (AI) in government are broad and significant. The characteristics of these technologies will have an impact on almost everything in public organizations, from governance or the multidimensional perspective of interoperability, to the organizational or social implications linked to concepts like public value, transparency, or accountability. This special issue seeks to shed light on foundations and key elements to be taken into account for AI adoption by public organizations. Governments are the primary enablers of technology and market stimulators and regulators of general activities in our society. Governments have always sought the common good and, therefore, the advancement of public and collective interests. This is key to understanding, as a first step, why the principles of public-sector organizations do not always match those of the private sector. Public and private perspectives are very different, whether they be management, strategy, or policy.",0.9018986225128174
83,excluded,10.1007/s43681-022-00200-5,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-022-00200-5,2023-08-01 00:00:00,trust and trustworthiness in ai ethics,"Due to the extensive progress of research in artificial intelligence (AI) as well as its deployment and application, the public debate on AI systems has also gained momentum in recent years. With the publication of the Ethics Guidelines for Trustworthy AI (2019), notions of trust and trustworthiness gained particular attention within AI ethics-debates; despite an apparent consensus that AI should be trustworthy, it is less clear what trust and trustworthiness entail in the field of AI. In this paper, I give a detailed overview on the notion of trust employed in AI Ethics Guidelines thus far. Based on that, I assess their overlaps and their omissions from the perspective of practical philosophy. I argue that, currently, AI ethics tends to overload the notion of trustworthiness. It thus runs the risk of becoming a buzzword that cannot be operationalized into a working concept for AI research. What is needed, however, is an approach that is also informed with findings of the research on trust in other fields, for instance, in social sciences and humanities, especially in the field of practical philosophy. This paper is intended as a step in this direction.",0.851370096206665
84,excluded,10.1007/s11948-024-00507-y,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s11948-024-00507-y,2024-10-09 00:00:00,reconstructing ai ethics principles: rawlsian ethics of artificial intelligence,"The popularisation of Artificial Intelligence (AI) technologies has sparked discussion about their ethical implications. This development has forced governmental organisations, NGOs, and private companies to react and draft ethics guidelines for future development of ethical AI systems. Whereas many ethics guidelines address values familiar to ethicists, they seem to lack in ethical justifications. Furthermore, most tend to neglect the impact of AI on democracy, governance, and public deliberation. Existing research suggest, however, that AI can threaten key elements of western democracies that are ethically relevant. In this paper, Rawls’s theory of justice is applied to draft a set of guidelines for organisations and policy-makers to guide AI development towards a more ethical direction. The goal is to contribute to the broadening of the discussion on AI ethics by exploring the possibility of constructing AI ethics guidelines that are philosophically justified and take a broader perspective of societal justice. The paper discusses how Rawls’s theory of justice as fairness and its key concepts relate to the ongoing developments in AI ethics and gives a proposition of how principles that offer a foundation for operationalising AI ethics in practice could look like if aligned with Rawls’s theory of justice as fairness.",0.8767043948173523
85,excluded,10.1007/s43681-021-00083-y,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-021-00083-y,2022-05-01 00:00:00,mapping global ai governance: a nascent regime in a fragmented landscape,"The rapid advances in the development and rollout of artificial intelligence (AI) technologies over the past years have triggered a frenzy of regulatory initiatives at various levels of government and the private sector. This article describes and evaluates the emerging global AI governance architecture and traces the contours of a nascent regime in a fragmented landscape. To do so, it organizes actors and initiatives in a two-by-two matrix, distinguishing between the nature of the driving actor(s) and whether or not their actions take place within the existing governance architecture. Based on this, it provides an overview of key actors and initiatives, highlighting their trajectories and connections. The analysis shows international organizations’ high levels of agency in addressing AI policy and a tendency to address new challenges within existing frameworks. Lastly, it is argued that we are witnessing the first signs of consolidation in this fragmented landscape. The nascent AI regime that emerges is polycentric and fragmented but gravitates around the Organisation for Economic Co-Operation and Development (OECD), which holds considerable epistemic authority and norm-setting power.",0.8250070810317993
86,included,10.1007/s11023-022-09611-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s11023-022-09611-z,2023-12-01 00:00:00,contestable ai by design: towards a framework,"As the use of AI systems continues to increase, so do concerns over their lack of fairness, legitimacy and accountability. Such harmful automated decision-making can be guarded against by ensuring AI systems are contestable by design: responsive to human intervention throughout the system lifecycle. Contestable AI by design is a small but growing field of research. However, most available knowledge requires a significant amount of translation to be applicable in practice. A proven way of conveying intermediate-level, generative design knowledge is in the form of frameworks. In this article we use qualitative-interpretative methods and visual mapping techniques to extract from the literature sociotechnical features and practices that contribute to contestable AI, and synthesize these into a design framework.",0.836030125617981
87,excluded,10.1007/s43681-024-00480-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-024-00480-z,2024-05-02 00:00:00,a semi-automated software model to support ai ethics compliance assessment of an ai system guided by ethical principles of ai,"Compliance with principles and guidelines for ethical AI has a significant impact on companies engaged in the development of artificial intelligence (AI) systems. Specifically, ethics is a broad concept that continuously evolves over time and across cultural and geographical boundaries. International organisations (IOs), individual states, and private groups, all have an interest in defining the concept of ethics of AI. IOs, as well as regional and national bodies, have issued many decisions on AI ethics. Developing a system that complies with the ethical framework poses a complex challenge for companies, and the consequences of not complying with ethical principles can have severe consequences, making compliance with these requirements a key issue for companies. Furthermore, there is a shortage of technical tools to ensure that such AI systems comply with ethical criteria. The scarcity of ethics compliance checking tools for AI, and the current focus on defining ethical guidelines for AI development, has led us to undertake a proposal consisting in a semi-automated software model to verify the ethical compliance of an AI system’s code. To implement this model, we focus on the following important aspects: (1) a literature review to identify existing ethical compliance systems, (2) a review of principles and guidelines for ethical AI to determine the international and European views regarding AI ethics, and (3) the identification of commonly accepted principles and sub-principles of AI. These elements served to inform (4) our proposal for the design of a semi-automated software for verifying the ethical compliance of AI systems both at design-time (ethics-by-design perspective) and afterwards on the resulting software.",0.8028798699378967
88,excluded,10.1016/j.techsoc.2024.102471,scopus,scopus,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184027069&origin=inward,2024-03-01,trustworthy ai in the public sector: an empirical analysis of a swedish labor market decision-support system,"This paper investigates the deployment of Artificial Intelligence (AI) in the Swedish Public Employment Service (PES), focusing on the concept of trustworthy AI in public decision-making. Despite Sweden's advanced digitalization efforts and the widespread application of AI in the public sector, our study reveals significant gaps between theoretical ambitions and practical outcomes, particularly in the context of AI's trustworthiness. We employ a robust theoretical framework comprising Institutional Theory, the Resource-Based View (RBV), and Ambidexterity Theory, to analyze the challenges and discrepancies in AI implementation within PES. Our analysis shows that while AI promises enhanced decision-making efficiency, the reality is marred by issues of transparency, interpretability, and stakeholder engagement. The opacity of the neural network used by the agency to assess jobseekers’ need for support and the lack of comprehensive technical understanding among PES management contribute to the challenges in achieving transparent and interpretable AI systems. Economic pressures for efficiency often overshadow the need for ethical considerations and stakeholder involvement, leading to decisions that may not be in the best interest of jobseekers. We propose recommendations for enhancing AI's trustworthiness in public services, emphasizing the importance of stakeholder engagement, particularly involving jobseekers in the decision-making process. Our study advocates for a more nuanced balance between the use of advanced AI technologies and the leveraging of internal resources such as skilled personnel and organizational knowledge. We also highlight the need for improved AI literacy among both management and personnel to effectively navigate AI's integration into public decision-making processes. Our findings contribute to the ongoing debate on trustworthy AI, offering a detailed case study that bridges the gap between theoretical exploration and practical application. By scrutinizing the AI implementation in the Swedish PES, we provide valuable insights and guidelines for other public sector organizations grappling with the integration of AI into their decision-making processes.",0.8432661294937134
89,excluded,10.1016/j.giq.2021.101596,scopus,scopus,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108562674&origin=inward,2022-10-01,enabling ai capabilities in government agencies: a study of determinants for european municipalities,"Artificial Intelligence (AI) is gradually becoming an integral part of the digital strategy of organizations. Yet, the use of AI in public organizations in still lagging significantly compared to private organizations. Prior literature looking into aspects that facilitate adoption and use of AI has concentrated on challenges concerning technical aspects of AI technologies, providing little insight regarding the organizational deployment of AI, particularly in public organizations. Building on this gap, this study seeks to examine what aspects enable public organizations to develop AI capabilities. To answer this question, we built an integrated and extended model from the Technology-Organization-Environment framework (TOE) and asked high-level technology managers from municipalities in Europe about factors that influence their development of AI capabilities. We collected data from 91 municipalities from three European countries (i.e., Germany, Norway, and Finland) and analyzed responses by means of structural equation modeling. Our findings indicate that five factors – i.e. perceived financial costs, organizational innovativeness, perceived governmental pressure, government incentives, regulatory support – have an impact on the development of AI capabilities. We also find that perceived citizen pressure and perceived value of AI solutions are not important determinants of AI capability formation. Our findings bear the potential to stimulate a more reflected adoption of AI supporting managers in public organizations to develop AI capabilities.",0.8688088655471802
90,included,10.48550/arxiv.2408.00965,arXiv.org,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/15b153e0f6342ad455bfb5e2b6090b89c8066340,2000-01-01 00:00:00,integrating esg and ai: a comprehensive responsible ai assessment framework,"Artificial Intelligence (AI) is a widely developed and adopted technology across entire industry sectors. Integrating environmental, social, and governance (ESG) considerations with AI investments is crucial for ensuring ethical and sustainable technological advancement. Particularly from an investor perspective, this integration not only mitigates risks but also enhances long-term value creation by aligning AI initiatives with broader societal goals. Yet, this area has been less explored in both academia and industry. To bridge the gap, we introduce a novel ESG-AI framework, which is developed based on insights from engagements with 28 companies and comprises three key components. The framework provides a structured approach to this integration, developed in collaboration with industry practitioners. The ESG-AI framework provides an overview of the environmental and social impacts of AI applications, helping users such as investors assess the materiality of AI use. Moreover, it enables investors to evaluate a company's commitment to responsible AI through structured engagements and thorough assessment of specific risk areas. We have publicly released the framework and toolkit in April 2024, which has received significant attention and positive feedback from the investment community. This paper details each component of the framework, demonstrating its applicability in real-world contexts and its potential to guide ethical AI investments.",0.8637049794197083
91,included,10.18178/jaai.2023.1.2.103-116,Journal of Advances in Artificial Intelligence,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/87d110893ac357209247502dfdd2d5312ec44cfd,2000-01-01 00:00:00,use of domain engineering in hyperautomation applied to decision making in government,"This article presents the domain engineering process carried out to obtain the requirements for the implementation of an Artificial Intelligence (AI) compliance framework aimed at the public sector. Owing to the current competitive and fast economy, which generates huge demand for increasingly efficient, reliable, and transparent intelligent systems, decision-support architectures should also be developed under strong restrictions of cost and time. Such a context requires adequate structures, processes, and technologies for coping with the complexity of building such intelligent systems. Currently, many public organizations have adopted applications for process automation, with the aim of refraining from repetitive work and producing more efficient results. However, what is not so often observed is the development of intelligent engines to support complex public decision-making. Possible explanations are the plethora of available data sources and the number of legal norms to be abided by. Moreover, it is important to highlight the need to incorporate transparency, auditability, reusability, and flexibility into such systems. Thus, they can be safely utilized in various analogous situations, reducing the need to develop new applications from scratch. An architecture suitable for supporting public decision-making with so many features and increasingly unstructured data, as well as abundant regulation, needs well-crafted formal specifications. This article aims to analyze three existing frameworks and carry out domain engineering studies in three cases to produce some guidance for future public applications and services based on AI. Next, we provide a conceptual preliminary architectural definition for the public sector. The proposed architecture targets were identified in the three cases studied, namely, frequent tasks of process mining requirements, detection of anomalies, and extraction of rules and public policies for helping public servants. All these aim at expedient AI development for public decision-making.",0.8242796063423157
92,included,10.1145/3657054.3657063,Digital Government Research,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/3488e7b86f16c0d93b7b151eca0d7e7526e6d44b,2000-01-01 00:00:00,beyond principles: embedding ethical ai risks in public sector risk management practice,"Artificial intelligence (AI) adoption by public sector organizations (PSOs) introduces various ethical risks stemming from a lack of integrating human values into AI design. Addressing these ethical risks is a complex collective responsibility among designers, developers, risk experts, and public sector managers. Embedding these risks in existing risk management practices is crucial for responsible AI adoption, as emphasized by the legal requirements of the EU AI Act. However, the responsibility for managing these ethical risks is often unclear. Public sector organizations face unique challenges due to the complex, uncertain, and rapidly evolving nature of AI technologies, further complicating the management of ethical risks. This paper explores using the Three Lines of Defense (TLoD) risk management model to understand and address these ethical risks in public sector AI adoption. The TLoD model structures risk management across three lines: operational management, risk oversight and compliance, and internal audit. This framework helps to distribute and integrate the collective responsibility for ethical AI risk management within public sector organizations, emphasizing alignment and collaboration among different actors. Through an exploratory study involving a survey and semi-structured interviews with professionals responsible for AI-related risk management in Dutch public sector organizations, we assess the TLoD model's usefulness in addressing ethical AI risks. The study examines the challenges and opportunities in applying the TLoD model to manage ethical risks and identifies the potential gaps in responsibility and oversight. The findings suggest that while the TLoD model offers a valuable lens for distributing risk management responsibilities, there are limitations in addressing the emergent and complex nature of ethical risks in AI adoption.",0.8306326270103455
93,excluded,10.1057/s41599-024-03560-x,Nature,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1057/s41599-024-03560-x,2024-09-01 00:00:00,ai governance in a complex and rapidly changing regulatory landscape: a global perspective,"The rapid advancement and deployment of Artificial Intelligence (AI) poses significant regulatory challenges for societies. While it has the potential to bring many benefits, the risks of commercial exploitation or unknown technological dangers have led many jurisdictions to seek a legal response before measurable harm occurs. However, the lack of technical capabilities to regulate this sector despite the urgency to do so resulted in regulatory inertia. Given the borderless nature of this issue, an internationally coordinated response is necessary. This article focuses on the theoretical framework being established in relation to the development of international law applicable to AI and the regulatory authority to create and monitor enforcement of said law. The authors argue that the road ahead remains full of obstacles that must be tackled before the above-mentioned elements see the light despite the attempts being made currently to that end.",0.8385800123214722
94,excluded,10.1007/s00146-024-02065-0,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-024-02065-0,2024-09-19 00:00:00,cognitive imperialism in artificial intelligence: counteracting bias with indigenous epistemologies,"This paper presents a novel methodology for integrating indigenous knowledge systems into AI development to counter cognitive imperialism and foster inclusivity. By critiquing the dominance of Western epistemologies and highlighting the risks of bias, the authors argue for incorporating diverse epistemologies. The proposed framework outlines a participatory approach that includes indigenous perspectives, ensuring AI benefits all. The methodology draws from AI ethics, indigenous studies, and postcolonial theory, emphasizing co-creation with indigenous communities, ethical protocols for indigenous data governance, and adaptation of AI algorithms. Case studies in natural language processing, content moderation, and healthcare demonstrate the methodology’s effectiveness and importance. By offering a concrete methodology for decolonizing AI, this paper contributes significantly to AI ethics and social justice, providing a roadmap for equitable, culturally respectful AI.",0.8412975668907166
95,excluded,10.1007/s43681-022-00232-x,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-022-00232-x,2023-11-01 00:00:00,all that glitters is not gold: trustworthy and ethical ai principles,"Ethics of technology systems have become an area of interest in academic research as well as international policy in recent years. Several organisation have consequently published principles of ethical artificial intelligence (AI) in line with this trend. The documents identify principles, values, and other abstract requirements for AI development and deployment. Critics raise concerns about whether these documents are in fact constructive, or if they are produced as a higher form of virtue signalling. A theme that is beginning to become apparent in the academic literature regarding these documents is the inherent lack of effective and practical methods and processes for producing ethical AI. This article attempts a critical analysis which draws upon ethical AI documents from a range of contexts including company, organisational, governmental, and academic perspectives. Both the theoretical and practical components of AI guidelines are explored and analysed, consequently bringing to light the necessity of introducing a measurable component to such documents for the purpose of ensuring a positive outcome of deploying AI systems based on ethical principles. We propose a minimal framework for stakeholders to develop AI in an ethical and human-centred manner.",0.8619669675827026
96,excluded,10.1007/s00146-022-01501-3,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01501-3,2023-06-01 00:00:00,the polyopticon: a diagram for urban artificial intelligences,"Smart city discourses often invoke the Panopticon, a disciplinary architecture designed by Jeremy Bentham and popularly theorized by Michel Foucault, as a model for understanding the social impact of AI technologies. This framing focuses attention almost exclusively on the negative ramifications of Urban AI, correlating ubiquitous surveillance, centralization, and data consolidation with AI development, and positioning technologies themselves as the driving factor shaping privacy, sociality, equity, access, and autonomy in the city. This paper describes an alternative diagram for Urban AI—the Polyopticon: a distributed, polyvalent, multi-modal network of synthetic intelligences. It posits that fourth industrial revolution technologies change the political, social, and psychodynamic relationships of sentience and witness in the city, shifting the effects of watching and watched beyond the exclusive domain of top-down surveillance and discipline. The Polyopticon poses a more expansive and ambivalent spectrum of possibilities for Urban AI scenarios, one that undermines the totalizing, singular, and cerebral notion of intelligence that so often characterizes Urban AI and smart city critiques.",0.833732008934021
97,excluded,10.1007/s00146-020-00960-w,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-020-00960-w,2020-12-01 00:00:00,"artificial intelligence, transparency, and public decision-making","The increasing use of Artificial Intelligence (AI) for making decisions in public affairs has sparked a lively debate on the benefits and potential harms of self-learning technologies, ranging from the hopes of fully informed and objectively taken decisions to fear for the destruction of mankind. To prevent the negative outcomes and to achieve accountable systems, many have argued that we need to open up the “black box” of AI decision-making and make it more transparent. Whereas this debate has primarily focused on how transparency can secure high-quality, fair, and reliable decisions, far less attention has been devoted to the role of transparency when it comes to how the general public come to perceive AI decision-making as legitimate and worthy of acceptance. Since relying on coercion is not only normatively problematic but also costly and highly inefficient, perceived legitimacy is fundamental to the democratic system. This paper discusses how transparency in and about AI decision-making can affect the public’s perception of the legitimacy of decisions and decision-makers and produce a framework for analyzing these questions. We argue that a limited form of transparency that focuses on providing justifications for decisions has the potential to provide sufficient ground for perceived legitimacy without producing the harms full transparency would bring.",0.8911622166633606
98,excluded,10.1007/s43681-024-00500-y,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-024-00500-y,2024-06-05 00:00:00,how to gain control and influence algorithms: contesting ai to find relevant reasons,"Relevancy is a prevalent term in value alignment. We either need to keep track of the relevant moral reasons, we need to embed the relevant values, or we need to learn from the relevant behaviour. What relevancy entails in particular cases, however, is often ill-defined. The reasons for this are obvious, it is hard to define relevancy in a way that is both general and concrete enough to give direction towards a specific implementation. In this paper, we describe the inherent difficulty that comes along with defining what is relevant to a particular situation. Simply due to design and the way an AI system functions, we need to state or learn particular goals and circumstances under which that goal is completed. However, because of both the changing nature of the world and the varied wielders and users of such implements, misalignment occurs, especially after a longer amount of time. We propose a way to counteract this by putting contestability front and centre throughout the lifecycle of an AI system, as it can provide insight into what is actually relevant at a particular instance. This allows designers to update the applications in such a manner that they can account for oversight during design.",0.821936845779419
99,excluded,10.48550/arxiv.2210.17218,Journal of Grid Computing,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/2afd1d3199326dc8a9184a5152616f5cfda1e2e6,2022-01-01 00:00:00,"artificial intelligence in government: concepts, standards, and a unified framework","Recent advances in artificial intelligence (AI), especially in generative language modelling, hold the promise of transforming government. Given the advanced capabilities of new AI systems, it is critical that these are embedded using standard operational procedures, clear epistemic criteria, and behave in alignment with the normative expectations of society. Scholars in multiple domains have subsequently begun to conceptualize the different forms that AI applications may take, highlighting both their potential benefits and pitfalls. However, the literature remains fragmented, with researchers in social science disciplines like public administration and political science, and the fast-moving fields of AI, ML, and robotics, all developing concepts in relative isolation. Although there are calls to formalize the emerging study of AI in government, a balanced account that captures the full depth of theoretical perspectives needed to understand the consequences of embedding AI into a public sector context is lacking. Here, we unify efforts across social and technical disciplines by first conducting an integrative literature review to identify and cluster 69 key terms that frequently co-occur in the multidisciplinary study of AI. We then build on the results of this bibliometric analysis to propose three new multifaceted concepts for understanding and analysing AI-based systems for government (AI-GOV) in a more unified way: (1) operational fitness, (2) epistemic alignment, and (3) normative divergence. Finally, we put these concepts to work by using them as dimensions in a conceptual typology of AI-GOV and connecting each with emerging AI technical measurement standards to encourage operationalization, foster cross-disciplinary dialogue, and stimulate debate among those aiming to rethink government with AI.",0.8791075944900513
100,excluded,10.1007/s44163-023-00060-w,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s44163-023-00060-w,2023-04-27 00:00:00,charting ai urbanism: conceptual sources and spatial implications of urban artificial intelligence,"The aim of this paper is to tease out some of the key issues concerning the relationship between AI and urbanism. This relationship, which is presented in the academic literature as a new driving force of contemporary urbanism, will be investigated through an interdisciplinary approach that places urban studies and philosophy of technology in dialogue. Thus, the analysis will not focus on the technological development of artificial intelligence systems but on how their application can affect urbanistic thinking and vice versa. The chart that is produced by this method is based on two fundamental axes: time and space. AI urbanism will then be inquired first through key turning points in the history of the relationship between technology and the city (modern urbanism, cybernetics and the smart city paradigm). Secondly, the spatial implications of urban AI will be investigated from the point of view of the concrete applications of this technology to the city (Robots, AVs, Software agents) and their impact on the relationships between different urban actors. Ultimately, this work aims to offer a conceptual tool for understanding some decisive implications of the relationship between AI and urbanism, such as the connection between quantitative and qualitative approaches, the implications related to autonomous technology, the economic-political background of AI urbanism, the material urban impact of AI, and the relationship between AI and other urban intelligences. Understanding these implications will be valuable for future research on AI urbanism oriented toward transforming simple technological development into sustainable urban innovations.",0.8053394556045532
101,excluded,10.1007/s00146-022-01589-7,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01589-7,2023-06-01 00:00:00,understanding citizen perceptions of ai in the smart city,"Artificial intelligence (AI) is embedded in a wide variety of Smart City applications and infrastructures, often without the citizens being aware of the nature of their “intelligence”. AI can affect citizens’ lives concretely, and thus, there may be uncertainty, concerns, or even fears related to AI. To build acceptable futures of Smart Cities with AI-enabled functionalities, the Human-Centered AI (HCAI) approach offers a relevant framework for understanding citizen perceptions. However, only a few studies have focused on clarifying the citizen perceptions of AI in the context of smart city research. To address this gap, we conducted a two-phased study. In the pre-study, we explored citizen perceptions and experiences of AI with a short survey ( N  = 91). Second, scenario-based interviews ( N  = 7) were utilized to gain in-depth insights of citizen perceptions of AI in the Smart City context. Five central themes were recognized: (1) I don’t like them monitoring me, (2) I want maximum gain for minimum effort, (3) I don’t want AI to mimic people, (4) I’ll avoid using AI if I consider the risk too high, and (5) I don’t need to be concerned about AI. These offer an idea of human-centered requirements worth considering while designing AI applications for future Smart Cities.",0.8647138476371765
102,included,10.1007/s13162-024-00275-9,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s13162-024-00275-9,2024-06-01 00:00:00,a theoretical framework to guide ai ethical decision making,"Artificial Intelligence (AI) ethics is needed to address the risks that are outpacing efforts to protect consumers and society. AI is becoming human-competitive with the ability to perform tasks, that without controls, can result in harmful or destructive actions. Principles are currently the most discussed ethical approach for pervasive boundaries for algorithmic rule-based intelligence. Principles, values, norms, and rules should be the foundation of an ethical corporate culture with all participants aware of and involved in developing AI ethics. To address these concerns, a theory-based decision framework is presented to incorporate ethical considerations into AI applications. With limited discussion on frameworks to manage AI ethics, we provide a modification of the Hunt–Vitell (H–V) ethical decision model to provide a supportive theoretical framework. This model considers the cultural, industry, organizational, and legal standards that shape AI ethical decision making. The model is based on individual decision making and parallels the decision process in autonomous AI system decision making. Topics for additional research are advanced to create expanded knowledge on this topic.",0.8691652417182922
103,excluded,10.1007/s10551-022-05050-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s10551-022-05050-z,2022-07-01 00:00:00,the dawn of the ai robots: towards a new framework of ai robot accountability,"Business, management, and business ethics literature pay little attention to the topic of AI robots. The broad spectrum of potential ethical issues pertains to using driverless cars, AI robots in care homes, and in the military, such as Lethal Autonomous Weapon Systems. However, there is a scarcity of in-depth theoretical, methodological, or empirical studies that address these ethical issues, for instance, the impact of morality and where accountability resides in AI robots’ use. To address this dearth, this study offers a conceptual framework that interpretively develops the ethical implications of AI robot applications, drawing on descriptive and normative ethical theory. The new framework elaborates on how the locus of morality (human to AI agency) and moral intensity combine within context-specific AI robot applications, and how this might influence accountability thinking. Our theorization indicates that in situations of escalating AI agency and situational moral intensity, accountability is widely dispersed between actors and institutions. ‘Accountability clusters’ are outlined to illustrate interrelationships between the locus of morality, moral intensity, and accountability and how these invoke different categorical responses: (i) illegal, (ii) immoral, (iii) permissible, and (iv) supererogatory pertaining to using AI robots. These enable discussion of the ethical implications of using AI robots, and associated accountability challenges for a constellation of actors—from designer, individual/organizational users to the normative and regulative approaches of industrial/governmental bodies and intergovernmental regimes.",0.801902711391449
104,excluded,10.1007/s43681-024-00569-5,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-024-00569-5,2024-09-23 00:00:00,"ai governance systems: a multi-scale analysis framework, empirical findings, and future directions","The governance of artificial intelligence (AI) has recently emerged as a field of research and practice, but the structural and functional components of AI governance (AIG) systems are not well understood by researchers and practitioners. To address that gap, we apply service system analysis methods and thematic analysis methods to develop a novel framework for conceptualizing and analyzing AI governance systems across multiple scales of activity, including international, national, subnational, sectoral, and organizational systems of governance. We apply our analysis framework to an empirical study of Canada’s national AIG system. Drawing upon qualitative data collected from 20 leaders of Canadian AIG initiatives and subject matter experts, we identify and discuss the actors, impacts, resources, networks, activities, logics, norms, and rules involved in structuring and operating a national AIG system, using Canada as a case study. Based on our findings, we propose three directions for future research: (1) conduct additional analysis of the 610 topics in our dataset, (2) further investigate institutional and ecosystem-level structures and dynamics in Canada’s national AIG system, (3) apply our framework, data, and findings to study AIG systems in other contexts. We also outline four strategic objectives for strengthening Canada’s AIG system: (1) implement new collaboration and coordination mechanisms, (2) create guidance for designing and implementing participatory AIG initiatives, (3) expand access to key resources needed for effective AIG practices, (4) advance diversity, equity, and inclusion in AIG activities.",0.8795304298400879
105,excluded,10.1007/s43681-023-00327-z,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s43681-023-00327-z,2023-08-30 00:00:00,when things go wrong: the recall of ai systems as a last resort for ethical and lawful ai,"This paper presents an initial exploration of the concept of AI system recall, primarily understood as a last resort when AI systems violate ethical norms, societal expectations, or legal obligations. The discussion is spurred by recent incidents involving notable AI systems, demonstrating that AI recalls can be a very real necessity. This study delves into the concept of product recall as traditionally understood in industry and explores its potential application to AI systems. Our analysis of this concept is centered around two prominent categories of recall drivers in the AI domain: ethical-social and legal considerations. In terms of ethical-social drivers, we apply the innovative notion of “moral Operational Design Domain”, suggesting AI systems should be recalled when they violate ethical principles and societal expectation. In addition, we also explore the recall of AI systems from a legal perspective, where the recently proposed AI Act provides regulatory measures for recalling AI systems that pose risks to health, safety, and fundamental rights. The paper also underscores the need for further research, especially around defining precise ethical and societal triggers for AI recalls, creating an efficient recall management framework for organizations, and reassessing the fit of traditional product recall models for AI systems within the AI Act's regulatory context. By probing these complex intersections between AI, ethics, and regulation, this work aims to contribute to the development of robust and responsible AI systems while maintaining readiness for failure scenarios.",0.8103897571563721
106,excluded,10.59476/ilpmt2024.100-106,"Innovations in Publishing, Printing and Multimedia Technologies",semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/2d88f0f218151f6f38f3888024ccff9e8c3ed0f7,2000-01-01 00:00:00,criteria for selecting artificial intelligence tools,"Artificial Intelligence (AI) represents a transformative force across numerous sectors, from healthcare and finance to automotive and public services. The selection and deployment of AI tools are critical to leveraging this technology’s potential while adhering to ethical standards, regulatory compliance, and ensuring societal benefit. The European Union (EU) has been at the forefront of establishing frameworks and criteria to guide the development, deployment, and selection of AI systems to foster innovation while protecting citizens’ rights and societal values. The EU’s proactive stance in establishing these criteria aims to balance innovation with ethical considerations and societal welfare, setting a benchmark for responsible AI development and deployment globally. The aim of the article is to present general criteria for the selection of artificial intelligence tools, as well as those specific to the field of publishing. The research was carried out based on the analysis of scientific and other sources. The results of the study can be useful for organizations and individuals that must be interested in selecting and using the right AI tools.",0.8998204469680786
107,excluded,10.1109/icccis60361.2023.10425428,IEEE,ieeexplore,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://ieeexplore.ieee.org/document/10425428/,2023-11-04 00:00:00,modelling the domains of artificial intelligence on social good: a study on analytic-based hierarchy,"AI is the technology that has transformed many industries and various sectors which include healthcare, finance education, agriculture etc. The purpose of this study is to explore the impact of AI on social good. More specifically, this research prioritizes the domains and subdomains of AI. Initially, the literature has been extensively reviewed to identify the uncharted implications of AI. To conduct the study authors have adopted the secondary research and a theoretical model has been developed to prioritize the domains at the time of contingency; for that purpose, an Analytical Hierarchical Process, a tool of MCDM, is used. The findings of the study concluded with a theoretical model presenting the rankings and maximum global weights. The current study has been conducted in the Indian context. Therefore, this can be considered as a limitation of research. Current study significantly contributes to the body of literature in this field and presents a hierarchical model of artificial intelligence domains and sub domains impacting social good.",0.8315266370773315
108,excluded,10.1145/3322640.3326722,International Conference on Artificial Intelligence and Law,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/b4fcc459433d2fc35b0214f81a2145bcbc74fe5f,2019-01-01 00:00:00,artificial intelligence and law: what do people really want?: example of a french multidisciplinary working group,"This paper addresses issues related to the ethical consequences of using AI technologies in court decisions. With the prodigious technological leap made in the field of artificial intelligence in recent years, disruptive innovations have affected many business sectors, with economic, social and ethical consequences. But what do people really want about the application of artificial intelligence technologies in the law system? This article presents a general methodological approach to take into account the ethical aspect of the introduction of a new technology in a given domain. We apply this methodology in the specific case of the introduction of AI technologies in the law system. As a multidisciplinary working group interested in this application in the case of France, we have organized a series of workshops to discuss this topic and highlight the respective values and interests of each stakeholder. The result of this work in presented in the form of an ethical matrix that can be used as a tool by the public authorities to help decision-making on the subject with a prioritization of certain values in order to reflect the respect for fundamental rights.",0.838420569896698
109,excluded,10.1007/s00146-022-01453-8,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01453-8,2023-04-01 00:00:00,a principle-based approach to ai: the case for european union and italy,"As Artificial Intelligence (AI) becomes more and more pervasive in our everyday life, new questions arise about its ethical and social impacts. Such issues concern all stakeholders involved in or committed to the design, implementation, deployment, and use of the technology. The present document addresses these preoccupations by introducing and discussing a set of practical obligations and recommendations for the development of applications and systems based on AI techniques. With this work we hope to contribute to spreading awareness on the many social challenges posed by AI and encouraging the establishment of good practices throughout the relevant social areas. As points of novelty, the paper elaborates on an integrated view that combines both human rights and ethical concepts to reap the benefits of the two approaches. Moreover, it proposes innovative recommendations, such as those on redress and governance, which add further insight to the debate. Finally, it incorporates a specific focus on the Italian Constitution, thus offering an example of how core legislations of Member States might contribute to further specify and enrich the EU normative framework on AI.",0.8925737738609314
110,excluded,10.1007/s10796-024-10475-0,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s10796-024-10475-0,2024-02-21 00:00:00,making sense of ai benefits: a mixed-method study in canadian public administration,"Public administrators receive conflicting signals on the transformative benefits of Artificial Intelligence (AI) and the counternarratives of AI’s ethical impacts on society and democracy. Against this backdrop, this paper explores the factors that affect the sensemaking of AI benefits in Canadian public administration. A mixed-method research design using PLS-SEM ( n  = 272) and interviews ( n  = 38) tests and explains the effect of institutional and consultant pressures on the perceived benefits of AI use. The quantitative study shows only service coercive pressures have a significant effect on perceived benefits of AI use and consultant pressures are significant in generating all institutional pressures. The qualitative study explains the results and highlights the underlying mechanisms. The key conclusion is that in the earlier stages of AI adoption, demand pull is the main driver rather than technology push. A processual sensemaking model is developed extending the theory on institutions and sensemaking. And several managerial implications are discussed.",0.8617125749588013
111,excluded,10.3233/ip-200249,Inf. Polity,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/8d03df21807637482739cbfe140b260aa8f1907b,2020-01-01 00:00:00,administration by algorithm: a risk management framework,"Algorithmic decision-making is neither a recent phenomenon nor one necessarily associated with artificial intelligence (AI), though advances in AI are increasingly resulting in what were heretofore human decisions being taken over by, or becoming dependent on, algorithms and technologies like machine learning. Such developments promise many potential benefits, but are not without certain risks. These risks are not always well understood. It is not just a question of machines making mistakes; it is the embedding of values, biases and prejudices in software which can discriminate against both individuals and groups in society. Such biases are often hard either to detect or prove, particularly where there are problems with transparency and accountability and where such systems are outsourced to the private sector. Consequently, being able to detect and categorise these risks is essential in order to develop a systematic and calibrated response. This paper proposes a simple taxonomy of decision-making algorithms in the public sector and uses this to build a risk management framework with a number of components including an accountability structure and regulatory governance. This framework is designed to assist scholars and practitioners interested in ensuring structured accountability and legal regulation of AI in the public sphere.",0.821026086807251
112,excluded,10.3390/su16177724,Sustainability,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/eced54e0bfcf41cbad64157ed5683138764a2d2c,2000-01-01 00:00:00,procurement of artificial intelligence systems in uae public sectors: an interpretive structural modeling of critical success factors,"This study investigates the critical success factors (CSFs) influencing the procurement of artificial intelligence (AI) systems within the United Arab Emirates (UAE) public sector. While AI holds immense potential to enhance public service delivery, its successful integration hinges on critical factors. This research utilizes Interpretive Structural Modeling (ISM) to analyze the CSFs impacting AI procurement within the UAE public sector. Through ISM, a structural model is developed to highlight the interrelationships between these CSFs and their influence on the procurement process, outlining the key elements for successful AI procurement within the UAE public sector. Based on the literature review and expert validation from the UAE public sector, ten CSFs were identified. This study found that clear needs assessment is the most influential CSF, while the long-term value of AI systems or services is the least influential. This study provides policymakers and public sector leaders with valuable insights, enabling them to formulate effective strategies to optimize the procurement process and establish a strong foundation for AI adoption. Finally, this will lead to an improved and more efficient public service delivery in the UAE.",0.8262103796005249
113,included,10.1007/s00146-022-01458-3,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-022-01458-3,2023-04-01 00:00:00,"ethical artificial intelligence framework for a good ai society: principles, opportunities and perils","The justification and rationality of this paper is to present some fundamental principles, theories, and concepts that we believe moulds the nucleus of a good artificial intelligence (AI) society. The morally accepted significance and utilitarian concerns that stems from the inception and realisation of an AI’s structural foundation are displayed in this study. This paper scrutinises the structural foundation, fundamentals, and cardinal righteous remonstrations, as well as the gaps in mechanisms towards novel prospects and perils in determining resilient fundamentals, accountability, and AI’s convoluted and responsible implications. We outline a number of salient and practical benefits, in which to place moral norms within the mise en scène of AI, to delineate the rudimentary ethical dilemmas and decorous directions within the realms of AI.",0.8412108421325684
114,excluded,10.1108/tg-01-2024-0006,"Transforming Government: People, Process and Policy",semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',https://www.semanticscholar.org/paper/efca4ec65048fae6d934f3c17dc70aa6803555a8,2000-01-01 00:00:00,unlocking the power and future potential of generative ai in government transformation,"
Purpose
This paper aims to investigate whether the implementation of generative artificial intelligence (GAI) impacts government functionality. The study will analyse GAI’s positive attributes across different dimensions to comprehensively understand its value proposition for public organisations. Furthermore, the paper will outline the strategic interventions required to integrate GAI effectively within the organisational context of government transformation.


Design/methodology/approach
This study measures “government functionality” and “GAI implementation” using abstract macro variables as a second-order formative model. It also includes first-order measurable micro-variables to better understand the concept. In addition, the study introduces “organisational context” as a moderating factor to explain the complex dynamics of integrating GAI to improve government functionality. The study proposes a conceptual framework, which was analysed using exploratory data analysis, with primary data collected through questionnaires.


Findings
The study finds a positive correlation between the implementation of GAI and improved government functionality. Furthermore, it found that organisational contextualisation significantly moderates this relationship. All the empirical outcomes align with the prescribed statistical thresholds, concluding that the articulated conceptual framework holds significance.


Research limitations/implications
The study has significant implications for managers, researchers and anyone involved in making, implementing or evaluating decisions related to digital government through GAI. However, the study has limitations, including a limited sample size and contextualisation of the Indian public sector.


Originality/value
The study contributes to existing knowledge by showing that implementing GAI positively correlates with improving government functionality. It further highlights the significance of GAI implementation according to the specific organisational context.
",0.8331549167633057
115,excluded,10.1007/s00146-020-01130-8,Springer,springer,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://dx.doi.org/10.1007/s00146-020-01130-8,2021-09-01 00:00:00,making the black box society transparent,"The growing presence of smart devices in our lives turns all of society into something largely unknown to us. The strategy of demanding transparency stems from the desire to reduce the ignorance to which this automated society seems to condemn us. An evaluation of this strategy first requires that we distinguish the different types of non-transparency. Once we reveal the limits of the transparency needed to confront these devices, the article examines the alternative strategy of explainable artificial intelligence and concludes with the idea that these types of complex realities exceed individual capacities and are only comprehensible in a collective fashion.",0.81824791431427
116,included,http://arxiv.org/abs/1906.05684v1,arxiv,arxiv,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',http://arxiv.org/abs/1906.05684v1,6/11/2019 0:00,understanding artificial intelligence ethics and safety,"A remarkable time of human promise has been ushered in by the convergence of
the ever-expanding availability of big data, the soaring speed and stretch of
cloud computing platforms, and the advancement of increasingly sophisticated
machine learning algorithms. Innovations in AI are already leaving a mark on
government by improving the provision of essential social goods and services
from healthcare, education, and transportation to food supply, energy, and
environmental management. These bounties are likely just the start. The
prospect that progress in AI will help government to confront some of its most
urgent challenges is exciting, but legitimate worries abound. As with any new
and rapidly evolving technology, a steep learning curve means that mistakes and
miscalculations will be made and that both unanticipated and harmful impacts
will occur.
  This guide, written for department and delivery leads in the UK public sector
and adopted by the British Government in its publication, 'Using AI in the
Public Sector,' identifies the potential harms caused by AI systems and
proposes concrete, operationalisable measures to counteract them. It stresses
that public sector organisations can anticipate and prevent these potential
harms by stewarding a culture of responsible innovation and by putting in place
governance processes that support the design and implementation of ethical,
fair, and safe AI systems. It also highlights the need for algorithmically
supported outcomes to be interpretable by their users and made understandable
to decision subjects in clear, non-technical, and accessible ways. Finally, it
builds out a vision of human-centred and context-sensitive implementation that
gives a central role to communication, evidence-based reasoning, situational
awareness, and moral justifiability.",0.873350501
