id,status,doi,publisher,database,query_name,query_value,url,publication_date,title,abstract,semantic_score
1,included,0ef4f7572bb6a7321de2841245946f6151efb839,,semantic_scholar,citation,citation,https://www.semanticscholar.org/paper/0ef4f7572bb6a7321de2841245946f6151efb839,,managing ethical risks of artiﬁcial intelligence in business applications,"The introduction of artiﬁcial intelligence (AI) capabilities in business applications provides signiﬁcant beneﬁts but requires organizations to manage critical risks of AI ethical consequences. We survey a range of large organizations on their use of enterprise risk management (ERM) processes and toolsets to predict and control the ethical risks of AI. Four serious gaps in current ERM systems are identiﬁed from analyses of the survey results: (1) AI ethical principles do not translate eﬀectively to ethical practices; (2) Real-time monitoring of AI ethical risks is needed; (3) ERM systems emphasize economic not ethical risks; and (4) When ethical risks are identiﬁed, no solutions are readily at hand. To address these gaps, we propose a proactive approach to manage ethical risks by extending current ERM frameworks. An enhanced ERM (e-ERM) framework is designed and evaluated by subject matter expert focus groups. We conclude with observations and future research directions on the need for more aggressive pro-ethical management oversight as organizations move to ubiquitous use of AI-driven business applications.",0.8062968552112579
2,included,4f4a2f5c9e1519db0c64e8cd2fb015ea5e3e4d0b,Future Internet,semantic_scholar,citation,citation,https://www.semanticscholar.org/paper/4f4a2f5c9e1519db0c64e8cd2fb015ea5e3e4d0b,2025.0,high-risk ai systems—lie detection application,"Integrating artificial intelligence into border control systems may help to strengthen security and make operations more efficient. For example, the emerging application of artificial intelligence for lie detection when inspecting passengers presents significant opportunities for future implementation. However, as it makes use of technology that is associated with artificial intelligence, the system is classified as high risk, in accordance with the EU AI Act and, therefore, must adhere to rigorous regulatory requirements to mitigate potential risks. This manuscript distinctly amalgamates the technical, ethical, and legal aspects, thereby offering an extensive examination of the AI-based lie detection systems utilized in border security. This academic paper is uniquely set apart from others because it undertakes a thorough investigation into the categorization of these emerging technologies in terms of the regulatory framework established by the EU AI Act, which classifies them as high risk. It further makes an assessment of practical case studies, including notable examples such as iBorderCtrl and AVATAR. This in-depth analysis seeks to emphasize not only the enormous challenges ahead for practitioners but also the progress made in this emerging field of study. Furthermore, it seeks to investigate threats, vulnerabilities, and privacy concerns associated with AI, while providing security controls to address difficulties related to lie detection. Finally, we propose a framework that encompasses the EU AI Act’s principles and serves as a foundation for future approaches and research projects. By analyzing current methodologies and considering future directions, the paper aims to provide a comprehensive understanding of the viability and consequences of deploying AI lie detection capabilities in border control.",0.8043087244033813
3,included,37730b6bc3fe8c5655780efba083c8401808acaf,arXiv.org,semantic_scholar,citation,citation,https://www.semanticscholar.org/paper/37730b6bc3fe8c5655780efba083c8401808acaf,2022.0,putting ai ethics into practice: the hourglass model of organizational ai governance,"The organizational use of artificial intelligence (AI) has rapidly spread across various sectors. Alongside the awareness of the benefits brought by AI, there is a growing consensus on the necessity of tackling the risks and potential harms, such as bias and discrimination, brought about by advanced AI technologies. A multitude of AI ethics principles have been proposed to tackle these risks, but the outlines of organizational processes and practices for ensuring socially responsible AI development are in a nascent state. To address the paucity of comprehensive governance models, we present an AI governance framework, the hourglass model of organizational AI governance, which targets organizations that develop and use AI systems. The framework is designed to help organizations deploying AI systems translate ethical AI principles into practice and align their AI systems and processes with the forthcoming European AI Act. The hourglass framework includes governance requirements at the environmental, organizational, and AI system levels. At the AI system level, we connect governance requirements to AI system life cycles to ensure governance throughout the system's life span. The governance model highlights the systemic nature of AI governance and opens new research avenues into its practical implementation, the mechanisms that connect different AI governance layers, and the dynamics between the AI governance actors. The model also offers a starting point for organizational decision-makers to consider the governance components needed to ensure social acceptability, mitigate risks, and realize the potential of AI.",0.8546511858701706
