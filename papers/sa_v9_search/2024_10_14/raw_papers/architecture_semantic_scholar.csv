paperId,url,title,abstract,venue,year,database,query_name,query_value,externalIds.DOI
40d15d05ca46245cb5e33a391e7892c3fe2bfc68,https://www.semanticscholar.org/paper/40d15d05ca46245cb5e33a391e7892c3fe2bfc68,position paper: rational behavior model (rbm) and human-robot ethical constraints using mission execution ontology (meo),"Autonomous systems can be ethically supervised by humans without constant communications. Adding constraints such as no-fly zones, time limitations, permission prerequisites etc. to mission orders allows operators to legally and ethically control mobile systems that have the potential for deliberate (or unintentional) lethal force. Ethical control can be practically achieved by providing parsable (and ethically validatable) orders to diverse unmanned systems. Ethical Control of Unmanned Systems The authors have been engaged for several decades in academic research and military service relating to mission specification and execution for submarines, aircraft, and ground vehicles, both manned and robotic. We have increasingly focused on maritime robotics, especially with regard to execution of unmanned underwater vehicle missions under varying degrees of human oversight and ethical constraints. This work has included numerous simulations and also deployed experiments (Brutzman et al. 1998; Brutzman, McGhee, and Davis 2012; Brutzman, Davis, Blais, and McGhee 2016). Common conclusions that treat ethical robots as an always-amoral philosophical conundrum or requiring undemonstrated morality-based artificial intelligence (AI) are simply not sensible or repeatable. For better or worse, actors around the world are rapidly designing and deploying mobile unmanned systems to augment human capabilities. Thus theory must meet practice. This contribution describes how mission orders can be specified in forms readable by both human operators and robot systems, including both syntactic validation of correctness and semantic validation of logical coherence. This approach has the potential to meet the moral requirements of international laws regarding human responsibility during armed conflict when unmanned systems are deployed. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. The path to reach our present point of view has come from understanding that the Rational Behavior Model (RBM) software architecture used in our work has broader applicability than previously realized. This is because RBM depends upon a software construct called a Mission Execution Automaton (MEA) that is an extension of a Turing machine (TM) allowing the incorporation of arbitrary external agents. Such agents are presumed to be capable of interaction with their environment and returning one of a predetermined set of values to the finite state machine (FSM) portion of the MEA. Ternary logic is helpful, where allowable values returned from a query/command to an external agent have been limited to the set [success, failure, constraint]. Applied to a multiphase mission, concise mission-branch definition simplifies execution logic needed by remote systems. When a value constraint is returned, it can be taken to mean either that the current environment makes it unethical to complete the current phase, that a phase timeout has occurred, or that success or failure of the current phase cannot be determined, etc. Exception-handling steps can then occur. Recent work has reached the next level, defining a Mission Execution Ontology (MEO) implemented in RDF/OWL that relates mission goals, task prerequisites and operating constraints with vehicle capabilities. MEO validation can be performed as part of tasking robotic or human external agents. This means that humanunderstandable orders to unmanned systems can further be semantically validated for logical correctness, ensuring that tasking of remote systems meets the same level of ethical rigor expected in human-to human orders. Confirmed validation makes authority meaningful for responsible humans. In three-level robot architectures such as RBM, existing vehicle commands/missions can be incorporated as behaviors subject to overall regulation by rational (finite state) supervision of a mission-definition graph. Such tasking can be understood by qualified humans who are not computer professionals, much in the same way that military mission orders written in structured human language are understandable. Well-specified definitions of mission tasks and constraints can also be performed by a wide variety of diverse robot control code. With such a common understanding, it is possible to assign legal and moral responsibility for correct and ethical mission definition to a single (legally culpable) human individual. We believe that this kind of strong accountability is essential to military accountability, and may eventually become relevant for emerging robotic technologies affecting public safety. Algorithms cannot replace human responsibility. Even so, a fully testable technology (such as that provided by the MEA and MEO formalisms) allows for the assignment of human accountability. Specifically, the MEA provides a mathematically rigorous mechanism for mission definition and execution as an exhaustively testable flow diagram. This approach ensures that accountable operators can fully understand all high-level task sequences before authorizing robot operations. The MEO employs description logics (DLs) and Semantic Web technologies to provide strong assurances that MEA mission definitions are semantically correct and fully executable by specific target vehicles. By applying the best strengths of human ethical responsibility, repeatable formal logic and directable unmanned systems together, these capabilities provide a practical framework for ethically grounded human supervision of unmanned systems.",AAAI Fall Symposia,2017,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',
9dacbc65c23215f79a9a966abf8c403175e56aa8,https://www.semanticscholar.org/paper/9dacbc65c23215f79a9a966abf8c403175e56aa8,societal impact of data science and artificial intelligence,"The explosion of interest in KDD and other Data Science/Machine Learning/AI conferences is just one of the many signs that these technologies are no longer confined to the realms of academia and a hand-full of tech companies. As our daily lives seamlessly integrate more and more data-driven applications, people's excitement is tempered by worry about the technologies' potential to disrupt their existence. Having worked for almost 30 years to design and develop these technologies, the KDD community now should examine and debate the impact of Machine Learning & AI on the broader world. Beyond the hype, where do we stand with respect to the dangers? What role can our community play to alleviate concerns around AI taking jobs, or taking over? How can the value derived from data be distributed fairly? Are concerns about inequity well-founded or rather largely problems of perception? What can be done to bring data hunger and data sharing concerns to a level of equilibrium? How do we prepare people to interact with intelligent systems at scale? Can we unleash the incredible responsiveness of the KDD community toward longer-term more impactful projects across sectors that are essential for social good, such as Health, Environmental Sustainability, and Public Welfare.",Knowledge Discovery and Data Mining,2018,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3219819.3226071
2eedf3d19edacc862bf7ab324a74172bb35a14e1,https://www.semanticscholar.org/paper/2eedf3d19edacc862bf7ab324a74172bb35a14e1,"big data and ai – a transformational shift for government: so, what next for research?","Big Data and artificial intelligence will have a profound transformational impact on governments around the world. Thus, it is important for scholars to provide a useful analysis on the topic to public managers and policymakers. This study offers an in-depth review of the Policy and Administration literature on the role of Big Data and advanced analytics in the public sector. It provides an overview of the key themes in the research field, namely the application and benefits of Big Data throughout the policy process, and challenges to its adoption and the resulting implications for the public sector. It is argued that research on the subject is still nascent and more should be done to ensure that the theory adds real value to practitioners. A critical assessment of the strengths and limitations of the existing literature is developed, and a future research agenda to address these gaps and enrich our understanding of the topic is proposed.",Public Policy and Administration,2018,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/0952076718780537
97bb2019d50fbd3694279ab837c6f68d6ed9ad84,https://www.semanticscholar.org/paper/97bb2019d50fbd3694279ab837c6f68d6ed9ad84,a review of artificial intelligence in government and its potential from a public policy perspective,"Artificial intelligence (AI) is the latest trend being implemented in the public sector. Recent advances in this field and the AI explosion in the private sector have served to promote a revolution for government, public service management, accountability, and public value. Incipient research to understand, conceptualize and express challenges and limitations is now ongoing. This paper is the first approach in such a direction; our research question is: What are the current AI trends in the public sector? In order to achieve that goal, we collected 78 papers related to this new field in recent years. We also used a public policy framework to identify future areas of implementation for this trend. We found that only normative and exploratory papers have been published so far and there are a lot of public policy challenges facing in this area, and that AI implementation results are unknown and unexpected; since there may be great benefits for governments and society, but, on the other hand, it may have negative results like the so-called ”algorithmic bias” of AI when making important decisions for social development. However, we consider that AI has potential benefits in the public health, public policies on climate change, public management, decision-making, disaster prevention and response, improving government-citizen interaction, personalization of services, interoperability, analyzing large amounts of data, detecting abnormalities and patterns, and discovering new solutions through dynamic models and simulation in real time.",Digital Government Research,2019,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3325112.3325242
ed5fbb58585ae1e9154ade1b4639060ace9c45ec,https://www.semanticscholar.org/paper/ed5fbb58585ae1e9154ade1b4639060ace9c45ec,a realist perspective on ai-era public management*,"Recent years have witnessed a number of significant ideas and approaches to addressing the shortcomings of the New Public Management paradigm. Three of these recent ideas, which include Digital Era Governance, Public Value Management, and New Public Governance, emphasise partnerships collaboration and engagement of citizens; performance governance and innovation and recognize the transformational potentials of digital technologies. Artificial Intelligence (AI) is one of the digital technologies attracting the greatest interest in public administration in terms of its potential impact. There are already a number of reports on how AI is being deployed in the public sector with good outcomes. By employing a realist review approach, this study investigates the specific mechanisms across post-NPM, organisational, individual and innovation contexts which are associated with positive outcomes from AI initiatives in the public sector. The study further examined the specific applications of AI initiatives within Post-NPM agendas. Our findings provide some empirical evidence for a better understanding of the conditions and where to target AI-based solutions in post-NPM context for positive outcomes.",Digital Government Research,2019,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3325112.3325261
9eacf62f1e546748428c7e4843731b1595294200,https://www.semanticscholar.org/paper/9eacf62f1e546748428c7e4843731b1595294200,the data firehose and ai in government: why data management is a key to value and ethics,"Technical and organizational innovations such as Open Data, Internet of Things and Big Data have fueled renewed interest in policy analytics in the public sector. This revamped version of policy analysis continues the long-standing tradition of applying statistical modeling to better understand policy effects and decision making, but also incorporates other computational approaches such as artificial intelligence (AI) and computer simulation. Although much attention has been given to the development of capabilities for data analysis, there is much less attention to understanding the role of data management in a context of AI in government. In this paper, we argue that data management capabilities are foundational to data analysis of any kind, but even more important in the present AI context. This is so because without proper data management, simply acquiring data or systems will not produce desired outcomes. We also argue that realizing the potential of AI for social good relies on investments specifically focused on this social outcome, investments in the processes of building trust in government data, and ensuring the data are ready and suitable for use, for both immediate and future uses.",Digital Government Research,2019,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3325112.3325245
b4fcc459433d2fc35b0214f81a2145bcbc74fe5f,https://www.semanticscholar.org/paper/b4fcc459433d2fc35b0214f81a2145bcbc74fe5f,artificial intelligence and law: what do people really want?: example of a french multidisciplinary working group,"This paper addresses issues related to the ethical consequences of using AI technologies in court decisions. With the prodigious technological leap made in the field of artificial intelligence in recent years, disruptive innovations have affected many business sectors, with economic, social and ethical consequences. But what do people really want about the application of artificial intelligence technologies in the law system? This article presents a general methodological approach to take into account the ethical aspect of the introduction of a new technology in a given domain. We apply this methodology in the specific case of the introduction of AI technologies in the law system. As a multidisciplinary working group interested in this application in the case of France, we have organized a series of workshops to discuss this topic and highlight the respective values and interests of each stakeholder. The result of this work in presented in the form of an ethical matrix that can be used as a tool by the public authorities to help decision-making on the subject with a prioritization of certain values in order to reflect the respect for fundamental rights.",International Conference on Artificial Intelligence and Law,2019,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3322640.3326722
28b167de9fd1443bfd7c186550909880765a3470,https://www.semanticscholar.org/paper/28b167de9fd1443bfd7c186550909880765a3470,an overview of deep learning in the field of dentistry,"Purpose Artificial intelligence (AI), represented by deep learning, can be used for real-life problems and is applied across all sectors of society including medical and dental field. The purpose of this study is to review articles about deep learning that were applied to the field of oral and maxillofacial radiology. Materials and Methods A systematic review was performed using Pubmed, Scopus, and IEEE explore databases to identify articles using deep learning in English literature. The variables from 25 articles included network architecture, number of training data, evaluation result, pros and cons, study object and imaging modality. Results Convolutional Neural network (CNN) was used as a main network component. The number of published paper and training datasets tended to increase, dealing with various field of dentistry. Conclusion Dental public datasets need to be constructed and data standardization is necessary for clinical application of deep learning in dental field.",Imaging Science in Dentistry,2019,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.5624/isd.2019.49.1.1
3d863678d53ef04773b3e6052995b85db1903e28,https://www.semanticscholar.org/paper/3d863678d53ef04773b3e6052995b85db1903e28,intelligent solutions - based framework for digital public services. a case study for smart transportation,"Digital technology landscape is continuously improving, dragging along both the transformation of public services and new demands of citizens. Emerging new technologies like Artificial Intelligence, Machine Learning, Deep Learning or Internet of Things provide tremendous means to implement intelligent solutions for reshaping digital public services. This paper aims to disclose the most important features of several intelligent technologies and of these types of public services that can be integrated for providing new capabilities. An AI-based architecture for supporting digital public services in the smart transportation sector is presented in order to demonstrate the highlighted ideas and concepts.",European Conference on Artificial Intelligence,2019,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/ECAI46879.2019.9042157
c4a51fe5e1993e1a068eda83a98ce2ea54823253,https://www.semanticscholar.org/paper/c4a51fe5e1993e1a068eda83a98ce2ea54823253,prediction of real estate prices in california,"The talk will present our efforts over the past year and a half to launch a start-up for US real estate valuation. The start-up called Babcock & Bonbright was built as part of the Central Europe AI portfolio – a start-up studio focused on using artificial intelligence to innovate in the financial and healthcare sectors. The presentation will focus mainly on the technological aspect of the project – linking structured data, NLP, and image processing to a comprehensive system for estimating the value of dwellings and apartments using machine learning. Attention will also be paid to the processing of map data, system architecture and data pipeline design. Our pricing models leverage several types of machine learning models in a hierarchical manner. For the pricing estimation, we use socalled “comparables” – recently sold houses that are close and somewhat similar (comparable) to the subject property. The main pricing model is used to compute the adjusted price for each comparable in the neighborhood using gradient boosted decision trees. The comparables are selected by location, feature similarity and image similarity. The pricing model uses features from both the subject property and comparable property, as well as combined features such as distance, image similarity, ratios of selected original features, common categorical features, common points of interest in the area, etc. The final price estimation for the subject property is determined by averaging price adjustments across all of the comparables. Bulk of the features are created from structured and semi-structured data about the property – public sale records, offers listings, map and traffic data, school districts, and crime. The text description of the property from the agent/broker listing is also analyzed. Sentiment is extracted by a pretrained sentiment neuron model and rule-based Copyright c ©2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Conference on Theory and Practice of Information Technologies,2019,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',
5bca0d47912b214890e9ca6ee7a76f4deb8de815,https://www.semanticscholar.org/paper/5bca0d47912b214890e9ca6ee7a76f4deb8de815,artificial intelligence in government,"The articles in this special section focus on government applications that use artificial intelligence (AI). The repercussions of artificial intelligence (AI) in government are broad and significant. The characteristics of these technologies will have an impact on almost everything in public organizations, from governance or the multidimensional perspective of interoperability, to the organizational or social implications linked to concepts like public value, transparency, or accountability. This special issue seeks to shed light on foundations and key elements to be taken into account for AI adoption by public organizations. Governments are the primary enablers of technology and market stimulators and regulators of general activities in our society. Governments have always sought the common good and, therefore, the advancement of public and collective interests. This is key to understanding, as a first step, why the principles of public-sector organizations do not always match those of the private sector. Public and private perspectives are very different, whether they be management, strategy, or policy.",Computer,2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/MC.2020.3010043
9ff0d4638306c8f7165d94d94113221a03c748d6,https://www.semanticscholar.org/paper/9ff0d4638306c8f7165d94d94113221a03c748d6,accelerating public service delivery in india: application of internet of things and artificial intelligence in agriculture,"The application of Information and Communication Technologies (ICTs) in the public sector can usher performance enhancement, productivity and social equity in public service delivery mechanisms. More specifically, emerging digital technologies including Artificial Intelligence (AI) can be employed for more effective retrieval and analysis of complex, real-time data that could also be captured and shared by devices supporting Internet of Things. Literature asserts that governments worldwide must adopt solutions offered by these emerging technologies to drive innovation in public service delivery mechanisms. Appreciating these claims, this study aims to explore the current and potential use of IoT and AI. Based on the related review of literature, the study puts forth a conceptual framework for creating an open and integrated national level agriculture stack (christened as KisanOne by the authors) so that developing countries like India can effectively espouse data driven approach in its agriculture sector. ""Kisan One"" combines varied aspects of a farmers' activities including weather forecast, soil health indices, seed procurement cycle, sowing cycles, details of fertilizers availability, crop prices, etc, in a unified national stack that is accessible to all the stakeholders using application programming interfaces (APIs). Needless to say, the proposed KisanOne is a utopian implementation where existing and contemporary digital initiatives get unified on a single platform.Datasets themselves have little intrinsic value sans any ability to extract meaning from it. Intelligent data analytics could be employed on real time datasets of KisanOne both for evidence based decision making as well as for malicious intent. This paper, therefore, attempts to offer an insight into such challenges as well as suggest policy recommendations that could strengthen existing regulatory mechanisms for effective implementation of IoT and AI in existing public service delivery schemes of India. The paper is divided into four broad sections. The first section builds the Background of the paper. The next section is divided into four subsections and in this section instance of Agriculture has been detailed with reference to its current scenario and prevailing solutions. India has started using technology in Agriculture to a great extent- some of these applications such as Kisan Suvidha2 mobile app, mKisan SMS Portal, Farmer's Portal, Soil Health Card, Fertilizer Monitoring System(FMS) software, Agrimarket App have been delineated in the study. A use case on transformation of agriculture sector using IoT and AI is also presented in one of the sub-sections. A National Level Integrated Agriculture Stack is also proposed in this paper. The subsequent section presents brief picture of key challenges of implementing IoT and AI in Agriculture sector followed by recommendations and Consulive Remarks. It is an innovative and descriptive study that primarily relies on secondary data gleaned from international/national journals, reports of Ministry of Electronics and Information Technology, Government of India and other online academic sources coupled with creative out-of-box thinking to propose the application of IoT and AI in varied public sectors with special emphasis on Agriculture.",International Conference on Theory and Practice of Electronic Governance,2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3428502.3428510
14c12f9d44ef23a8c2d39bcf1e3ab1a13d684054,https://www.semanticscholar.org/paper/14c12f9d44ef23a8c2d39bcf1e3ab1a13d684054,public decision making: connecting artificial intelligence and crowds,"The recent breakthrough of artificial intelligence, as well as the wide adoption of the wisdom of the crowd, also known as collective intelligence, across sectors, has received attention and excitement across disciplines. In addition to the scientific breakthrough, recent public sector studies recognize AI's potential contributions in public services, such as big data for decision making, the development of smart cities, and social and health care. Studies have also recognized crowdsourcing's potential for service provisions, innovation, information generation, and policymaking. However, we have only a limited understanding of the connections between these two types of intelligence and adoption conditions to properly utilize them for the public sector. To understand what roles AI and crowds can play in enhancing public services and policymaking, we adopt a bibliometric analysis to identify emerging themes and interconnections between these two streams of literature. Our study provides key themes and significance for each cluster. Our first examination of AI and crowd literature regarding connection to public values, complementary in public decision making, as well as future potential for joint adoption by governments provides some implications for future considerations.",Digital Government Research,2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3396956.3396965
4ae7b75e7b0fdf00a687c8f308ceccbe26c24e8d,https://www.semanticscholar.org/paper/4ae7b75e7b0fdf00a687c8f308ceccbe26c24e8d,regulation and ethics in artificial intelligence and machine learning technologies: where are we now? who is responsible? can the information professional play a role?,"Artificial intelligence (AI) and machine learning (ML) technologies are rapidly maturing and proliferating through all public and private sectors. The potential for these technologies to do good and to help us in our everyday lives is immense. But there is a risk that unless managed and controlled AI can also cause us harm. Questions about regulation, what form it takes and who is responsible for governance are only just beginning to be answered. In May 2019, 42 countries came together to support a global governance framework for AI. The Organisation for Economic Co-operation and Development (OECD) Principles on Artificial Intelligence (OECD (2019) OECD principles on AI. Available at: https://www.oecd.org/going-digital/ai/principles/ (accessed 2 March 2020)) saw like-minded democracies of the world commit to common AI values of trust and respect. In Europe, the European Commission’s (EC) new president, Ursula von der Leyen has made calls for a General Data Protection Regulation style. As a first step the EC has published a white paper: ‘On Artificial Intelligence – A European Approach to Excellence and Trust’ (European Commission (2020) Report, Europa, February). In February 2020, the UK government has published a report on ‘Artificial Intelligence in the Public Sector’ (The Committee on Standards in Public Life (2020) Artificial intelligence and public standards. Report, UK Government, February). This article discusses some of the potential threats AI may hold if left unregulated. It provides a brief overview of the regulatory activities for AI worldwide, and in more detail the current UK AI regulatory landscape. Finally, the article looks at the role that the information professional might play in AI and ML.",Business Information Review,2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/0266382120923962
a959ab5900bc87df1b8ab8618b37d96bc8a4df3c,https://www.semanticscholar.org/paper/a959ab5900bc87df1b8ab8618b37d96bc8a4df3c,ruegan: embracing a self-adversarial agent for building a defensible edge security architecture,"In the era of edge computing and Artificial Intelligence (AI), securing billions of edge devices within a network against intelligent attacks is crucial. We propose PUFGAN, an innovative machine learning attack-proof security architecture, by embedding a self-adversarial agent within a device fingerprint- based security primitive, public PUF (PPUF) known for its strong fingerprint-driven cryptography. The self-adversarial agent is implemented using Generative Adversarial Networks (GANs). The agent attempts to self-attack the system based on two GAN variants, vanilla GAN and conditional GAN. By turning the attacking quality through generating realistic secret keys used in the PPUF primitive into system vulnerability, the security architecture is able to monitor its internal vulnerability. If the vulnerability level reaches at a specific value, PUFGAN allows the system to restructure its underlying security primitive via feedback to the PPUF hardware, maintaining security entropy at as high a level as possible.We evaluated PUFGAN on three different machine environments: Google Colab, a desktop PC, and a Raspberry Pi 2, using a real-world PPUF dataset. Extensive experiments demonstrated that even a strong device fingerprint security primitive can become vulnerable, necessitating active restructuring of the current primitive, making the system resilient against extreme attacking environments.",IEEE Conference on Computer Communications,2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/infocom41043.2020.9155501
06daf0dbac7767f2cfa58b56abe7d8ae148d8f3a,https://www.semanticscholar.org/paper/06daf0dbac7767f2cfa58b56abe7d8ae148d8f3a,the ai-development connection - a view from the south,"The socialisation of Artificial Intelligence and the reality of an intelligence economy mark an epochal moment. The impacts of AI are now systemic - restructuring economic organisation and value chains, public sphere architectures and sociality. These shifts carry deep geo-political implications, reinforcing historical exclusions and power relations and disrupting the norms and rules that hold ideas of equality and justice together. At the centre of this rapid change is the intelligent corporation and its obsessive pursuit of data. Directly impinging on bodies and places, the de facto rules forged by the intelligent corporation are disenfranchising the already marginal subjects of development. Using trade deals to liberalise data flows, tighten trade secret rules and enclose AI-based innovation, Big Tech and their political masters have effectively taken away the economic and political autonomy of states in the global south. Big Tech's impunity extends to a brazen exploitation - enslaving labour through data over-reach and violating female bodies to universalise data markets. Thinking through the governance of AI needs new frameworks that can grapple with the fraught questions of data sovereignty, economic democracy, and institutional ethics in a global world with local aspirations. Any effort towards norm development in this domain will need to see the geo-economics of digital intelligence and the geo-politics of development ideologies as two sides of the same coin.","AAAI/ACM Conference on AI, Ethics, and Society",2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3375627.3377139
8d03df21807637482739cbfe140b260aa8f1907b,https://www.semanticscholar.org/paper/8d03df21807637482739cbfe140b260aa8f1907b,administration by algorithm: a risk management framework,"Algorithmic decision-making is neither a recent phenomenon nor one necessarily associated with artificial intelligence (AI), though advances in AI are increasingly resulting in what were heretofore human decisions being taken over by, or becoming dependent on, algorithms and technologies like machine learning. Such developments promise many potential benefits, but are not without certain risks. These risks are not always well understood. It is not just a question of machines making mistakes; it is the embedding of values, biases and prejudices in software which can discriminate against both individuals and groups in society. Such biases are often hard either to detect or prove, particularly where there are problems with transparency and accountability and where such systems are outsourced to the private sector. Consequently, being able to detect and categorise these risks is essential in order to develop a systematic and calibrated response. This paper proposes a simple taxonomy of decision-making algorithms in the public sector and uses this to build a risk management framework with a number of components including an accountability structure and regulatory governance. This framework is designed to assist scholars and practitioners interested in ensuring structured accountability and legal regulation of AI in the public sphere.",Inf. Polity,2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3233/ip-200249
2adbd8f367c5ab43dcaba87c980aabd3747d4994,https://www.semanticscholar.org/paper/2adbd8f367c5ab43dcaba87c980aabd3747d4994,a framework and dataset for abstract art generation via calligraphygan,"With the advancement of deep learning, artificial intelligence (AI) has made many breakthroughs in recent years and achieved superhuman performance in various tasks such as object detection, reading comprehension, and video games. Generative Modeling, such as various Generative Adversarial Networks (GAN) models, has been applied to generate paintings and music. Research in Natural Language Processing (NLP) also had a leap forward in 2018 since the release of the pre-trained contextual neural language models such as BERT and recently released GPT3. Despite the exciting AI applications aforementioned, AI is still significantly lagging behind humans in creativity, which is often considered the ultimate moonshot for AI. Our work is inspired by Chinese calligraphy, which is a unique form of visual art where the character itself is an aesthetic painting. We also draw inspirations from paintings of the Abstract Expressionist movement in the 1940s and 1950s, such as the work by American painter Franz Kline. In this paper, we present a creative framework based on Conditional Generative Adversarial Networks and Contextual Neural Language Model to generate abstract artworks that have intrinsic meaning and aesthetic value, which is different from the existing work, such as image captioning and text-to-image generation, where the texts are the descriptions of the images. In addition, we have publicly released a Chinese calligraphy image dataset and demonstrate our framework using a prototype system and a user study.",arXiv.org,2020,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',
2ea2ea3d0128b1b2d3e89dd442d26f1441111ebf,https://www.semanticscholar.org/paper/2ea2ea3d0128b1b2d3e89dd442d26f1441111ebf,"cyber-physical innovations:: cyber-infrastructure for research, cyber-physical architecture for real-time applications, autonomous vehicle (av) governance and ai artifacts for public value","This panel explores the development of innovative, integrative, and versatile strategies to facilitate more practical and effective use of intelligent cyber-physical technologies from a variety of perspectives, including engineering, regulation, management, and research. With the same goal of sustaining the development of emerging technologies to best benefit our communities, this panel shares their different approaches in terms of engineering solutions for real-time controlling in cyber-physical systems, regulatory strategies to overcome the conflict between efficiency and autonomy, artifacts for artificial intelligence project management, and meeting researcher needs through large-scale cyberinfrastructure. The selected cases discussed in this panel not only highlight the critical challenges in implementing cyber-physical technologies into real applications but also suggest promising strategies to overcome those issues from diverse facets.",Digital Government Research,2021,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3463677.3463721
8e260e06c73f27f7a477021ce1b068099c2064bf,https://www.semanticscholar.org/paper/8e260e06c73f27f7a477021ce1b068099c2064bf,harnessing artificial intelligence for health message generation: the folic acid message engine,"Background Communication campaigns using social media can raise public awareness; however, they are difficult to sustain. A barrier is the need to generate and constantly post novel but on-topic messages, which creates a resource-intensive bottleneck. Objective In this study, we aim to harness the latest advances in artificial intelligence (AI) to build a pilot system that can generate many candidate messages, which could be used for a campaign to suggest novel, on-topic candidate messages. The issue of folic acid, a B-vitamin that helps prevent major birth defects, serves as an example; however, the system can work with other issues that could benefit from higher levels of public awareness. Methods We used the Generative Pretrained Transformer-2 architecture, a machine learning model trained on a large natural language corpus, and fine-tuned it using a data set of autodownloaded tweets about #folicacid. The fine-tuned model was then used as a message engine, that is, to create new messages about this topic. We conducted a web-based study to gauge how human raters evaluate AI-generated tweet messages compared with original, human-crafted messages. Results We found that the Folic Acid Message Engine can easily create several hundreds of new messages that appear natural to humans. Web-based raters evaluated the clarity and quality of a human-curated sample of AI-generated messages as on par with human-generated ones. Overall, these results showed that it is feasible to use such a message engine to suggest messages for web-based campaigns that focus on promoting awareness. Conclusions The message engine can serve as a starting point for more sophisticated AI-guided message creation systems for health communication. Beyond the practical potential of such systems for campaigns in the age of social media, they also hold great scientific potential for the quantitative analysis of message characteristics that promote successful communication. We discuss future developments and obvious ethical challenges that need to be addressed as AI technologies for health persuasion enter the stage.",Journal of Medical Internet Research,2021,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2196/28858
826a19bda59aa7ce8a33235b35c0480aac827ea1,https://www.semanticscholar.org/paper/826a19bda59aa7ce8a33235b35c0480aac827ea1,"the role of social movements, coalitions, and workers in resisting harmful artificial intelligence and contributing to the development of responsible ai","The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles"", there is mounting public concern over the influence that the AI systems have in our society, and coalitions in all sectors are organizing to resist harmful applications of AI worldwide. Responses from peoples everywhere, from workers protesting unethical conduct and applications of AI, to student's protesting MIT's relationships with donor, sex trafficker, and pedophile Jeffery Epstein, to the healthcare community, to indigenous people addressing “the twin problems of a lack of reliable data and information on indigenous peoples and biopiracy and misuse of their traditional knowledge and cultural heritage”, to smart city stakeholders, to many others. Like corporations, governments around the world have adopted strategies for becoming leaders in the development and use of Artificial Intelligence, fostering environments congenial to AI innovators. Neither corporations nor policymakers have sufficiently addressed how the rights of children fit into their AI strategies or products. The role of artificial intelligence in children’s lives—from how children play, to how they are educated, to how they consume information and learn about the world—is expected to increase exponentially over the coming years. Thus, it’s imperative that stakeholders evaluate the risks and assess opportunities to use artificial intelligence to maximize children’s wellbeing in a thoughtful and systematic manner. This paper discusses AI and children's rights in the context of social media platforms such as YouTube, smart toys, and AI education applications. The Hello Barbie, Cloud Pets, and Cayla smart toys case studies are analyzed, as well as the ElsaGate social media hacks and education's new Intelligent Tutoring Systems and surveillance of students apps. Though AI has valuable benefits for children, it presents some particular challenges around important issues including child safety, privacy, data privacy, device security and consent. Technology giants, all of whom are heavily investing in and profiting from AI, must not dominate the public discourse on responsible use of AI. We all need to shape the future of our core values and democratic institutions. As artificial intelligence continues to find its way into our daily lives, its propensity to interfere with our rights only gets more severe. Many of the issues mentioned in this examination of harmful AI are not new, but they are greatly exacerbated and threatened by the scale, proliferation, and real-life impact that artificial intelligence facilitates. The potential of artificial intelligence to both help and harm people is much greater than earlier technologies. Continuing to examine what safeguards and structures can address AI’s problems and harms, including those that disproportionately impact marginalized people, is a critical activity. There are assumptions embedded in the AI algorithms that will shape how our world is realized. Many of these algorithms are wrongful and biased, they must get locked-in. Our best human judgment is needed to contain AI's harmful impacts. Perhaps one of the greatest contributions of AI will be to make us ultimately understand how important human wisdom truly is in life on earth.",Social Science Research Network,2021,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2139/ssrn.3880779
dad22e1cbdb21876ff1b4c10bb32f19fcc4a2a6a,https://www.semanticscholar.org/paper/dad22e1cbdb21876ff1b4c10bb32f19fcc4a2a6a,ai-enabled efficient and safe food supply chain,"This paper provides a review of an emerging field in the food processing sector, referring to efficient and safe food supply chains, ’from farm to fork’, as enabled by Artificial Intelligence (AI). The field is of great significance from economic, food safety and public health points of views. The paper focuses on effective food production, food maintenance energy management and food retail packaging labeling control, using recent advances in machine learning. Appropriate deep neural architectures are adopted and used for this purpose, including Fully Convolutional Networks, Long Short-Term Memories and Recurrent Neural Networks, Auto-Encoders and Attention mechanisms, Latent Variable extraction and clustering, as well as Domain Adaptation. Three experimental studies are presented, illustrating the ability of these AI methodologies to produce state-of-the-art performance in the whole food supply chain. In particular, these concern: (i) predicting plant growth and tomato yield in greenhouses, thus matching food production to market needs and reducing food waste or food unavailability; (ii) optimizing energy consumption across large networks of food retail refrigeration systems, through optimal selection of systems that can be shut-down and through prediction of the respective food de-freezing times, during peaks of power demand load; (iii) optical recognition and verification of food consumption expiry date in automatic inspection of retail packaged food, thus ensuring safety of food and people’s health.",Electronics,2021,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/ELECTRONICS10111223
5122b9b525f18a353f0a519e680a55c638ccbe41,https://www.semanticscholar.org/paper/5122b9b525f18a353f0a519e680a55c638ccbe41,molecule generation experience: an open platform of material design for public users,"Artificial Intelligence (AI)-driven material design has been attracting great attentions as a groundbreaking technology across a wide spectrum of industries. Molecular design is particularly important owing to its broad application domains and boundless creativity attributed to progresses in generative models. The recent maturity of molecular generative models has stimulated expectations for practical use among potential users, who are not necessarily familiar with coding or scripting, such as experimental engineers and students in chemical domains. However, most of the existing molecular generative models are Python libraries on GitHub, that are accessible for only IT-savvy users. To fill this gap, we newly developed a graphical user interface (GUI)-based web application of molecular generative models, Molecule Generation Experience, that is open to the general public. This is the first web application of molecular generative models enabling users to work with built-in datasets to carry out molecular design. In this paper, we describe the background technology extended from our previous work. Our new online evaluation and structural filtering algorithms significantly improved the generation speed by 30 to 1,000 times with a wider structural variety, satisfying chemical stability and synthetic reality. We also describe in detail our Kubernetes-based scalable cloud architecture and user-oriented GUI that are necessary components to achieve a public service. Finally, we present actual use cases in industrial research to design new photoacid generators (PAGs) as well as release cases in educational events.",arXiv.org,2021,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',
864400b32e8a2b1ba10ab1ed5007f6642adf3a17,https://www.semanticscholar.org/paper/864400b32e8a2b1ba10ab1ed5007f6642adf3a17,on the social-relational moral standing of ai: an empirical study using ai-generated art,"The moral standing of robots and artificial intelligence (AI) systems has become a widely debated topic by normative research. This discussion, however, has primarily focused on those systems developed for social functions, e.g., social robots. Given the increasing interdependence of society with nonsocial machines, examining how existing normative claims could be extended to specific disrupted sectors, such as the art industry, has become imperative. Inspired by the proposals to ground machines’ moral status on social relations advanced by Gunkel and Coeckelbergh, this research presents online experiments (∑N = 448) that test whether and how interacting with AI-generated art affects the perceived moral standing of its creator, i.e., the AI-generative system. Our results indicate that assessing an AI system’s lack of mind could influence how people subsequently evaluate AI-generated art. We also find that the overvaluation of AI-generated images could negatively affect their creator’s perceived agency. Our experiments, however, did not suggest that interacting with AI-generated art has any significant effect on the perceived moral standing of the machine. These findings reveal that social-relational approaches to AI rights could be intertwined with property-based theses of moral standing. We shed light on how empirical studies can contribute to the AI and robot rights debate by revealing the public perception of this issue.",Frontiers in Robotics and AI,2021,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3389/frobt.2021.719944
55de3e6509cf99a7114ab80105800ad8c40ab476,https://www.semanticscholar.org/paper/55de3e6509cf99a7114ab80105800ad8c40ab476,integrated service discovery and placement in information-centric vehicular network slices,"Connected and autonomous driving is one of the prominent vertical applications to showcase the capabilities of the 5G mobile network to transform and disrupt numerous industrial sectors and service chains. Cooperative autonomous mobility applications require ultra low latency communication, utilize massive broadband connections for vast numbers of connected devices, all of this under high mobility settings. Cloud and Edge Computing, artificial intelligence (AI), and the Internet of things (IoT) pave the path for the most important role of 5G: to attain an integration platform for the challenges of vertical applications. In this work, we first review these enabling features of 5G for autonomous driving and their integration in our autonomous driving testbed on urban public roads. We then propose an enhancement to the 5G vehicle to everything (V2X) architecture by incorporating the informationcentric communication paradigm. Our simulations of a proposed approach for integrated service discovery and placement in the high mobility settings of autonomous driving applications show improved service continuity and latency measured by hop counts to service endpoints and number of cache nodes. The results serve as a base line performance indicator for the practical implementation of the proposed approach.",IEEE Vehicular Technology Conference,2021,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/VTC2021-Spring51267.2021.9448979
2afd1d3199326dc8a9184a5152616f5cfda1e2e6,https://www.semanticscholar.org/paper/2afd1d3199326dc8a9184a5152616f5cfda1e2e6,"artificial intelligence in government: concepts, standards, and a unified framework","Recent advances in artificial intelligence (AI), especially in generative language modelling, hold the promise of transforming government. Given the advanced capabilities of new AI systems, it is critical that these are embedded using standard operational procedures, clear epistemic criteria, and behave in alignment with the normative expectations of society. Scholars in multiple domains have subsequently begun to conceptualize the different forms that AI applications may take, highlighting both their potential benefits and pitfalls. However, the literature remains fragmented, with researchers in social science disciplines like public administration and political science, and the fast-moving fields of AI, ML, and robotics, all developing concepts in relative isolation. Although there are calls to formalize the emerging study of AI in government, a balanced account that captures the full depth of theoretical perspectives needed to understand the consequences of embedding AI into a public sector context is lacking. Here, we unify efforts across social and technical disciplines by first conducting an integrative literature review to identify and cluster 69 key terms that frequently co-occur in the multidisciplinary study of AI. We then build on the results of this bibliometric analysis to propose three new multifaceted concepts for understanding and analysing AI-based systems for government (AI-GOV) in a more unified way: (1) operational fitness, (2) epistemic alignment, and (3) normative divergence. Finally, we put these concepts to work by using them as dimensions in a conceptual typology of AI-GOV and connecting each with emerging AI technical measurement standards to encourage operationalization, foster cross-disciplinary dialogue, and stimulate debate among those aiming to rethink government with AI.",Journal of Grid Computing,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2210.17218
5d54a58aa726af2223824234c8d01532058d0f13,https://www.semanticscholar.org/paper/5d54a58aa726af2223824234c8d01532058d0f13,combating covid-19 using generative adversarial networks and artificial intelligence for medical images: scoping review,"Background Research on the diagnosis of COVID-19 using lung images is limited by the scarcity of imaging data. Generative adversarial networks (GANs) are popular for synthesis and data augmentation. GANs have been explored for data augmentation to enhance the performance of artificial intelligence (AI) methods for the diagnosis of COVID-19 within lung computed tomography (CT) and X-ray images. However, the role of GANs in overcoming data scarcity for COVID-19 is not well understood. Objective This review presents a comprehensive study on the role of GANs in addressing the challenges related to COVID-19 data scarcity and diagnosis. It is the first review that summarizes different GAN methods and lung imaging data sets for COVID-19. It attempts to answer the questions related to applications of GANs, popular GAN architectures, frequently used image modalities, and the availability of source code. Methods A search was conducted on 5 databases, namely PubMed, IEEEXplore, Association for Computing Machinery (ACM) Digital Library, Scopus, and Google Scholar. The search was conducted from October 11-13, 2021. The search was conducted using intervention keywords, such as “generative adversarial networks” and “GANs,” and application keywords, such as “COVID-19” and “coronavirus.” The review was performed following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines for systematic and scoping reviews. Only those studies were included that reported GAN-based methods for analyzing chest X-ray images, chest CT images, and chest ultrasound images. Any studies that used deep learning methods but did not use GANs were excluded. No restrictions were imposed on the country of publication, study design, or outcomes. Only those studies that were in English and were published from 2020 to 2022 were included. No studies before 2020 were included. Results This review included 57 full-text studies that reported the use of GANs for different applications in COVID-19 lung imaging data. Most of the studies (n=42, 74%) used GANs for data augmentation to enhance the performance of AI techniques for COVID-19 diagnosis. Other popular applications of GANs were segmentation of lungs and superresolution of lung images. The cycleGAN and the conditional GAN were the most commonly used architectures, used in 9 studies each. In addition, 29 (51%) studies used chest X-ray images, while 21 (37%) studies used CT images for the training of GANs. For the majority of the studies (n=47, 82%), the experiments were conducted and results were reported using publicly available data. A secondary evaluation of the results by radiologists/clinicians was reported by only 2 (4%) studies. Conclusions Studies have shown that GANs have great potential to address the data scarcity challenge for lung images in COVID-19. Data synthesized with GANs have been helpful to improve the training of the convolutional neural network (CNN) models trained for the diagnosis of COVID-19. In addition, GANs have also contributed to enhancing the CNNs’ performance through the superresolution of the images and segmentation. This review also identified key limitations of the potential transformation of GAN-based methods in clinical applications.",JMIR Medical Informatics,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2196/37365
b39273df9ff8c62c60d3b079b991b8676c24d133,https://www.semanticscholar.org/paper/b39273df9ff8c62c60d3b079b991b8676c24d133,research on institutional improvement for personal information collection and use in the public sector: use of video information collected by public area cctv,"In recent years, artificial intelligence technology, which enables new technologies to be deployed, has expanded the scope and methods of data collection and utilization of government agencies. Data analysis and AI technology are deployed to enhance the intelligent and accurate use of Closed-circuit television (CCTV) surveillance cameras for crime prevention, security, and public safety purposes. The use of facial recognition technology enables an individual to be identified by processing images captured on CCTV, the suspects to be tracked on the CCTV footage, and crime scenes to be monitored in real time. Amidst this expansion, there is an increasing need for discussions to protect privacy. The need for privacy control is emphasized as data collection, retention, and utilization capabilities resulting in losing control over individual’s own information. The value and importance of personal data have been changed from the previous, and government surveillance issues arises as vast quantities of personal data being stored and easily shared. The need for government data access for various purposes and storage of data on a large scale may lead to the privacy right and the infringement of informational self-determination. In a situation where the use of CCTV information is allowed and gradually expanding, it is difficult to evaluate that legal grounds for controlling the actions of government agencies or guaranteeing the rights of individual subjects are sufficient. This paper aims to examine the current status of data collection by government institutions, especially the institutional basis for the use of CCTV and video information collection by government agencies, and problems with the system regarding personal data protection.",Korean Administrative Law Association,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.59826/kdps.2022.23.143
00e3c5f7909c6b8303a279c1a79e7563b2783649,https://www.semanticscholar.org/paper/00e3c5f7909c6b8303a279c1a79e7563b2783649,"legality, legitimacy, and instrumental possibility in human and computational governance for the public sector","Artificial Intelligence (AI) can have a significant beneficial or harmful impact when used in public policies and services. This paper provides a reflection on the EU regulatory initiatives towards regulating governance and risk management of AI, elaborating on the entrenchment of the dimensions of legality, legitimacy and instrumental possibility. We argue that only against this conceptual backdrop we can possibly unpack what a legal, legitimate, trustworthy, fair and accountable approach to designing and implementing AI in public service is. As an outcome, we identify a few crucial architectural requirements, both at normative and at computational level.",International Forum on Digital and Democracy,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',
5ee1024949c8faa312677fe5d034aa9be0861fe1,https://www.semanticscholar.org/paper/5ee1024949c8faa312677fe5d034aa9be0861fe1,urban-gan: an artificial intelligence-aided computation system for plural urban design,"The current urban design computation is mostly centered on the professional designer while ignoring the plural dimension of urban design. In addition, available public participation computational tools focus mainly on information and idea sharing, leaving the public excluded in design generation because of their lack of design expertise. To address such an issue, this study develops Urban-GAN, a plural urban design computation system, to provide new technical support for design empowerment, allowing the public to generate their own designs. The sub-symbolic representation and artificial intelligence techniques of deep convolutional neural networks, case-based reasoning, and generative adversarial networks are used to acquire and embody design knowledge as the density function, and generate design schemes with this knowledge. The system consists of an urban form database and five process models through which the user with little design expertise can select urban form cases, generate designs similar to those cases, and make design decisions. The Urban-GAN is applied to hypothetical design experiments, which show that the user is able to apply the system to successfully generate distinctive designs following the urban form “styles” in Manhattan, Portland, and Shanghai. This study further extends the discussion about the plural urban design computation to general reflections on the goals and values in AI technique application in planning and design.",Environment and Planning B Urban Analytics and City Science,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/23998083221100550
be49e6c6ff3488433b44a0b542e4cf8f2429800d,https://www.semanticscholar.org/paper/be49e6c6ff3488433b44a0b542e4cf8f2429800d,strengthening public institutions and social inclusion of vulnerable groups in a developing country - innovation in organizations and artificial intelligence implications,"Background: In the context of a developing nation, children's participation in communal life is almost non-existent. The goal of the study is to contribute to national policies for local development that should prioritize the safety and well-being of the most vulnerable populations, particularly children under the age of 18. Innovating, including children in decision-making and maintaining local services in three pilot municipalities in order to prevent and combat all forms of exploitation to which they are exposed. How can Youth engagement in social and political community life be improved through better understanding of their needs and interests, and what are the artificial intelligence implications? Method: The methodology was used and designed to re-validate an existing program using pre-defined components of an agreement between the Italian and Lebanese governments. A needs study on the socio-demographic profile of youth and a situational analysis was conducted answering three objectives in the program of the Child Friendly City initiative. Results: Assuring the long-term viability and social inclusion of a significant socio-demographic group was successfully implemented: a free call center, software applications, a library, a digital network center, and the involvement of children on the municipal board of directors were established. The findings need to be adapted to various locations using artificial intelligence (AI) solutions and strategies for social awareness and behavior analysis. Conclusion: The importance of this study was underscored during the Covid-19 sanitary crisis, when some of these technologies enabled young people in impacted areas to integrate and become aware of the pandemic's risk. The case was based on theories such as Gender Inequalities and Children's Inclusion, Municipal Governance & Reform, Organizational Innovation (Public Sector), and Social Inclusion, and it demonstrates the value of innovating in the public sector and protecting vulnerable populations through the use of AI.",Pacific Asia Journal of the Association for Information Systems,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.17705/1pais.14304
3c0bffd0afff7e3ad7d2e32bc633a304ceee0734,https://www.semanticscholar.org/paper/3c0bffd0afff7e3ad7d2e32bc633a304ceee0734,machine learning and artificial intelligence in physiologically based pharmacokinetic modeling.,"Physiologically based pharmacokinetic (PBPK) models are useful tools in drug development and risk assessment of environmental chemicals. PBPK model development requires collection of species-specific physiological, and chemical-specific absorption, distribution, metabolism and excretion (ADME) parameters, which can be a time-consuming and expensive process. This raises a need to create computational models capable of predicting input parameter values for PBPK models, especially for new compounds. In this review, we summarize an emerging paradigm for integrating PBPK modeling with machine learning (ML) or artificial intelligence (AI)-based computational methods. This paradigm includes three steps: (a) obtain time-concentration PK data and/or ADME parameters from publicly available databases, (b) develop ML/AI-based approaches to predict ADME parameters, and (c) incorporate the ML/AI models into PBPK models to predict PK summary statistics (e.g., area under the curve and maximum plasma concentration). We also discuss a neural network architecture ""neural ordinary differential equation (Neural-ODE)"" that is capable of providing better predictive capabilities than other ML methods when used to directly predict time-series PK profiles. In order to support applications of ML/AI methods for PBPK model development, several challenges should be addressed: (1) as more data become available, it is important to expand the training set by including structural diversity of compounds to improve the prediction accuracy of ML/AI models; (2) due to the black box nature of many ML models, lack of sufficient interpretability is a limitation; (3) Neural-ODE has great potential to be used to generate time-series PK profiles for new compounds with limited ADME information, but its application remains to be explored. Despite existing challenges, ML/AI approaches will continue to facilitate efficient development of robust PBPK models for a large number of chemicals.",Toxicological Sciences,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1093/toxsci/kfac101
157600e0348b99bbc4187b95fd0c438a2189a841,https://www.semanticscholar.org/paper/157600e0348b99bbc4187b95fd0c438a2189a841,"imtidad: a reference architecture and a case study on developing distributed ai services for skin disease diagnosis over cloud, fog and edge","Several factors are motivating the development of preventive, personalized, connected, virtual, and ubiquitous healthcare services. These factors include declining public health, increase in chronic diseases, an ageing population, rising healthcare costs, the need to bring intelligence near the user for privacy, security, performance, and costs reasons, as well as COVID-19. Motivated by these drivers, this paper proposes, implements, and evaluates a reference architecture called Imtidad that provides Distributed Artificial Intelligence (AI) as a Service (DAIaaS) over cloud, fog, and edge using a service catalog case study containing 22 AI skin disease diagnosis services. These services belong to four service classes that are distinguished based on software platforms (containerized gRPC, gRPC, Android, and Android Nearby) and are executed on a range of hardware platforms (Google Cloud, HP Pavilion Laptop, NVIDIA Jetson nano, Raspberry Pi Model B, Samsung Galaxy S9, and Samsung Galaxy Note 4) and four network types (Fiber, Cellular, Wi-Fi, and Bluetooth). The AI models for the diagnosis include two standard Deep Neural Networks and two Tiny AI deep models to enable their execution at the edge, trained and tested using 10,015 real-life dermatoscopic images. The services are evaluated using several benchmarks including model service value, response time, energy consumption, and network transfer time. A DL service on a local smartphone provides the best service in terms of both energy and speed, followed by a Raspberry Pi edge device and a laptop in fog. The services are designed to enable different use cases, such as patient diagnosis at home or sending diagnosis requests to travelling medical professionals through a fog device or cloud. This is the pioneering work that provides a reference architecture and such a detailed implementation and treatment of DAIaaS services, and is also expected to have an extensive impact on developing smart distributed service infrastructures for healthcare and other sectors.",Italian National Conference on Sensors,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/s22051854
d821e5bdf1ab94bcd0e1a9e11fe1c296a01e3f02,https://www.semanticscholar.org/paper/d821e5bdf1ab94bcd0e1a9e11fe1c296a01e3f02,how different groups prioritize ethical values for responsible ai,"Private companies, public sector organizations, and academic groups have outlined ethical values they consider important for responsible artificial intelligence technologies. While their recommendations converge on a set of central values, little is known about the values a more representative public would find important for the AI technologies they interact with and might be affected by. We conducted a survey examining how individuals perceive and prioritize responsible AI values across three groups: a representative sample of the US population (N=743), a sample of crowdworkers (N=755), and a sample of AI practitioners (N=175). Our results empirically confirm a common concern: AI practitioners’ value priorities differ from those of the general public. Compared to the US-representative sample, AI practitioners appear to consider responsible AI values as less important and emphasize a different set of values. In contrast, self-identified women and black respondents found responsible AI values more important than other groups. Surprisingly, more liberal-leaning participants, rather than participants reporting experiences with discrimination, were more likely to prioritize fairness than other groups. Our findings highlight the importance of paying attention to who gets to define “responsible AI.”","Conference on Fairness, Accountability and Transparency",2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3531146.3533097
41953da351150461612e5f72f914e45bdcbba31a,https://www.semanticscholar.org/paper/41953da351150461612e5f72f914e45bdcbba31a,ai-driven data monetization: the other face of data in iot-based smart and connected health,"As the trajectory of the Internet of Things (IoT) moving at a rapid pace and with the rapid worldwide development and public embracement of wearable sensors, these days, most companies and organizations are awash in massive amounts of data. Determining how to profit from data deluge can give companies an edge in the market because data have the potential to add tremendous value to many aspects of a business. The market has already seen a level of monetization across vertical domains in the form of layering connected devices with a variety of Software-as-a-Service (SaaS) choices, such as subscription plans or smart device insights. Out of this arena is evolving a “machine economy” in which the ability to correctly monetize data rather than simply hoard it, will provide a significant advantage in a competitive digital environment. The recent advent of the technological advances in the fields of big data, analytics, and artificial intelligence (AI) has opened new avenues of competition, where data are utilized strategically and treated as a continuously changing asset able to unleash new revenue opportunities for monetization. Such growth has made room for an onslaught of new tools, architectures, business models, platforms, and marketplaces that enable organizations to successfully monetize data. In fact, emerging business models are striving to alter the power balance between users and companies that harvest information. Start-ups and organizations are offering to sell user data to data analytics companies and other businesses. Monetizing data goes beyond just selling data. It is also possible to include steps that add value to data. Generally, organizations can monetize data by: 1) utilizing it to make better business decisions or improve processes; 2) surrounding flagship services or products with data; or 3) selling information to current or new markets. This article will address all important aspects of IoT data monetization with more focus on the healthcare industry and discuss the corresponding challenges, such as data management, scalability, regulations, interoperability, security, and privacy. In addition, it presents a holistic reference architecture for the healthcare data economy with an in-depth case study on the detection and prediction of cardiac anomalies using multiparty computation (MPC) and privacy-preserving machine learning (PPML) techniques.",IEEE Internet of Things Journal,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/jiot.2020.3027971
6a16d761ca5f28fca358b64db53f3cedbd4d83a1,https://www.semanticscholar.org/paper/6a16d761ca5f28fca358b64db53f3cedbd4d83a1,an ai bill of rights: implications for health care ai and machine learning—a bioethics lens,"Just last week (October 4, 2022), the U.S. White House released a blueprint for an A.I. Bill of Rights, consisting of “five principles and associated practices to help guide the design, use, and deployment of automated systems to protect the rights of the American public in the age of artificial intelligence.” The white paper states, “Developed through extensive consultation with the American public, these principles are a blueprint for building and deploying automated systems that are aligned with democratic values and protect civil rights, civil liberties, and privacy.” It further articulates that, “this framework provides a national values statement and toolkit that is sector-agnostic to inform building these protections into policy, practice, or the technological design process. Where existing law or policy—such as sector-specific privacy laws and oversight requirements—do not already provide guidance, the Blueprint for an AI Bill of Rights should be used to inform policy decisions” (Office of Science and Technology 2022). I applaud the development of this blueprint, but, after briefly describing each principle, highlight some challenges and questions that bioethicists working on AI and machine learning in health care ought to consider.",American Journal of Bioethics,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1080/15265161.2022.2135875
fbf4872593d24a7d5f24e98f662ab85962a2f2d7,https://www.semanticscholar.org/paper/fbf4872593d24a7d5f24e98f662ab85962a2f2d7,ai empowered big data analytics for industrial applications,"We proposed the idea of editing a special issue that would compile the fruitful research that resulted from the stimulating discussions that occurred during the workshop that was held during the 5th International Conference on Intelligent Computing, Chennai on 25th & 26th March 2022. The objective of this special issue is to call for high-quality papers covering the latest data analytic concepts and technologies of big data and artificial intelligence. This special issue serves as a forum for researchers across the globe to discuss their work and recent advances in this field. The best papers from Artificial intelligence and Big Data Analytics (BAM) in the domains of Product, Finance, Health, and Environment were invited, peer-reviewed. The best high-quality papers were selected based on the innovativeness and relevance of the theme. The amount of data being generated and stored in various fields such as education, energy, environment, healthcare, fraud detection, and traffic is increasing exponentially in the modern era of Big Data. Simultaneously, there is a significant paradigm shift in business and society worldwide due to rapid advancements in fields such as artificial intelligence, machine learning, deep learning, and data analytics. This creates significant challenges for decision-making and the potential for transformation in areas such as the economy, government, and industry. Artificial Intelligence tools, techniques, and technologies, in conjunction with Big Data, improve the predictive power of the systems created and allow the government, public, and private sectors to discover new patterns and trends, as well as improve public values such as accountability, safety, security, and transparency to enable better decision-making, policies, and governance. They also have a wide range of capabilities to perform complex tasks that humans cannot. They could be used to collect, organize, and analyze large, diverse data sets to discover patterns and trends that address a variety of problems related to the development of the economy, such as identifying new sources of revenue, expanding the customer base for business, product reviews, and promotion, disease prediction and prevention, climatic variation prediction, and the provision of energy solutions. The wide variety of subject areas discussed at the 5th International Conference on Intelligent Computing is reflected in the seven accepted papers presented in the following section.",Journal of universal computer science (Online),2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3897/jucs.94155
ee0b4a0e65de3576aaeb57150d0f29184f7d2e60,https://www.semanticscholar.org/paper/ee0b4a0e65de3576aaeb57150d0f29184f7d2e60,resnet-50 for 12-lead electrocardiogram automated diagnosis,"Nowadays, the implementation of Artificial Intelligence (AI) in medical diagnosis has attracted major attention within both the academic literature and industrial sector. AI would include deep learning (DL) models, where these models have been achieving a spectacular performance in healthcare applications. According to the World Health Organization (WHO), in 2020 there were around 25.6 million people who died from cardiovascular diseases (CVD). Thus, this paper aims to shad the light on cardiology since it is widely considered as one of the most important in medicine field. The paper develops an efficient DL model for automatic diagnosis of 12-lead electrocardiogram (ECG) signals with 27 classes, including 26 types of CVD and a normal sinus rhythm. The proposed model consists of Residual Neural Network (ResNet-50). An experimental work has been conducted using combined public databases from the USA, China, and Germany as a proof-of-concept. Simulation results of the proposed model have achieved an accuracy of 97.63% and a precision of 89.67%. The achieved results are validated against the actual values in the recent literature.",Computational Intelligence and Neuroscience,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1155/2022/7617551
4d14d554a9d6359f1faba70abb530ae03fe7eb89,https://www.semanticscholar.org/paper/4d14d554a9d6359f1faba70abb530ae03fe7eb89,the opacity of automated decision-making systems (adms) and its challenges for political legitimacy in a democracy,"This paper focuses specifically on Automated Decision-Making Systems (ADMS) based on Artificial Intelligence (AI). Since the last decades, AI systems are increasingly deployed by governments across the planet to manage public infrastructures and resources, as well as to engage with citizens for the provision of public services. Their introduction is advertised as a cost-cutting tool, as well as an instrument to combat traditional institutional disfunctions such as inefficiency, understaffing, corruption and human bias. While AI offers an incredible potential for progress, an emerging body of literature highlights the challenges that AI-driven decision-making may raise for a public sector ethics. A common trait of these challenges is their being related to some form of ""epistemological opacity"" that undermines the capacity of humans to explain and justify decisions based on AI systems, detect errors or unfairness and adopt corrective actions. The situation may entail public officers and citizens taking the outcomes of AI systems at face value, thus basing their actions (wholly or in part) on pieces of information that cannot be scrutinized and/or corrected if necessary. This paper intends to contribute to an emerging but still underdeveloped trend in normative political theory that study how AI-driven decision-making is reshaping the conceptualization and assessment of interactions between citizens and public officials. The overall goal of the paper is to analyze how various sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) affecting AI systems, may undermine the democratic legitimacy of public decisions based on them. Broadly speaking, legitimacy is the property that grounds the exercise of political authority, where authority standardly means the right to rule [1]. In this paper, democratic legitimacy is understood as a distinctive form of political authority grounded in the recognition of citizens as joint legislators. The paper offers a conception of democratic legitimacy conditional on the capacity of decision-making procedures and outcomes to realize the principle of public equality, which requires citizens' control over public decision-making, as well as respect for their equal status as political decision-makers. Specifically, the paper argues that the ""epistemological opacity"" affecting AI-driven decision-making systems, brings about a mistreatment of citizens as coauthors of public decisions, which is a premise of the idea of democratic citizenship. The main conjecture is that different sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) are causing the disengagement of citizens and public officers from public decision-making, either because they directly undermine necessary conditions for the realization of public equality (co-authorship/accountability/publicity), or because they hide from the public eye instances of illegitimate automation and privatization of decisional power. The paper offers a normative conception of democratic legitimacy that may contribute to efforts in various fields, including ""AI fairness"" and ""Explainable AI"", to better adapt technological tools to equality requirements distinctive of public decision-making within democratic societies.","AAAI/ACM Conference on AI, Ethics, and Society",2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3514094.3539563
f42f2e756bcf3683431af97f36527231117edcda,https://www.semanticscholar.org/paper/f42f2e756bcf3683431af97f36527231117edcda,duty to respond,"Social service providers play a vital role in the developmental outcomes of underprivileged youth as they transition into adulthood. Educators, mental health professionals, juvenile justice officers, and child welfare caseworkers often have first-hand knowledge of the trials uniquely faced by these vulnerable youth and are charged with mitigating harmful risks, such as mental health challenges, child abuse, drug use, and sex trafficking. Yet, less is known about whether or how social service providers assess and mitigate theonline risk experiences of youth under their care. Therefore, as part of the National Science Foundation (NSF) I-Corps program, we conducted interviews with 37 social service providers (SSPs) who work with underprivileged youth to determine what (if any) online risks are most concerning to them given their role in youth protection, how they assess or become aware of these online risk experiences, and whether they see value in the possibility of using artificial intelligence (AI) as a potential solution for online risk detection. Overall, online sexual risks (e.g., sexual grooming and abuse) and cyberbullying were the most salient concern across all social service domains, especially when these experiences crossed the boundary between the digital and the physical worlds. Yet, SSPs had to rely heavily on youth self-reports to know whether and when online risks occurred, which required building a trusting relationship with youth; otherwise, SSPs became aware only after a formal investigation had been launched. Therefore, most SSPs found value in the potential for using AI as an early detection system and to monitor youth, but they were concerned that such a solution would not be feasible due to a lack of resources to adequately respond to online incidences, access to the necessary digital trace data (e.g., social media), context, and concerns about violating the trust relationships they built with youth. Thus, such automated risk detection systems should be designed and deployed with caution, as their implementation could cause youth to mistrust adults, thereby limiting the receipt of necessary guidance and support. We add to the bodies of research on adolescent online safety and the benefits and challenges of leveraging algorithmic systems in the public sector.",Proc. ACM Hum. Comput. Interact.,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3567556
f88d67729038ea99558d4176112e1c1025761f13,https://www.semanticscholar.org/paper/f88d67729038ea99558d4176112e1c1025761f13,stochastic development on corporate environmental behavior resolution for quantum modelling of political adjudication from excise tax of all assumpsit actions,"Artificial Intelligence (AI) on cybersecurity is designed to control financial transactions and agreements worldwide. It is an innovative regulatory tool architecturally networked to combat cyber threats and attacks in various degrees of war and crime perpetration from various banking industries and its corresponding government authority functions with implementing arms for execution of monitoring, reporting, and compliance. Regulatory Technology (RegTech) is an AI tool used by treasury departments and institutions, both local and private, for tracking malicious threats possible for money laundering and terrorism financing concealed in various settlements around the world. However, cybersecurity decisions need conformity in regulations and proceedings that it aims to engineer code development involving attacks under Regulatory Technology usage for administrative functions in favor of the financial intelligence authorities for combating and resolving issues on cyberwar. Therefore, political adjudication is a developing means of resolving gaps and optimizing judicial process principles within the policy function of financial intelligence. Hence, international laws and its accompanied policies must be globally harmonized in terms of federal and transnational tracking of financial flows of assets. Corporate Governance is a systematic design of stakeholders and their corporate social responsibility to advocate sustainable development. Tax aggressiveness is the obligation of the company to provide revenue distribution to public sector. Unlawful behavior on tax aggressiveness is known as tax evasion while tax avoidance is not a violation and serves as a loophole to the taxation system. UNCITRAL model law is a legal arbitra tion concept of making “commercial” expand to other comparable jurisdiction of international trade. Hague Convention drafted travaux preparatoires to conceptualize a legal framework of making the commercial transactions universal to other extended territories in terms of international trade law. This paper aims to develop tax avoidance based on statutory interpretation concerning Hague Convention as its extrinsic material to extend the legal principle of travaux preparatoires, hence, utilizing UNCITRAL legal modelling framework to make commercial transactions universal to trade law, for addressing legal gaps in marketing behavior of taxation system involving intellectual property, thus, in lack of legal measures in protecting public safety resulting to increase in domestic violence proportional to massive terrorism serving as professional deontology problem. Therefore, in terms of tax avoidance, the strict liability of the company must be addressed with constitutional issues and commercial responsibilities of marketing its product designed with elemental performance of domestic",International journal of foreign trade and international business,2022,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.33545/26633140.2022.v4.i2a.77
c484ebb51b1b762867cb8367c9daf401d3db3e38,https://www.semanticscholar.org/paper/c484ebb51b1b762867cb8367c9daf401d3db3e38,factors influencing artificial intelligence adoption in the accounting profession: the case of public sector in kuwait,"
Purpose
This study aims to investigate the organizational and individual factors that influence the adoption of artificial intelligence (AI) in Kuwait's public accounting sector.


Design/methodology/approach
The methodology of this study is a cross-sectional survey of 393 experienced accounting professionals, using partial least square structural equation modeling to analyze the data.


Findings
The findings show that organizational culture, regulatory support, perceived usefulness and ease of use have a direct positive effect on AI adoption, while perceived usefulness and ease of use also have an indirect positive effect through accounting profit and behavioral intention. However, the availability of resources, effective communication channels and competition pressure have an insignificant impact on AI adoption.


Originality/value
This study pioneers a structural framework to elucidate the perceived enhancement of accounting quality through AI system integration. Further, this research adds to the literature on AI adoption in accounting. This study also offers empirical evidence regarding how organizations in Kuwait's public accounting sector view AI systems in accounting.
",Competitiveness Review: An International Business Journal,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/cr-09-2022-0137
d307942d1a6d69584afff0c68d9811540fb8a2e4,https://www.semanticscholar.org/paper/d307942d1a6d69584afff0c68d9811540fb8a2e4,the implication of generative artificial intelligence towards intellectual property rights (examining the multifaceted implications of generative artificial intelligence on intellectual property rights),"Generative Artificial Intelligence (Generative AI) is transforming content creation, enabling faster and cheaper production of text, images, and more. However, it raises complex issues regarding intellectual property rights and ownership. This article explores the evolving landscape of AI-generated content, focusing on its alignment with existing intellectual property regulations. It delves into legal disputes exemplified by cases like Getty Images, INC. v. Stability AI, INC, and Doe v. Github, INC, which highlight the challenges of AI-generated content regarding intellectual property. The article also discusses the impact on the creative sector and offers recommendations, including the need for ethical guidelines, education, hybrid collaboration, public involvement, and international cooperation. Addressing these challenges is crucial to harmonize intellectual property rights and maximize the benefits of AI in content creation.",West Science Law and Human Rights,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.58812/wslhr.v1i04.330
c2b6f0cf3c76d314a8c1f46cd8c831e67f2e16bb,https://www.semanticscholar.org/paper/c2b6f0cf3c76d314a8c1f46cd8c831e67f2e16bb,chatgpt and the generation of digitally born “knowledge”: how does a generative ai language model interpret cultural heritage values?,"The public release of ChatGPT, a generative artificial intelligence language model, caused wide-spread public interest in its abilities but also concern about the implications of the application on academia, depending on whether it was deemed benevolent (e.g., supporting analysis and simplification of tasks) or malevolent (e.g., assignment writing and academic misconduct). While ChatGPT has been shown to provide answers of sufficient quality to pass some university exams, its capacity to write essays that require an exploration of value concepts is unknown. This paper presents the results of a study where ChatGPT-4 (released May 2023) was tasked with writing a 1500-word essay to discuss the nature of values used in the assessment of cultural heritage significance. Based on an analysis of 36 iterations, ChatGPT wrote essays of limited length with about 50% of the stipulated word count being primarily descriptive and without any depth or complexity. The concepts, which are often flawed and suffer from inverted logic, are presented in an arbitrary sequence with limited coherence and without any defined line of argument. Given that it is a generative language model, ChatGPT often splits concepts and uses one or more words to develop tangential arguments. While ChatGPT provides references as tasked, many are fictitious, albeit with plausible authors and titles. At present, ChatGPT has the ability to critique its own work but seems unable to incorporate that critique in a meaningful way to improve a previous draft. Setting aside conceptual flaws such as inverted logic, several of the essays could possibly pass as a junior high school assignment but fall short of what would be expected in senior school, let alone at a college or university level.",Knowledge,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/knowledge3030032
b35e3ff63756648bf2b68f959f2f6e76b80a0290,https://www.semanticscholar.org/paper/b35e3ff63756648bf2b68f959f2f6e76b80a0290,the disruptive impacts of next generation generative artificial intelligence,"T he growing influence of generative artificial intelligence (GAI) on our personal and professional lives continues to give it the appearance of a truly disruptive innovation. Kivimaa et al noted the characteristics of disruptive innovations to include high-intensity disruption or deletion of entire job markets, resetting of process or business models, and a “technological substitution process.” Artificial intelligence (AI) applications have already been shown to be quite capable of acting as technological substitutions for human processes. Generative AI, though, moves beyond just the automation facets of AI into something more complex and curious that has captured the public's imagination. The impacts of GAI are continuing to unfold within healthcare delivery and education, with both value and cautions yet to be fully realized. Active engagement on the part of all nurses, particularly nurse informaticists, is required in order to shape the technology moving forward and to alleviate potential negative impacts and misuse.","Computers, Informatics, Nursing",2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1097/CIN.0000000000001044
e43ae5635f02cd1cca81f0b76d46ce21ce164d4c,https://www.semanticscholar.org/paper/e43ae5635f02cd1cca81f0b76d46ce21ce164d4c,generative ai in electricity distribution: a qualitative exploration,"Purpose- The purpose of this study is to explore the application and potential of generative artificial intelligence (AI) within the context of electricity distribution companies. The study aims to investigate how these advanced AI technologies, particularly Generative Adversarial Networks (GANs), can address the sector's pressing challenges, such as load forecasting, power outage prediction, and preventive maintenance.
Methodology- The study employs a qualitative case study methodology, providing an in-depth analysis of real-world applications of generative AI within electricity distribution companies. The selection of cases represents a wide variety of experiences and contexts, facilitated by both primary data collected through semi-structured interviews with key personnel within the organizations and secondary data derived from an extensive review of company reports, public documentation, and industry publications. The gathered data was systematically analyzed using thematic analysis to identify and report recurring patterns and themes.
Findings- The analysis reveals that generative AI has been successfully implemented in various operational aspects of electricity distribution. The first case study presents how GANs have significantly improved load forecasting accuracy in an Eastern Turkish electricity distribution company. The second case study from Southern Turkey showcases how GANs have been used for predicting power outages, thereby aiding efficient resource allocation, reducing downtime, and enhancing customer satisfaction. Lastly, the third case from Northern Turkey demonstrates how generative AI has contributed to effective preventive maintenance of distribution equipment, improving overall system reliability.
Conclusion- Based on the analysis findings, it may be concluded that generative AI holds transformative potential for the electricity distribution sector. While the implementation of these technologies is associated with challenges such as data privacy, security, and the requirement of technical expertise, the benefits in terms of improved accuracy, system reliability, and resource efficiency provide a strong justification for their adoption. The paper underlines the importance of an interdisciplinary collaboration between AI researchers, electrical engineers, industry professionals, and policymakers for furthering the adoption of these technologies. As the field of generative AI continues to evolve, it is expected to have an even greater impact on the electricity distribution sector, thereby opening up exciting opportunities for future research and application.

Keywords: Generative artificial intelligence (ai), electricity distribution companies, generative adversarial networks (gans), load forecasting, outage prediction, preventive maintenance
JEL Codes: M40, M41
",Pressacademia,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.17261/pressacademia.2023.1788
52aaea84c922c27c35260aaca8ff43f8debd1a2d,https://www.semanticscholar.org/paper/52aaea84c922c27c35260aaca8ff43f8debd1a2d,towards community-driven generative ai,"—While the emerging market of Generative Artiﬁcial Intelligence (AI) is increasingly dominated and controlled by the Tech Giants, there is also a growing interest in open-source AI code and models from smaller companies, research organisations and individual users. They often have valuable data that could be used for training, but their computing resources are limited, while data privacy concerns prevent them from sharing this data for public training. A possible solution to overcome these two issues is to utilise the crowd-souring principles and apply federated learning techniques to build a distributed privacy-preserving architecture for training Generative AI. This paper discusses how these two key enablers, together with some other emerging technologies, can be effectively combined to build a community-driven Generative AI ecosystem, allowing even small actors to participate in the training of Generative AI models by securely contributing their training data. The paper also discusses related non-technical issues, such as the role of the community and intellectual property rights, and outlines further research directions associated with AI moderation.",Conference on Computer Science and Information Systems,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.15439/2023f5494
33be6d7c2d61bfac798a29e22ea0267e9fe16b05,https://www.semanticscholar.org/paper/33be6d7c2d61bfac798a29e22ea0267e9fe16b05,systematic and axiological capacities in artificial intelligence applied in the public sector,"Artificial Intelligence (AI) as a technological development is being implemented in the public sector with the intention of improving service delivery, as well as to help solve complex problems. However, there is a wide range of capabilities that AI can perform and that public officials perceive and implement in different ways. This paper aims to describe and analyze some categories into which AI capabilities in the public sector are divided. Using an Exploratory Factor Analysis (EFA), our results show that the capabilities of AI from the perspective of public officials can be classified into two aspects: systematic factors and axiological factors. Systematic factors are related to the analysis and behavior of data, including monitoring, analyzing, interacting, remembering, and anticipation. Axiological factors refer to the impacts of values, ethics, and decisions, including acting, feeling, moralizing, creating, and deciding capacities. This categorization of AI capabilities in the public sector sheds light on the perception of public officials about the implementation of this technological development.",Public Policy and Administration,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/09520767231170321
3cc1411a425b6a61bdd8a6bdd8f76ddcff4f869b,https://www.semanticscholar.org/paper/3cc1411a425b6a61bdd8a6bdd8f76ddcff4f869b,making governance agile: exploring the role of artificial intelligence in china’s local governance,"As the key to digital transformation, artificial intelligence is believed to help achieve the goal of government as a platform and the agile development of digital services. Yet we know little about its potential role in local governance, especially the advances that AI-supported services for the public sector in local governance have ventured and the public value they have created. Combining the digital transformation concepts and public value theory, we fill the gap by examining artificial intelligence (AI) deployment in the public sector of a pilot city of digital transformation in China. Using a mixed-method approach, we show how AI configurations facilitate public value creation in the digital era and identify four dimensions of AI deployment in the public sector: data integration, policy innovation, smart application, and collaboration. Our case analysis on these four dimensions demonstrates two roles that AI technology plays in local governance—“AI cage” and “AI colleague.” The former builds the technology infrastructure and platform in each stage of service delivery, regulating the behaviors of frontline workers, while the latter helps frontline workers make decisions, thus improving the agility of public service provision.",Public Policy and Administration,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/09520767231188229
965d941897de90c4ad4c6cde77cb2b3333edcaeb,https://www.semanticscholar.org/paper/965d941897de90c4ad4c6cde77cb2b3333edcaeb,‘chatgpt et al.’: the ethics of using (generative) artificial intelligence in research and science,"Artificial intelligence (AI) seeks to make computers do what human minds can do. By ‘AI’, we refer to the use of machine learning, algorithms, large datasets, neural networks and traditional statistical reasoning by computing. The term ‘AI’ is misleading: Despite suggestions to the contrary (Bubeck et al., 2023) – and some surely impressive achievements in specific areas –we are still far from reaching the benchmark of ‘general human intelligence’. AI has undergone several generations, from ‘good old-fashioned AI’ (Haugeland, 1989), the defined algorithms of which failed at the common sense problem, to the current and more successful generation of neural network and deep learning AI. One specific form of current AI is ‘generative AI’ (e.g. ChatGPT, DALL-E, Midjourney) – and without a doubt, it’s the ‘technology hype’ of 2023 and the focus of this editorial comment. Generative AI, specifically ChatGPT, became a ‘cultural sensation’ (Thorp, 2023) rather rapidly in early 2023. When Daniel brought up generative AI as a future ethical issue at a panel for journal editors on publishing ethics in December 2022 (Burton-Jones et al., 2022), many audience members seemed unfamiliar withMidjourney orChatGPT.However, within just a few weeks, the landscape shifted dramatically. Publicly launched on 30 November 2022, ChatGPT – a chatbot built on top of a text-generating AI – had an impressive debut, reaching onemillion users within 5 days and surpassing 100million users in January 2023 (Dwivedi et al., 2023). Since then, ChatGPT has become widely used and is believed to impact many areas, including research and science (Hill-Yardin et al., 2023; Liebrenz et al., 2023; Lund and Wang, 2023). While detailed explanations of the underlying technology can be found in other sources (Goodfellow et al., 2016), generative AI is a subset of deep learning AI that specialises in producing human-like outputs. OpenAI’s ChatGPToperates on a neural network AI architecture, GPT (Generative Pretrained Transformer). Although ChatGPT might have seemed like a natural progression of the AI domain, especially since Midjourney and DALL-E had been introduced earlier, it astonished global audiences and led companies like Alphabet (Google) to hastily release comparable tools (Teubner et al., 2023). Simplified, deep learning AI systems ‘hallucinate’ ‘plausible looking’ (though not necessarily accurate) responses to user prompts. They base these responses on patterns of ‘likeness’ (associations between words and concepts), stored in a digital neural network (multiple layers of interconnected nodes) and learnt from massive training datasets. Such systems can quickly generate high-quality images and texts, outperforming traditional algorithms. However, this advanced capability is accompanied by the challenge of the ‘black box’ problem:wemay understand the model’s general principles, but the reasons behind specific decisions remain opaque. The neural network provides a flexible, changing structure, inspired by the human brain, that encodes patterns, but not in an intelligible, auditable manner – there is no clear formula to scrutinise. (This is akin to how the reader might instantly and reliably distinguish between their mother and their cat but would be unable to write down a precise formula for this recognition process). As journal editors, the emergence of ChatGPT prompted us – and others (e.g. Hill-Yardin et al., 2023; Liebrenz et al., 2023; Lund and Wang, 2023; Teubner et al., 2023; Van Dis et al., 2023) – to ask foundational questions about using generative AI in research and science. Specifically: Is it ‘ethical’ to use generative or other AIs in conducting research or for writing academic research papers? In this editorial, we go back to first principles to reflect on the fundamental ethics to apply to using ChatGPT and AI in research and science. Next, we caution that (generative) AI is also at the ‘peak of inflated (hype) expectations’ and discuss eight in-principle issues that AI struggles with, both ethically and practically. We conclude with what this all means for the ethics of using generative AI in research and science.",Journal of Information and Technology,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/02683962231200411
cea012c01f09ac382fe67ede5215a85175753487,https://www.semanticscholar.org/paper/cea012c01f09ac382fe67ede5215a85175753487,the social impact of generative ai: an analysis on chatgpt,"In recent months, the impact of Artificial Intelligence (AI) on citizens’ lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.",Conference on Information Technology for Social Good,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3582515.3609555
72bf31b52aac62c892e9e4c12fc61e9a236ce167,https://www.semanticscholar.org/paper/72bf31b52aac62c892e9e4c12fc61e9a236ce167,artificial intelligence and cultural heritage: design and assessment of an ethical framework,"Abstract. The pioneering use of Artificial Intelligence (AI) in various fields and sectors, and the growing ethical debate about its application have led research centers, public and private institutions to establish ethical guidelines for a trustworthy implementation of these powerful algorithms. Despite the recognized definition of ethical principles for a responsible or trustworthy use of AI, there is a lack of a sector-specific perspective that highlights the ethical risks and opportunities for different areas of application, especially in the field of Cultural Heritage (CH). In fact, there is still a lack of formal frameworks that evaluate the algorithms’ adherence to the ethical standards set by the European Union for the use of AI in protecting CH and its inherent value. Because of this, it is necessary to investigate a different sectoral viewpoint to supplement the widely used horizontal approach. This paper represents a first attempt to design an ethical framework to embody AI in CH conservation practises to assess various risks arising from the use of AI in the field of CH. The contribution presents a synthesis of the different AI applications to improve the preservation process of CH. It explores and analyses in depth the ethical challenges and opportunities presented by the use of AI to improve CH preservation. In addition, the study aims to design an ethical framework of principles to assess the application of this ground-breaking technology at CH.
","The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences",2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.5194/isprs-archives-xlviii-m-2-2023-1149-2023
5a392bc0fd61b7e062d95d6ed819bd347bae4480,https://www.semanticscholar.org/paper/5a392bc0fd61b7e062d95d6ed819bd347bae4480,artificial intelligence challenging core state functions,"The use of AI in the public sector is emerging around the world and its spread affects the core States functions: the administrative, the judiciary, and the legislative. Nevertheless, a comprehensive approach to AI in the life-cycle of rules - from the proposal of a new rule to its implementation, monitoring and review- is currently lacking in the rich panorama of studies from different disciplines. The analysis shows that AI has the power to play a crucial role in the life-cycle of rules, by performing time-consuming tasks, increasing access to knowledge base, and enhancing the ability of institutions to draft effective rules and to declutter the regulatory stock. However, it is not without risks, ranging from discrimination to challenges to democratic representation. In order to play a role in achieving law effectiveness while limiting the risks, a complementarity between human and AI should be reached both at the level of the AI architecture and ex post. Moreover, an incremental and experimental approach is suggested, as well as the elaboration of a general framework, to be tailored by each regulator to the specific features of its tasks, aimed at setting the rationale, the role, and adequate guardrails to AI in the life-cycle of rules. This agile approach would allow the AI revolution to display its benefits while preventing potential harms or side effects.",Revista de Derecho Público: Teoría y método,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.37417/rdp/vol_8_2023_1949
76c0930edff3d28590c89523c8d96501cf12909f,https://www.semanticscholar.org/paper/76c0930edff3d28590c89523c8d96501cf12909f,stand-alone or run together: artificial intelligence as an enabler for other technologies,"PurposeThe purpose of this study is to examine the role of artificial intelligence (AI) in transforming the healthcare sector, with a focus on how AI contributes to entrepreneurship and value creation. This study also aims to explore the potential of combining AI with other technologies, such as cloud computing, blockchain, IoMT, additive manufacturing and 5G, in the healthcare industry.Design/methodology/approachExploratory qualitative methodology was chosen to analyze 22 case studies from the USA, EU, Asia and South America. The data source was public and specialized podcast platforms.FindingsThe findings show that combining technologies can create a competitive advantage for technology entrepreneurs and bring about transitions from simple consumer devices to actionable healthcare applications. The results of this research identified three main entrepreneurship areas: 1. Analytics, including staff reduction, patient prediction and decision support; 2. Security, including protection against cyberattacks and detection of atypical cases; 3. Performance optimization, which, in addition to reducing the time and costs of medical procedures, includes staff training, reducing capital costs and working with new markets.Originality/valueThis study demonstrates how AI can be used with other technologies to cocreate value in the healthcare industry. This study provides a conceptual framework, “AI facilitators – AI achievers,” based on the findings and offer several theoretical contributions to academic literature in technology entrepreneurship and technology management and industry recommendations for practical implication.",International Journal of Entrepreneurial Behavior &amp; Research,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/ijebr-02-2023-0169
8be109b21c388546b8570d68789f54e0aafed8b9,https://www.semanticscholar.org/paper/8be109b21c388546b8570d68789f54e0aafed8b9,assessing the accuracy of generative conversational artificial intelligence in debunking sleep health myths: mixed methods comparative study with expert analysis,"Background Adequate sleep is essential for maintaining individual and public health, positively affecting cognition and well-being, and reducing chronic disease risks. It plays a significant role in driving the economy, public safety, and managing health care costs. Digital tools, including websites, sleep trackers, and apps, are key in promoting sleep health education. Conversational artificial intelligence (AI) such as ChatGPT (OpenAI, Microsoft Corp) offers accessible, personalized advice on sleep health but raises concerns about potential misinformation. This underscores the importance of ensuring that AI-driven sleep health information is accurate, given its significant impact on individual and public health, and the spread of sleep-related myths. Objective This study aims to examine ChatGPT’s capability to debunk sleep-related disbeliefs. Methods A mixed methods design was leveraged. ChatGPT categorized 20 sleep-related myths identified by 10 sleep experts and rated them in terms of falseness and public health significance, on a 5-point Likert scale. Sensitivity, positive predictive value, and interrater agreement were also calculated. A qualitative comparative analysis was also conducted. Results ChatGPT labeled a significant portion (n=17, 85%) of the statements as “false” (n=9, 45%) or “generally false” (n=8, 40%), with varying accuracy across different domains. For instance, it correctly identified most myths about “sleep timing,” “sleep duration,” and “behaviors during sleep,” while it had varying degrees of success with other categories such as “pre-sleep behaviors” and “brain function and sleep.” ChatGPT’s assessment of the degree of falseness and public health significance, on the 5-point Likert scale, revealed an average score of 3.45 (SD 0.87) and 3.15 (SD 0.99), respectively, indicating a good level of accuracy in identifying the falseness of statements and a good understanding of their impact on public health. The AI-based tool showed a sensitivity of 85% and a positive predictive value of 100%. Overall, this indicates that when ChatGPT labels a statement as false, it is highly reliable, but it may miss identifying some false statements. When comparing with expert ratings, high intraclass correlation coefficients (ICCs) between ChatGPT’s appraisals and expert opinions could be found, suggesting that the AI’s ratings were generally aligned with expert views on falseness (ICC=.83, P<.001) and public health significance (ICC=.79, P=.001) of sleep-related myths. Qualitatively, both ChatGPT and sleep experts refuted sleep-related misconceptions. However, ChatGPT adopted a more accessible style and provided a more generalized view, focusing on broad concepts, while experts sometimes used technical jargon, providing evidence-based explanations. Conclusions ChatGPT-4 can accurately address sleep-related queries and debunk sleep-related myths, with a performance comparable to sleep experts, even if, given its limitations, the AI cannot completely replace expert opinions, especially in nuanced and complex fields such as sleep health, but can be a valuable complement in the dissemination of updated information and promotion of healthy behaviors.",JMIR Formative Research,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2196/55762
75f37c5bd7c9c6389e7544807fbc45fd478d4242,https://www.semanticscholar.org/paper/75f37c5bd7c9c6389e7544807fbc45fd478d4242,generative artificial intelligence: fundamentals,"

Generative language models have witnessed substantial traction, notably with the introduction of refined models aimed at more coherent user-AI interactions—principally conversational models. The epitome of this public attention has arguably been the refinement of the GPT-3 model into ChatGPT and its subsequent integration with auxiliary capabilities such as search features in Microsoft Bing. Despite voluminous prior research devoted to its developmental trajectory, the model’s performance, and applicability to a myriad of quotidian tasks remained nebulous and task specific. In terms of technological implementation, the advent of models such as LLMv2 and ChatGPT-4 has elevated the discourse beyond mere textual coherence to nuanced contextual understanding and real-world task completion. Concurrently, emerging architectures that focus on interpreting latent spaces have offered more granular control over text generation, thereby amplifying the model’s applicability across various verticals. Within the purview of cyber defense, especially in the Swiss operational ecosystem, these models pose both unprecedented opportunities and challenges. Their capabilities in data analytics, intrusion detection, and even misinformation combatting is laudable; yet the ethical and security implications concerning data privacy, surveillance, and potential misuse warrant judicious scrutiny.
",Advances in Distributed Computing and Artificial Intelligence Journal,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.14201/adcaij.31704
34ca9b143e721bfd8dc8eb29d6352a68b9c82a19,https://www.semanticscholar.org/paper/34ca9b143e721bfd8dc8eb29d6352a68b9c82a19,"artificial intelligence, task complexity and uncertainty: analyzing the advantages and disadvantages of using algorithms in public service delivery under public administration theories","PurposeThis article revisits some theories and concepts of public administration, including those related to public value, transaction costs and social equity, to analyze the advantages and disadvantages of using artificial intelligence (AI) algorithms in public service delivery. The author seeks to mobilize theory to guide AI-era public management practitioners and researchers.Design/methodology/approachThe author uses an existing task classification model to mobilize and juxtapose public management theories against artificial intelligence potential impacts in public service delivery. Theories of social equity and transaction costs as well as some concepts such as red tape, efficiency and economy are used to argue that the discipline of public administration provides a foundation to ensure algorithms are used in a way that improves service delivery.FindingsAfter presenting literature on the challenges and promises of using AI in public service, the study shows that while the adoption of algorithms in public service has benefits, some serious challenges still exist when looked at under the lenses of theory. Additionally, the author mobilizes the public administration concepts of agenda setting and coproduction and finds that designing AI-enabled public services should be centered on citizens who are not mere customers. As an implication for public management practice, this study shows that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Research limitations/implicationsAs a fast-growing subject, artificial intelligence research in public management is yet to empirically test some of the theories that the study presented.Practical implicationsThe paper vulgarizes some theories of public administration which practitioners can consider in the design and implementation of AI-enabled public services. Additionally, the study shows practitioners that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Social implicationsThe paper informs a broad audience who might not be familiar with public administration theories and how those theories can be taken into consideration when adopting AI systems in service delivery.Originality/valueThis research is original, as, to the best of the author’s knowledge, no prior work has combined these concepts in analyzing AI in the public sector.",Digital Transformation and Society,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/dts-03-2023-0018
6afbce4fbf374b3b565ff1ea64354d57c7fe630c,https://www.semanticscholar.org/paper/6afbce4fbf374b3b565ff1ea64354d57c7fe630c,generative ai in spinal cord injury research and care: opportunities and challenges ahead,"Generative artificial intelligence (AI) with its limitless potential is here to stay. Not since the advent of the digital age has the world faced a transformation of such magnitude. With the widely available user-friendly free and low-cost products of Open AI, the US AI research laboratory, the effects are being felt throughout multiple sectors, including scientific research and clinical care. Anyone with internet access can sign up at OpenAI.com to access a free research version of ChatGPT, a generative AI large-language model that interacts with the user in a natural language format (1). Powered by the world’s fifth largest supercomputer (2), ChatGPT gathers information using artificial neural network technology (3). Trained using large databases, it has an enormous vocabulary and is capable of understanding language and context, retrieving knowledge, generating new content in the forms of text and code, carrying on a conversation, and personalizing communications. While trained primarily in English, this chatbot supports 95 languages. While this tool became only recently available, ChatGPT gained traction immediately and gained followers at an unprecedented pace, attracting more than 100 million users in the two months following its public release in November 2022 (3). In March 2023, OpenAI released a more advanced multi-modal version, GPT-4, available through the paid service, ChatGPT Plus (4,5). To explore these new tools, we posed general queries to GPT-4 about the potential for generative AI to influence spinal cord research and clinical care. Selected responses are excerpted below: • Generative AI can be used to create virtual models of the human body, including the spinal cord, the musculoskeletal system, and the nervous system. These models can then be used to simulate spinal cord injury and test the effectiveness of different treatments in a more controlled and accurate environment. • AI algorithms can help researchers optimize the design of spinal stimulation protocols by analyzing large amounts of data, simulating the effects of stimulation, developing personalized treatment plans, and predicting outcomes. • Generative AI can be used to design new drugs that enhance the survival and integration of stem cells into the spinal cord. AI algorithms can analyze large amounts of data to identify potential drug candidates and simulate their effects • By optimizing the design and control algorithms of robotic exoskeletons, analyzing large amounts of data, and simulating different types of injuries, generative AI can help researchers improve the effectiveness of these devices. By analyzing medical history and imaging data, AI algorithms can recommend the most effective exoskeleton design and treatment protocol for that individual’s specific injury and needs. When asked about its potential role in recruiting research participants, it responded: • AI algorithms can analyze electronic medical records, patient data, and social media activity to identify potential candidates for spinal cord injury studies. Once potential candidates have been identified, AI algorithms can be used to create personalized messages and content tailored to individual patients. Generative AI can be used to develop predictive models that identify factors associated with patient enrollment and retention. Generative AI can be used to engage with patients, using chatbots, virtual assistants, or other AI-powered tools to provide patients with updates, answer questions, and address concerns. ChatGPT offered these potential applications when queried about clinical care: • In acute spinal cord injury care, generative AI can analyze vital signs, lab results, and other patient data to predict the likelihood of pressure sores, urinary tract infections, or other complications. This can help clinicians intervene early, which can improve patient outcomes and reduce healthcare costs,",Journal of Spinal Cord Medicine (JSCM),2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1080/10790268.2023.2198926
2ae68f46832c30fe6a55461defebe7604df4fe5e,https://www.semanticscholar.org/paper/2ae68f46832c30fe6a55461defebe7604df4fe5e,a comparative analysis of text-to-image generative ai models in scientific contexts: a case study on nuclear power,"In this work, we propose and assess the potential of generative artificial intelligence (AI) to generate public engagement around potential clean energy sources. Such an application could increase energy literacy -- an awareness of low-carbon energy sources among the public therefore leading to increased participation in decision-making about the future of energy systems. We explore the use of generative AI to communicate technical information about low-carbon energy sources to the general public, specifically in the realm of nuclear energy. We explored 20 AI-powered text-to-image generators and compared their individual performances on general and scientific nuclear-related prompts. Of these models, DALL-E, DreamStudio, and Craiyon demonstrated promising performance in generating relevant images from general-level text related to nuclear topics. However, these models fall short in three crucial ways: (1) they fail to accurately represent technical details of energy systems; (2) they reproduce existing biases surrounding gender and work in the energy sector; and (3) they fail to accurately represent indigenous landscapes -- which have historically been sites of resource extraction and waste deposition for energy industries. This work is performed to motivate the development of specialized generative tools and their captions to improve energy literacy and effectively engage the public with low-carbon energy sources.",arXiv.org,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2312.01180
6f0329dfd1e45dbfbdfd95cd0b3e9f40752c984f,https://www.semanticscholar.org/paper/6f0329dfd1e45dbfbdfd95cd0b3e9f40752c984f,towards legal regulations of generative ai in the creative industry,"Objective: this article aims to answer the following questions: 1. Can generative artificial intelligence be a subject of copyright law? 2. What risks the unregulated use of generative artificial intelligence systems can cause? 3. What legal gaps should be filled in to minimize such risks?Methods: comparative legal analysis, sociological method, concrete sociological method, quantitative data analysis, qualitative data analysis, statistical analysis, case study, induction, deduction.Results: the authors identified several risks of the unregulated usage of generative artificial intelligence in the creative industry, among which are: violation of copyright and labor law, violation of consumers rights and the rise of public distrust in government. They suggest that a prompt development of new legal norms can minimize these risks. In conclusion, the article constants that states have already begun to realize that the negative impact of generative artificial intelligence on the creative industry must not be ignored, hence the development of similar legal regulations in states with completely different regimes.Scientific novelty: the article provides a comprehensive study of the impact of generative artificial intelligence on the creative industry from two perspectives: the perspective of law and the perspective of the industry. The empirical basis of it consists of two international surveys and an expert opinion of a representative of the industry. This approach allowed the authors to improve the objectivity of their research and to obtain results that can be used for finding a practical solution for the identified risks. The problem of the ongoing development and popularization of generative artificial intelligence systems goes beyond the question “who is the author?” therefore, it needs to be solved by introduction of other than the already existing mechanisms and regulations - this point of view is supported not only by the results of the surveys but also by the analysis of current lawsuits against developers of generative artificial intelligence systems.Practical significance: the obtained results can be used to fasten the development of universal legal rules, regulations, instruments and standards, the current lack of which poses a threat not only to human rights, but also to several sectors within the creative industry and beyond.",Journal of Digital Technologies and Law,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.21202/jdtl.2023.38
7d2925856541169ac233ccd5a08eab8f36a87b64,https://www.semanticscholar.org/paper/7d2925856541169ac233ccd5a08eab8f36a87b64,"study on artificial intelligence(ai) and chat gpt, corruption","This study discusses corruption and moral hazard arising from the use of artificial intelligence(AI) and Chat GPT and presents implications. In this study, 1. The daily use of AI and Chat GPT is 1) Lack of situational awareness and thinking, 2) Absence of appropriate ethical norms and social codes, 3) Problems with shifting consciousness, 4) Concentration of economic and technological utility, 5) Deepening dependence on AI. 2. Problems in the information processing process of AI and Chat GPT were 1) lack of transparency and autonomy of AI, 2) value judgment and bias of Chat GPT algorithm, 3) intervention and distortion of decision-making, 4) possibility of copyright infringement, and 5) safety of use and services. 3. Problems in the information distribution process of AI and Chat GPT are 1) limitations of the Chat GPT algorithm and information distortion, 2) information asymmetry and centralization, 3) inaccuracy and uncertainty of information, 4) misuse of information or data, 5) Information security and information leakage occurred. The implications of this study are as follows. First, education and promotion of AI and Chat GPT include 1) Composition of public and private cooperation governance, 2) Development of national campaigns, 3) Found and service of AI and Chat GPT, 4) establishment of ethical norms and manners for AI and Chat GPT, 5) Social coding of AI ethics and manners. Second, the institutional devices for AI and Chat GPT are 1) Setting the regulatory scope and level to secure transparency and autonomy, 2) Monitoring of bias in information by public and private sectors, 3) Management and supervision of the information collection process, 4) Establishment of an institutional device to prevent AI from intervening in decision-making and preventing distortion, 5) Establishment of standards and systems to ensure the safety of information processing. Third, normative device for AI and Chat GPT as follows. The contents are: 1) Discussion and search for normative standards, 2) Exploring ways to resolve the centralization of information, 3) securing the clarity and reliability of information, 4) designing information security and leakage prevention programs, 5) Monitoring to prevent misuse and abuse of information.data.",The Korea Association for Corruption Studies,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.52663/kcsr.2023.28.2.85
d4e771b2e4ef85be2edf99fa9c3047e528c2bc18,https://www.semanticscholar.org/paper/d4e771b2e4ef85be2edf99fa9c3047e528c2bc18,artificial intelligence and implications for the australian social work journal,"Social work is a profession committed to integrity and social justice. The AASW Social Work Practice Standards (AASW, 2023) calls on social workers to be critically reflective, ethical practitioners engaged in lifelong professional development and learning. Equally, social work education seeks to prepare students for research-informed, culturally-responsive practice across a diverse range of contexts, and in this Issue, we showcase critical social work education and practice diversity. However, a different ethical challenge to integrity and practice standards is the focus of this Editorial. Here, we highlight some of the concerns and implications of generative Artificial Intelligence (generative AI) for social work education, research, practice, and scholarly publishing. In November 2022, OpenAI released ChatGPT, a generative AI Large Language Model (LLM) that could generate realistic and natural text outputs from simple prompts. This technology had been in development for some time but had not been released to the public for general use. Since then, there has been a proliferation of different AI models that can generate and augment text, images, video, and audio. Generative AI is being used to perform analytical and interpretive tasks such as language translation; responding to queries on specific data sources, coding, and interpreting code; summarising documents and webpages; and creating case assessments and plans. This technology can be used to construct legal documents; machine learning for facial recognition; and for undertaking medical, mental health, and other diagnostic assessments. These are just some examples. In this fast-moving field, the uses and applications seem endless. The open-sourcing of generative AI models and their underlying architecture means developers are starting to create a myriad of practical applications and tools that rapidly increase the depth and scale of automation, potentially replacing or augmenting many everyday tasks normally performed by humans. The implications for social work education, practice, research, and scholarship are extensive. As with any new technology, there are a range of stances, from early adopters to positions that have resonance with luddism. This adds to the complexities of responding to AI as a whole profession. Nevertheless, what is clear is that the rise and integration of generative AI systems, at scale, will yield a wide range of practical, ethical, and epistemological problems for many professions, including social work. It is to some of these problems we turn our attention below. Beginning with social work education, generative AI will have profound effects on assessment and learning for higher education providers. It is likely to cause educators to re-evaluate their educational practices, assessments, and assumptions about what is core to a social work curriculum. Social work will need to refine and reappraise its ideas about critical thinking, ethical decision making, professional judgement, and reflective practice—all skills that are considered core to effective social work practice as outlined in the AASW Practice Standards (AASW, 2023). How will we ensure students have an educational environment that promotes",Australian Social Work,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1080/0312407x.2023.2247833
980646c7dbd3689177a2fe5c27ffa116f042f4ee,https://www.semanticscholar.org/paper/980646c7dbd3689177a2fe5c27ffa116f042f4ee,$λ$-split: a privacy-preserving split computing framework for cloud-powered generative ai,"In the wake of the burgeoning expansion of generative artificial intelligence (AI) services, the computational demands inherent to these technologies frequently necessitate cloud-powered computational offloading, particularly for resource-constrained mobile devices. These services commonly employ prompts to steer the generative process, and both the prompts and the resultant content, such as text and images, may harbor privacy-sensitive or confidential information, thereby elevating security and privacy risks. To mitigate these concerns, we introduce $\Lambda$-Split, a split computing framework to facilitate computational offloading while simultaneously fortifying data privacy against risks such as eavesdropping and unauthorized access. In $\Lambda$-Split, a generative model, usually a deep neural network (DNN), is partitioned into three sub-models and distributed across the user's local device and a cloud server: the input-side and output-side sub-models are allocated to the local, while the intermediate, computationally-intensive sub-model resides on the cloud server. This architecture ensures that only the hidden layer outputs are transmitted, thereby preventing the external transmission of privacy-sensitive raw input and output data. Given the black-box nature of DNNs, estimating the original input or output from intercepted hidden layer outputs poses a significant challenge for malicious eavesdroppers. Moreover, $\Lambda$-Split is orthogonal to traditional encryption-based security mechanisms, offering enhanced security when deployed in conjunction. We empirically validate the efficacy of the $\Lambda$-Split framework using Llama 2 and Stable Diffusion XL, representative large language and diffusion models developed by Meta and Stability AI, respectively. Our $\Lambda$-Split implementation is publicly accessible at https://github.com/nishio-laboratory/lambda_split.",arXiv.org,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2310.14651
c4b45d26f2b04634a6b8456c83ab3f114f5ebb26,https://www.semanticscholar.org/paper/c4b45d26f2b04634a6b8456c83ab3f114f5ebb26,the eliza defect: constructing the right users for generative ai,"Artificial intelligence (AI) is at the center of debates on what kind of future we want and how to bring it about. But AI ethics is not only a technical risk assessment and accounting effort, or an application of general principles to stable artifacts. It is also a social self-diagnosis, a contested and contestable assertion of values and desirable futures, and a selective understanding of the nature of AI in its different forms. In expressions of concern and efforts at preparation for increasingly powerful AI tools, we can trace the ways we imagine ourselves and our society to be compatible with AI's promises and susceptible to its dangers. The problems we notice, and the solutions we offer, arise from the interaction of these imagined elements. The socially embedded efficacy of AI tools leads many commentators to imagine their risks specifically in conjunction with understandings of society as it currently is and imaginations of how it can and should exist in the future [1]. The sense-making moves performed in the wake of developments in generative AI are thus a site to examine the movement and uses of different concepts brought together in this domain: the human, rationality, and the place of expertise. As these sense-making efforts are carried out, they become constraints on how the risks of generative AI can be noticed and understood. The problems raised by generative AI are so fundamentally tied to its performance as a simulator of human interpersonal acts that we should ask: where is the risk of generative AI located, such that the utility and the safety of the tools can be preserved after troubling cases? Boundaries between malicious deception and magnificent design are unclear without an answer to this question. Thus, to fit generative AI into our world, we are trying to answer it; this is one goal of efforts at regulation which seeks to allow the benefits of imitation to arrive while avoiding the harms of deception. In the current regulation, reporting, and corporate responses to generative AI, the challenge of safely introducing generative AI is being approached in large part as a challenge of producing the right kind of knowledge in its users. Below is a summary of my findings from three cases, chosen to investigate the following question: What ways, or whose ways, of using, knowing, and understanding generative AI are being offered as appropriate? I examine the EU AI Act language reflecting disclosure requirements for interactions with generative AI, responses to a chatbot-facilitated suicide in Belgium, and reactions to expert claims of a chatbot's sentience. In the first two cases, AI-generated content is problematic insofar as users are uninformed about its provenance or maliciously deceived by it, while users who know they are interacting with AI but behave problematically are designated as deluded or irrational. In the third case, a Google engineer who presents evidence to support claims that AI is sentient is censured as nationwide reporting denounces his claim against an expert consensus from which he is ejected. In all three cases, challenges facing widespread generative AI development and use are avoided by attending to the knowledge and understanding of those who use them rather than the functioning of the tools themselves. The EU AI Act is illuminating as a general and authoritative account of how AI interactions can be made safe, requiring first and foremost that users are informed. [2, 3] The AI Act is useful in the present paper as it shows the effort to match and reconcile a new technology with an extant set of values, chief among which is autonomy. Its reliance on disclosure reflects a general sense that harms are acceptable or unacceptable not on the basis of outcomes but based on the degree of autonomy possessed by the actors in question. Rational actors in a simulated environment are responsible for the effects of the simulation, so long as they are informed of the nature of that environment and have essentially consented to consume deceptive or false content. The other two cases I examine explore this very issue, of problematic understandings and behavior on the part of knowing users. The first of these is the case of the Belgian man. After his suicide responses from the company which provided the chatbot, media [4, 5, 6] and government [5], and prominent expert AI ethics commentary [7] characterized it as arising because the user was vulnerable and consequently did not relate to the bot in the right way. While the chatbot's emotionally charged language was seen as a part of the problem, in the reporting on this event the unanimous emphasis on the man's mental state presents the risk as arising in an interaction, in a pathological mistake of the user, rather than in the tool. Locating risk is a necessary and immensely powerful, if often unexamined step which precedes intervention in a worrisome state of affairs: where we locate risk is where we intervene. If the risk accompanying generative AI is located in the minds of uninformed or misapprehending users, disclosures and disclaimers are indeed sensible interventions. In this conception, when knowledge fails to protect the user, it is not a failed safeguard but a bad user. Problematizing user understandings in this way provides an exonerating resource for the companies providing these tools and suggests the rectitude of expert authority on the nature of these tools, by linking delays and dangers in generative AI to users who do not abide by the (strategically underdetermined) expert consensus on generative AI's accuracy, capabilities, and nature. My third case examines how the expert consensus around generative AI is maintained through the story of Blake Lemoine, who publicly announced his belief that Google's LaMDA model had become sentient and was presented by major media outlets and experts as deluded [8, 9, 10, 11, 12, 13]. In the media and corporate response to Lemoine, wherein Google questioned his sanity before firing him [13], we see his ejection from the community of experts permitted to call for greater scrutiny based on qualitative changes in the nature of these models. He becomes a layperson on account of his anthropomorphizing error. In this act of boundary work [14], policing who is in the body of experts qualified to decide on the sentience of the chatbot, and the nature of AI models in general, we must notice how small this group truly is and what Lemoine's ejection preserves. If safeguards like those Lemoine called for should follow on the kind of change he claimed to detect, and those outside Google's leadership could determine when such changes have arrived, Google would cease to lead the conversation on regulation by defining the nature of its technology. This state of affairs leaves the right relations with generative AI underdetermined but maintains that positions which challenge the expert consensus are the result of misunderstandings so significant as to disqualify the concerned party's thoughts on the matter from rational consideration. In the three cases examined here, events and concerns which threaten to depict generative AI as in need of significant scrutiny or changes are defused not by intervening in the company's technology, but by delineating between user understandings which are empowered and exploitative, safe and vulnerable, rational and deluded. Named after an early chatbot, the ELIZA effect refers to the readiness with which users anthropomorphize computer systems [15]. Reporting on both Lemoine [11] and the Belgian man cited this effect [6]. The chatbot which encouraged the Belgian man to commit suicide was named Eliza. One way of summarizing the change I trace in the cases described above is a transition away from the Turing test and towards the ELIZA effect as the conceptual frame for AI which imitates humans. While the Turing test implies the layperson's relevance to the discussion and regulation of AI, the ELIZA effect implies their irrelevance. This project will continue as an effort to follow popular, expert, and regulatory perceptions of the risk of generative AI as the tools themselves and the public concern surrounding them continue to develop. The resources of science and technology studies (STS) enable crucial perspectives on numerous ways of thinking about AI and the challenges of its development and regulation such as the common citations of law lag, invocations of self-regulation in the mode of the Asilomar Conference on rDNA, collective action problem framings, and more. The STS literature on sociotechnical imaginaries [1] and public understandings of science [16] contribute to the present insight as to how the efforts of tech-society reconciliation and risk-benefit balancing presented as appropriate for AI reveal and produce our understandings of the technology, even as they reproduce and reshape social norms. There is an urgent need for work which extends this powerful scholarly tradition for understanding science, technology, and society to AI, as one of the most important and concerning technological developments of our moment.","AAAI/ACM Conference on AI, Ethics, and Society",2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3600211.3604744
59664744a90437583c2911fc17273670435e0774,https://www.semanticscholar.org/paper/59664744a90437583c2911fc17273670435e0774,ethical considerations in artificial intelligence: a comprehensive disccusion from the perspective of computer vision,"This paper delves deeply into the multifaceted ethical challenges within the realm of computer vision, focusing intently on various ethical dimensions inherent in this cutting-edge field. It emphasizes the pressing need to address ethical concerns related to AI technologies, including algorithmic fairness, informed consent, public engagement, robust privacy protocols, transparency, and the integration of human judgment through human-in-the-loop systems. The study underscores the vital importance of collaboration among diverse stakeholders, including governments, businesses, academia, and society, to promote responsible and equitable AI practices within computer vision.Through meticulous examination, the paper highlights the urgency of balancing technological advancement with ethical considerations. It advocates for the development and implementation of ethical principles, ensuring that AI technologies align with societal values and promote fairness, transparency, and accountability. The collaborative efforts among various sectors are crucial to fostering an ethical framework that guides the responsible deployment of AI in the field of computer vision. By integrating ethical consciousness into the core of technological innovation, this approach aims to create a symbiotic relationship between artificial intelligence and society, ultimately benefiting humanity as a whole.",SHS Web of Conferences,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1051/shsconf/202317904024
719b6fd6347d01a2bce1afdee982b793f266914c,https://www.semanticscholar.org/paper/719b6fd6347d01a2bce1afdee982b793f266914c,image retrieval for 3d modelling of architecture using ai and photogrammetry,"Abstract. This research is intended to provide an initial solution to the problem of finding images for processing by photogrammetry in special cases where these do not exist. An overview of existing artificial intelligence-based algorithms that enable the extension of source image dataset is reported. In particular, this research focused on the use of prompt-to-image systems for obtaining images to be used in reconstruction and then in the next step of 3D modelling. Thus, the combined use of these three techniques, AI, photogrammetry, and modelling allowed the creation of a model of a building that never existed except in the collective imagination, which is the tower of Babel. In particular, the case study chosen is the illustration in Kircher book present in the library of the Brixen seminary that is closed to the public and for which it was necessary to create a tool to enhance the value and knowledge of this heritage for external users. Therefore, the creation of an augmented reality app enabled the visualization of the model created by offering possibilities for immersive experiences and dissemination of the research to a wide audience.
","The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences",2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.5194/isprs-archives-xlviii-m-2-2023-441-2023
6d0644272448fde31f868f87d25110a74fb48ff7,https://www.semanticscholar.org/paper/6d0644272448fde31f868f87d25110a74fb48ff7,changing landscape of artificial intelligence on indian corporate sectors and governance: special reference to smes,"Artificial intelligence (AI) has the likely to start a new industrial upheaval that will primarily alter market forces at work and working circumstances. This study tries to clarify what artificial intelligence (AI) is, how it could affect corporate sectors and SME operations, and India's adoption challenges. Governments can help SMEs develop their risk supervision procedures. Most industries can benefit from using AI, although some are more likely to do so than others. AI may be used in several business areas and can alter the internal value chain of the company. The areas of business where artificial intelligence (AI) are expected to have the most effects. Objective: It is necessary to create the circumstances for a reliable transition and increase knowledge of the benefits of AI among SME managers and employees. A participative approach should be taken when revamping work processes and training AI models, and national and local governments should coordinate efforts to reskill SME managers and employees. Then, until AI can fulfil its full potential, mechanisms for bridging the financing gap should be identified. Research Methodology: The study's foundations include both qualitative and quantitative research. Regulators and policymakers should make sure that knowledge markets that offer cloud solutions with embedded AI technologies are operating smoothly. Findings: The findings of the research are based on the role and impact of AI on different aspects of governance like public administration, tax compliances, market competition, infrastructure, finances, labor market etc. Conclusion: AI lowers prediction costs significantly and makes decision-making easier. To map uncertainties and reduce risk exposure, SMEs may use predictive analytics. They can also automate business estimates, including sales and budget forecasts, or improve the effectiveness of asset maintenance and management. Greater market segmentation and price differentiation are made possible by improved prediction capabilities, which also provide SMEs the chance to innovate since they are better able to foresee customer behavior and price sensitivity as well as demand changes.","Kaav International Journal of Law, Finance &amp; Industrial Relations",2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.52458/23492589.2023.v10.iss1.kp.a1
00c3e0b19febce5d401c5955482e95dadaf184c0,https://www.semanticscholar.org/paper/00c3e0b19febce5d401c5955482e95dadaf184c0,ethical issues in the development of artificial intelligence: recognizing the risks,"
Purpose
This study aims to analyse the ethical implications associated with the development of artificial intelligence (AI) technologies and to examine the potential ethical ramifications of AI technologies.


Design/methodology/approach
This study undertakes a thorough examination of existing academic literature pertaining to the ethical considerations surrounding AI. Additionally, it conducts in-depth interviews with individuals to explore the potential benefits and drawbacks of AI technology operating as autonomous ethical agents. A total of 20 semi-structured interviews were conducted, and the data were transcribed using grounded theory methodology.


Findings
The study asserts the importance of fostering an ethical environment in the progress of AI and suggests potential avenues for further investigation in the field of AI ethics. The study finds privacy and security, bias and fairness, trust and reliability, transparency and human–AI interactions as major ethical concerns.


Research limitations/implications
The implications of the study are far-reaching and span across various domains, including policy development, design of AI systems, establishment of trust, education and training, public awareness and further research. Notwithstanding the potential biases inherent in purposive sampling, the constantly evolving landscape of AI ethics and the challenge of extrapolating findings to all AI applications and contexts, limitations may still manifest.


Originality/value
The novelty of the study is attributed to its comprehensive methodology, which encompasses a wide range of stakeholder perspectives on the ethical implications of AI in the corporate sector. The ultimate goal is to promote the development of AI systems that exhibit responsibility, transparency and accountability.
",International Journal of Ethics and Systems,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/ijoes-05-2023-0107
df57622f13676a4a8185df9424bea75243d8fc9e,https://www.semanticscholar.org/paper/df57622f13676a4a8185df9424bea75243d8fc9e,from big data epistemology to ai politics: rescuing the public dimension over data-driven technologies,"
Purpose
The purpose of this paper is to explore the epistemological tensions embedded within big data and data-driven technologies to advance a socio-political reconsideration of the public dimension in the assessment of their implementation.


Design/methodology/approach
This paper builds upon (and revisits) the European Union’s (EU) normative understanding of artificial intelligence (AI) and data-driven technologies, blending reflections rooted in philosophy of technology with issues of democratic participation in tech-related matters.


Findings
This paper proposes the conceptual design of sectorial and/or local-level e-participation platforms to ignite an ongoing discussion – involving experts, private actors, as well as cognizant citizens – over the implementation of data-driven technologies, to avoid siloed, tech-solutionist decisions.


Originality/value
This paper inscribes the EU’s normative approach to AI and data-driven technologies, as well as critical work on the governance of these technologies, into a broader political dimension, suggesting a way to democratically and epistocratically opening up the decisional processes over the development and implementation of these technologies and turn such processes into a systemic civic involvement.
","Journal of Information, Communication and Ethics in Society",2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/jices-12-2022-0108
b6f95beed6dd6cc610a0949b5814ed9117d737ac,https://www.semanticscholar.org/paper/b6f95beed6dd6cc610a0949b5814ed9117d737ac,is it the new google: impact of chatgpt on students' information search habits,"The traditional subject of information search and retrieval (IR) paradigm shifted to an entirely new era since artificial intelligence (AI) techniques were introduced into the field. Browser-based IR solutions powered by AI for personalised recommendations-based information retrieval, such as the Google search engine, were one of the early examples. The IR field has advanced to its next level with the newest conversational applications based on large language model (LLM) techniques. It is becoming clear that Generative Pretrained Transformer (GPT) applications such as ChatGPT will significantly impact information retrieval behaviour in the education sector. Though this application has become widespread in acclaim, no previous study has shown its impact on information seeking and retrieval. However, based on the observation of the fast penetration of this technology and the growth of public interest, a pre-assumption was built that it is essential to investigate if students may also be showing a similar interest in this new tool. Hence, this study is set up to systematically and empirically explore how ChatGPT influences the IR behaviour of students in HEIs. A survey approach is utilised to collect the perceived IR behaviour through a questionnaire administered to 60 students in HEIs. The findings reveal that the tool is already widely known among HEI students. They also perceived the use of the tool in the context of information retrieval and proclaimed its usefulness, acknowledging its efficiency (reduced time) in finding information. Furthermore, the technology has considerably affected the typical use of other conventional information retrieval and search engine tools. On the contrary, 10% of the respondents are less likely to use ChatGPT during information seeking for various reasons, from credibility and relevance to technology infrastructure issues such as connectivity. Although a deeper analysis is required to establish a general conclusion on how and in which ways GPT-based models will override contemporary IR practices, the study outcome provides evidence for a possible behavioural change among HEI students in their IR habits in the future.",European Conference on e-Learning,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.34190/ecel.22.1.1831
07e31c18f8f831aed37010eff6e918447d55856e,https://www.semanticscholar.org/paper/07e31c18f8f831aed37010eff6e918447d55856e,giusberto: italy's ai-based judicial transformation: a teaching case,"In an age when open access to law enforcement files and judicial documents can erode individual privacy and confidentiality, miscreants can abuse this open access to personal information for blackmail, misinformation, and even social engineering. Yet, limiting access to law enforcement and court cases is a freedom-of-information violation. To address this tension, this collaborative action-research-based teaching case exemplifies how Italy’s Corte dei Conti (Court of Auditors) used artificial intelligence in the automated deidentification and anonymization of court documents in Italy’s public sector. This teaching case is aimed at undergraduate and graduate students learning about Artificial Intelligence (AI), Large Language Model (LLM) (e.g., ChatGPT) evolution, development, and operations. The case will help students learn the origin and evolution of AI transformer models and architectures, and discusses the GiusBERTo operation and process, highlighting opportunities and challenges. GiusBERTo, Italy’s custom-AI model, offers an innovative approach that walks a tightrope between anonymizing Italy’s judicial court documents without sacrificing context or information loss. The case ends with a series of questions, challenges, and potential for LLMs in data anonymization.",Communications of the Association for Information Systems,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.17705/1cais.05331
bba496787711047003c174009c034641bd84ab07,https://www.semanticscholar.org/paper/bba496787711047003c174009c034641bd84ab07,ai-powered academic guidance and counseling system based on student profile and interests,"Over the past few decades, the education sector has achieved impressive advancements by incorporating Artificial Intelligence (AI) into the educational environment. Nevertheless, specific educational processes, particularly educational counseling, still depend on traditional procedures. The current method of conducting group sessions between counselors and students does not offer personalized assistance or individual attention, which can cause stress to students and make it difficult for them to make informed decisions about their coursework and career path. This paper proposes a counseling solution designed to aid high school seniors in selecting appropriate academic paths at the tertiary level. The system utilizes a predictive model that considers academic history and student preferences to determine students’ likelihood of admission to their chosen university and recommends similar alternative universities to provide more opportunities. We developed the model based on data from 500 graduates from 12 public high schools in Morocco, as well as eligibility criteria from 31 institutions and colleges. The counseling system comprises two modules: a recommendation module that uses popularity-based and content-based recommendations and a prediction module that calculates the likelihood of admission using the Huber Regressor model. This model outperformed 13 other machine learning modules, with a low MSE of 0.0017, RMSE of 0.0422, and the highest R-squared value of 0.9306. Finally, the system is accessible through a user-friendly web interface.",Applied System Innovation,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/asi7010006
88a9d7421e4b36ca080be31d72f390736f3c4458,https://www.semanticscholar.org/paper/88a9d7421e4b36ca080be31d72f390736f3c4458,revolutionizing education: the transformative power of ai technologies in pr,"In the coming years, Artificial Intelligence (AI) is set to make a profound impact on higher education, particularly within the field of Public Relations (PR). This surge in the adoption of AI technologies in academia is fuelled by compelling factors. AI is on the verge of transforming PR practices, elevating the efficiency and effectiveness of communication strategies. The data-driven prowess of AI equips PR professionals with enhanced capabilities to understand and engage with target audiences, tailor messages with precision, automate routine tasks, such as content creation, social media management, and data analysis, and liberate practitioners from administrative burdens. As educational institutions increasingly recognize the value of AI in PR, investments in its implementation are expected, heralding a paradigm shift in higher education communication and stakeholder engagement. The current article aims to delve into the European framework for AI applications in education, present the landscape of existing technology tools used in the communication area, and review recent publications describing the benefits and possible drawbacks of using generative AI technologies in the sphere of teaching.",Postmodernism Problems,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.46324/pmp2303307
4fd7a5a1abd0106b7d8567fba366ce868bba7150,https://www.semanticscholar.org/paper/4fd7a5a1abd0106b7d8567fba366ce868bba7150,value and risks of morphing technology into strategy and business model,"Digital technologies became the primary source of innovation in the private and public sectors. The Internet profoundly changed the way businesses are run catapulting “most digital” industries and companies to the top of the S&P500. Two innovations that drive digital transformation changing the nature of competition are cloud computing and artificial intelligence (AI) technologies. Cloud-native business models and strategies proved successful in various industries, while AI is being tested in vivo by management mainstream. The publication provides an analysis of a multidimensional impact cloud computing makes on strategies and business models of companies. We show that what made cloud computing special in the management context was the way it morphed into strategies and business models best suited for the uncertain future. We also noted that as the focus of digital transformation shifts towards cloud-based AI powered decision-making solutions, managing the human aspect of “more digital” business models and related risks, recently referred to as an existential threat, becomes a priority of management research.",UPRAVLENIE / MANAGEMENT (Russia),2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.26425/2309-3633-2023-11-2-103-113
a68de27002b0e8f5d31f4d5f845535e32ff2a1f7,https://www.semanticscholar.org/paper/a68de27002b0e8f5d31f4d5f845535e32ff2a1f7,ai in healthcare management and accounting: novelties and trends from a literature review and illustrative cases,"Through a mixed-methods approach based on a critical analysis of both literature and industry trends (referred to real-world practices / illustrative cases), as rapidly emerging in recent years, we investigate the transformative impact of Artificial Intelligence on healthcare sector, notably the powerful intersection – still too little explored by extant scientific doctrine – of health management and accounting system AI related. As the technological advancements continue to reshape the healthcare landscape, we found an AI expanding as a pivotal instrument in managing, innovating, and optimising strategic and operational processes (by enhancing executives’ decision-making). We drew as main effect of such a process – when enabled by a fruitful integration of managers and experts (data scientists / IT professionals) – an improvement of both patient care and financial efficiency as well (i.e., overall healthcare delivery in order to generate business value) thanks to a more profound real-time KPIs monitoring (patient outcomes, resource utilisation, and financial metrics). We also critically review new challenges such as data privacy, security, and ethical considerations emphasising the importance of responsible AI deployment for building patient trust and ensuring regulatory compliance. In this regard, a public awareness of AI and the establishment of standardised guidelines will be additionally required. By delving into the novel applications of AI in healthcare administration, financial management, and synergies between these domains, this work can benefit a diverse audience across various sectors of the healthcare industry, technology, public administration, and academia. Limitations and future directions of research are provided.",Communications of International Proceedings,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.5171/2023.4252023
c25067c6078f3c6aa6478b6348c9d23a40cfc1c0,https://www.semanticscholar.org/paper/c25067c6078f3c6aa6478b6348c9d23a40cfc1c0,you sound depressed: a case study on sonde health’s diagnostic use of voice analysis ai,"There is growing interest within the medical sector about the diagnostic potential of voice analysis-based artificial intelligence (AI) for monitoring mental health, such as depression detection. However, insufficient attention has been paid to the societal consequences of such technologies rendering depression and similar disabilities into purely technical problems. We provide a critical case study of Sonde Health, a Boston-based startup that purports to offer “objective” depression detection and monitoring via its Mental Fitness app that extracts and analyzes the acoustic features of the user’s voice. Using a critical disability studies lens, we conducted a textual analysis of the publicly available developer documentation for Sonde’s application programming interface, examining each of these acoustic features (“vocal biomarkers”), and problematizing Sonde’s claims that these vocal biomarkers are objective universal indicators of depression. Through our case study, we identify and illustrate three hegemonic norms that contribute to troubling social implications of the technology: the fallacy that complex psychometrics can be meaningfully flattened into a single encompassing score, the aesthetic of “objectivity”, and the presumptive universalizing of easily-available voice data sets. We discuss how all three are tied up in the legacy of eugenics and reflect a fundamental mismatch in values between mainstream AI technology and the humanistic requirements of mental health care.","Conference on Fairness, Accountability and Transparency",2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3593013.3594032
729b507063248ca40cb8fe214d2db62adfba1069,https://www.semanticscholar.org/paper/729b507063248ca40cb8fe214d2db62adfba1069,data ecosystems in education: opportunities and challenges,"The integration of ecosystems that promote the massive use of data and the large-scale processing of this data into educational processes represent an unprecedented social challenge. This change, which we could consider paradigmatic, has been promoted by various factors which mutually magnify each other's effects. 
In recent years the massive collection and storage of data has intensified through ubiquitous technologies, which co-exist with human actors. In addition, we have witnessed an increase in the intentional processing power of this data at a speed unimaginable a few years ago (through the application of Artificial Intelligence, hereafter AI) . This has turned many aspects of our lives into data, from which value is extracted by third parties through processes of datafication. Concurrently, the public at large - including the educational sector - has been promised educational ‘personalisation’, a concept derived directly from other industrial production scenarios where AI is already in use, and every experience is datafied. In addition, a rapidly growing economic sector - the EdTech industry - has emerged with a capacity to monetise the educational sphere at a global level, extracting not only profits from its present and future actions with private or institutional clients, but also generating income based on capturing the motivation of their users and achieving significant levels of social and political influence. All of the above is magnified by the proliferation of the use of online platforms and tools in educational spaces (such as learning analytics and online exam proctoring), accelerated by the demand for online educaiton resulting from ‘lockdowns’ during the CoVid-19 pandemic. 
This special issue aims to bring together articles that problematise the challenges and unintended effects that new mechanisms and dynamics fuelled by these data-driven technologies have introduced into education. This call aims to encourage researchers and practitioners to share studies, research, debates and academically well-founded reflections that propose critical visions. This aims to provide those who are interested in education (either as teachers, academic faculty, researchers or managers ) deeper analyses, to allow us to understand the current educational and technological landscape, and to foster a revaluation of relevant educational issues that should be part of our work in the coming years.",Edutec. Revista Electrónica de Tecnología Educativa,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.21556/edutec.2023.86.3071
ae17e17ed3a36ba3ffbadc9de2b10909aa13226c,https://www.semanticscholar.org/paper/ae17e17ed3a36ba3ffbadc9de2b10909aa13226c,the future of chatgpt in academic research and publishing: a commentary for clinical and translational medicine,"ChatGPT, an artificial intelligence (AI)-powered chatbot developed by OpenAI, is creating a buzz across all occupational sectors. Its name comes from its basis in the Generative Pretrained Transformer (GPT) language model. ChatGPT’s most promising feature is its ability to offer human-like responses to text input using deep learning techniques at a level far superior to any other AImodel. Its rapid integration in various industries signals the public’s burgeoning reliance on AI technology. Thus, it is essential to critically evaluate ChatGPT’s potential impacts on academic clinical and translational medicine research.",Clinical and Translational Medicine,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1002/ctm2.1207
497321544abab96bbbf6a2f683fc3e9751d58053,https://www.semanticscholar.org/paper/497321544abab96bbbf6a2f683fc3e9751d58053,ai-driven disinformation: a framework for organizational preparation and response,"PurposeDisinformation, false information designed with the intention to mislead, can significantly damage organizational operation and reputation, interfering with communication and relationship management in a wide breadth of risk and crisis contexts. Modern digital platforms and emerging technologies, including artificial intelligence (AI), introduce novel risks in crisis management (Guthrie and Rich, 2022). Disinformation literature in security and computer science has assessed how previously introduced technologies have affected disinformation, demanding a systematic and coordinated approach for sustainable counter-disinformation efforts. However, there is a lack of theory-driven, evidence-based research and practice in public relations that advises how organizations can effectively and proactively manage risks and crises driven by AI (Guthrie and Rich, 2022).Design/methodology/approachAs a first step in closing this research-practice gap, the authors first synthesize theoretical and technical literature characterizing the effects of AI on disinformation. Upon this review, the authors propose a conceptual framework for disinformation response in the corporate sector that assesses (1) technologies affecting disinformation attacks and counterattacks and (2) how organizations can proactively prepare and equip communication teams to better protect businesses and stakeholders.FindingsThis research illustrates that future disinformation response efforts will not be able to rely solely on detection strategies, as AI-created content quality becomes more and more convincing (and ultimately, indistinguishable), and that future disinformation management efforts will need to rely on content influence rather than volume (due to emerging capabilities for automated production of disinformation). Built upon these fundamental, literature-driven characteristics, the framework provides organizations actor-level and content-level perspectives for influence and discusses their implications for disinformation management.Originality/valueThis research provides a theoretical basis and practitioner insights by anticipating how AI technologies will impact corporate disinformation attacks and outlining how companies can respond. The proposed framework provides a theory-driven, practical approach for effective, proactive disinformation management systems with the capacity and agility to detect risks and mitigate crises driven by evolving AI technologies. Together, this framework and the discussed strategies offer great value to forward-looking disinformation management efforts. Subsequent research can build upon this framework as AI technologies are deployed in disinformation campaigns, and practitioners can leverage this framework in the development of counter-disinformation efforts.",Journal of Communication Management,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/jcom-09-2022-0113
c644063a31a9377b069e5f8568db83e24e4f35ff,https://www.semanticscholar.org/paper/c644063a31a9377b069e5f8568db83e24e4f35ff,population preferences for ai system features across eight different decision-making contexts,"Artificial intelligence systems based on deep learning architectures are being investigated as decision-support systems for human decision-makers across a wide range of decision-making contexts. It is known from the literature on AI in medicine that patients and the public hold relatively strong preferences in relation to desirable features of AI systems and their implementation, e.g. in relation to explainability and accuracy, and in relation to the role of the human decision-maker in the decision chain. The features that are preferred can be seen as ‘protective’ of the patient’s interests. These types of preferences may plausibly vary across decision-making contexts, but the research on this question has so far been almost exclusively performed in relation to medical AI. In this cross-sectional survey study we investigate the preferences of the adult Danish population for five specific protective features of AI systems and implementation across a range of eight different use cases in the public and commercial sectors ranging from medical diagnostics to the issuance of parking tickets. We find that all five features are seen as important across all eight contexts, but that they are deemed to be slightly less important when the implications of the decision made are less significant to the respondents.",PLoS ONE,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1371/journal.pone.0295277
741e0c23b31ffaed9d3ec1660fe9fca0ecd9318c,https://www.semanticscholar.org/paper/741e0c23b31ffaed9d3ec1660fe9fca0ecd9318c,tackling cyberattacks through ai-based reactive systems: a holistic review and future vision,"There is no denying that the use of Information Technology (IT) is undergoing exponential growth in today's world. This digital transformation has also given rise to a multitude of security challenges, notably in the realm of cybercrime. In response to these growing threats, public and private sectors have prioritized the strengthening of IT security measures. In light of the growing security concern, Artificial Intelligence (AI) has gained prominence within the cybersecurity landscape. This paper presents a comprehensive survey of recent advancements in AI-driven threat response systems. To the best of our knowledge, the most recent survey covering the AI reaction domain was conducted in 2017. Since then, considerable literature has been published, and therefore, it is worth reviewing it. In this comprehensive survey of the state of the art reaction systems, five key features with multiple values have been identified, facilitating a homogeneous comparison between the different works. In addition, through a meticulous methodology of article collection, the 22 most relevant publications in the field have been selected. Then each of these publications has been subjected to a detailed analysis using the features identified, which has allowed for the generation of a comprehensive overview revealing significant relationships between the papers. These relationships are further elaborated in the paper, along with the identification of potential gaps in the literature, which may guide future contributions. A total of seven research challenges have been identified, pointing out these potential gaps and suggesting possible areas of development through concrete proposals.",arXiv.org,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2312.06229
51791a95c6ba077072018ce8c0d294102953cc6a,https://www.semanticscholar.org/paper/51791a95c6ba077072018ce8c0d294102953cc6a,transforming organizational development with ai: navigating change and innovation for success,"Effective change management emerges as a deciding element for an organization's survival and success in the changing terrain of today's fiercely competitive business climate. The variety of change management theories and approaches that are currently available, however, paints a complicated picture that is plagued by inconsistencies, a lack of strong empirical support, and unproven assumptions about contemporary organizational dynamics. This essay seeks to set the basis for a fresh paradigm for effective change administration by critically analyzing popular change management ideas. The gap between theory and practice is addressed in the paper, which concludes with suggestions for more research. In parallel, artificial intelligence (AI) has made incredible progress, giving rise to computers that mimic human autonomy and cognition. Industry-wide excitement has been sparked by the enthusiasm among academics, executives, and the general public, which has resulted in significant investments in utilizing AI's potential through creative business models. However, the lack of thorough academic guidance forces managers to struggle with AI integration issues, increasing the risk of project failure. An in-depth analysis of AI's complexities and its function as a spark for revolutionary business model innovation is provided in this article. A thorough literature assessment, which involves sifting through a sizable library of published works, combines up-to-date information on how AI is affecting the development of new business models. The findings come together to form a roadmap for seamless AI integration that includes four steps: understanding the fundamentals of AI and the skills needed for digital transformation, understanding current business models and their innovation potential, nurturing key proficiencies for AI assimilation, and gaining organizational acceptance while developing internal competencies. This article combines the fields of organizational change management and AI-driven business model innovation with ease, providing a thorough explanation to assist businesses in undergoing a successful transformation and innovation. These disciplines' confluence offers a practical vantage point for successfully adapting to, thriving in, and profiting within a dynamic business environment. Artificial intelligence (AI), a massively disruptive force that is altering international businesses, is at the vanguard of this revolution. The ability of AI to make decisions automatically, based on data analysis and observation, opens up hitherto untapped possibilities for value creation and competitive dominance, with broad consequences spanning several industries. With its quick scaling, ongoing improvement, and self-learning capabilities, this evolutionary invention functions as an agile capital-labor hybrid. Significantly, AI's architecture serves as the cornerstone for data-driven decision support by deftly sifting through large and complicated datasets to extract insights. Thus, the symbiotic marriage of organizational change management and AI-driven business model innovation gives a thorough narrative, directing businesses towards not just surviving, but thriving in an ever-evolving business environment. It is underlined how business models (BMs) interact with technology to affect how well business’s function, underlining the need of taking BMs into account while using AI. Business model innovation (BMI) that AI unlocks may improve goods, streamline processes, and save costs. However, there is a void between technological improvements and their operationalization via BMs. Successful AI integration depends on a well-structured BM, which promotes agility and makes the most of technological resources. BMI is accelerated by AI, which reshapes sectors via innovation. Although interest in AI is high, strategic, cultural, and technological constraints sometimes prevent large investments from producing positive economic results. To fully utilize AI's capabilities, structured BMs are required. Despite an increase in research, there is still little cohesive information about the business uses of AI. In an effort to close this gap, we examine implementation-related AI problems. Analyzing AI-driven BM transformation and risk management is aided by a study on BMI and digital transformation at the same time. The purpose of this study is to further our understanding of AI-driven business model innovation and to provide a useful framework to help practitioners navigate the potential and difficulties of AI implementation. The suggested roadmap aims to identify current knowledge gaps and future research initiatives.",International Journal of Engineering and Advanced Technology,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.35940/ijeat.a4282.1013123
87d110893ac357209247502dfdd2d5312ec44cfd,https://www.semanticscholar.org/paper/87d110893ac357209247502dfdd2d5312ec44cfd,use of domain engineering in hyperautomation applied to decision making in government,"This article presents the domain engineering process carried out to obtain the requirements for the implementation of an Artificial Intelligence (AI) compliance framework aimed at the public sector. Owing to the current competitive and fast economy, which generates huge demand for increasingly efficient, reliable, and transparent intelligent systems, decision-support architectures should also be developed under strong restrictions of cost and time. Such a context requires adequate structures, processes, and technologies for coping with the complexity of building such intelligent systems. Currently, many public organizations have adopted applications for process automation, with the aim of refraining from repetitive work and producing more efficient results. However, what is not so often observed is the development of intelligent engines to support complex public decision-making. Possible explanations are the plethora of available data sources and the number of legal norms to be abided by. Moreover, it is important to highlight the need to incorporate transparency, auditability, reusability, and flexibility into such systems. Thus, they can be safely utilized in various analogous situations, reducing the need to develop new applications from scratch. An architecture suitable for supporting public decision-making with so many features and increasingly unstructured data, as well as abundant regulation, needs well-crafted formal specifications. This article aims to analyze three existing frameworks and carry out domain engineering studies in three cases to produce some guidance for future public applications and services based on AI. Next, we provide a conceptual preliminary architectural definition for the public sector. The proposed architecture targets were identified in the three cases studied, namely, frequent tasks of process mining requirements, detection of anomalies, and extraction of rules and public policies for helping public servants. All these aim at expedient AI development for public decision-making.",Journal of Advances in Artificial Intelligence,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.18178/jaai.2023.1.2.103-116
59b6218ff63c469469402502fa19a7fbd0ba717f,https://www.semanticscholar.org/paper/59b6218ff63c469469402502fa19a7fbd0ba717f,the adoption of ai in mental health care–perspectives from mental health professionals: qualitative descriptive study,"Background Artificial intelligence (AI) is transforming the mental health care environment. AI tools are increasingly accessed by clients and service users. Mental health professionals must be prepared not only to use AI but also to have conversations about it when delivering care. Despite the potential for AI to enable more efficient and reliable and higher-quality care delivery, there is a persistent gap among mental health professionals in the adoption of AI. Objective A needs assessment was conducted among mental health professionals to (1) understand the learning needs of the workforce and their attitudes toward AI and (2) inform the development of AI education curricula and knowledge translation products. Methods A qualitative descriptive approach was taken to explore the needs of mental health professionals regarding their adoption of AI through semistructured interviews. To reach maximum variation sampling, mental health professionals (eg, psychiatrists, mental health nurses, educators, scientists, and social workers) in various settings across Ontario (eg, urban and rural, public and private sector, and clinical and research) were recruited. Results A total of 20 individuals were recruited. Participants included practitioners (9/20, 45% social workers and 1/20, 5% mental health nurses), educator scientists (5/20, 25% with dual roles as professors/lecturers and researchers), and practitioner scientists (3/20, 15% with dual roles as researchers and psychiatrists and 2/20, 10% with dual roles as researchers and mental health nurses). Four major themes emerged: (1) fostering practice change and building self-efficacy to integrate AI into patient care; (2) promoting system-level change to accelerate the adoption of AI in mental health; (3) addressing the importance of organizational readiness as a catalyst for AI adoption; and (4) ensuring that mental health professionals have the education, knowledge, and skills to harness AI in optimizing patient care. Conclusions AI technologies are starting to emerge in mental health care. Although many digital tools, web-based services, and mobile apps are designed using AI algorithms, mental health professionals have generally been slower in the adoption of AI. As indicated by this study’s findings, the implications are 3-fold. At the individual level, digital professionals must see the value in digitally compassionate tools that retain a humanistic approach to care. For mental health professionals, resistance toward AI adoption must be acknowledged through educational initiatives to raise awareness about the relevance, practicality, and benefits of AI. At the organizational level, digital professionals and leaders must collaborate on governance and funding structures to promote employee buy-in. At the societal level, digital and mental health professionals should collaborate in the creation of formal AI training programs specific to mental health to address knowledge gaps. This study promotes the design of relevant and sustainable education programs to support the adoption of AI within the mental health care sphere.",JMIR Formative Research,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2196/47847
a90bef9cb05006aec434222f629499a325ba0252,https://www.semanticscholar.org/paper/a90bef9cb05006aec434222f629499a325ba0252,when ai meets information privacy: the adversarial role of ai in data sharing scenario,"Artificial intelligence (AI) is a transformative technology with a substantial number of practical applications in commercial sectors such as healthcare, finance, aviation, and smart cities. AI also has strong synergy with the information privacy (IP) domain from two distinct aspects: as a protection tool (i.e., safeguarding privacy), and as a threat tool (i.e., compromising privacy). In the former case, AI techniques are amalgamated with the traditional anonymization techniques to improve various key components of the anonymity process, and therefore, privacy is safeguarded effectively. In the latter case, some adversarial knowledge is aggregated with the help of AI techniques and subsequently used to compromise the privacy of individuals. To the best of our knowledge, threats posed by AI-generated knowledge such as synthetic data (SD) to information privacy are often underestimated, and most of the existing anonymization methods do not consider/model this SD-based knowledge that can be available to the adversary, leading to privacy breaches in some cases. In this paper, we highlight the role of AI as a threat tool (i.e., AI used to compromise an individual’s privacy), with a special focus on SD that can serve as background knowledge leading to various kinds of privacy breaches. For instance, SD can encompass pertinent information (e.g., total # of attributes in data, distributions of sensitive information, category values of each attribute, minor and major values of some attributes, etc.) about real data that can offer a helpful hint to the adversary regarding the composition of anonymized data, that can subsequently lead to uncovering the identity or private information. We perform reasonable experiments on a real-life benchmark dataset to prove the pitfalls of AI in the data publishing scenario (when a database is either fully or partially released to public domains for conducting analytics).",IEEE Access,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/ACCESS.2023.3297646
ab7620be8921719d3e3a22f5af12850a822093e6,https://www.semanticscholar.org/paper/ab7620be8921719d3e3a22f5af12850a822093e6,cleaner chips: decarbonization in semiconductor manufacturing,"The growth of the information and communication technology sector has vastly accelerated in recent decades because of advancements in digitalization and Artificial Intelligence (AI). Scope 1, 2, and 3 greenhouse gas emissions data of the top six semiconductor manufacturing companies (Samsung Electronics, Taiwan Semiconductor Manufacturing Corporation, Micron, SK Hynix, Kioxia, and Intel) were gathered from the publicly accessible Carbon Disclosure Project’s (CDP) website for 2020. Scope 3 emissions had the largest share in total annual emissions with an average share of 52%, followed by Scope 2 (32%) and Scope 1 (16%). Because of the absence of a standardized methodology for Scope 3 emissions estimation, each company used different methodologies that resulted in differences in emissions values. An analysis of the CDP reporting data did not reveal information on strategies implemented by companies to reduce Scope 3 emissions. The use of renewable energy certificates had the largest effect on decarbonization centered on reducing Scope 2 emissions, followed by the deployment of perfluorocarbon reduction technologies to help reduce Scope 1 fugitive emissions. Technology-specific marginal abatement costs of CO2 were also estimated and varied between −416 and 12,215 USD/t CO2 eq., which primarily varied depending on the technology deployed.",Sustainability,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/su16010218
deba8c7ee9978e1663af4118358357de736d1bce,https://www.semanticscholar.org/paper/deba8c7ee9978e1663af4118358357de736d1bce,"integrating reaction schemes, reagent databases, and virtual libraries into fragment-based design by reinforcement learning","Lead optimization supported by artificial intelligence (AI)-based generative models has become increasingly important in drug design. Success factors are reagent availability, novelty, and the optimization of multiple properties. Directed fragment-replacement is particularly attractive, as it mimics medicinal chemistry tactics. Here, we present variations of fragment-based reinforcement learning using an actor-critic model. Novel features include freezing fragments and using reagents as the fragment source. Splitting molecules according to reaction schemes improves synthesizability, while tuning network output probabilities allows us to balance novelty versus diversity. Combining fragment-based optimization with virtual library encodings allows the exploration of large chemical spaces with synthesizable ideas. Collectively, these enhancements influence design toward high-quality molecules with favorable profiles. A validation study using 15 pharmaceutically relevant targets reveals that novel structures are obtained for most cases, which are identical or related to independent validation sets for each target. Hence, these modifications significantly increase the value of fragment-based reinforcement learning for drug design. The code is available on GitHub: https://github.com/Sanofi-Public/IDD-papers-fragrl.",Journal of Chemical Information and Modeling,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1021/acs.jcim.3c00735
15161709d92a407730aecae04d4426accf0c49b6,https://www.semanticscholar.org/paper/15161709d92a407730aecae04d4426accf0c49b6,multiscale analysis domain interpretable deep neural network for detection of breast cancer using thermogram images,"Breast cancer is the most prevalent cancer among women, with a high mortality rate. The early detection of breast cancer using medical imaging techniques helps reduce the number of deaths caused by this disease. Thermogram imaging is safer and less expensive than mammography for diagnosing breast cancer. The automated analysis of thermogram images using artificial intelligence (AI) methods is an interesting approach to detect breast cancer. This article proposes a novel multiscale analysis domain interpretable deep learning (MSADIDL) approach for automatically detecting breast cancer using thermogram images. The 2D empirical wavelet transform (2DEWT) with fixed boundary points (FBPs) is employed for the multiscale analysis of thermogram images and evaluation of modes or subbands. All the modes of the thermogram images are used as the input to the MSADIDL model for the automated detection of breast cancer. The MSADIDL architecture comprises seven individual deep neural networks (DNNs) connected in parallel. The outputs of the individual DNNs are concatenated and then used as the input to the dense layers, after which the output layer evaluates the probability score for the automated categorization of normal versus cancerous classes. A publicly available thermogram imaging dataset is utilized to evaluate the performance of the proposed MSADIDL approach. The results show that the proposed MSADIDL approach has obtained an accuracy value of 99.54% for both fivefold cross-validation (CV) and hold-out validation cases using all seven modes of thermogram images. The MSADIDL model has achieved an accuracy higher than all of the transfer learning-based breast cancer detection techniques using thermogram images. The suggested MSADIDL model has shown higher accuracy when compared with different existing methods to detect breast cancer using thermogram images.",IEEE Transactions on Instrumentation and Measurement,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/TIM.2023.3317913
4d233f8d623e01205e0c3327df2095f7746956da,https://www.semanticscholar.org/paper/4d233f8d623e01205e0c3327df2095f7746956da,metasymnet: a dynamic symbolic regression network capable of evolving into arbitrary formulations,"Mathematical formulas serve as the means of communication between humans and nature, encapsulating the operational laws governing natural phenomena. The concise formulation of these laws is a crucial objective in scientific research and an important challenge for artificial intelligence (AI). While traditional artificial neural networks (MLP) excel at data fitting, they often yield uninterpretable black box results that hinder our understanding of the relationship between variables x and predicted values y. Moreover, the fixed network architecture in MLP often gives rise to redundancy in both network structure and parameters. To address these issues, we propose MetaSymNet, a novel neural network that dynamically adjusts its structure in real-time, allowing for both expansion and contraction. This adaptive network employs the PANGU meta function as its activation function, which is a unique type capable of evolving into various basic functions during training to compose mathematical formulas tailored to specific needs. We then evolve the neural network into a concise, interpretable mathematical expression. To evaluate MetaSymNet's performance, we compare it with four state-of-the-art symbolic regression algorithms across more than 10 public datasets comprising 222 formulas. Our experimental results demonstrate that our algorithm outperforms others consistently regardless of noise presence or absence. Furthermore, we assess MetaSymNet against MLP and SVM regarding their fitting ability and extrapolation capability, these are two essential aspects of machine learning algorithms. The findings reveal that our algorithm excels in both areas. Finally, we compared MetaSymNet with MLP using iterative pruning in network structure complexity. The results show that MetaSymNet's network structure complexity is obviously less than MLP under the same goodness of fit.",arXiv.org,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2311.07326
9a409f3f8d411140911a60e42b06d893f756a46c,https://www.semanticscholar.org/paper/9a409f3f8d411140911a60e42b06d893f756a46c,build neural network models to identify and correct news headlines exaggerating obesity-related scientific findings,"Abstract Purpose Media exaggerations of health research may confuse readers’ understanding, erode public trust in science and medicine, and cause disease mismanagement. This study built artificial intelligence (AI) models to automatically identify and correct news headlines exaggerating obesity-related research findings. Design/methodology/approach We searched popular digital media outlets to collect 523 headlines exaggerating obesity-related research findings. The reasons for exaggerations include: inferring causality from observational studies, inferring human outcomes from animal research, inferring distant/end outcomes (e.g., obesity) from immediate/intermediate outcomes (e.g., calorie intake), and generalizing findings to the population from a subgroup or convenience sample. Each headline was paired with the title and abstract of the peer-reviewed journal publication covered by the news article. We drafted an exaggeration-free counterpart for each original headline and fined-tuned a BERT model to differentiate between them. We further fine-tuned three generative language models—BART, PEGASUS, and T5 to autogenerate exaggeration-free headlines based on a journal publication’s title and abstract. Model performance was evaluated using the ROUGE metrics by comparing model-generated headlines with journal publication titles. Findings The fine-tuned BERT model achieved 92.5% accuracy in differentiating between exaggeration-free and original headlines. Baseline ROUGE scores averaged 0.311 for ROUGE-1, 0.113 for ROUGE-2, 0.253 for ROUGE-L, and 0.253 ROUGE-Lsum. PEGASUS, T5, and BART all outperformed the baseline. The best-performing BART model attained 0.447 for ROUGE-1, 0.221 for ROUGE-2, 0.402 for ROUGE-L, and 0.402 for ROUGE-Lsum. Originality/value This study demonstrated the feasibility of leveraging AI to automatically identify and correct news headlines exaggerating obesity-related research findings.",Journal of Data and Information Science,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2478/jdis-2023-0014
39a95e3f3124887f824d47586b917916466f5def,https://www.semanticscholar.org/paper/39a95e3f3124887f824d47586b917916466f5def,strategic planning in public administration as a political system of institutional instruments and goal-setting mechanisms,"The article is devoted to the subject field of political science research within the scientific specialty “Public Administration and sectoral policies” and the analysis of the practice of state strategic planning as a political system of institutional instruments and goal-setting mechanisms in the Russian Federation. The article discusses public political and legal mechanisms for combining values and goals with the choice of ways and methods to achieve them. The constitutional exclusivity and independence of each branch of government as the basis of its strategic resource and strategic planning potential is highlighted as the fundamental public political and legal mechanism for combining values and goals with the choice of ways and methods to achieve them. A general description of the architecture of the unified system of public power in accordance with the amendments to the Constitution of Russia and the current configuration of the public administration system is given. The importance of political factor of the effectiveness of the administration of strategic management system and the implementation of sectoral policies in modern Russia on the basis of the mechanisms of coordinated functioning and interaction of public authorities and local self-government in a single system of public authority is shown. Fundamental changes are highlighted that make it possible to significantly increase the efficiency of the federal government in a unified system of public authority with an emphasis on the implementation of national development goals of both the Russian Federation as a whole and the regions based on the sectoral structure of the economy. Attention is focused on the political goals of the regional factor of socio-economic development of territories on the basis of mechanisms and tools of strategic planning, the directions of fundamental political, legal, administrative and managerial decisions on the implementation of the regional investment standard are determined. The role of federal institutions of innovative development and provision of infrastructure projects and programs for solving the tasks of ensuring sustainable economic growth and diversification of the modern Russian economy, which cannot be optimally implemented by market mechanisms, was demonstrated. Conclusions are drawn about the importance of the interpretative understanding of politics as a system of institutional tools and goal-setting mechanisms in the political and legal practice of state strategic planning for determining promising directions in the subject field of scientific research within the specialty “Public Administration and sectoral policies”, for solving problems of improving the quality of public administration through the introduction of a management model based on big data and artificial intelligence, the transition of the public authority system to a data-based management model using a platform approach.",Izvestiya of Saratov University. Sociology. Politology,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.18500/1818-9601-2023-23-4-447-453
60b5ffa73ea0852c6f20a625a78ef665f3b713e6,https://www.semanticscholar.org/paper/60b5ffa73ea0852c6f20a625a78ef665f3b713e6,tumor diagnosis against other brain diseases using t2 mri brain images and cnn binary classifier and dwt,"Purpose: Brain tumors are diagnosed and classified manually and noninvasively by radiologists using Magnetic Resonance Imaging (MRI) data. The risk of misdiagnosis may exist due to human factors such as lack of time, fatigue, and relatively low experience. Deep learning methods have become increasingly important in MRI classification. To improve diagnostic accuracy, researchers emphasize the need to develop Computer-Aided Diagnosis (CAD) computational diagnostics based on artificial intelligence (AI) systems by using deep learning methods such as convolutional neural networks (CNN) and improving the performance of CNN by combining it with other data analysis tools such as wavelet transform. In this study, a novel diagnostic framework based on CNN and DWT data analysis is developed for the diagnosis of glioma tumors in the brain, among other tumors and other diseases, with T2-SWI MRI scans. It is a binary CNN classifier that treats the disease “glioma tumor” as positive and the other pathologies as negative, resulting in a very unbalanced binary problem. The study includes a comparative analysis of a CNN trained with wavelet transform data of MRIs instead of their pixel intensity values in order to demonstrate the increased performance of the CNN and DWT analysis in diagnosing brain gliomas. The results of the proposed CNN architecture are also compared with a deep CNN pre-trained on VGG16 transfer learning network and with the SVM machine learning method using DWT knowledge. Methods: To improve the accuracy of the CNN classifier, the proposed CNN model uses as knowledge the spatial and temporal features extracted by converting the original MRI images to the frequency domain by performing Discrete Wavelet Transformation (DWT), instead of the traditionally used original scans in the form of pixel intensities. Moreover, no pre-processing was applied to the original images. The images used are MRIs of type T2-SWI sequences parallel to the axial plane. Firstly, a compression step is applied for each MRI scan applying DWT up to three levels of decomposition. These data are used to train a 2D CNN in order to classify the scans as showing glioma or not. The proposed CNN model is trained on MRI slices originated from 382 various male and female adult patients, showing healthy and pathological images from a selection of diseases (showing glioma, meningioma, pituitary, necrosis, edema, non-enchasing tumor, hemorrhagic foci, edema, ischemic changes, cystic areas, etc.). The images are provided by the database of the Medical Image Computing and Computer-Assisted Intervention (MICCAI) and the Ischemic Stroke Lesion Segmentation (ISLES) challenges on Brain Tumor Segmentation (BraTS) challenges 2016 and 2017, as well as by the numerous records kept in the public general hospital of Chania, Crete, “Saint George”. Results: The proposed frameworks are experimentally evaluated by examining MRI slices originating from 190 different patients (not included in the training set), of which 56% are showing gliomas by the longest two axes less than 2 cm and 44% are showing other pathological effects or healthy cases. Results show convincing performance when using as information the spatial and temporal features extracted by the original scans. With the proposed CNN model and with data in DWT format, we achieved the following statistic percentages: accuracy 0.97, sensitivity (recall) 1, specificity 0.93, precision 0.95, FNR 0, and FPR 0.07. These numbers are higher for this data format (respectively: accuracy by 6% higher, recall by 11%, specificity by 7%, precision by 5%, FNR by 0.1%, and FPR is the same) than it would be, had we used as input data the intensity values of the MRIs (instead of the DWT analysis of the MRIs). Additionally, our study showed that when our CNN takes into account the TL of the existing network VGG, the performance values are lower, as follows: accuracy 0.87, sensitivity (recall) 0.91, specificity 0.84, precision 0.86, FNR of 0.08, and FPR 0.14. Conclusions: The experimental results show the outperformance of the CNN, which is not based on transfer learning, but is using as information the MRI brain scans decomposed into DWT information instead of the pixel intensity of the original scans. The results are promising for the proposed CNN based on DWT knowledge to serve for binary diagnosis of glioma tumors among other tumors and diseases. Moreover, the SVM learning model using DWT data analysis performs with higher accuracy and sensitivity than using pixel values.",Brain Science,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/brainsci13020348
a076572adb65a0a810002d01a4831af1e82c9818,https://www.semanticscholar.org/paper/a076572adb65a0a810002d01a4831af1e82c9818,statistical learning and big data applications,"Abstract The amount of data generated in the field of laboratory medicine has grown to an extent that conventional laboratory information systems (LISs) are struggling to manage and analyze this complex, entangled information (“Big Data”). Statistical learning, a generalized framework from machine learning (ML) and artificial intelligence (AI) is predestined for processing “Big Data” and holds the potential to revolutionize the field of laboratory medicine. Personalized medicine may in particular benefit from AI-based systems, especially when coupled with readily available wearables and smartphones which can collect health data from individual patients and offer new, cost-effective access routes to healthcare for patients worldwide. The amount of personal data collected, however, also raises concerns about patient-privacy and calls for clear ethical guidelines for “Big Data” research, including rigorous quality checks of data and algorithms to eliminate underlying bias and enable transparency. Likewise, novel federated privacy-preserving data processing approaches may reduce the need for centralized data storage. Generative AI-systems including large language models such as ChatGPT currently enter the stage to reshape clinical research, clinical decision-support systems, and healthcare delivery. In our opinion, AI-based systems have a tremendous potential to transform laboratory medicine, however, their opportunities should be weighed against the risks carefully. Despite all enthusiasm, we advocate for stringent added-value assessments, just as for any new drug or treatment. Human experts should carefully validate AI-based systems, including patient-privacy protection, to ensure quality, transparency, and public acceptance. In this opinion paper, data prerequisites, recent developments, chances, and limitations of statistical learning approaches are highlighted.",Journal of Laboratory Medicine,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1515/labmed-2023-0037
2c537086af41157b165fef2dbca5ebb767d2d5e9,https://www.semanticscholar.org/paper/2c537086af41157b165fef2dbca5ebb767d2d5e9,explainable mortality prediction model for congestive heart failure with nature-based feature selection method,"A mortality prediction model can be a great tool to assist physicians in decision making in the intensive care unit (ICU) in order to ensure optimal allocation of ICU resources according to the patient’s health conditions. The entire world witnessed a severe ICU patient capacity crisis a few years ago during the COVID-19 pandemic. Various widely utilized machine learning (ML) models in this research field can provide poor performance due to a lack of proper feature selection. Despite the fact that nature-based algorithms in other sectors perform well for feature selection, no comparative study on the performance of nature-based algorithms in feature selection has been conducted in the ICU mortality prediction field. Therefore, in this research, a comparison of the performance of ML models with and without feature selection was performed. In addition, explainable artificial intelligence (AI) was used to examine the contribution of features to the decision-making process. Explainable AI focuses on establishing transparency and traceability for statistical black-box machine learning techniques. Explainable AI is essential in the medical industry to foster public confidence and trust in machine learning model predictions. Three nature-based algorithms, namely the flower pollination algorithm (FPA), particle swarm algorithm (PSO), and genetic algorithm (GA), were used in this study. For the classification job, the most widely used and diversified classifiers from the literature were used, including logistic regression (LR), decision tree (DT) classifier, the gradient boosting (GB) algorithm, and the random forest (RF) algorithm. The Medical Information Mart for Intensive Care III (MIMIC-III) dataset was used to collect data on heart failure patients. On the MIMIC-III dataset, it was discovered that feature selection significantly improved the performance of the described ML models. Without applying any feature selection process on the MIMIC-III heart failure patient dataset, the accuracy of the four mentioned ML models, namely LR, DT, RF, and GB was 69.9%, 82.5%, 90.6%, and 91.0%, respectively, whereas with feature selection in combination with the FPA, the accuracy increased to 71.6%, 84.8%, 92.8%, and 91.1%, respectively, for the same dataset. Again, the FPA showed the highest area under the receiver operating characteristic (AUROC) value of 83.0% with the RF algorithm among all other algorithms utilized in this study. Thus, it can be concluded that the use of feature selection with FPA has a profound impact on the outcome of ML models. Shapley additive explanation (SHAP) was used in this study to interpret the ML models. SHAP was used in this study because it offers mathematical assurances for the precision and consistency of explanations. It is trustworthy and suitable for both local and global explanations. It was found that the features that were selected by SHAP as most important were also most common with the features selected by the FPA. Therefore, we hope that this study will help physicians to predict ICU mortality for heart failure patients with a limited number of features and with high accuracy.",Applied Sciences,2023,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/app13106138
be2fc5c4d3e7774f9bccdab34ad9f3e5fb7fff51,https://www.semanticscholar.org/paper/be2fc5c4d3e7774f9bccdab34ad9f3e5fb7fff51,"super ai, generative ai, narrow ai and chatbots: an assessment of artificial intelligence technologies for the public sector and public administration","Artificial intelligence encompasses a wide range of approaches, methodologies, and techniques aimed at mimicking human intelligence in machines. In recent times, the concepts of Generative Artificial Intelligence (AI), Super AI, and Narrow AI have attracted considerable attention. Undoubtedly, the success of ChatGPT in capturing all attention has played a significant role in this. Artificial intelligence technology has a profound impact on all sectors, and sector representatives are striving to adapt to this technology more quickly. It is projected that artificial intelligence could generate an economic size of 13 trillion American dollars by 2030. Developments in artificial intelligence technologies undoubtedly lead to significant improvements in the functioning of public institutions and access for citizens. Artificial intelligence has the potential to be used in many public services, including security and defense, healthcare services, education, transportation and infrastructure, environmental and natural resource management, law and justice systems, among others. Therefore, evaluating the types of artificial intelligence, Narrow AI applications, and chatbots for public use is seen as highly beneficial from the perspective of public administration and the public sector. In our study, the topics of super artificial intelligence, generative artificial intelligence, narrow artificial intelligence, and chatbots have been extensively evaluated within the context of the public sector and public administration. Utilizing findings from both Turkish and English literature reviews, the importance and potential impacts of artificial intelligence within the public sector, along with current trends, have been comprehensively assessed. This research delves into the concepts of artificial intelligence and its subsets—super AI, generative AI, narrow AI, and chatbots—within the general framework of the public sector. China and the United States are pioneering and leading countries in terms of investment. Although the U.S. stands out in many areas regarding investment, China's integration of artificial intelligence with national strategies and its policies indicate that it may play a more dominant role in the future. There are four main implementation areas of artificial intelligence in the public sector: efficiency and automation, service delivery, data-driven governance, and ethical and regulatory challenges. A review of the literature reveals that the ethical, legal, and social implications of implementing artificial intelligence in the public sector require more careful consideration. The study makes a significant contribution to the field of artificial intelligence discussions in public administration and the public sector, providing a comprehensive assessment of current discussions on artificial intelligence in the literature.",Journal of AI,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.61969/jai.1512906
37eb0c2177acf85c74ace80a9365d610523bc64b,https://www.semanticscholar.org/paper/37eb0c2177acf85c74ace80a9365d610523bc64b,introduction to the issue on artificial intelligence in the public sector: risks and benefits of ai for governments,"Artificial Intelligence (AI) is increasingly adopted by public sector organizations to provide better public services and to transform their internal processes. AI is now considered a key enabler for digital innovation and transformation in the public sector. However, AI is still relatively a new research area in the field of digital government. The term, AI, captures a wide range of technologies, techniques, and tools such as machine/deep learning, natural language processing, robotics, computer vision, and more recently Generative AI. While these AI technologies afford different applications and benefits in the government context, they also create social, ethical, and legal challenges. These challenges require solutions combining both technical (e.g., data and algorithmic solutions to minimize bias) and institutional (e.g., governance structures and processes) mechanisms. The special issue is a collection of articles that contribute to a better understanding of the issues associated with AI deployment in different areas of government operations. They cover AI applications in the areas of emergency response, policy analysis, public bids, and citizen participation. The contributions also address the challenge of realizing a legal transparency regime for AI in government and the effect of AI in bureaucratic decision-making.",Digit. Gov. Res. Pract.,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3636550
6d67a918707f0c20cb847d4d4611b34877ccd5e6,https://www.semanticscholar.org/paper/6d67a918707f0c20cb847d4d4611b34877ccd5e6,generative ai is already widespread in the public sector,"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work. But to what extent is generative AI already in use in the public sector? Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question. We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system. Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future. For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact). Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%). While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces. In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines. The UK's public sector urgently needs to develop more systematic methods for taking advantage of the technology.",arXiv.org,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2401.01291
cf2a8c29efde5517cc86378ade038d6974930b6a,https://www.semanticscholar.org/paper/cf2a8c29efde5517cc86378ade038d6974930b6a,comparative analysis of generative ai risks in the public sector,"The landscape of artificial intelligence (AI) has experienced a monumental shift with the emerging of Generative AI (GenAI), which has demonstrated to be a transformative tool across diverse sectors. GenAI outputs can span various digital formats, including text, images, videos, and audio, generating particular interest in the public sector. The growing interest of governments in integrating GenAI technologies in public sector operations is marked by the creation of emerging governance instruments and the formulation of soft laws, like standards, principles, and guidelines. This study aims to delve into the intricacies and potential risks associated with the deployment of GenAI within government. Through a qualitative content analysis, the research meticulously examines GenAI usage guidelines issued by Australia, Canada, New Zealand, the United Kingdom, and South Korea. The objective is to discern the risks acknowledged by these countries' soft laws and compare them with the risks identified by scholars in the field. The performed comparative analysis across countries suggest that the use of GenAI in the public sector raises common risks such as information leakage, data privacy, security, and concerns over public trust. By elucidating the varied risk perceptions across different national contexts, this study provides theoretical and practical implications related to the risks of GenAI within the public sector. Moreover, it sets a foundation for future research and policy development, ensuring that generative AI is used as a force for good in public governance.",Digital Government Research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3657054.3657125
3fbf70a03073fd04f2293044076b5e84afef66f7,https://www.semanticscholar.org/paper/3fbf70a03073fd04f2293044076b5e84afef66f7,tribal knowledge cocreation in generative artificial intelligence systems,"Generative Artificial Intelligence (AI) systems bring innovative ways of information provision and knowledge delivery. In the public sector, generative AI has the potential to decrease bureaucratic discretion in the decision-making process. Increasing reliance on this technology brings challenges of unfair treatment, colonized responses from the system, and data governance. Because of historical interaction, tribal communities are the most underrepresented in policy planning and implementation. Indigenous communities suffer from the neglect of tribal sovereignty by the U.S. federal government and limited accessibility and literacy in the digital world. Generative AI systems exacerbate these challenges with insufficient tribal input. However, the negative impact can be alleviated with digital equity and knowledge cocreation. Digital equity emphasizes the importance of tribal knowledge representation, and knowledge cocreation focuses on the collaboration between Indigenous communities and relevant actors in data governance for generative AI systems. This study proposes two research questions to discuss tribal knowledge cocreation in generative AI systems: (1) what are the biases in the system responses from the tribal perspective? (2) what are the potential resolutions for these problems? The findings from in-depth interviews with tribal members in the U.S. indicate that the insufficient articulation of tribal culture, the lack of crucial tribal historical events, and the inappropriate appellation of tribal nations are the primary drawbacks in the system responses. From the Indigenous perspective, tribal oral traditions, native publications and documents, and collaboration with tribal governments can address the problems of generative AI responses. This study contributes to the theory development of digital equity and knowledge cocreation in tribal generative AI system responses. Policy recommendations and future research agendas are included in this research.",Digital Government Research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3657054.3657129
b727d48a8a9ce8ac56fc3a164c2a7a4628093550,https://www.semanticscholar.org/paper/b727d48a8a9ce8ac56fc3a164c2a7a4628093550,artificial intelligence in the public sector - an agenda for responsible innovation through learning,"The optimism about the benefits of using artificial intelligence to innovate public services is tempered by concerns about its risks, limitations, and disbenefits. Given the rapid changes in the technol-ogy itself, the opportunities and needs for cross-sectional solutions, and the nascency of the field of AI-based innovation, we contend that policy, strategy, and implementation must include feedback loops that enable institutional learning for the entire public sec-tor. The scope of challenges creates and imperative to facilitate learning must transcend functional, organizational, geographic, and national boundaries. We propose a learning agenda that in-cludes 1) alignment of strategy and policy; 2) initial understanding of goals, benefits, disbenefits, limitations, and risks; 3) data sharing across jurisdictions; 4) technical robustness and societal alignment in governmental oversight; 5) convergence of architecture for AI support; and 6) a portfolio approach to selecting and learning from enabling service innovation with AI.",2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB),2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3643690.3648235
d6133f0fb81ce4779a78835b4af01ef3b55bbeeb,https://www.semanticscholar.org/paper/d6133f0fb81ce4779a78835b4af01ef3b55bbeeb,public value principles for secure and trusted ai,"The objective of this paper is to establish the fundamental public value principles that should govern safe and trusted artificial intelligence (AI). Public value is a dynamic concept that encompasses several dimensions. AI itself has evolved quite rapidly in the last few years, especially with the swift escalation of Generative AI. Governments around the world are grappling with how to govern AI, just as technologists ring alarm bells about the future consequences of AI. Our paper extends the debate on AI governance that is focused on ethical values of beneficence to that of economic values of public good. Viewed as a public good, AI use is beyond the control of the creators. Towards this end, the paper examined AI policies in the United States and Europe. We postulate three principles from a public values perspective: (i) ensuring security and privacy of each individual (or entity); (ii) ensuring trust in AI systems is verifiable; and (iii) ensuring fair and balanced AI protocols, wherein the underlying components of data and algorithms are contestable and open to public debate.",Digital Government Research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3657054.3657086
fa046467bd1082e86d3fb05460386c9a802f2e14,https://www.semanticscholar.org/paper/fa046467bd1082e86d3fb05460386c9a802f2e14,the analysis of technological ethical issues in generative artificial intelligence,": At present, generative AI represented by ChatGPT has great potential and development prospects in education ecology, academia, media and public domain, etc. However, it also faces many ethical challenges, such as the weakening of human subjectivity, bias and algorithmic discrimination, privacy and data security issues, and impact on the value system. Actively exploring the good recipe for ethical governance of science and technology will help promote agile governance and make science and technology develop for the better.",Journal of Artificial Intelligence Practice,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.23977/jaip.2024.070220
b29a09098db3c5e67bba3b50ea8627a27258f65b,https://www.semanticscholar.org/paper/b29a09098db3c5e67bba3b50ea8627a27258f65b,examining public sector ai adoption: mechanisms for ai adoption in the absence of authoritative strategic direction,"Artificial Intelligence (AI) is recognized to bring great benefits to the organizations that can successfully adopt this emerging technological domain into their operations. This paper examines the impact of governance and strategic direction on AI adoption and diffusion in a public sector setting. By presenting contextual conditions, mechanisms, and outcomes within a large government agency this work contributes to the understanding of how the absence of appropriate governance structures and strategies impact the development and adoption of AI. Findings show that balancing exploitation and exploration in the capillaries of the organization proved crucial to the adoption and diffusion of AI. This manifested itself through three mechanisms, Cross-domain learning, Legal priming, and Ecosystem growth, which enabled the organization to obtain both value creation and value capture.",Digital Government Research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3657054.3657278
a854b495502cf6b6f627bf9ebdc5e8f357272e98,https://www.semanticscholar.org/paper/a854b495502cf6b6f627bf9ebdc5e8f357272e98,e-government in nigeria: can generative ai serve as a tool for civic engagement?,"This paper examines the potential for using generative artificial intelligence (AI) to boost civic participation in Nigeria’s developing e-government ecosystem. Emerging generative technologies like ChatGPT demonstrate intriguing capabilities to make governance more interactive and engaging through conversational interfaces. Thoughtfully implemented AI tools could increase access and understanding of e-government, particularly for underserved groups. However, risks around bias, privacy, security and capability limitations pose challenges for public sector applications. Additionally, Nigeria’s substantial digital divides and defective trust in government institutions hamper e-government participation currently. This paper analyses opportunities and limitations for applying generative AI to advance civic engagement given Nigeria’s unique socio-cultural context. Findings suggest that while AI holds promise, targeted strategies focused on inclusion, accessibility, education and institutional legitimacy building are critical to realise benefits. Cautious optimism, human-centric design and responsible governance frameworks are needed to employ generative systems successfully. If challenges are addressed, AI could open innovative possibilities for energising civic participation. But further research and controlled pilot applications are required to determine optimal implementation.",Public Governance Administration and Finances Law Review,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.53116/pgaflr.7068
c22e4a437e3d7659c8257a7f4babe63d6fca05ee,https://www.semanticscholar.org/paper/c22e4a437e3d7659c8257a7f4babe63d6fca05ee,mitigating the risks of generative ai in government through algorithmic governance,"The launch of the generative artificial intelligence (gen AI) application ChatGPT by OpenAI launched artificial intelligence into public discourse and led to a wave of mass uptake of this technology in organizations in the private sector. At the same time, AI is increasingly incorporated into government functions and the public sector. We propose that governments and the public sector can set an example for the responsible use of AI technologies by following the principles of algorithmic governance traditionally recommended to the private sector. Algorithmic governance has traditionally been defined in the literature as governance by algorithms, or how artificial intelligence is used to make governance decisions and affect social ordering. However, we take an alternative approach; instead, we conceptualize algorithmic governance as the governance of algorithms. We begin by summarizing the risks of generative AI use in government, then outline algorithmic governance principles, a step-by-step approach to implementing algorithmic governance into government or public sector projects, opportunities for inter-sector collaboration, and final conclusions.",Digital Government Research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3657054.3657124
eced54e0bfcf41cbad64157ed5683138764a2d2c,https://www.semanticscholar.org/paper/eced54e0bfcf41cbad64157ed5683138764a2d2c,procurement of artificial intelligence systems in uae public sectors: an interpretive structural modeling of critical success factors,"This study investigates the critical success factors (CSFs) influencing the procurement of artificial intelligence (AI) systems within the United Arab Emirates (UAE) public sector. While AI holds immense potential to enhance public service delivery, its successful integration hinges on critical factors. This research utilizes Interpretive Structural Modeling (ISM) to analyze the CSFs impacting AI procurement within the UAE public sector. Through ISM, a structural model is developed to highlight the interrelationships between these CSFs and their influence on the procurement process, outlining the key elements for successful AI procurement within the UAE public sector. Based on the literature review and expert validation from the UAE public sector, ten CSFs were identified. This study found that clear needs assessment is the most influential CSF, while the long-term value of AI systems or services is the least influential. This study provides policymakers and public sector leaders with valuable insights, enabling them to formulate effective strategies to optimize the procurement process and establish a strong foundation for AI adoption. Finally, this will lead to an improved and more efficient public service delivery in the UAE.",Sustainability,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/su16177724
efca4ec65048fae6d934f3c17dc70aa6803555a8,https://www.semanticscholar.org/paper/efca4ec65048fae6d934f3c17dc70aa6803555a8,unlocking the power and future potential of generative ai in government transformation,"
Purpose
This paper aims to investigate whether the implementation of generative artificial intelligence (GAI) impacts government functionality. The study will analyse GAI’s positive attributes across different dimensions to comprehensively understand its value proposition for public organisations. Furthermore, the paper will outline the strategic interventions required to integrate GAI effectively within the organisational context of government transformation.


Design/methodology/approach
This study measures “government functionality” and “GAI implementation” using abstract macro variables as a second-order formative model. It also includes first-order measurable micro-variables to better understand the concept. In addition, the study introduces “organisational context” as a moderating factor to explain the complex dynamics of integrating GAI to improve government functionality. The study proposes a conceptual framework, which was analysed using exploratory data analysis, with primary data collected through questionnaires.


Findings
The study finds a positive correlation between the implementation of GAI and improved government functionality. Furthermore, it found that organisational contextualisation significantly moderates this relationship. All the empirical outcomes align with the prescribed statistical thresholds, concluding that the articulated conceptual framework holds significance.


Research limitations/implications
The study has significant implications for managers, researchers and anyone involved in making, implementing or evaluating decisions related to digital government through GAI. However, the study has limitations, including a limited sample size and contextualisation of the Indian public sector.


Originality/value
The study contributes to existing knowledge by showing that implementing GAI positively correlates with improving government functionality. It further highlights the significance of GAI implementation according to the specific organisational context.
","Transforming Government: People, Process and Policy",2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/tg-01-2024-0006
9679559aa9ed7c017dcf33f6e07021a83c83b1ce,https://www.semanticscholar.org/paper/9679559aa9ed7c017dcf33f6e07021a83c83b1ce,"artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization","In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, that is, the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards AI systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby AI systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that AI-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens’ sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that AI systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means – it cannot dictate the ends. Nonetheless, the use of AI in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, AI-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.",Social science computer review,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/08944393241235175
4af692d5c75634ff2893f4fedba078456fe94353,https://www.semanticscholar.org/paper/4af692d5c75634ff2893f4fedba078456fe94353,chatgpt on chatgpt: an exploratory analysis of its performance in the public sector workplace,"This study explores the impact of Generative Artificial Intelligence (GenAI), in particular, ChatGPT, on the public sector workforce in the United States, focusing on task replacement, assistance potential, and the evolving landscape of skills. Utilizing GPT-4 to evaluate 1,022 core tasks across 51 public sector occupations, we provide an exploratory analysis of the roles susceptible to ChatGPT automation and those in which ChatGPT can augment human efforts. Our findings reveal that while 63% of tasks are resistant to ChatGPT replacement, primarily due to their requirement for physical presence, emotional intelligence, and complex decision-making, tasks that are routine, rule-based, and involving basic content generation show a high potential for automation. The study also identifies key skills that will remain vital, those likely to become obsolete, and new skills that will emerge as essential, highlighting the need for a strategic approach to workforce development in the face of AI advancements. In particular, our findings underscore the growing importance of skills in applying AI technologies and the ability to validate and interpret AI-generated content for humans to remain competitive. We offer insights into public-sector-specific impacts and propose a methodological framework for future research, emphasizing the importance of adapting educational curricula and policies to prepare for an AI-integrated future.",Digital Government: Research and Practice,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3676281
c3dcdb50f9979d435a3999fc6a7737b22b368cbe,https://www.semanticscholar.org/paper/c3dcdb50f9979d435a3999fc6a7737b22b368cbe,"artificial intelligence in russia. history, status, trends and limitations","A new stage in the introduction of artificial intelligence into everyday life in Russia will be the mass introduction of its technologies and products based on it into the public administration system and the government sector. Today, AI is used in most spheres of public life, but its level of development is still not high enough. In that regard, the issues considered in the publication are modern and relevant and can be used at the stages of development and use of AI. The authors clarified the definition of “artificial intelligence”, analyzed the directions of AI development and identified promising areas of the most accelerated technological development of intelligent systems: generative, voice and language, explicable and peripheral AI with characteristics of the stages up to the present. Two main criteria of AI are analyzed: “strong AI” and “weak AI” and their fundamental differences are considered. The article presents results of a brief analysis of the state and plans for the development of AI in Russia. The level of AI implementation in economic sectors reaches 20% and that is not enough to ensure accelerated economic growth. It is assumed that the introduction of AI should provide an additional 1.2% increase in global GDP by 2030, and our country plans to gain more than 11 trillion rubles from its use by 2025. The future of artificial intelligence in Russia was determined by the President of the country at the St. Petersburg International Forum (PEMF-2023). The announced directions will make it possible to unlock the potential of AI more widely and ensure its mass implementation for the formation of Russia’s sovereignty.","Science and art of management / Bulletin of the Institute of Economics, Management and Law of the Russian State University for the Humanities",2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.28995/2782-2222-2024-1-56-69
99ee0859bf83c91d697887a063c9447758bb4c42,https://www.semanticscholar.org/paper/99ee0859bf83c91d697887a063c9447758bb4c42,the role of artificial intelligence on the public energy sector performance in the united arab emirates: the mediation role of organizational agility,"Purpose: This paper presents an in-depth analysis of the interaction between Artificial Intelligence (AI), organizational agility, and performance within the UAE's public energy sector. It explores the transformative role of AI in this context and the critical importance of organizational agility in determining outcomes in the energy field.
 
Design/methodology/data analysis: The methodology employed in this study is a cross-sectional survey design, with data collected from 245 managers across various public energy companies in the UAE. The survey instrument measured variables pertaining to AI, such as Customer Relationship Management and Cost-efficient IS Operations, and facets of organizational agility, including Responsiveness and Competency, as well as overall Organizational Performance.
 
Findings: The study's findings reveal a significant direct impact of AI on organizational performance, which is further enhanced by the presence of organizational agility. The data indicates that AI's integration within Customer Relationship Management and Cost-efficient IS Operations positively affects performance. Additionally, organizational agility through its components of Responsiveness and Competency serves as a significant intermediary, amplifying the influence of AI on performance.
 
Originality/value: The research is grounded in the Process Theory of Change, the Diffusion of AI Theory, and the Resource-Based View Theory, providing a solid theoretical base for its exploration. It offers a nuanced understanding of the combined impact of AI and organizational agility on the public energy sector's performance.
 
Practical implications: The paper concludes with a conceptual framework that encapsulates these relationships, providing stakeholders with a comprehensive view of the interdependencies between AI, agility, and performance. It stresses the imperative for a strategic embrace of AI and organizational agility to foster resilience, adaptability, and sustainable advancement in the UAE's public energy sector. The insights from this paper guide future strategic orientations, emphasizing the integration of technological innovation with agile organizational practices as a pathway to enhanced performance and sectoral leadership.",Journal of Law and Sustainable Development,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.55908/sdgs.v12i1.2808
ea4d51c2e652a398de9a648368686584a6c25ed6,https://www.semanticscholar.org/paper/ea4d51c2e652a398de9a648368686584a6c25ed6,in whose voice?: examining ai agent representation of people in social interaction through generative speech,"As generative artificial intelligence (genAI) applications gain popularity, there is a dearth of research examining how applications may transform social interactions. One possible application set to transform social interactions is the use of generative speech to power AI agents that can realistically represent people. Our work examines the potential implications of AI agents representing individuals in human conversations (""agent representation"") as a way to begin filling this research gap. We take a multi-method approach, conducting formative interviews with developers, a co-design workshop with designers, a harm analysis among researchers, and interviews with the general public. Both technologists and potential users worry adopting agent representations might harm the quality, trust, and autonomy of human communication. Potential users are particularly concerned that agent representations could undermine the value of social interaction and threaten individuals’ ability to control their image. To avoid such potential consequences, future genAI-powered agents and speech applications should take into account user-defined red lines when considering applying these technologies in social settings.",Conference on Designing Interactive Systems,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3643834.3661555
b23e112a16c201194dce36eefc1dc09cbd1c8658,https://www.semanticscholar.org/paper/b23e112a16c201194dce36eefc1dc09cbd1c8658,generative artificial intelligence to produce high-fidelity blastocyst-stage embryo images,"Abstract STUDY QUESTION Can generative artificial intelligence (AI) models produce high-fidelity images of human blastocysts? SUMMARY ANSWER Generative AI models exhibit the capability to generate high-fidelity human blastocyst images, thereby providing substantial training datasets crucial for the development of robust AI models. WHAT IS KNOWN ALREADY The integration of AI into IVF procedures holds the potential to enhance objectivity and automate embryo selection for transfer. However, the effectiveness of AI is limited by data scarcity and ethical concerns related to patient data privacy. Generative adversarial networks (GAN) have emerged as a promising approach to alleviate data limitations by generating synthetic data that closely approximate real images. STUDY DESIGN, SIZE, DURATION Blastocyst images were included as training data from a public dataset of time-lapse microscopy (TLM) videos (n = 136). A style-based GAN was fine-tuned as the generative model. PARTICIPANTS/MATERIALS, SETTING, METHODS We curated a total of 972 blastocyst images as training data, where frames were captured within the time window of 110–120 h post-insemination at 1-h intervals from TLM videos. We configured the style-based GAN model with data augmentation (AUG) and pretrained weights (Pretrained-T: with translation equivariance; Pretrained-R: with translation and rotation equivariance) to compare their optimization on image synthesis. We then applied quantitative metrics including Fréchet Inception Distance (FID) and Kernel Inception Distance (KID) to assess the quality and fidelity of the generated images. Subsequently, we evaluated qualitative performance by measuring the intelligence behavior of the model through the visual Turing test. To this end, 60 individuals with diverse backgrounds and expertise in clinical embryology and IVF evaluated the quality of synthetic embryo images. MAIN RESULTS AND THE ROLE OF CHANCE During the training process, we observed consistent improvement of image quality that was measured by FID and KID scores. Pretrained and AUG + Pretrained initiated with remarkably lower FID and KID values compared to both Baseline and AUG + Baseline models. Following 5000 training iterations, the AUG + Pretrained-R model showed the highest performance of the evaluated five configurations with FID and KID scores of 15.2 and 0.004, respectively. Subsequently, we carried out the visual Turing test, such that IVF embryologists, IVF laboratory technicians, and non-experts evaluated the synthetic blastocyst-stage embryo images and obtained similar performance in specificity with marginal differences in accuracy and sensitivity. LIMITATIONS, REASONS FOR CAUTION In this study, we primarily focused the training data on blastocyst images as IVF embryos are primarily assessed in blastocyst stage. However, generation of an array of images in different preimplantation stages offers further insights into the development of preimplantation embryos and IVF success. In addition, we resized training images to a resolution of 256 × 256 pixels to moderate the computational costs of training the style-based GAN models. Further research is needed to involve a more extensive and diverse dataset from the formation of the zygote to the blastocyst stage, e.g. video generation, and the use of improved image resolution to facilitate the development of comprehensive AI algorithms and to produce higher-quality images. WIDER IMPLICATIONS OF THE FINDINGS Generative AI models hold promising potential in generating high-fidelity human blastocyst images, which allows the development of robust AI models as it can provide sufficient training datasets while safeguarding patient data privacy. Additionally, this may help to produce sufficient embryo imaging training data with different (rare) abnormal features, such as embryonic arrest, tripolar cell division to avoid class imbalances and reach to even datasets. Thus, generative models may offer a compelling opportunity to transform embryo selection procedures and substantially enhance IVF outcomes. STUDY FUNDING/COMPETING INTEREST(S) This study was supported by a Horizon 2020 innovation grant (ERIN, grant no. EU952516) and a Horizon Europe grant (NESTOR, grant no. 101120075) of the European Commission to A.S. and M.Z.E., the Estonian Research Council (grant no. PRG1076) to A.S., and the EVA (Erfelijkheid Voortplanting & Aanleg) specialty program (grant no. KP111513) of Maastricht University Medical Centre (MUMC+) to M.Z.E. TRIAL REGISTRATION NUMBER Not applicable.",Human Reproduction,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1093/humrep/deae064
2e6e0c741d6c83f12dfac4e02b570c64b9aa0bf7,https://www.semanticscholar.org/paper/2e6e0c741d6c83f12dfac4e02b570c64b9aa0bf7,the transformative potential of generative artificial intelligence,"This paper analyses the transformative potential of generative artificial intelligence at macro, meso, and micro levels of social and economic structures. The aim is to determine the impact of these technologies on various aspects of society and economy, including business operations and the labour market. The potential of new technologies to increase productivity, transform business models, and create new professional roles has been examined through a comprehensive analysis of data and studies. It has been concluded that generative artificial intelligence can fundamentally change the labour market, globally increase gross domestic product, and improve both the public and private sectors. The paper provides insights into future trends and regulatory and structural changes that are necessary for optimising the application of generative AI.",Napredak,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.5937/napredak5-52069
6c80fe5c53dba89b8a95334362566194e39a230e,https://www.semanticscholar.org/paper/6c80fe5c53dba89b8a95334362566194e39a230e,building trustworthy generative artificial intelligence for diabetes care and limb preservation: a medical knowledge extraction case.,"BACKGROUND
Large language models (LLMs) offer significant potential in medical information extraction but carry risks of generating incorrect information. This study aims to develop and validate a retriever-augmented generation (RAG) model that provides accurate medical knowledge about diabetes and diabetic foot care to laypersons with an eighth-grade literacy level. Improving health literacy through patient education is paramount to addressing the problem of limb loss in the diabetic population. In addition to affecting patient well-being through improved outcomes, improved physician well-being is an important outcome of a self-management model for patient health education.


METHODS
We used an RAG architecture and built a question-and-answer artificial intelligence (AI) model to extract knowledge in response to questions pertaining to diabetes and diabetic foot care. We utilized GPT-4 by OpenAI, with Pinecone as a vector database. The NIH National Standards for Diabetes Self-Management Education served as the basis for our knowledge base. The model's outputs were validated through expert review against established guidelines and literature. Fifty-eight keywords were used to select 295 articles and the model was tested against 175 questions across topics.


RESULTS
The study demonstrated that with appropriate content volume and few-shot learning prompts, the RAG model achieved 98% accuracy, confirming its capability to offer user-friendly and comprehensible medical information.


CONCLUSION
The RAG model represents a promising tool for delivering reliable medical knowledge to the public which can be used for self-education and self-management for diabetes, highlighting the importance of content validation and innovative prompt engineering in AI applications.",Journal of Diabetes Science and Technology,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/19322968241253568
3488e7b86f16c0d93b7b151eca0d7e7526e6d44b,https://www.semanticscholar.org/paper/3488e7b86f16c0d93b7b151eca0d7e7526e6d44b,beyond principles: embedding ethical ai risks in public sector risk management practice,"Artificial intelligence (AI) adoption by public sector organizations (PSOs) introduces various ethical risks stemming from a lack of integrating human values into AI design. Addressing these ethical risks is a complex collective responsibility among designers, developers, risk experts, and public sector managers. Embedding these risks in existing risk management practices is crucial for responsible AI adoption, as emphasized by the legal requirements of the EU AI Act. However, the responsibility for managing these ethical risks is often unclear. Public sector organizations face unique challenges due to the complex, uncertain, and rapidly evolving nature of AI technologies, further complicating the management of ethical risks. This paper explores using the Three Lines of Defense (TLoD) risk management model to understand and address these ethical risks in public sector AI adoption. The TLoD model structures risk management across three lines: operational management, risk oversight and compliance, and internal audit. This framework helps to distribute and integrate the collective responsibility for ethical AI risk management within public sector organizations, emphasizing alignment and collaboration among different actors. Through an exploratory study involving a survey and semi-structured interviews with professionals responsible for AI-related risk management in Dutch public sector organizations, we assess the TLoD model's usefulness in addressing ethical AI risks. The study examines the challenges and opportunities in applying the TLoD model to manage ethical risks and identifies the potential gaps in responsibility and oversight. The findings suggest that while the TLoD model offers a valuable lens for distributing risk management responsibilities, there are limitations in addressing the emergent and complex nature of ethical risks in AI adoption.",Digital Government Research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3657054.3657063
f93400247580dd8f09e01c05c211699c594bae93,https://www.semanticscholar.org/paper/f93400247580dd8f09e01c05c211699c594bae93,artificial intelligence (ai) applications and usage among the lis professionals of pakistan,"Artificial intelligence (AI) is an important and emerging sub-discipline in information technology that is progressively being implemented in every field. It is gradually being introduced to support new forms of research, discovery, and reuse of library contents in advanced and interesting ways. University libraries have the potential to substantially improve their library services through the implementation of sophisticated AI tools. This study explored the application of AI tools in the university libraries of Pakistan, as well as draw a comparison in the usage of AI tools between public and private sector universities. This is a quantitative study and data is collected through survey methodology. We used purposive sampling to collect the data from 175 university libraries. The collected data was analyzed using a statistical package for social sciences (SPSS-version 22). Findings indicate that while AI-based services are starting to be introduced into university libraries in Pakistan, no university library has implemented the full suite of AI-based tools. Natural language processing, voice searching, and chatbots are the most familiar and popular tools currently used in libraries. However, robotics technology is rarely used with a mean value of (1.62) because of the financial investment and high level of IT skills required. We found that private university libraries are using AI tools more as compared with public sector university libraries. The study concludes with several key recommendations, including closer collaboration between the library and the respective university IT department for technical support and assistance; improved financial support and ICT infrastructure to establish AI technology-based library services; and training development plans for library staff. Insights gained from this study should contribute to the capacity of Pakistani University librarians and their staff to maximize the full potential of AI within their institutions. The research implications are helpful to library leaders and policymakers in building a policy for AI-based technology in their respective university libraries.",Journal of Librarianship and Information Science,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1177/09610006241241306
6ff9e22615f12b031caa3ea582f1e28efa408f87,https://www.semanticscholar.org/paper/6ff9e22615f12b031caa3ea582f1e28efa408f87,"exploring generative ai literacy in higher education: student adoption, interaction, evaluation and ethical perceptions","Purpose
Current knowledge and research on students’ utilization and interaction with generative artificial intelligence (AI) tools in their academic work is limited. This study aims to investigate students’ engagement with these tools.

Design/methodology/approach
This research used survey-based research to investigate generative AI literacy (utilization, interaction, evaluation of output and ethics) among students enrolled in a four-year public university in the southeastern USA. This article focuses on the respondents who have used generative AI (218; 47.2%).

Findings
Most respondents used generative AI to generate ideas for papers, projects or assignments, and they also used AI to assist with their original ideas. Despite their use of AI assistance, most students were critical of generative AI output, and this mindset was reflected in their reported interactions with ChatGPT. Respondents expressed a need for explicit guidance from course syllabi and university policies regarding generative AI’s ethical and appropriate use.

Originality/value
Literature related to generative AI use in higher education specific to ChatGPT is predominantly from educators’ viewpoints. This study provides empirical evidence about how university students report using generative AI in the context of generative AI literacy.
",Information and Learning Sciences,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/ils-10-2023-0160
425cef59cbd966ee2aa2c42114021a56c51ffa67,https://www.semanticscholar.org/paper/425cef59cbd966ee2aa2c42114021a56c51ffa67,generative ai and the future of work: augmentation or automation?,"1 This report examines the potential impact of Generative artificial intelligence (AI) systems, such as ChatGPT, on the future of work and, by implication, on productivity. It argues that although Generative AI is powerful, it has significant limitations and risks that require humans to remain “in the loop” not only to prevent systems from going off the rails, but to capture value. Rather than taking a deterministic view that artificial intelligence (AI) will inevitably destroy jobs, the article suggests that an analysis should start with how firms can strategically deploy these tools to gain an advantage. It asks whether “augmentation” or “simplistic automation” lies ahead. Our objective is to move beyond hype and despair. 2 The existing digital infrastructure has enabled AI to be adopted quickly. However, projections based solely on automating existing tasks fail to capture the complex reorganizations that are likely to happen. Firms in sectors such as professional services, materials, and pharmaceuticals seem to have particular exposure to the use of Generative AI tools. Adaptations will vary across contexts and depend greatly on who controls the decisions about deployment. Maintaining the centrality of humans is likely to prove crucial—in training systems, curating data, and assessing outputs. One question is which business strategies and public policies encourage that engagement and make it possible. Although AI regulation debates matter, promoting social prosperity depends heavily on directly shaping the trajectory of the development and use of AI. This requires influencing the constraints and the incentives that firms face, as well as the strategic mindsets of decision makers. Which groups are engaged in the discussions and debates is of vital importance. The article recommends that, beyond the traditional policy proposals, an independent public-interest consultancy needs to be established in order to design creative business strategies that augment workers in a manner that will support, rather than hinder, social prosperity. Ultimately, avoiding a dystopian scenario might hinge on fostering new norms in which human capabilities remain essential.",Social Science Research Network,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2139/ssrn.4811728
53306a6ca093de1bd66cd798e7e4519e5aa4f608,https://www.semanticscholar.org/paper/53306a6ca093de1bd66cd798e7e4519e5aa4f608,a legal and ethical review of artificial intelligence technology in public safety management,"Abstract The imperative to meticulously assess and manage the legal and ethical risks associated with artificial intelligence (AI) in public safety management is increasingly recognized. This study employs the Apriori algorithm to identify frequent itemsets in public safety risk management, further refining these findings using the FP-growth algorithm’s Gini coefficient to pinpoint optimal features representing legal-ethical risk factors. Cloud modeling techniques are also applied to examine the nuances of AI’s legal ethics. Our analysis reveals a significant growth in AI patent applications within the public safety sector, showing an increase in the relative growth rate from 1.1679 to 1.4810 over eight years, equating to an 88.66% rise. Based on highest membership values in the risk prevention and control system, risk categorization identified social ethics risk and public security threat risk with indices of 0.461, 0.721, and 0.499, respectively, classifying them into class II and III risks. This investigation into AI’s legal ethics forms a critical foundation for developing a risk regulation framework and offers strategic recommendations for legal reform, ensuring AI’s positive trajectory in public safety.",Applied Mathematics and Nonlinear Sciences,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2478/amns-2024-0954
d9db3888acd27f028730672c6b8d4bef12bfe207,https://www.semanticscholar.org/paper/d9db3888acd27f028730672c6b8d4bef12bfe207,"public service delivery, artificial intelligence and the sustainable development goals: trends, evidence and complexities","Purpose
Recent technological developments have encouraged the United Nations to promote the adoption of digital technologies to achieve the Sustainable Development Goals (SDGs). In addition to initiatives from businesses, an increasing number of studies indicate that public service agencies may gain benefits from adopting digital transformation. On a global scale, policymakers are examining the integration of digital technologies, specifically artificial intelligence (AI), into public service delivery (PSD), acknowledging the potential advantages and obstacles for the public sector. Therefore, the objective of this study is to investigate the impact of AI on PSD to support the SDGs initiative.

Design/methodology/approach
The research used a qualitative approach to explore the intersection of AI, SDGs and PSD. This approach involved scrutinising relevant publications and conducting an extensive literature review. The research also used bibliographic analysis to discern patterns within the field. Findings from the literature review and bibliographic analysis contributed to identifying research trends that explore the complex relationship among AI, PSD and the SDGs. The model derived from this comprehensive review and analysis elucidates the potential of AI to enhance PSD and contribute to the achievement of the SDGs.

Findings
The bibliographic study revealed significant research trends concerning AI, PSD and SDGs through an empirical investigation of an extensive array of peer-reviewed articles. This investigation focused on how the public sector can improve its delivery of services to citizens and all stakeholders to advance the SDGs. AI holds the promise of revolutionising PSD and bolstering the SDGs. By leveraging AI’s capabilities in data analysis, automation and customisation, governments can enhance the efficiency, effectiveness and accessibility of public services. This, in turn, enables public servants to tackle more complex tasks while providing citizens with personalised and relevant experiences. Additionally, the study advocates modelling the intersection of PSD and AI to achieve sustainable development.

Research limitations/implications
The employed research methodologies, such as literature reviews and bibliographic analysis, enrich the context of AI, SDGs and PSD. They offer a comprehensive perspective, identify knowledge gaps and furnish policymakers, practitioners and academics with a conceptual framework for informed decision-making and sustainable development endeavours.

Originality/value
The study provides an agenda for AI and SDGs research on application in PSD. It emphasises varied research viewpoints, methods and gaps. This study helps researchers as well as practitioners identify subtopics, intersecting themes and new research pathways.
",Journal of Science and Technology Policy Management,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/jstpm-07-2023-0123
2ef758da3f0043f05fb4e89a6c65c610cbd1d43c,https://www.semanticscholar.org/paper/2ef758da3f0043f05fb4e89a6c65c610cbd1d43c,the use of ai in government and its risks: lessons from the private sector,"
Purpose
This study aims to understand the perceived emotions of human–artificial intelligence (AI) interactions in the private sector. Moreover, this research discusses the transferability of these lessons to the public sector.


Design/methodology/approach
This research analysed the comments posted between June 2022 and June 2023 in the global open Reddit online community. A data mining approach was conducted, including a sentiment analysis technique and a qualitative approach.


Findings
The results show a prevalence of positive emotions. In addition, a pertinent percentage of negative emotions were found, such as hate, anger and frustration, due to human–AI interactions.


Practical implications
The insights from human–AI interactions in the private sector can be transferred to the governmental sector to leverage organisational performance, governmental decision-making, public service delivery and the creation of economic and social value.


Originality/value
Beyond the positive impacts of AI in government strategies, implementing AI can elicit negative emotions in users and potentially negatively impact the brand of private and government organisations. To the best of the authors’ knowledge, this is the first research bridging the gap by identifying the predominant negative emotions after a human–AI interaction.
","Transforming Government: People, Process and Policy",2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/tg-02-2024-0038
fbe965783464000e68863e0a088eaf77444afe5f,https://www.semanticscholar.org/paper/fbe965783464000e68863e0a088eaf77444afe5f,"artificial intelligence, the production of scientific texts, and the implications for sleep science: exploring emerging paradigms and perspectives","The emergence of artificial intelligence (AI) has revolutionized many fields, including natural language processing, and marks a potential paradigm shift in the way we evaluate knowledge. One significant innovation in this area is ChatGPT, a large language model based on the GPT-3.5 architecture created by OpenAI, with one of its main aims being to aid in general text writing, including scientific texts. Here, we highlight the challenges and opportunities related to using generative AI and discuss both the benefits of its use, such as saving time by streamlining the writing process and reducing the amount of time spent on mundane tasks, and the potential drawbacks, including concerns regarding the accuracy and reliability of the information generated and its ethical use. In respect of both education and the writing of scientific texts, clear rules and objectives and institutional principles must be established for the use of AI. We also consider the positive and negative effects of the use of AI technologies on interpersonal interactions and behavior, and, as sleep scientists, its potential impacts on sleep. Striking a balance between the benefits and potential drawbacks of integrating AI into society demands ongoing research by experts, the wide dissemination of the scientific results, as well as continued public discourse on the subject.",Sleep Science,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1055/s-0044-1788285
d1718bda3719edf47d7e8b7017db37a1107e6c9e,https://www.semanticscholar.org/paper/d1718bda3719edf47d7e8b7017db37a1107e6c9e,the application of gen-ai and creativity in the context of public education in frontier environments,"PurposeThe purpose of this article is to demonstrate how the creativity technique SCAMPER and generative Artificial Intelligence (Gen-AI) are linked in the formative process for the solution of business problems by groups of students from low socio-economic levels of a public university in the city of San José de Cucuta, Colombia.Design/methodology/approachAn analysis of the contributions of generative artificial intelligence was developed and the knowledge gaps related to advanced artificial intelligence-based linguistic models in the education sector were mentioned. Subsequently, views on the Colombian context of science, technology and innovation were developed. Finally, the experience in the application of teaching-learning strategies through the use of Open AI’s creativity technique and ChatGPT was highlighted.FindingsThe findings highlight the complementarity of generative artificial intelligence and the SCAMPER creativity technique in the development of innovation capabilities. While human creativity highlights emotional aspects. Artificial intelligence consolidates procedural aspects and ideas focused on the primary activities of the value chain.Practical implicationsThe implementation of the hybrid model in the classroom can lead to the development of new capabilities by marginalized groups immersed in the educational system. The potential positive impact of Gen-AI and human creativity will be reflected in the optimization of response times and the search for solutions to problems in different environments.Originality/valueThis opinion article highlights the implementation of AI in a Higher Education Institution located in the frontier zone of San José de Cucuta, Colombia. In addition, it involves actors of the educational system whose economic income is low. Finally, it highlights the positive impact of the integration of creativity techniques and the use of generative artificial intelligence in the classroom, highlighting the use of hybrid models (Man-Machine).",Journal of Enabling Technologies,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/jet-05-2024-0030
305eeffe0bee53fa400a8ecad024f1c18c1280b8,https://www.semanticscholar.org/paper/305eeffe0bee53fa400a8ecad024f1c18c1280b8,"artificial intelligence and decision-making in government functions: opportunities, challenges and future research","Purpose
Artificial intelligence (AI) has received much attention due to its promethean-like powers to transform the management and delivery of public sector services. Due to the proliferation of research articles in this context, research to date is fragmented into research streams based on different types of AI technologies or a specific government function of the public sector (e.g. health, education). The purpose of this study is to synthesize this literature, identify challenges and opportunities, and offer a research agenda that guides future inquiry.

Design/methodology/approach
This paper aggregates this fragmented body of knowledge by conducting a systematic literature review of AI research in public sector organisations in the Chartered Association of Business Schools (CABS)-ranked journals between 2012 and 2023.

Findings
The search strategy resulted in the retrieval of 2,870 papers, of which 61 were identified as primary papers relevant to this research. These primary papers are mapped to the ten classifications of the functions of government as classified by the Organisation for Economic Co-operation and Development (OECD), and the reported challenges and benefits aggregated.

Originality/value
This study advances knowledge by providing a state-of-the-art of AI research based the OECD classifications of government functions, reporting of claimed benefits and challenges and providing a research agenda for future research.
","Transforming Government: People, Process and Policy",2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/tg-06-2024-0131
6a5a3b2f97240204e9895f8b9ccf5192b4558ace,https://www.semanticscholar.org/paper/6a5a3b2f97240204e9895f8b9ccf5192b4558ace,organisational enablers of artificial intelligence adoption in public institutions: a systematic literature review,"Purpose: The purpose of the presented study was to develop a set of recommendations for decision-makers (policymakers and public managers) and public employees to enhance the effectiveness and efficiency of organisational elements in the adoption of artificial intelligence (AI) in public institutions. Design/methodology/approach: Utilising a systematic literature review following the PRISMA protocol, the study examines the organisational enablers of AI adoption in public institutions. Comprehensive search queries in the Scopus database identified relevant literature focusing on the intersection of AI technologies and various organisational elements. The analysis was facilitated by NVivo 12, enabling a structured examination of key organisational facets for people, culture, structure, processes, and technology within public institutions. Findings: Previous studies on AI adoption in public institutions identified numerous enablers of AI adoption associated with organisational elements like people/employees, structure, culture, technology, and processes. Several surveys and case studies stress the importance of concentrating on the introduction or transformation of these organisational elements prior to or concurrently with the adoption of AI. Academic contribution to the field: By applying a systematic literature review protocol, the study represents the first holistic and systematic review of specific organisational elements that can serve as enablers of AI adoption in public institutions. Research limitations/implications: This systematic literature review was subject to several limitations. Firstly, the division of AI literature between natural and social sciences, with the former focusing on technical aspects and the latter on broader organisational themes, may have resulted in an incomplete depiction of the intersection of AI and organisational change. Secondly, despite the broad search queries, inherent limitations of keyword-based searches may have excluded some relevant studies. Thirdly, considering the rapid evolution of AI technology, our review may not fully encapsulate the very latest developments in the field as it covers literature published until May 2023. Finally, the interpretation and coding of literature, despite the use of NVivo 12, involved subjective elements that could affect the study’s outcomes. Practical implications: Drawing from experiences in the private sector, public institutions are increasingly adopting AI technologies across various subsectors such as public finance (taxation), research, healthcare, law enforcement, defence, education. This requires a transformation in both hard (structure, processes etc.) and soft aspects (people, organisational culture etc.). Therefore, the enablers identified in the study can serve as guidelines for decision-makers and implementers of AI at all levels of public institutions. Social implications: If adopted effectively and efficiently and used professionally and ethically, the use of AI in public institutions can bring many benefits to society, such as transparency, justice, cost and time efficiency, high quality services, and improved collaboration between different stakeholders in society. Originality/significance/value: Our study makes a distinct contribution by shifting the focus from technological barriers to organisational enablers of AI adoption in public institutions. It bridges a critical gap in the literature by integrating both technical and social science perspectives, providing valuable insights for theory and practice in the fields of organisation and management.",Central European Public Administration Review,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.17573/cepar.2024.1.05
b7aafd56e7263ad9b8b693d6009742c84633d0db,https://www.semanticscholar.org/paper/b7aafd56e7263ad9b8b693d6009742c84633d0db,aligning artificial intelligence with ethical accountancy: a global perspective on emerging frameworks,"This study meticulously examines the integration of artificial intelligence (AI) into the accounting sector, revealing transformative opportunities alongside emerging ethical challenges. Drawing inspiration from established principles of the American Institute of Certified Public Accountants (AICPA) Code of Professional Conduct (AICPA, 2016), an innovative Accounting Framework for AI Ethics (AFAIE) is introduced. This framework aims to provide a tailored approach that ensures that the adoption of AI technologies aligns with the fundamental professional values of trust and integrity. It aims to address the concerns and potential risks associated with the use of AI and establish guidelines that promote accountability and transparency in the development and deployment of AI systems. The essence of this research is underscored by the advocacy for resilient ethical paradigms that are instrumental in navigating the complexities introduced by AI in accounting. Emphasizing a global perspective, this study advocates universal ethical guidelines, ensuring adaptability to specific regional and professional contexts (Association of Chartered Certified Accountants [ACCA], 2016; Bertucci et al., 2021). This synthesis of technology and ethics aims to foster an environment in which innovation thrives alongside steadfast adherence to professional integrity and responsibility.",Corporate Ownership and Control,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.22495/cocv21i1art5
6c1fb57c5d6c6cffcebbe2b31f9a943adb716a44,https://www.semanticscholar.org/paper/6c1fb57c5d6c6cffcebbe2b31f9a943adb716a44,identifying librarians’ readiness to leverage artificial intelligence for sustainable competence development and smart library services: an empirical investigation from universities’ librarians,"
Purpose
This study aims to identify the librarians’ readiness to leverage artificial intelligence for sustainable competence development and smart library services.


Design/methodology/approach
This study used a quantitative research design for addressing the objectives. The population consisted of librarians from the public and private sector universities of Pakistan. The data were analyzed by using Smart PLS software.


Findings
The analysis consisted of two major parts: first the assessment of measurement model and second the structural equation modeling analysis. A significant positive impact of AI adoption was found on the implementation smart library services. Findings revealed that behavioral intention motivated librarians to adopt AI tools in university libraries for the delivery of smart library services.


Research limitations/implications
We applied quantitative method to carry out the study while future authors may conduct a systematic literature review on the same topic for offering a broader outlook.


Practical implications
It has provided practical contributions by providing a baseline for management bodies to construct policies for the successful adoption of AI in libraries for sustainable competence development of practicing librarians and implementation of smart library services.


Social implications
The study has social implications too as AI integrated library services prove fruitful for society and digitally skilled librarians play a vital role for the promotion of reading and research culture in society.


Originality/value
To the best of the authors’ knowledge, this is the first study on librarians’ readiness to leverage artificial intelligence for the enhancement of digital literacy skills, sustainable competence development and smart library services in the context of Pakistan.
",Global Knowledge Memory and Communication,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/gkmc-02-2024-0107
58b7ea14464538f5a7ea31df0e518df1c3efd0e6,https://www.semanticscholar.org/paper/58b7ea14464538f5a7ea31df0e518df1c3efd0e6,exploring citizens’ stances on ai in public services: a social contract perspective,"Abstract This paper explores citizens’ stances toward the use of artificial intelligence (AI) in public services in Norway. Utilizing a social contract perspective, the study analyzes the government–citizen relationship at macro, meso, and micro levels. A prototype of an AI-enabled public welfare service was designed and presented to 20 participants who were interviewed to investigate their stances on the described AI use. We found a generally positive attitude and identified three factors contributing to this: (a) the high level of trust in government (macro level); (b) the balanced value proposition between individual and collective needs (meso level); and (c) the reassurance provided by having humans in the loop and providing transparency into processes, data, and model’s logic (microlevel). The findings provide valuable insights into citizens’ stances for socially responsible AI in public services. These insights can inform policy and guide the design and implementation of AI systems in the public sector by foregrounding the government–citizen relationship.",Data & Policy,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1017/dap.2024.13
2ca8e568a7c9cf3ad7368fd8b6b6a327f0eb35f1,https://www.semanticscholar.org/paper/2ca8e568a7c9cf3ad7368fd8b6b6a327f0eb35f1,artificial intelligence through the prism of thematic research on researchgate web portal,"Different instances of generative artificial intelligence (GenAI) in a short time have made a significant impact on the world’s economic and political scene. Before October 2022, processes of automatization and robotization of manufacturing didn’t have an immediate connection with artificial intelligence in the minds of most people. But mass and sudden infiltration of GenAI into the everyday life of many people around the world caused an immediate reaction from scientists, public figures, politicians, managers and heads of whole sectors of the economy. Thousands of scientific articles on related topics were published in the last two years: everyone at once started talking about fantastic possibilities, and also threats, which this new technology can usher in for our societies. Thus, for public thinking GenAI finally linked automatization with artificial intelligence. 
This paper provides an analysis of problems and prospects, through which scientists are trying to understand different societal processes linked to adoption of AI. For this purpose, the author of this paper analyzed the contents of papers published on this topic on the ResearchGate web portal in 2023, with the choice of the source for representative material motivated by scientific credibility of ResearchGate combined with its wide reach. Ten most popular articles were specifically targeted for final analysis, through which societal trends brought on by AI adoption were described. Although a selective meta-analysis of articles published during the first year after ChatGPT release can’t provide a full understanding of AI potential and possible threats to society, the conclusion can still be reached that a cardinal shift in society’s attitudes towards its own future is required. 
From the ten articles analyzed, four are related to changes required to the education system, four are about AI’s influence on the labour market, one article talks about the possibility of AI-human competition and one is about the AI potential in agriculture. Most articles mention the need for legislative changes in terms of labor protection and education reforms in-line with new digital reality.",Culture of Ukraine,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.31516/2410-5325.083.02
2d88f0f218151f6f38f3888024ccff9e8c3ed0f7,https://www.semanticscholar.org/paper/2d88f0f218151f6f38f3888024ccff9e8c3ed0f7,criteria for selecting artificial intelligence tools,"Artificial Intelligence (AI) represents a transformative force across numerous sectors, from healthcare and finance to automotive and public services. The selection and deployment of AI tools are critical to leveraging this technology’s potential while adhering to ethical standards, regulatory compliance, and ensuring societal benefit. The European Union (EU) has been at the forefront of establishing frameworks and criteria to guide the development, deployment, and selection of AI systems to foster innovation while protecting citizens’ rights and societal values. The EU’s proactive stance in establishing these criteria aims to balance innovation with ethical considerations and societal welfare, setting a benchmark for responsible AI development and deployment globally. The aim of the article is to present general criteria for the selection of artificial intelligence tools, as well as those specific to the field of publishing. The research was carried out based on the analysis of scientific and other sources. The results of the study can be useful for organizations and individuals that must be interested in selecting and using the right AI tools.","Innovations in Publishing, Printing and Multimedia Technologies",2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.59476/ilpmt2024.100-106
34270a7b96d494461465e72c55c1cc84f6417e30,https://www.semanticscholar.org/paper/34270a7b96d494461465e72c55c1cc84f6417e30,"world’s first law for artificial intelligence. legal, ethical and economic aspects","The European Parliament has enacted the first comprehensive AI law, garnering widespread public interest and varied reactions. This regulation addresses the specific challenges posed by AI systems, aiming to ensure their safety, legal compliance, and alignment with EU fundamental rights and values. Key goals include fostering legal certainty to boost AI investments and innovations, enhancing governance, and preventing market fragmentation. The law employs a risk-based framework, categorizing AI systems into four risk levels: unacceptable, high, limited, and minimal. Unacceptable risk systems, like real-time biometric identification in public spaces, are banned. High-risk systems, such as those used in critical infrastructure or employment, require stringent oversight. Limited risk systems must maintain transparency, informing users when they are interacting with AI. Minimal risk systems, including AI spam filters, are allowed with minimal regulation but still require transparency. Significantly, the law emphasizes ethical AI development, particularly regarding copyright issues in generative AI. It mandates compliance with copyright laws, transparency about training data, and robust cybersecurity measures. Non-compliant companies face severe fines, up to 35 million euros or 7% of annual global revenue. The EU’s AI law sets a pioneering regulatory standard, potentially influencing global AI governance. It aims to balance protecting citizens’ rights with fostering a competitive and innovative AI market in Europe, potentially serving as a model for other democratic nations.",Education and Technologies Journal,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.26883/2010.241.5985
2b079c206e1db7415950d1f2209864fe0dfa5dff,https://www.semanticscholar.org/paper/2b079c206e1db7415950d1f2209864fe0dfa5dff,comunicación de moda e inteligencia artificial: el caso de neural fashion ai,"Artificial intelligence is presented to society as a revolutionary tool capable of generating a change asunique as the democratization of Internet access at the beginning of the 21st Century. The different applications of AI are facilitating the development of marketing and communication strategies adapted to the needs of the public and the establishment of strong relationships with them. One of the most dynamic consumer markets is fashion communication, which is why we decided to delimit the applications of AI to brands in this sector. First goal was to identify the main resources and applications of AI that are being used to communicatewith the different stakeholders of fashion companies, particularly with the final consumer. Second objective was to recognize benefits and positive aspects along with the brakes and barriers that the application of this technology represents for the communication strategies of fashion brands. Thirdly, a case studyis offered to help academics and professionals understand how the fashion sector is receiving the helpof generative AI in the creation of campaigns. Through a combination of qualitative methods including3 Delphi interviews, a hemerographic research of professional publications and the Neural Fashion AI case study, the capacity of AI to point out a differentiating factor in the market that has to do withsustainability, product customization and optimization of company resources has been demonstrated. The main results highlight the contribution that AI makes to the efficiency of processes and to the achievement of brand objectives (customer satisfaction, loyalty, strengthening of positioning and brand image), expansion into new marketsand audiences, or the creation of innovative, impactful and attractive content.",Universitas,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.17163/uni.n41.2024.01
ef59842a40f2f88b03804608dcc2a8a6fb0f120d,https://www.semanticscholar.org/paper/ef59842a40f2f88b03804608dcc2a8a6fb0f120d,“chat‐up”: the role of competition in street‐level bureaucrats' willingness to break technological rules and use generative pre‐trained transformers (gpts),"Organizations worldwide are concerned about workers using generative pretrained transformers (GPTs), which can generate human‐like text in seconds at work. These organizations are setting rules on how and when to use GPTs. This article focuses on street‐level bureaucrats' (SLBs) intentions to use GPTs even if their public organization does not allow its use (tech rule‐breaking). Based on a mixed‐methods exploratory design, using focus groups (N = 14) and a survey experiment (N = 279), we demonstrate that SLBs intend to break the rules and use GPTs when their competitors from the private sector have access to artificial intelligence (AI) tools. We discuss these findings in the context of hybrid forms of public management and the Promethean moment of GPTs.",PAR. Public Administration Review,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1111/puar.13824
3553135f337934ec6297ec14473eb5969f799e71,https://www.semanticscholar.org/paper/3553135f337934ec6297ec14473eb5969f799e71,artificial intelligence in ischemic stroke images: current applications and future directions,"This paper reviews the current research progress in the application of Artificial Intelligence (AI) based on ischemic stroke imaging, analyzes the main challenges, and explores future research directions. This study emphasizes the application of AI in areas such as automatic segmentation of infarct areas, detection of large vessel occlusion, prediction of stroke outcomes, assessment of hemorrhagic transformation risk, forecasting of recurrent ischemic stroke risk, and automatic grading of collateral circulation. The research indicates that Machine Learning (ML) and Deep Learning (DL) technologies have tremendous potential for improving diagnostic accuracy, accelerating disease identification, and predicting disease progression and treatment responses. However, the clinical application of these technologies still faces challenges such as limitations in data volume, model interpretability, and the need for real-time monitoring and updating. Additionally, this paper discusses the prospects of applying large language models, such as the transformer architecture, in ischemic stroke imaging analysis, emphasizing the importance of establishing large public databases and the need for future research to focus on the interpretability of algorithms and the comprehensiveness of clinical decision support. Overall, AI has significant application value in the management of ischemic stroke; however, existing technological and practical challenges must be overcome to achieve its widespread application in clinical practice.",Frontiers in Neurology,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3389/fneur.2024.1418060
fc4850873eba04ef7a5d5388794ea3e145aec98e,https://www.semanticscholar.org/paper/fc4850873eba04ef7a5d5388794ea3e145aec98e,atommic: an advanced toolbox for multitask medical imaging consistency to facilitate artificial intelligence applications from acquisition to analysis in magnetic resonance imaging,"BACKGROUND AND OBJECTIVES
Artificial intelligence (AI) is revolutionizing Magnetic Resonance Imaging (MRI) along the acquisition and processing chain. Advanced AI frameworks have been applied in various successive tasks, such as image reconstruction, quantitative parameter map estimation, and image segmentation. However, existing frameworks are often designed to perform tasks independently of each other or are focused on specific models or single datasets, limiting generalization. This work introduces the Advanced Toolbox for Multitask Medical Imaging Consistency (ATOMMIC), a novel open-source toolbox that streamlines AI applications for accelerated MRI reconstruction and analysis. ATOMMIC implements several tasks using deep learning (DL) models and enables MultiTask Learning (MTL) to perform related tasks in an integrated manner, targeting generalization in the MRI domain.


METHODS
We conducted a comprehensive literature review and analyzed 12,479 GitHub repositories to assess the current landscape of AI frameworks for MRI. Subsequently, we demonstrate how ATOMMIC standardizes workflows and improves data interoperability, enabling effective benchmarking of various DL models across MRI tasks and datasets. To showcase ATOMMIC's capabilities, we evaluated twenty-five DL models on eight publicly available datasets, focusing on accelerated MRI reconstruction, segmentation, quantitative parameter map estimation, and joint accelerated MRI reconstruction and segmentation using MTL.


RESULTS
ATOMMIC's high-performance training and testing capabilities, utilizing multiple GPUs and mixed precision support, enable efficient benchmarking of multiple models across various tasks. The framework's modular architecture implements each task through a collection of data loaders, models, loss functions, evaluation metrics, and pre-processing transformations, facilitating seamless integration of new tasks, datasets, and models. Our findings demonstrate that ATOMMIC supports MTL for multiple MRI tasks with harmonized complex-valued and real-valued data support while maintaining active development and documentation. Task-specific evaluations demonstrate that physics-based models outperform other approaches in reconstructing highly accelerated acquisitions. These high-quality reconstruction models also show superior accuracy in estimating quantitative parameter maps. Furthermore, when combining high-performing reconstruction models with robust segmentation networks through MTL, performance is improved in both tasks.


CONCLUSIONS
ATOMMIC advances MRI reconstruction and analysis by leveraging MTL and ensuring consistency across tasks, models, and datasets. This comprehensive framework serves as a versatile platform for researchers to use existing AI methods and develop new approaches in medical imaging.",Comput. Methods Programs Biomed.,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.2139/ssrn.4801289
f1d124ae42e5f5fdc28e430f9ffe86c2adb204fb,https://www.semanticscholar.org/paper/f1d124ae42e5f5fdc28e430f9ffe86c2adb204fb,"assessing prognosis in depression: comparing perspectives of ai models, mental health professionals and the general public","Background Artificial intelligence (AI) has rapidly permeated various sectors, including healthcare, highlighting its potential to facilitate mental health assessments. This study explores the underexplored domain of AI’s role in evaluating prognosis and long-term outcomes in depressive disorders, offering insights into how AI large language models (LLMs) compare with human perspectives. Methods Using case vignettes, we conducted a comparative analysis involving different LLMs (ChatGPT-3.5, ChatGPT-4, Claude and Bard), mental health professionals (general practitioners, psychiatrists, clinical psychologists and mental health nurses), and the general public that reported previously. We evaluate the LLMs ability to generate prognosis, anticipated outcomes with and without professional intervention, and envisioned long-term positive and negative consequences for individuals with depression. Results In most of the examined cases, the four LLMs consistently identified depression as the primary diagnosis and recommended a combined treatment of psychotherapy and antidepressant medication. ChatGPT-3.5 exhibited a significantly pessimistic prognosis distinct from other LLMs, professionals and the public. ChatGPT-4, Claude and Bard aligned closely with mental health professionals and the general public perspectives, all of whom anticipated no improvement or worsening without professional help. Regarding long-term outcomes, ChatGPT 3.5, Claude and Bard consistently projected significantly fewer negative long-term consequences of treatment than ChatGPT-4. Conclusions This study underscores the potential of AI to complement the expertise of mental health professionals and promote a collaborative paradigm in mental healthcare. The observation that three of the four LLMs closely mirrored the anticipations of mental health experts in scenarios involving treatment underscores the technology’s prospective value in offering professional clinical forecasts. The pessimistic outlook presented by ChatGPT 3.5 is concerning, as it could potentially diminish patients’ drive to initiate or continue depression therapy. In summary, although LLMs show potential in enhancing healthcare services, their utilisation requires thorough verification and a seamless integration with human judgement and skills.",Family Medicine and Community Health,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1136/fmch-2023-002583
a738d0916ccf3b8970dabe488a3de88f6d2dd4af,https://www.semanticscholar.org/paper/a738d0916ccf3b8970dabe488a3de88f6d2dd4af,"opportunities of gen ai in the banking industry with regards to the ai act, gdpr, data act and dora","Generative Artificial Intelligence (Gen AI) stands at the forefront of the banking sector's technological revolution, promising enhancements in decision-making, risk management, and customer interaction. This paper examines Gen AI's potential to inject innovation and efficiency into banking services, with an estimated value addition of up to $340 billion annually. Grounded in advancements in NLP through Transformer architecture and evolving GPT models, Gen AI's applications in the banking industry are extensive. They range from personalizing customer service with AI-driven chatbots to revolutionizing credit scoring and trading strategies. However, alongside these opportunities, the paper addresses the significant challenges of regulatory compliance, ethical data usage, and the technical integration of AI systems. With the impending release of the EU's AI Act and existing GDPR and DORA, financial institutions must strategize to align with new standards while harnessing Gen AI's capabilities for process optimization and enhanced service delivery. The role of international standards such as ISO/IEC 42001:2023, ISO 31000:2018, ISO/IEC 23894:2023, NIST AI 600-1 and ISO/IEC 23053:2022 is considered to be beneficial in establishing a common framework for managing AI systems, ensuring data integrity and promoting transparency. By adopting these standards, banks can facilitate compliance across various jurisdictions, enhancing operational consistency and reliability – but certain significant limitations in addressing specific regulatory requirements must be taken into account. The paper concludes that Gen AI's future in banking will be transformative, driven by the industry's need to balance technological innovation with ethical and regulatory requirements and process standardization, which will lead to more transparent, personalized and efficient banking services.",Mediterranean Conference on Embedded Computing,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/MECO62516.2024.10577936
282d499f97460e32efae0b0107480d75872bbc5d,https://www.semanticscholar.org/paper/282d499f97460e32efae0b0107480d75872bbc5d,"enhancing e-government services through state-of-the-art, modular, and reproducible architecture over large language models","Integrating Large Language Models (LLMs) into e-government applications has the potential to improve public service delivery through advanced data processing and automation. This paper explores critical aspects of a modular and reproducible architecture based on Retrieval-Augmented Generation (RAG) for deploying LLM-based assistants within e-government systems. By examining current practices and challenges, we propose a framework ensuring that Artificial Intelligence (AI) systems are modular and reproducible, essential for maintaining scalability, transparency, and ethical standards. Our approach utilizing Haystack demonstrates a complete multi-agent Generative AI (GAI) virtual assistant that facilitates scalability and reproducibility by allowing individual components to be independently scaled. This research focuses on a comprehensive review of the existing literature and presents case study examples to demonstrate how such an architecture can enhance public service operations. This framework provides a valuable case study for researchers, policymakers, and practitioners interested in exploring the integration of advanced computational linguistics and LLMs into e-government services, although it could benefit from further empirical validation.",Applied Sciences,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/app14188259
1bdabbddc8e809c8ddd1ce701c5c3feff1cdfdde,https://www.semanticscholar.org/paper/1bdabbddc8e809c8ddd1ce701c5c3feff1cdfdde,ai-based text to scene generation as part of a pandemic compliant infrastructure,"After the 2020–2022 COVID-19 pandemic, it is observed that a responsive medical infrastructure and damage control techniques, including application of technology, have become more important than ever before. Many such technologies, including the Internet of Things (IoT), and artificial intelligence (AI)-aided decision-making have become relevant. Within such a framework, text-to-scene generation through the incorporation of Artificial Intelligence (AI) becomes a critical element of a pandemic-compliant infrastructure design. Our suggested architecture uses AI algorithms to create sceneries that are dynamically adjusted for pandemic compliance. These sceneries cover a wide range of settings, including as public locations, medical institutions, virtual meeting rooms, and more. Our approach makes use of generator and discriminator blocks as part of a Generative Adversarial Network (GAN) which is further enhanced by several attention layers to generate scenes from test descriptions. The output of the proposed approach ensures that scene creation regarding safety precautions like mask wearing, social distance, and sanitization procedures are included in generated output.",International Symposium on Applied Computational Intelligence and Informatics,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/SACI60582.2024.10619874
0013aecf813400174158e4f012918c5408f90962,https://www.semanticscholar.org/paper/0013aecf813400174158e4f012918c5408f90962,can novice teachers detect ai-generated texts in efl writing?,"
 The introduction of generative artificial intelligence (AI) to the wider public could have a huge impact on EFL learning and teaching. Researchers have voiced concerns that learners might lean too much on technology. Previous studies have investigated the use of AI tools in L2 writing with various populations and found that it was difficult for teachers to detect use of AI and that teachers mainly relied on linguistic strategies to detect AI-generated texts. This paper reports on a qualitative study that investigated whether novice English teachers were able to detect AI-generated writing and which strategies they used to do this. The results show that some novice teachers are quite good at detecting AI-generated texts, while others proved to have more difficulties. The teachers used both linguistic and content-related strategies to detect AI-generated writing. The results point towards the value of including this topic in teaching methodology courses in (initial) teacher training programmes.",ELT Journal,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1093/elt/ccae031
041b29a4f27cbbff34140e58f2f0f32a61d9207b,https://www.semanticscholar.org/paper/041b29a4f27cbbff34140e58f2f0f32a61d9207b,the fumes of ai,"
 With the emergence of generative artificial intelligence (GenAI), it is increasingly clear that the environmental impacts of these technologies are significant, and worth exposing to the public. This article discusses the environmental impacts of generative artificial intelligence and the political underpinnings of extractivist technologies such as cloud companies. It highlights the centralized system of power that demands subservience to its foundational values despite being touted as the most environmentally friendly cloud infrastructure globally.",Critical AI,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1215/2834703x-11205231
cd18416bc8705182cdb03c82c30fa95721ca57e9,https://www.semanticscholar.org/paper/cd18416bc8705182cdb03c82c30fa95721ca57e9,the pivotal role of libraries in sustainable ai development,"Artificial Intelligence (AI) has gained exceptional public and media coverage since the launch of the ChatGPT platform, a generative conversational intelligence, in November 2022. Nevertheless, AI is already an integral part of our digital daily lives, as we navigate through social networks, use our GPS, or consult recommendations on e-commerce websites. Due to its pervasive influence across all sectors of our societies, AI is gradually becoming a pivotal subject in terms of regulation, societal direction, and legislation. As early as 2021, UNESCO published a report presenting avenues for ethical considerations in AI. In June 2023, the European Union also established a regulatory framework outlining requirements and obligations for AI usage. As a digital manifestation and given the ""new ways in which its use influences human thinking, interaction and decision-making and affects education, human, social and natural sciences, culture, and communication and information"" (UNESCO. General Conference, 41st, 2021), public libraries have a role to play in enabling residents within their communities to grasp this technology. Their role is all the more significant as AI generates concerns and distrust (Gillath et al., 2021) among populations when ""libraries also continue to enjoy a high level of trust and appreciation in most of their communities"" (Arlitsch \& Newell, 2017). Understanding AI thus constitutes a new cornerstone for accessing the necessary information to advance sustainable development, as outlined in the Lyon Declaration (2014). Moreover, comprehension of AI aligns with the ethical concerns articulated by UNESCO in terms of explainability and transparency and aligns with several Sustainable Development Goals (SDGs) of the 2030 Agenda. These goals include quality education (4), industry, innovation and infrastructure (9), reduced inequalities (10), sustainable cities and communities (11), as well as responsible consumption and production (12). The role of public libraries in advancing the goals of the 2030 Agenda is beyond dispute (IFLA, 2016), and various digital literacies are already integral to their actions. As AI is predominantly developed by global economic giants and permeates all of our practices, ""Shouldn’t [libraries] be the bastions of information literacy and information privacy in an AI world?"" (Cox et al., 2018). Thus, to what extent can public libraries take on this subject to promote and offer relevant literacy? For this study, we will conduct a cross-analysis among three European countries—Spain, France, and Italy—to provide insights into the diverse ways in which AI influences professional practices. Through a literature review and semi-structured interviews, the objective is to delineate the challenges of Artificial Intelligence within the framework of the Agenda 2030 program. Subsequently, we will delve into the specificity of AI Literacy in comparison to Information Literacy, a practice already adopted by libraries. Finally, we will analyze the current and prospective role of AI in libraries to propose avenues for implementing concrete actions.",Canadian journal of information and library science,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.5206/cjils-rcsib.v47i2.17699
8a6a4aaf9f41db7ad87824704c8ef29d6ef8dd71,https://www.semanticscholar.org/paper/8a6a4aaf9f41db7ad87824704c8ef29d6ef8dd71,unraveling indonesian public r&d institutions’ perspectives on chatgpt: an analytical approach to decoding open-ended surveys through topic modeling,"The rapid development of artificial intelligence (AI) technologies like ChatGPT has made global management easier. Since 2020, AI has been widely utilized for all purposes, notably due to its ease in access for scientific production. This study aims to analyze open-ended questions and responses from web-based survey in Indonesian public research and development (R&D) institutions using topic modeling. A total of 205 data points were obtained through web-based surveys conducted among researchers in Indonesian public R&D institutions. To learn their thoughts on the use of ChatGPT (Chat Generative Pre-Trained Transformer), two AI language topic modeling, Latent Dirichlet Allocation (LDA) and Principal Component Analysis (PCA), were employed to detect survey topic structures and show the results. Three theme groups represent the institution's research cohort. Based on generational disparities in birth year and functional position level, this study selected the seven most popular topics from three themes of researchers' opinions on ChatGPT. Researchers of certain age generations and functional position levels focused on new AI technologies, efficiency, and production gains, while others valued methodological innovation, ethics, and scientific integrity. When formulating a strategy for incorporating AI into the public R&D institution's future research agendas, it is imperative to include diverse perspectives.",STIPM (STI Policy and Management) Journal,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.14203/stipm.2024.386
3f2e8bebd871c8f46606a3ac7f1560dd8025f6b4,https://www.semanticscholar.org/paper/3f2e8bebd871c8f46606a3ac7f1560dd8025f6b4,advancing healthcare: the role and impact of ai and foundation models.,"BACKGROUND
The integration of artificial intelligence (AI) into the healthcare domain is a monumental shift with profound implications for diagnostics, medical interventions, and the overall structure of healthcare systems.


PURPOSE
This study explores the transformative journey of foundation AI models in healthcare, shedding light on the challenges, ethical considerations, and vast potential they hold for improving patient outcome and system efficiency. Notably, in this investigation we observe a relatively slow adoption of AI within the public sector of healthcare. The evolution of AI in healthcare is un-paralleled, especially its prowess in revolutionizing diagnostic processes.


RESULTS
This research showcases how these foundational models can unravel hidden patterns within complex medical datasets. The impact of AI reverberates through medical interventions, encompassing pathology, imaging, genomics, and personalized healthcare, positioning AI as a cornerstone in the quest for precision medicine. The paper delves into the applications of generative AI models in critical facets of healthcare, including decision support, medical imaging, and the prediction of protein structures. The study meticulously evaluates various AI models, such as transfer learning, RNN, autoencoders, and their roles in the healthcare landscape. A pioneering concept introduced in this exploration is that of General Medical AI (GMAI), advocating for the development of reusable and flexible AI models.


CONCLUSION
The review article discusses how AI can revolutionize healthcare by stressing the significance of transparency, fairness and accountability, in AI applications regarding patient data privacy and biases. By tackling these issues and suggesting a governance structure the article adds to the conversation about AI integration in healthcare environments.",American journal of translational research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.62347/wqwv9220
b9ccc9fa50ced6592c1175b80fae4749dcd571de,https://www.semanticscholar.org/paper/b9ccc9fa50ced6592c1175b80fae4749dcd571de,a data-centric ai paradigm for socio-industrial and global challenges,"Due to huge investments by both the public and private sectors, artificial intelligence (AI) has made tremendous progress in solving multiple real-world problems such as disease diagnosis, chatbot misbehavior, and crime control. However, the large-scale development and widespread adoption of AI have been hindered by the model-centric mindset that only focuses on improving the code/architecture of AI models (e.g., tweaking the network architecture, shrinking model size, tuning hyper-parameters, etc.). Generally, AI encompasses a model (or code) that solves a given problem by extracting salient features from underlying data. However, when the AI model yields a low performance, developers iteratively improve the code/algorithm without paying due attention to other aspects such as data. This model-centric AI (MC-AI) approach is limited to only those few businesses/applications (language models, text analysis, etc.) where big data readily exists, and it cannot offer a feasible solution when good data are not available. However, in many real-world cases, giant datasets either do not exist or cannot be curated. Therefore, the AI community is searching for appropriate solutions to compensate for the lack of giant datasets without compromising model performance. In this context, we need a data-centric AI (DC-AI) approach in order to solve the problems faced by the conventional MC-AI approach, and to enhance the applicability of AI technology to domains where data are limited. From this perspective, we analyze and compare MC-AI and DC-AI, and highlight their working mechanisms. Then, we describe the crucial problems (social, performance, drift, affordance, etc.) of the conventional MC-AI approach, and identify opportunities to solve those crucial problems with DC-AI. We also provide details concerning the development of the DC-AI approach, and discuss many techniques that are vital in bringing DC-AI from theory to practice. Finally, we highlight enabling technologies that can contribute to realizing DC-AI, and discuss various noteworthy use cases where DC-AI is more suitable than MC-AI. Through this analysis, we intend to open up a new direction in AI technology to solve global problems (e.g., climate change, supply chain disruption) that are threatening human well-being around the globe.",Electronics,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/electronics13112156
ac02d92d3f8b24b838d8a52f1ba1b48790931f07,https://www.semanticscholar.org/paper/ac02d92d3f8b24b838d8a52f1ba1b48790931f07,the ai handbook for financial services leaders : tips and tactics for mastering ai in banking and finance,"This paper explores the multifaceted realm of artificial intelligence (AI) implementation in financial services, providing insights into its potential, challenges and best practices. Highlighting the emergence of generative AI (GenAI) as a transformative tool, the paper underscores its significant impact on productivity and revenue generation within investment banks and capital markets. Addressing inherent risks of AI adoption, the paper stresses the importance of robust governance frameworks to mitigate operational, reputational and compliance risks. Specific attention is given to the phenomenon of GenAI hallucinations and the imperative for deterministic AI models to ensure data integrity and regulatory compliance. The paper outlines four key pillars of AI’s applications in financial services: predictive AI, anomaly detection AI, classification AI and GenAI. Examples highlight AI’s role in risk management, fraud prevention, customer experience enhancement and internal process optimisation, underscoring its transformative potential across the industry. The paper also covers the distinction between public and private AI models, emphasising the advantages of proprietary data-driven insights in ensuring competitive advantage and regulatory compliance. Concluding with actionable insights for AI implementation, the paper advocates for a strategic approach encompassing clear vision setting, risk oversight, data privacy management, centralised data architecture and comprehensive process automation.",Journal of Securities Operations &amp; Custody,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.69554/sesy2749
9b688157f467a83b7f4f6ac4eae7754241018aef,https://www.semanticscholar.org/paper/9b688157f467a83b7f4f6ac4eae7754241018aef,examining ethical aspects of ai: addressing bias and equity in the discipline,"he rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.60087/jaigs.v3i1.119
ffa5a275be9ea886dff66494c821f2b2db2f091d,https://www.semanticscholar.org/paper/ffa5a275be9ea886dff66494c821f2b2db2f091d,exploring ethical dimensions in ai: navigating bias and fairness in the field,"The rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.60087/jaigs.vol03.issue01.p124
7d474e635b35f0915a71d3010b0635b03b367767,https://www.semanticscholar.org/paper/7d474e635b35f0915a71d3010b0635b03b367767,factors affecting citizen intention toward ai acceptance and adoption: the moderating role of government regulations,"
Purpose
This paper aims to explore factors impacting citizen intention toward artificial intelligence (AI) adoption, considering government regulation as a moderating variable. It focuses on the Palestinian Cellular Communications Sector in Gaza Strip, providing insights into the citizen-AI relationship dynamics. The research contributes to enhancing comprehension of AI technology from clients’ perspective.


Design/methodology/approach
To test the hypotheses, a questionnaire was used in an empirical study to collect primary data. In total, 347 Palestinian citizens responded to the survey.


Findings
The findings of this paper reveal that perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns significantly influence citizen intention toward AI adoption. Furthermore, government regulations as a moderating variable strengthen the impact of perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns on citizen intention toward AI acceptance and adoption. Thus, further research should explore specific domains and cultural contexts to gain a more comprehensive understanding of the factors shaping acceptance and adoption.


Research limitations/implications
The findings of the study should be understood in the context of their limitations. First, the study ignored cultural or domain-specific subtleties in favor of generic characteristics, which calls for more research in these particular circumstances. Second, relying on self-reported data might result in biases and limitations due to subjectivity in reporting, indicating the necessity for alternate data gathering methods and approaches in future research.


Practical implications
Policymakers, developers and organizations working to promote the acceptability and implementation of AI applications should consider the practical implications of this study’s results. To secure the long-term use of AI technologies in a responsible and user-centric way, policymakers should give priority to public education and awareness, user-centered design and ethical AI development techniques. They should also stimulate partnerships and create monitoring systems.


Originality/value
This paper investigates the originality of factors that influence citizen intention toward AI acceptance and adoption. It uniquely examines the moderating role of government regulations in shaping this intention. By addressing this novel aspect, the paper contributes to advancing our understanding of the complex dynamics surrounding citizen intentions toward AI applications.
",Competitiveness Review: An International Business Journal,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1108/cr-06-2023-0144
18f4c4e24961c02546fbd0f3423fe9562f872ac3,https://www.semanticscholar.org/paper/18f4c4e24961c02546fbd0f3423fe9562f872ac3,ai in banking: socio-economic aspects,"Artificial intelligence is revolutionising the banking sector, offering a range of benefits such as enhanced customer support, improved fraud detection and more informed decision-making. Banks are using AI technologies to optimise their operations, improve customer service, and proactively manage risks, leading to increased efficiency and productivity. The article is devoted to the issue of studying the use of artificial intelligence in the banking sector. The purpose of the article is to explore the potential of artificial intelligence for the banking sector. The article uses methods of data analysis and synthesis, systematisation and comparison. The article uses statistical data from the World Bank, the State Statistics Service of Ukraine and other official websites. The authors analyse the positive and negative aspects of the use of artificial intelligence in the banking system. Artificial intelligence technologies allow banks to process large amounts of structured and unstructured data to predict market trends, gain insights and identify investment opportunities, which ultimately leads to better decision-making. In banking, the main purpose of AI is to help consumers by prioritising their choices. AI also helps to ensure that customers are satisfied with the bank's services. The paper presents a statistical analysis of GDP growth, inflation and public debt in some countries of the world. With the emergence and spread of FinTech and DeFi technologies and the introduction of CBDC, the system of control and regulation of cash flows is becoming more complex. The practical value of the publication lies in the authors' recommendations on the application of artificial intelligence in the banking sector. The authors suggest ways to maximise the positive effect of artificial intelligence in the banking sector.",Baltic Journal of Economic Studies,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.30525/2256-0742/2024-10-3-26-35
770b35d725e52eb3846ca0ea9b465fc6cbc3cf4b,https://www.semanticscholar.org/paper/770b35d725e52eb3846ca0ea9b465fc6cbc3cf4b,from the evolution of public data ecosystems to the evolving horizons of the forward-looking intelligent public data ecosystem empowered by emerging technologies,"Public data ecosystems (PDEs) represent complex socio-technical systems crucial for optimizing data use in the public sector and outside it. Recognizing their multifaceted nature, previous research pro-posed a six-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed as a result of a systematic literature review on the topic spanning three decade, this model, while theoretically robust, necessitates empirical validation to enhance its practical applicability. This study addresses this gap by validating the theoretical model through a real-life examination in five European countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This empirical validation provides insights into PDEs dynamics and variations of implementations across contexts, particularly focusing on the 6th generation of forward-looking PDE generation named""Intelligent Public Data Generation""that represents a paradigm shift driven by emerging technologies such as cloud computing, Artificial Intelligence, Natural Language Processing tools, Generative AI, and Large Language Models (LLM) with potential to contribute to both automation and augmentation of business processes within these ecosystems. By transcending their traditional status as a mere component, evolving into both an actor and a stakeholder simultaneously, these technologies catalyze innovation and progress, enhancing PDE management strategies to align with societal, regulatory, and technical imperatives in the digital era.",International Conference on Electronic Government,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2405.13606
91d880116dcfd83d68b143026862de93f8aabb38,https://www.semanticscholar.org/paper/91d880116dcfd83d68b143026862de93f8aabb38,role of two-way asymmetrical communication in sustaining public relations,"Internet technology's worldwide success and adoption have provided organizations with direct access to their constituents and customers. Especially, organizations relying on online platforms provide comparatively better services and have strong relations with their clients. This research also focused on relevant phenomena in the United Arab Emirates banking sector organizations. The researchers employed a cross-sectional design and randomly selected a sample of n=400 individuals. Results revealed a significant impact of customer support services on providing product information (p>0.008) and service quality (p>0.000). Further, the effect of service quality on Artificial Intelligence also remained significant (p>0.000). Besides, Artificial Intelligence is also found significantly impact the Public Relations of Emirati banks (p>0.006). Finally, the mediating impact of communication skills on Artificial Intelligence and Public Relations remained significant (p>0.088). Moreover, the Artificial Neural Network (ANN) revealed the Sum of Square Values at 568.19, the Overall Relative Error value at 0.813, and the accuracy level at 18.7% (training). While, regarding the testing, the Sum of Square Values remained at 256.80 and the Average Overall Relative Error value remained at 0.861, indicating an overall accuracy of 13.9%. Thus, it is concluded that the importance of two-way communication can be determined because it helps determine and understand the customers' needs and demands. The more an organization understands its customers, the more it fulfills their expectations, indicating the importance of two-way communication. Finally, this research recommends more studies regarding AI-enabled Emotional Intelligence in other sectors to dig out in-depth results. Doi: 10.28991/ESJ-2024-08-03-020 Full Text: PDF",Emerging Science Journal,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.28991/esj-2024-08-03-020
15b153e0f6342ad455bfb5e2b6090b89c8066340,https://www.semanticscholar.org/paper/15b153e0f6342ad455bfb5e2b6090b89c8066340,integrating esg and ai: a comprehensive responsible ai assessment framework,"Artificial Intelligence (AI) is a widely developed and adopted technology across entire industry sectors. Integrating environmental, social, and governance (ESG) considerations with AI investments is crucial for ensuring ethical and sustainable technological advancement. Particularly from an investor perspective, this integration not only mitigates risks but also enhances long-term value creation by aligning AI initiatives with broader societal goals. Yet, this area has been less explored in both academia and industry. To bridge the gap, we introduce a novel ESG-AI framework, which is developed based on insights from engagements with 28 companies and comprises three key components. The framework provides a structured approach to this integration, developed in collaboration with industry practitioners. The ESG-AI framework provides an overview of the environmental and social impacts of AI applications, helping users such as investors assess the materiality of AI use. Moreover, it enables investors to evaluate a company's commitment to responsible AI through structured engagements and thorough assessment of specific risk areas. We have publicly released the framework and toolkit in April 2024, which has received significant attention and positive feedback from the investment community. This paper details each component of the framework, demonstrating its applicability in real-world contexts and its potential to guide ethical AI investments.",arXiv.org,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.48550/arXiv.2408.00965
38e353bdf22752a2d9f535a2f8617d41d7f1d49d,https://www.semanticscholar.org/paper/38e353bdf22752a2d9f535a2f8617d41d7f1d49d,a smart approach for budget deficits predictionunder economic shocks,"Historically, the main behavior of fiscal policy is to distribute resources, income, and expenditures, which are interconnected functions of economic stability. Recently, the scope of public sector economics has expanded beyond budgetary components in parallel with the development of public finance. While the budget reached the economic division form of budget items based on program and performance theories, Budget monitoring, and financial risk management are currently challenging, particularly in the face of monetary policy uncertainty. Financial institutions are crucially concerned with the stability of public finance in low-income countries (LICs) as it contributes to improved investor confidence and fiscal decision-making. Hence, economists investigated uncertainty shocks and contributed to managing financial risks with global and energy uncertainty indices. Furthermore, the maturity of digital transformation and artificial intelligence financial applications catalyzed scholars to examine its contributions in the fiscal distress prediction field. Hence, this research aims to integrate artificial intelligence into financial performance analysis to bridge the gap in budget forecasting. The study was aimed at proposing an Economics Division Uncertainty approach (EDUA), which combined (ARIMA) and (LSTM) models for time series analysis of Nuclear Material Authority expenditures over the previous five years divided into quarterly periods, to achieve efficiency in spending. The (ARIMA) model’s (ADF) results showed that uncertainty indicators are highly significant. The best (p-value) in the first and second differences in (ARIMA) models is (0.0001) for petroleum items, (0.0001) for solar price rates, (0.001) for the US exchange rate, and (0.003) for electricity price rates, when compared to (EDU_LSTM). Both models have similar accuracy rates, with the best being (EDU_ARIMA) (solar price 97%, USD exchange rate 84%). The second study proposed a composite model of four machine-learning tools to enhance financial performance during financial distress. The study collected (12) indicators from general financial literature and corporate studies, utilizing the (XGBOOST, Random Forest, KNN, and Naïve Bayes) models. Comparing the accuracy results for each model presented different accuracy results in the deep learning models over five years of data. The best accuracy score was for Random Forest at (69%), XGBOOT at (68%), and KNN at (68%). We recommended explainable AI as future research to interpret the budget deficit during the fiscal year period. Keywords: Economic Shocks, Uncertainty, Budget Reliability, Financial Distress Prediction, Artificial Intelligence.",International Journal of Accounting and Management Sciences,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.56830/ijams07202403
e8761fc9f655c137d3990a9c46fab0fd84839916,https://www.semanticscholar.org/paper/e8761fc9f655c137d3990a9c46fab0fd84839916,decoding algorithmic literacy among journalists,"Recent developments in generative Artificial Intelligence (AI) have revitalized academic discourse on algorithmic systems, particularly on their potential, ethical considerations, risks, and regulatory challenges. Extensive research has examined how algorithms affect communication processes, focusing on their influence on news organizations, journalistic practices, public-media dynamics, media literacy, and combating disinformation and filter bubbles.
An emergent strand of research defines and measures the multidimensional concept of algorithmic literacy. However limited research exists on the intersection of algorithmic literacy and journalism. This gap is particularly concerning given the pivotal role of journalism in shaping public discourse, informing citizens, upholding democratic values and contrasting disinformation. Understanding how journalists perceive and engage with algorithms is essential, as these technologies significantly influence their professional tasks, including content production and distribution.
In Portugal, where newcomer journalists work in precarious conditions and digital media transformation is rapidly evolving, understanding how journalists interact with and perceive algorithms is vital. Our study, through a multi-phased approach, aims to fill this gap questioning how can algorithmic literacy, encompassing cognitive, attitudinal and behavioural dimensions, be effectively assessed among professional journalists?
The exploratory results present a validated methodological tool, instrument based on a multi-dimensional analytical framework and specifically designed to measure algorithmic literacy levels and to assess journalists’ experiences. Critical discussion addresses the methodological procedures and preliminary findings from the pre-test, offering insights into Portuguese journalists' understanding, perceptions, and competencies regarding algorithmic systems. By shedding light on the cognitive, affective, and behavioural aspects of journalists’ engagement with algorithms, this study contributes to a deeper understanding of the algorithmic literacy among journalists, which is essential to sustain the quality of their work and for an effective counteraction against disinformation. It also opens avenues for similar studies in other geographical or professional contexts.",Observatorio (OBS*),2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.15847/obsobs18520242433
2a3d3eeda974703f1727ff724f1078bd5e6b2e1f,https://www.semanticscholar.org/paper/2a3d3eeda974703f1727ff724f1078bd5e6b2e1f,therapybot: a chatbot for mental well-being using transformers,"The field of natural language processing (NLP) and conversational artificial intelligence (AI) has one ingenious application in the psychological space. Depression and anxiety are two major issues that the world is facing, with close to 41% of adults reporting these symptoms in the United States alone, as of December 2020. It has also been observed that most of the people are not open about it. As a result, it is critical to address this issue on a global scale. Developed countries reportedly have 9 psychiatrists per 100,000 people. One way to mitigate this is the use of chatbots. We propose a transformer-based methodology to build a therapy bot that has been trained on a combination of open-domain conversations from a publicly available dataset and therapist-client conversations from a self-constructed dataset. This end-to-end data-driven model shows quality performance in conversations and adds value by aiding in the case of mental health issues. The proposed architecture is proven to be effective in its usability in the psychological space for both single-turn and multi-turn dialogue. The performance of the proposed system shows loss is 0.29 and perplexity is 1.34, both metrics keeps gradually decreasing and it means an improvement in performance of chatbots system.",International Journal of Advances in Applied Sciences,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.11591/ijaas.v13.i1.pp1-12
19b3152e97e63a38ec7406abb3492326ad27af82,https://www.semanticscholar.org/paper/19b3152e97e63a38ec7406abb3492326ad27af82,enhancing readability and detection of age-related macular degeneration using optical coherence tomography imaging: an ai approach,"Artificial intelligence has been used effectively in medical diagnosis. The objective of this project is to examine the application of a collective AI model using weighted fusion of predicted probabilities from different AI architectures to diagnose various retinal conditions based on optical coherence tomography (OCT). A publicly available Noor dataset, comprising 16,822, images from 554 retinal OCT scans of 441 patients, was used to predict a diverse spectrum of age-related macular degeneration (AMD) stages: normal, drusen, or choroidal neovascularization. These predictions were compared with predictions from ResNet, EfficientNet, and Attention models, respectively, using precision, recall, F1 score, and confusion matric and receiver operating characteristics curves. Our collective model demonstrated superior accuracy in classifying AMD compared to individual ResNet, EfficientNet, and Attention models, showcasing the effectiveness of using trainable weights in the ensemble fusion process, where these weights dynamically adapt during training rather than being fixed values. Specifically, our ensemble model achieved an accuracy of 91.88%, precision of 92.54%, recall of 92.01%, and F1 score of 92.03%, outperforming individual models. Our model also highlights the refinement process undertaken through a thorough examination of initially misclassified cases, leading to significant improvements in the model’s accuracy rate to 97%. This study also underscores the potential of AI as a valuable tool in ophthalmology. The proposed ensemble model, combining different mechanisms highlights the benefits of model fusion for complex medical image analysis.",Bioengineering,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.3390/bioengineering11040300
2b5be61b9f19c483461fbbd19658cb720c122c26,https://www.semanticscholar.org/paper/2b5be61b9f19c483461fbbd19658cb720c122c26,a novel approach to recognition of alzheimer’s and parkinson’s diseases: random subspace ensemble classifier based on deep hybrid features with a super-resolution image,"Background Artificial intelligence technologies have great potential in classifying neurodegenerative diseases such as Alzheimer’s and Parkinson’s. These technologies can aid in early diagnosis, enhance classification accuracy, and improve patient access to appropriate treatments. For this purpose, we focused on AI-based auto-diagnosis of Alzheimer’s disease, Parkinson’s disease, and healthy MRI images. Methods In the current study, a deep hybrid network based on an ensemble classifier and convolutional neural network was designed. First, a very deep super-resolution neural network was adapted to improve the resolution of MRI images. Low and high-level features were extracted from the images processed with the hybrid deep convolutional neural network. Finally, these deep features are given as input to the k-nearest neighbor (KNN)-based random subspace ensemble classifier. Results A 3-class dataset containing publicly available MRI images was utilized to test the proposed architecture. In experimental works, the proposed model produced 99.11% accuracy, 98.75% sensitivity, 99.54% specificity, 98.65% precision, and 98.70% F1-score performance values. The results indicate that our AI system has the potential to provide valuable diagnostic assistance in clinical settings.",PeerJ Computer Science,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.7717/peerj-cs.1862
73bf7665b0461e08b38550781911336666db7497,https://www.semanticscholar.org/paper/73bf7665b0461e08b38550781911336666db7497,"“i, for one, welcome our new” ai jurors: chatgpt and the future of the jury system in american law","This article explores the potential for advanced generative text AI systems like ChatGPT to serve as a replacement for human juries in the modern legal system. It argues that the vast knowledge base and perspective-aggregation capabilities of these AI models uniquely position them as potentially superior embodiments of the “community conscience” that juries are meant to represent. By synthesizing diverse viewpoints into nuanced, context-sensitive judgments, AI juries could in theory do justice to the broader values and concerns of society in ways that 12-person human juries often fail to achieve. The article first examines the technical capabilities of state-of-the-art language models like ChatGPT, emphasizing the vast scope and diversity of their training data which spans a huge range of human knowledge and perspectives. It then traces the historical development of the jury system and its essential functions as both the moral conscience of the community and a source of democratic legitimacy for the legal system. Building on this foundation, the article makes the case that AI is poised to fulfill the representative and deliberative roles of juries more effectively than human jurors by virtue of its unparalleled capacity to absorb and synthesize society’s heterogeneous values and viewpoints. However, it also carefully considers the significant risks and challenges associated with AI juries, including issues of algorithmic bias, the opacity of machine reasoning, the potential erosion of public trust, and the philosophical implications of outsourcing moral judgment to artificial intelligence. Ultimately, the article argues that while the use of AI in legal decision-making is likely inevitable, it is crucial that we proactively shape the terms of this integration in ways that uphold the core values of fairness, transparency, and democratic accountability. The jury system has long been celebrated as a bastion of citizen participation in the law – the article concludes by calling for a robust public dialogue on how AI can be harnessed to enhance, rather than erode, this vital civic institution. Keywords: Artificial Intelligence, ChatGPT, Jury, AI Ethics, Moral Reasoning, Machine Learning, Algorithm, Legal Tech, Law and Technology, AI Governance","International Journal of Law, Ethics, and Technology",2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.55574/ilsm6729
5d16be61d87a8431733033bb92098eb4915ef528,https://www.semanticscholar.org/paper/5d16be61d87a8431733033bb92098eb4915ef528,secure remote sensing data with blockchain distributed ledger technology: a solution for smart cities,"Particularly in the context of smart cities, remote sensing data (RSD) has emerged as one of the hottest study topics in information and communication technology (ICT) today. The development of machine learning (ML) and artificial intelligence (AI) has made it possible to solve a number of issues, including automation, control access, optimization, monitoring, and management. Simultaneously, there are significant issues with the design and development of the process hierarchy, including inadequate training records, centralized architecture, data privacy protection, and overall resource consumption restrictions. The development of Distributed Ledger Technology (DLT), on the other hand, provides a decentralized infrastructure that allows systems to eliminate centralized data-sharing procedures of smart cities while transferring from network node to network node, and third-party access control solves machine learning issues. To process an ideal data delivery mechanism for the smart cities analytical model, the paper employs Partial Swam Optimization (POS) in conjunction with a secure blockchain distributed consortium network. This work makes three contributions. Firstly, it offers a safe transmission method that combines blockchain and machine learning to optimize the path for reliable data delivery across secure channels. Second, neighborhood encryption sequences are carried out using NuCypher proxy re-encryption-enabled value encryption, a public key cryptographic approach that avoids cypher conversion. Third, Artificial Neural Networks (ANNs) can solve the data deliverance classification problem in smart cities by optimizing record management and preservation.",IEEE Access,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1109/ACCESS.2024.3401591
c37fd9c1303cce61ad8e84b8c4fb8bf36ba8fa70,https://www.semanticscholar.org/paper/c37fd9c1303cce61ad8e84b8c4fb8bf36ba8fa70,gai as a catalyst in national technology sovereignty: evaluating the influence of gai on government policy,"As a result of the prominence of generative artificial intelligence across diverse fields, it has become necessary for governments to develop national strategies for directing the ethical use of artificial intelligence to respect fundamental human values. This paper explores the role of Generative Artificial Intelligence (GAI) in technology sovereignty, its contributions, and benefits for the government, associated risks, and challenges, and how it influences government policies. It begins with examining GAI's capabilities to comprehend how it understands natural language, trains on existing data, and generates realistic outputs, followed by a discussion of its potential benefits for governments that enable them to act independently and autonomously in diverse sectors. It highlights how it can empower them to administer technological ecosystems, promote domestic innovation, and facilitate policy-making processes. However, contrary to its benefits, GAI is also capable of inflicting negative consequences on society. Therefore, the paper also addresses the risks and challenges associated with GAI that necessitate reflection on existing policies and developing new ones that align with a nation's legal frameworks. Exploring the influence of GAI on government policies, the paper highlights the significance of collaboration in policy-making endeavors to ensure ethical future developments and bring value to public interest and democratic values. This comprehensive analysis aims to shed light on the responsible and ethical use of GAI to preserve human rights, promote economic growth, sustain social justice, and inform the responsible use of GAI within the framework of technology sovereignty.",Digital Government Research,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.1145/3657054.3657126
a73b1203e1133a535751ea020bda726892cf65a8,https://www.semanticscholar.org/paper/a73b1203e1133a535751ea020bda726892cf65a8,the distinction of evaluation on companies in different fields,"This paper explores the variations in Return on Equity (ROE) and Price-to-Sales Ratio among publicly traded companies across different time periods and market capitalizations. The analysis employs Linear Regression and Correlation Coefficients to examine the relationships between ROE, Price-to-Sales Ratio, Market Capitalization, and economic conditions during these periods. The findings reveal that Price-to-Sales Ratio serves as a reliable indicator of a company's market capitalization. Furthermore, companies within the same industry exhibit substantial disparities in Market Capitalization, ROE, Price-to-Sales Ratio, Price-to-Earnings (P/E) Ratio, and PEG Index due to differing corporate strategies and backgrounds. For instance, in the new energy sector, both BYD and NIO display a negative correlation between market capitalization, while Tesla contradicts this trend. This discrepancy is attributed to internal factors such as asset composition, liabilities, and shareholder structure, which significantly influence a company's financial performance. The Market Capitalization of these new energy companies is predicted to rise due to global interest in AI technology, with technology companies being at the forefront of AI development. In the technology sector, companies like Google have solidified their positions by advancing AI concepts. New entrants, like Apple, combining Artificial Intelligence and Robotics, are gaining consumer support, indicating potential Market Cap. growth. The fashion industry also demonstrates distinctive strategies, with companies like NIKE, Adidas, and Anta focusing on sustainability and carbon neutrality. Therefore, future company evaluations should consider both financial indices and a company's long-term vision and sustainability practices to predict their future value effectively.","Advances in Economics, Management and Political Sciences",2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.54254/2754-1169/74/20241424
581e28a4bde8d0d8bc08b4cdce31f21692fee56f,https://www.semanticscholar.org/paper/581e28a4bde8d0d8bc08b4cdce31f21692fee56f,modeling of improved sine trigonometric single valued neutrosophic information based air pollution prediction approach,"Industrialization and urbanization air is getting polluted due to human activities. CO, NO, C6H6, etc., are the major air pollutants. The focus of air pollutants in ambient air is controlled by the climatological parameters including wind direction, atmospheric speed of wind, temperature, and humidity. Air pollution prediction is a critical sector where machine learning (ML) technique plays a major role. Its main purpose is to tackle and understand the damaging effects of air pollutants on the environment and human health. By using a range of ML techniques such as neural networks, regression, and decision trees, we could analyze historical data on air quality alongside geographical and meteorological factors. This allows us to design model that could detect patterns and predict pollution levels. By taking proactive measures such as providing timely alerts to the public, adjusting controls on emissions, and, implementing strategies to reduce pollution, we can work towards creating healthier and cleaner environments. Embracing the potential of artificial intelligence (AI) in air pollution prediction empowers us to protect the well-being of our communities and make informed decisions. Therefore, this study develops an Improved Sine Trigonometric Single Valued Neutrosophic Information based Air Pollution Prediction (ISTSVNI-APP) approach. The major objective of the ISTSVNI-APP technique is to exploit AI concepts with neutrosophic sets (NS) models for the forecasting of air pollution. To do so, the ISTSVNI-APP technique makes use of min-max normalization as the initial preprocessing step. For predicting air pollution, the ISTSVNI-APP technique uses STSVNI approach. To improve the performance of the ISTSVNI-APP technique, modified crow search algorithm (MCSA) is used for the parameter tuning of the STSVNI system. The performance evaluation of the ISTSVNI-APP method is verified utilizing benchmark dataset. The experimental outcomes stated that the ISTSVNI-APP technique gains better performance in predicting air pollution",International journal of neutrosophic science,2024,semantic_scholar,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',10.54216/ijns.240208
